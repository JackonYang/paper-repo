{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721860"
                        ],
                        "name": "M. Wainwright",
                        "slug": "M.-Wainwright",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Wainwright",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wainwright"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We now have the two necessary ingredients to define a convex variational principle based on a log-determinant relaxation [243]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Finally, there are other convex variational relaxations that are not directly based on convex combinations of tractable distributions, including the method of conditional entropy decompositions [92], and methods based on semidefinite constraints and log-determinant programming [243]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We illustrate this two-step procedure by describing a log-determinant relaxation for discrete Markov random fields [243]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "A key property of this construction is that it matches the discrete entropy of X with the differential entropy of X\u0303\u2014that is, h(X\u0303) = H(X); see Wainwright and Jordan [243] for the proof."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Wainwright and Jordan [243] derive an efficient algorithm for solving a slightly weakened form of the log-determinant problem (7."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9920431,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d233ae0ab616b400612759fbe59c2b134ab2b334",
            "isKey": false,
            "numCitedBy": 90,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Graphical models are well suited to capture the complex and non-Gaussian statistical dependencies that arise in many real-world signals. A fundamental problem common to any signal processing application of a graphical model is that of computing approximate marginal probabilities over subsets of nodes. This paper proposes a novel method, applicable to discrete-valued Markov random fields (MRFs) on arbitrary graphs, for approximately solving this marginalization problem . The foundation of our method is a reformulation of the marginalization problem as the solution of a low-dimensional convex optimization problem over the marginal polytope. Exactly solving this problem for general graphs is intractable; for binary Markov random fields, we describe how to relax it by using a Gaussian bound on the discrete entropy and a semidefinite outer bound on the marginal polytope. This combination leads to a log-determinant maximization problem that can be solved efficiently by interior point methods, thereby providing approximations to the exact marginals. We show how a slightly weakened log-determinant relaxation can be solved even more efficiently by a dual reformulation. When applied to denoising problems in a coupled mixture-of-Gaussian model defined on a binary MRF with cycles, we find that the performance of this log-determinant relaxation is comparable or superior to the widely used sum-product algorithm over a range of experimental conditions."
            },
            "slug": "Log-determinant-relaxation-for-approximate-in-Wainwright-Jordan",
            "title": {
                "fragments": [],
                "text": "Log-determinant relaxation for approximate inference in discrete Markov random fields"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel method, applicable to discrete-valued Markov random fields on arbitrary graphs, for approximately solving this marginalization problem, and finds that the performance of this log-determinant relaxation is comparable or superior to the widely used sum-product algorithm over a range of experimental conditions."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Signal Processing"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721860"
                        ],
                        "name": "M. Wainwright",
                        "slug": "M.-Wainwright",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Wainwright",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wainwright"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "See the papers [171, 247, 235] for further details on tree EP."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": ", see Wainwright [235])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This section is a refinement of results from the thesis [235]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "[263, 264] and further explored by various researchers [184, 163, 108, 235, 265], that improves both components simultaneously."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1735253,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "38c47af4d89c318e40004258f1a7523a2f306ad9",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 165,
            "paperAbstract": {
                "fragments": [],
                "text": "Stochastic processes de ned on graphs arise in a tremendous variety of elds, including statistical physics, signal processing, computer vision, arti cial intelligence, and information theory. The formalism of graphical models provides a useful language with which to formulate fundamental problems common to all of these elds, including estimation, model tting, and sampling. For graphs without cycles, known as trees, all of these problems are relatively well-understood, and can be solved e\u00c6ciently with algorithms whose complexity scales in a tractable manner with problem size. In contrast, these same problems present considerable challenges in general graphs with cycles. The focus of this thesis is the development and analysis of methods, both exact and approximate, for problems on graphs with cycles. Our contributions are in developing and analyzing techniques for estimation, as well as methods for computing upper and lower bounds on quantities of interest (e.g., marginal probabilities; partition functions). In order to do so, we make use of exponential representations of distributions, as well as insight from the associated information geometry and Legendre duality. Our results demonstrate the power of exponential representations for graphical models, as well as the utility of studying collections of modi ed problems de ned on trees embedded within the original graph with cycles. The speci c contributions of this thesis include the following. We develop a method for performing exact estimation of Gaussian processes on graphs with cycles by solving a sequence of modi ed problems on embedded spanning trees. We present the tree-based reparameterization framework for approximate estimation of discrete processes. This framework leads to a number of theoretical results on belief propagation and related algorithms, including characterizations of their xed points and the associated approximation error. Next we extend the notion of reparameterization to a much broader class of methods for approximate inference, including Kikuchi methods, and present results on their xed points and accuracy. Finally, we develop and analyze a novel class of upper bounds on the log partition function based on convex combinations of distributions in the exponential domain. In the special case of combining tree-structured distributions, the associated dual function gives an interesting perspective on the Bethe free energy. Thesis Supervisors: Alan S. Willsky and Tommi S. Jaakkola Title: Professors of Electrical Engineering and Computer Science"
            },
            "slug": "Stochastic-processes-on-graphs-with-cycles:-and-Wainwright",
            "title": {
                "fragments": [],
                "text": "Stochastic processes on graphs with cycles: geometric and variational approaches"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A method for performing exact estimation of Gaussian processes on graphs with cycles by solving a sequence of modi ed problems on embedded spanning trees, and a tree-based reparameterization framework for approximate estimation of discrete processes are presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678311"
                        ],
                        "name": "M. Welling",
                        "slug": "M.-Welling",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Welling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Welling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39530238"
                        ],
                        "name": "S. Parise",
                        "slug": "S.-Parise",
                        "structuredName": {
                            "firstName": "Sridevi",
                            "lastName": "Parise",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Parise"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The use of such approximate methods and their impact on parameter estimation is still an active area of research [220, 226, 238, 236, 248]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1161652,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6e896f4a5c393bdf5ba91a7b7225140cdf561039",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "While learning the maximum likelihood value of parameters of an undirected graphical model is hard, modelling the posterior distribution over parameters given data is harder. Yet, undirected models are ubiquitous in computer vision and text modelling (e.g. conditional random fields). But where Bayesian approaches for directed models have been very successful, a proper Bayesian treatment of undirected models in still in its infant stages. We propose a new method for approximating the posterior of the parameters given data based on the Laplace approximation. This approximation requires the computation of the covariance matrix over features which we compute using the linear response approximation based in turn on loopy belief propagation. We develop the theory for conditional and 'unconditional' random fields with or without hidden variables. In the conditional setting we introduce a new variant of bagging suitable for structured domains. Here we run the loopy max-product algorithm on a 'super-graph' composed of graphs for individual models sampled from the posterior and connected by constraints. Experiments on real world data validate the proposed methods."
            },
            "slug": "Bayesian-Random-Fields:-The-Bethe-Laplace-Welling-Parise",
            "title": {
                "fragments": [],
                "text": "Bayesian Random Fields: The Bethe-Laplace Approximation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A new method for approximating the posterior of the parameters given data based on the Laplace approximation is proposed and the theory for conditional and 'unconditional' random fields with or without hidden variables is developed."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1773821"
                        ],
                        "name": "Matthew J. Beal",
                        "slug": "Matthew-J.-Beal",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Beal",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew J. Beal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In the literature on the topic, however, the term \u201cvariational Bayes\u201d has been reserved thus far for the application of the mean-field variational method to Bayesian inference [14, 88]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11861569,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "00cf63a7926a826f7cf73c1d5edb117f98d70c2c",
            "isKey": false,
            "numCitedBy": 1836,
            "numCiting": 181,
            "paperAbstract": {
                "fragments": [],
                "text": "The Bayesian framework for machine learning allows for the incorporation of prior knowledge in a coherent way, avoids overfitting problems, and provides a principled basis for selecting between alternative models. Unfortunately the computations required are usually intractable. This thesis presents a unified variational Bayesian (VB) framework which approximates these computations in models with latent variables using a lower bound on the marginal likelihood. Chapter 1 presents background material on Bayesian inference, graphical models, and propagation algorithms. Chapter 2 forms the theoretical core of the thesis, generalising the expectationmaximisation (EM) algorithm for learning maximum likelihood parameters to the VB EM algorithm which integrates over model parameters. The algorithm is then specialised to the large family of conjugate-exponential (CE) graphical models, and several theorems are presented to pave the road for automated VB derivation procedures in both directed and undirected graphs (Bayesian and Markov networks, respectively). Chapters 3-5 derive and apply the VB EM algorithm to three commonly-used and important models: mixtures of factor analysers, linear dynamical systems, and hidden Markov models. It is shown how model selection tasks such as determining the dimensionality, cardinality, or number of variables are possible using VB approximations. Also explored are methods for combining sampling procedures with variational approximations, to estimate the tightness of VB bounds and to obtain more effective sampling algorithms. Chapter 6 applies VB learning to a long-standing problem of scoring discrete-variable directed acyclic graphs, and compares the performance to annealed importance sampling amongst other methods. Throughout, the VB approximation is compared to other methods including sampling, Cheeseman-Stutz, and asymptotic approximations such as BIC. The thesis concludes with a discussion of evolving directions for model selection including infinite models and alternative approximations to the marginal likelihood."
            },
            "slug": "Variational-algorithms-for-approximate-Bayesian-Beal",
            "title": {
                "fragments": [],
                "text": "Variational algorithms for approximate Bayesian inference"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A unified variational Bayesian (VB) framework which approximates computations in models with latent variables using a lower bound on the marginal likelihood and is compared to other methods including sampling, Cheeseman-Stutz, and asymptotic approximations such as BIC."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744700"
                        ],
                        "name": "Zoubin Ghahramani",
                        "slug": "Zoubin-Ghahramani",
                        "structuredName": {
                            "firstName": "Zoubin",
                            "lastName": "Ghahramani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zoubin Ghahramani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35132120"
                        ],
                        "name": "T. Jaakkola",
                        "slug": "T.-Jaakkola",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Jaakkola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jaakkola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796044"
                        ],
                        "name": "L. Saul",
                        "slug": "L.-Saul",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Saul",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Saul"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our treatment is brief; further details can be found in various sources [2, 62, 139, 122, 151]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2073260,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6120cc252bc74239012f11b8b075cb7cb16bee26",
            "isKey": false,
            "numCitedBy": 2947,
            "numCiting": 127,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a tutorial introduction to the use of variational methods for inference and learning in graphical models (Bayesian networks and Markov random fields). We present a number of examples of graphical models, including the QMR-DT database, the sigmoid belief network, the Boltzmann machine, and several variants of hidden Markov models, in which it is infeasible to run exact inference algorithms. We then introduce variational methods, which exploit laws of large numbers to transform the original graphical model into a simplified graphical model in which inference is efficient. Inference in the simpified model provides bounds on probabilities of interest in the original model. We describe a general framework for generating variational transformations based on convex duality. Finally we return to the examples and demonstrate how variational algorithms can be formulated in each case."
            },
            "slug": "An-Introduction-to-Variational-Methods-for-Models-Jordan-Ghahramani",
            "title": {
                "fragments": [],
                "text": "An Introduction to Variational Methods for Graphical Models"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "This paper presents a tutorial introduction to the use of variational methods for inference and learning in graphical models (Bayesian networks and Markov random fields), and describes a general framework for generating variational transformations based on convex duality."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145617808"
                        ],
                        "name": "D. Barber",
                        "slug": "D.-Barber",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Barber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Barber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783429"
                        ],
                        "name": "W. Wiegerinck",
                        "slug": "W.-Wiegerinck",
                        "structuredName": {
                            "firstName": "Wim",
                            "lastName": "Wiegerinck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Wiegerinck"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This structured mean field approach was first proposed by Saul and Jordan [204], and further developed by various researchers [9, 254, 117]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16049210,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eee1c6295c7778a966261424c9d48ff78fb072be",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Graphical models provide a broad probabilistic framework with applications in speech recognition (Hidden Markov Models), medical diagnosis (Belief networks) and artificial intelligence (Boltzmann Machines). However, the computing time is typically exponential in the number of nodes in the graph. Within the variational framework for approximating these models, we present two classes of distributions, decimatable Boltzmann Machines and Tractable Belief Networks that go beyond the standard factorized approach. We give generalised mean-field equations for both these directed and undirected approximations. Simulation results on a small benchmark problem suggest using these richer approximations compares favorably against others previously reported in the literature."
            },
            "slug": "Tractable-Variational-Structures-for-Approximating-Barber-Wiegerinck",
            "title": {
                "fragments": [],
                "text": "Tractable Variational Structures for Approximating Graphical Models"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work presents two classes of distributions, decimatable Boltzmann Machines and Tractable Belief Networks that go beyond the standard factorized approach, and gives generalised mean-field equations for both these directed and undirected approximations."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799035"
                        ],
                        "name": "Erik B. Sudderth",
                        "slug": "Erik-B.-Sudderth",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Sudderth",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Erik B. Sudderth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721860"
                        ],
                        "name": "M. Wainwright",
                        "slug": "M.-Wainwright",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Wainwright",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wainwright"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701607"
                        ],
                        "name": "A. Willsky",
                        "slug": "A.-Willsky",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Willsky",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Willsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 126
                            }
                        ],
                        "text": "3), both of which solve the quadratic program in an iterative manner, or by iterative algorithms based on tractable subgraphs [218, 158]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 542323,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "d2d69f43a86c7e8339099592ec2b93f56d3cd2a0",
            "isKey": false,
            "numCitedBy": 95,
            "numCiting": 104,
            "paperAbstract": {
                "fragments": [],
                "text": "Graphical models provide a powerful general framework for encoding the structure of large-scale estimation problems. However, the graphs describing typical real-world phenomena contain many cycles, making direct estimation procedures prohibitively costly. In this paper, we develop an iterative inference algorithm for general Gaussian graphical models. It operates by exactly solving a series of modified estimation problems on spanning trees embedded within the original cyclic graph. When these subproblems are suitably chosen, the algorithm converges to the correct conditional means. Moreover, and in contrast to many other iterative methods, the tree-based procedures we propose can also be used to calculate exact error variances. Although the conditional mean iteration is effective for quite densely connected graphical models, the error variance computation is most efficient for sparser graphs. In this context, we present a modeling example suggesting that very sparsely connected graphs with cycles may provide significant advantages relative to their tree-structured counterparts, thanks both to the expressive power of these models and to the efficient inference algorithms developed herein. The convergence properties of the proposed tree-based iterations are characterized both analytically and experimentally. In addition, by using the basic tree-based iteration to precondition the conjugate gradient method, we develop an alternative, accelerated iteration that is finitely convergent. Simulation results are presented that demonstrate this algorithm's effectiveness on several inference problems, including a prototype distributed sensing application."
            },
            "slug": "Embedded-trees:-estimation-of-Gaussian-Processes-on-Sudderth-Wainwright",
            "title": {
                "fragments": [],
                "text": "Embedded trees: estimation of Gaussian Processes on graphs with cycles"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "An iterative inference algorithm for general Gaussian graphical models that operates by exactly solving a series of modified estimation problems on spanning trees embedded within the original cyclic graph, and develops an alternative, accelerated iteration that is finitely convergent."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Signal Processing"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050895"
                        ],
                        "name": "S. Lauritzen",
                        "slug": "S.-Lauritzen",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Lauritzen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lauritzen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Examples of such algorithms include the family of expectationpropagation algorithms due to Minka [172], the related class of assumed density filtering methods [149, 161, 37], expectation-consistent inference [181], structured summary-propagation algorithms [61, 112], and"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17051088,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a87f270ac2c8420db2669e5e12abb6aff0755115",
            "isKey": false,
            "numCitedBy": 493,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract A scheme is presented for modeling and local computation of exact probabilities, means, and variances for mixed qualitative and quantitative variables. The models assume that the conditional distribution of the quantitative variables, given the qualitative, is multivariate Gaussian. The computational architecture is set up by forming a tree of belief universes, and the calculations are then performed by local message passing between universes. The asymmetry between the quantitative and qualitative variables sets some additional limitations for the specification and propagation structure. Approximate methods when these are not appropriately fulfilled are sketched. It has earlier been shown how to exploit the local structure in the specification of a discrete probability model for fast and efficient computation, thereby paving the way for exploiting probability-based models as parts of realistic systems for planning and decision support. The purpose of this article is to extend this computational s..."
            },
            "slug": "Propagation-of-Probabilities,-Means,-and-Variances-Lauritzen",
            "title": {
                "fragments": [],
                "text": "Propagation of Probabilities, Means, and Variances in Mixed Graphical Association Models"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The purpose of this article is to extend the local structure in the specification of a discrete probability model for fast and efficient computation, thereby paving the way for exploiting probability-based models as parts of realistic systems for planning and decision support."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2627005"
                        ],
                        "name": "T. Roosta",
                        "slug": "T.-Roosta",
                        "structuredName": {
                            "firstName": "Tanya",
                            "lastName": "Roosta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Roosta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721860"
                        ],
                        "name": "M. Wainwright",
                        "slug": "M.-Wainwright",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Wainwright",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wainwright"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144797536"
                        ],
                        "name": "S. Sastry",
                        "slug": "S.-Sastry",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Sastry",
                            "middleNames": [
                                "Shankar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sastry"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "[199] provide sufficient conditions for convergence, based on contraction arguments such as those used for ordinary sumproduct [225, 87, 175, 115]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 213
                            }
                        ],
                        "text": "Moreover, for graphical models where all configurations are given strictly positive mass (such as graphical models in exponential form with finite \u03b8), the sum-product messages stay bounded strictly away from zero [199], so that there is always an optimum \u03c4\u2217 with strictly positive elements."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 38
                            }
                        ],
                        "text": "In subsequent work, other researchers [115, 175, 199] have used various types of contraction arguments to obtain sharper conditions for convergence, or uniqueness of fixed points [106]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7969654,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dcc1e6ab4ade23dd46584b0d6a8e847ed3901508",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "Markov random fields are designed to represent structured dependencies among large collections of random variables, and are well-suited to capture the structure of real-world signals. Many fundamental tasks in signal processing (e.g., smoothing, denoising, segmentation etc.) require efficient methods for computing (approximate) marginal probabilities over subsets of nodes in the graph. The marginalization problem, though solvable in linear time for graphs without cycles, is computationally intractable for general graphs with cycles. This intractability motivates the use of approximate ldquomessage-passingrdquo algorithms. This paper studies the convergence and stability properties of the family of reweighted sum-product algorithms, a generalization of the widely used sum-product or belief propagation algorithm, in which messages are adjusted with graph-dependent weights. For pairwise Markov random fields, we derive various conditions that are sufficient to ensure convergence, and also provide bounds on the geometric convergence rates. When specialized to the ordinary sum-product algorithm, these results provide strengthening of previous analyses. We prove that some of our conditions are necessary and sufficient for subclasses of homogeneous models, but not for general models. The experimental simulations on various classes of graphs validate our theoretical results."
            },
            "slug": "Convergence-Analysis-of-Reweighted-Sum-Product-Roosta-Wainwright",
            "title": {
                "fragments": [],
                "text": "Convergence Analysis of Reweighted Sum-Product Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper studies the convergence and stability properties of the family of reweighted sum-product algorithms, a generalization of the widely used sum-Product or belief propagation algorithm, in which messages are adjusted with graph-dependent weights."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Signal Processing"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2571487"
                        ],
                        "name": "C. Yanover",
                        "slug": "C.-Yanover",
                        "structuredName": {
                            "firstName": "Chen",
                            "lastName": "Yanover",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Yanover"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46737210"
                        ],
                        "name": "Talya Meltzer",
                        "slug": "Talya-Meltzer",
                        "structuredName": {
                            "firstName": "Talya",
                            "lastName": "Meltzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Talya Meltzer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30400079"
                        ],
                        "name": "Yair Weiss",
                        "slug": "Yair-Weiss",
                        "structuredName": {
                            "firstName": "Yair",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yair Weiss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 149
                            }
                        ],
                        "text": "Various forms of these reweighted maxproduct algorithms have been applied in problems such as segmentation and disparity problems in computer vision [165, 134, 136, 246, 222, 260], error-control coding [73], side-chain prediction [261, 246], sensor fusion [43, 46]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11801724,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0ab5b00d4fb0ef319093f94d5024008b6000381",
            "isKey": false,
            "numCitedBy": 215,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of finding the most probable (MAP) configuration in graphical models comes up in a wide range of applications. In a general graphical model this problem is NP hard, but various approximate algorithms have been developed. Linear programming (LP) relaxations are a standard method in computer science for approximating combinatorial problems and have been used for finding the most probable assignment in small graphical models. However, applying this powerful method to real-world problems is extremely challenging due to the large numbers of variables and constraints in the linear program. Tree-Reweighted Belief Propagation is a promising recent algorithm for solving LP relaxations, but little is known about its running time on large problems. \n \nIn this paper we compare tree-reweighted belief propagation (TRBP) and powerful general-purpose LP solvers (CPLEX) on relaxations of real-world graphical models from the fields of computer vision and computational biology. We find that TRBP almost always finds the solution significantly faster than all the solvers in CPLEX and more importantly, TRBP can be applied to large scale problems for which the solvers in CPLEX cannot be applied. Using TRBP we can find the MAP configurations in a matter of minutes for a large range of real world problems."
            },
            "slug": "Linear-Programming-Relaxations-and-Belief-An-Study-Yanover-Meltzer",
            "title": {
                "fragments": [],
                "text": "Linear Programming Relaxations and Belief Propagation - An Empirical Study"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper compares tree-reweighted belief propagation (TRBP) and powerful general-purpose LP solvers (CPLEX) on relaxations of real-world graphical models from the fields of computer vision and computational biology and finds that TRBP almost always finds the solution significantly faster than all the solvers in CPLEX and more importantly, TRBP can be applied to large scale problems for which the solver in CLEX cannot be applied."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744700"
                        ],
                        "name": "Zoubin Ghahramani",
                        "slug": "Zoubin-Ghahramani",
                        "structuredName": {
                            "firstName": "Zoubin",
                            "lastName": "Ghahramani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zoubin Ghahramani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 118
                            }
                        ],
                        "text": "5(b) shows a factorial HMM, in which multiple chains are coupled by their links to a common set of observed variables [89]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 85
                            }
                        ],
                        "text": "24), consider a factorial hidden Markov model, as described in Ghahramani and Jordan [89]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 519313,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "78e510627d3f28601e370212bf063bbfa539ebed",
            "isKey": false,
            "numCitedBy": 1201,
            "numCiting": 103,
            "paperAbstract": {
                "fragments": [],
                "text": "Hidden Markov models (HMMs) have proven to be one of the most widely used tools for learning probabilistic models of time series data. In an HMM, information about the past is conveyed through a single discrete variable\u2014the hidden state. We discuss a generalization of HMMs in which this state is factored into multiple state variables and is therefore represented in a distributed manner. We describe an exact algorithm for inferring the posterior probabilities of the hidden state variables given the observations, and relate it to the forward\u2013backward algorithm for HMMs and to algorithms for more general graphical models. Due to the combinatorial nature of the hidden state representation, this exact algorithm is intractable. As in other intractable systems, approximate inference can be carried out using Gibbs sampling or variational methods. Within the variational framework, we present a structured approximation in which the the state variables are decoupled, yielding a tractable algorithm for learning the parameters of the model. Empirical comparisons suggest that these approximations are efficient and provide accurate alternatives to the exact methods. Finally, we use the structured approximation to model Bach's chorales and show that factorial HMMs can capture statistical structure in this data set which an unconstrained HMM cannot."
            },
            "slug": "Factorial-Hidden-Markov-Models-Ghahramani-Jordan",
            "title": {
                "fragments": [],
                "text": "Factorial Hidden Markov Models"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A generalization of HMMs in which this state is factored into multiple state variables and is therefore represented in a distributed manner, and a structured approximation in which the the state variables are decoupled, yielding a tractable algorithm for learning the parameters of the model."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30400079"
                        ],
                        "name": "Yair Weiss",
                        "slug": "Yair-Weiss",
                        "structuredName": {
                            "firstName": "Yair",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yair Weiss"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "However, it is known [244, 107] that for any discrete Markov random field in exponential family form with at most a single cycle, the sum-product has a unique fixed point, and always converges to it."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15402308,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "300f73c89bfeb6b88b9b18f63793568c3d06bee6",
            "isKey": false,
            "numCitedBy": 512,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "Graphical models, such as Bayesian networks and Markov networks, represent joint distributions over a set of variables by means of a graph. When the graph is singly connected, local propagation rules of the sort proposed by Pearl (1988) are guaranteed to converge to the correct posterior probabilities. Recently a number of researchers have empirically demonstrated good performance of these same local propagation schemes on graphs with loops, but a theoretical understanding of this performance has yet to be achieved. For graphical models with a single loop, we derive an analytical relationship between the probabilities computed using local propagation and the correct marginals. Using this relationship we show a category of graphical models with loops for which local propagation gives rise to provably optimal maximum a posteriori assignments (although the computed marginals will be incorrect). We also show how nodes can use local information in the messages they receive in order to correct their computed marginals. We discuss how these results can be extended to graphical models with multiple loops and show simulation results suggesting that some properties of propagation on single-loop graphs may hold for a larger class of graphs. Specifically we discuss the implication of our results for understanding a class of recently proposed error-correcting codes known as turbo codes."
            },
            "slug": "Correctness-of-Local-Probability-Propagation-in-Weiss",
            "title": {
                "fragments": [],
                "text": "Correctness of Local Probability Propagation in Graphical Models with Loops"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An analytical relationship is derived between the probabilities computed using local propagation and the correct marginals and a category of graphical models with loops for which local propagation gives rise to provably optimal maximum a posteriori assignments (although the computed marginals will be incorrect)."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744700"
                        ],
                        "name": "Zoubin Ghahramani",
                        "slug": "Zoubin-Ghahramani",
                        "structuredName": {
                            "firstName": "Zoubin",
                            "lastName": "Ghahramani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zoubin Ghahramani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1773821"
                        ],
                        "name": "Matthew J. Beal",
                        "slug": "Matthew-J.-Beal",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Beal",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew J. Beal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In the literature on the topic, however, the term \u201cvariational Bayes\u201d has been reserved thus far for the application of the mean-field variational method to Bayesian inference [14, 88]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1011289,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e5f22d558526017f130c75ca35fe0a737c01aaee",
            "isKey": false,
            "numCitedBy": 342,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Variational approximations are becoming a widespread tool for Bayesian learning of graphical models. We provide some theoretical results for the variational updates in a very general family of conjugate-exponential graphical models. We show how the belief propagation and the junction tree algorithms can be used in the inference step of variational Bayesian learning. Applying these results to the Bayesian analysis of linear-Gaussian state-space models we obtain a learning procedure that exploits the Kalman smoothing propagation, while integrating over all model parameters. We demonstrate how this can be used to infer the hidden state dimensionality of the state-space model in a variety of synthetic problems and one real high-dimensional data set."
            },
            "slug": "Propagation-Algorithms-for-Variational-Bayesian-Ghahramani-Beal",
            "title": {
                "fragments": [],
                "text": "Propagation Algorithms for Variational Bayesian Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is demonstrated how the belief propagation and the junction tree algorithms can be used in the inference step of variational Bayesian learning to infer the hidden state dimensionality of the state-space model in a variety of synthetic problems and one real high-dimensional data set."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721860"
                        ],
                        "name": "M. Wainwright",
                        "slug": "M.-Wainwright",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Wainwright",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wainwright"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35132120"
                        ],
                        "name": "T. Jaakkola",
                        "slug": "T.-Jaakkola",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Jaakkola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jaakkola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701607"
                        ],
                        "name": "A. Willsky",
                        "slug": "A.-Willsky",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Willsky",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Willsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5749684,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "f178383deb578992b2a62844a08a6451cbad16ed",
            "isKey": false,
            "numCitedBy": 453,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new class of upper bounds on the log partition function of a Markov random field (MRF). This quantity plays an important role in various contexts, including approximating marginal distributions, parameter estimation, combinatorial enumeration, statistical decision theory, and large-deviations bounds. Our derivation is based on concepts from convex duality and information geometry: in particular, it exploits mixtures of distributions in the exponential domain, and the Legendre mapping between exponential and mean parameters. In the special case of convex combinations of tree-structured distributions, we obtain a family of variational problems, similar to the Bethe variational problem, but distinguished by the following desirable properties: i) they are convex, and have a unique global optimum; and ii) the optimum gives an upper bound on the log partition function. This optimum is defined by stationary conditions very similar to those defining fixed points of the sum-product algorithm, or more generally, any local optimum of the Bethe variational problem. As with sum-product fixed points, the elements of the optimizing argument can be used as approximations to the marginals of the original model. The analysis extends naturally to convex combinations of hypertree-structured distributions, thereby establishing links to Kikuchi approximations and variants."
            },
            "slug": "A-new-class-of-upper-bounds-on-the-log-partition-Wainwright-Jaakkola",
            "title": {
                "fragments": [],
                "text": "A new class of upper bounds on the log partition function"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "A new class of upper bounds on the log partition function of a Markov random field (MRF) is introduced, based on concepts from convex duality and information geometry, and the Legendre mapping between exponential and mean parameters is exploited."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Information Theory"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "123333909"
                        ],
                        "name": "M.I. Jordan",
                        "slug": "M.I.-Jordan",
                        "structuredName": {
                            "firstName": "M.I.",
                            "lastName": "Jordan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M.I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Again, special cases of variational inference have been presented for such models\u2014see in particular the work of Blei and Jordan [28] on variational inference for Dirichlet processes\u2014but there is as of yet no general framework."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7327180,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e996344199af190bdd47ee31a652e76811a5487b",
            "isKey": false,
            "numCitedBy": 1309,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Dirichlet process (DP) mixture models are the cornerstone of non- parametric Bayesian statistics, and the development of Monte-Carlo Markov chain (MCMC) sampling methods for DP mixtures has enabled the application of non- parametric Bayesian methods to a variety of practical data analysis problems. However, MCMC sampling can be prohibitively slow, and it is important to ex- plore alternatives. One class of alternatives is provided by variational methods, a class of deterministic algorithms that convert inference problems into optimization problems (Opper and Saad 2001; Wainwright and Jordan 2003). Thus far, varia- tional methods have mainly been explored in the parametric setting, in particular within the formalism of the exponential family (Attias 2000; Ghahramani and Beal 2001; Blei et al. 2003). In this paper, we present a variational inference algorithm for DP mixtures. We present experiments that compare the algorithm to Gibbs sampling algorithms for DP mixtures of Gaussians and present an application to a large-scale image analysis problem."
            },
            "slug": "Variational-inference-for-Dirichlet-process-Jordan-Jordan",
            "title": {
                "fragments": [],
                "text": "Variational inference for Dirichlet process mixtures"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A variational inference algorithm forDP mixtures is presented and experiments that compare the algorithm to Gibbs sampling algorithms for DP mixtures of Gaussians and present an application to a large-scale image analysis problem are presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30400079"
                        ],
                        "name": "Yair Weiss",
                        "slug": "Yair-Weiss",
                        "structuredName": {
                            "firstName": "Yair",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yair Weiss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 18
                            }
                        ],
                        "text": "Weiss and Freeman [245] also showed that Gaussian max-product converges for arbitrary graphs if the precision matrix (\u2212\u0398 in our notation) satisfies a certain diagonal dominance condition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 27
                            }
                        ],
                        "text": "However, Weiss and Freeman [245] and independently Rusmevichientong and van Roy [200] showed that if Gaussian max-product (or equivalently, Gaussian sum-product) converges, then the fixed point specifies the correct Gaussian means \u03bcs, but the estimates of the node variances \u03c32 s need not be incorrect."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 149
                            }
                        ],
                        "text": "6) can be efficiently implemented with one recursion for the mean term (number a), and a second recursion for the variance component (see the papers [245, 257] for further details)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10624764,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2b7201afa6727252aa4d00cfed508249a637df67",
            "isKey": false,
            "numCitedBy": 646,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Graphical models, such as Bayesian networks and Markov random fields, represent statistical dependencies of variables by a graph. Local belief propagation rules of the sort proposed by Pearl (1988) are guaranteed to converge to the correct posterior probabilities in singly connected graphs. Recently, good performance has been obtained by using these same rules on graphs with loops, a method we refer to as loopy belief propagation. Perhaps the most dramatic instance is the near Shannon-limit performance of Turbo codes, whose decoding algorithm is equivalent to loopy propagation. Except for the case of graphs with a single loop, there has been little theoretical understanding of loopy propagation. Here we analyze belief propagation in networks with arbitrary topologies when the nodes in the graph describe jointly gaussian random variables. We give an analytical formula relating the true posterior probabilities with those calculated using loopy propagation. We give sufficient conditions for convergence and show that when belief propagation converges, it gives the correct posterior means for all graph topologies, not just networks with a single loop. These results motivate using the powerful belief propagation algorithm in a broader class of networks and help clarify the empirical performance results."
            },
            "slug": "Correctness-of-Belief-Propagation-in-Gaussian-of-Weiss-Freeman",
            "title": {
                "fragments": [],
                "text": "Correctness of Belief Propagation in Gaussian Graphical Models of Arbitrary Topology"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work analyzes belief propagation in networks with arbitrary topologies when the nodes in the graph describe jointly gaussian random variables and gives an analytical formula relating the true posterior probabilities with those calculated using loopy propagation."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688721"
                        ],
                        "name": "D. Malioutov",
                        "slug": "D.-Malioutov",
                        "structuredName": {
                            "firstName": "Dmitry",
                            "lastName": "Malioutov",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Malioutov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39869361"
                        ],
                        "name": "J. Johnson",
                        "slug": "J.-Johnson",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Johnson",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Johnson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701607"
                        ],
                        "name": "A. Willsky",
                        "slug": "A.-Willsky",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Willsky",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Willsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "3), both of which solve the quadratic program in an iterative manner, or by iterative algorithms based on tractable subgraphs [218, 158]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "[158], using the notions of walk-summability and pairwise normalizability; see also the paper [173] for further refinements."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18732205,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "aa73ee74eec90b44ca0cd36607d4026b7a349469",
            "isKey": false,
            "numCitedBy": 283,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new framework based on walks in a graph for analysis and inference in Gaussian graphical models. The key idea is to decompose the correlation between each pair of variables as a sum over all walks between those variables in the graph. The weight of each walk is given by a product of edgewise partial correlation coefficients. This representation holds for a large class of Gaussian graphical models which we call walk-summable. We give a precise characterization of this class of models, and relate it to other classes including diagonally dominant, attractive, non-frustrated, and pairwise-normalizable. We provide a walk-sum interpretation of Gaussian belief propagation in trees and of the approximate method of loopy belief propagation in graphs with cycles. The walk-sum perspective leads to a better understanding of Gaussian belief propagation and to stronger results for its convergence in loopy graphs."
            },
            "slug": "Walk-Sums-and-Belief-Propagation-in-Gaussian-Models-Malioutov-Johnson",
            "title": {
                "fragments": [],
                "text": "Walk-Sums and Belief Propagation in Gaussian Graphical Models"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The walk-sum perspective leads to a better understanding of Gaussian belief propagation and to stronger results for its convergence in loopy graphs."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37210858"
                        ],
                        "name": "Charles Sutton",
                        "slug": "Charles-Sutton",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Sutton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charles Sutton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 113
                            }
                        ],
                        "text": "The use of such approximate methods and their impact on parameter estimation is still an active area of research [220, 226, 238, 236, 248]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1549479,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "beb0766d6233836ac1203b224930dc037e2b1dff",
            "isKey": false,
            "numCitedBy": 197,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "For many large undirected models that arise in real-world applications, exact maximum-likelihood training is intractable, because it requires computing marginal distributions of the model. Conditional training is even more difficult, because the partition function depends not only on the parameters, but also on the observed input, requiring repeated inference over each training example. An appealing idea for such models is to independently train a local undirected classifier over each clique, afterwards combining the learned weights into a single global model. In this paper, we show that this piecewise method can be justified as minimizing a new family of upper bounds on the log partition function. On three natural-language data sets, piecewise training is more accurate than pseudolikelihood, and often performs comparably to global training using belief propagation."
            },
            "slug": "Piecewise-Training-for-Undirected-Models-Sutton-McCallum",
            "title": {
                "fragments": [],
                "text": "Piecewise Training for Undirected Models"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper shows that this piecewise method can be justified as minimizing a new family of upper bounds on the log partition function, and on three natural-language data sets, piecewise training is more accurate than pseudolikelihood, and often performs comparably to global training using belief propagation."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1934584"
                        ],
                        "name": "Onureena Banerjee",
                        "slug": "Onureena-Banerjee",
                        "structuredName": {
                            "firstName": "Onureena",
                            "lastName": "Banerjee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Onureena Banerjee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701847"
                        ],
                        "name": "L. Ghaoui",
                        "slug": "L.-Ghaoui",
                        "structuredName": {
                            "firstName": "Laurent",
                            "lastName": "Ghaoui",
                            "middleNames": [
                                "El"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Ghaoui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1387902104"
                        ],
                        "name": "A. d'Aspremont",
                        "slug": "A.-d'Aspremont",
                        "structuredName": {
                            "firstName": "Alexandre",
                            "lastName": "d'Aspremont",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. d'Aspremont"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[7] exploit the log-determinant relaxation (7."
                    },
                    "intents": []
                }
            ],
            "corpusId": 311,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5006e66095e3a42634e5ee4de59f10220c204778",
            "isKey": false,
            "numCitedBy": 1318,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of estimating the parameters of a Gaussian or binary distribution in such a way that the resulting undirected graphical model is sparse. Our approach is to solve a maximum likelihood problem with an added l1-norm penalty term. The problem as formulated is convex but the memory requirements and complexity of existing interior point methods are prohibitive for problems with more than tens of nodes. We present two new algorithms for solving problems with at least a thousand nodes in the Gaussian case. Our first algorithm uses block coordinate descent, and can be interpreted as recursive l1-norm penalized regression. Our second algorithm, based on Nesterov's first order method, yields a complexity estimate with a better dependence on problem size than existing interior point methods. Using a log determinant relaxation of the log partition function (Wainwright and Jordan, 2006), we show that these same algorithms can be used to solve an approximate sparse maximum likelihood problem for the binary case. We test our algorithms on synthetic data, as well as on gene expression and senate voting records data."
            },
            "slug": "Model-Selection-Through-Sparse-Maximum-Likelihood-Banerjee-Ghaoui",
            "title": {
                "fragments": [],
                "text": "Model Selection Through Sparse Maximum Likelihood Estimation for Multivariate Gaussian or Binary Data"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "This work considers the problem of estimating the parameters of a Gaussian or binary distribution in such a way that the resulting undirected graphical model is sparse, and presents two new algorithms for solving problems with at least a thousand nodes in the Gaussian case."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 163
                            }
                        ],
                        "text": "This equivalence can be established by a suitable generalization of the proof of correctness of the sum-product algorithm presented previously (see also Lauritzen [68])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 133
                            }
                        ],
                        "text": "An analogous result holds in the case of directed graphical models, with the only alteration being a di erent notion of reachability [68]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 152
                            }
                        ],
                        "text": "This equivalence can be established by a suitable generalization of the proof of correctness of the sum-product algorithm sketched previously (see also Lauritzen [153])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 91
                            }
                        ],
                        "text": "A key theorem is that a graph G has a junction tree if and only if it is triangulated (see Lauritzen [153] for a proof)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 164
                            }
                        ],
                        "text": "We only touch upon this characterization here, as it is not needed in the remainder of the paper; for a full treatment, we refer the interested reader to Lauritzen [68]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 155
                            }
                        ],
                        "text": "We only touch upon this characterization here, as it is not needed in the remainder of the survey; for a full treatment, we refer the interested reader to Lauritzen [153]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6286159,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e16a25faf7428e1fc5ed0a10b8196c0499c7fd0d",
            "isKey": true,
            "numCitedBy": 3412,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Statistical applications in fields such as bioinformatics, information retrieval, speech processing, image processing and communications often involve large-scale models in which thousands or millions of random variables are linked in complex ways. Graphical models provide a general methodology for approaching these problems, and indeed many of the models developed by researchers in these applied fields are instances of the general graphical model formalism. We review some of the basic ideas underlying graphical models, including the algorithmic ideas that allow graphical models to be deployed in large-scale data analysis problems. We also present examples of graphical models in bioinformatics, error-control coding and language processing."
            },
            "slug": "Graphical-Models-Jordan",
            "title": {
                "fragments": [],
                "text": "Graphical Models"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Some of the basic ideas underlying graphical models are reviewed, including the algorithmic ideas that allow graphical models to be deployed in large-scale data analysis problems and examples of graphical models in bioinformatics, error-control coding and language processing are presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3198578"
                        ],
                        "name": "J. Yedidia",
                        "slug": "J.-Yedidia",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Yedidia",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Yedidia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30400079"
                        ],
                        "name": "Yair Weiss",
                        "slug": "Yair-Weiss",
                        "structuredName": {
                            "firstName": "Yair",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yair Weiss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "[123], it turns out to be important to ensure that every hyperedge (including vertices) in the original hypergraph G0 is counted exactly once in the augmented hypergraph G."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "[123] includes entropy approximations that need not follow from hypertrees on the original vertex set."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 111
                            }
                        ],
                        "text": "we cluster the nodes into groups of four, which is known as Kikuchi 4-plaque clustering in statistical physics [123]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "[123], that is a natural generalization of the ordinary sum-product updates for the Bethe approximation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 103
                            }
                        ],
                        "text": "Further details on di erent variants of generalized sum-product updates can be found in various papers [123, 82, 76]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "[123] and further explored by various researchers [e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "[123], the pseudomarginal h takes the following form: h(xh) = Y"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 121439686,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "05a281df21f4cb2b01e7751c50a4cba3ae0b992f",
            "isKey": true,
            "numCitedBy": 1568,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "\"Inference\" problems arise in statistical physics, computer vision, error-correcting coding theory, and AI. We explain the principles behind the belief propagation (BP) algorithm, which is an efficient way to solve inference problems based on passing local messages. We develop a unified approach, with examples, notation, and graphical models borrowed from the relevant disciplines.We explain the close connection between the BP algorithm and the Bethe approximation of statistical physics. In particular, we show that BP can only converge to a fixed point that is also a stationary point of the Bethe approximation to the free energy. This result helps explaining the successes of the BP algorithm and enables connections to be made with variational approaches to approximate inference.The connection of BP with the Bethe approximation also suggests a way to construct new message-passing algorithms based on improvements to Bethe's approximation introduced Kikuchi and others. The new generalized belief propagation (GBP) algorithms are significantly more accurate than ordinary BP for some problems. We illustrate how to construct GBP algorithms with a detailed example."
            },
            "slug": "Understanding-belief-propagation-and-its-Yedidia-Freeman",
            "title": {
                "fragments": [],
                "text": "Understanding belief propagation and its generalizations"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that BP can only converge to a fixed point that is also a stationary point of the Bethe approximation to the free energy, which enables connections to be made with variational approaches to approximate inference."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35132120"
                        ],
                        "name": "T. Jaakkola",
                        "slug": "T.-Jaakkola",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Jaakkola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jaakkola"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We now consider an example, drawn from Jaakkola [117], that illustrates the nonconvexity of naive mean field for a simple model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This structured mean field approach was first proposed by Saul and Jordan [204], and further developed by various researchers [9, 254, 117]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 118538409,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a9273ea2f53a74530527eab71f9b1c8acca06f0c",
            "isKey": false,
            "numCitedBy": 336,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Tutorial topics \u2022 A bit of history \u2022 Examples of variational methods \u2022 A brief intro to graphical models \u2022 Variational mean field theory \u2013 Accuracy of variational mean field \u2013 Structured mean field theory \u2022 Variational methods in Bayesian estimation \u2022 Convex duality and variational factorization methods \u2013 Example: variational inference and the QMR-DT Variational methods \u2022 Classical setting: \" finding the extremum of an integral involving a function and its derivatives \" Example: finding the trajectory of a particle under external field \u2022 The key idea here is that the problem of interest is formulated as an optimization problem Variational methods cont'd \u2022 Variational methods have a long history in physics, statistics, control theory as well as economics. \u2013 calculus of variations (physics) \u2013 linear/non-linear moments problems (statistics) \u2013 dynamic programming (control theory) \u2022 Variational formulations appear naturally also in machine learning contexts: \u2013 regularization theory \u2013 maximum entropy estimation \u2022 Recently variational methods been used and further developed in the context of approximate inference and estimation Examples of variational methods \u2022 In classical examples the formulation itself is given but for us this is one of the key problems \u2022 We provide here a few examples that highlight 1. how to cast problems as optimization problems 2. how to find an approximate solution when the exact solution is not feasible \u2022 The examples we use involve a) finite element methods for solving differential equations b) large deviation methods (Chernoff bound)"
            },
            "slug": "Tutorial-on-variational-approximation-methods-Jaakkola",
            "title": {
                "fragments": [],
                "text": "Tutorial on variational approximation methods"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This tutorial provides a few examples that highlight how to cast problems as optimization problems and how to find an approximate solution when the exact solution is not feasible."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39869361"
                        ],
                        "name": "J. Johnson",
                        "slug": "J.-Johnson",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Johnson",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Johnson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688721"
                        ],
                        "name": "D. Malioutov",
                        "slug": "D.-Malioutov",
                        "structuredName": {
                            "firstName": "Dmitry",
                            "lastName": "Malioutov",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Malioutov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701607"
                        ],
                        "name": "A. Willsky",
                        "slug": "A.-Willsky",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Willsky",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Willsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 110
                            }
                        ],
                        "text": "5), including subgradient methods [73, 136], dual coordinate ascent methods [94, 234], annealing-type methods [121, 246], proximal optimization schemes [193], and adaptive LP solvers [223]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14433916,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "9bdb624f6f52609c231d0cee8abd8068b4199ec8",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop a general framework for MAP es- timation in discrete and Gaussian graphical models using Lagrangian relaxation techniques. The key idea is to refor- mulate an intractable estimation problem as one defined on a more tractable graph, but subject to additional constraints. Relaxing these constraints gives a tractable dual problem, one defined by a thin graph, which is then optimized by an iterative procedure. When this iterative optimization leads to a consistent estimate, one which also satisfies the constraints, then it corresponds to an optimal MAP estimate of the original model. Otherwise there is a \"duality gap\", and we obtain a bound on the optimal solution. Thus, our approach combines convex optimization with dynamic programming techniques applicable for thin graphs. The popular tree-reweighted max- product (TRMP) method may be seen as solving a particular class of such relaxations, where the intractable graph is relaxed to a set of spanning trees. We also consider relaxations to a set of small induced subgraphs, thin subgraphs (e.g. loops), and a connected tree obtained by \"unwinding\" cycles. In addition, we propose a new class of multiscale relaxations that introduce \"summary\" variables. The potential benefits of such generalizations include: reducing or eliminating the \"duality gap\" in hard problems, reducing the number of Lagrange multipliers in the dual problem, and accelerating convergence of the iterative optimization procedure."
            },
            "slug": "Lagrangian-Relaxation-for-MAP-Estimation-in-Models-Johnson-Malioutov",
            "title": {
                "fragments": [],
                "text": "Lagrangian Relaxation for MAP Estimation in Graphical Models"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A general framework for MAP es- timation in discrete and Gaussian graphical models using Lagrangian relaxation techniques is developed, and a new class of multiscale relaxations that introduce \"summary\" variables are proposed."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32451478"
                        ],
                        "name": "Antar Bandyopadhyay",
                        "slug": "Antar-Bandyopadhyay",
                        "structuredName": {
                            "firstName": "Antar",
                            "lastName": "Bandyopadhyay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antar Bandyopadhyay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708116"
                        ],
                        "name": "D. Gamarnik",
                        "slug": "D.-Gamarnik",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Gamarnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gamarnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14655854,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "3799060dbbc48f5da0db4a01ba77589d459da7b2",
            "isKey": false,
            "numCitedBy": 53,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new type of approximate counting algorithms for the problems of enumerating the number of independent sets and proper colorings in low degree graphs with large girth. Our algorithms are not based on a commonly used Markov chain technique, but rather are inspired by recent developments in statistical physics in connection with correlation decay properties of Gibbs measures and its implications to uniqueness of Gibbs measures on infinite trees, reconstruction problems and local weak convergence methods. On a negative side, our algorithms provide \u2208-approximations only to the logarithms of the size of a feasible set (also known as free energy in statistical physics). But on the positive side, unlike Markov chain based algorithms, our approach provides deterministic as opposed to probabilistic guarantee on approximations. Moreover, for some regular graphs we obtain explicit values for the counting problem. For example, we show that every 4-regular n-node graph with large girth has asymptotically (1.494 ...)n independent sets, and in every r-regular graph with n nodes and large girth the number of q \u2265 r + 1-proper colorings is asymptotically (q(1-1/q)r/2)n for large n. In statistical physics terminology, we compute explicitly the partition function (free energy) in these cases. We extend our results to random regular graphs graphs also. The explicit results obtained in this paper would be hard to derive via Markov chain sampling technique."
            },
            "slug": "Counting-without-sampling:-new-algorithms-for-using-Bandyopadhyay-Gamarnik",
            "title": {
                "fragments": [],
                "text": "Counting without sampling: new algorithms for enumeration problems using statistical physics"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A new type of approximate counting algorithms for the problems of enumerating the number of independent sets and proper colorings in low degree graphs with large girth, inspired by recent developments in statistical physics in connection with correlation decay properties of Gibbs measures."
            },
            "venue": {
                "fragments": [],
                "text": "SODA '06"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3198578"
                        ],
                        "name": "J. Yedidia",
                        "slug": "J.-Yedidia",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Yedidia",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Yedidia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30400079"
                        ],
                        "name": "Yair Weiss",
                        "slug": "Yair-Weiss",
                        "structuredName": {
                            "firstName": "Yair",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yair Weiss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 52835993,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a8921b3462a3575b0b5de602a975bd608f6f6652",
            "isKey": false,
            "numCitedBy": 1611,
            "numCiting": 115,
            "paperAbstract": {
                "fragments": [],
                "text": "Important inference problems in statistical physics, computer vision, error-correcting coding theory, and artificial intelligence can all be reformulated as the computation of marginal probabilities on factor graphs. The belief propagation (BP) algorithm is an efficient way to solve these problems that is exact when the factor graph is a tree, but only approximate when the factor graph has cycles. We show that BP fixed points correspond to the stationary points of the Bethe approximation of the free energy for a factor graph. We explain how to obtain region-based free energy approximations that improve the Bethe approximation, and corresponding generalized belief propagation (GBP) algorithms. We emphasize the conditions a free energy approximation must satisfy in order to be a \"valid\" or \"maxent-normal\" approximation. We describe the relationship between four different methods that can be used to generate valid approximations: the \"Bethe method\", the \"junction graph method\", the \"cluster variation method\", and the \"region graph method\". Finally, we explain how to tell whether a region-based approximation, and its corresponding GBP algorithm, is likely to be accurate, and describe empirical results showing that GBP can significantly outperform BP."
            },
            "slug": "Constructing-free-energy-approximations-and-belief-Yedidia-Freeman",
            "title": {
                "fragments": [],
                "text": "Constructing free-energy approximations and generalized belief propagation algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work explains how to obtain region-based free energy approximations that improve the Bethe approximation, and corresponding generalized belief propagation (GBP) algorithms, and describes empirical results showing that GBP can significantly outperform BP."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Information Theory"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721860"
                        ],
                        "name": "M. Wainwright",
                        "slug": "M.-Wainwright",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Wainwright",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wainwright"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35132120"
                        ],
                        "name": "T. Jaakkola",
                        "slug": "T.-Jaakkola",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Jaakkola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jaakkola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701607"
                        ],
                        "name": "A. Willsky",
                        "slug": "A.-Willsky",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Willsky",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Willsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10007532,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b28024225b22741035cf87203a3639c917959404",
            "isKey": false,
            "numCitedBy": 709,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop and analyze methods for computing provably optimal maximum a posteriori probability (MAP) configurations for a subclass of Markov random fields defined on graphs with cycles. By decomposing the original distribution into a convex combination of tree-structured distributions, we obtain an upper bound on the optimal value of the original problem (i.e., the log probability of the MAP assignment) in terms of the combined optimal values of the tree problems. We prove that this upper bound is tight if and only if all the tree distributions share an optimal configuration in common. An important implication is that any such shared configuration must also be a MAP configuration for the original distribution. Next we develop two approaches to attempting to obtain tight upper bounds: a) a tree-relaxed linear program (LP), which is derived from the Lagrangian dual of the upper bounds; and b) a tree-reweighted max-product message-passing algorithm that is related to but distinct from the max-product algorithm. In this way, we establish a connection between a certain LP relaxation of the mode-finding problem and a reweighted form of the max-product (min-sum) message-passing algorithm."
            },
            "slug": "MAP-estimation-via-agreement-on-trees:-and-linear-Wainwright-Jaakkola",
            "title": {
                "fragments": [],
                "text": "MAP estimation via agreement on trees: message-passing and linear programming"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "This work develops and analyze methods for computing provably optimal maximum a posteriori probability (MAP) configurations for a subclass of Markov random fields defined on graphs with cycles and establishes a connection between a certain LP relaxation of the mode-finding problem and a reweighted form of the max-product (min-sum) message-passing algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Information Theory"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3194361"
                        ],
                        "name": "S. Geman",
                        "slug": "S.-Geman",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Geman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707642"
                        ],
                        "name": "D. Geman",
                        "slug": "D.-Geman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Moreover, the Ising model and variations on it have been used in image processing and spatial statistics [25, 86, 98], where Xs might correspond to pixel values in a black-and-white image."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Problems of constraint satisfaction and combinatorial optimization arise in a wide variety of areas, among them artificial intelligence [63, 188], communication theory [84], computational complexity theory [52], statistical image processing [86], and bioinformatics [190]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Markov chain Monte Carlo methods are often used [86], but they can be too slow and computationally intensive for many applications."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5837272,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "459b30a9a960080f3b313e41886b1aa0e51e882c",
            "isKey": false,
            "numCitedBy": 18710,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "We make an analogy between images and statistical mechanics systems. Pixel gray levels and the presence and orientation of edges are viewed as states of atoms or molecules in a lattice-like physical system. The assignment of an energy function in the physical system determines its Gibbs distribution. Because of the Gibbs distribution, Markov random field (MRF) equivalence, this assignment also determines an MRF image model. The energy function is a more convenient and natural mechanism for embodying picture attributes than are the local characteristics of the MRF. For a range of degradation mechanisms, including blurring, nonlinear deformations, and multiplicative or additive noise, the posterior distribution is an MRF with a structure akin to the image model. By the analogy, the posterior distribution defines another (imaginary) physical system. Gradual temperature reduction in the physical system isolates low energy states (``annealing''), or what is the same thing, the most probable states under the Gibbs distribution. The analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations. The result is a highly parallel ``relaxation'' algorithm for MAP estimation. We establish convergence properties of the algorithm and we experiment with some simple pictures, for which good restorations are obtained at low signal-to-noise ratios."
            },
            "slug": "Stochastic-Relaxation,-Gibbs-Distributions,-and-the-Geman-Geman",
            "title": {
                "fragments": [],
                "text": "Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "The analogy between images and statistical mechanics systems is made and the analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations, creating a highly parallel ``relaxation'' algorithm for MAP estimation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1889982"
                        ],
                        "name": "F. Kschischang",
                        "slug": "F.-Kschischang",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Kschischang",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Kschischang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749650"
                        ],
                        "name": "B. Frey",
                        "slug": "B.-Frey",
                        "structuredName": {
                            "firstName": "Brendan",
                            "lastName": "Frey",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Frey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143681410"
                        ],
                        "name": "H. Loeliger",
                        "slug": "H.-Loeliger",
                        "structuredName": {
                            "firstName": "Hans-Andrea",
                            "lastName": "Loeliger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Loeliger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14394619,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "08c370eb9ba13bfb836349e7f3ea428be4697818",
            "isKey": false,
            "numCitedBy": 4132,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "Algorithms that must deal with complicated global functions of many variables often exploit the manner in which the given functions factor as a product of \"local\" functions, each of which depends on a subset of the variables. Such a factorization can be visualized with a bipartite graph that we call a factor graph, In this tutorial paper, we present a generic message-passing algorithm, the sum-product algorithm, that operates in a factor graph. Following a single, simple computational rule, the sum-product algorithm computes-either exactly or approximately-various marginal functions derived from the global function. A wide variety of algorithms developed in artificial intelligence, signal processing, and digital communications can be derived as specific instances of the sum-product algorithm, including the forward/backward algorithm, the Viterbi algorithm, the iterative \"turbo\" decoding algorithm, Pearl's (1988) belief propagation algorithm for Bayesian networks, the Kalman filter, and certain fast Fourier transform (FFT) algorithms."
            },
            "slug": "Factor-graphs-and-the-sum-product-algorithm-Kschischang-Frey",
            "title": {
                "fragments": [],
                "text": "Factor graphs and the sum-product algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A generic message-passing algorithm, the sum-product algorithm, that operates in a factor graph, that computes-either exactly or approximately-various marginal functions derived from the global function."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3198578"
                        ],
                        "name": "J. Yedidia",
                        "slug": "J.-Yedidia",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Yedidia",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Yedidia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30400079"
                        ],
                        "name": "Yair Weiss",
                        "slug": "Yair-Weiss",
                        "structuredName": {
                            "firstName": "Yair",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yair Weiss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15300022,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b2799fd1254689eec52f86daf3668a5aac3ea943",
            "isKey": false,
            "numCitedBy": 1127,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Belief propagation (BP) was only supposed to work for treelike networks but works surprisingly well in many applications involving networks with loops, including turbo codes. However, there has been little understanding of the algorithm or the nature of the solutions it finds for general graphs. \n \nWe show that BP can only converge to a stationary point of an approximate free energy, known as the Bethe free energy in statistical physics. This result characterizes BP fixed-points and makes connections with variational approaches to approximate inference. \n \nMore importantly, our analysis lets us build on the progress made in statistical physics since Bethe's approximation was introduced in 1935. Kikuchi and others have shown how to construct more accurate free energy approximations, of which Bethe's approximation is the simplest. Exploiting the insights from our analysis, we derive generalized belief propagation (GBP) versions of these Kikuchi approximations. These new message passing algorithms can be significantly more accurate than ordinary BP, at an adjustable increase in complexity. We illustrate such a new GBP algorithm on a grid Markov network and show that it gives much more accurate marginal probabilities than those found using ordinary BP."
            },
            "slug": "Generalized-Belief-Propagation-Yedidia-Freeman",
            "title": {
                "fragments": [],
                "text": "Generalized Belief Propagation"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "It is shown that BP can only converge to a stationary point of an approximate free energy, known as the Bethe free energy in statistical physics, and generalized belief propagation (GBP) versions of these Kikuchi approximations are derived."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721860"
                        ],
                        "name": "M. Wainwright",
                        "slug": "M.-Wainwright",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Wainwright",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wainwright"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 200
                            }
                        ],
                        "text": "The main result of this section is to show how combining a semide nite outer bound with a Gaussian-based entropy approximation leads to a log-determinant relaxation of the exact variational principle [114]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 130
                            }
                        ],
                        "text": "More details on the log-determinant relaxation and its performance for approximate inference can be found in the technical report [114]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 215,
                                "start": 210
                            }
                        ],
                        "text": "Finally, to illustrate the use of semide nite constraints, we combine semide nite outer bounds with a Gaussian-based entropy approximation to derive a novel log-determinant relaxation for approximate inference [114]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1089299,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "0f4cf1d303f53fa115e41e416fc9051fd4f465b6",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new method for calculating approximate marginals for probability distributions defined by graphs with cycles, based on a Gaussian entropy bound combined with a semidefinite outer bound on the marginal polytope. This combination leads to a log-determinant maximization problem that can be solved by efficient interior point methods [8]. As with the Bethe approximation and its generalizations [12], the optimizing arguments of this problem can be taken as approximations to the exact marginals. In contrast to Bethe/Kikuchi approaches, our variational problem is strictly convex and so has a unique global optimum. An additional desirable feature is that the value of the optimal solution is guaranteed to provide an upper bound on the log partition function. In experimental trials, the performance of the log-determinant relaxation is comparable to or better than the sum-product algorithm, and by a substantial margin for certain problem classes. Finally, the zero-temperature limit of our log-determinant relaxation recovers a class of well-known semidefinite relaxations for integer programming [e.g., 3]."
            },
            "slug": "Semidefinite-Relaxations-for-Approximate-Inference-Wainwright-Jordan",
            "title": {
                "fragments": [],
                "text": "Semidefinite Relaxations for Approximate Inference on Graphs with Cycles"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A new method for calculating approximate marginals for probability distributions defined by graphs with cycles, based on a Gaussian entropy bound combined with a semidefinite outer bound on the marginal polytope, which leads to a log-determinant maximization problem that can be solved by efficient interior point methods."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799035"
                        ],
                        "name": "Erik B. Sudderth",
                        "slug": "Erik-B.-Sudderth",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Sudderth",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Erik B. Sudderth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721860"
                        ],
                        "name": "M. Wainwright",
                        "slug": "M.-Wainwright",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Wainwright",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wainwright"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701607"
                        ],
                        "name": "A. Willsky",
                        "slug": "A.-Willsky",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Willsky",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Willsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 75
                            }
                        ],
                        "text": "Proposition 6 has extensions to more general factor graphs; see the papers [48, 219] for more details."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "[219] for results on certain classes of attractive graphical models for which the Bethe approximation does provide such a lower bound."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "[219] show that the loop series expansion can be exploited to show that for certain types of graphical models with attractive interactions, the Bethe value ABethe(\u03b8) is actually a lower bound on the true cumulant function A(\u03b8)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "[219] for the derivation for more general factor graphs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "[219] show that ABethe(\u03b8) is a lower bound on the cumulant function A(\u03b8) for"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13476001,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2f06295c93237ab2ae836431b1c04b3132a42d74",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Variational methods are frequently used to approximate or bound the partition or likelihood function of a Markov random field. Methods based on mean field theory are guaranteed to provide lower bounds, whereas certain types of convex relaxations provide upper bounds. In general, loopy belief propagation (BP) provides often accurate approximations, but not bounds. We prove that for a class of attractive binary models, the so-called Bethe approximation associated with any fixed point of loopy BP always lower bounds the true likelihood. Empirically, this bound is much tighter than the naive mean field bound, and requires no further work than running BP. We establish these lower bounds using a loop series expansion due to Chertkov and Chernyak, which we show can be derived as a consequence of the tree reparameterization characterization of BP fixed points."
            },
            "slug": "Loop-Series-and-Bethe-Variational-Bounds-in-Models-Sudderth-Wainwright",
            "title": {
                "fragments": [],
                "text": "Loop Series and Bethe Variational Bounds in Attractive Graphical Models"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is proved that for a class of attractive binary models, the so-called Bethe approximation associated with any fixed point of loopy BP always lower bounds the true likelihood."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691022"
                        ],
                        "name": "M. Opper",
                        "slug": "M.-Opper",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Opper",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Opper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724252"
                        ],
                        "name": "O. Winther",
                        "slug": "O.-Winther",
                        "structuredName": {
                            "firstName": "Ole",
                            "lastName": "Winther",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Winther"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "As with assumed density filtering, expectationpropagation [172, 171] and various related algorithms [181, 61, 112] are typically described in terms of moment-matching operations."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Finally, we describe expectation-propagation algorithms [180, 172] and related moment-matching methods [181, 61, 112]; these are also varia-"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "3, the family of expectation-propagation algorithms [169, 172], as well as related moment-matching algorithms [181, 61, 112], can be understood in terms of term-by-term entropy approximations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Examples of such algorithms include the family of expectationpropagation algorithms due to Minka [172], the related class of assumed density filtering methods [149, 161, 37], expectation-consistent inference [181], structured summary-propagation algorithms [61, 112], and"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14853129,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cb98eb97299f340066f91d681935fd178e266baa",
            "isKey": true,
            "numCitedBy": 204,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel framework for approximations to intractable probabilistic models which is based on a free energy formulation. The approximation can be understood as replacing an average over the original intractable distribution with a tractable one. It requires two tractable probability distributions which are made consistent on a set of moments and encode different features of the original intractable distribution. In this way we are able to use Gaussian approximations for models with discrete or bounded variables which allow us to include non-trivial correlations. These are neglected in many other methods. We test the framework on toy benchmark problems for binary variables on fully connected graphs and 2D grids and compare with other methods, such as loopy belief propagation. Good performance is already achieved by using single nodes as tractable substructures. Significant improvements are obtained when a spanning tree is used instead."
            },
            "slug": "Expectation-Consistent-Approximate-Inference-Opper-Winther",
            "title": {
                "fragments": [],
                "text": "Expectation Consistent Approximate Inference"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A novel framework for approximations to intractable probabilistic models which is based on a free energy formulation is proposed which requires two tractable probability distributions which are made consistent on a set of moments and encode different features of the originalintractable distribution."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796044"
                        ],
                        "name": "L. Saul",
                        "slug": "L.-Saul",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Saul",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Saul"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14500325,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2dc4d6d7d55f9f0f1de53bb7f6816502f8f38892",
            "isKey": false,
            "numCitedBy": 90,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a statistical mechanical framework for the modeling of discrete time series. Maximum likelihood estimation is done via Boltzmann learning in one-dimensional networks with tied weights. We call these networks Boltzmann chains and show that they contain hidden Markov models (HMMs) as a special case. Our framework also motivates new architectures that address particular shortcomings of HMMs. We look at two such architectures: parallel chains that model feature sets with disparate time scales, and looped networks that model long-term dependencies between hidden states. For these networks, we show how to implement the Boltzmann learning rule exactly, in polynomial time, without resort to simulated or mean-field annealing. The necessary computations are done by exact decimation procedures from statistical mechanics."
            },
            "slug": "Boltzmann-Chains-and-Hidden-Markov-Models-Saul-Jordan",
            "title": {
                "fragments": [],
                "text": "Boltzmann Chains and Hidden Markov Models"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "A statistical mechanical framework for the modeling of discrete time series is proposed, and maximum likelihood estimation is done via Boltzmann learning in one-dimensional networks with tied weights, which motivates new architectures that address particular shortcomings of HMMs."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2550392"
                        ],
                        "name": "B. Efron",
                        "slug": "B.-Efron",
                        "structuredName": {
                            "firstName": "Bradley",
                            "lastName": "Efron",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Efron"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Such constraints require the general machinery of curved exponential families [71]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In our view, the most promising avenue towards a variational methodology tuned to statistics is to build on existing links between variational analysis and the exponential family of distributions [4, 10, 40, 71]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 120162246,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "221d44cd364bfa4f6d789eba44b55243f70fdd4b",
            "isKey": false,
            "numCitedBy": 240,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "There are two important spaces connected with every multivariate exponential family, the natural parameter space and the expectation parameter space. We describe some geometric results relating the two. (In the simplest case, that of a normal translation family, the two spaces coincide and the geometry is the familiar Euclidean one.) Maximum likelihood estimation, within one-parameter curved subfamilies of the multivariate family, has two simple and useful geometric interpretations. The geometry also relates to the Fisherian question: to what extent can the Fisher information be replaced by $-\\partial^2/\\partial\\theta^2\\lbrack\\log f_\\theta(x)\\rbrack\\mid_{\\theta=\\hat{\\theta}}$ in the variance bound for $\\hat{\\theta}$, the maximum likelihood estimator?"
            },
            "slug": "THE-GEOMETRY-OF-EXPONENTIAL-FAMILIES-Efron",
            "title": {
                "fragments": [],
                "text": "THE GEOMETRY OF EXPONENTIAL FAMILIES"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1918412"
                        ],
                        "name": "Tamir Hazan",
                        "slug": "Tamir-Hazan",
                        "structuredName": {
                            "firstName": "Tamir",
                            "lastName": "Hazan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tamir Hazan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140335"
                        ],
                        "name": "A. Shashua",
                        "slug": "A.-Shashua",
                        "structuredName": {
                            "firstName": "Amnon",
                            "lastName": "Shashua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shashua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 218
                            }
                        ],
                        "text": "Another possibility would be to adapt other double-loop algorithms [265, 249, 108, 107], originally developed for the ordinary Bethe/Kikuchi problems, to solve these convex minimization problems; see Hazan and Shashua [105] for some recent work along these lines."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1166443,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "38dacee0054cfcfcc78f3ffa84c6c40a4cd53d60",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Inference problems in graphical models can be represented as a constrained optimization of a free energy function. It is known that when the Bethe free energy is used, the fixed-points of the belief propagation (BP) algorithm correspond to the local minima of the free energy. However BP fails to converge in many cases of interest. Moreover, the Bethe free energy is non-convex for graphical models with cycles thus introducing great difficulty in deriving efficient algorithms for finding local minima of the free energy for general graphs. In this paper we introduce two efficient BP-like algorithms, one sequential and the other parallel, that are guaranteed to converge to the global minimum, for any graph, over the class of energies known as \"convex free energies\". In addition, we propose an efficient heuristic for setting the parameters of the convex free energy based on the structure of the graph."
            },
            "slug": "Convergent-Message-Passing-Algorithms-for-Inference-Hazan-Shashua",
            "title": {
                "fragments": [],
                "text": "Convergent Message-Passing Algorithms for Inference over General Graphs with Convex Free Energies"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper introduces two efficient BP-like algorithms that are guaranteed to converge to the global minimum, for any graph, over the class of energies known as \"convex free energies\" and proposes an efficient heuristic for setting the parameters of the convex free energy based on the structure of the graph."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678771"
                        ],
                        "name": "P. Bickel",
                        "slug": "P.-Bickel",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Bickel",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bickel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2934481"
                        ],
                        "name": "K. Doksum",
                        "slug": "K.-Doksum",
                        "structuredName": {
                            "firstName": "Kjell",
                            "lastName": "Doksum",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Doksum"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120450474,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "92d92fd3de1af6a46e8cd9ca841d5433e659179f",
            "isKey": false,
            "numCitedBy": 1456,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": "(NOTE: Each chapter concludes with Problems and Complements, Notes, and References.) 1. Statistical Models, Goals, and Performance Criteria. Data, Models, Parameters, and Statistics. Bayesian Models. The Decision Theoretic Framework. Prediction. Sufficiency. Exponential Families. 2. Methods of Estimation. Basic Heuristics of Estimation. Minimum Contrast Estimates and Estimating Equations. Maximum Likelihood in Multiparameter Exponential Families. Algorithmic Issues. 3. Measures of Performance. Introduction. Bayes Procedures. Minimax Procedures. Unbiased Estimation and Risk Inequalities. Nondecision Theoretic Criteria. 4. Testing and Confidence Regions. Introduction. Choosing a Test Statistic: The Neyman-Pearson Lemma. Uniformly Most Powerful Tests and Monotone Likelihood Ratio Models. Confidence Bounds, Intervals and Regions. The Duality between Confidence Regions and Tests. Uniformly Most Accurate Confidence Bounds. Frequentist and Bayesian Formulations. Prediction Intervals. Likelihood Ratio Procedures. 5. Asymptotic Approximations. Introduction: The Meaning and Uses of Asymptotics. Consistency. First- and Higher-Order Asymptotics: The Delta Method with Applications. Asymptotic Theory in One Dimension. Asymptotic Behavior and Optimality of the Posterior Distribution. 6. Inference in the Multiparameter Case. Inference for Gaussian Linear Models. Asymptotic Estimation Theory in p Dimensions. Large Sample Tests and Confidence Regions. Large Sample Methods for Discrete Data. Generalized Linear Models. Robustness Properties and Semiparametric Models. Appendix A: A Review of Basic Probability Theory. The Basic Model. Elementary Properties of Probability Models. Discrete Probability Models. Conditional Probability and Independence. Compound Experiments. Bernoulli and Multinomial Trials, Sampling with and without Replacement. Probabilities on Euclidean Space. Random Variables and Vectors: Transformations. Independence of Random Variables and Vectors. The Expectation of a Random Variable. Moments. Moment and Cumulant Generating Functions. Some Classical Discrete and Continuous Distributions. Modes of Convergence of Random Variables and Limit Theorems. Further Limit Theorems and Inequalities. Poisson Process. Appendix B: Additional Topics in Probability and Analysis. Conditioning by a Random Variable or Vector. Distribution Theory for Transformations of Random Vectors. Distribution Theory for Samples from a Normal Population. The Bivariate Normal Distribution. Moments of Random Vectors and Matrices. The Multivariate Normal Distribution. Convergence for Random Vectors: Op and Op Notation. Multivariate Calculus. Convexity and Inequalities. Topics in Matrix Theory and Elementary Hilbert Space Theory. Appendix C: Tables. The Standard Normal Distribution. Auxiliary Table of the Standard Normal Distribution. t Distribution Critical Values. X 2 Distribution Critical Values. F Distribution Critical Values. Index."
            },
            "slug": "Mathematical-Statistics:-Basic-Ideas-and-Selected-Bickel-Doksum",
            "title": {
                "fragments": [],
                "text": "Mathematical Statistics: Basic Ideas and Selected Topics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786843"
                        ],
                        "name": "A. Globerson",
                        "slug": "A.-Globerson",
                        "structuredName": {
                            "firstName": "Amir",
                            "lastName": "Globerson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Globerson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35132120"
                        ],
                        "name": "T. Jaakkola",
                        "slug": "T.-Jaakkola",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Jaakkola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jaakkola"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Globerson and Jaakkola [91] exploit these facts in order to derive a variational relaxation based on convex combination of planar subgraphs, as well as iterative algorithms for computing the optimal bound."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "It has also suggested novel variational methods, also based on the notion of convex combinations, including those based on planar graph decomposition [91]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5652237,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6568359d23425b5c7fb387fe30ff4137cde3f86d",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "A number of exact and approximate methods are available for inference calculations in graphical models. Many recent approximate methods for graphs with cycles are based on tractable algorithms for tree structured graphs. Here we base the approximation on a different tractable model, planar graphs with binary variables and pure interaction potentials (no external field). The partition function for such models can be calculated exactly using an algorithm introduced by Fisher and Kasteleyn in the 1960s. We show how such tractable planar models can be used in a decomposition to derive upper bounds on the partition function of non-planar models. The resulting algorithm also allows for the estimation of marginals. We compare our planar decomposition to the tree decomposition method of Wain-wright et. al., showing that it results in a much tighter bound on the partition function, improved pairwise marginals, and comparable singleton marginals."
            },
            "slug": "Approximate-inference-using-planar-graph-Globerson-Jaakkola",
            "title": {
                "fragments": [],
                "text": "Approximate inference using planar graph decomposition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work base the approximation on a different tractable model, planar graphs with binary variables and pure interaction potentials (no external field), and shows how such tractable planar models can be used in a decomposition to derive upper bounds on the partition function of non-planar models."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2894468"
                        ],
                        "name": "P. Pakzad",
                        "slug": "P.-Pakzad",
                        "structuredName": {
                            "firstName": "Payam",
                            "lastName": "Pakzad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pakzad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145785241"
                        ],
                        "name": "V. Anantharam",
                        "slug": "V.-Anantharam",
                        "structuredName": {
                            "firstName": "Venkat",
                            "lastName": "Anantharam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Anantharam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 57
                            }
                        ],
                        "text": "In contrast, with the exception of certain special cases [107, 184, 185, 163], Kikuchi and other hypergraph-based entropy approximations are typically not convex."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 26
                            }
                        ],
                        "text": "Various other researchers [107, 163, 184, 185] also discuss the choice edge/clique weights in Bethe/Kikuchi approximations, and its consequences for convexity."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 55261,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "a1d814d7545dffeed61d088b06de20bb95d909b6",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "In this letter, we examine a general method of approximation, known as the Kikuchi approximation method, for finding the marginals of a product distribution, as well as the corresponding partition function. The Kikuchi approximation method defines a certain constrained optimization problem, called the Kikuchi problem, and treats its stationary points as approximations to the desired marginals. We show how to associate a graph to any Kikuchi problem and describe a class of local message-passing algorithms along the edges of any such graph, which attempt to find the solutions to the problem. Implementation of these algorithms on graphs with fewer edges requires fewer operations in each iteration. We therefore characterize minimal graphs for a Kikuchi problem, which are those with the minimum number of edges. We show with empirical results that these simpler algorithms often offer significant savings in computational complexity, without suffering a loss in the convergence rate. We give conditions for the convexity of a given Kikuchi problem and the exactness of the approximations in terms of the loops of the minimal graph. More precisely, we show that if the minimal graph is cycle free, then the Kikuchi approximation method is exact, and the converse is also true generically. Together with the fact that in the cycle-free case, the iterative algorithms are equivalent to the well-known belief propagation algorithm, our results imply that, generically, the Kikuchi approximation method can be exact if and only if traditional junction tree methods could also solve the problem exactly."
            },
            "slug": "Estimation-and-Marginalization-Using-the-Kikuchi-Pakzad-Anantharam",
            "title": {
                "fragments": [],
                "text": "Estimation and Marginalization Using the Kikuchi Approximation Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This letter examines a general method of approximation for finding the marginals of a product distribution, as well as the corresponding partition function, and shows that if the minimal graph is cycle free, then the Kikuchi approximation method is exact, and the converse is also true generically."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721860"
                        ],
                        "name": "M. Wainwright",
                        "slug": "M.-Wainwright",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Wainwright",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wainwright"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35132120"
                        ],
                        "name": "T. Jaakkola",
                        "slug": "T.-Jaakkola",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Jaakkola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jaakkola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701607"
                        ],
                        "name": "A. Willsky",
                        "slug": "A.-Willsky",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Willsky",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Willsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 50
                            }
                        ],
                        "text": "We summarize our findings in the following result [238, 241]:"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 90
                            }
                        ],
                        "text": "Indeed, given multiple fixed points, its behavior can be unstable and erratic; the papers [238, 236] provide some cautionary instances of poor behavior with ordinary sum-product."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 115
                            }
                        ],
                        "text": "We begin by deriving the tree-reweighted sum-product algorithm and the tree-reweighted Bethe variational principle [238, 241], corresponding to a \u201cconvexified\u201d analog of the ordinary Bethe variational principle described in Section 4."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 158
                            }
                        ],
                        "text": "The proof of this fact relies on the tree-based reparameterization interpretation of the ordinary sum-product algorithm, as well as its reweighted extensions [238, 241]; see Section 4."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 242,
                                "start": 232
                            }
                        ],
                        "text": "As our first example illustrates, following this procedure using tree-structured distributions as the tractable class leads to the family of \u201cconvexified\u201d Bethe variational problems, and associated reweighted sum-product algorithms [238, 241]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 113
                            }
                        ],
                        "text": "The use of such approximate methods and their impact on parameter estimation is still an active area of research [220, 226, 238, 236, 248]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15761929,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "44bed05c75b761e1ad2a93c0be35a2acb4deb5b9",
            "isKey": false,
            "numCitedBy": 229,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "In previous work [10], we presented a class of upper bounds on the log partition function of an arbitrary undirected graphical model based on solving a convex variational problem. Here we develop a class of local message-passing algorithms, which we call tree-reweighted belief propagation, for efficiently computing the value of these upper bounds, as well as the associated pseudomarginals. We also consider the uses of our bounds for the problem of maximum likelihood (ML) parameter estimation. For a completely observed model, our analysis gives rise to a concave lower bound on the log likelihood of the data. Maximizing this lower bound yields an approximate ML estimate which, in analogy to the moment-matching of exact ML estimation, can be interpreted in terms of pseudo-moment-matching. We present preliminary results illustrating the behavior of this approximate ML estimator."
            },
            "slug": "Tree-reweighted-belief-propagation-algorithms-and-Wainwright-Jaakkola",
            "title": {
                "fragments": [],
                "text": "Tree-reweighted belief propagation algorithms and approximate ML estimation by pseudo-moment matching"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A class of local message-passing algorithms is developed, which is called tree-reweighted belief propagation, for efficiently computing the value of these upper bounds on the log partition function of an arbitrary undirected graphical model, as well as the associated pseudomarginals."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1889982"
                        ],
                        "name": "F. Kschischang",
                        "slug": "F.-Kschischang",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Kschischang",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Kschischang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749650"
                        ],
                        "name": "B. Frey",
                        "slug": "B.-Frey",
                        "structuredName": {
                            "firstName": "Brendan",
                            "lastName": "Frey",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Frey"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our treatment is brief; further details can be found in various sources [2, 62, 139, 122, 151]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "represented here in the factor graph formalism [139]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6522238,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bbd45449e1cdadbf1f0c06a9510b5ac247cb70b9",
            "isKey": false,
            "numCitedBy": 425,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a unified graphical model framework for describing compound codes and deriving iterative decoding algorithms. After reviewing a variety of graphical models (Markov random fields, Tanner graphs, and Bayesian networks), we derive a general distributed marginalization algorithm for functions described by factor graphs. From this general algorithm, Pearl's (1986) belief propagation algorithm is easily derived as a special case. We point out that iterative decoding algorithms for various codes, including \"turbo decoding\" of parallel-concatenated convolutional codes, may be viewed as probability propagation in a graphical model of the code. We focus on Bayesian network descriptions of codes, which give a natural input/state/output/channel description of a code and channel, and we indicate how iterative decoders can be developed for parallel-and serially concatenated coding systems, product codes, and low-density parity-check codes."
            },
            "slug": "Iterative-Decoding-of-Compound-Codes-by-Probability-Kschischang-Frey",
            "title": {
                "fragments": [],
                "text": "Iterative Decoding of Compound Codes by Probability Propagation in Graphical Models"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is pointed out that iterative decoding algorithms for various codes, including \"turbo decoding\" of parallel-concatenated convolutional codes, may be viewed as probability propagation in a graphical model of the code."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE J. Sel. Areas Commun."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743286"
                        ],
                        "name": "D. Karger",
                        "slug": "D.-Karger",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Karger",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Karger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706280"
                        ],
                        "name": "Nathan Srebro",
                        "slug": "Nathan-Srebro",
                        "structuredName": {
                            "firstName": "Nathan",
                            "lastName": "Srebro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nathan Srebro"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Indeed, the hypertree analog of the maximum weight spanning tree problem is known to be NP-hard [126]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2149813,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "e114af27ac1927496f58f94fa8a9777558649bdd",
            "isKey": false,
            "numCitedBy": 146,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Markov networks are a common class of graphical models used in machine learning. Such models use an undirected graph to capture dependency information among random variables in a joint probability distribution. Once one has chosen to use a Markov network model, one aims to choose the model that \u201cbest explains\u201d the data that has been observed\u2014this model can then be used to make predictions about future data.\nWe show that the problem of learning a maximum likelihood Markov network given certain observed data can be reduced to the problem of identifying a maximum weight low-treewidth graph under a given input weight function. We give the first constant factor approximation algorithm for this problem. More precisely, for any fixed treewidth objective k, we find a treewidth-k graph with an f(k) fraction of the maximum possible weight of any treewidth-k graph."
            },
            "slug": "Learning-Markov-networks:-maximum-bounded-graphs-Karger-Srebro",
            "title": {
                "fragments": [],
                "text": "Learning Markov networks: maximum bounded tree-width graphs"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The problem of learning a maximum likelihood Markov network given certain observed data can be reduced to the problem of identifying a maximum weight low-treewidth graph under a given input weight function and the first constant factor approximation algorithm is given."
            },
            "venue": {
                "fragments": [],
                "text": "SODA '01"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3072213"
                        ],
                        "name": "J. Besag",
                        "slug": "J.-Besag",
                        "structuredName": {
                            "firstName": "Julian",
                            "lastName": "Besag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Besag"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145392702"
                        ],
                        "name": "P. Green",
                        "slug": "P.-Green",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Green",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Green"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 116604648,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "591ab85ffae8d5b021dd380ded7457ffd5e0416f",
            "isKey": false,
            "numCitedBy": 519,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "on Wednesday, May 6th, 1992, Professor B. W. Silverman in the Chair] SUMMARY Markov chain Monte Carlo (MCMC) algorithms, such as the Gibbs sampler, have provided a Bayesian inference machine in image analysis and in other areas of spatial statistics for several years, founded on the pioneering ideas of Ulf Grenander. More recently, the observation that hyperparameters can be included as part of the updating schedule and the fact that almost any multivariate distribution is equivalently a Markov random field has opened the way to the use of MCMC in general Bayesian computation. In this paper, we trace the early development of MCMC in Bayesian inference, review some recent computational progress in statistical physics, based on the introduction of auxiliary variables, and discuss its current and future relevance in Bayesian applications. We briefly describe a simple MCMC implementation for the Bayesian analysis of agricultural field experiments, with which we have some practical experience."
            },
            "slug": "Spatial-Statistics-and-Bayesian-Computation-Besag-Green",
            "title": {
                "fragments": [],
                "text": "Spatial Statistics and Bayesian Computation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The early development of MCMC in Bayesian inference is traced, some recent computational progress in statistical physics is reviewed, based on the introduction of auxiliary variables, and its current and future relevance in Bayesesian applications are discussed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30400079"
                        ],
                        "name": "Yair Weiss",
                        "slug": "Yair-Weiss",
                        "structuredName": {
                            "firstName": "Yair",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yair Weiss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2571487"
                        ],
                        "name": "C. Yanover",
                        "slug": "C.-Yanover",
                        "structuredName": {
                            "firstName": "Chen",
                            "lastName": "Yanover",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Yanover"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46737210"
                        ],
                        "name": "Talya Meltzer",
                        "slug": "Talya-Meltzer",
                        "structuredName": {
                            "firstName": "Talya",
                            "lastName": "Meltzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Talya Meltzer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13343223,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e2ded827bc58c9a46e571d0c215d6fe53e507d79",
            "isKey": false,
            "numCitedBy": 162,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Finding the most probable assignment (MAP) in a general graphical model is known to be NP hard but good approximations have been attained with max-product belief propagation (BP) and its variants. In particular, it is known that using BP on a single-cycle graph or tree reweighted BP on an arbitrary graph will give the MAP solution if the beliefs have no ties. In this paper we extend the setting under which BP can be used to provably extract the MAP. We define Convex BP as BP algorithms based on a convex free energy approximation and show that this class includes ordinary BP with single-cycle, tree reweighted BP and many other BP variants. We show that when there are no ties, fixed-points of convex max-product BP will provably give the MAP solution. We also show that convex sum-product BP at sufficiently small temperatures can be used to solve linear programs that arise from relaxing the MAP problem. Finally, we derive a novel condition that allows us to derive the MAP solution even if some of the convex BP beliefs have ties. In experiments, we show that our theorems allow us to find the MAP in many real-world instances of graphical models where exact inference using junction-tree is impossible."
            },
            "slug": "MAP-Estimation,-Linear-Programming-and-Belief-with-Weiss-Yanover",
            "title": {
                "fragments": [],
                "text": "MAP Estimation, Linear Programming and Belief Propagation with Convex Free Energies"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Convex BP is defined as BP algorithms based on a convex free energy approximation and it is shown that this class includes ordinary BP with single-cycle, tree reweighted BP and many other BP variants, and fixed-points of convex max-product BP will provably give the MAP solution when there are no ties."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50361223"
                        ],
                        "name": "L. Thomas",
                        "slug": "L.-Thomas",
                        "structuredName": {
                            "firstName": "Lyn",
                            "lastName": "Thomas",
                            "middleNames": [
                                "C."
                            ],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Thomas"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 174
                            }
                        ],
                        "text": "Sum-product algorithm: The sum-product algorithm is a form of non-serial dynamic programming (DP) that generalizes the usual serial form of deterministic dynamic programming [7] to arbitrary tree-structured graphs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62727947,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "e27c7213bf12c872f7831f3886c164fe0d1e1cea",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "of the models analyzed include the spectral representation of solution vectors, limiting states, the covariance matrix of the elements of the state composition vector, the means and variances of sojourn times, and expanding and contracting systems, rather than methods of statistical estimation. In the discussion of discrete time models, the illustrations are drawn primarily from the study of social and occupational mobility, and for continuous time models, they are drawn from the field of educational and manpower planning. The remaining five chapters treat control theory for Markov models, models for duration and size, models for social systems with fixed class sizes, and simple and general epidemic models for the diffusion of news, rumors, and ideas. Simple epidemic models are birth process models that assume that infection is an irreversible state, so given either a constant individual rate of transmission or a single constant source of transmission, the entire population is eventually infected. General epidemic models allow for the duration of infection to be a random variable. The book ends with a full, up-to-date bibliography, an author index, and a subject index. In summary, Bartholomew gives an excellent introduction to many types of stochastic processes and a broad range of applications for modeling and planning social systems. The applications of stochastic processes to studying social mobility and flows of personnel within organizations receive much more extended treatment here than in other introductory treatments of applied stochastic processes. The \"Complements\" section at the end of each chapter is a useful overview of recent research investigations in many other areas of application that apply or extend the models presented in the chapter. Since no problems for solution are contained and the exposition is often informal, some teachers may wish to supplement the book with more traditional stochastic process textbooks, one good choice being Karlin and Taylor (1975). There seem to be few typographical errors."
            },
            "slug": "Optimization-over-Time.-Dynamic-Programming-and-1-Thomas",
            "title": {
                "fragments": [],
                "text": "Optimization over Time. Dynamic Programming and Stochastic Control. Volume 1"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The applications of stochastic processes to studying social mobility and flows of personnel within organizations receive much more extended treatment here than in other introductory treatments of applied stochastics processes."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143930409"
                        ],
                        "name": "M. Chertkov",
                        "slug": "M.-Chertkov",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Chertkov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Chertkov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145833214"
                        ],
                        "name": "V. Chernyak",
                        "slug": "V.-Chernyak",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Chernyak",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Chernyak"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In this section, we discuss the loop series expansions of Chertkov and Chernyak [48]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This lower-bounding property is closely related to the connection between the Bethe approximation and loop series expansions [48], discussed in Section 4."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Proposition 6 has extensions to more general factor graphs; see the papers [48, 219] for more details."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Following Chertkov and Chernyak [48], we define a generalized loop to be a subgraph G(F ) for which all nodes s \u2208 V have degree ds(F ) 6= 1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14745624,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e3551f58e2d2fb4476f9edb2a1055dd087dbac85",
            "isKey": true,
            "numCitedBy": 152,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present the derivation details, logic, and motivation for the three loop calculus introduced in Chertkov and Chernyak (2006\u00a0Phys.\u00a0Rev.\u00a0E\u00a073\u00a0065102(R)). Generating functions for each of the three interrelated discrete statistical models are expressed in terms of a finite series. The first term in the series corresponds to the Bethe\u2013Peierls belief\u2013propagation (BP) contribution; the other terms are labelled by loops on the factor graph. All loop contributions are simple rational functions of spin correlation functions calculated within the BP approach. We discuss two alternative derivations of the loop series. One approach implements a set of local auxiliary integrations over continuous fields with the BP contribution corresponding to an integrand saddle-point value. The integrals are replaced by sums in the complementary approach, briefly explained in Chertkov and Chernyak\u00a0(2006\u00a0Phys.\u00a0Rev.\u00a0E\u00a073\u00a0065102(R)). Local gauge symmetry transformations that clarify an important invariant feature of the BP solution are revealed in both approaches. The individual terms change under the gauge transformation while the partition function remains invariant. The requirement for all individual terms to be nonzero only for closed loops in the factor graph (as opposed to paths with loose ends) is equivalent to fixing the first term in the series to be exactly equal to the BP contribution. Further applications of the loop calculus to problems in statistical physics, computer and information sciences are discussed."
            },
            "slug": "Loop-series-for-discrete-statistical-models-on-Chertkov-Chernyak",
            "title": {
                "fragments": [],
                "text": "Loop series for discrete statistical models on graphs"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "The derivation details, logic, and motivation for the three loop calculus introduced in Chertkov and Chernyak (2006) are presented and local gauge symmetry transformations that clarify an important invariant feature of the BP solution are revealed."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35132120"
                        ],
                        "name": "T. Jaakkola",
                        "slug": "T.-Jaakkola",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Jaakkola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jaakkola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "While there have been specialized examples of the application of variational methods for such families [119], there does not yet exist a general treatment of variational methods for curved exponential families."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11595354,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b0d62ffdcebed5da55bd48242ed62ba25d7fd87",
            "isKey": false,
            "numCitedBy": 185,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a variational approximation method for efficient inference in large-scale probabilistic models. Variational methods are deterministic procedures that provide approximations to marginal and conditional probabilities of interest. They provide alternatives to approximate inference methods based on stochastic sampling or search. We describe a variational approach to the problem of diagnostic inference in the \"Quick Medical Reference\" (QMR) network. The QMR network is a large-scale probabilistic graphical model built on statistical and expert knowledge. Exact probabilistic inference is infeasible in this model for all but a small set of cases. We evaluate our variational inference algorithm on a large set of diagnostic test cases, comparing the algorithm to a state-of-the-art stochastic sampling method."
            },
            "slug": "Variational-Probabilistic-Inference-and-the-QMR-DT-Jaakkola-Jordan",
            "title": {
                "fragments": [],
                "text": "Variational Probabilistic Inference and the QMR-DT Network"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "This work describes a variational approximation method for efficient inference in large-scale probabilistic models and evaluates the algorithm on a large set of diagnostic test cases, comparing the algorithm to a state-of-the-art stochastic sampling method."
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif. Intell. Res."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790356"
                        ],
                        "name": "T. Heskes",
                        "slug": "T.-Heskes",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Heskes",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Heskes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073572"
                        ],
                        "name": "K. Albers",
                        "slug": "K.-Albers",
                        "structuredName": {
                            "firstName": "Kees",
                            "lastName": "Albers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Albers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792269"
                        ],
                        "name": "H. Kappen",
                        "slug": "H.-Kappen",
                        "structuredName": {
                            "firstName": "Hilbert",
                            "lastName": "Kappen",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kappen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "A parallel line of work [265, 249, 108] has explored alternatives to sum-product that are guaranteed to converge, albeit at the price of increased computational cost."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Another possibility would be to adapt other double-loop algorithms [265, 249, 108, 107], originally developed for the ordinary Bethe/Kikuchi problems, to solve these convex minimization problems; see Hazan and Shashua [105] for some recent work along these lines."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "63), possibly along the lines of convergent algorithms developed for the ordinary Bethe variational problem [265, 249, 108]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "[263, 264] and further explored by various researchers [184, 163, 108, 235, 265], that improves both components simultaneously."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6845974,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c09ff975d5ed65512a9c89e7216320ae64cd786c",
            "isKey": true,
            "numCitedBy": 111,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Loopy and generalized belief propagation are popular algorithms for approximate inference in Markov random fields and Bayesian networks. Fixed points of these algorithms correspond to extrema of the Bethe and Kikuchi free energy (Yedidia et al., 2001). However, belief propagation does not always converge, which motivates approaches that explicitly minimize the Kikuchi/Bethe free energy, such as CCCP (Yuille, 2002) and UPS (Teh and Welling, 2002). Here we describe a class of algorithms that solves this typically non-convex constrained minimization problem through a sequence of convex constrained minimizations of upper bounds on the Kikuchi free energy. Intuitively one would expect tighter bounds to lead to faster algorithms, which is indeed convincingly demonstrated in our simulations. Several ideas are applied to obtain tight convex bounds that yield dramatic speed-ups over CCCP."
            },
            "slug": "Approximate-Inference-and-Constrained-Optimization-Heskes-Albers",
            "title": {
                "fragments": [],
                "text": "Approximate Inference and Constrained Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "A class of algorithms is described that solves this typically non-convex constrained minimization problem through a sequence of conveX constrained minimizations of upper bounds on the Kikuchi free energy."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145878635"
                        ],
                        "name": "Tom\u00e1\u0161 Werner",
                        "slug": "Tom\u00e1\u0161-Werner",
                        "structuredName": {
                            "firstName": "Tom\u00e1\u0161",
                            "lastName": "Werner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom\u00e1\u0161 Werner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "There also turn out to be a number of interesting connections between TRW max-product and a line of research, due to Schlesinger and collaborators, previously published in the Russian literature [205, 137]; Werner [251] provides a detailed overview of this line of work, and some connections to reweighted max-product and LP relaxation."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 11901033,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f156f0c7ef3ac5274d92234cd3a3a40f9ca1fb94",
            "isKey": false,
            "numCitedBy": 403,
            "numCiting": 124,
            "paperAbstract": {
                "fragments": [],
                "text": "The max-sum labeling problem, defined as maximizing a sum of binary (i.e., pairwise) functions of discrete variables, is a general NP-hard optimization problem with many applications, such as computing the MAP configuration of a Markov random field. We review a not widely known approach to the problem, developed by Ukrainian researchers Schlesinger et al. in 1976, and show how it contributes to recent results, most importantly, those on the convex combination of trees and tree-reweighted max-product. In particular, we review Schlesinger et al.'s upper bound on the max-sum criterion, its minimization by equivalent transformations, its relation to the constraint satisfaction problem, the fact that this minimization is dual to a linear programming relaxation of the original problem, and the three kinds of consistency necessary for optimality of the upper bound. We revisit problems with Boolean variables and supermodular problems. We describe two algorithms for decreasing the upper bound. We present an example application for structural image analysis."
            },
            "slug": "A-Linear-Programming-Approach-to-Max-Sum-Problem:-A-Werner",
            "title": {
                "fragments": [],
                "text": "A Linear Programming Approach to Max-Sum Problem: A Review"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work reviews a not widely known approach to the max-sum labeling problem, developed by Ukrainian researchers Schlesinger et al. in 1976, and shows how it contributes to recent results, most importantly, those on the convex combination of trees and tree-reweighted max-product."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3198578"
                        ],
                        "name": "J. Yedidia",
                        "slug": "J.-Yedidia",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Yedidia",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Yedidia"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Despite these issues, the naive mean field approximation becomes asymptotically exact for certain types of models as the number of nodes m grows to infinity [11, 262]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 141225804,
            "fieldsOfStudy": [
                "Chemistry"
            ],
            "id": "91699ea4bec60d4d47ca3db8c8d1e035d069d9e4",
            "isKey": false,
            "numCitedBy": 46,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "I try to clarify the relationships between different ways of deriving or correcting mean field theory, and present \u201dtranslations\u201d between the language of physicists and that of computer scientists. The connecting thread between the different methods described here is the Gibbs free energy. After introducing the inference problem we are interested in analyzing, I will define the Gibbs free energy, and describe how to derive a mean field approximation to it using a variational approach. I will then explain how one might re-derive and correct the mean field and TAP free energies using high temperature expansions with constrained one-node beliefs. I will explore the relationships between the high-temperature expansion approach, the Bethe approximation, and the belief propagation algorithm, and point out in particular the equivalence of the Bethe approximation and belief propagation. Finally, I will describe Kikuchi approximations to the Gibbs Free energy and advertise new belief propagation algorithms that efficiently compute beliefs equivalent to those obtained from the Kikuchi free energy. To appear as a chapter in \u201cAdvanced Mean Field Methods Theory and Practice\u201d, eds. D. Saad and M. Opper, MIT Press, 2000. This work may not be copied or reproduced in whole or in part for any commercial purpose. Permission to copy in whole or in part without payment of fee is granted for nonprofit educational and research purposes provided that all such whole or partial copies include the following: a notice that such copying is by permission of Mitsubishi Electric Information Technology Center America; an acknowledgment of the authors and individual contributions to the work; and all applicable portions of the copyright notice. Copying, reproduction, or republishing for any other purpose shall require a license with payment of fee to Mitsubishi Electric Information Technology Center America. All rights reserved. Copyright c Mitsubishi Electric Information Technology Center America, 2000 201 Broadway, Cambridge, Massachusetts 02139 Publication History:\u2013 1. First printing, TR-2000-27, June 2000 ! \" # %$& ' () * ,+ .-0/ 1 2 314#57698#5 4;:= A@CB#DEB#DE5 F < F G 4,69H 3IB J#KL6MDE314 NPORQTS UWV)XYS'ZL[7Q]\\_^`NAabUdcec QT^]fgQ]hiXjcWZL^]UlkmfnQTS \\o^T\\9cdZLQTUdhpO VTS Ud[ Vrq1\\jQsat\\_\\9Ovu7Ulw,\\_^]\\_O Q atZxf7V)hLkyu7\\9^TUdzCUeO {nhp^|Xjh ^T^]\\9XjQTUdO {i}|\\9ZpO\u007f~ \\9cduvQTS \\9hp^]fp\u0080 \u0081 S \\\"\u0082y\\MXj\\_})q'\\9^0\u0083M\u0084p\u0084 \u0084 \u0085\u0086Ns\u0087 \u0088nathp^]\u00897V\u008aS h [ih O!\u008b]\u008cyu7z ZpO Xj\\Mun\u008d\u008e\\MZLO\u007f\u008f#Ue\\9cduR\u008d\u008e\\_QTS h7u V]\u0090\u008eVT\u0091 X_X_\\_\\9u \\9u O UWXj\\_cdf UeO q ^]UeO { UeO {\u0092Q]hp{p\\_QTS \\9^A[ SCfCVTUWXjUWVsQYV\u0093ZpO u Xjhp}|[ \u0091 QT\\_^rV]XjUd\\_O QTUWV\u008aQ]V9\u0094 abS h0O h atZ u Zxf7V hLk\u0095QT\\9O0athp^]\u0089|hpO0[ ^T\\MXjUWV\u008a\\9cef\u0096Q]S \\rVTZp}\u0096\\\u0097[ ^]hpq cd\\_}\u0098V9\u0094 q \u00917Q\u0086Xjhp}|\\\u0097QTh)QTS \\MV\u008a\\\u0093[ ^]hpq cd\\_}\u0098V abUlQ]S%u7Uew1\\9^T\\9O Qn['\\9^]VT['\\MX\u0099Q]Uez \\9V9\u0094y}|\\jQ]S h7u V_\u0094\u0093O Zp}\u0096\\MViZpO u O hLQYZ Q]Ueh O V_\u0080\u0093\u0088Chp}|\\\u009ahpk QTS UWV\u0086XYS Zp[7QT\\9^bUdVtQ]S \\_^]\\jkmh ^T\\ru7\\9zphLQ]\\9u\u0092QTh|[ ^]\\9VT\\_O QTUdO {\u0096QT^YZLO'V\u008acWZ Q]Ueh O Vtq'\\_Qsa \\9\\_O0QTS \\ cdZpO {p\u0091 Zp{p\\0hLkyQ]S \\\"[ SCf7V\u008aUWXjUWVsQ\u0098ZLO'uvQ]S \\\"cdZpO {p\u0091 Zp{p\\0hLk\u0086Q]S \\\u008eXjhp}|[ \u0091 QT\\_^oV]XjUd\\_O Q]UdV\u008aQ9\u0094 ZLceQTS h \u0091 {pSvN`Zp}\u009bV\u008a\u0091 ^]\\oQ]S Z Q\u0096}\u009cfRhp^]Ud{pUdO ZLc QT^YZLUdO UeO {nZpV)Zg[ SCf7VTUdX_UdV\u008aQ)abUdcec VTS h a QTS ^]hp\u0091 { SI\u0080 N abUecdc hpO cef\u009cX_h zp\\9^#}|\\_QTS h7u V?Q]S Z Q N#S Zxzp\\t[1\\_^YV\u008ah O ZLcdcefr\u0091'V\u008a\\Mu \u0094pVTh\u0097Q]S UWV XYS ZL[7Q]\\_^ u7hC\\9V\u007fO hpQ\u009aZ QTQT\\_}|[7Q\u009aQTh\u009dq1\\\u009eZ!QTS h ^Th \u0091 {pS\u009fVT\u0091 ^Tz \\_f.hpk UeQ]V\u009aV\u008a\u0091 q is\\9X\u0099QM\u0080)\u00a2b\\MZpu7\\9^]V UeO QT\\9^T\\MVsQ]\\9uRUdOv}|hp^]\\oq Z XY\u0089 { ^Th \u0091 O u hpORQ]S \\0V\u008aQ]ZLQTUWVsQ]UdX9ZLc [ SCfCVTUWX_V`hpkyu7UWV\u008ah ^]u7\\9^T\\Mu V\u008af7V\u008aQT\\_}\u0098V \u00a3m[ Zp^\u008aQ]UdX_\u0091 cWZL^]cef\u00a4abUeQTS\u009e^]\\_{ ZL^Yu\u00a5QTh\u009aQTS \\nQT\\MXYS O UW\u00a6 \u0091 \\nhpk)Zxzp\\9^]Zp{pUdO {Rh zp\\_^ u7UdVThp^Yu7\\9^ \u0091 V\u008aUdO {rQ]S \\\u0086^]\\_[ cdUWX_Z\u0093}|\\jQTS hCu'\u00a7 }|Ue{ S Q ZLcWV\u008ahra ZLO Q QTh`X_hpO VT\u0091 ceQ ^]\\jkm\\_^]\\_O'Xj\\9V \u00a3s\u00839\u0084 \u00a7\u0099\u0094)\u00a3 L\u00a9 \u00a7\u0099\u0094\u0097ZpO u\u009f\u00a3Ea \u0083M\u00a7\u0099\u0094\u0097abS Udce\\RQ]S h VT\\vUdO Q]\\_^]\\9V\u008aQT\\Mu;UdO QTS \\\u009aXjh }\u0096[ \u00917QT\\9^iVTX_Ue\\9O Xj\\ ceUeQT\\9^]ZLQT\u0091 ^]\\\u0098hpO\u007f{ ^]Zp[ S UWX_ZLc }\u0096h7u7\\9cdV\u009c}|Ue{ S Q\u009cX_hpO VT\u0091 ceQ\u009c^]\\jkm\\_^]\\_O'Xj\\9V\u0092\u00a3* La \u00a7\u0099\u0094t\u00a3s\u0083p\u0083M\u00a7`ZLO'u \u00a3 \u00abL\u00a7j\u0080 \u0081 S \\\u0086X_hpO O \\9X\u0099Q]UeO {\u0097Q]S ^]\\9Zpu\u0096q1\\jQsat\\_\\9O)Q]S \\\u0086u7Uew1\\9^T\\9O Q=}\u0096\\_QTS h7u V u7\\9V]Xj^]Ueq1\\9u\u0096S \\9^T\\ UdV QTS \\r\u00ac\u0093Udq q V km^T\\9\\y\\_O \\_^]{pfp\u0080C\u008cbk\u0095Q]\\_^tUeO Q]^Th7u7\u0091 X_UeO {`QTS \\\u0097UdO7km\\_^]\\_O'Xj\\y[ ^Th q ce\\9}\u009fa \\yZp^T\\ UeO QT\\9^T\\MVsQ]\\9u\u0092UeO ZLO ZpcefC\u00ad_UdO {'\u0094 N=abUdcdcIu7\\j~ O \\yQ]S \\`\u00ac\u0093Ueq q'V km^]\\_\\\u0093\\_O \\_^]{pfp\u0094CZLO'u\u0092u7\\MVTX_^TUdq'\\ S h a\u009dQTh\u008eu7\\9^TUdzp\\\u0096Z\u0092}|\\MZLOn~ \\_cWunZp[ [ ^]hx\u00ae7Ue}\u0098Z Q]Ueh O\"QTh\"UeQA\u0091'V\u008aUdO {\"Z\u0092z ZL^]UWZ QTUdhpO'ZLc?ZL[7 [ ^Th ZpXYSI\u0080MNIabUdcecCQ]S \\_O\u0096\\j\u00ae7[ cWZLUdO\u009cS h avhpO \\t}|Ue{ S Q#^]\\j Pu7\\_^]Udzp\\ ZpO u\u009cX_hp^]^T\\MX\u0099Q QTS \\ }|\\9ZpO ~ \\_cWu)ZpO u\u0096\u0081 \u008c\u0097\u0087gkm^]\\_\\ \\_O \\_^]{pUd\\9V \u0091 V\u008aUdO {AS Ud{pS\u009cQT\\_}|[1\\_^YZ Q]\u0091 ^T\\ \\_\u00aeC['ZLO VTUeh O V abUlQ]S\u0096X_hpO7 VsQ]^]ZpUeO \\Mu\u007fhpO \\j \u00b0O h7u7\\\u0092q1\\_cdUe\\_kEV_\u0080 N\u009cabUecdc \\j\u00ae7[ cdhp^]\\\u0098QTS \\\"^]\\_cWZ Q]Ueh O V\u008aS Ue[ V\u009cq'\\_Qsa \\9\\_O\u009aQTS \\ S Ue{ S7 QT\\_}|[1\\_^YZ Q]\u0091 ^T\\i\\j\u00ae7[ ZLO'V\u008aUdhpO\u00b1Zp[ [ ^]h ZpXYS \u0094 QTS \\R2t\\jQ]S \\nZp[ [ ^]hx\u00aeCUd}\u0098Z Q]Ueh OI\u0094 ZLO'u QTS \\Aq1\\_cdUe\\_k#[ ^]hp['ZL{ ZLQTUdhpO\u0092Zpce{ hp^]UlQ]S }\"\u00947ZLO u\u0092['h UeO Qbhp\u00917QbUdO0['ZL^TQTUWXj\u0091 cWZL^tQTS \\\u0093\\M\u00a6 \u0091 Uez ZLcd\\_O X_\\bhLk1QTS \\y2t\\_QTS \\yZp[ [ ^]hx\u00ae7Ue}\u0098Z Q]Ueh O)ZpO u|q'\\9ceUd\\jk [ ^]hp['ZL{ ZLQTUdhpOI\u0080 \u008f#UdO ZLcdcef \u0094pN#abUecdc u7\\9V]Xj^]Ueq1\\o3AUd\u0089 \u0091'XYS U ZL[ [ ^Thx\u00ae7Ud}\u0098Z QTUdhpO'V\u0093QTh\"QTS \\0\u00ac\u0093Ueq q V\u009c\u008f ^T\\9\\\u0098\\_O \\9^T{ fnZLO'u Z u7zp\\9^\u008a QTUWV\u008a\\0O \\_a q1\\_cdUe\\_k\u0086[ ^]hp[ Zp{ Z Q]Ueh O Zpce{ hp^]UlQ]S }\u0098VrQ]S Z Q\u0096\\j\u03bcoXjUd\\_O QTcdfRXjhp}|[ \u0091 QT\\\u0092q1\\_cdUd\\jkEV \\9\u00a6 \u0091 UdzxZpce\\9O QtQ]h|QTS h V\u008a\\Ah q7Q]ZpUeO \\Mu0km^Th } QTS \\`3AUd\u0089C\u0091 XYS U,km^]\\_\\A\\_O \\_^]{pfp\u0080 \u00b6A\u00b7\u0095 \u008e11o \u00bbs1\u20444*1\u20444 \u00b6r1\u20442]3\u20444*? AYA#\u00c2jAYA\u0099A\u0099A\u0099AjAYA\u0099AjA9AEsCxEEAE\u008aEME E\u0099II1'1\u20442YI\u0099\u00bb AE"
            },
            "slug": "An-Idiosyncratic-Journey-Beyond-Mean-Field-Theory-Yedidia",
            "title": {
                "fragments": [],
                "text": "An Idiosyncratic Journey Beyond Mean Field Theory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143681410"
                        ],
                        "name": "H. Loeliger",
                        "slug": "H.-Loeliger",
                        "structuredName": {
                            "firstName": "Hans-Andrea",
                            "lastName": "Loeliger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Loeliger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The formalism of factor graphs provides an alternative graphical representation, one which emphasizes the factorization of the distribution [140, 154]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7722934,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f054792ab3ec8d827d84d007dc2bd01e69c4cea7",
            "isKey": false,
            "numCitedBy": 801,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": "Graphical models such as factor graphs allow a unified approach to a number of key topics in coding and signal processing such as the iterative decoding of turbo codes, LDPC codes and similar codes, joint decoding, equalization, parameter estimation, hidden-Markov models, Kalman filtering, and recursive least squares. Graphical models can represent complex real-world systems, and such representations help to derive practical detection/estimation algorithms in a wide area of applications. Most known signal processing techniques -including gradient methods, Kalman filtering, and particle methods -can be used as components of such algorithms. Other than most of the previous literature, we have used Forney-style factor graphs, which support hierarchical modeling and are compatible with standard block diagrams."
            },
            "slug": "An-introduction-to-factor-graphs-Loeliger",
            "title": {
                "fragments": [],
                "text": "An introduction to factor graphs"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work uses Forney-style factor graphs, which support hierarchical modeling and are compatible with standard block diagrams, and uses them to derive practical detection/estimation algorithms in a wide area of applications."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Signal Processing Magazine"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721860"
                        ],
                        "name": "M. Wainwright",
                        "slug": "M.-Wainwright",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Wainwright",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wainwright"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35132120"
                        ],
                        "name": "T. Jaakkola",
                        "slug": "T.-Jaakkola",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Jaakkola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jaakkola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701607"
                        ],
                        "name": "A. Willsky",
                        "slug": "A.-Willsky",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Willsky",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Willsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15245893,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "01e560a3e0eae9f80a1f6c033e429768f3d1109c",
            "isKey": false,
            "numCitedBy": 141,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": "Finding the maximum a posteriori (MAP) assignment of a discrete-state distribution specified by a graphical model requires solving an integer program. The max-product algorithm, also known as the max-plus or min-sum algorithm, is an iterative method for (approximately) solving such a problem on graphs with cycles. We provide a novel perspective on the algorithm, which is based on the idea of reparameterizing the distribution in terms of so-called pseudo-max-marginals on nodes and edges of the graph. This viewpoint provides conceptual insight into the max-product algorithm in application to graphs with cycles. First, we prove the existence of max-product fixed points for positive distributions on arbitrary graphs. Next, we show that the approximate max-marginals computed by max-product are guaranteed to be consistent, in a suitable sense to be defined, over every tree of the graph. We then turn to characterizing the nature of the approximation to the MAP assignment computed by max-product. We generalize previous work by showing that for any graph, the max-product assignment satisfies a particular optimality condition with respect to any subgraph containing at most one cycle per connected component. We use this optimality condition to derive upper bounds on the difference between the log probability of the true MAP assignment, and the log probability of a max-product assignment. Finally, we consider extensions of the max-product algorithm that operate over higher-order cliques, and show how our reparameterization analysis extends in a natural manner."
            },
            "slug": "Tree-consistency-and-bounds-on-the-performance-of-Wainwright-Jaakkola",
            "title": {
                "fragments": [],
                "text": "Tree consistency and bounds on the performance of the max-product algorithm and its generalizations"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A novel perspective on the max-product algorithm is provided, based on the idea of reparameterizing the distribution in terms of so-called pseudo-max-marginals on nodes and edges of the graph, to provide conceptual insight into the algorithm in application to graphs with cycles."
            },
            "venue": {
                "fragments": [],
                "text": "Stat. Comput."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783429"
                        ],
                        "name": "W. Wiegerinck",
                        "slug": "W.-Wiegerinck",
                        "structuredName": {
                            "firstName": "Wim",
                            "lastName": "Wiegerinck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Wiegerinck"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "However, this basic procedure for \u201cconvexification\u201d is quite broadly applicable; as we describe, it yields convex analogs of other known variational methods, including Kikuchi and region-graph methods [241, 255, 246], as well as expectation-propagation approximation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Similarly, empirical results due to Wiegerinck [255] show that suitably reweighted forms of generalized belief propagation (GBP) also behave in a stable manner (unlike standard GBP), and this stability can be confirmed theoretically via strong convexity."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In analogy to the tree-reweighted sum-product algorithm, it is possible to develop hypertree-reweighted forms of generalized sum-product updates [255, 246]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "[241], and has been further studied by various researchers [255, 246]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6093712,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fe8df499fee8989844185ddb9b8d9d31ceef7e66",
            "isKey": true,
            "numCitedBy": 22,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "In (Wainwright et al., 2002) a new general class of upper bounds on the log partition function of arbitrary undirected graphical models has been developed. This bound is constructed by taking convex combinations of tractable distributions. The experimental results published so far concentrates on combinations of tree-structured distributions leading to a convexified Bethe free energy, which is minimized by the tree-reweighted belief propagation algorithm. One of the favorable properties of this class of approximations is that increasing the complexity of the approximation is guaranteed to increase the precision. The lack of this guarantee is notorious in standard generalized belief propagation. We increase the complexity of the approximating distributions by taking combinations of junction trees, leading to a convexified Kikuchi free energy, which is minimized by reweighted generalized belief propagation. Experimental results for Ising grids as well as for fully connected Ising models are presented illustrating advantages and disadvantages of the reweighting method in approximate inference."
            },
            "slug": "Approximations-with-Reweighted-Generalized-Belief-Wiegerinck",
            "title": {
                "fragments": [],
                "text": "Approximations with Reweighted Generalized Belief Propagation"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This work increases the complexity of the approximating distributions by taking combinations of junction trees, leading to a convexified Kikuchi free energy, which is minimized by reweighted generalized belief propagation."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2673947"
                        ],
                        "name": "Pawan Kumar Mudigonda",
                        "slug": "Pawan-Kumar-Mudigonda",
                        "structuredName": {
                            "firstName": "Pawan",
                            "lastName": "Mudigonda",
                            "middleNames": [
                                "Kumar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pawan Kumar Mudigonda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144653004"
                        ],
                        "name": "V. Kolmogorov",
                        "slug": "V.-Kolmogorov",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Kolmogorov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Kolmogorov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143635540"
                        ],
                        "name": "Philip H. S. Torr",
                        "slug": "Philip-H.-S.-Torr",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Torr",
                            "middleNames": [
                                "H.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philip H. S. Torr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "[142] also give other cycle-structured SOC constraints that are redundant in certain cases (in particular, for certain settings of the parameters that define the mode-finding problem)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "[142] showed that one form of their SOCP relaxation is equivalent to a form of the quadratic programming (QP) relaxation proposed by Lafferty and Ravikumar [194]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "[142] also provide a cautionary message, by demonstrating that certain classes of SOCP constraints fail to improve upon the first-order tree-based LP relaxation (8."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 65681,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "47741ddc16e000d964d3160e40844b90df03a78e",
            "isKey": true,
            "numCitedBy": 77,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of obtaining the maximum a posteriori estimate of a general discrete random field (i.e. a random field defined using a finite and discrete set of labels) is known to be NP-hard. However, due to its central importance in many applications, several approximate algorithms have been proposed in the literature. In this paper, we present an analysis of three such algorithms based on convex relaxations: (i) LP-S: the linear programming (LP) relaxation proposed by Schlesinger [20] for a special case and independently in [4, 12, 23] for the general case; (ii) QP-RL: the quadratic programming (QP) relaxation by Ravikumar and Lafferty [18]; and (iii) SOCP-MS: the second order cone programming (SOCP) relaxation first proposed by Muramatsu and Suzuki [16] for two label problems and later extended in [14] for a general label set. \n \nWe show that the SOCP-MS and the QP-RL relaxations are equivalent. Furthermore, we prove that despite the flexibility in the form of the constraints/objective function offered by QP and SOCP, the LP-S relaxation strictly dominates (i.e. provides a better approximation than) QP-RL and SOCP-MS. We generalize these results by defining a large class of SOCP (and equivalent QP) relaxations which is dominated by the LP-S relaxation. Based on these results we propose some novel SOCP relaxations which strictly dominate the previous approaches."
            },
            "slug": "An-Analysis-of-Convex-Relaxations-for-MAP-Mudigonda-Kolmogorov",
            "title": {
                "fragments": [],
                "text": "An Analysis of Convex Relaxations for MAP Estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An analysis of three approximate algorithms based on convex relaxations and it is proved that despite the flexibility in the form of the constraints/objective function offered by QP and SOCP, the LP-S relaxation strictly dominates and provides a better approximation than the QP-RL and SOCp-MS."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756798"
                        ],
                        "name": "I. Csisz\u00e1r",
                        "slug": "I.-Csisz\u00e1r",
                        "structuredName": {
                            "firstName": "Imre",
                            "lastName": "Csisz\u00e1r",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Csisz\u00e1r"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 131
                            }
                        ],
                        "text": "As a consequence, the mean eld procedure is an operation that di ers in fundamental ways from the I-projection with KL divergences [3, 26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18053591,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "72b2aeeb76dbff312321ccbcc58e85009e0b57ae",
            "isKey": false,
            "numCitedBy": 1453,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide range of content in a trusted digital archive. We use information technology and tools to increase productivity and facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org.. Institute of Mathematical Statistics is collaborating with JSTOR to digitize, preserve and extend access to The Annals of Probability. Some geometric properties of PD's are established, Kullback's I-divergence playing the role of squared Euclidean distance. The minimum discrimination information problem is viewed as that of projecting a PD onto a convex set of PD's and useful existence theorems for and characterizations of the minimizing PD are arrived at. A natural generalization of known iterative algorithms converging to the minimizing PD in special situations is given; even for those special cases, our convergence proof is more generally valid than those previously published. As corollaries of independent interest, generalizations of known results on the existence of PD's or nonnegative matrices of a certain form are obtained. The Lagrange multiplier technique is not used."
            },
            "slug": "$I$-Divergence-Geometry-of-Probability-and-Problems-Csisz\u00e1r",
            "title": {
                "fragments": [],
                "text": "$I$-Divergence Geometry of Probability Distributions and Minimization Problems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52626911"
                        ],
                        "name": "T. Minka",
                        "slug": "T.-Minka",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Minka",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Minka"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Finally, we describe expectation-propagation algorithms [180, 172] and related moment-matching methods [181, 61, 112]; these are also varia-"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "3, the family of expectation-propagation algorithms [169, 172], as well as related moment-matching algorithms [181, 61, 112], can be understood in terms of term-by-term entropy approximations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Examples of such algorithms include the family of expectationpropagation algorithms due to Minka [172], the related class of assumed density filtering methods [149, 161, 37], expectation-consistent inference [181], structured summary-propagation algorithms [61, 112], and"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "As with assumed density filtering, expectationpropagation [172, 171] and various related algorithms [181, 61, 112] are typically described in terms of moment-matching operations."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We refer the reader to Minka [169, 172] and Seeger [208] for further details of the Gaussian-mixture EP algorithm and some of its properties."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Minka [172] observed that the basic ideas underlying ADF can be generalized beyond Markov chains to arbitrary graphical models, an insight that forms the basis for the family of expectation-propagation (EP) algorithms."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8632802,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bf527ca11d7d81a15ff5b5603374a4e9d53b55b6",
            "isKey": true,
            "numCitedBy": 986,
            "numCiting": 126,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the major obstacles to using Bayesian methods for pattern recognition has been its computational expense. This thesis presents an approximation technique that can perform Bayesian inference faster and more accurately than previously possible. This method, \u201cExpectation Propagation,\u201d unifies and generalizes two previous techniques: assumed-density filtering, an extension of the Kalman filter, and loopy belief propagation, an extension of belief propagation in Bayesian networks. The unification shows how both of these algorithms can be viewed as approximating the true posterior distribution with simpler distribution, which is close in the sense of KL-divergence. Expectation Propagation exploits the best of both algorithms: the generality of assumed-density filtering and the accuracy of loopy belief propagation. \nLoopy belief propagation, because it propagates exact belief states, is useful for limited types of belief networks, such as purely discrete networks. Expectation Propagation approximates the belief states with expectations, such as means and variances, giving it much wider scope. Expectation Propagation also extends belief propagation in the opposite direction\u2014propagating richer belief states which incorporate correlations between variables. \nThis framework is demonstrated in a variety of statistical models using synthetic and real-world data. On Gaussian mixture problems, Expectation Propagation is found, for the same amount of computation, to be convincingly better than rival approximation techniques: Monte Carlo, Laplace's method, and variational Bayes. For pattern recognition, Expectation Propagation provides an algorithm for training Bayes Point Machine classifiers that is faster and more accurate than any previously known. The resulting classifiers outperform Support Vector Machines on several standard datasets, in addition to having a comparable training time. Expectation Propagation can also be used to choose an appropriate feature set for classification, via Bayesian model selection. (Copies available exclusively from MIT Libraries, Rm. 14-0551, Cambridge, MA 02139-4307. Ph. 617-253-5668; Fax 617-253-1690.)"
            },
            "slug": "A-family-of-algorithms-for-approximate-Bayesian-Minka",
            "title": {
                "fragments": [],
                "text": "A family of algorithms for approximate Bayesian inference"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "This thesis presents an approximation technique that can perform Bayesian inference faster and more accurately than previously possible, and is found to be convincingly better than rival approximation techniques: Monte Carlo, Laplace's method, and variational Bayes."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3072213"
                        ],
                        "name": "J. Besag",
                        "slug": "J.-Besag",
                        "structuredName": {
                            "firstName": "Julian",
                            "lastName": "Besag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Besag"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": ", 258, 104, 55, 86], as well as in spatial statistics more generally [23, 24, 197, 25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 116757950,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "1406b6d771c270aff4dcb1c96e4f5c62c02c00a5",
            "isKey": false,
            "numCitedBy": 1657,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "In rather formal terms, the situation with which this paper is concerned may be described as follows. We are given a fixed system of n sites, labelled by the first n positive integers, and an associated vector x of observations, Xi, . . ., Xn, which, in turn, is presumed to be a realization of a vector X of (dependent) random variables, Xi, . . ., X.. In practice, the sites may represent points or regions in space and the random variables may be either continuous or discrete. The main statistical objectives are the following: firstly, to provide a means of using the available concomitant information, particularly the configuration of the sites, to attach a plausible probability distribution to the random vector X; secondly, to estimate any unknown parameters in the distribution from the realization x; thirdly, where possible, to quantify the extent of disagreement between hypothesis and observation."
            },
            "slug": "Statistical-Analysis-of-Non-Lattice-Data-Besag",
            "title": {
                "fragments": [],
                "text": "Statistical Analysis of Non-Lattice Data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144362425"
                        ],
                        "name": "S. Amari",
                        "slug": "S.-Amari",
                        "structuredName": {
                            "firstName": "Shun\u2010ichi",
                            "lastName": "Amari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Amari"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 194
                            }
                        ],
                        "text": "In our view, the most promising avenue towards variational methodology tuned to statistics is to build on existing links between variational analysis and the exponential family of distributions [3, 5, 17, 35]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 131
                            }
                        ],
                        "text": "As a consequence, the mean eld procedure is an operation that di ers in fundamental ways from the I-projection with KL divergences [3, 26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 121983766,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "af689de0eb4d26ed4ad400dce2c6972e8ec4b133",
            "isKey": false,
            "numCitedBy": 352,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "The differential-geometrical framework is given for analyzing statistical problems related to multi-parameter families of distributions. The dualistic structures of the exponential families and curved exponential families are elucidated from the geometrical viewpoint. The duality connected by the Legendre transformation is thus extended to include two kinds of affine connections and two kinds of curvatures. The second-order information loss is calculated for Fisher-efficient estimators, and is decomposed into the sum of two non-negative terms. One is related to the exponential curvature of the statistical model and the other is related to the mixture curvature of the estimator. Only the latter term depends on the estimator, and vanishes for the maximum-likelihood estimator. A set of statistics which recover the second-order information loss are given. The second-order efficiency also is obtained. The differential geometry of the function space of distributions is discussed."
            },
            "slug": "Differential-Geometry-of-Curved-Exponential-and-Amari",
            "title": {
                "fragments": [],
                "text": "Differential Geometry of Curved Exponential Families-Curvatures and Information Loss"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46491690"
                        ],
                        "name": "M. Bayati",
                        "slug": "M.-Bayati",
                        "structuredName": {
                            "firstName": "Mohsen",
                            "lastName": "Bayati",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bayati"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081804"
                        ],
                        "name": "D. Shah",
                        "slug": "D.-Shah",
                        "structuredName": {
                            "firstName": "Devavrat",
                            "lastName": "Shah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Shah"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110200935"
                        ],
                        "name": "Mayank Sharma",
                        "slug": "Mayank-Sharma",
                        "structuredName": {
                            "firstName": "Mayank",
                            "lastName": "Sharma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mayank Sharma"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 170
                            }
                        ],
                        "text": "A line of recent research has established close links between the LP relaxation and the ordinary max-product algorithm, including the case of bipartite weighted matching [13], bipartite weighted b-matching [113], weighted matching on general graphs [201], and weighted b-matching on general graphs [12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 319,
                                "start": 305
                            }
                        ],
                        "text": "17) have studied in past and ongoing work by various authors, including the special cases of {0, 1}-quadratic programs [102], metric labeling with Potts models [132, 45], error-control coding problems [73, 75, 234, 223, 47, 59], independent set problems [177, 202], and various types of matching problems [13, 113, 201]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7920427,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "a24f72d29b8021a82a0feb3b918a3817527a17ad",
            "isKey": false,
            "numCitedBy": 133,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "The max-product \"belief propagation\" algorithm is an iterative, local, message passing algorithm for finding the maximum a posteriori (MAP) assignment of a discrete probability distribution specified by a graphical model. Despite the spectacular success of the algorithm in many application areas such as iterative decoding and computer vision which involve graphs with many cycles, theoretical convergence results are only known for graphs which are tree-like or have a single cycle. In this paper, we consider a weighted complete bipartite graph and define a probability distribution on it whose MAP assignment corresponds to the maximum weight matching (MWM) in that graph. We analyze the fixed points of the max-product algorithm when run on this graph and prove the surprising result that even though the underlying graph has many short cycles, the maxproduct assignment converges to the correct MAP assignment. We also provide a bound on the number of iterations required by the algorithm"
            },
            "slug": "Maximum-weight-matching-via-max-product-belief-Bayati-Shah",
            "title": {
                "fragments": [],
                "text": "Maximum weight matching via max-product belief propagation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A weighted complete bipartite graph is considered and a probability distribution on it whose MAP assignment corresponds to the maximum weight matching (MWM) in that graph is defined and it is proved that even though the underlying graph has many short cycles, the maxproduct assignment converges to the correct MAP assignment."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. International Symposium on Information Theory, 2005. ISIT 2005."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680574"
                        ],
                        "name": "M. Seeger",
                        "slug": "M.-Seeger",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Seeger",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Seeger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2083878667"
                        ],
                        "name": "F. Steinke",
                        "slug": "F.-Steinke",
                        "structuredName": {
                            "firstName": "Florian",
                            "lastName": "Steinke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Steinke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34628173"
                        ],
                        "name": "K. Tsuda",
                        "slug": "K.-Tsuda",
                        "structuredName": {
                            "firstName": "Koji",
                            "lastName": "Tsuda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Tsuda"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "[209] reported that reweighted forms of EP appear to have better empirical convergence properties than standard EP."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6148021,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bc43a1d2e609a9878117fb0ea75140271a5d4677",
            "isKey": false,
            "numCitedBy": 314,
            "numCiting": 94,
            "paperAbstract": {
                "fragments": [],
                "text": "The sparse linear model has seen many successful applications in Statistics, Machine Learning, and Computational Biology, such as identification of gene regulatory networks from micro-array expression data. Prior work has either approximated Bayesian inference by expensive Markov chain Monte Carlo, or replaced it by point estimation. We show how to obtain a good approximation to Bayesian analysis efficiently, using the Expectation Propagation method. We also address the problems of optimal design and hyperparameter estimation. We demonstrate our framework on a gene network identification task."
            },
            "slug": "Bayesian-Inference-and-Optimal-Design-in-the-Sparse-Seeger-Steinke",
            "title": {
                "fragments": [],
                "text": "Bayesian Inference and Optimal Design in the Sparse Linear Model"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work shows how to obtain a good approximation to Bayesian analysis efficiently, using the Expectation Propagation method, and addresses the problems of optimal design and hyperparameter estimation."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721860"
                        ],
                        "name": "M. Wainwright",
                        "slug": "M.-Wainwright",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Wainwright",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wainwright"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 23
                            }
                        ],
                        "text": "11) is strongly convex [236] for any pairwise Markov random field, so that as a corollary, the treereweighted sum-product algorithm is guaranteed to be globally Lipschitz stable."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 39
                            }
                        ],
                        "text": "Under this assumption, it can be shown [236, 109] that the output \u03c4(\u03b8) = \u2207B(\u03b8) of the variational method is Lipschitz stable, in the sense of definition (7."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 90
                            }
                        ],
                        "text": "Indeed, given multiple fixed points, its behavior can be unstable and erratic; the papers [238, 236] provide some cautionary instances of poor behavior with ordinary sum-product."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 113
                            }
                        ],
                        "text": "The use of such approximate methods and their impact on parameter estimation is still an active area of research [220, 226, 238, 236, 248]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16451367,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f3d831a9447ae7a8f9aa5c5beef8a28dbfacf352",
            "isKey": false,
            "numCitedBy": 129,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Consider the problem of joint parameter estimation and prediction in a Markov random field: that is, the model parameters are estimated on the basis of an initial set of data, and then the fitted model is used to perform prediction (e.g., smoothing, denoising, interpolation) on a new noisy observation. Working under the restriction of limited computation, we analyze a joint method in which the same convex variational relaxation is used to construct an M-estimator for fitting parameters, and to perform approximate marginalization for the prediction step. The key result of this paper is that in the computation-limited setting, using an inconsistent parameter estimator (i.e., an estimator that returns the \"wrong\" model even in the infinite data limit) is provably beneficial, since the resulting errors can partially compensate for errors made by using an approximate prediction technique. En route to this result, we analyze the asymptotic properties of M-estimators based on convex variational relaxations, and establish a Lipschitz stability property that holds for a broad class of convex variational methods. This stability result provides additional incentive, apart from the obvious benefit of unique global optima, for using message-passing methods based on convex variational relaxations. We show that joint estimation/prediction based on the reweighted sum-product algorithm substantially outperforms a commonly used heuristic based on ordinary sum-product."
            },
            "slug": "Estimating-the-\"Wrong\"-Graphical-Model:-Benefits-in-Wainwright",
            "title": {
                "fragments": [],
                "text": "Estimating the \"Wrong\" Graphical Model: Benefits in the Computation-Limited Setting"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The key result of this paper is that in the computation-limited setting, using an inconsistent parameter estimator is provably beneficial, since the resulting errors can partially compensate for errors made by using an approximate prediction technique."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678311"
                        ],
                        "name": "M. Welling",
                        "slug": "M.-Welling",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Welling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Welling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725303"
                        ],
                        "name": "Y. Teh",
                        "slug": "Y.-Teh",
                        "structuredName": {
                            "firstName": "Yee",
                            "lastName": "Teh",
                            "middleNames": [
                                "Whye"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Teh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3175219,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "973cd47a48c79209aac17b24594636361941a051",
            "isKey": false,
            "numCitedBy": 111,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel inference algorithm for arbitrary, binary, undirected graphs. Unlike loopy belief propagation, which iterates fixed point equations, we directly descend on the Bethe free energy. The algorithm consists of two phases, first we update the pairwise probabilities, given the marginal probabilities at each unit, using an analytic expression. Next, we update the marginal probabilities, by following the negative gradient of the Bethe free energy. Both steps are guaranteed to decrease the Bethe free energy, and since it is lower bounded, the algorithm is guaranteed to converge to a local minimum. We also show that the Bethe free energy is equal to the TAP free energy up to second order in the weights. In experiments we confirm that when belief propagation converges it usually finds identical solutions as our belief optimization method. The stable nature of belief optimization makes it ideally suited for learning graphical models from data."
            },
            "slug": "Belief-Optimization-for-Binary-Networks:-A-Stable-Welling-Teh",
            "title": {
                "fragments": [],
                "text": "Belief Optimization for Binary Networks: A Stable Alternative to Loopy Belief Propagation"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A novel inference algorithm for arbitrary, binary, undirected graphs that directly descend on the Bethe free energy, which is ideally suited for learning graphical models from data."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52626911"
                        ],
                        "name": "T. Minka",
                        "slug": "T.-Minka",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Minka",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Minka"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 52
                            }
                        ],
                        "text": "3, the family of expectation-propagation algorithms [169, 172], as well as related moment-matching algorithms [181, 61, 112], can be understood in terms of term-by-term entropy approximations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 29
                            }
                        ],
                        "text": "We refer the reader to Minka [169, 172] and Seeger [208] for further details of the Gaussian-mixture EP algorithm and some of its properties."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9011563,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "15c10ae31b039fe50d5cb51f7dbac6cbc3e4102c",
            "isKey": false,
            "numCitedBy": 1657,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new deterministic approximation technique in Bayesian networks. This method, \"Expectation Propagation,\" unifies two previous techniques: assumed-density filtering, an extension of the Kalman filter, and loopy belief propagation, an extension of belief propagation in Bayesian networks. Loopy belief propagation, because it propagates exact belief states, is useful for a limited class of belief networks, such as those which are purely discrete. Expectation Propagation approximates the belief states by only retaining expectations, such as mean and varitmce, and iterates until these expectations are consistent throughout the network. This makes it applicable to hybrid networks with discrete and continuous nodes. Experiments with Gaussian mixture models show Expectation Propagation to be donvincingly better than methods with similar computational cost: Laplace's method, variational Bayes, and Monte Carlo. Expectation Propagation also provides an efficient algorithm for training Bayes point machine classifiers."
            },
            "slug": "Expectation-Propagation-for-approximate-Bayesian-Minka",
            "title": {
                "fragments": [],
                "text": "Expectation Propagation for approximate Bayesian inference"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Expectation Propagation approximates the belief states by only retaining expectations, such as mean and varitmce, and iterates until these expectations are consistent throughout the network, which makes it applicable to hybrid networks with discrete and continuous nodes."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3717791"
                        ],
                        "name": "M. P. Kumar",
                        "slug": "M.-P.-Kumar",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Kumar",
                            "middleNames": [
                                "Pawan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. P. Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143635539"
                        ],
                        "name": "P. Torr",
                        "slug": "P.-Torr",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Torr",
                            "middleNames": [
                                "H.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Torr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "[143] study the use of SOCPs for mode-finding in pairwise Markov random fields, in particular using matrices \u039b that are locally defined on the edges of the graph, as well as additional linear inequalities, such as the cycle inequalities in the binary case (see Example 42)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 191
                            }
                        ],
                        "text": "The resulting second-order cone programming (SOCP) relaxations of the mode-finding problem (as well as more general non-convex optimization problems) have been studied by various researchers [143, 131]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14151624,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9d2d7ece8d744662c0183222a5b9ac6a4f80184f",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a generic method for solvingMarkov random fields (MRF) by formulating the problem of MAP estimation as 0-1 quadratic programming (QP). Though in general solving MRFs is NP-hard, we propose a second order cone programming relaxation scheme which solves a closely related (convex) approximation. In terms of computational efficiency, our method significantly outperforms the semidefinite relaxations previously used whilst providing equally (or even more) accurate results. Unlike popular inference schemes such as Belief Propagation and Graph Cuts, convergence is guaranteed within a small number of iterations. Furthermore, we also present a method for greatly reducing the runtime and increasing the accuracy of our approach for a large and useful class of MRFs. We compare our approach with the state-of-the-art methods for subgraph matching and object recognition and demonstrate significant improvements."
            },
            "slug": "Solving-Markov-Random-Fields-using-Second-Order-Kumar-Torr",
            "title": {
                "fragments": [],
                "text": "Solving Markov Random Fields using Second Order Cone Programming Relaxations"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "A generic method for solving Markov random fields (MRF) by formulating the problem of MAP estimation as 0-1 quadratic programming (QP) and proposing a second order cone programming relaxation scheme which solves a closely related (convex) approximation."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712569"
                        ],
                        "name": "A. Braunstein",
                        "slug": "A.-Braunstein",
                        "structuredName": {
                            "firstName": "Alfredo",
                            "lastName": "Braunstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Braunstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2338183"
                        ],
                        "name": "M. M\u00e9zard",
                        "slug": "M.-M\u00e9zard",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "M\u00e9zard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. M\u00e9zard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719010"
                        ],
                        "name": "R. Zecchina",
                        "slug": "R.-Zecchina",
                        "structuredName": {
                            "firstName": "Riccardo",
                            "lastName": "Zecchina",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zecchina"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 176
                            }
                        ],
                        "text": "Survey propagation turns out to be an instance of the sum-product or belief propagation algorithm, but as applied to an alternative graphical model for satisfiability problems [38, 159]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6601396,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c800d18a9fb1b21c492a643743e4fef32d19b0a6",
            "isKey": false,
            "numCitedBy": 436,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the satisfiability of randomly generated formulas formed by M clauses of exactly K literals over N Boolean variables. For a given value of N the problem is known to be most difficult when \u03b1 = M/N is close to the experimental threshold \u03b1c separating the region where almost all formulas are SAT from the region where all formulas are UNSAT. Recent results from a statistical physics analysis suggest that the difficulty is related to the existence of a clustering phenomenon of the solutions when \u03b1 is close to (but smaller than) \u03b1c. We introduce a new type of message passing algorithm which allows to find efficiently a satisfying assignment of the variables in this difficult region. This algorithm is iterative and composed of two main parts. The first is a message\u2010passing procedure which generalizes the usual methods like Sum\u2010Product or Belief Propagation: It passes messages that may be thought of as surveys over clusters of the ordinary messages. The second part uses the detailed probabilistic information obtained from the surveys in order to fix variables and simplify the problem. Eventually, the simplified problem that remains is solved by a conventional heuristic. \u00a9 2005 Wiley Periodicals, Inc. Random Struct. Alg., 2005"
            },
            "slug": "Survey-propagation:-An-algorithm-for-satisfiability-Braunstein-M\u00e9zard",
            "title": {
                "fragments": [],
                "text": "Survey propagation: An algorithm for satisfiability"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A new type of message passing algorithm is introduced which allows to find efficiently a satisfying assignment of the variables in this difficult region of randomly generated formulas."
            },
            "venue": {
                "fragments": [],
                "text": "Random Struct. Algorithms"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144652072"
                        ],
                        "name": "Miroslav Dud\u00edk",
                        "slug": "Miroslav-Dud\u00edk",
                        "structuredName": {
                            "firstName": "Miroslav",
                            "lastName": "Dud\u00edk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Miroslav Dud\u00edk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30352875"
                        ],
                        "name": "Steven J. Phillips",
                        "slug": "Steven-J.-Phillips",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Phillips",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steven J. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "As pointed out by various authors [60, 68], a similar dual interpretation also exists for regularized exact maximum likelihood."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8004388,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "24c7f652acd8aeb1e67ce71adbb06f3529a0dfb4",
            "isKey": false,
            "numCitedBy": 212,
            "numCiting": 71,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a unified and complete account of maximum entropy density estimation subject to constraints represented by convex potential functions or, alternatively, by convex regularization. We provide fully general performance guarantees and an algorithm with a complete convergence proof. As special cases, we easily derive performance guarantees for many known regularization types, including l1, l2, l22, and l2 + l22 style regularization. We propose an algorithm solving a large and general subclass of generalized maximum entropy problems, including all discussed in the paper, and prove its convergence. Our approach generalizes and unifies techniques based on information geometry and Bregman divergences as well as those based more directly on compactness. Our work is motivated by a novel application of maximum entropy to species distribution modeling, an important problem in conservation biology and ecology. In a set of experiments on real-world data, we demonstrate the utility of maximum entropy in this setting. We explore effects of different feature types, sample sizes, and regularization levels on the performance of maxent, and discuss interpretability of the resulting models."
            },
            "slug": "Maximum-Entropy-Density-Estimation-with-Generalized-Dud\u00edk-Phillips",
            "title": {
                "fragments": [],
                "text": "Maximum Entropy Density Estimation with Generalized Regularization and an Application to Species Distribution Modeling"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work proposes an algorithm solving a large and general subclass of generalized maximum entropy problems, including all discussed in the paper, and proves its convergence."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790356"
                        ],
                        "name": "T. Heskes",
                        "slug": "T.-Heskes",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Heskes",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Heskes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "However, with the exception of trees and other special cases [184, 163, 107], the Bethe variational problem is usually a nonconvex problem, in that HBethe fails to be concave."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "However, it is known [244, 107] that for any discrete Markov random field in exponential family form with at most a single cycle, the sum-product has a unique fixed point, and always converges to it."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Various other researchers [107, 163, 184, 185] also discuss the choice edge/clique weights in Bethe/Kikuchi approximations, and its consequences for convexity."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Another possibility would be to adapt other double-loop algorithms [265, 249, 108, 107], originally developed for the ordinary Bethe/Kikuchi problems, to solve these convex minimization problems; see Hazan and Shashua [105] for some recent work along these lines."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In contrast, with the exception of certain special cases [107, 184, 185, 163], Kikuchi and other hypergraph-based entropy approximations are typically not convex."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16348864,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d00b06ce1bf91bb5bf27b8287f015623c997de8a",
            "isKey": true,
            "numCitedBy": 102,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Loopy and generalized belief propagation are popular algorithms for approximate inference in Markov random fields and Bayesian networks. Fixed points of these algorithms have been shown to correspond to extrema of the Bethe and Kikuchi free energy, both of which are approximations of the exact Helmholtz free energy. However, belief propagation does not always converge, which motivates approaches that explicitly minimize the Kikuchi/Bethe free energy, such as CCCP and UPS. \n \nHere we describe a class of algorithms that solves this typically non-convex constrained minimization problem through a sequence of convex constrained minimizations of upper bounds on the Kikuchi free energy. Intuitively one would expect tighter bounds to lead to faster algorithms, which is indeed convincingly demonstrated in our simulations. Several ideas are applied to obtain tight convex bounds that yield dramatic speed-ups over CCCP."
            },
            "slug": "Convexity-Arguments-for-Efficient-Minimization-of-Heskes",
            "title": {
                "fragments": [],
                "text": "Convexity Arguments for Efficient Minimization of the Bethe and Kikuchi Free Energies"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "A class of algorithms is described that solves this typically non-convex constrained constrained minimization problem through a sequence of convex constrained minimizations of upper bounds on the Kikuchi free energy."
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif. Intell. Res."
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783429"
                        ],
                        "name": "W. Wiegerinck",
                        "slug": "W.-Wiegerinck",
                        "structuredName": {
                            "firstName": "Wim",
                            "lastName": "Wiegerinck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Wiegerinck"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 60
                            }
                        ],
                        "text": "Depending on the particular context, other types of updates [117, 56] or techniques from nonlinear programming may be more suitable for solving the mean eld problem (53)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8291055,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f84da30b31b2b3e76956413abc0a2f4ce856a4a1",
            "isKey": false,
            "numCitedBy": 99,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, variational approximations such as the mean field approximation have received much interest. We extend the standard mean field method by using an approximating distribution that factorises into cluster potentials. This includes undirected graphs, directed acyclic graphs and junction trees. We derive generalized mean field equations to optimize the cluster potentials. We show that the method bridges the gap between the standard mean field approximation and the exact junction tree algorithm. In addition, we address the problem of how to choose the graphical structure of the approximating distribution. From the generalised mean field equations we derive rules to simplify the structure of the approximating distribution in advance without affecting the quality of the approximation. We also show how the method fits into some other variational approximations that are currently popular."
            },
            "slug": "Variational-Approximations-between-Mean-Field-and-Wiegerinck",
            "title": {
                "fragments": [],
                "text": "Variational Approximations between Mean Field Theory and the Junction Tree Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "This work extends the standard mean field method by using an approximating distribution that factorises into cluster potentials, which includes undirected graphs, directed acyclic graphs and junction trees, and derives generalized mean field equations to optimize the clusters potentials."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145969795"
                        ],
                        "name": "Pradeep Ravikumar",
                        "slug": "Pradeep-Ravikumar",
                        "structuredName": {
                            "firstName": "Pradeep",
                            "lastName": "Ravikumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pradeep Ravikumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739581"
                        ],
                        "name": "J. Lafferty",
                        "slug": "J.-Lafferty",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Lafferty",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lafferty"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1887807,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b4312e1a819d39601ac32b1dbe8e79b0c8cf5f5d",
            "isKey": false,
            "numCitedBy": 128,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Quadratic program relaxations are proposed as an alternative to linear program relaxations and tree reweighted belief propagation for the metric labeling or MAP estimation problem. An additional convex relaxation of the quadratic approximation is shown to have additive approximation guarantees that apply even when the graph weights have mixed sign or do not come from a metric. The approximations are extended in a manner that allows tight variational relaxations of the MAP problem, although they generally involve non-convex optimization. Experiments carried out on synthetic data show that the quadratic approximations can be more accurate and computationally efficient than the linear programming and propagation based alternatives."
            },
            "slug": "Quadratic-programming-relaxations-for-metric-and-Ravikumar-Lafferty",
            "title": {
                "fragments": [],
                "text": "Quadratic programming relaxations for metric labeling and Markov random field MAP estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Experiments carried out on synthetic data show that the quadratic approximations can be more accurate and computationally efficient than the linear programming and propagation based alternatives."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684961"
                        ],
                        "name": "S. Fienberg",
                        "slug": "S.-Fienberg",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Fienberg",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Fienberg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Contingency tables are a central tool in categorical data analysis [148, 77, 1], dating back to the seminal work of Pearson, Yule and Fisher."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 123558783,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "d7d40d9e27f991fb412fad3527856d14977fa18d",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Martin, R. D., and Yohai, V. J. (1986), \u201cInfluence Functionals for Time Series,\u201d The Annals of Statistics, 14, 781-818. McCulloch, R. E., and Tsay, R. S. (1993), \u201cBayesian Inference and Prediction for Mean and Variance Shifts in Autoregressive Time Series,\u201d Journal of the American Statistical Association, 88, 968-978. Meyn, S., and Tweedie, R. L. (1993). Markov Chains and Stochastic Stability, New York: Springer-Verlag. Montgomery, A. L., Zarnowitz, V., Tsay, R. S., and Tiao, G. C. (19981, \u201cForecasting the U.S. Unemployment Rate,\u201d Journal of the American Statistical Association, 93, 478493. Petruccelli, J., and Woolford, S. W. (1984), \u201cA Threshold AR(1) Model,\u201d Journal of Applied Probability, 21, 270-286. Phillips, P. C. B. (1987), \u201cTime Series Regression With a Unit Root,\u201d Econometrica, 55, 277-301. Priestley, M. B. (1981), Spectral Analysis and Time Series, Vols. I and 11, London: Academic Press. Quenouille, M. H. (1957), The Analysis of Multiple Time Series, London: Griffin. Resnick, S. I. (1997), \u201cHeavy Tail Modeling and Teletraffic Data,\u201d (with discussion), The Annals of Statistics, 25, 1805-1869. Samorodnitsky, G., and Taqqu (19941, Stable Non-Gaussian Random Processes, New York: Chapman and Hall. Tanner, M.. and Wong, W. H. (19871, \u201cThe Calculation of Posterior Dis65-79. tributions,\u201d (with discussion), Journal of the American Statistical Association, 82, 528-550. Tiao, G. C. , and Tsay, R. S. (1989), \u201cModel Specification in Multivariate Time Series,\u201d (with discussion), Journal of the Royal Statistical Society, Ser. B, 51, 157-213. Tiao, G. C., Tsay, R. S., and Wang, T. (1993), \u201cUsefulness of Linear Transformation in Multivariate Time Series Analysis,\u201d Empirical Economics,"
            },
            "slug": "Contingency-Tables-and-Log-Linear-Models:-Basic-and-Fienberg",
            "title": {
                "fragments": [],
                "text": "Contingency Tables and Log-Linear Models: Basic Results and New Developments"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691022"
                        ],
                        "name": "M. Opper",
                        "slug": "M.-Opper",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Opper",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Opper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724252"
                        ],
                        "name": "O. Winther",
                        "slug": "O.-Winther",
                        "structuredName": {
                            "firstName": "Ole",
                            "lastName": "Winther",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Winther"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "the adaptive TAP method of Opper and Winther [179, 180]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10063289,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d4323cf65589bc509aea260ccaa4ef32a94b2f7e",
            "isKey": false,
            "numCitedBy": 269,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "We derive a mean-field algorithm for binary classification with gaussian processes that is based on the TAP approach originally proposed in statistical physics of disordered systems. The theory also yields an approximate leave-one-out estimator for the generalization error, which is computed with no extra computational cost. We show that from the TAP approach, it is possible to derive both a simpler naive mean-field theory and support vector machines (SVMs) as limiting cases. For both mean-field algorithms and support vector machines, simulation results for three small benchmark data sets are presented. They show that one may get state-of-the-art performance by using the leave-one-out estimator for model selection and the built-in leave-one-out estimators are extremely precise when compared to the exact leave-one-out estimate. The second result is taken as strong support for the internal consistency of the mean-field approach."
            },
            "slug": "Gaussian-Processes-for-Classification:-Mean-Field-Opper-Winther",
            "title": {
                "fragments": [],
                "text": "Gaussian Processes for Classification: Mean-Field Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "A mean-field algorithm for binary classification with gaussian processes that is based on the TAP approach originally proposed in statistical physics of disordered systems is derived and an approximate leave-one-out estimator for the generalization error is computed."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701607"
                        ],
                        "name": "A. Willsky",
                        "slug": "A.-Willsky",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Willsky",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Willsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "For Gaussian max-product applied to a tree-structured problem, the updates are guaranteed to converge, and compute both the correct means \u03bcs = E[Xs] and variances \u03c3 2 s = E[X 2 s ] \u2212 \u03bc 2 s at each node [257]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "8(b), can be used to approximate lattice models [257]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "(b) A multiscale quad tree approximation to a 2D lattice model [257]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "6) can be efficiently implemented with one recursion for the mean term (number a), and a second recursion for the variance component (see the papers [245, 257] for further details)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "on trees [257] can be viewed as a fast algorithm for solving the matrixinverse-vector system of normal equations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 122692461,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a5e6244b225845766921da4bf3147e7dc5e2cc5",
            "isKey": true,
            "numCitedBy": 329,
            "numCiting": 431,
            "paperAbstract": {
                "fragments": [],
                "text": "Reviews a significant component of the rich field of statistical multiresolution (MR) modeling and processing. These MR methods have found application and permeated the literature of a widely scattered set of disciplines, and one of our principal objectives is to present a single, coherent picture of this framework. A second goal is to describe how this topic fits into the even larger field of MR methods and concepts-in particular, making ties to topics such as wavelets and multigrid methods. A third goal is to provide several alternate viewpoints for this body of work, as the methods and concepts we describe intersect with a number of other fields. The principle focus of our presentation is the class of MR Markov processes defined on pyramidally organized trees. The attractiveness of these models stems from both the very efficient algorithms they admit and their expressive power and broad applicability. We show how a variety of methods and models relate to this framework including models for self-similar and 1/f processes. We also illustrate how these methods have been used in practice."
            },
            "slug": "Multiresolution-Markov-models-for-signal-and-image-Willsky",
            "title": {
                "fragments": [],
                "text": "Multiresolution Markov models for signal and image processing"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This presentation reviews a significant component of the rich field of statistical multiresolution (MR) modeling and processing, and shows how a variety of methods and models relate to this framework including models for self-similar and 1/f processes."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145500336"
                        ],
                        "name": "Alex Kulesza",
                        "slug": "Alex-Kulesza",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Kulesza",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Kulesza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Kulesza and Pereira [141] provide an detailed analysis of the max-product message-passing updates for this example, analytically deriving the updates and explicitly demonstrating convergence to incorrect configurations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10876177,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "325ea1f2022ee3886a5810df76dcfbe4010ad439",
            "isKey": false,
            "numCitedBy": 151,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "In many structured prediction problems, the highest-scoring labeling is hard to compute exactly, leading to the use of approximate inference methods. However, when inference is used in a learning algorithm, a good approximation of the score may not be sufficient. We show in particular that learning can fail even with an approximate inference method with rigorous approximation guarantees. There are two reasons for this. First, approximate methods can effectively reduce the expressivity of an underlying model by making it impossible to choose parameters that reliably give good predictions. Second, approximations can respond to parameter changes in such a way that standard learning algorithms are misled. In contrast, we give two positive results in the form of learning bounds for the use of LP-relaxed inference in structured perceptron and empirical risk minimization settings. We argue that without understanding combinations of inference and learning, such as these, that are appropriately compatible, learning performance under approximate inference cannot be guaranteed."
            },
            "slug": "Structured-Learning-with-Approximate-Inference-Kulesza-Pereira",
            "title": {
                "fragments": [],
                "text": "Structured Learning with Approximate Inference"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "It is shown in particular that learning can fail even with an approximate inference method with rigorous approximation guarantees, and argued that without understanding combinations of inference and learning, such as these that are appropriately compatible, learning performance under approximate inference cannot be guaranteed."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786843"
                        ],
                        "name": "A. Globerson",
                        "slug": "A.-Globerson",
                        "structuredName": {
                            "firstName": "Amir",
                            "lastName": "Globerson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Globerson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35132120"
                        ],
                        "name": "T. Jaakkola",
                        "slug": "T.-Jaakkola",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Jaakkola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jaakkola"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "As an alternative, Globerson and Jaakkola [93] proposed a related messagepassing algorithm based on oriented trees that is guaranteed to converge, but appears to do so more slowly than damped TRW-message passing."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 601098,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e94084fd504fe07058536a44d8e561abb0921a75",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Inference problems in graphical models are often approximated by casting them as constrained optimization problems. Message passing algorithms, such as belief propagation, have previously been suggested as methods for solving these optimization problems. However, there are few convergence guarantees for such algorithms, and the algorithms are therefore not guaranteed to solve the corresponding optimization problem. Here we present an oriented tree decomposition algorithm that is guaranteed to converge to the global optimum of the Tree-Reweighted (TRW) variational problem. Our algorithm performs local updates in the convex dual of the TRW problem - an unconstrained generalized geometric program. Primal updates, also local, correspond to oriented reparametrization operations that leave the distribution intact."
            },
            "slug": "Convergent-Propagation-Algorithms-via-Oriented-Globerson-Jaakkola",
            "title": {
                "fragments": [],
                "text": "Convergent Propagation Algorithms via Oriented Trees"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work presents an oriented tree decomposition algorithm that is guaranteed to converge to the global optimum of the Tree-Reweighted (TRW) variational problem."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678311"
                        ],
                        "name": "M. Welling",
                        "slug": "M.-Welling",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Welling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Welling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52626911"
                        ],
                        "name": "T. Minka",
                        "slug": "T.-Minka",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Minka",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Minka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725303"
                        ],
                        "name": "Y. Teh",
                        "slug": "Y.-Teh",
                        "structuredName": {
                            "firstName": "Yee",
                            "lastName": "Teh",
                            "middleNames": [
                                "Whye"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Teh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "See the papers [171, 247, 235] for further details on tree EP."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1613604,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9358dbf89959aa7e79eed8ecb5ba436a33273b87",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "GBP and EP are two successful algorithms for approximate probabilistic inference, which are based on different approximation strategies. An open problem in both algorithms has been how to choose an appropriate approximation structure. We introduce \"structured region graphs,\" a formalism which marries these two strategies, reveals a deep connection between them, and suggests how to choose good approximation structures. In this formalism, each region has an internal structure which defines an exponential family, whose sufficient statistics must be matched by the parent region. Reduction operators on these structures allow conversion between EP and GBP free energies. Thus it is revealed that all EP approximations on discrete variables are special cases of GBP, and conversely that some well-known GBP approximations, such as overlapping squares, are special cases of EP. Furthermore, region graphs derived from EP have a number of good structural properties, including maxent-normality and overall counting number of one. The result is a convenient framework for producing high-quality approximations with a user-adjustable level of complexity."
            },
            "slug": "Structured-Region-Graphs:-Morphing-EP-into-GBP-Welling-Minka",
            "title": {
                "fragments": [],
                "text": "Structured Region Graphs: Morphing EP into GBP"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "\"structured region graphs,\" a formalism which marries these two strategies, reveals a deep connection between them, and suggests how to choose good approximation structures, which is a convenient framework for producing high-quality approximations with a user-adjustable level of complexity."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47966942"
                        ],
                        "name": "G. Grimmett",
                        "slug": "G.-Grimmett",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Grimmett",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Grimmett"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Moreover, by the Hammersley-Clifford theorem [103, 23, 99], the precision matrix P has the same sparsity pattern as the graph adjacency matrix (i."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18530728,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0431cd2fa4a1ffdf833a44c8b996b32220ddddf3",
            "isKey": false,
            "numCitedBy": 211,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Averintsev [1] and Spitzer [2] proved that the class of Markov fields is identical to the class of Gibbs ensembles when the domain is a finite subset of the cubic lattice and each site may be in either of two given states. Hammersley and Clifford [3] proved the same result for the more general case when the domain is the set of sites of an arbitrary finite graph and the number of possible states for each site is finite. In order to show this, they extended the notion of a Gibbs ensemble to embrace more complex interactions than occur on the cubic lattice. Their method was circuitous and showed merely the existence of a potential function for a Markov field with little indication of its form. In [4], Preston gives a more direct approach to the two-state problem and presents an explicit formula for the potential. We show here that the equivalence of Markov fields and Gibbs ensembles follows immediately from a very simple application of the Mobius inversion theorem of [5] which allows us to construct a natural expression for the potential function of a Markov field. We confine our attention to the set of sites of an arbitrary finite graph and allow each site to be in any one of a countable set of states. The two-state solution of Preston emerges as a corollary."
            },
            "slug": "A-THEOREM-ABOUT-RANDOM-FIELDS-Grimmett",
            "title": {
                "fragments": [],
                "text": "A THEOREM ABOUT RANDOM FIELDS"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145810673"
                        ],
                        "name": "V. G\u00f3mez",
                        "slug": "V.-G\u00f3mez",
                        "structuredName": {
                            "firstName": "V.",
                            "lastName": "G\u00f3mez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. G\u00f3mez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696158"
                        ],
                        "name": "J. Mooij",
                        "slug": "J.-Mooij",
                        "structuredName": {
                            "firstName": "Joris",
                            "lastName": "Mooij",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mooij"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792269"
                        ],
                        "name": "H. Kappen",
                        "slug": "H.-Kappen",
                        "structuredName": {
                            "firstName": "Hilbert",
                            "lastName": "Kappen",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kappen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13582282,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c2763c3aa01fe20a18f4ef0a0fa9afd215cdc4f4",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, Chertkov and Chernyak (2006b) derived an exact expression for the partition sum (normalization constant) corresponding to a graphical model, which is an expansion around the belief propagation (BP) solution. By adding correction terms to the BP free energy, one for each \"generalized loop\" in the factor graph, the exact partition sum is obtained. However, the usually enormous number of generalized loops generally prohibits summation over all correction terms. In this article we introduce truncated loop series BP (TLSBP), a particular way of truncating the loop series of Chertkov & Chernyak by considering generalized loops as compositions of simple loops. We analyze the performance of TLSBP in different scenarios, including the Ising model on square grids and regular random graphs, and on PROMEDAS, a large probabilistic medical diagnostic system. We show that TLSBP often improves upon the accuracy of the BP solution, at the expense of increased computation time. We also show that the performance of TLSBP strongly depends on the degree of interaction between the variables. For weak interactions, truncating the series leads to significant improvements, whereas for strong interactions it can be ineffective, even if a high number of terms is considered."
            },
            "slug": "Truncating-the-Loop-Series-Expansion-for-Belief-G\u00f3mez-Mooij",
            "title": {
                "fragments": [],
                "text": "Truncating the Loop Series Expansion for Belief Propagation"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This article introduces truncated loop series BP (TLSBP), a particular way of truncating the loop series of Chertkov & Chernyak by considering generalized loops as compositions of simple loops, and examines the performance of TLSBP in different scenarios, including the Ising model on square grids and regular random graphs, and on PROMEDAS, a large probabilistic medical diagnostic system."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2014414"
                        ],
                        "name": "L. Vandenberghe",
                        "slug": "L.-Vandenberghe",
                        "structuredName": {
                            "firstName": "Lieven",
                            "lastName": "Vandenberghe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Vandenberghe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1843103"
                        ],
                        "name": "Stephen P. Boyd",
                        "slug": "Stephen-P.-Boyd",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Boyd",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen P. Boyd"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46238940"
                        ],
                        "name": "Shao-Po Wu",
                        "slug": "Shao-Po-Wu",
                        "structuredName": {
                            "firstName": "Shao-Po",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shao-Po Wu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8952069,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "97c47de1aae432f90554f3de8f58e90096c54876",
            "isKey": false,
            "numCitedBy": 692,
            "numCiting": 155,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of maximizing the determinant of a matrix subject to linear matrix inequalities (LMIs) arises in many fields, including computational geometry, statistics, system identification, experiment design, and information and communication theory. It can also be considered as a generalization of the semidefinite programming problem. \nWe give an overview of the applications of the determinant maximization problem, pointing out simple cases where specialized algorithms or analytical solutions are known. We then describe an interior-point method, with a simplified analysis of the worst-case complexity and numerical results that indicate that the method is very efficient, both in theory and in practice. Compared to existing specialized algorithms (where they are available), the interior-point method will generally be slower; the advantage is that it handles a much wider variety of problems."
            },
            "slug": "Determinant-Maximization-with-Linear-Matrix-Vandenberghe-Boyd",
            "title": {
                "fragments": [],
                "text": "Determinant Maximization with Linear Matrix Inequality Constraints"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145969795"
                        ],
                        "name": "Pradeep Ravikumar",
                        "slug": "Pradeep-Ravikumar",
                        "structuredName": {
                            "firstName": "Pradeep",
                            "lastName": "Ravikumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pradeep Ravikumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40333747"
                        ],
                        "name": "Alekh Agarwal",
                        "slug": "Alekh-Agarwal",
                        "structuredName": {
                            "firstName": "Alekh",
                            "lastName": "Agarwal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alekh Agarwal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721860"
                        ],
                        "name": "M. Wainwright",
                        "slug": "M.-Wainwright",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Wainwright",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wainwright"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 152
                            }
                        ],
                        "text": "5), including subgradient methods [73, 136], dual coordinate ascent methods [94, 234], annealing-type methods [121, 246], proximal optimization schemes [193], and adaptive LP solvers [223]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13206497,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "daa7c0eba5791d9835a70699f7771e6e409432a8",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "A large body of past work has focused on the first-order tree-based LP relaxation for the MAP problem in Markov random fields. This paper develops a family of super-linearly convergent LP solvers based on proximal minimization schemes using Bregman divergences that exploit the underlying graphical structure, and so scale well to large problems. All of our algorithms have a double-loop character, with the outer loop corresponding to the proximal sequence, and an inner loop of cyclic Bregman divergences used to compute each proximal update. The inner loop updates are distributed and respect the graph structure, and thus can be cast as message-passing algorithms. We establish various convergence guarantees for our algorithms, illustrate their performance, and also present rounding schemes with provable optimality guarantees."
            },
            "slug": "Message-passing-for-graph-structured-linear-and-Ravikumar-Agarwal",
            "title": {
                "fragments": [],
                "text": "Message-passing for graph-structured linear programs: proximal projections, convergence and rounding schemes"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper develops a family of super-linearly convergent LP solvers based on proximal minimization schemes using Bregman divergences that exploit the underlying graphical structure, and so scale well to large problems."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721860"
                        ],
                        "name": "M. Wainwright",
                        "slug": "M.-Wainwright",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Wainwright",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wainwright"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35132120"
                        ],
                        "name": "T. Jaakkola",
                        "slug": "T.-Jaakkola",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Jaakkola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jaakkola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701607"
                        ],
                        "name": "A. Willsky",
                        "slug": "A.-Willsky",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Willsky",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Willsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 492441,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f26da30b639ac79f3b74b00b00bea6e527a4bf7c",
            "isKey": false,
            "numCitedBy": 268,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a tree-based reparameterization (TRP) framework that provides a new conceptual view of a large class of algorithms for computing approximate marginals in graphs with cycles. This class includes the belief propagation (BP) or sum-product algorithm as well as variations and extensions of BP. Algorithms in this class can be formulated as a sequence of reparameterization updates, each of which entails refactorizing a portion of the distribution corresponding to an acyclic subgraph (i.e., a tree, or more generally, a hypertree). The ultimate goal is to obtain an alternative but equivalent factorization using functions that represent (exact or approximate) marginal distributions on cliques of the graph. Our framework highlights an important property of the sum-product algorithm and the larger class of reparameterization algorithms: the original distribution on the graph with cycles is not changed. The perspective of tree-based updates gives rise to a simple and intuitive characterization of the fixed points in terms of tree consistency. We develop interpretations of these results in terms of information geometry. The invariance of the distribution, in conjunction with the fixed-point characterization, enables us to derive an exact expression for the difference between the true marginals on an arbitrary graph with cycles, and the approximations provided by belief propagation. More broadly, our analysis applies to any algorithm that minimizes the Bethe free energy. We also develop bounds on the approximation error, which illuminate the conditions that govern their accuracy. Finally, we show how the reparameterization perspective extends naturally to generalizations of BP (e.g., Kikuchi (1951) approximations and variants) via the notion of hypertree reparameterization."
            },
            "slug": "Tree-based-reparameterization-framework-for-of-and-Wainwright-Jaakkola",
            "title": {
                "fragments": [],
                "text": "Tree-based reparameterization framework for analysis of sum-product and related algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A tree-based reparameterization (TRP) framework is presented that provides a new conceptual view of a large class of algorithms for computing approximate marginals in graphs with cycles, which includes the belief propagation or sum-product algorithm as well as variations and extensions of BP."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792269"
                        ],
                        "name": "H. Kappen",
                        "slug": "H.-Kappen",
                        "structuredName": {
                            "firstName": "Hilbert",
                            "lastName": "Kappen",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kappen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145677606"
                        ],
                        "name": "Francisco de Borja Rodr\u00edguez Ortiz",
                        "slug": "Francisco-de-Borja-Rodr\u00edguez-Ortiz",
                        "structuredName": {
                            "firstName": "Francisco",
                            "lastName": "Ortiz",
                            "middleNames": [
                                "de",
                                "Borja",
                                "Rodr\u00edguez"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Francisco de Borja Rodr\u00edguez Ortiz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8174520,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9742bfbda40bcacd32cf5ff598448edfee358b4d",
            "isKey": false,
            "numCitedBy": 164,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "The learning process in Boltzmann machines is computationally very expensive. The computational complexity of the exact algorithm is exponential in the number of neurons. We present a new approximate learning algorithm for Boltzmann machines, based on mean-field theory and the linear response theorem. The computational complexity of the algorithm is cubic in the number of neurons. In the absence of hidden units, we show how the weights can be directly computed from the fixed-point equation of the learning rules. Thus, in this case we do not need to use a gradient descent procedure for the learning process. We show that the solutions of this method are close to the optimal solutions and give a significant improvement when correlations play a significant role. Finally, we apply the method to a pattern completion task and show good performance for networks up to 100 neurons."
            },
            "slug": "Efficient-Learning-in-Boltzmann-Machines-Using-Kappen-Ortiz",
            "title": {
                "fragments": [],
                "text": "Efficient Learning in Boltzmann Machines Using Linear Response Theory"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work presents a new approximate learning algorithm for Boltzmann machines, based on mean-field theory and the linear response theorem, that is close to the optimal solutions and gives a significant improvement when correlations play a significant role."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731356"
                        ],
                        "name": "E. Maneva",
                        "slug": "E.-Maneva",
                        "structuredName": {
                            "firstName": "Elitza",
                            "lastName": "Maneva",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Maneva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688109"
                        ],
                        "name": "Elchanan Mossel",
                        "slug": "Elchanan-Mossel",
                        "structuredName": {
                            "firstName": "Elchanan",
                            "lastName": "Mossel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Elchanan Mossel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721860"
                        ],
                        "name": "M. Wainwright",
                        "slug": "M.-Wainwright",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Wainwright",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wainwright"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Survey propagation turns out to be an instance of the sum-product or belief propagation algorithm, but as applied to an alternative graphical model for satisfiability problems [38, 159]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1361511,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "d05ad4e97808081c911833f4500369d5e78a1b74",
            "isKey": false,
            "numCitedBy": 153,
            "numCiting": 87,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the survey propagation algorithm [19, 5, 4], which is an iterative technique that appears to be very effective in solving random k-SAT problems even with densities close to threshold. We first describe how any SAT formula can be associated with a novel family of Markov random fields (MRFs), parameterized by a real number \u03c1. We then show that applying belief propagation---a well-known \"message-passing technique---to this family of MRFs recovers various algorithms, ranging from pure survey propagation at one extreme (\u03c1 = 1) to standard belief propagation on the uniform distribution over SAT assignments at the other extreme (\u03c1 = 0). Configurations in these MRFs have a natural interpretation as generalized satisfiability assignments, on which a partial order can be defined. We isolate cores as minimal elements in this partial ordering, and prove that any core is a fixed point of survey propagation. We investigate the associated lattice structure, and prove a weight-preserving identity that shows how any MRF with p > 0 can be viewed as a \"smoothed\" version of the naive factor graph representation of the k-SAT problem (p = 0). Our experimental results show that message-passing on our family of MRFs is most effective for values of \u03c1 \u2260 1 (i.e., distinct from survey propagation); moreover, they suggest that random formulas may not typically possess non-trivial cores. Finally, we isolate properties of Gibbs sampling and message-passing algorithms that are typical for an ensemble of k-SAT problems. We prove that the space of cores for random formulas is highly disconnected, and show that for values of p sufficiently close to one, either the associated MRF is highly concentrated around the all-star assignment, or it has exponentially small conductance. Similarly, we prove that for p sufficiently close to one, the all-star assignment is attractive for message-passing when analyzed in the density-evolution setting."
            },
            "slug": "A-new-look-at-survey-propagation-and-its-Maneva-Mossel",
            "title": {
                "fragments": [],
                "text": "A new look at survey propagation and its generalizations"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The experimental results show that message-passing on a novel family of Markov random fields is most effective for values of \u03c1 \u2260 1 (i.e., distinct from survey propagation), and suggest that random formulas may not typically possess non-trivial cores."
            },
            "venue": {
                "fragments": [],
                "text": "SODA '05"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52626911"
                        ],
                        "name": "T. Minka",
                        "slug": "T.-Minka",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Minka",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Minka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114755206"
                        ],
                        "name": "Yuan Qi",
                        "slug": "Yuan-Qi",
                        "structuredName": {
                            "firstName": "Yuan",
                            "lastName": "Qi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuan Qi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 69
                            }
                        ],
                        "text": "We illustrate this idea by deriving the tree-structured EP algorithm [171], applied to a pairwise Markov random field on a graph G = (V,E)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 58
                            }
                        ],
                        "text": "As with assumed density filtering, expectationpropagation [172, 171] and various related algorithms [181, 61, 112] are typically described in terms of moment-matching operations."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 15
                            }
                        ],
                        "text": "See the papers [171, 247, 235] for further details on tree EP."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2108276,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3148f8ffe2cf20fecbd199cdffa2b6dfe2ae3a7f",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Approximation structure plays an important role in inference on loopy graphs. As a tractable structure, tree approximations have been utilized in the variational method of Ghahramani & Jordan (1997) and the sequential projection method of Frey et al. (2000). However, belief propagation represents each factor of the graph with a product of single-node messages. In this paper, belief propagation is extended to represent factors with tree approximations, by way of the expectation propagation framework. That is, each factor sends a \"message\" to all pairs of nodes in a tree structure. The result is more accurate inferences and more frequent convergence than ordinary belief propagation, at a lower cost than variational trees or double-loop algorithms."
            },
            "slug": "Tree-structured-Approximations-by-Expectation-Minka-Qi",
            "title": {
                "fragments": [],
                "text": "Tree-structured Approximations by Expectation Propagation"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Belief propagation is extended to represent factors with tree approximations, by way of the expectation propagation framework, which results in more accurate inferences and more frequent convergence than ordinary belief propagation, at a lower cost than variational trees or double-loop algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783429"
                        ],
                        "name": "W. Wiegerinck",
                        "slug": "W.-Wiegerinck",
                        "structuredName": {
                            "firstName": "Wim",
                            "lastName": "Wiegerinck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Wiegerinck"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790356"
                        ],
                        "name": "T. Heskes",
                        "slug": "T.-Heskes",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Heskes",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Heskes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 79234,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "e266e47cd43fd43a5af932e0f7c52a5679da840b",
            "isKey": false,
            "numCitedBy": 100,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider loopy belief propagation for approximate inference in probabilistic graphical models. A limitation of the standard algorithm is that clique marginals are computed as if there were no loops in the graph. To overcome this limitation, we introduce fractional belief propagation. Fractional belief propagation is formulated in terms of a family of approximate free energies, which includes the Bethe free energy and the naive mean-field free as special cases. Using the linear response correction of the clique marginals, the scale parameters can be tuned. Simulation results illustrate the potential merits of the approach."
            },
            "slug": "Fractional-Belief-Propagation-Wiegerinck-Heskes",
            "title": {
                "fragments": [],
                "text": "Fractional Belief Propagation"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Fractional belief propagation is formulated in terms of a family of approximate free energies, which includes the Bethe free energy and the naive mean-field free as special cases, and using the linear response correction of the clique marginals, the scale parameters can be tuned."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3067836"
                        ],
                        "name": "Martijn A. R. Leisink",
                        "slug": "Martijn-A.-R.-Leisink",
                        "structuredName": {
                            "firstName": "Martijn",
                            "lastName": "Leisink",
                            "middleNames": [
                                "A.",
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martijn A. R. Leisink"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792269"
                        ],
                        "name": "H. Kappen",
                        "slug": "H.-Kappen",
                        "structuredName": {
                            "firstName": "Hilbert",
                            "lastName": "Kappen",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kappen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Leisinck and Kappen [153] proposed a class of higher-order expansions that generate tighter lower bounds."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2366426,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "b7819760c0642eb7e4e6a46479f7a3800e661c59",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method to bound the partition function of a Boltzmann machine neural network with any odd-order polynomial. This is a direct extension of the mean-field bound, which is first order. We show that the third-order bound is strictly better than mean field. Additionally, we derive a third-order bound for the likelihood of sigmoid belief networks. Numerical experiments indicate that an error reduction of a factor of two is easily reached in the region where expansion-based approximations are useful."
            },
            "slug": "A-Tighter-Bound-for-Graphical-Models-Leisink-Kappen",
            "title": {
                "fragments": [],
                "text": "A Tighter Bound for Graphical Models"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A method to bound the partition function of a Boltzmann machine neural network with any odd-order polynomial is presented and it is shown that the third-order bound is strictly better than mean field."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145810673"
                        ],
                        "name": "V. G\u00f3mez",
                        "slug": "V.-G\u00f3mez",
                        "structuredName": {
                            "firstName": "V.",
                            "lastName": "G\u00f3mez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. G\u00f3mez"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In some cases, accounting for a small set of significant loop corrections may lead to improved approximations to the partition function [97], or more accurate approximations of the marginals for LDPC codes [49]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9193277,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1a43b891fbb3ec8a779e20927e3c2445f707eab8",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, Chertkov and Chernyak (2006a) derived an exact expression for the partition sum (normalization constant) corresponding to a graphical model, which is an expansion around the Belief Propagation solution. By adding correction terms to the BP free energy, one for each \u201cgeneralized loop\u201d in the factor graph, the exact partition sum is obtained. However, the usually enormous number of generalized loops generally prohibits summation over all correction terms. In this article we introduce Truncated Loop Series BP (TLSBP), a particular way of truncating the loop series of Chertkov & Chernyak by considering generalized loops as compositions of simple loops. We analyze the performance of TLSBP in different scenarios, including the Ising model, regular random graphs and on Promedas, a large probabilistic medical diagnostic system. We show that TLSBP often improves upon the accuracy of the BP solution, at the expense of increased computation time. We also show that the performance of TLSBP strongly depends on the degree of interaction between the variables. For weak interactions, truncating the series leads to significant improvements, whereas for strong interactions it can be ineffective, even if a high number of terms is considered."
            },
            "slug": "Truncating-the-loop-series-expansion-for-BP-G\u00f3mez",
            "title": {
                "fragments": [],
                "text": "Truncating the loop series expansion for BP"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This article introduces Truncated Loop Series BP (TLSBP), a particular way of truncating the loop series of Chertkov & Chernyak by considering generalized loops as compositions of simple loops and analyzes the performance of TLSBP in different scenarios, including the Ising model, regular random graphs and on Promedas, a large probabilistic medical diagnostic system."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796044"
                        ],
                        "name": "L. Saul",
                        "slug": "L.-Saul",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Saul",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Saul"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15116562,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e9a54374aec5c92296c7b24436f08934643829ae",
            "isKey": false,
            "numCitedBy": 288,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop a refined mean field approximation for inference and learning in probabilistic neural networks. Our mean field theory, unlike most, does not assume that the units behave as independent degrees of freedom; instead, it exploits in a principled way the existence of large substructures that are computationally tractable. To illustrate the advantages of this framework, we show how to incorporate weak higher order interactions into a first-order hidden Markov model, treating the corrections (but not the first order structure) within mean field theory."
            },
            "slug": "Exploiting-Tractable-Substructures-in-Intractable-Saul-Jordan",
            "title": {
                "fragments": [],
                "text": "Exploiting Tractable Substructures in Intractable Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A refined mean field approximation for inference and learning in probabilistic neural networks is developed, and it is shown how to incorporate weak higher order interactions into a first-order hidden Markov model."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796335"
                        ],
                        "name": "D. Blei",
                        "slug": "D.-Blei",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Blei",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The latent Dirichlet allocation model [29] is a particular type of hierarchical Bayes model for capturing the statistical dependencies among words in a corpus of documents."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "An example \u201cbag-of-words\u201d model is the latent Dirichlet allocation model [29], in which a topic defines a probability distribution on words, and a document defines a probability distribution on topics."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3177797,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f198043a866e9187925a8d8db9a55e3bfdd47f2c",
            "isKey": false,
            "numCitedBy": 30948,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Latent-Dirichlet-Allocation-Blei-Ng",
            "title": {
                "fragments": [],
                "text": "Latent Dirichlet Allocation"
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35132120"
                        ],
                        "name": "T. Jaakkola",
                        "slug": "T.-Jaakkola",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Jaakkola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jaakkola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Jaakkola and Jordan [118] explored the use of mixture distributions in improving the mean field approximation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 122944385,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b5571a1cf9d3f640883812358498f64c1655d5a",
            "isKey": false,
            "numCitedBy": 91,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Mean field methods provide computationally efficient approximations to posterior probability distributions for graphical models. Simple mean field methods make a completely factorized approximation to the posterior, which is unlikely to be accurate when the posterior is multimodal. Indeed, if the posterior is multi-modal, only one of the modes can be captured. To improve the mean field approximation in such cases, we employ mixture models as posterior approximations, where each mixture component is a factorized distribution. We describe efficient methods for optimizing the Parameters in these models."
            },
            "slug": "Improving-the-Mean-Field-Approximation-Via-the-Use-Jaakkola-Jordan",
            "title": {
                "fragments": [],
                "text": "Improving the Mean Field Approximation Via the Use of Mixture Distributions"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work employs mixture models as posterior approximations, where each mixture component is a factorized distribution, and describes efficient methods for optimizing the Parameters in these models."
            },
            "venue": {
                "fragments": [],
                "text": "Learning in Graphical Models"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681881"
                        ],
                        "name": "Xavier Boyen",
                        "slug": "Xavier-Boyen",
                        "structuredName": {
                            "firstName": "Xavier",
                            "lastName": "Boyen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xavier Boyen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736370"
                        ],
                        "name": "D. Koller",
                        "slug": "D.-Koller",
                        "structuredName": {
                            "firstName": "Daphne",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Koller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Examples of such algorithms include the family of expectationpropagation algorithms due to Minka [172], the related class of assumed density filtering methods [149, 161, 37], expectation-consistent inference [181], structured summary-propagation algorithms [61, 112], and"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5556701,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92aea50331c19fe9716d3a9a02e26704afe24d88",
            "isKey": false,
            "numCitedBy": 617,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "The monitoring and control of any dynamic system depends crucially on the ability to reason about its current status and its future trajectory. In the case of a stochastic system, these tasks typically involve the use of a belief state--a probability distribution over the state of the process at a given point in time. Unfortunately, the state spaces of complex processes are very large, making an explicit representation of a belief state intractable. Even in dynamic Bayesian networks (DBNs), where the process itself can be represented compactly, the representation of the belief state is intractable. We investigate the idea of maintaining a compact approximation to the true belief state, and analyze the conditions under which the errors due to the approximations taken over the lifetime of the process do not accumulate to make our answers completely irrelevant. We show that the error in a belief state contracts exponentially as the process evolves. Thus, even with multiple approximations, the error in our process remains bounded indefinitely. We show how the additional structure of a DBN can be used to design our approximation scheme, improving its performance significantly. We demonstrate the applicability of our ideas in the context of a monitoring task, showing that orders of magnitude faster inference can be achieved with only a small degradation in accuracy."
            },
            "slug": "Tractable-Inference-for-Complex-Stochastic-Boyen-Koller",
            "title": {
                "fragments": [],
                "text": "Tractable Inference for Complex Stochastic Processes"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work investigates the idea of maintaining a compact approximation to the true belief state, and analyzes the conditions under which the errors due to the approximations taken over the lifetime of the process do not accumulate to make the authors' answers completely irrelevant."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678311"
                        ],
                        "name": "M. Welling",
                        "slug": "M.-Welling",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Welling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Welling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725303"
                        ],
                        "name": "Y. Teh",
                        "slug": "Y.-Teh",
                        "structuredName": {
                            "firstName": "Yee",
                            "lastName": "Teh",
                            "middleNames": [
                                "Whye"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Teh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5921506,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "03c8660b2788f929889992d82ef81a409e84bc69",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Belief propagation on cyclic graphs is an efficient algorithm for computing approximate marginal probability distributions over single nodes and neighboring nodes in the graph. In this paper we propose two new algorithms for approximating joint probabilities of arbitrary pairs of nodes and prove a number of desirable properties that these estimates fulfill. The first algorithm is a propagation algorithm which is shown to converge if belief propagation converges to a stable fixed point. The second algorithm is based on matrix inversion. Experiments compare a number of competing methods."
            },
            "slug": "Linear-Response-for-Approximate-Inference-Welling-Teh",
            "title": {
                "fragments": [],
                "text": "Linear Response for Approximate Inference"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "This paper proposes two new algorithms for approximating joint probabilities of arbitrary pairs of nodes and proves a number of desirable properties that these estimates fulfill."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2588854"
                        ],
                        "name": "M. Gr\u00f6tschel",
                        "slug": "M.-Gr\u00f6tschel",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Gr\u00f6tschel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gr\u00f6tschel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725557"
                        ],
                        "name": "L. Lov\u00e1sz",
                        "slug": "L.-Lov\u00e1sz",
                        "structuredName": {
                            "firstName": "L\u00e1szl\u00f3",
                            "lastName": "Lov\u00e1sz",
                            "middleNames": [
                                "Mikl\u00f3s"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Lov\u00e1sz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689196"
                        ],
                        "name": "A. Schrijver",
                        "slug": "A.-Schrijver",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Schrijver",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Schrijver"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The field of polyhedral combinatorics [66, 101, 177, 207] is devoted to understanding the structure of such polytopes arising from various classes of discrete problems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 122339802,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ea2251357fa4d3f44c5623ab8b80c18dfe05e712",
            "isKey": false,
            "numCitedBy": 2441,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "0. Mathematical Preliminaries.- 0.1 Linear Algebra and Linear Programming.- Basic Notation.- Hulls, Independence, Dimension.- Eigenvalues, Positive Definite Matrices.- Vector Norms, Balls.- Matrix Norms.- Some Inequalities.- Polyhedra, Inequality Systems.- Linear (Diophantine) Equations and Inequalities.- Linear Programming and Duality.- 0.2 Graph Theory.- Graphs.- Digraphs.- Walks, Paths, Circuits, Trees.- 1. Complexity, Oracles, and Numerical Computation.- 1.1 Complexity Theory: P and NP.- Problems.- Algorithms and Turing Machines.- Encoding.- Time and Space Complexity.- Decision Problems: The Classes P and NP.- 1.2 Oracles.- The Running Time of Oracle Algorithms.- Transformation and Reduction.- NP-Completeness and Related Notion.- 1.3 Approximation and Computation of Numbers.- Encoding Length of Numbers.- Polynomial and Strongly Polynomial Computations.- Polynomial Time Approximation of Real Numbers.- 1.4 Pivoting and Related Procedures.- Gaussian Elimination.- Gram-Schmidt Orthogonalization.- The Simplex Method.- Computation of the Hermite Normal Form.- 2. Algorithmic Aspects of Convex Sets: Formulation of the Problems.- 2.1 Basic Algorithmic Problems for Convex Sets.- 2.2 Nondeterministic Decision Problems for Convex Sets.- 3. The Ellipsoid Method.- 3.1 Geometric Background and an Informal Description.- Properties of Ellipsoids.- Description of the Basic Ellipsoid Method.- Proofs of Some Lemmas.- Implementation Problems and Polynomiality.- Some Examples.- 3.2 The Central-Cut Ellipsoid Method.- 3.3 The Shallow-Cut Ellipsoid Method.- 4. Algorithms for Convex Bodies.- 4.1 Summary of Results.- 4.2 Optimization from Separation.- 4.3 Optimization from Membership.- 4.4 Equivalence of the Basic Problems.- 4.5 Some Negative Results.- 4.6 Further Algorithmic Problems for Convex Bodies.- 4.7 Operations on Convex Bodies.- The Sum.- The Convex Hull of the Union.- The Intersection.- Polars, Blockers, Antiblockers.- 5. Diophantine Approximation and Basis Reduction.- 5.1 Continued Fractions.- 5.2 Simultaneous Diophantine Approximation: Formulation of the Problems.- 5.3 Basis Reduction in Lattices.- 5.4 More on Lattice Algorithms.- 6. Rational Polyhedra.- 6.1 Optimization over Polyhedra: A Preview.- 6.2 Complexity of Rational Polyhedra.- 6.3 Weak and Strong Problems.- 6.4 Equivalence of Strong Optimization and Separation.- 6.5 Further Problems for Polyhedra.- 6.6 Strongly Polynomial Algorithms.- 6.7 Integer Programming in Bounded Dimension.- 7. Combinatorial Optimization: Some Basic Examples.- 7.1 Flows and Cuts.- 7.2 Arborescences.- 7.3 Matching.- 7.4 Edge Coloring.- 7.5 Matroids.- 7.6 Subset Sums.- 7.7 Concluding Remarks.- 8. Combinatorial Optimization: A Tour d'Horizon.- 8.1 Blocking Hypergraphs and Polyhedra.- 8.2 Problems on Bipartite Graphs.- 8.3 Flows, Paths, Chains, and Cuts.- 8.4 Trees, Branchings, and Rooted and Directed Cuts.- Arborescences and Rooted Cuts.- Trees and Cuts in Undirected Graphs.- Dicuts and Dijoins.- 8.5 Matchings, Odd Cuts, and Generalizations.- Matching.- b-Matching.- T-Joins and T-Cuts.- Chinese Postmen and Traveling Salesmen.- 8.6 Multicommodity Flows.- 9. Stable Sets in Graphs.- 9.1 Odd Circuit Constraints and t-Perfect Graphs.- 9.2 Clique Constraints and Perfect Graphs.- Antiblockers of Hypergraphs.- 9.3 Orthonormal Representations.- 9.4 Coloring Perfect Graphs.- 9.5 More Algorithmic Results on Stable Sets.- 10. Submodular Functions.- 10.1 Submodular Functions and Polymatroids.- 10.2 Algorithms for Polymatroids and Submodular Functions.- Packing Bases of a Matroid.- 10.3 Submodular Functions on Lattice, Intersecting, and Crossing Families.- 10.4 Odd Submodular Function Minimization and Extensions.- References.- Notation Index.- Author Index."
            },
            "slug": "Geometric-Algorithms-and-Combinatorial-Optimization-Gr\u00f6tschel-Lov\u00e1sz",
            "title": {
                "fragments": [],
                "text": "Geometric Algorithms and Combinatorial Optimization"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2129428282"
                        ],
                        "name": "Hoon Kim",
                        "slug": "Hoon-Kim",
                        "structuredName": {
                            "firstName": "Hoon",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hoon Kim"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 79
                            }
                        ],
                        "text": "Such a strategy can be viewed as a deterministic analog of simulated annealing [91]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 33807429,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "17a09383cf450da8fe9830b9420914fa47707916",
            "isKey": false,
            "numCitedBy": 3242,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "dents. The first six chapters, the sixth added since the first edition, cover mixing processes, density and regression estimation for discrete time processes, density and regression estimation for continuous time processes, and the local time density estimator. The final chapter, also added since the first edition and the only one not devoted to theoretical results, reviews some aspects of implementation and gives examples. The book opens with a synopsis that defines the object of the study as being the construction of time series alternatives to the usual BoxJenkins SARIMA processes. Following that, it proceeds to highlight and summarize the main ideas of the book, beginning with definitions of kernel density and regression estimators and concluding with a brief list of some advantages of nonparametric over parametric time series methods. Specific advantages listed are that they are robust, that deseasonalization is not necessary, and that parametric convergence rates can, under some circumstances, be achieved. Having provided that overview, the book then proceeds in Chapter 1 to lay the theoretical groundwork for the analysis of a wide class of time series by a review of historical results for mixing processes. Results given include Berbee\u2019s and Bradley\u2019s lemmas for coupling, some results for covariances and joint densities including Rio\u2019s, Davydov\u2019s, and Billingsley\u2019s inequalities, some inequalities for partial sums including Hoeffding\u2019s and Bernstein\u2019s, and some limit theorems (laws of large numbers and central limit theorem) for strongly mixing processes. Chapters 2 and 3 cover the analysis of discrete time processes, Chapter 2 focusing on density estimation for sequences of correlated random variables and Chapter 3 on regression estimation and prediction. Topics include some specific kernels, optimal asymptotic quadratic error, uniform almost sure convergence for some kernels, asymptotic normality, and prediction for some stationary and nonstationary processes. These chapters are mainly review; although several results are from earlier papers by the author, they are not, by and large, new. Chapters 4 and 5 consider estimation for continuous time processes and are mainly new results. Their development is a broad parallel of the \u2019 development of Chapters 2 and 3, with Chapter 4 devoted to density estimation and Chapter 5 covering regression estimation and prediction. Topics and results include optimal and superoptimal asymptotic quadratic error including a minimax bound of Kutoyants (1997) and minimaxity of intermediate rates, optimal and superoptimal uniform convergence rates, asymptotic normality, irregular and admissible sampling, and the convergence rates of continuous-time nonparametric predictors. Some conditions are given under which a nonparametric predictor reaches a parametric convergence rate. Chapter 6 explores the use of local time for unbiased density estimation given a continuous time sample and consists, apart from one result, of new results. A definition is given of local time, followed by two existence criteria for local time, the first due to Geman and Horowitz (1973, 1980) and the second proven by the author. A density estimator based on local time is then defined and shown to be unbiased and consistent. Some results on convergence rates are then given, followed by asymptotic normality, a functional law of the iterated logarithm, and parametric rates for pointwise and uniform convergence. Chapter 7 is a brief summary of some practical aspects of nonparametric time series analysis. These fall into three areas-aspects of implementation. the comparison of nonparametric with parametric methods, and applied examples. The aspects of implementation addressed are variance stabilization via BoxCox transformation, methods for eliminating trend and seasonality, methods for choosing kernel bandwidth, and choosing a suitable order for predicting a Markov process in which the true order of the process is unknown. In comparing nonparametric and parametric methods of time series analysis, the book summarizes the results of Carbon and Delecroix (1993). who considered several simulated autoregressive moving average (ARMA) processes and some real business and engineering datasets, and the results of Rosa (1993), who considered ARMA models with and without generalized autoregressive conditional heteroscedasticity effects. An appendix gives 17 tables summarizing the results of the comparisons. Finally. some examples are given of applying nonparametric methods to finance and economic data. The value of this book is primarily in its theoretical development and, as such, it would be of more interest to researchers in statistical theory and"
            },
            "slug": "Monte-Carlo-Statistical-Methods-Kim",
            "title": {
                "fragments": [],
                "text": "Monte Carlo Statistical Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "In comparing nonparametric and parametric methods of time series analysis, the book summarizes the results of Carbon and Delecroix (1993), who considered several simulated autoregressive moving average (ARMA) processes."
            },
            "venue": {
                "fragments": [],
                "text": "Technometrics"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1869519"
                        ],
                        "name": "G. R. Cross",
                        "slug": "G.-R.-Cross",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Cross",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. R. Cross"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 19038308,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "7862fc4099b31f0a21fcf681403c2e594c2dd5bc",
            "isKey": false,
            "numCitedBy": 1501,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider a texture to be a stochastic, possibly periodic, two-dimensional image field. A texture model is a mathematical procedure capable of producing and describing a textured image. We explore the use of Markov random fields as texture models. The binomial model, where each point in the texture has a binomial distribution with parameter controlled by its neighbors and ``number of tries'' equal to the number of gray levels, was taken to be the basic model for the analysis. A method of generating samples from the binomial model is given, followed by a theoretical and practical analysis of the method's convergence. Examples show how the parameters of the Markov random field control the strength and direction of the clustering in the image. The power of the binomial model to produce blurry, sharp, line-like, and blob-like textures is demonstrated. Natural texture samples were digitized and their parameters were estimated under the Markov random field model. A hypothesis test was used for an objective assessment of goodness-of-fit under the Markov random field model. Overall, microtextures fit the model well. The estimated parameters of the natural textures were used as input to the generation procedure. The synthetic microtextures closely resembled their real counterparts, while the regular and inhomogeneous textures did not."
            },
            "slug": "Markov-Random-Field-Texture-Models-Cross-Jain",
            "title": {
                "fragments": [],
                "text": "Markov Random Field Texture Models"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The power of the binomial model to produce blurry, sharp, line-like, and blob-like textures is demonstrated and the synthetic microtextures closely resembled their real counterparts, while the regular and inhomogeneous textures did not."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717841"
                        ],
                        "name": "R. Szeliski",
                        "slug": "R.-Szeliski",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Szeliski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Szeliski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2984143"
                        ],
                        "name": "R. Zabih",
                        "slug": "R.-Zabih",
                        "structuredName": {
                            "firstName": "Ramin",
                            "lastName": "Zabih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zabih"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709053"
                        ],
                        "name": "Daniel Scharstein",
                        "slug": "Daniel-Scharstein",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Scharstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Scharstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1922280"
                        ],
                        "name": "O. Veksler",
                        "slug": "O.-Veksler",
                        "structuredName": {
                            "firstName": "Olga",
                            "lastName": "Veksler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Veksler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144653004"
                        ],
                        "name": "V. Kolmogorov",
                        "slug": "V.-Kolmogorov",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Kolmogorov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Kolmogorov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696487"
                        ],
                        "name": "A. Agarwala",
                        "slug": "A.-Agarwala",
                        "structuredName": {
                            "firstName": "Aseem",
                            "lastName": "Agarwala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Agarwala"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802944"
                        ],
                        "name": "M. Tappen",
                        "slug": "M.-Tappen",
                        "structuredName": {
                            "firstName": "Marshall",
                            "lastName": "Tappen",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Tappen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756036"
                        ],
                        "name": "C. Rother",
                        "slug": "C.-Rother",
                        "structuredName": {
                            "firstName": "Carsten",
                            "lastName": "Rother",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rother"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1210309,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0f02f771339d3e5524238a9d960b2ef505e2f47",
            "isKey": false,
            "numCitedBy": 1029,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "Among the most exciting advances in early vision has been the development of efficient energy minimization algorithms for pixel-labeling tasks such as depth or texture computation. It has been known for decades that such problems can be elegantly expressed as Markov random fields, yet the resulting energy minimization problems have been widely viewed as intractable. Algorithms such as graph cuts and loopy belief propagation (LBP) have proven to be very powerful: For example, such methods form the basis for almost all the top-performing stereo methods. However, the trade-offs among different energy minimization algorithms are still not well understood. In this paper, we describe a set of energy minimization benchmarks and use them to compare the solution quality and runtime of several common energy minimization algorithms. We investigate three promising methods-graph cuts, LBP, and tree-reweighted message passing-in addition to the well-known older iterated conditional mode (ICM) algorithm. Our benchmark problems are drawn from published energy functions used for stereo, image stitching, interactive segmentation, and denoising. We also provide a general-purpose software interface that allows vision researchers to easily switch between optimization methods. The benchmarks, code, images, and results are available at http://vision.middlebury.edu/MRF/."
            },
            "slug": "A-Comparative-Study-of-Energy-Minimization-Methods-Szeliski-Zabih",
            "title": {
                "fragments": [],
                "text": "A Comparative Study of Energy Minimization Methods for Markov Random Fields with Smoothness-Based Priors"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A set of energy minimization benchmarks are described and used to compare the solution quality and runtime of several common energy minimizations algorithms and a general-purpose software interface is provided that allows vision researchers to easily switch between optimization methods."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764325"
                        ],
                        "name": "Radford M. Neal",
                        "slug": "Radford-M.-Neal",
                        "structuredName": {
                            "firstName": "Radford",
                            "lastName": "Neal",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Radford M. Neal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 237
                            }
                        ],
                        "text": "Although the EM algorithm is often presented as an alternation between an expectation step (E step) and a maximization step (M step), it is also possible to take a variational perspective on EM, and view both steps as maximization steps [25, 78]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17947141,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "9f87a11a523e4680e61966e36ea2eac516096f23",
            "isKey": false,
            "numCitedBy": 2597,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The EM algorithm performs maximum likelihood estimation for data in which some variables are unobserved. We present a function that resembles negative free energy and show that the M step maximizes this function with respect to the model parameters and the E step maximizes it with respect to the distribution over the unobserved variables. From this perspective, it is easy to justify an incremental variant of the EM algorithm in which the distribution for only one of the unobserved variables is recalculated in each E step. This variant is shown empirically to give faster convergence in a mixture estimation problem. A variant of the algorithm that exploits sparse conditional distributions is also described, and a wide range of other variant algorithms are also seen to be possible."
            },
            "slug": "A-View-of-the-Em-Algorithm-that-Justifies-Sparse,-Neal-Hinton",
            "title": {
                "fragments": [],
                "text": "A View of the Em Algorithm that Justifies Incremental, Sparse, and other Variants"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "An incremental variant of the EM algorithm in which the distribution for only one of the unobserved variables is recalculated in each E step is shown empirically to give faster convergence in a mixture estimation problem."
            },
            "venue": {
                "fragments": [],
                "text": "Learning in Graphical Models"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3371403"
                        ],
                        "name": "J. Kleinberg",
                        "slug": "J.-Kleinberg",
                        "structuredName": {
                            "firstName": "Jon",
                            "lastName": "Kleinberg",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kleinberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746222"
                        ],
                        "name": "\u00c9. Tardos",
                        "slug": "\u00c9.-Tardos",
                        "structuredName": {
                            "firstName": "\u00c9va",
                            "lastName": "Tardos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00c9. Tardos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "17) have studied in past and ongoing work by various authors, including the special cases of {0, 1}-quadratic programs [102], metric labeling with Potts models [132, 45], error-control coding problems [73, 75, 234, 223, 47, 59], independent set problems [177, 202], and various types of matching problems [13, 113, 201]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16241328,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "a3b3aad58ecc6aed599c7567d4fe07ad3480a866",
            "isKey": false,
            "numCitedBy": 378,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "In a traditional classification problem, we wish to assign one of k labels (or classes) to each of n objects, in a way that is consistent with some observed data that we have about the problem. An active line of research in this area is concerned with classification when one has information about pairwise relationships among the objects to be classified; this issue is one of the principal motivations for the framework of Markov random fields, and it arises in areas such as image processing, biometry: and document analysis. In its most basic form, this style of analysis seeks a classification that optimizes a combinatorial function consisting of assignment costs-based on the individual choice of label we make for each object-and separation costs-based on the pair of choices we make for two \"related\" objects. We formulate a general classification problem of this type, the metric labeling problem; we show that it contains as special cases a number of standard classification frameworks, including several arising from the theory of Markov random fields. From the perspective of combinatorial optimization, our problem can be viewed as a substantial generalization of the multiway cut problem, and equivalent to a type of uncapacitated quadratic assignment problem. We provide the first non-trivial polynomial-time approximation algorithms for a general family of classification problems of this type. Our main result is an O(log k log log k)-approximation algorithm for the metric labeling problem, with respect to an arbitrary metric on a set of k labels, and an arbitrary weighted graph of relationships on a set of objects. For the special case in which the labels are endowed with the uniform metric-all distances are the same-our methods provide a 2-approximation."
            },
            "slug": "Approximation-algorithms-for-classification-with-Kleinberg-Tardos",
            "title": {
                "fragments": [],
                "text": "Approximation algorithms for classification problems with pairwise relationships: metric labeling and Markov random fields"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work provides the first non-trivial polynomial-time approximation algorithms for a general family of classification problems of this type, the metric labeling problem, and shows that it contains as special cases a number of standard classification frameworks, including several arising from the theory of Markov random fields."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717841"
                        ],
                        "name": "R. Szeliski",
                        "slug": "R.-Szeliski",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Szeliski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Szeliski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2984143"
                        ],
                        "name": "R. Zabih",
                        "slug": "R.-Zabih",
                        "structuredName": {
                            "firstName": "Ramin",
                            "lastName": "Zabih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zabih"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709053"
                        ],
                        "name": "Daniel Scharstein",
                        "slug": "Daniel-Scharstein",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Scharstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Scharstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1922280"
                        ],
                        "name": "O. Veksler",
                        "slug": "O.-Veksler",
                        "structuredName": {
                            "firstName": "Olga",
                            "lastName": "Veksler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Veksler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144653004"
                        ],
                        "name": "V. Kolmogorov",
                        "slug": "V.-Kolmogorov",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Kolmogorov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Kolmogorov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696487"
                        ],
                        "name": "A. Agarwala",
                        "slug": "A.-Agarwala",
                        "structuredName": {
                            "firstName": "Aseem",
                            "lastName": "Agarwala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Agarwala"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802944"
                        ],
                        "name": "M. Tappen",
                        "slug": "M.-Tappen",
                        "structuredName": {
                            "firstName": "Marshall",
                            "lastName": "Tappen",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Tappen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756036"
                        ],
                        "name": "C. Rother",
                        "slug": "C.-Rother",
                        "structuredName": {
                            "firstName": "Carsten",
                            "lastName": "Rother",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rother"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 149
                            }
                        ],
                        "text": "Various forms of these reweighted maxproduct algorithms have been applied in problems such as segmentation and disparity problems in computer vision [165, 134, 136, 246, 222, 260], error-control coding [73], side-chain prediction [261, 246], sensor fusion [43, 46]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7529769,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a9820932d30bca5828701fd4fe351a2bd0d8883a",
            "isKey": false,
            "numCitedBy": 484,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the most exciting advances in early vision has been the development of efficient energy minimization algorithms. Many early vision tasks require labeling each pixel with some quantity such as depth or texture. While many such problems can be elegantly expressed in the language of Markov Random Fields (MRF's), the resulting energy minimization problems were widely viewed as intractable. Recently, algorithms such as graph cuts and loopy belief propagation (LBP) have proven to be very powerful: for example, such methods form the basis for almost all the top-performing stereo methods. Unfortunately, most papers define their own energy function, which is minimized with a specific algorithm of their choice. As a result, the tradeoffs among different energy minimization algorithms are not well understood. In this paper we describe a set of energy minimization benchmarks, which we use to compare the solution quality and running time of several common energy minimization algorithms. We investigate three promising recent methods\u2014graph cuts, LBP, and tree-reweighted message passing\u2014as well as the well-known older iterated conditional modes (ICM) algorithm. Our benchmark problems are drawn from published energy functions used for stereo, image stitching and interactive segmentation. We also provide a general-purpose software interface that allows vision researchers to easily switch between optimization methods with minimal overhead. We expect that the availability of our benchmarks and interface will make it significantly easier for vision researchers to adopt the best method for their specific problems. Benchmarks, code, results and images are available at http://vision.middlebury.edu/MRF."
            },
            "slug": "A-Comparative-Study-of-Energy-Minimization-Methods-Szeliski-Zabih",
            "title": {
                "fragments": [],
                "text": "A Comparative Study of Energy Minimization Methods for Markov Random Fields"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A set of energy minimization benchmarks, which are used to compare the solution quality and running time of several common energy minimizations algorithms, as well as a general-purpose software interface that allows vision researchers to easily switch between optimization methods with minimal overhead."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2454055"
                        ],
                        "name": "A. Gelfand",
                        "slug": "A.-Gelfand",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Gelfand",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gelfand"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109352679"
                        ],
                        "name": "Adrian F. M. Smith",
                        "slug": "Adrian-F.-M.-Smith",
                        "structuredName": {
                            "firstName": "Adrian",
                            "lastName": "Smith",
                            "middleNames": [
                                "F.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adrian F. M. Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "However, the development of MCMC methodology specifically designed for statistical problems has played an important role in sparking widespread application of such methods in statistics [85]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 53446269,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8d990deca66c9afefbe042f95e41ada0c7227877",
            "isKey": false,
            "numCitedBy": 7054,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract Stochastic substitution, the Gibbs sampler, and the sampling-importance-resampling algorithm can be viewed as three alternative sampling- (or Monte Carlo-) based approaches to the calculation of numerical estimates of marginal probability distributions. The three approaches will be reviewed, compared, and contrasted in relation to various joint probability structures frequently encountered in applications. In particular, the relevance of the approaches to calculating Bayesian posterior densities for a variety of structured models will be discussed and illustrated."
            },
            "slug": "Sampling-Based-Approaches-to-Calculating-Marginal-Gelfand-Smith",
            "title": {
                "fragments": [],
                "text": "Sampling-Based Approaches to Calculating Marginal Densities"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "Stochastic substitution, the Gibbs sampler, and the sampling-importance-resampling algorithm can be viewed as three alternative sampling- (or Monte Carlo-) based approaches to the calculation of numerical estimates of marginal probability distributions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733122"
                        ],
                        "name": "C. Chekuri",
                        "slug": "C.-Chekuri",
                        "structuredName": {
                            "firstName": "Chandra",
                            "lastName": "Chekuri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Chekuri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144335444"
                        ],
                        "name": "S. Khanna",
                        "slug": "S.-Khanna",
                        "structuredName": {
                            "firstName": "Sanjeev",
                            "lastName": "Khanna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Khanna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751440"
                        ],
                        "name": "J. Naor",
                        "slug": "J.-Naor",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Naor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Naor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2908093"
                        ],
                        "name": "L. Zosin",
                        "slug": "L.-Zosin",
                        "structuredName": {
                            "firstName": "Leonid",
                            "lastName": "Zosin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Zosin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "17) have studied in past and ongoing work by various authors, including the special cases of {0, 1}-quadratic programs [102], metric labeling with Potts models [132, 45], error-control coding problems [73, 75, 234, 223, 47, 59], independent set problems [177, 202], and various types of matching problems [13, 113, 201]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13275863,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "70c5c7bef93ad372a835db6cfdae09e361ee93a8",
            "isKey": false,
            "numCitedBy": 102,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider approximation algorithms for the metric labeling problem. This problem was introduced in a paper by Kleinberg and Tardos [J. ACM, 49 (2002), pp. 616--630] and captures many classification problems that arise in computer vision and related fields. They gave an O(log k log log k) approximation for the general case, where k is the number of labels, and a 2-approximation for the uniform metric case. (In fact, the bound for general metrics can be improved to O(log k) by the work of Fakcheroenphol, Rao, and Talwar [Proceedings of the 35th Annual ACM Symposium on Theory of Computing, 2003, pp. 448--455].) Subsequently, Gupta and Tardos [Proceedings of the 32nd Annual ACM Symposium on the Theory of Computing, 2000, pp. 652--658] gave a 4-approximation for the truncated linear metric, a metric motivated by practical applications to image restoration and visual correspondence. In this paper we introduce an integer programming formulation and show that the integrality gap of its linear relaxation either matches or improves the ratios known for several cases of the metric labeling problem studied until now, providing a unified approach to solving them. In particular, we show that the integrality gap of our linear programming (LP) formulation is bounded by O(log k) for a general k-point metric and 2 for the uniform metric, thus matching the known ratios. We also develop an algorithm based on our LP formulation that achieves a ratio of $2+\\sqrt{2}\\simeq 3.414$ for the truncated linear metric improving the earlier known ratio of 4. Our algorithm uses the fact that the integrality gap of the LP formulation is 1 on a linear metric."
            },
            "slug": "A-Linear-Programming-Formulation-and-Approximation-Chekuri-Khanna",
            "title": {
                "fragments": [],
                "text": "A Linear Programming Formulation and Approximation Algorithms for the Metric Labeling Problem"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An integer programming formulation is introduced and it is shown that the integrality gap of its linear relaxation either matches or improves the ratios known for several cases of the metric labeling problem studied until now, providing a unified approach to solving them."
            },
            "venue": {
                "fragments": [],
                "text": "SIAM J. Discret. Math."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701677"
                        ],
                        "name": "S. Sanghavi",
                        "slug": "S.-Sanghavi",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Sanghavi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sanghavi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081804"
                        ],
                        "name": "D. Shah",
                        "slug": "D.-Shah",
                        "structuredName": {
                            "firstName": "Devavrat",
                            "lastName": "Shah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Shah"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701607"
                        ],
                        "name": "A. Willsky",
                        "slug": "A.-Willsky",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Willsky",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Willsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11016058,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "f0b0dc66408c34acbb4a08e3a3207415175cfa77",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate the use of message-passing algorithms for the problem of finding the max-weight independent set (MWIS) in a graph. First, we study the performance of loopy max-product belief propagation. We show that, if it converges, the quality of the estimate is closely related to the tightness of an LP relaxation of the MWIS problem. We use this relationship to obtain sufficient conditions for correctness of the estimate. We then develop a modification of max-product - one that converges to an optimal solution of the dual of the MWIS problem. We also develop a simple iterative algorithm for estimating the max-weight independent set from this dual solution. We show that the MWIS estimate obtained using these two algorithms in conjunction is correct when the graph is bipartite and the MWIS is unique. Finally, we show that any problem of MAP estimation for probability distributions over finite domains can be reduced to an MWIS problem. We believe this reduction will yield new insights and algorithms for MAP estimation."
            },
            "slug": "Message-Passing-for-Max-weight-Independent-Set-Sanghavi-Shah",
            "title": {
                "fragments": [],
                "text": "Message Passing for Max-weight Independent Set"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "The use of message-passing algorithms for the problem of finding the max-weight independent set (MWIS) in a graph is investigated and it is shown that any problem of MAP estimation for probability distributions over finite domains can be reduced to an MWIS problem."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710055"
                        ],
                        "name": "A. Siepel",
                        "slug": "A.-Siepel",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Siepel",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Siepel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6588198,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "1c0d6bfe82bfadc76c22c3e604545ff9c91d7a7b",
            "isKey": false,
            "numCitedBy": 169,
            "numCiting": 82,
            "paperAbstract": {
                "fragments": [],
                "text": "A few models have appeared in recent years that consider not only the way substitutions occur through evolutionary history at each site of a genome, but also the way the process changes from one site to the next. These models combine phylogenetic models of molecular evolution, which apply to individual sites, and hidden Markov models, which allow for changes from site to site. Besides improving the realism of ordinary phylogenetic models, they are potentially very powerful tools for inference and prediction---for gene finding, for example, or prediction of secondary structure. In this paper, we review progress on combined phylogenetic and hidden Markov models and present some extensions to previous work. Our main result is a simple and efficient method for accommodating higher-order states in the HMM, which allows for context-sensitive models of substitution---that is, models that consider the effects of neighboring bases on the pattern of substitution. We present experimental results indicating that higher-order states, autocorrelated rates, and multiple functional categories all lead to significant improvements in the fit of a combined phylogenetic and hidden Markov model, with the effect of higher-order states being particularly pronounced."
            },
            "slug": "Combining-phylogenetic-and-hidden-Markov-models-in-Siepel-Haussler",
            "title": {
                "fragments": [],
                "text": "Combining phylogenetic and hidden Markov models in biosequence analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper presents experimental results indicating that higher-order states, autocorrelated rates, and multiple functional categories all lead to significant improvements in the fit of a combined phylogenetic and hidden Markov model, with the effect of higher- order states being particularly pronounced."
            },
            "venue": {
                "fragments": [],
                "text": "RECOMB '03"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684677"
                        ],
                        "name": "G. Elidan",
                        "slug": "G.-Elidan",
                        "structuredName": {
                            "firstName": "Gal",
                            "lastName": "Elidan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Elidan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143685627"
                        ],
                        "name": "Ian McGraw",
                        "slug": "Ian-McGraw",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "McGraw",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ian McGraw"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736370"
                        ],
                        "name": "D. Koller",
                        "slug": "D.-Koller",
                        "structuredName": {
                            "firstName": "Daphne",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Koller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9008993,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8850119d05f852e67a71151b6da2f88e9bcac9be",
            "isKey": false,
            "numCitedBy": 289,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Inference for probabilistic graphical models is still very much a practical challenge in large domains. The commonly used and effective belief propagation (BP) algorithm and its generalizations often do not converge when applied to hard, real-life inference tasks. While it is widely recognized that the scheduling of messages in these algorithms may have significant consequences, this issue remains largely unexplored. In this work, we address the question of how to schedule messages for asynchronous propagation so that a fixed point is reached faster and more often. We first show that any reasonable asynchronous BP converges to a unique fixed point under conditions similar to those that guarantee convergence of synchronous BP. In addition, we show that the convergence rate of a simple round-robin schedule is at least as good as that of synchronous propagation. We then propose residual belief propagation (RBP), a novel, easy-to-implement, asynchronous propagation algorithm that schedules messages in an informed way, that pushes down a bound on the distance from the fixed point. Finally, we demonstrate the superiority of RBP over state-of-the-art methods for a variety of challenging synthetic and real-life problems: RBP converges significantly more often than other methods; and it significantly reduces running time until convergence, even when other methods converge."
            },
            "slug": "Residual-Belief-Propagation:-Informed-Scheduling-Elidan-McGraw",
            "title": {
                "fragments": [],
                "text": "Residual Belief Propagation: Informed Scheduling for Asynchronous Message Passing"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "RBP is proposed, a novel, easy-to-implement, asynchronous propagation algorithm that schedules messages in an informed way that pushes down a bound on the distance from the fixed point and demonstrates the superiority of RBP over state-of-the-art methods for a variety of challenging synthetic and real-life problems."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38838239"
                        ],
                        "name": "J. Feldman",
                        "slug": "J.-Feldman",
                        "structuredName": {
                            "firstName": "Jon",
                            "lastName": "Feldman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Feldman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721860"
                        ],
                        "name": "M. Wainwright",
                        "slug": "M.-Wainwright",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Wainwright",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wainwright"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743286"
                        ],
                        "name": "D. Karger",
                        "slug": "D.-Karger",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Karger",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Karger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Since its introduction [73, 75], the performance of this LP relaxation has been extensively studied [e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "[75] for decoding low-density parity check (LDPC) codes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "17) have studied in past and ongoing work by various authors, including the special cases of {0, 1}-quadratic programs [102], metric labeling with Potts models [132, 45], error-control coding problems [73, 75, 234, 223, 47, 59], independent set problems [177, 202], and various types of matching problems [13, 113, 201]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Not surprisingly, given the role of the constraint set L(G) in the Bethe variational problem, there are close connections between LP decoding and standard iterative algorithms like sum-product decoding [73, 133, 75]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "It plays a key role in the error-control decoding problem [75], studied intensively in the coding and information theory communities."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3120399,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d3f2ff0a5e52c5b24c3ed956b0e5d4e358377f45",
            "isKey": false,
            "numCitedBy": 502,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method is given for performing approximate maximum-likelihood (ML) decoding of an arbitrary binary linear code based on observations received from any discrete memoryless symmetric channel. The decoding algorithm is based on a linear programming (LP) relaxation that is defined by a factor graph or parity-check representation of the code. The resulting \"LP decoder\" generalizes our previous work on turbo-like codes. A precise combinatorial characterization of when the LP decoder succeeds is provided, based on pseudocodewords associated with the factor graph. Our definition of a pseudocodeword unifies other such notions known for iterative algorithms, including \"stopping sets,\" \"irreducible closed walks,\" \"trellis cycles,\" \"deviation sets,\" and \"graph covers.\" The fractional distance d/sub frac/ of a code is introduced, which is a lower bound on the classical distance. It is shown that the efficient LP decoder will correct up to /spl lceil/d/sub frac//2/spl rceil/-1 errors and that there are codes with d/sub frac/=/spl Omega/(n/sup 1-/spl epsi//). An efficient algorithm to compute the fractional distance is presented. Experimental evidence shows a similar performance on low-density parity-check (LDPC) codes between LP decoding and the min-sum and sum-product algorithms. Methods for tightening the LP relaxation to improve performance are also provided."
            },
            "slug": "Using-linear-programming-to-Decode-Binary-linear-Feldman-Wainwright",
            "title": {
                "fragments": [],
                "text": "Using linear programming to Decode Binary linear codes"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The definition of a pseudocodeword unifies other such notions known for iterative algorithms, including \"stopping sets,\" \"irreducible closed walks,\" \"trellis cycles,\" \"deviation sets,\" and \"graph covers,\" which is a lower bound on the classical distance."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Information Theory"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1900102"
                        ],
                        "name": "G. Ziegler",
                        "slug": "G.-Ziegler",
                        "structuredName": {
                            "firstName": "G\u00fcnter",
                            "lastName": "Ziegler",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Ziegler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "A classical technique for computing such projections is Fourier-Motzkin elimination [22, 266]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 117286447,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ace27f05cc915147c53dc899c8277f1870bb6f1f",
            "isKey": false,
            "numCitedBy": 3231,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "Based on a graduate course given at the Technische Universitat, Berlin, these lectures present a wealth of material on the modern theory of convex polytopes. The clear and straightforward presentation features many illustrations, and provides complete proofs for most theorems. The material requires only linear algebra as a prerequisite, but takes the reader quickly from the basics to topics of recent research, including a number of unanswered questions. The lectures - introduce the basic facts about polytopes, with an emphasis on the methods that yield the results (Fourier-Motzkin elimination, Schlegel diagrams, shellability, Gale transforms, and oriented matroids) - discuss important examples and elegant constructions (cyclic and neighborly polytopes, zonotopes, Minkowski sums, permutahedra and associhedra, fiber polytopes, and the Lawrence construction) - show the excitement of current work in the field (Kalai's new diameter bounds, construction of non-rational polytopes, the Bohne-Dress tiling theorem, the upper-bound theorem), and nonextendable shellings) They should provide interesting and enjoyable reading for researchers as well as students."
            },
            "slug": "Lectures-on-Polytopes-Ziegler",
            "title": {
                "fragments": [],
                "text": "Lectures on Polytopes"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692786"
                        ],
                        "name": "H. Sherali",
                        "slug": "H.-Sherali",
                        "structuredName": {
                            "firstName": "Hanif",
                            "lastName": "Sherali",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sherali"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3201651"
                        ],
                        "name": "Warren P. Adams",
                        "slug": "Warren-P.-Adams",
                        "structuredName": {
                            "firstName": "Warren",
                            "lastName": "Adams",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Warren P. Adams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 93
                            }
                        ],
                        "text": "In the binary f0; 1g case, this sequence has been proposed previously by various researchers [50, 98], although without the connections to the underlying graphical structure."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 186
                            }
                        ],
                        "text": "Remarks: (a) The sequences SDEF(Kt;n) and LOCAL(Kt;n) de ned by the complete hypergraphs Kt;n (for t = 1; : : : ; n) correspond to particular cases of the Lasserre [64] and SheraliAdams [98] sequences of relaxations respectively."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11969019,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "b84315788e08e5a81617ec197cbe340e37914196",
            "isKey": false,
            "numCitedBy": 699,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper a reformulation technique is presented that takes a given linear zero-one programming problem, converts it into a zero-one polynomial programming problem, and then relinearizes it into an extended linear program. It is shown that the strength of the resulting reformulation depends on the degree of the terms used to produce the polynomial program at the intermediate step of this method. In fact, as this degree varies from one up to the number of variables in the problem, a hierarchy of sharper representations is obtained with the final relaxation representing the convex hull of feasible solutions. The reformulation technique readily extends to produce a similar hierarchy of linear relaxations for zero-one polynomial programming problems. A characterization of the convex hull in the original variable space is also available through a projection process. The structure of this convex hull characterization (or its other relaxations) can be exploited to generate strong or facetial valid inequalities through appropriate surrogates in a computational framework. The surrogation process can also be used to study various classes of facets for different combinatorial optimization problems. Some examples are given to illustrate this point. 1. Introduction. This paper describes a technique for generating a hierarchy of polyhedral representations for linear and polynomial zero-one programming problems."
            },
            "slug": "A-Hierarchy-of-Relaxations-Between-the-Continuous-Sherali-Adams",
            "title": {
                "fragments": [],
                "text": "A Hierarchy of Relaxations Between the Continuous and Convex Hull Representations for Zero-One Programming Problems"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "It is shown that the strength of the resulting reformulation depends on the degree of the terms used to produce the polynomial program at the intermediate step of this method, and a hierarchy of sharper representations is obtained with the final relaxation representing the convex hull of feasible solutions."
            },
            "venue": {
                "fragments": [],
                "text": "SIAM J. Discret. Math."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731977"
                        ],
                        "name": "B. Bollob\u00e1s",
                        "slug": "B.-Bollob\u00e1s",
                        "structuredName": {
                            "firstName": "B\u00e9la",
                            "lastName": "Bollob\u00e1s",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Bollob\u00e1s"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Here we collect some basic definitions and results on graphs and hypergraphs; see the standard books [15, 31, 32] for further background."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 120529008,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5b2d23a567b117ffe32dad3907a473e328127ff2",
            "isKey": false,
            "numCitedBy": 2485,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This text is an in-depth account of graph theory. It reflects the current state of the subject and emphasizes connections with other branches of pure mathematics. Recognizing that graph theory is one of several courses competing for the attention of a student, the book contains descriptive passages designed to convey the flavour of the subject and to arouse interest. In addition to a modern treatment of the classical areas of graph theory such as colouring, matching, extremal theory, and algebraic graph theory, the book presents an account of newer topics, including: Szemer'edi's Regularity Lemma and its use; Shelah's extension of the Hales-Jewett Theorem; the precise nature of the phase transition in a random graph process; the connection between electrical networks and random walks on graphs; and the Tutte polynomial and its cousins in knot theory."
            },
            "slug": "Modern-Graph-Theory-Bollob\u00e1s",
            "title": {
                "fragments": [],
                "text": "Modern Graph Theory"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This book presents an account of newer topics, including Szemer'edi's Regularity Lemma and its use; Shelah's extension of the Hales-Jewett Theorem; the precise nature of the phase transition in a random graph process; the connection between electrical networks and random walks on graphs; and the Tutte polynomial and its cousins in knot theory."
            },
            "venue": {
                "fragments": [],
                "text": "Graduate Texts in Mathematics"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143930409"
                        ],
                        "name": "M. Chertkov",
                        "slug": "M.-Chertkov",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Chertkov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Chertkov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145833214"
                        ],
                        "name": "V. Chernyak",
                        "slug": "V.-Chernyak",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Chernyak",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Chernyak"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In some cases, accounting for a small set of significant loop corrections may lead to improved approximations to the partition function [97], or more accurate approximations of the marginals for LDPC codes [49]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6621405,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4f1f55fb8d7eaf8c75310efa0a0ee2342af6142f",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 76,
            "paperAbstract": {
                "fragments": [],
                "text": "We illustrate the utility of the recently developed loop calculus (1), (2) for improving the Belief Propagation (BP) algorithm. If the algorithm that minimizes the Bethe free energy fails we modify the free energy by accounting for a critical loop in a graphical representation of the code. The log-likelihood specific critical loop is found by means of the loop calculus. The general method is tested using an example of the Linear Programming (LP) decoding, that can be viewed as a special limit of the BP decoding. Considering the (155, 64, 20) code that performs over Additive-White-Gaussian channel we show that the loop calculus improves the LP decoding and corrects all previously found dangerous configurations of log-likel ihoods related to pseudo-codewords with low effective distance, thus reducing the code's error-floor. Belief Propagation (BP) constitutes an efficient approxi- mation, as well as an algorithm, that applies to many infer- ence problems in statistical physics (3), (4), (5), informa tion"
            },
            "slug": "Loop-Calculus-Helps-to-Improve-Belief-Propagation-Chertkov-Chernyak",
            "title": {
                "fragments": [],
                "text": "Loop Calculus Helps to Improve Belief Propagation and Linear Programming Decodings of Low-Density-Parity-Check Codes"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is shown that the loop calculus improves the LP decoding and corrects all previously found dangerous configurations of log-likel ihoods related to pseudo-codewords with low effective distance, thus reducing the code's error-floor."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081362"
                        ],
                        "name": "A. Yuille",
                        "slug": "A.-Yuille",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Yuille",
                            "middleNames": [
                                "Loddon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yuille"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "A parallel line of work [265, 249, 108] has explored alternatives to sum-product that are guaranteed to converge, albeit at the price of increased computational cost."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Another possibility would be to adapt other double-loop algorithms [265, 249, 108, 107], originally developed for the ordinary Bethe/Kikuchi problems, to solve these convex minimization problems; see Hazan and Shashua [105] for some recent work along these lines."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "63), possibly along the lines of convergent algorithms developed for the ordinary Bethe variational problem [265, 249, 108]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "[263, 264] and further explored by various researchers [184, 163, 108, 235, 265], that improves both components simultaneously."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 782136,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "974fee9c3836d91aee9492c07379898ccc2c3a85",
            "isKey": true,
            "numCitedBy": 235,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "This article introduces a class of discrete iterative algorithms that are provably convergent alternatives to belief propagation (BP) and generalized belief propagation (GBP). Our work builds on recent results by Yedidia, Freeman, and Weiss (2000), who showed that the fixed points of BP and GBP algorithms correspond to extrema of the Bethe and Kikuchi free energies, respectively. We obtain two algorithms by applying CCCP to the Bethe and Kikuchi free energies, respectively (CCCP is a procedure, introduced here, for obtaining discrete iterative algorithms by decomposing a cost function into a concave and a convex part). We implement our CCCP algorithms on two- and three-dimensional spin glasses and compare their results to BP and GBP. Our simulations show that the CCCP algorithms are stable and converge very quickly (the speed of CCCP is similar to that of BP and GBP). Unlike CCCP, BP will often not converge for these problems (GBP usually, but not always, converges). The results found by CCCP applied to the Bethe or Kikuchi free energies are equivalent, or slightly better than, those found by BP or GBP, respectively (when BP and GBP converge). Note that for these, and other problems, BP and GBP give very accurate results (see Yedidia et al., 2000), and failure to converge is their major error mode. Finally, we point out that our algorithms have a large range of inference and learning applications."
            },
            "slug": "CCCP-Algorithms-to-Minimize-the-Bethe-and-Kikuchi-Yuille",
            "title": {
                "fragments": [],
                "text": "CCCP Algorithms to Minimize the Bethe and Kikuchi Free Energies: Convergent Alternatives to Belief Propagation"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A class of discrete iterative algorithms that are provably convergent alternatives to believe propagation (BP) and generalized belief propagation (GBP) and are pointed out that have a large range of inference and learning applications."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102797092"
                        ],
                        "name": "P. W. Kasteleyn",
                        "slug": "P.-W.-Kasteleyn",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Kasteleyn",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. W. Kasteleyn"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 212
                            }
                        ],
                        "text": ", Ising models of the form p\u03b8(x) \u221d exp{ \u2211 (s,t)\u2208E \u03b8stxsxt}), then it is possible to compute the cumulant function A(\u03b8) exactly, using clever combinatorial reductions due independently to Fisher [78] and Kastelyn [129]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 120602846,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "998fecaf9aa0d0de3e64161c422591ca9cf7daa5",
            "isKey": false,
            "numCitedBy": 717,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "After the introduction of the concept of lattice graph and a brief discussion of its role in the theory of the Ising model, a related combinatorial problem is discussed, namely that of the statistics of non\u2010overlapping dimers, each occupying two neighboring sites of a lattice graph. It is shown that the configurational partition function of this system can be expressed in terms of a Pfaffian, and hence calculated explicitly, if the lattice graph is planar and if the dimers occupy all lattice sites. By the examples of the quadratic and the hexagonal lattice, it is found that the dimer system may show a phase transition similar to that of a two\u2010dimensional Ising model, or one of a different nature, or no transition at all, depending on the activities of various classes of bonds. The Ising problem is then shown to be equivalent to a generalized dimer problem, and a rederivation, of Onsager's expression for the Ising partition function of a rectangular lattice graph is sketched on the basis of this equivalence."
            },
            "slug": "Dimer-Statistics-and-Phase-Transitions-Kasteleyn",
            "title": {
                "fragments": [],
                "text": "Dimer Statistics and Phase Transitions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1963
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145500409"
                        ],
                        "name": "G. Shafer",
                        "slug": "G.-Shafer",
                        "structuredName": {
                            "firstName": "Glenn",
                            "lastName": "Shafer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Shafer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707788"
                        ],
                        "name": "P. P. Shenoy",
                        "slug": "P.-P.-Shenoy",
                        "structuredName": {
                            "firstName": "Prakash",
                            "lastName": "Shenoy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. P. Shenoy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 104
                            }
                        ],
                        "text": "More generally, updates of this form apply to arbitrary commutative semirings on tree-structured graphs [106, 97, 29, 1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 535323,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ac789d8e373cbb3260b2881d66fe00789adf291f",
            "isKey": false,
            "numCitedBy": 264,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we give a simple account of local computation of marginal probabilities when the joint probability distribution is given in factored form and the sets of variables involved in the factors form a hypertree. Previous expositions of such local computation have emphasized conditional probability. We believe this emphasis is misplaced. What is essential to local computation is a factorization. It is not essential that this factorization be interpreted in terms of conditional probabilities. The account given here avoids the divisions required by conditional probabilities and generalizes readily to alternative measures of subjective probability, such as Dempster-Shafer or Spohnian belief functions."
            },
            "slug": "Probability-propagation-Shafer-Shenoy",
            "title": {
                "fragments": [],
                "text": "Probability propagation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The account given here avoids the divisions required by conditional probabilities and generalizes readily to alternative measures of subjective probability, such as Dempster-Shafer or Spohnian belief functions."
            },
            "venue": {
                "fragments": [],
                "text": "Annals of Mathematics and Artificial Intelligence"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40486307"
                        ],
                        "name": "Bert Huang",
                        "slug": "Bert-Huang",
                        "structuredName": {
                            "firstName": "Bert",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bert Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768120"
                        ],
                        "name": "T. Jebara",
                        "slug": "T.-Jebara",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Jebara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jebara"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "A line of recent research has established close links between the LP relaxation and the ordinary max-product algorithm, including the case of bipartite weighted matching [13], bipartite weighted b-matching [113], weighted matching on general graphs [201], and weighted b-matching on general graphs [12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "17) have studied in past and ongoing work by various authors, including the special cases of {0, 1}-quadratic programs [102], metric labeling with Potts models [132, 45], error-control coding problems [73, 75, 234, 223, 47, 59], independent set problems [177, 202], and various types of matching problems [13, 113, 201]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8874978,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "99ec51f5b7b7bcafebc3977cd5b9f450268dafb1",
            "isKey": false,
            "numCitedBy": 111,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We formulate the weighted b-matching objective function as a probability distribution function and prove that belief propagation (BP) on its graphical model converges to the optimum. Standard BP on our graphical model cannot be computed in polynomial time, but we introduce an algebraic method to circumvent the combinatorial message updates. Empirically, the resulting algorithm is on average faster than popular combinatorial implementations, while still scaling at the same asymptotic rate of O(bn). Furthermore, the algorithm shows promising performance in machine learning applications."
            },
            "slug": "Loopy-Belief-Propagation-for-Bipartite-Maximum-Huang-Jebara",
            "title": {
                "fragments": [],
                "text": "Loopy Belief Propagation for Bipartite Maximum Weight b-Matching"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "The weighted b-matching objective function is formulated as a probability distribution function and it is proved that belief propagation on its graphical model converges to the optimum and shows promising performance in machine learning applications."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4141450"
                        ],
                        "name": "J. Lasserre",
                        "slug": "J.-Lasserre",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Lasserre",
                            "middleNames": [
                                "Bernard"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lasserre"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We now describe the Lasserre sequence [145, 147] of semidefinite outer bounds on the marginal polytope M(G)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16740871,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a6430d5de0a3aea562052151efec5ff53d83a10f",
            "isKey": false,
            "numCitedBy": 2326,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of finding the unconstrained global minimum of a real-valued polynomial p(x): {\\mathbb{R}}^n\\to {\\mathbb{R}}$, as well as the global minimum of p(x), in a compact set K defined by polynomial inequalities. It is shown that this problem reduces to solving an (often finite) sequence of convex linear matrix inequality (LMI) problems. A notion of Karush--Kuhn--Tucker polynomials is introduced in a global optimality condition. Some illustrative examples are provided."
            },
            "slug": "Global-Optimization-with-Polynomials-and-the-of-Lasserre",
            "title": {
                "fragments": [],
                "text": "Global Optimization with Polynomials and the Problem of Moments"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "It is shown that the problem of finding the unconstrained global minimum of a real-valued polynomial p(x): R n to R, in a compact set K defined byPolynomial inequalities reduces to solving an (often finite) sequence of convex linear matrix inequality (LMI) problems."
            },
            "venue": {
                "fragments": [],
                "text": "SIAM J. Optim."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3072213"
                        ],
                        "name": "J. Besag",
                        "slug": "J.-Besag",
                        "structuredName": {
                            "firstName": "Julian",
                            "lastName": "Besag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Besag"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Moreover, the Ising model and variations on it have been used in image processing and spatial statistics [25, 86, 98], where Xs might correspond to pixel values in a black-and-white image."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": ", 258, 104, 55, 86], as well as in spatial statistics more generally [23, 24, 197, 25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15128952,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "47865b56fee61d9c9ff477f7c79f090cc6663d3a",
            "isKey": false,
            "numCitedBy": 4634,
            "numCiting": 79,
            "paperAbstract": {
                "fragments": [],
                "text": "may 7th, 1986, Professor A. F. M. Smith in the Chair] SUMMARY A continuous two-dimensional region is partitioned into a fine rectangular array of sites or \"pixels\", each pixel having a particular \"colour\" belonging to a prescribed finite set. The true colouring of the region is unknown but, associated with each pixel, there is a possibly multivariate record which conveys imperfect information about its colour according to a known statistical model. The aim is to reconstruct the true scene, with the additional knowledge that pixels close together tend to have the same or similar colours. In this paper, it is assumed that the local characteristics of the true scene can be represented by a nondegenerate Markov random field. Such information can be combined with the records by Bayes' theorem and the true scene can be estimated according to standard criteria. However, the computational burden is enormous and the reconstruction may reflect undesirable largescale properties of the random field. Thus, a simple, iterative method of reconstruction is proposed, which does not depend on these large-scale characteristics. The method is illustrated by computer simulations in which the original scene is not directly related to the assumed random field. Some complications, including parameter estimation, are discussed. Potential applications are mentioned briefly."
            },
            "slug": "On-the-Statistical-Analysis-of-Dirty-Pictures-Besag",
            "title": {
                "fragments": [],
                "text": "On the Statistical Analysis of Dirty Pictures"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3806712"
                        ],
                        "name": "C. Daskalakis",
                        "slug": "C.-Daskalakis",
                        "structuredName": {
                            "firstName": "Constantinos",
                            "lastName": "Daskalakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Daskalakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718469"
                        ],
                        "name": "A. Dimakis",
                        "slug": "A.-Dimakis",
                        "structuredName": {
                            "firstName": "Alexandros",
                            "lastName": "Dimakis",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dimakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47546648"
                        ],
                        "name": "R. Karp",
                        "slug": "R.-Karp",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Karp",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Karp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721860"
                        ],
                        "name": "M. Wainwright",
                        "slug": "M.-Wainwright",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Wainwright",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wainwright"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "17) have studied in past and ongoing work by various authors, including the special cases of {0, 1}-quadratic programs [102], metric labeling with Potts models [132, 45], error-control coding problems [73, 75, 234, 223, 47, 59], independent set problems [177, 202], and various types of matching problems [13, 113, 201]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2209908,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0e6c5f313ddf94367ffd08bc864cfed229a9fe86",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "We initiate the probabilistic analysis of linear programming (LP) decoding of low-density parity-check (LDPC) codes. Specifically, we show that for a random LDPC code ensemble, the linear programming decoder of Feldman succeeds in correcting a constant fraction of errors with high probability. The fraction of correctable errors guaranteed by our analysis surpasses previous nonasymptotic results for LDPC codes, and in particular, exceeds the best previous finite-length result on LP decoding by a factor greater than ten. This improvement stems in part from our analysis of probabilistic bit-flipping channels, as opposed to adversarial channels. At the core of our analysis is a novel combinatorial characterization of LP decoding success, based on the notion of a flow on the Tanner graph of the code. An interesting by-product of our analysis is to establish the existence of ldquoprobabilistic expansionrdquo in random bipartite graphs, in which one requires only that almost every (as opposed to every) set of a certain size expands, for sets much larger than in the classical worst case setting."
            },
            "slug": "Probabilistic-Analysis-of-Linear-Programming-Daskalakis-Dimakis",
            "title": {
                "fragments": [],
                "text": "Probabilistic Analysis of Linear Programming Decoding"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "The probabilistic analysis of linear programming (LP) decoding of low-density parity-check (LDPC) codes is initiated, showing that for a random LDPC code ensemble, the linear programming decoder of Feldman succeeds in correcting a constant fraction of errors with high probability."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Information Theory"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786843"
                        ],
                        "name": "A. Globerson",
                        "slug": "A.-Globerson",
                        "structuredName": {
                            "firstName": "Amir",
                            "lastName": "Globerson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Globerson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35132120"
                        ],
                        "name": "T. Jaakkola",
                        "slug": "T.-Jaakkola",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Jaakkola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jaakkola"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "5), including subgradient methods [73, 136], dual coordinate ascent methods [94, 234], annealing-type methods [121, 246], proximal optimization schemes [193], and adaptive LP solvers [223]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15800479,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5e11fc1e66c1f0a1b514f4d403da500a9125329d",
            "isKey": false,
            "numCitedBy": 370,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel message passing algorithm for approximating the MAP problem in graphical models. The algorithm is similar in structure to max-product but unlike max-product it always converges, and can be proven to find the exact MAP solution in various settings. The algorithm is derived via block coordinate descent in a dual of the LP relaxation of MAP, but does not require any tunable parameters such as step size or tree weights. We also describe a generalization of the method to cluster based potentials. The new method is tested on synthetic and real-world problems, and compares favorably with previous approaches."
            },
            "slug": "Fixing-Max-Product:-Convergent-Message-Passing-for-Globerson-Jaakkola",
            "title": {
                "fragments": [],
                "text": "Fixing Max-Product: Convergent Message Passing Algorithms for MAP LP-Relaxations"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A novel message passing algorithm for approximating the MAP problem in graphical models that is derived via block coordinate descent in a dual of the LP relaxation of MAP, but does not require any tunable parameters such as step size or tree weights."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2571487"
                        ],
                        "name": "C. Yanover",
                        "slug": "C.-Yanover",
                        "structuredName": {
                            "firstName": "Chen",
                            "lastName": "Yanover",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Yanover"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398554769"
                        ],
                        "name": "O. Schueler\u2010Furman",
                        "slug": "O.-Schueler\u2010Furman",
                        "structuredName": {
                            "firstName": "Ora",
                            "lastName": "Schueler\u2010Furman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Schueler\u2010Furman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30400079"
                        ],
                        "name": "Yair Weiss",
                        "slug": "Yair-Weiss",
                        "structuredName": {
                            "firstName": "Yair",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yair Weiss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7472042,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f3f1522e54e8cdb94d8fec0f0bc29938ce6084fb",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "Side-chain prediction is an important subproblem of the general protein folding problem. Despite much progress in side-chain prediction, performance is far from satisfactory. As an example, the ROSETTA program that uses simulated annealing to select the minimum energy conformations, correctly predicts the first two side-chain angles for approximately 72% of the buried residues in a standard data set. Is further improvement more likely to come from better search methods, or from better energy functions? Given that exact minimization of the energy is NP hard, it is difficult to get a systematic answer to this question. In this paper, we present a novel search method and a novel method for learning energy functions from training data that are both based on Tree Reweighted Belief Propagation (TRBP). We find that TRBP can obtain the global optimum of the ROSETTA energy function in a few minutes of computation for approximately 85% of the proteins in a standard benchmark set. TRBP can also effectively bound the partition function which enables using the Conditional Random Fields (CRF) framework for learning. Interestingly, finding the global minimum does not significantly improve side-chain prediction for an energy function based on ROSETTA's default energy terms (less than 0:1%), while learning new weights gives a significant boost from 72% to 78%. Using a recently modified ROSETTA energy function with a softer Lennard-Jones repulsive term, the global optimum does improve prediction accuracy from 77% to 78%. Here again, learning new weights improves side-chain modeling even further to 80%. Finally, the highest accuracy (82.6%) is obtained using an extended rotamer library and CRF learned weights. Our results suggest that combining machine learning with approximate inference can improve the state-of-the-art in side-chain prediction."
            },
            "slug": "Minimizing-and-Learning-Energy-Functions-for-Yanover-Schueler\u2010Furman",
            "title": {
                "fragments": [],
                "text": "Minimizing and Learning Energy Functions for Side-Chain Prediction"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A novel search method and a novel method for learning energy functions from training data that are both based on Tree Reweighted Belief Propagation are presented, which suggest that combining machine learning with approximate inference can improve the state-of-the-art in side-chain prediction."
            },
            "venue": {
                "fragments": [],
                "text": "RECOMB"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40411909"
                        ],
                        "name": "Jon D. McAuliffe",
                        "slug": "Jon-D.-McAuliffe",
                        "structuredName": {
                            "firstName": "Jon",
                            "lastName": "McAuliffe",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jon D. McAuliffe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2514969"
                        ],
                        "name": "L. Pachter",
                        "slug": "L.-Pachter",
                        "structuredName": {
                            "firstName": "Lior",
                            "lastName": "Pachter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Pachter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 108
                            }
                        ],
                        "text": "This model has proven useful for gene- nding in the human genome based on data for multiple primate species [74]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 133
                            }
                        ],
                        "text": "Figure 2(a) shows a hidden Markov phylogeny, an HMM in which the observations are sets of nucleotides related by a phylogenetic tree [74, 86, 99]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5947858,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "d93cacf6c7bddb1a38a530fe601d34dad829059d",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "MOTIVATION\nPhylogenetic shadowing is a comparative genomics principle that allows for the discovery of conserved regions in sequences from multiple closely related organisms. We develop a formal probabilistic framework for combining phylogenetic shadowing with feature-based functional annotation methods. The resulting model, a generalized hidden Markov phylogeny (GHMP), applies to a variety of situations where functional regions are to be inferred from evolutionary constraints.\n\n\nRESULTS\nWe show how GHMPs can be used to predict complete shared gene structures in multiple primate sequences. We also describe shadower, our implementation of such a prediction system. We find that shadower outperforms previously reported ab initio gene finders, including comparative human-mouse approaches, on a small sample of diverse exonic regions. Finally, we report on an empirical analysis of shadower's performance which reveals that as few as five well-chosen species may suffice to attain maximal sensitivity and specificity in exon demarcation.\n\n\nAVAILABILITY\nA Web server is available at http://bonaire.lbl.gov/shadower"
            },
            "slug": "Multiple-sequence-functional-annotation-and-the-McAuliffe-Pachter",
            "title": {
                "fragments": [],
                "text": "Multiple-sequence functional annotation and the generalized hidden Markov phylogeny"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A formal probabilistic framework for combining phylogenetic shadowing with feature-based functional annotation methods is developed and a generalized hidden Markov phylogeny (GHMP) is shown how GHMPs can be used to predict complete shared gene structures in multiple primate sequences."
            },
            "venue": {
                "fragments": [],
                "text": "Bioinform."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723150"
                        ],
                        "name": "R. McEliece",
                        "slug": "R.-McEliece",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "McEliece",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. McEliece"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40132164"
                        ],
                        "name": "M. Yildirim",
                        "slug": "M.-Yildirim",
                        "structuredName": {
                            "firstName": "Muhammed",
                            "lastName": "Yildirim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Yildirim"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "4 A convenient graphical representation of a hypergraph is in terms of a diagram of its hyperedges, with directed edges representing the inclusion relations; such a representation is known as a poset diagram [163, 184, 216]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "[263, 264] and further explored by various researchers [184, 163, 108, 235, 265], that improves both components simultaneously."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Further details on different variants of generalized sumproduct updates can be found in various papers [263, 264, 184, 163, 125]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "However, with the exception of trees and other special cases [184, 163, 107], the Bethe variational problem is usually a nonconvex problem, in that HBethe fails to be concave."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Various other researchers [107, 163, 184, 185] also discuss the choice edge/clique weights in Bethe/Kikuchi approximations, and its consequences for convexity."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In contrast, with the exception of certain special cases [107, 184, 185, 163], Kikuchi and other hypergraph-based entropy approximations are typically not convex."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 31458417,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a74cafb36ebd025f56aa30cf0631f9b65a2bc68e",
            "isKey": true,
            "numCitedBy": 56,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, which is based on the important recent work of Yedidia, Freeman, and Weiss, we present a generalized form of belief propagation, viz. belief propagation on a partially ordered set (PBP). PBP is an iterative message-passing algorithm for solving, either exactly or approximately, the marginalized product density problem, which is a general computational problem of wide applicability. We will show that PBP can be thought of as an algorithm for minimizing a certain \u201cfree energy\u201d function, and by exploiting this interpretation, we will exhibit a one-to-one correspondence between the fixed points of PBP and the stationary points of the free energy."
            },
            "slug": "Belief-Propagation-on-Partially-Ordered-Sets-McEliece-Yildirim",
            "title": {
                "fragments": [],
                "text": "Belief Propagation on Partially Ordered Sets"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that PBP can be thought of as an algorithm for minimizing a certain \u201cfree energy\u201d function, and by exploiting this interpretation, a one-to-one correspondence between the fixed points of PBP and the stationary points of the free energy is exhibited."
            },
            "venue": {
                "fragments": [],
                "text": "Mathematical Systems Theory in Biology, Communications, Computation, and Finance"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746662"
                        ],
                        "name": "D. Sontag",
                        "slug": "D.-Sontag",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Sontag",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Sontag"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35132120"
                        ],
                        "name": "T. Jaakkola",
                        "slug": "T.-Jaakkola",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Jaakkola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jaakkola"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2185784,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5bb686506dd11caa959244038e134cf16c8807be",
            "isKey": false,
            "numCitedBy": 156,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We give a new class of outer bounds on the marginal polytope, and propose a cutting-plane algorithm for efficiently optimizing over these constraints. When combined with a concave upper bound on the entropy, this gives a new variational inference algorithm for probabilistic inference in discrete Markov Random Fields (MRFs). Valid constraints on the marginal polytope are derived through a series of projections onto the cut polytope. As a result, we obtain tighter upper bounds on the log-partition function. We also show empirically that the approximations of the marginals are significantly more accurate when using the tighter outer bounds. Finally, we demonstrate the advantage of the new constraints for finding the MAP assignment in protein structure prediction."
            },
            "slug": "New-Outer-Bounds-on-the-Marginal-Polytope-Sontag-Jaakkola",
            "title": {
                "fragments": [],
                "text": "New Outer Bounds on the Marginal Polytope"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "A new class of outer bounds on the marginal polytope is given, and a cutting-plane algorithm for efficiently optimizing over these constraints is proposed, which gives a new variational inference algorithm for probabilistic inference in discrete Markov Random Fields (MRFs)."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692786"
                        ],
                        "name": "H. Sherali",
                        "slug": "H.-Sherali",
                        "structuredName": {
                            "firstName": "Hanif",
                            "lastName": "Sherali",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sherali"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3201651"
                        ],
                        "name": "Warren P. Adams",
                        "slug": "Warren-P.-Adams",
                        "structuredName": {
                            "firstName": "Warren",
                            "lastName": "Adams",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Warren P. Adams"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120682807,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "4af6c573cdc78e4f05c129d8902b776c466611ff",
            "isKey": false,
            "numCitedBy": 707,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper a reformulation technique is presented that takes a given linear zero-one programming problem, converts it into a zero-one polynomial programming problem, and then relinearizes it into an extended linear program. It is shown that the strength of the resulting reformulation depends on the degree of the terms used to produce the polynomial program at the intermediate step of this method. In fact, as this degree varies from one up to the number of variables in the problem, a hierarchy of sharper representations is obtained with the final relaxation representing the convex hull of feasible solutions. The reformulation technique readily extends to produce a similar hierarchy of linear relaxations for zero-one polynomial programming problems. A characterization of the convex hull in the original variable space is also available through a projection process. The structure of this convex hull characterization (or its other relaxations) can be exploited to generate strong or facetial valid inequaliti..."
            },
            "slug": "A-hierarchy-of-relaxation-between-the-continuous-Sherali-Adams",
            "title": {
                "fragments": [],
                "text": "A hierarchy of relaxation between the continuous and convex hull representations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2881822"
                        ],
                        "name": "J. S. Pedersen",
                        "slug": "J.-S.-Pedersen",
                        "structuredName": {
                            "firstName": "Jakob",
                            "lastName": "Pedersen",
                            "middleNames": [
                                "Skou"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. S. Pedersen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143631093"
                        ],
                        "name": "J. Hein",
                        "slug": "J.-Hein",
                        "structuredName": {
                            "firstName": "Jotun",
                            "lastName": "Hein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "5(a) shows a hidden Markov phylogeny, an HMM in which the observations are sets of nucleotides related by a phylogenetic tree [162, 189, 213]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2643452,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "9c1fc52f779b8478cafd65427480acc9ba451b17",
            "isKey": false,
            "numCitedBy": 126,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "MOTIVATION\nA growing number of genomes are sequenced. The differences in evolutionary pattern between functional regions can thus be observed genome-wide in a whole set of organisms. The diverse evolutionary pattern of different functional regions can be exploited in the process of genomic annotation. The modelling of evolution by the existing comparative gene finders leaves room for improvement.\n\n\nRESULTS\nA probabilistic model of both genome structure and evolution is designed. This type of model is called an Evolutionary Hidden Markov Model (EHMM), being composed of an HMM and a set of region-specific evolutionary models based on a phylogenetic tree. All parameters can be estimated by maximum likelihood, including the phylogenetic tree. It can handle any number of aligned genomes, using their phylogenetic tree to model the evolutionary correlations. The time complexity of all algorithms used for handling the model are linear in alignment length and genome number. The model is applied to the problem of gene finding. The benefit of modelling sequence evolution is demonstrated both in a range of simulations and on a set of orthologous human/mouse gene pairs.\n\n\nAVAILABILITY\nFree availability over the Internet on www server: http://www.birc.dk/Software/evogene."
            },
            "slug": "Gene-finding-with-a-hidden-Markov-model-of-genome-Pedersen-Hein",
            "title": {
                "fragments": [],
                "text": "Gene finding with a hidden Markov model of genome structure and evolution"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A probabilistic model of both genome structure and evolution, called an Evolutionary Hidden Markov Model (EHMM), being composed of an HMM and a set of region-specific evolutionary models based on a phylogenetic tree."
            },
            "venue": {
                "fragments": [],
                "text": "Bioinform."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66269502"
                        ],
                        "name": "R. Baxter",
                        "slug": "R.-Baxter",
                        "structuredName": {
                            "firstName": "Rodney",
                            "lastName": "Baxter",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Baxter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "An example is the ferromagnetic Ising model defined on the complete graph Km with suitably rescaled parameters \u03b8st > 0 for all (s, t) \u2208 E; see Baxter [11] for further discussion of such exact cases."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Despite these issues, the naive mean field approximation becomes asymptotically exact for certain types of models as the number of nodes m grows to infinity [11, 262]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The Ising model from statistical physics [11, 116] is a classical example of a graphical model in exponential form."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 117867044,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "5e6a4eda0a3d0d3a8c2864fd3afee4e67026bd40",
            "isKey": false,
            "numCitedBy": 5490,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "exactly solved models in statistical mechanics exactly solved models in statistical mechanics rodney j baxter exactly solved models in statistical mechanics exactly solved models in statistical mechanics flae exactly solved models in statistical mechanics dover books exactly solved models in statistical mechanics dover books exactly solved models in statistical mechanics dover books hatsutori in size 15 gvg7bzbookyo.qhigh literature cited r. j. baxter, exactly solved models in exactly solvable models in statistical mechanics exactly solved models in statistical mechanics dover books okazaki in size 24 vk19j3book.buncivy exactly solved models of statistical mechanics valerio nishizawa in size 11 b4zntdbookntey fukuda in size 13 33oloxbooknhuy yamada in size 19 x6g84ybook.zolay in honour of r j baxter\u2019s 75th birthday arxiv:1608.04899v2 statistical mechanics, threedimensionality and np beautiful models: 70 years of exactly solved quantum many exactly solved models in statistical mechanics (dover solved lattice models: 1944 2010 university of melbourne exactly solved models and beyond: a special issue in the statistical mechanics of the classical two-dimensional faculty of science, p. j. saf \u0301arik university in ko?sice? a one-dimensional statistical mechanics model with exact statistical mechanics department of physics and astronomy statistical mechanics principles and selected applications graph theory and statistical physics yaroslavvb chapter 4 methods of statistical mechanics ijs thermodynamics and an introduction to thermostatistics potts models and related problems in statistical mechanics methods of quantum field theory in statistical physics statistical mechanics: theory and molecular simulation exactly solvable su(n) mixed spin ladders springer statistical field theory : an introduction to exactly"
            },
            "slug": "Exactly-solved-models-in-statistical-mechanics-Baxter",
            "title": {
                "fragments": [],
                "text": "Exactly solved models in statistical mechanics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37210858"
                        ],
                        "name": "Charles Sutton",
                        "slug": "Charles-Sutton",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Sutton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charles Sutton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 81
                            }
                        ],
                        "text": ", 164]; some recent work has also studied adaptive schedules for message-passing [72, 221]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13978122,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "50ddc38dd719aeaa3f8ec6f737573ad04231cab2",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Belief propagation and its variants are popular methods for approximate inference, but their running time and even their convergence depend greatly on the schedule used to send the messages. Recently, dynamic update schedules have been shown to converge much faster on hard networks than static schedules, namely the residual BP schedule of Elidan et al. [2006]. But that RBP algorithm wastes message updates: many messages are computed solely to determine their priority, and are never actually performed. In this paper, we show that estimating the residual, rather than calculating it directly, leads to significant decreases in the number of messages required for convergence, and in the total running time. The residual is estimated using an upper bound based on recent work on message errors in BP. On both synthetic and real-world networks, this dramatically decreases the running time of BP, in some cases by a factor of five, without affecting the quality of the solution."
            },
            "slug": "Improved-Dynamic-Schedules-for-Belief-Propagation-Sutton-McCallum",
            "title": {
                "fragments": [],
                "text": "Improved Dynamic Schedules for Belief Propagation"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that estimating the residual, rather than calculating it directly, leads to significant decreases in the number of messages required for convergence, and in the total running time of BP, on both synthetic and real-world networks."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725557"
                        ],
                        "name": "L. Lov\u00e1sz",
                        "slug": "L.-Lov\u00e1sz",
                        "structuredName": {
                            "firstName": "L\u00e1szl\u00f3",
                            "lastName": "Lov\u00e1sz",
                            "middleNames": [
                                "Mikl\u00f3s"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Lov\u00e1sz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "What is the connection to the LP relaxation? It turns out that the problem instance that we have constructed\u2014in particular, with the hard core constraint \u03b3 = \u2212\u221e\u2014 generates an instance of super-modular maximization for binary variables [155]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 117358746,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b4821d2dee04f27e55112090c9029da30cc8b291",
            "isKey": false,
            "numCitedBy": 964,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "In \u201ccontinuous\u201d optimization convex functions play a central role. Besides elementary tools like differentiation, various methods for finding the minimum of a convex function constitute the main body of nonlinear optimization. But even linear programming may be viewed as the optimization of very special (linear) objective functions over very special convex domains (polyhedra). There are several reasons for this popularity of convex functions: \n \n \nConvex functions occur in many mathematical models in economy, engineering, and other sciencies. Convexity is a very natural property of various functions and domains occuring in such models; quite often the only non-trivial property which can be stated in general."
            },
            "slug": "Submodular-functions-and-convexity-Lov\u00e1sz",
            "title": {
                "fragments": [],
                "text": "Submodular functions and convexity"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "In \u201ccontinuous\u201d optimization convex functions play a central role, and linear programming may be viewed as the optimization of very special (linear) objective functions over very special convex domains (polyhedra)."
            },
            "venue": {
                "fragments": [],
                "text": "ISMP"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740137"
                        ],
                        "name": "A. Ihler",
                        "slug": "A.-Ihler",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Ihler",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ihler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31496901"
                        ],
                        "name": "John W. Fisher III",
                        "slug": "John-W.-Fisher-III",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Fisher III",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John W. Fisher III"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701607"
                        ],
                        "name": "A. Willsky",
                        "slug": "A.-Willsky",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Willsky",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Willsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[199] provide sufficient conditions for convergence, based on contraction arguments such as those used for ordinary sumproduct [225, 87, 175, 115]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In subsequent work, other researchers [115, 175, 199] have used various types of contraction arguments to obtain sharper conditions for convergence, or uniqueness of fixed points [106]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 978091,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "317a2def8dd3babd024c343ec85e3d80a3cf119c",
            "isKey": false,
            "numCitedBy": 324,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Belief propagation (BP) is an increasingly popular method of performing approximate inference on arbitrary graphical models. At times, even further approximations are required, whether due to quantization of the messages or model parameters, from other simplified message or model representations, or from stochastic approximation methods. The introduction of such errors into the BP message computations has the potential to affect the solution obtained adversely. We analyze the effect resulting from message approximation under two particular measures of error, and show bounds on the accumulation of errors in the system. This analysis leads to convergence conditions for traditional BP message passing, and both strict bounds and estimates of the resulting error in systems of approximate BP message passing."
            },
            "slug": "Loopy-Belief-Propagation:-Convergence-and-Effects-Ihler-Fisher",
            "title": {
                "fragments": [],
                "text": "Loopy Belief Propagation: Convergence and Effects of Message Errors"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This analysis leads to convergence conditions for traditional BP message Passing, and both strict bounds and estimates of the resulting error in systems of approximate BP message passing."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35206065"
                        ],
                        "name": "E. Jaynes",
                        "slug": "E.-Jaynes",
                        "structuredName": {
                            "firstName": "Edwin",
                            "lastName": "Jaynes",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Jaynes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "One way in which to motivate exponential family representations of graphical models is through the principle of maximum entropy [120, 259]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17870175,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "08b67692bc037eada8d3d7ce76cc70994e7c8116",
            "isKey": false,
            "numCitedBy": 10876,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Treatment of the predictive aspect of statistical mechanics as a form of statistical inference is extended to the density-matrix formalism and applied to a discussion of the relation between irreversibility and information loss. A principle of \"statistical complementarity\" is pointed out, according to which the empirically verifiable probabilities of statistical mechanics necessarily correspond to incomplete predictions. A preliminary discussion is given of the second law of thermodynamics and of a certain class of irreversible processes, in an approximation equivalent to that of the semiclassical theory of radiation."
            },
            "slug": "Information-Theory-and-Statistical-Mechanics-Jaynes",
            "title": {
                "fragments": [],
                "text": "Information Theory and Statistical Mechanics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1957
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701677"
                        ],
                        "name": "S. Sanghavi",
                        "slug": "S.-Sanghavi",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Sanghavi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sanghavi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688721"
                        ],
                        "name": "D. Malioutov",
                        "slug": "D.-Malioutov",
                        "structuredName": {
                            "firstName": "Dmitry",
                            "lastName": "Malioutov",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Malioutov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701607"
                        ],
                        "name": "A. Willsky",
                        "slug": "A.-Willsky",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Willsky",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Willsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 254,
                                "start": 249
                            }
                        ],
                        "text": "A line of recent research has established close links between the LP relaxation and the ordinary max-product algorithm, including the case of bipartite weighted matching [13], bipartite weighted b-matching [113], weighted matching on general graphs [201], and weighted b-matching on general graphs [12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 319,
                                "start": 305
                            }
                        ],
                        "text": "17) have studied in past and ongoing work by various authors, including the special cases of {0, 1}-quadratic programs [102], metric labeling with Potts models [132, 45], error-control coding problems [73, 75, 234, 223, 47, 59], independent set problems [177, 202], and various types of matching problems [13, 113, 201]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6562704,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c3671919164be73f1a58099e9407ccceecadd6d2",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Loopy belief propagation has been employed in a wide variety of applications with great empirical success, but it comes with few theoretical guarantees. In this paper we investigate the use of the max-product form of belief propagation for weighted matching problems on general graphs. We show that max-product converges to the correct answer if the linear programming (LP) relaxation of the weighted matching problem is tight and does not converge if the LP relaxation is loose. This provides an exact characterization of max-product performance and reveals connections to the widely used optimization technique of LP relaxation. In addition, we demonstrate that max-product is effective in solving practical weighted matching problems in a distributed fashion by applying it to the problem of self-organization in sensor networks."
            },
            "slug": "Linear-programming-analysis-of-loopy-belief-for-Sanghavi-Malioutov",
            "title": {
                "fragments": [],
                "text": "Linear programming analysis of loopy belief propagation for weighted matching"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is shown that max-product converges to the correct answer if the linear programming (LP) relaxation of the weighted matching problem is tight and does not converge if the LP relaxation is loose."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1843103"
                        ],
                        "name": "Stephen P. Boyd",
                        "slug": "Stephen-P.-Boyd",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Boyd",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen P. Boyd"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2014414"
                        ],
                        "name": "L. Vandenberghe",
                        "slug": "L.-Vandenberghe",
                        "structuredName": {
                            "firstName": "Lieven",
                            "lastName": "Vandenberghe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Vandenberghe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The benefit of this weakening is that many SOCPs can be solved with lower computational complexity than semidefinite programs [36]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Rockafellar [198] is a standard reference on convex analysis; see also the books by Hiriart-Urruty and Lemar\u00e9chal [109, 110], Boyd and Vandenberghe [36], and Bertsekas [21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Since the log-determinant function is strictly concave on the cone of positive semidefinite matrices [36], this representation demonstrates the convexity of \u2212(A\u2217) in an explicit way."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": ", [36])."
                    },
                    "intents": []
                }
            ],
            "corpusId": 37925315,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4f607f03272e4d62708f5b2441355f9e005cb452",
            "isKey": true,
            "numCitedBy": 38725,
            "numCiting": 276,
            "paperAbstract": {
                "fragments": [],
                "text": "Convex optimization problems arise frequently in many different fields. A comprehensive introduction to the subject, this book shows in detail how such problems can be solved numerically with great efficiency. The focus is on recognizing convex optimization problems and then finding the most appropriate technique for solving them. The text contains many worked examples and homework exercises and will appeal to students, researchers and practitioners in fields such as engineering, computer science, mathematics, statistics, finance, and economics."
            },
            "slug": "Convex-Optimization-Boyd-Vandenberghe",
            "title": {
                "fragments": [],
                "text": "Convex Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A comprehensive introduction to the subject of convex optimization shows in detail how such problems can be solved numerically with great efficiency."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Automatic Control"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694388"
                        ],
                        "name": "M. Goemans",
                        "slug": "M.-Goemans",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Goemans",
                            "middleNames": [
                                "X."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Goemans"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30094424"
                        ],
                        "name": "David P. Williamson",
                        "slug": "David-P.-Williamson",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Williamson",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David P. Williamson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "5) can be specialized to this problem; later, we also describe the celebrated semidefinite program (SDP) relaxation for MAX-CUT due to Goemans and Williamson [95]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15794408,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d17c6e1592265738a4636ebfff46e4c3663e9a7d",
            "isKey": false,
            "numCitedBy": 3391,
            "numCiting": 95,
            "paperAbstract": {
                "fragments": [],
                "text": "We present randomized approximation algorithms for the maximum cut (MAX CUT) and maximum 2-satisfiability (MAX 2SAT) problems that always deliver solutions of expected value at least.87856 times the optimal value. These algorithms use a simple and elegant technique that randomly rounds the solution to a nonlinear programming relaxation. This relaxation can be interpreted both as a semidefinite program and as an eigenvalue minimization problem. The best previously known approximation algorithms for these problems had performance guarantees of 1/2 for MAX CUT and 3/4 or MAX 2SAT. Slight extensions of our analysis lead to a.79607-approximation algorithm for the maximum directed cut problem (MAX DICUT) and a.758-approximation algorithm for MAX SAT, where the best previously known approximation algorithms had performance guarantees of 1/4 and 3/4, respectively. Our algorithm gives the first substantial progress in approximating MAX CUT in nearly twenty years, and represents the first use of semidefinite programming in the design of approximation algorithms."
            },
            "slug": "Improved-approximation-algorithms-for-maximum-cut-Goemans-Williamson",
            "title": {
                "fragments": [],
                "text": "Improved approximation algorithms for maximum cut and satisfiability problems using semidefinite programming"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This algorithm gives the first substantial progress in approximating MAX CUT in nearly twenty years, and represents the first use of semidefinite programming in the design of approximation algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2338183"
                        ],
                        "name": "M. M\u00e9zard",
                        "slug": "M.-M\u00e9zard",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "M\u00e9zard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. M\u00e9zard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719010"
                        ],
                        "name": "R. Zecchina",
                        "slug": "R.-Zecchina",
                        "structuredName": {
                            "firstName": "Riccardo",
                            "lastName": "Zecchina",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zecchina"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 36512754,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a2c3dd9e842320ca71a51f4b367b2af6e2189c35",
            "isKey": false,
            "numCitedBy": 362,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the problem of satisfiability of randomly chosen clauses, each with K Boolean variables. Using the cavity method at zero temperature, we find the phase diagram for the K=3 case. We show the existence of an intermediate phase in the satisfiable region, where the proliferation of metastable states is at the origin of the slowdown of search algorithms. The fundamental order parameter introduced in the cavity method, which consists of surveys of local magnetic fields in the various possible states of the system, can be computed for one given sample. These surveys can be used to invent new types of algorithms for solving hard combinatorial optimizations problems. One such algorithm is shown here for the K=3 satisfiability problem, with very good performances."
            },
            "slug": "Random-K-satisfiability-problem:-from-an-analytic-M\u00e9zard-Zecchina",
            "title": {
                "fragments": [],
                "text": "Random K-satisfiability problem: from an analytic solution to an efficient algorithm."
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The fundamental order parameter introduced in the cavity method, which consists of surveys of local magnetic fields in the various possible states of the system, can be computed for one given sample."
            },
            "venue": {
                "fragments": [],
                "text": "Physical review. E, Statistical, nonlinear, and soft matter physics"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2718299"
                        ],
                        "name": "N. Wiberg",
                        "slug": "N.-Wiberg",
                        "structuredName": {
                            "firstName": "Niclas",
                            "lastName": "Wiberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Wiberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 115168171,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb44d50bce92b4ce2c0ea53bd8ede95f628ee3cb",
            "isKey": false,
            "numCitedBy": 1007,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Iterative decoding techniques have become a viable alternative for constructing high performance coding systems. In particular, the recent success of turbo codes indicates that performance close to the Shannon limit may be achieved. In this thesis, it is showed that many iterative decoding algorithms are special cases of two generic algorithms, the min-sum and sum-product algorithms, which also include non-iterative algorithms such as Viterbi decoding. The min-sum and sum-product algorithms are developed and presented as generalized trellis algorithms, where the time axis of the trellis is replaced by an arbitrary graph, the \u201cTanner graph\u201d. With cycle-free Tanner graphs, the resulting decoding algorithms (e.g., Viterbi decoding) are maximum-likelihood but suffer from an exponentially increasing complexity. Iterative decoding occurs when the Tanner graph has cycles (e.g., turbo codes); the resulting algorithms are in general suboptimal, but significant complexity reductions are possible compared to the cycle-free case. Several performance estimates for iterative decoding are developed, including a generalization of the union bound used with Viterbi decoding and a characterization of errors that are uncorrectable after infinitely many decoding iterations."
            },
            "slug": "Codes-and-Decoding-on-General-Graphs-Wiberg",
            "title": {
                "fragments": [],
                "text": "Codes and Decoding on General Graphs"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is showed that many iterative decoding algorithms are special cases of two generic algorithms, the min-sum and sum-product algorithms, which also include non-iterative algorithms such as Viterbi decoding."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34608005"
                        ],
                        "name": "Lei Chen",
                        "slug": "Lei-Chen",
                        "structuredName": {
                            "firstName": "Lei",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lei Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721860"
                        ],
                        "name": "M. Wainwright",
                        "slug": "M.-Wainwright",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Wainwright",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wainwright"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145724968"
                        ],
                        "name": "M. \u00c7etin",
                        "slug": "M.-\u00c7etin",
                        "structuredName": {
                            "firstName": "M\u00fcjdat",
                            "lastName": "\u00c7etin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. \u00c7etin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701607"
                        ],
                        "name": "A. Willsky",
                        "slug": "A.-Willsky",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Willsky",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Willsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7214407,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0a549f01256d51b589db087a51c8c5f17683f156",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Data association is a fundamental problem in multitarget-multisensor tracking. It entails selecting the most probable association between sensor measurements and target tracks from a very large set of possibilities. With N sensors and n targets in the detection range of each sensor, even with perfect detection there are (n!)N different configurations which renders infeasible a solution by direct computation even in modestly-sized applications. We describe an iterative method for solving the optimal data association problem in a distributed fashion; the work exploits the framework of graphical models, which are a powerful tool for encoding the statistical dependencies of a set of random variables and are widely used in many applications (e.g., computer vision, error-correcting codes). Our basic idea is to treat the measurement assignment for each sensor as a random variable, which is in turn represented as a node in an underlying graph. Neighboring nodes are coupled by the targets visible to both sensors. Thus we transform the data association problem to that of computing the maximum a posteriori (MAP) configuration in a graphical model to which efficient techniques (e.g., the max-product/min-sum algorithm) can be applied. We use a tree-reweighted version of the usual max-product algorithm that either outputs the MAP data association, or acknowledges failure. For acyclic graphs, this message-passing algorithm can solve the data association problem directly and recursively with complexity O((n!)2N). On graphs with cycles, the algorithm may require more iterations to converge, and need not output an unambiguous assignment. However, for the data association problems considered here, the coupling matrices involved in computations are inherently of low rank, and experiments show that the algorithm converges very fast and finds the MAP configurations in this case."
            },
            "slug": "Multitarget-multisensor-data-association-using-the-Chen-Wainwright",
            "title": {
                "fragments": [],
                "text": "Multitarget-multisensor data association using the tree-reweighted max-product algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An iterative method for solving the optimal data association problem in a distributed fashion using a tree-reweighted version of the usual max-product algorithm that either outputs the maximum a posteriori (MAP) data association, or acknowledges failure."
            },
            "venue": {
                "fragments": [],
                "text": "SPIE Defense + Commercial Sensing"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2089883"
                        ],
                        "name": "W. Gilks",
                        "slug": "W.-Gilks",
                        "structuredName": {
                            "firstName": "Walter",
                            "lastName": "Gilks",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Gilks"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50130827"
                        ],
                        "name": "S. Richardson",
                        "slug": "S.-Richardson",
                        "structuredName": {
                            "firstName": "Sylvia",
                            "lastName": "Richardson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Richardson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48616434"
                        ],
                        "name": "D. Spiegelhalter",
                        "slug": "D.-Spiegelhalter",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Spiegelhalter",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Spiegelhalter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "These advantages and others have led to the development of general software programs for specifying and manipulating hierarchical Bayesian models via the directed graphical model formalism [90]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 221894711,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3fbcff06339605696423609c0f3c02737c9e91e4",
            "isKey": false,
            "numCitedBy": 4092,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "INTRODUCING MARKOV CHAIN MONTE CARLO Introduction The Problem Markov Chain Monte Carlo Implementation Discussion HEPATITIS B: A CASE STUDY IN MCMC METHODS Introduction Hepatitis B Immunization Modelling Fitting a Model Using Gibbs Sampling Model Elaboration Conclusion MARKOV CHAIN CONCEPTS RELATED TO SAMPLING ALGORITHMS Markov Chains Rates of Convergence Estimation The Gibbs Sampler and Metropolis-Hastings Algorithm INTRODUCTION TO GENERAL STATE-SPACE MARKOV CHAIN THEORY Introduction Notation and Definitions Irreducibility, Recurrence, and Convergence Harris Recurrence Mixing Rates and Central Limit Theorems Regeneration Discussion FULL CONDITIONAL DISTRIBUTIONS Introduction Deriving Full Conditional Distributions Sampling from Full Conditional Distributions Discussion STRATEGIES FOR IMPROVING MCMC Introduction Reparameterization Random and Adaptive Direction Sampling Modifying the Stationary Distribution Methods Based on Continuous-Time Processes Discussion IMPLEMENTING MCMC Introduction Determining the Number of Iterations Software and Implementation Output Analysis Generic Metropolis Algorithms Discussion INFERENCE AND MONITORING CONVERGENCE Difficulties in Inference from Markov Chain Simulation The Risk of Undiagnosed Slow Convergence Multiple Sequences and Overdispersed Starting Points Monitoring Convergence Using Simulation Output Output Analysis for Inference Output Analysis for Improving Efficiency MODEL DETERMINATION USING SAMPLING-BASED METHODS Introduction Classical Approaches The Bayesian Perspective and the Bayes Factor Alternative Predictive Distributions How to Use Predictive Distributions Computational Issues An Example Discussion HYPOTHESIS TESTING AND MODEL SELECTION Introduction Uses of Bayes Factors Marginal Likelihood Estimation by Importance Sampling Marginal Likelihood Estimation Using Maximum Likelihood Application: How Many Components in a Mixture? Discussion Appendix: S-PLUS Code for the Laplace-Metropolis Estimator MODEL CHECKING AND MODEL IMPROVEMENT Introduction Model Checking Using Posterior Predictive Simulation Model Improvement via Expansion Example: Hierarchical Mixture Modelling of Reaction Times STOCHASTIC SEARCH VARIABLE SELECTION Introduction A Hierarchical Bayesian Model for Variable Selection Searching the Posterior by Gibbs Sampling Extensions Constructing Stock Portfolios With SSVS Discussion BAYESIAN MODEL COMPARISON VIA JUMP DIFFUSIONS Introduction Model Choice Jump-Diffusion Sampling Mixture Deconvolution Object Recognition Variable Selection Change-Point Identification Conclusions ESTIMATION AND OPTIMIZATION OF FUNCTIONS Non-Bayesian Applications of MCMC Monte Carlo Optimization Monte Carlo Likelihood Analysis Normalizing-Constant Families Missing Data Decision Theory Which Sampling Distribution? Importance Sampling Discussion STOCHASTIC EM: METHOD AND APPLICATION Introduction The EM Algorithm The Stochastic EM Algorithm Examples GENERALIZED LINEAR MIXED MODELS Introduction Generalized Linear Models (GLMs) Bayesian Estimation of GLMs Gibbs Sampling for GLMs Generalized Linear Mixed Models (GLMMs) Specification of Random-Effect Distributions Hyperpriors and the Estimation of Hyperparameters Some Examples Discussion HIERARCHICAL LONGITUDINAL MODELLING Introduction Clinical Background Model Detail and MCMC Implementation Results Summary and Discussion MEDICAL MONITORING Introduction Modelling Medical Monitoring Computing Posterior Distributions Forecasting Model Criticism Illustrative Application Discussion MCMC FOR NONLINEAR HIERARCHICAL MODELS Introduction Implementing MCMC Comparison of Strategies A Case Study from Pharmacokinetics-Pharmacodynamics Extensions and Discussion BAYESIAN MAPPING OF DISEASE Introduction Hypotheses and Notation Maximum Likelihood Estimation of Relative Risks Hierarchical Bayesian Model of Relative Risks Empirical Bayes Estimation of Relative Risks Fully Bayesian Estimation of Relative Risks Discussion MCMC IN IMAGE ANALYSIS Introduction The Relevance of MCMC to Image Analysis Image Models at Different Levels Methodological Innovations in MCMC Stimulated by Imaging Discussion MEASUREMENT ERROR Introduction Conditional-Independence Modelling Illustrative examples Discussion GIBBS SAMPLING METHODS IN GENETICS Introduction Standard Methods in Genetics Gibbs Sampling Approaches MCMC Maximum Likelihood Application to a Family Study of Breast Cancer Conclusions MIXTURES OF DISTRIBUTIONS: INFERENCE AND ESTIMATION Introduction The Missing Data Structure Gibbs Sampling Implementation Convergence of the Algorithm Testing for Mixtures Infinite Mixtures and Other Extensions AN ARCHAEOLOGICAL EXAMPLE: RADIOCARBON DATING Introduction Background to Radiocarbon Dating Archaeological Problems and Questions Illustrative Examples Discussion Index"
            },
            "slug": "Markov-Chain-Monte-Carlo-in-Practice-Gilks-Richardson",
            "title": {
                "fragments": [],
                "text": "Markov Chain Monte Carlo in Practice"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The Markov Chain Monte Carlo Implementation Results Summary and Discussion MEDICAL MONITORING Introduction Modelling Medical Monitoring Computing Posterior Distributions Forecasting Model Criticism Illustrative Application Discussion MCMC for NONLINEAR HIERARCHICAL MODELS."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689196"
                        ],
                        "name": "A. Schrijver",
                        "slug": "A.-Schrijver",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Schrijver",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Schrijver"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "By standard properties of linear programs [206], the optimal value of the relaxed LP must be attained by at least one vertex of the polytope L(G)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "1 Most importantly, the right-hand side is a linear program, where the number of constraints defining L(G) grows only linearly in the graph size, so that it can be solved in polynomial-time for any graph [206]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 29180149,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3ce2d233cee585ecff73729836918ba87195c18f",
            "isKey": false,
            "numCitedBy": 4832,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Introduction and Preliminaries. Problems, Algorithms, and Complexity. LINEAR ALGEBRA. Linear Algebra and Complexity. LATTICES AND LINEAR DIOPHANTINE EQUATIONS. Theory of Lattices and Linear Diophantine Equations. Algorithms for Linear Diophantine Equations. Diophantine Approximation and Basis Reduction. POLYHEDRA, LINEAR INEQUALITIES, AND LINEAR PROGRAMMING. Fundamental Concepts and Results on Polyhedra, Linear Inequalities, and Linear Programming. The Structure of Polyhedra. Polarity, and Blocking and Anti--Blocking Polyhedra. Sizes and the Theoretical Complexity of Linear Inequalities and Linear Programming. The Simplex Method. Primal--Dual, Elimination, and Relaxation Methods. Khachiyana s Method for Linear Programming. The Ellipsoid Method for Polyhedra More Generally. Further Polynomiality Results in Linear Programming. INTEGER LINEAR PROGRAMMING. Introduction to Integer Linear Programming. Estimates in Integer Linear Programming. The Complexity of Integer Linear Programming. Totally Unimodular Matrices: Fundamental Properties and Examples. Recognizing Total Unimodularity. Further Theory Related to Total Unimodularity. Integral Polyhedra and Total Dual Integrality. Cutting Planes. Further Methods in Integer Linear Programming. References. Indexes."
            },
            "slug": "Theory-of-linear-and-integer-programming-Schrijver",
            "title": {
                "fragments": [],
                "text": "Theory of linear and integer programming"
            },
            "venue": {
                "fragments": [],
                "text": "Wiley-Interscience series in discrete mathematics and optimization"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3231485"
                        ],
                        "name": "S. Aji",
                        "slug": "S.-Aji",
                        "structuredName": {
                            "firstName": "Srinivas",
                            "lastName": "Aji",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Aji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723150"
                        ],
                        "name": "R. McEliece",
                        "slug": "R.-McEliece",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "McEliece",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. McEliece"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "More generally, updates of this form apply to arbitrary commutative semirings on tree-structured graphs [232, 211, 62, 2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Our treatment is brief; further details can be found in various sources [2, 62, 139, 122, 151]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Consider applying the LP decoder to the cost function \u03b8 = (2, 0, 0,\u22121); using the previously constructed \u03c4\u0303 = [ 1 1 2 1 2 0 ] , a little calculation shows that \u3008\u03b8, \u03c4\u0303\u3009 = 2."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "1(b), the marginal polytope M(C3) is strictly contained within the scaled cube [0, 1 2 ] 3."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Consider the vector \u03c4\u0303 = [ 1 12 1 2 0 ] ; it is easy to verify that it satisfies the box inequalities and the forbidden set constraints (8."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "\u03c4\u0303 = [ \u03c41(1) \u03c42(1) \u03c43(1) \u03c44(1) ] = [ 1 1 2 1 2 0 ] ,"
                    },
                    "intents": []
                }
            ],
            "corpusId": 11355291,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0e8933300a20f3d799dc9f19e352967f41d8efcc",
            "isKey": true,
            "numCitedBy": 773,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We discuss a general message passing algorithm, which we call the generalized distributive law (GDL). The GDL is a synthesis of the work of many authors in information theory, digital communications, signal processing, statistics, and artificial intelligence. It includes as special cases the Baum-Welch algorithm, the fast Fourier transform (FFT) on any finite Abelian group, the Gallager-Tanner-Wiberg decoding algorithm, Viterbi's algorithm, the BCJR algorithm, Pearl's \"belief propagation\" algorithm, the Shafer-Shenoy probability propagation algorithm, and the turbo decoding algorithm. Although this algorithm is guaranteed to give exact answers only in certain cases (the \"junction tree\" condition), unfortunately not including the cases of GTW with cycles or turbo decoding, there is much experimental evidence, and a few theorems, suggesting that it often works approximately even when it is not supposed to."
            },
            "slug": "The-generalized-distributive-law-Aji-McEliece",
            "title": {
                "fragments": [],
                "text": "The generalized distributive law"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Although this algorithm is guaranteed to give exact answers only in certain cases (the \"junction tree\" condition), unfortunately not including the cases of GTW with cycles or turbo decoding, there is much experimental evidence, and a few theorems, suggesting that it often works approximately even when it is not supposed to."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144845491"
                        ],
                        "name": "A. Dawid",
                        "slug": "A.-Dawid",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Dawid",
                            "middleNames": [
                                "Philip"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dawid"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We refer the reader to Dawid [62] for an extensive discussion of the max-product version of the junction tree algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "More generally, updates of this form apply to arbitrary commutative semirings on tree-structured graphs [232, 211, 62, 2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Given these max-marginals, it is straightforward to compute a mode x\u0302 \u2208 argmaxx p(x) of the distribution; see the papers [62, 239] for further details."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Our treatment is brief; further details can be found in various sources [2, 62, 139, 122, 151]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61247712,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b9abff70b0acf9c6bb74d85f3141d76bef2039a5",
            "isKey": true,
            "numCitedBy": 288,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "A probabilistic expert system provides a graphical representation of a joint probability distribution which can be used to simplify and localize calculations. Jensenet al. (1990) introduced a \u2018flow-propagation\u2019 algorithm for calculating marginal and conditional distributions in such a system. This paper analyses that algorithm in detail, and shows how it can be modified to perform other tasks, including maximization of the joint density and simultaneous \u2018fast retraction\u2019 of evidence entered on several variables."
            },
            "slug": "Applications-of-a-general-propagation-algorithm-for-Dawid",
            "title": {
                "fragments": [],
                "text": "Applications of a general propagation algorithm for probabilistic expert systems"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper analyses a \u2018flow-propagation\u2019 algorithm for calculating marginal and conditional distributions in a probabilistic expert system in detail, and shows how it can be modified to perform other tasks, including maximization of the joint density and simultaneous 'fast retraction' of evidence entered on several variables."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751239"
                        ],
                        "name": "R. Dechter",
                        "slug": "R.-Dechter",
                        "structuredName": {
                            "firstName": "Rina",
                            "lastName": "Dechter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dechter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Problems of constraint satisfaction and combinatorial optimization arise in a wide variety of areas, among them artificial intelligence [63, 188], communication theory [84], computational complexity theory [52], statistical image processing [86], and bioinformatics [190]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5319073,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2bc1daaba330f4ea8a4f951d5dcd40c39bef5a8a",
            "isKey": false,
            "numCitedBy": 1186,
            "numCiting": 204,
            "paperAbstract": {
                "fragments": [],
                "text": "Constraint satisfaction is a simple but powerful tool. Constraints identify the impossible and reduce the realm of possibilities to effectively focus on the possible, allowing for a natural declarative formulation of what must be satisfied, without expressing how. The field of constraint reasoning has matured over the last three decades with contributions from a diverse community of researchers in artificial intelligence, databases and programming languages, operations research, management science, and applied mathematics. Today, constraint problems are used to model cognitive tasks in vision, language comprehension, default reasoning, diagnosis, scheduling, temporal and spatial reasoning. \n \nIn Constraint Processing, Rina Dechter, synthesizes these contributions, along with her own significant work, to provide the first comprehensive examination of the theory that underlies constraint processing algorithms. Throughout, she focuses on fundamental tools and principles, emphasizing the representation and analysis of algorithms. \n \n\u00b7Examines the basic practical aspects of each topic and then tackles more advanced issues, including current research challenges \n\u00b7Builds the reader's understanding with definitions, examples, theory, algorithms and complexity analysis \n\u00b7Synthesizes three decades of researchers work on constraint processing in AI, databases and programming languages, operations research, management science, and applied mathematics \n \nTable of Contents \n \nPreface; Introduction; Constraint Networks; Consistency-Enforcing Algorithms: Constraint Propagation; Directional Consistency; General Search Strategies; General Search Strategies: Look-Back; Local Search Algorithms; Advanced Consistency Methods; Tree-Decomposition Methods; Hybrid of Search and Inference: Time-Space Trade-offs; Tractable Constraint Languages; Temporal Constraint Networks; Constraint Optimization; Probabilistic Networks; Constraint Logic Programming; Bibliography"
            },
            "slug": "Constraint-Processing-Dechter",
            "title": {
                "fragments": [],
                "text": "Constraint Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Rina Dechter synthesizes three decades of researchers work on constraint processing in AI, databases and programming languages, operations research, management science, and applied mathematics to provide the first comprehensive examination of the theory that underlies constraint processing algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46737210"
                        ],
                        "name": "Talya Meltzer",
                        "slug": "Talya-Meltzer",
                        "structuredName": {
                            "firstName": "Talya",
                            "lastName": "Meltzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Talya Meltzer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2571487"
                        ],
                        "name": "C. Yanover",
                        "slug": "C.-Yanover",
                        "structuredName": {
                            "firstName": "Chen",
                            "lastName": "Yanover",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Yanover"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30400079"
                        ],
                        "name": "Yair Weiss",
                        "slug": "Yair-Weiss",
                        "structuredName": {
                            "firstName": "Yair",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yair Weiss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Various forms of these reweighted maxproduct algorithms have been applied in problems such as segmentation and disparity problems in computer vision [165, 134, 136, 246, 222, 260], error-control coding [73], side-chain prediction [261, 246], sensor fusion [43, 46]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9103886,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e507bbcffb87fa53ac2815936e430aff5cf938ff",
            "isKey": false,
            "numCitedBy": 129,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "A wide range of low level vision problems have been formulated in terms of finding the most probable assignment of a Markov random field (or equivalently the lowest energy configuration). Perhaps the most successful example is stereo vision. For the stereo problem, it has been shown that finding the global optimum is NP hard but good results have been obtained using a number of approximate optimization algorithms. In this paper, we show that for standard benchmark stereo pairs, the global optimum can be found in about 30 minutes using a variant of the belief propagation (BP) algorithm. We extend previous theoretical results on reweighted belief propagation to account for possible ties in the beliefs and using these results we obtain easily checkable conditions that guarantee that the BP disparities are the global optima. We verify experimentally that these conditions are typically met for the standard benchmark stereo pairs and discuss the implications of our results for further progress in stereo."
            },
            "slug": "Globally-optimal-solutions-for-energy-minimization-Meltzer-Yanover",
            "title": {
                "fragments": [],
                "text": "Globally optimal solutions for energy minimization in stereo vision using reweighted belief propagation"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "It is shown that for standard benchmark stereo pairs, the global optimum can be found in about 30 minutes using a variant of the belief propagation (BP) algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3067836"
                        ],
                        "name": "Martijn A. R. Leisink",
                        "slug": "Martijn-A.-R.-Leisink",
                        "structuredName": {
                            "firstName": "Martijn",
                            "lastName": "Leisink",
                            "middleNames": [
                                "A.",
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martijn A. R. Leisink"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792269"
                        ],
                        "name": "H. Kappen",
                        "slug": "H.-Kappen",
                        "structuredName": {
                            "firstName": "Hilbert",
                            "lastName": "Kappen",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kappen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2556569,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "af72d0221482e8087cf00093fdffed10110ea973",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-in-higher-order-Boltzmann-machines-using-Leisink-Kappen",
            "title": {
                "fragments": [],
                "text": "Learning in higher order Boltzmann machines using linear response"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2014414"
                        ],
                        "name": "L. Vandenberghe",
                        "slug": "L.-Vandenberghe",
                        "structuredName": {
                            "firstName": "Lieven",
                            "lastName": "Vandenberghe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Vandenberghe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1843103"
                        ],
                        "name": "Stephen P. Boyd",
                        "slug": "Stephen-P.-Boyd",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Boyd",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen P. Boyd"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In this section, we show that the mode-finding problem for a Gaussian is a semidefinite program (SDP), another well-known class of convex optimization problems [229, 230]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The problem on the right-hand side is a semidefinite program [229], as it involves a linear objective function subject to the linear matrix inequality (LMI) constraint (C."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10531091,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "e309a155425162cf3b363b9393291b4f568416a0",
            "isKey": false,
            "numCitedBy": 2642,
            "numCiting": 265,
            "paperAbstract": {
                "fragments": [],
                "text": "In semidefinite programming, one minimizes a linear function subject to the constraint that an affine combination of symmetric matrices is positive semidefinite. Such a constraint is nonlinear and nonsmooth, but convex, so semidefinite programs are convex optimization problems. Semidefinite programming unifies several standard problems (e.g., linear and quadratic programming) and finds many applications in engineering and combinatorial optimization. Although semidefinite programs are much more general than linear programs, they are not much harder to solve. Most interior-point methods for linear programming have been generalized to semidefinite programs. As in linear programming, these methods have polynomial worst-case complexity and perform very well in practice. This paper gives a survey of the theory and applications of semidefinite programs and an introduction to primaldual interior-point methods for their solution."
            },
            "slug": "Semidefinite-Programming-Vandenberghe-Boyd",
            "title": {
                "fragments": [],
                "text": "Semidefinite Programming"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A survey of the theory and applications of semidefinite programs and an introduction to primaldual interior-point methods for their solution are given."
            },
            "venue": {
                "fragments": [],
                "text": "SIAM Rev."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1891751"
                        ],
                        "name": "E. Pasztor",
                        "slug": "E.-Pasztor",
                        "structuredName": {
                            "firstName": "Egon",
                            "lastName": "Pasztor",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Pasztor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2575670"
                        ],
                        "name": "Owen Carmichael",
                        "slug": "Owen-Carmichael",
                        "structuredName": {
                            "firstName": "Owen",
                            "lastName": "Carmichael",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Owen Carmichael"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1414109,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "861897df39716877fb1e03a7d09a234faca076e9",
            "isKey": false,
            "numCitedBy": 1220,
            "numCiting": 82,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a learning-based method for low-level vision problems\u2014estimating scenes from images. We generate a synthetic world of scenes and their corresponding rendered images, modeling their relationships with a Markov network. Bayesian belief propagation allows us to efficiently find a local maximum of the posterior probability for the scene, given an image. We call this approach VISTA\u2014Vision by Image/Scene TrAining.We apply VISTA to the \u201csuper-resolution\u201d problem (estimating high frequency details from a low-resolution image), showing good results. To illustrate the potential breadth of the technique, we also apply it in two other problem domains, both simplified. We learn to distinguish shading from reflectance variations in a single image under particular lighting conditions. For the motion estimation problem in a \u201cblobs world\u201d, we show figure/ground discrimination, solution of the aperture problem, and filling-in arising from application of the same probabilistic machinery."
            },
            "slug": "Learning-Low-Level-Vision-Freeman-Pasztor",
            "title": {
                "fragments": [],
                "text": "Learning Low-Level Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A learning-based method for low-level vision problems\u2014estimating scenes from images with Bayesian belief propagation, applied to the \u201csuper-resolution\u201d problem (estimating high frequency details from a low-resolution image), showing good results."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1779993"
                        ],
                        "name": "P. Pevzner",
                        "slug": "P.-Pevzner",
                        "structuredName": {
                            "firstName": "Pavel",
                            "lastName": "Pevzner",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pevzner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Problems of constraint satisfaction and combinatorial optimization arise in a wide variety of areas, among them artificial intelligence [63, 188], communication theory [84], computational complexity theory [52], statistical image processing [86], and bioinformatics [190]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 45667473,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "0a96654a443e1cfecc745f463c62b59582e7478a",
            "isKey": false,
            "numCitedBy": 484,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "In one of the first major texts in the emerging field of computational molecular biology, Pavel Pevzner covers a broad range of algorithmic and combinatorial topics and shows how they are connected to molecular biology and to biotechnology. The book has a substantial \"computational biology without formulas\" component that presents the biological and computational ideas in a relatively simple manner. This makes the material accessible to computer scientists without biological training, as well as to biologists with limited background in computer science. Computational Molecular Biology seriesComputer science and mathematics are transforming molecular biology from an informational to a computational science. Drawing on computational, statistical, experimental, and technological methods, the new discipline of computational molecular biology is dramatically increasing the discovery of new technologies and tools for molecular biology. The new MIT Press Computational Molecular Biology series provides a unique venue for the rapid publication of monographs, textbooks, edited collections, reference works, and lecture notes of the highest quality."
            },
            "slug": "Computational-molecular-biology-an-algorithmic-Pevzner",
            "title": {
                "fragments": [],
                "text": "Computational molecular biology - an algorithmic approach"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "In one of the first major texts in the emerging field of computational molecular biology, Pavel Pevzner covers a broad range of algorithmic and combinatorial topics and shows how they are connected to molecular biology and to biotechnology."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1387902104"
                        ],
                        "name": "A. d'Aspremont",
                        "slug": "A.-d'Aspremont",
                        "structuredName": {
                            "firstName": "Alexandre",
                            "lastName": "d'Aspremont",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. d'Aspremont"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1934584"
                        ],
                        "name": "Onureena Banerjee",
                        "slug": "Onureena-Banerjee",
                        "structuredName": {
                            "firstName": "Onureena",
                            "lastName": "Banerjee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Onureena Banerjee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701847"
                        ],
                        "name": "L. Ghaoui",
                        "slug": "L.-Ghaoui",
                        "structuredName": {
                            "firstName": "Laurent",
                            "lastName": "Ghaoui",
                            "middleNames": [
                                "El"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Ghaoui"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7733891,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "91a95bf76f977328f95bf7e88ab7669ca29f96f1",
            "isKey": false,
            "numCitedBy": 362,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Given a sample covariance matrix, we solve a maximum likelihood problem penalized by the number of nonzero coefficients in the inverse covariance matrix. Our objective is to find a sparse representation of the sample data and to highlight conditional independence relationships between the sample variables. We first formulate a convex relaxation of this combinatorial problem, we then detail two efficient first-order algorithms with low memory requirements to solve large-scale, dense problem instances."
            },
            "slug": "First-Order-Methods-for-Sparse-Covariance-Selection-d'Aspremont-Banerjee",
            "title": {
                "fragments": [],
                "text": "First-Order Methods for Sparse Covariance Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work first formulate a convex relaxation of this combinatorial problem, then detail two efficient first-order algorithms with low memory requirements to solve large-scale, dense problem instances."
            },
            "venue": {
                "fragments": [],
                "text": "SIAM J. Matrix Anal. Appl."
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749650"
                        ],
                        "name": "B. Frey",
                        "slug": "B.-Frey",
                        "structuredName": {
                            "firstName": "Brendan",
                            "lastName": "Frey",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Frey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7715701"
                        ],
                        "name": "R. Koetter",
                        "slug": "R.-Koetter",
                        "structuredName": {
                            "firstName": "Ralf",
                            "lastName": "Koetter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Koetter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2173574"
                        ],
                        "name": "Nemanja Petrovic",
                        "slug": "Nemanja-Petrovic",
                        "structuredName": {
                            "firstName": "Nemanja",
                            "lastName": "Petrovic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nemanja Petrovic"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10192687,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "39202bce61b76f3fa2c948b5d365f6adb78b9050",
            "isKey": false,
            "numCitedBy": 76,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Since the discovery that the best error-correcting decoding algorithm can be viewed as belief propagation in a cycle-bound graph, researchers have been trying to determine under what circumstances \"loopy belief propagation\" is effective for probabilistic inference. Despite several theoretical advances in our understanding of loopy belief propagation, to our knowledge, the only problem that has been solved using loopy belief propagation is error-correcting decoding on Gaussian channels. We propose a new representation for the two-dimensional phase unwrapping problem, and we show that loopy belief propagation produces results that are superior to existing techniques. This is an important result, since many imaging techniques, including magnetic resonance imaging and interfer-ometric synthetic aperture radar, produce phase-wrapped images. Interestingly, the graph that we use has a very large number of very short cycles, supporting evidence that a large minimum cycle length is not needed for excellent results using belief propagation."
            },
            "slug": "Very-loopy-belief-propagation-for-unwrapping-phase-Frey-Koetter",
            "title": {
                "fragments": [],
                "text": "Very loopy belief propagation for unwrapping phase images"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work proposes a new representation for the two-dimensional phase unwrapping problem, and shows that loopy belief propagation produces results that are superior to existing techniques, and Interestingly, the graph that is used has a very large number of very short cycles, supporting evidence that a large minimum cycle length is not needed for excellent results using belief propagation."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38838239"
                        ],
                        "name": "J. Feldman",
                        "slug": "J.-Feldman",
                        "structuredName": {
                            "firstName": "Jon",
                            "lastName": "Feldman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Feldman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743286"
                        ],
                        "name": "D. Karger",
                        "slug": "D.-Karger",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Karger",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Karger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721860"
                        ],
                        "name": "M. Wainwright",
                        "slug": "M.-Wainwright",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Wainwright",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wainwright"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 0
                            }
                        ],
                        "text": "[36, 37] have applied the tree-based relaxation (155) to the task of decoding turbo and low-density parity check (LDPC) codes, and provided analytical results to characterize its decoding performance."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9039845,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4b5ed2df68ed8ad6c56d16d13e04f120b416244c",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "In recent work (Feldman and Karger [8]), we introduced a new a pproach to decoding turbo-like codes based on linear programming (LP). We gave a precise characterization of the noise patterns that cause decoding error under the binar y symmetric and additive white Gaussian noise channels. We used this characterization to p rove that the word error rate is bounded by an inverse polynomial in the code length. Furth ermore, for any turbo-like code, our algorithm has the ML certificateproperty: whenever it outputs a code word, it is guaranteed to be the maximum-likelihood (ML) code word. In this paper we extend these results and give an iterative de coder whose output is equivalent to that of the LP decoder. We also extend the ML cer tifi ate property to the more efficient iterativetree reweighted max-product message-passing algorithm developed by Wainwright, Jaakkola, and Willsky [13]: we show that whenev er this algorithm converges to a code word, it must be the ML code word. Finally, we demonstrate experimentally that the noise patt erns that cause decoding error in the LP decoder also cause decoding error in the stand ard iterative sum-product and max-product (min-sum) message-passing algorithms. Conse quently, the deterministically constructible interleaver used by the LP decoder to achieve its bounds on error rate is useful in practice not only for the LP decoder, but for these s tandard iterative decoders as"
            },
            "slug": "Linear-Programming-Based-Decoding-of-Turbo-Like-and-Feldman-Karger",
            "title": {
                "fragments": [],
                "text": "Linear Programming-Based Decoding of Turbo-Like Codes and its Relation to Iterative Approaches"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "This paper gives an iterative de coder whose output is equivalent to that of the LP decoder, and extends the ML certificateproperty to the more efficient iterativetree reweighted max-product message-passing algorithm developed by Wainwright, Jaakkola, and Willsky."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725303"
                        ],
                        "name": "Y. Teh",
                        "slug": "Y.-Teh",
                        "structuredName": {
                            "firstName": "Yee",
                            "lastName": "Teh",
                            "middleNames": [
                                "Whye"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Teh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678311"
                        ],
                        "name": "M. Welling",
                        "slug": "M.-Welling",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Welling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Welling"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10637224,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "03a882cd0eddc86a0067b6c4f09705bdf80495fe",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Iterative proportional fitting (IPF) on junction trees is an important tool for learning in graphical models. We identify the propagation and IPF updates on the junction tree as fixed point equations of a single constrained entropy maximization problem. This allows a more efficient message updating protocol than the well known effective IPF of Jirou\u0161ek and P\u0159eu\u010dil (1995). When the junction tree has an intractably large maximum clique size we propose to maximize an approximate constrained entropy based on region graphs (Yedidia et al., 2002). To maximize the new objective we propose a \u201cloopy\u201d version of IPF. We show that this yields accurate estimates of the weights of undirected graphical models in a simple experiment."
            },
            "slug": "On-Improving-the-Efficiency-of-the-Iterative-Teh-Welling",
            "title": {
                "fragments": [],
                "text": "On Improving the Efficiency of the Iterative Proportional Fitting Procedure"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "This work identifies the propagation and IPF updates on the junction tree as fixed point equations of a single constrained entropy maximization problem and proposes a \u201cloopy\u201d version of IPF that yields accurate estimates of the weights of undirected graphical models in a simple experiment."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4141450"
                        ],
                        "name": "J. Lasserre",
                        "slug": "J.-Lasserre",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Lasserre",
                            "middleNames": [
                                "Bernard"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lasserre"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 164
                            }
                        ],
                        "text": "Remarks: (a) The sequences SDEF(Kt;n) and LOCAL(Kt;n) de ned by the complete hypergraphs Kt;n (for t = 1; : : : ; n) correspond to particular cases of the Lasserre [64] and SheraliAdams [98] sequences of relaxations respectively."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 82
                            }
                        ],
                        "text": "The validity of this nite termination in a general setting was proved by Lasserre [64], and also by Laurent [66, 67] using di erent methods."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 167
                            }
                        ],
                        "text": "Of course, we can also consider moments for higher-order multi-indices as well; doing so leads a special case of what is known as the Lasserre sequence of relaxations [64, 66]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 38727313,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c037ccba0f63ba0af5ac5f791cd45f3574b6cf2d",
            "isKey": false,
            "numCitedBy": 180,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the general nonlinear optimization problem in 0-1 variables and provide an explicit equivalent positive semidefinite program in 2n-1 variables. The optimal values of both problems are identical. From every optimal solution of the former, one easily finds an optimal solution of the latter, and conversely, from every solution of the latter, one may construct an optimal solution of the former. For illustration, the equivalent positive semidefinite program is explicated for quadratic 0-1 programs and MAX-CUT in $\\mathbb{R}^3$. For unconstrained 0-1 programs, a special representation in terms of a weighted sum of squares is provided."
            },
            "slug": "An-Explicit-Equivalent-Positive-Semidefinite-for-Lasserre",
            "title": {
                "fragments": [],
                "text": "An Explicit Equivalent Positive Semidefinite Program for Nonlinear 0-1 Programs"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "This work considers the general nonlinear optimization problem in 0-1 variables and provides an explicit equivalent positive semidefinite program in 2n-1 variable and its optimal values are identical."
            },
            "venue": {
                "fragments": [],
                "text": "SIAM J. Optim."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1932728"
                        ],
                        "name": "T. Richardson",
                        "slug": "T.-Richardson",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Richardson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Richardson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727633"
                        ],
                        "name": "R. Urbanke",
                        "slug": "R.-Urbanke",
                        "structuredName": {
                            "firstName": "R\u00fcdiger",
                            "lastName": "Urbanke",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Urbanke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "One important domain in which hard-core constraints arise is communication theory, and in particular the problem of error-control coding [84, 164, 196]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Random constructions of factor graphs on m vertices with bounded degree have cycles of typical length \u224d logm; this tree-like property is essential to the success of the sum-product algorithm for approximate decoding [196, 166]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 43202122,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d5c20ac7da03b37c211dcb2cc0348a66fd5c2f82",
            "isKey": false,
            "numCitedBy": 1807,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "Having trouble deciding which coding scheme to employ, how to design a new scheme, or how to improve an existing system? This summary of the state-of-the-art in iterative coding makes this decision more straightforward. With emphasis on the underlying theory, techniques to analyse and design practical iterative coding systems are presented. Using Gallager's original ensemble of LDPC codes, the basic concepts are extended for several general codes, including the practically important class of turbo codes. The simplicity of the binary erasure channel is exploited to develop analytical techniques and intuition, which are then applied to general channel models. A chapter on factor graphs helps to unify the important topics of information theory, coding and communication theory. Covering the most recent advances, this text is ideal for graduate students in electrical engineering and computer science, and practitioners. Additional resources, including instructor's solutions and figures, available online: www.cambridge.org/9780521852296."
            },
            "slug": "Modern-Coding-Theory-Richardson-Urbanke",
            "title": {
                "fragments": [],
                "text": "Modern Coding Theory"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This summary of the state-of-the-art in iterative coding makes this decision more straightforward, with emphasis on the underlying theory, techniques to analyse and design practical iterative codes systems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691022"
                        ],
                        "name": "M. Opper",
                        "slug": "M.-Opper",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Opper",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Opper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064612704"
                        ],
                        "name": "David Saad",
                        "slug": "David-Saad",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Saad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Saad"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 125183395,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "22f464167e25d0e38cf38b035fce6ba9fee7a643",
            "isKey": false,
            "numCitedBy": 46,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter contains sections titled: Introduction, Inference, Some Models from Statistical Physics, The Gibbs Free Energy, Mean Field Theory: The Variational Approach, Correcting Mean Field Theory, The Bethe Approximation, Belief Propagation, Kikuchi Approximations and Generalized Belief Propagation, Acknowledgments, References"
            },
            "slug": "An-Idiosyncratic-Journey-Beyond-Mean-Field-Theory-Opper-Saad",
            "title": {
                "fragments": [],
                "text": "An Idiosyncratic Journey Beyond Mean Field Theory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143961444"
                        ],
                        "name": "M. Laurent",
                        "slug": "M.-Laurent",
                        "structuredName": {
                            "firstName": "Monique",
                            "lastName": "Laurent",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Laurent"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 12
                            }
                        ],
                        "text": "See Laurent [66, 67] for comparison of these sequences in a more general setting."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 108
                            }
                        ],
                        "text": "The validity of this nite termination in a general setting was proved by Lasserre [64], and also by Laurent [66, 67] using di erent methods."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15742917,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d6ea3c804e60a81a89942b4490a8794121db391f",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We compare several semideenite relaxations for the cut polytope obtained by applying the lift and project methods of Lovv asz and Schrijver and of Lasserre. We show that the tightest relaxation is obtained when aplying the Lasserre construction to the node formulation of the max-cut problem. This relaxation Q t (G) can be deened as the projection on the edge subspace of the set F t (n), which consists of the matrices indexed by all subsets of 1; n] of cardinality t + 1 with the same parity as t + 1 and having the property that their (I; J)-th entry depends only on the symmetric diierence of the sets I and J. The set F 0 (n) is the basic semideenite relaxation of max-cut consisting of the semideenite matrices of order n with an all ones diagonal, while F n?2 (n) is the 2 n?1-dimensional simplex with the cut matrices as vertices. We show the following geometric properties: If Y 2 F t (n) has rank t + 1, then Y can be written as a convex combination of at most 2 t cut matrices, extending a result of Anjos and Wolkowicz for the case t = 1; any 2 t+1 cut matrices form a face of F t (n) for t = 0; 1; n ? 2. The class L t of the graphs G for which Q t (G) is the cut polytope of G is shown to be closed under taking minors. The graph K 7 is a forbidden minor for membership in L 2 , while K 3 and K 5 are the only minimal forbidden minors for the classes L 0 and L 1 , respectively."
            },
            "slug": "Semidefinite-Relaxations-for-Max-Cut-Laurent",
            "title": {
                "fragments": [],
                "text": "Semidefinite Relaxations for Max-Cut"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that the tightest relaxation is obtained when aplying the Lasserre construction to the node formulation of the max-cut problem, and the class L t of the graphs G for which Q t (G) is the cut polytope of G is shown to be closed under taking minors."
            },
            "venue": {
                "fragments": [],
                "text": "The Sharpest Cut"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692448"
                        ],
                        "name": "P. Hammer",
                        "slug": "P.-Hammer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hammer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hammer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144250254"
                        ],
                        "name": "P. Hansen",
                        "slug": "P.-Hansen",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Hansen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hansen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744574"
                        ],
                        "name": "B. Simeone",
                        "slug": "B.-Simeone",
                        "structuredName": {
                            "firstName": "Bruno",
                            "lastName": "Simeone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Simeone"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "5), it is natural to ask the question: do fractional solutions yield partial information about the set of optimal solutions to the original integer program? One way in which to formalize this question is through the notion of persistence [102]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "19)\u2014where the interactions between variables are supermodular [102, 135]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "1 that the firstorder LP relaxation, when applied to integer programs with binary variables, has the strong persistency property [102], as summarized in Proposition 11."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "17) have studied in past and ongoing work by various authors, including the special cases of {0, 1}-quadratic programs [102], metric labeling with Potts models [132, 45], error-control coding problems [73, 75, 234, 223, 47, 59], independent set problems [177, 202], and various types of matching problems [13, 113, 201]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In the special case of binary variables, there are a number of links to work in the literature on pseudo-Boolean optimization [102, 34]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "[102] studied the roof-dual relaxation for binary quadratic programs, an LP relaxation which is equivalent to specializing the first-order LP to binary variables, and proved the following result:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 23630537,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "7c6da6017d0325a37787d78f5015700c45eaa765",
            "isKey": true,
            "numCitedBy": 333,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper is concerned with the \u2018primal\u2019 problem of maximizing a given quadratic pseudo-boolean function. Four equivalent problems are discussed\u2014the primal, the \u2018complementation\u2019, the \u2018discrete Rhys LP\u2019 and the \u2018weighted stability problem of a SAM graph\u2019. Each of them has a relaxation\u2014the \u2018roof dual\u2019, the \u2018quadratic complementation,\u2019 the \u2018continuous Rhys LP\u2019 and the \u2018fractional weighted stability problem of a SAM graph\u2019. The main result is that the four gaps associated with the four relaxations are equal. Furthermore, a solution to any of these problems leads at once to solutions of the other three equivalent ones. The four relaxations can be solved in polynomial time by transforming them to a bipartite maximum flow problem. The optimal solutions of the \u2018roof-dual\u2019 define \u2018best\u2019 linear majorantsp(x) off, having the following persistency property: if theith coefficient inp is positive (negative) thenxi=1 (0) in every optimum of the primal problem. Several characterizations are given for the case where these persistency results cannot be used to fix any variable of the primal. On the other hand, a class of gap-free functions (properly including the supermodular ones) is exhibited."
            },
            "slug": "Roof-duality,-complementation-and-persistency-in-Hammer-Hansen",
            "title": {
                "fragments": [],
                "text": "Roof duality, complementation and persistency in quadratic 0\u20131 optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The main result is that the four gaps associated with the four relaxations are equal, and a class of gap-free functions (properly including the supermodular ones) is exhibited."
            },
            "venue": {
                "fragments": [],
                "text": "Math. Program."
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721860"
                        ],
                        "name": "M. Wainwright",
                        "slug": "M.-Wainwright",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Wainwright",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wainwright"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 26
                            }
                        ],
                        "text": "See Wainwright and Jordan [242] for additional material on the ideas presented here."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6742134,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0288740f9bbf102d153d191989ed4d331d2e028b",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The Sherali-Adams (SA) and Lasserre (LS) approaches are \u201clift-and-project\u201d methods that generate nested sequences of linear and/or semidefinite relaxations of an arbitrary 0-1 polytope P \u2286 [0, 1]n. Although both procedures are known to terminate with an exact description of P after n steps, there are various open questions associated with characterizing, for particular problem classes, whether exactness is obtained at some step s < n. This paper provides sufficient conditions for exactness of these relaxations based on the hypergraph-theoretic notion of treewidth. More specifically, we relate the combinatorial structure of a given polynomial system to an underlying hypergraph. We prove that the complexity of assessing the global validity of moment sequences, and hence the tightness of the SA and LS relaxations, is determined by the treewidth of this hypergraph. We provide some examples to illustrate this characterization."
            },
            "slug": "Treewidth-based-conditions-for-exactness-of-the-and-Wainwright-Jordan",
            "title": {
                "fragments": [],
                "text": "Treewidth-based conditions for exactness of the Sherali-Adams and Lasserre relaxations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143930409"
                        ],
                        "name": "M. Chertkov",
                        "slug": "M.-Chertkov",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Chertkov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Chertkov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144307649"
                        ],
                        "name": "M. Stepanov",
                        "slug": "M.-Stepanov",
                        "structuredName": {
                            "firstName": "Mikhail",
                            "lastName": "Stepanov",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Stepanov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1979444,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cc98582ce465db51b794f2804f30594fa01df3a8",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "In Linear Programming (LP) decoding of a Low-Density-Parity-Check (LDPC) code one minimizes a linear functional, with coefficients related to log-likelihood ratios, over a relaxation of the polytope spanned by the codewords \\cite{03FWK}. In order to quantify LP decoding, and thus to describe performance of the error-correction scheme at moderate and large Signal-to-Noise-Ratios (SNR), it is important to study the relaxed polytope to understand better its vertexes, so-called pseudo-codewords, especially those which are neighbors of the zero codeword. In this manuscript we propose a technique to heuristically create a list of these neighbors and their distances. Our pseudo-codeword-search algorithm starts by randomly choosing the initial configuration of the noise. The configuration is modified through a discrete number of steps. Each step consists of two sub-steps. Firstly, one applies an LP decoder to the noise-configuration deriving a pseudo-codeword. Secondly, one finds configuration of the noise equidistant from the pseudo codeword and the zero codeword. The resulting noise configuration is used as an entry for the next step. The iterations converge rapidly to a pseudo-codeword neighboring the zero codeword. Repeated many times, this procedure is characterized by the distribution function (frequency spectrum) of the pseudo-codeword effective distance. The effective distance of the coding scheme is approximated by the shortest distance pseudo-codeword in the spectrum. The efficiency of the procedure is demonstrated on examples of the Tanner $[155,64,20]$ code and Margulis $p=7$ and $p=11$ codes (672 and 2640 bits long respectively) operating over an Additive-White-Gaussian-Noise (AWGN) channel."
            },
            "slug": "An-Efficient-Pseudo-Codeword-Search-Algorithm-for-Chertkov-Stepanov",
            "title": {
                "fragments": [],
                "text": "An Efficient Pseudo-Codeword Search Algorithm for Linear Programming Decoding of LDPC Codes"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This manuscript proposes a technique to heuristically create a list of so-called pseudo-codewords, especially those which are neighbors of the zero codeword, and their distances and demonstrates the efficiency of the procedure on examples of the Tanner and Margulis codes operating over an Additive-White-Gaussian-Noise (AWGN) channel."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792269"
                        ],
                        "name": "H. Kappen",
                        "slug": "H.-Kappen",
                        "structuredName": {
                            "firstName": "Hilbert",
                            "lastName": "Kappen",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kappen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783429"
                        ],
                        "name": "W. Wiegerinck",
                        "slug": "W.-Wiegerinck",
                        "structuredName": {
                            "firstName": "Wim",
                            "lastName": "Wiegerinck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Wiegerinck"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Further details on different variants of generalized sumproduct updates can be found in various papers [263, 264, 184, 163, 125]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18311336,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b05c266e258273ca5fe3643955cca243a825f470",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "The Cluster Variation method is a class of approximation methods containing the Bethe and Kikuchi approximations as special cases. We derive two novel iteration schemes for the Cluster Variation Method. One is a fixed point iteration scheme which gives a significant improvement over loopy BP. mean field and TAP methods on directed graphical models. The other is a gradient based method, that is guaranteed to converge and is shown to give useful results on random graphs with mild frustration. We conclude that the methods are of significant practical value for large inference problems."
            },
            "slug": "Novel-iteration-schemes-for-the-Cluster-Variation-Kappen-Wiegerinck",
            "title": {
                "fragments": [],
                "text": "Novel iteration schemes for the Cluster Variation Method"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "This work derives two novel iteration schemes for the Cluster Variation Method, one of which is a fixed point iteration scheme which gives a significant improvement over loopy BP and the other a gradient based method that is guaranteed to converge and is shown to give useful results on random graphs with mild frustration."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7647770"
                        ],
                        "name": "M. Padberg",
                        "slug": "M.-Padberg",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Padberg",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Padberg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In the polyhedral combinatorics literature, this set is known as the correlation polytope, or the cut polytope [66, 183]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Sontag and Jaakkola [214] examine the effect of tightened outer bounds on the marginal polytope, including the so-called cycle inequalities [66, 183]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4573196,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "62f677a4babf3c5fdfbbd9c0dd1c297b66e4eddb",
            "isKey": false,
            "numCitedBy": 348,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "We study unconstrained quadratic zero\u2013one programming problems havingn variables from a polyhedral point of view by considering the Boolean quadric polytope QPn inn(n+1)/2 dimensions that results from the linearization of the quadratic form. We show that QPn has a diameter of one, descriptively identify three families of facets of QPn and show that QPn is symmetric in the sense that all facets of QPn can be obtained from those that contain the origin by way of a mapping. The naive linear programming relaxation QPnLP of QPn is shown to possess the Trubin-property and its extreme points are shown to be {0,1/2,1}-valued. Furthermore, O(n3) facet-defining inequalities of QPn suffice to cut off all fractional vertices of QPnLP, whereas the family of facets described by us has at least O(3n) members. The problem is also studied for sparse quadratic forms (i.e. when several or many coefficients are zero) and conditions are given for the previous results to carry over to this case. Polynomially solvable problem instances are discussed and it is shown that the known polynomiality result for the maximization of nonnegative quadratic forms can be obtained by simply rounding the solution to the linear programming relaxation. In the case that the graph induced by the nonzero coefficients of the quadratic form is series-parallel, a complete linear description of the associated Boolean quadric polytope is given. The relationship of the Boolean quadric polytope associated to sparse quadratic forms with the vertex-packing polytope is discussed as well."
            },
            "slug": "The-boolean-quadric-polytope:-Some-characteristics,-Padberg",
            "title": {
                "fragments": [],
                "text": "The boolean quadric polytope: Some characteristics, facets and relatives"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "It is shown that the known polynomiality result for the maximization of nonnegative quadratic forms can be obtained by simply rounding the solution to the linear programming relaxation, and the Boolean quadric polytope QPn inn(n+1)/2 dimensions is considered."
            },
            "venue": {
                "fragments": [],
                "text": "Math. Program."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050895"
                        ],
                        "name": "S. Lauritzen",
                        "slug": "S.-Lauritzen",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Lauritzen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lauritzen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48616434"
                        ],
                        "name": "D. Spiegelhalter",
                        "slug": "D.-Spiegelhalter",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Spiegelhalter",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Spiegelhalter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 52
                            }
                        ],
                        "text": ") This result underlies the junction tree algorithm [69] for exact inference on arbitrary graphs:"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 72
                            }
                        ],
                        "text": "Our treatment is brief; further details can be found in various sources [1, 29, 63, 57, 69]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 58792451,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0a3767909649cf31d32e087693d93171af28ebe0",
            "isKey": false,
            "numCitedBy": 4303,
            "numCiting": 126,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Local-computations-with-probabilities-on-graphical-Lauritzen-Spiegelhalter",
            "title": {
                "fragments": [],
                "text": "Local computations with probabilities on graphical structures and their application to expert systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731770"
                        ],
                        "name": "P. Parrilo",
                        "slug": "P.-Parrilo",
                        "structuredName": {
                            "firstName": "Pablo",
                            "lastName": "Parrilo",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Parrilo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7166802,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "6d888b81b58c627ec2d12a578fe272c419b472cf",
            "isKey": false,
            "numCitedBy": 1513,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract.\u2002A hierarchy of convex relaxations for semialgebraic problems is introduced. For questions reducible to a finite number of polynomial equalities and inequalities, it is shown how to construct a complete family of polynomially sized semidefinite programming conditions that prove infeasibility. The main tools employed are a semidefinite programming formulation of the sum of squares decomposition for multivariate polynomials, and some results from real algebraic geometry. The techniques provide a constructive approach for finding bounded degree solutions to the Positivstellensatz, and are illustrated with examples from diverse application fields."
            },
            "slug": "Semidefinite-programming-relaxations-for-problems-Parrilo",
            "title": {
                "fragments": [],
                "text": "Semidefinite programming relaxations for semialgebraic problems"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "It is shown how to construct a complete family of polynomially sized semidefinite programming conditions that prove infeasibility and provide a constructive approach for finding bounded degree solutions to the Positivstellensatz."
            },
            "venue": {
                "fragments": [],
                "text": "Math. Program."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052960694"
                        ],
                        "name": "J. Pierce",
                        "slug": "J.-Pierce",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Pierce",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pierce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 128
                            }
                        ],
                        "text": "For various classes of problems in combinatorial optimization, such LP relaxations have been studied extensively; see the books [49, 79] for further details."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59227675,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7cd97b0579ea3e4be968b4f52ce83ad06f2e7349",
            "isKey": false,
            "numCitedBy": 1576,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Geometric-Algorithms-and-Combinatorial-Optimization-Pierce",
            "title": {
                "fragments": [],
                "text": "Geometric Algorithms and Combinatorial Optimization"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680574"
                        ],
                        "name": "M. Seeger",
                        "slug": "M.-Seeger",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Seeger",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Seeger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We refer the reader to Minka [169, 172] and Seeger [208] for further details of the Gaussian-mixture EP algorithm and some of its properties."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1139278,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "80a992011660efa9c2916663312affdb6a8b407c",
            "isKey": false,
            "numCitedBy": 151,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "This is a tutorial describing the Expectation Propagation (EP) algorithm for a general exponential family. Our focus is on simplicity of exposition. Although the overhead of translating a specific model into its exponential family representation can be considerable, many apparent complications of EP can simply be sidestepped by working in this canonical representation."
            },
            "slug": "Expectation-Propagation-for-Exponential-Families-Seeger",
            "title": {
                "fragments": [],
                "text": "Expectation Propagation for Exponential Families"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "This is a tutorial describing the Expectation Propagation algorithm for a general exponential family and its focus is on simplicity of exposition."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725180"
                        ],
                        "name": "T. Cormen",
                        "slug": "T.-Cormen",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Cormen",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Cormen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145372049"
                        ],
                        "name": "C. Leiserson",
                        "slug": "C.-Leiserson",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Leiserson",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Leiserson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113911099"
                        ],
                        "name": "R. Rivest",
                        "slug": "R.-Rivest",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Rivest",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rivest"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This result also has algorithmic consequences, in that it reduces the problem of assessing conditional independence to the problem of assessing reachability on a graph, which is readily solved using simple breadth-first search algorithms [53]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 222237163,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f01c4e51cb33f4bed8d37832dc1325ec5dedf49d",
            "isKey": false,
            "numCitedBy": 12424,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nThe updated new edition of the classic Introduction to Algorithms is intended primarily for use in undergraduate or graduate courses in algorithms or data structures. Like the first edition,this text can also be used for self-study by technical professionals since it discusses engineering issues in algorithm design as well as the mathematical aspects. \nIn its new edition,Introduction to Algorithms continues to provide a comprehensive introduction to the modern study of algorithms. The revision has been updated to reflect changes in the years since the book's original publication. New chapters on the role of algorithms in computing and on probabilistic analysis and randomized algorithms have been included. Sections throughout the book have been rewritten for increased clarity,and material has been added wherever a fuller explanation has seemed useful or new information warrants expanded coverage. \nAs in the classic first edition,this new edition of Introduction to Algorithms presents a rich variety of algorithms and covers them in considerable depth while making their design and analysis accessible to all levels of readers. Further,the algorithms are presented in pseudocode to make the book easily accessible to students from all programming language backgrounds. \nEach chapter presents an algorithm,a design technique,an application area,or a related topic. The chapters are not dependent on one another,so the instructor can organize his or her use of the book in the way that best suits the course's needs. Additionally,the new edition offers a 25% increase over the first edition in the number of problems,giving the book 155 problems and over 900 exercises thatreinforcethe concepts the students are learning."
            },
            "slug": "Introduction-to-Algorithms-Cormen-Leiserson",
            "title": {
                "fragments": [],
                "text": "Introduction to Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The updated new edition of the classic Introduction to Algorithms is intended primarily for use in undergraduate or graduate courses in algorithms or data structures and presents a rich variety of algorithms and covers them in considerable depth while making their design and analysis accessible to all levels of readers."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 32583695,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "70ef29e6f0ce082bb8a47fd85b9bfb7cc0f20c93",
            "isKey": false,
            "numCitedBy": 18218,
            "numCiting": 230,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nProbabilistic Reasoning in Intelligent Systems is a complete andaccessible account of the theoretical foundations and computational methods that underlie plausible reasoning under uncertainty. The author provides a coherent explication of probability as a language for reasoning with partial belief and offers a unifying perspective on other AI approaches to uncertainty, such as the Dempster-Shafer formalism, truth maintenance systems, and nonmonotonic logic. The author distinguishes syntactic and semantic approaches to uncertainty\u0097and offers techniques, based on belief networks, that provide a mechanism for making semantics-based systems operational. Specifically, network-propagation techniques serve as a mechanism for combining the theoretical coherence of probability theory with modern demands of reasoning-systems technology: modular declarative inputs, conceptually meaningful inferences, and parallel distributed computation. Application areas include diagnosis, forecasting, image interpretation, multi-sensor fusion, decision support systems, plan recognition, planning, speech recognition\u0097in short, almost every task requiring that conclusions be drawn from uncertain clues and incomplete information. \nProbabilistic Reasoning in Intelligent Systems will be of special interest to scholars and researchers in AI, decision theory, statistics, logic, philosophy, cognitive psychology, and the management sciences. Professionals in the areas of knowledge-based systems, operations research, engineering, and statistics will find theoretical and computational tools of immediate practical use. The book can also be used as an excellent text for graduate-level courses in AI, operations research, or applied probability."
            },
            "slug": "Probabilistic-reasoning-in-intelligent-systems-of-Pearl",
            "title": {
                "fragments": [],
                "text": "Probabilistic reasoning in intelligent systems - networks of plausible inference"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The author provides a coherent explication of probability as a language for reasoning with partial belief and offers a unifying perspective on other AI approaches to uncertainty, such as the Dempster-Shafer formalism, truth maintenance systems, and nonmonotonic logic."
            },
            "venue": {
                "fragments": [],
                "text": "Morgan Kaufmann series in representation and reasoning"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2338183"
                        ],
                        "name": "M. M\u00e9zard",
                        "slug": "M.-M\u00e9zard",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "M\u00e9zard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. M\u00e9zard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145052965"
                        ],
                        "name": "G. Parisi",
                        "slug": "G.-Parisi",
                        "structuredName": {
                            "firstName": "Giorgio",
                            "lastName": "Parisi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Parisi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719010"
                        ],
                        "name": "R. Zecchina",
                        "slug": "R.-Zecchina",
                        "structuredName": {
                            "firstName": "Riccardo",
                            "lastName": "Zecchina",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zecchina"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The survey propagation algorithm, developed in the statistical physics community [168, 167], turns out to be very successful in solving random instances of 3-SAT."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15150698,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bed19807ad7676a8897526329b0aa705203f079e",
            "isKey": false,
            "numCitedBy": 865,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the satisfiability of random Boolean expressions built from many clauses with K variables per clause (K-satisfiability). Expressions with a ratio \u03b1 of clauses to variables less than a threshold \u03b1c are almost always satisfiable, whereas those with a ratio above this threshold are almost always unsatisfiable. We show the existence of an intermediate phase below \u03b1c, where the proliferation of metastable states is responsible for the onset of complexity in search algorithms. We introduce a class of optimization algorithms that can deal with these metastable states; one such algorithm has been tested successfully on the largest existing benchmark of K-satisfiability."
            },
            "slug": "Analytic-and-Algorithmic-Solution-of-Random-M\u00e9zard-Parisi",
            "title": {
                "fragments": [],
                "text": "Analytic and Algorithmic Solution of Random Satisfiability Problems"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A class of optimization algorithms that can deal with the proliferation of metastable states are introduced; one such algorithm has been tested successfully on the largest existing benchmark of K-satisfiability."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723150"
                        ],
                        "name": "R. McEliece",
                        "slug": "R.-McEliece",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "McEliece",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. McEliece"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145852650"
                        ],
                        "name": "D. Mackay",
                        "slug": "D.-Mackay",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mackay",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mackay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157745208"
                        ],
                        "name": "Jung-Fu Cheng",
                        "slug": "Jung-Fu-Cheng",
                        "structuredName": {
                            "firstName": "Jung-Fu",
                            "lastName": "Cheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jung-Fu Cheng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "One important domain in which hard-core constraints arise is communication theory, and in particular the problem of error-control coding [84, 164, 196]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14553992,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "26d953005dd08a863c157b528bbabdf5671d18b6",
            "isKey": false,
            "numCitedBy": 1004,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the close connection between the now celebrated iterative turbo decoding algorithm of Berrou et al. (1993) and an algorithm that has been well known in the artificial intelligence community for a decade, but which is relatively unknown to information theorists: Pearl's (1982) belief propagation algorithm. We see that if Pearl's algorithm is applied to the \"belief network\" of a parallel concatenation of two or more codes, the turbo decoding algorithm immediately results. Unfortunately, however, this belief diagram has loops, and Pearl only proved that his algorithm works when there are no loops, so an explanation of the experimental performance of turbo decoding is still lacking. However, we also show that Pearl's algorithm can be used to routinely derive previously known iterative, but suboptimal, decoding algorithms for a number of other error-control systems, including Gallager's (1962) low-density parity-check codes, serially concatenated codes, and product codes. Thus, belief propagation provides a very attractive general methodology for devising low-complexity iterative decoding algorithms for hybrid coded systems."
            },
            "slug": "Turbo-Decoding-as-an-Instance-of-Pearl's-\"Belief-McEliece-Mackay",
            "title": {
                "fragments": [],
                "text": "Turbo Decoding as an Instance of Pearl's \"Belief Propagation\" Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that Pearl's algorithm can be used to routinely derive previously known iterative, but suboptimal, decoding algorithms for a number of other error-control systems, including Gallager's low-density parity-check codes, serially concatenated codes, and product codes."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE J. Sel. Areas Commun."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145155783"
                        ],
                        "name": "C. Robert",
                        "slug": "C.-Robert",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Robert",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Robert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144898907"
                        ],
                        "name": "G. Casella",
                        "slug": "G.-Casella",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Casella",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Casella"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59843537,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "64b483e8d68b3f7518c2078d1b707d4543b6f9dc",
            "isKey": false,
            "numCitedBy": 1223,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Are you looking to uncover monte carlo statistical methods springer texts in statistics Digitalbook. Correct here it is possible to locate as well as download monte carlo statistical methods springer texts in statistics Book. We've got ebooks for every single topic monte carlo statistical methods springer texts in statistics accessible for download cost-free. Search the site also as find Jean Campbell eBook in layout. We also have a fantastic collection of information connected to this Digitalbook for you. As well because the best part is you could assessment as well as download for monte carlo statistical methods springer texts in statistics eBook"
            },
            "slug": "Monte-Carlo-Statistical-Methods-(Springer-Texts-in-Robert-Casella",
            "title": {
                "fragments": [],
                "text": "Monte Carlo Statistical Methods (Springer Texts in Statistics)"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "It is possible to locate as well as download monte carlo statistical methods springer texts in statistics Book."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767325"
                        ],
                        "name": "Y. Censor",
                        "slug": "Y.-Censor",
                        "structuredName": {
                            "firstName": "Yair",
                            "lastName": "Censor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Censor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732625"
                        ],
                        "name": "S. Zenios",
                        "slug": "S.-Zenios",
                        "structuredName": {
                            "firstName": "Stavros",
                            "lastName": "Zenios",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Zenios"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This interpretation shows that the KL divergence is a particular example of a Bregman distance [39, 42]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "More generally, this iterative proportional fitting procedure is a special case of a broader class of iterative scaling, or successive projection algorithms; see papers [58, 56, 57] or the book [42] for further details on such algorithms and their properties."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 115480745,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5d044b2ece3579ad1d6452f725524694a078b4cc",
            "isKey": false,
            "numCitedBy": 393,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Foreword Preface Glossary of Symbols 1. Introduction Part I Theory 2. Generalized Distances and Generalized Projections 3. Proximal Minimization with D-Functions Part II Algorithms 4. Penalty Methods, Barrier Methods and Augmented Lagrangians 5. Iterative Methods for Convex Feasibility Problems 6. Iterative Algorithms for Linearly Constrained Optimization Problems 7. Model Decomposition Algorithms 8. Decompositions in Interior Point Algorithms Part III Applications 9. Matrix Estimation Problems 10. Image Reconsturction from Projections 11. The Inverse Problem in Radiation Therapy Treatment Planning 12. Multicommodity Network Flow Problems 13. Planning Under Uncertainty 14. Decompositions for Parallel Computing 15. Numerical Investigations"
            },
            "slug": "Parallel-Optimization:-Theory,-Algorithms,-and-Censor-Zenios",
            "title": {
                "fragments": [],
                "text": "Parallel Optimization: Theory, Algorithms, and Applications"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145881044"
                        ],
                        "name": "M. Luby",
                        "slug": "M.-Luby",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Luby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Luby"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745699"
                        ],
                        "name": "M. Mitzenmacher",
                        "slug": "M.-Mitzenmacher",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Mitzenmacher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mitzenmacher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143916589"
                        ],
                        "name": "A. Shokrollahi",
                        "slug": "A.-Shokrollahi",
                        "structuredName": {
                            "firstName": "Amin",
                            "lastName": "Shokrollahi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shokrollahi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2417095"
                        ],
                        "name": "D. Spielman",
                        "slug": "D.-Spielman",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Spielman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Spielman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The behavior of sum-product algorithm is well understood in the asymptotic limit (as the code length m goes to infinity), where martingale arguments can be used to prove concentration results [195, 157]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1880834,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8e901f2445df1e34f31f56794af85de0569cdc67",
            "isKey": false,
            "numCitedBy": 827,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We construct new families of error-correcting codes based on Gallager's (1973) low-density parity-check codes. We improve on Gallager's results by introducing irregular parity-check matrices and a new rigorous analysis of hard-decision decoding of these codes. We also provide efficient methods for finding good irregular structures for such decoding algorithms. Our rigorous analysis based on martingales, our methodology for constructing good irregular codes, and the demonstration that irregular structure improves performance constitute key points of our contribution. We also consider irregular codes under belief propagation. We report the results of experiments testing the efficacy of irregular codes on both binary-symmetric and Gaussian channels. For example, using belief propagation, for rate 1/4 codes on 16000 bits over a binary-symmetric channel, previous low-density parity-check codes can correct up to approximately 16% errors, while our codes correct over 17%. In some cases our results come very close to reported results for turbo codes, suggesting that variations of irregular low density parity-check codes may be able to match or beat turbo code performance."
            },
            "slug": "Improved-low-density-parity-check-codes-using-Luby-Mitzenmacher",
            "title": {
                "fragments": [],
                "text": "Improved low-density parity-check codes using irregular graphs"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The results of experiments testing the efficacy of irregular codes on both binary-symmetric and Gaussian channels suggest that variations of irregular low density parity-check codes may be able to match or beat turbo code performance."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38838239"
                        ],
                        "name": "J. Feldman",
                        "slug": "J.-Feldman",
                        "structuredName": {
                            "firstName": "Jon",
                            "lastName": "Feldman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Feldman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769717"
                        ],
                        "name": "T. Malkin",
                        "slug": "T.-Malkin",
                        "structuredName": {
                            "firstName": "Tal",
                            "lastName": "Malkin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Malkin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729835"
                        ],
                        "name": "R. Servedio",
                        "slug": "R.-Servedio",
                        "structuredName": {
                            "firstName": "Rocco",
                            "lastName": "Servedio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Servedio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690758"
                        ],
                        "name": "C. Stein",
                        "slug": "C.-Stein",
                        "structuredName": {
                            "firstName": "Clifford",
                            "lastName": "Stein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Stein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721860"
                        ],
                        "name": "M. Wainwright",
                        "slug": "M.-Wainwright",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Wainwright",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wainwright"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4664994,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e45a001f9d3c044efc680611a0394c1b89157fb",
            "isKey": false,
            "numCitedBy": 114,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We show that for low-density parity-check (LDPC) codes whose Tanner graphs have sufficient expansion, the linear programming (LP) decoder of Feldman, Karger, and Wainwright can correct a constant fraction of errors. A random graph will have sufficient expansion with high probability, and recent work shows that such graphs can be constructed efficiently. A key element of our method is the use of a dual witness: a zero-valued dual solution to the decoding linear program whose existence proves decoding success. We show that as long as no more than a certain constant fraction of the bits are flipped by the channel, we can find a dual witness. This new method can be used for proving bounds on the performance of any LP decoder, even in a probabilistic setting. Our result implies that the word error rate of the LP decoder decreases exponentially in the code length under the binary-symmetric channel (BSC). This is the first such error bound for LDPC codes using an analysis based on \"pseudocodewords.\" Recent work by Koetter and Vontobel shows that LP decoding and min-sum decoding of LDPC codes are closely related by the \"graph cover\" structure of their pseudocodewords; in their terminology, our result implies that that there exist families of LDPC codes where the minimum BSC pseudoweight grows linearly in the block length"
            },
            "slug": "LP-Decoding-Corrects-a-Constant-Fraction-of-Errors-Feldman-Malkin",
            "title": {
                "fragments": [],
                "text": "LP Decoding Corrects a Constant Fraction of Errors"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "It is shown that for low-density parity-check (LDPC) codes whose Tanner graphs have sufficient expansion, the linear programming (LP) decoder of Feldman, Karger, and Wainwright can correct a constant fraction of errors."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Information Theory"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7715701"
                        ],
                        "name": "R. Koetter",
                        "slug": "R.-Koetter",
                        "structuredName": {
                            "firstName": "Ralf",
                            "lastName": "Koetter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Koetter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2566577"
                        ],
                        "name": "P. Vontobel",
                        "slug": "P.-Vontobel",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Vontobel",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Vontobel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 215,
                                "start": 202
                            }
                        ],
                        "text": "Not surprisingly, given the role of the constraint set L(G) in the Bethe variational problem, there are close connections between LP decoding and standard iterative algorithms like sum-product decoding [73, 133, 75]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16913204,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4b52c1eeb0c86bb33b25ffcdf1987c38d25b4c1a",
            "isKey": false,
            "numCitedBy": 206,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Codewords in finite covers of a Tanner graph G are characterized. Since iterative, locally operating decoding algorithms cannot distinguish the underlying graph G from any covering graph, these codewords, dubbed pseudo-codewords are directly responible for sub-optimal behavior of iterative decoding algorithms. We give a simple characterization of pseudocodewords from finite covers and show that, for the additive, white Gaussian noise channel, their impact is captured in a finite set of \u201cminimal\u201d pseudocodewords. We also show that any (j, k)-regular graph possesses asymptotically vanishing relative minimal pseudo-weight. This stands in sharp contrast to the observation that for j > 2 the minimum Hamming distance of a (j, k)-regular low-density parity-check code typically grows linearly with the length of the code."
            },
            "slug": "Graph-covers-and-iterative-decoding-of-nite-length-Koetter-Vontobel",
            "title": {
                "fragments": [],
                "text": "Graph-covers and iterative decoding of nite length codes"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A simple characterization of pseudocodewords from finite covers is given and it is shown that, for the additive, white Gaussian noise channel, their impact is captured in a finite set of \u201cminimal\u201d pseudo-codewords."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718469"
                        ],
                        "name": "A. Dimakis",
                        "slug": "A.-Dimakis",
                        "structuredName": {
                            "firstName": "Alexandros",
                            "lastName": "Dimakis",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dimakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6475907"
                        ],
                        "name": "A. Gohari",
                        "slug": "A.-Gohari",
                        "structuredName": {
                            "firstName": "Amin",
                            "lastName": "Gohari",
                            "middleNames": [
                                "Aminzadeh"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gohari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721860"
                        ],
                        "name": "M. Wainwright",
                        "slug": "M.-Wainwright",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Wainwright",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wainwright"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 61155636,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1456195424040249e3d4f45607c638dd40709e71",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "A new approach for decoding binary linear codes by solving a linear program (LP) over a relaxed codeword polytope was recently proposed by Feldman et al. In this paper we investigate the structure of the polytope used in the LP relaxation decoding. We begin by showing that for expander codes, every fractional pseudocodeword always has at least a constant fraction of non-integral bits. We then prove that for expander codes, the active set of any fractional pseudocodeword is smaller by a constant fraction than the active set of any codeword. We exploit this fact to devise a decoding algorithm that provably outperforms the LP decoder for finite blocklengths. It proceeds by guessing facets of the polytope, and resolving the linear program on these facets. While the LP decoder succeeds only if the ML codeword has the highest likelihood over all pseudocodewords, we prove that for expander codes the proposed algorithm succeeds even with a constant number of pseudocodewords of higher likelihood. Moreover, the complexity of the proposed algorithm is only a constant factor larger than that of the LP decoder."
            },
            "slug": "Guessing-Facets:-Polytope-Structure-and-Improved-LP-Dimakis-Gohari",
            "title": {
                "fragments": [],
                "text": "Guessing Facets: Polytope Structure and Improved LP Decoding"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper investigates the structure of the polytope used in the LP relaxation decoding, and proves that for expander codes the proposed algorithm succeeds even with a constant number of pseudocodewords of higher likelihood."
            },
            "venue": {
                "fragments": [],
                "text": "ISIT"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143961444"
                        ],
                        "name": "M. Laurent",
                        "slug": "M.-Laurent",
                        "structuredName": {
                            "firstName": "Monique",
                            "lastName": "Laurent",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Laurent"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 12
                            }
                        ],
                        "text": "See Laurent [66, 67] for comparison of these sequences in a more general setting."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 108
                            }
                        ],
                        "text": "The validity of this nite termination in a general setting was proved by Lasserre [64], and also by Laurent [66, 67] using di erent methods."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 167
                            }
                        ],
                        "text": "Of course, we can also consider moments for higher-order multi-indices as well; doing so leads a special case of what is known as the Lasserre sequence of relaxations [64, 66]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13059510,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "6026ab578bc62efa73d5b98ac4a7ce1ba4756ffe",
            "isKey": false,
            "numCitedBy": 421,
            "numCiting": 79,
            "paperAbstract": {
                "fragments": [],
                "text": "Sherali and Adams [SA90], Lov\\''asz and Schrijver [LS91] and, recently, Lasserre [Las01b] have proposed lift and project methods for constructing hierarchies of successive linear or semidefinite relaxations of a $0-1$ polytope $P\\subseteq \\oR^n$ converging to $P$ in $n$ steps. Lasserre''s approach uses results about representations of positive polynomials as sums of squares and the dual theory of moments. We present the three methods in a common elementary framework and show that the Lasserre construction provides the tightest relaxations of $P$. As an application this gives a direct simple proof for the convergence of the Lasserre''s hierarchy. We describe applications to the stable set polytope and to the cut polytope."
            },
            "slug": "A-Comparison-of-the-Sherali-Adams,-and-Lasserre-for-Laurent",
            "title": {
                "fragments": [],
                "text": "A Comparison of the Sherali-Adams, Lov\u00e1sz-Schrijver, and Lasserre Relaxations for 0-1 Programming"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "The three methods for constructing hierarchies of successive linear or semidefinite relaxations of a polytope are presented in a common elementary framework and it is shown that the Lasserre construction provides the tightest Relaxations of P."
            },
            "venue": {
                "fragments": [],
                "text": "Math. Oper. Res."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115806726"
                        ],
                        "name": "Alun Thomas",
                        "slug": "Alun-Thomas",
                        "structuredName": {
                            "firstName": "Alun",
                            "lastName": "Thomas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alun Thomas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1774779"
                        ],
                        "name": "A. Gutin",
                        "slug": "A.-Gutin",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Gutin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gutin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3013000"
                        ],
                        "name": "V. Abkevich",
                        "slug": "V.-Abkevich",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Abkevich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Abkevich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49374535"
                        ],
                        "name": "A. Bansal",
                        "slug": "A.-Bansal",
                        "structuredName": {
                            "firstName": "Aruna",
                            "lastName": "Bansal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bansal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This model captures the problem of multi-locus linkage analysis in genetics, where the state variables correspond to phase (maternal or paternal) along the chromosomes in meiosis [227]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14911089,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "47591eeaba44936184ee6a7fca30166083b560c2",
            "isKey": false,
            "numCitedBy": 121,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of multilocus linkage analysis is expressed as a graphical model, making explicit a previously implicit connection, and recent developments in the field are described in this context. A novel application of blocked Gibbs sampling for Bayesian networks is developed to generate inheritance matrices from an irreducible Markov chain. This is used as the basis for reconstruction of historical meiotic states and approximate calculation of the likelihood function for the location of an unmapped genetic trait. We believe this to be the only approach that currently makes fully informative multilocus linkage analysis possible on large extended pedigrees."
            },
            "slug": "Multilocus-linkage-analysis-by-blocked-Gibbs-Thomas-Gutin",
            "title": {
                "fragments": [],
                "text": "Multilocus linkage analysis by blocked Gibbs sampling"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is believed that the only approach that currently makes fully informative multilocus linkage analysis possible on large extended pedigrees is the novel application of blocked Gibbs sampling for Bayesian networks."
            },
            "venue": {
                "fragments": [],
                "text": "Stat. Comput."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708061"
                        ],
                        "name": "E. Boros",
                        "slug": "E.-Boros",
                        "structuredName": {
                            "firstName": "Endre",
                            "lastName": "Boros",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Boros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804430"
                        ],
                        "name": "Y. Crama",
                        "slug": "Y.-Crama",
                        "structuredName": {
                            "firstName": "Yves",
                            "lastName": "Crama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Crama"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692448"
                        ],
                        "name": "P. Hammer",
                        "slug": "P.-Hammer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hammer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hammer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[33], and Sherali and Adams [212], although without the connections to the underlying graphical structure provided by Proposition 13."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 123061451,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3290796e95b2f9097f3c0e8b3d984080ca04b1b1",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Upper-bounds-for-quadratic-0-1-maximization-Boros-Crama",
            "title": {
                "fragments": [],
                "text": "Upper-bounds for quadratic 0-1 maximization"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47546648"
                        ],
                        "name": "R. Karp",
                        "slug": "R.-Karp",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Karp",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Karp"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 240
                            }
                        ],
                        "text": "For a general graph with cycles, this discrete mode-finding problem is known to be computationally intractable, since it includes as special cases many problems known to be NP-complete, among them MAXCUT and related satisfiability problems [128]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 33509266,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9fb53a3bdfb47230eeaf7d956b1a238db5cba690",
            "isKey": false,
            "numCitedBy": 9779,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "Throughout the 1960s I worked on combinatorial optimization problems including logic circuit design with Paul Roth and assembly line balancing and the traveling salesman problem with Mike Held. These experiences made me aware that seemingly simple discrete optimization problems could hold the seeds of combinatorial explosions. The work of Dantzig, Fulkerson, Hoffman, Edmonds, Lawler and other pioneers on network flows, matching and matroids acquainted me with the elegant and efficient algorithms that were sometimes possible. Jack Edmonds\u2019 papers and a few key discussions with him drew my attention to the crucial distinction between polynomial-time and superpolynomial-time solvability. I was also influenced by Jack\u2019s emphasis on min-max theorems as a tool for fast verification of optimal solutions, which foreshadowed Steve Cook\u2019s definition of the complexity class NP. Another influence was George Dantzig\u2019s suggestion that integer programming could serve as a universal format for combinatorial optimization problems."
            },
            "slug": "Reducibility-Among-Combinatorial-Problems-Karp",
            "title": {
                "fragments": [],
                "text": "Reducibility Among Combinatorial Problems"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "Throughout the 1960s I worked on combinatorial optimization problems including logic circuit design with Paul Roth and assembly line balancing and the traveling salesman problem with Mike Held, which made me aware of the importance of distinction between polynomial-time and superpolynomial-time solvability."
            },
            "venue": {
                "fragments": [],
                "text": "50 Years of Integer Programming"
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143930409"
                        ],
                        "name": "M. Chertkov",
                        "slug": "M.-Chertkov",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Chertkov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Chertkov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144307649"
                        ],
                        "name": "M. Stepanov",
                        "slug": "M.-Stepanov",
                        "structuredName": {
                            "firstName": "Mikhail",
                            "lastName": "Stepanov",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Stepanov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9001227,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ddb691da2ff3a2108d247402238218f46ad7fdc8",
            "isKey": false,
            "numCitedBy": 50,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "In linear programming (LP) decoding of a low-density parity-check (LDPC) code one minimizes a linear functional, with coefficients related to log-likelihood ratios, over a relaxation of the polytope spanned by the codewords. In order to quantify LP decoding it is important to study vertexes of the relaxed polytope, so-called pseudocodewords. We propose a technique to heuristcally create a list of pseudocodewords close to the zero codeword and their distances. Our pseudocodeword-search algorithm starts by randomly choosing configuration of the noise. The configuration is modified through a discrete number of steps. Each step consists of two substeps: one applies an LP decoder to the noise-configuration deriving a pseudocodeword, and then finds configuration of the noise equidistant from the pseudocodeword and the zero codeword. The resulting noise configuration is used as an entry for the next step. The iterations converge rapidly to a pseudocodeword neighboring the zero codeword. Repeated many times, this procedure is characterized by the distribution function of the pseudocodeword effective distance. The efficiency of the procedure is demonstrated on examples of the Tanner code and Margulis codes operating over an additive white Gaussian noise (AWGN) channel."
            },
            "slug": "An-Efficient-Pseudocodeword-Search-Algorithm-for-of-Chertkov-Stepanov",
            "title": {
                "fragments": [],
                "text": "An Efficient Pseudocodeword Search Algorithm for Linear Programming Decoding of LDPC Codes"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work proposes a technique to heuristcally create a list of pseudocodewords close to the zero codeword and their distances, and demonstrates the efficiency of the procedure on examples of the Tanner code and Margulis codes operating over an additive white Gaussian noise (AWGN) channel."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Information Theory"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102835246"
                        ],
                        "name": "J. Hiriart-Urruty",
                        "slug": "J.-Hiriart-Urruty",
                        "structuredName": {
                            "firstName": "Jean-Baptiste",
                            "lastName": "Hiriart-Urruty",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hiriart-Urruty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8773884"
                        ],
                        "name": "C. Lemar\u00e9chal",
                        "slug": "C.-Lemar\u00e9chal",
                        "structuredName": {
                            "firstName": "Claude",
                            "lastName": "Lemar\u00e9chal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lemar\u00e9chal"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Rockafellar [198] is a standard reference on convex analysis; see also the books by Hiriart-Urruty and Lemar\u00e9chal [109, 110], Boyd and Vandenberghe [36], and Bertsekas [21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 118023878,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "e820a224d0f55a7bdae9ed2034a5efd8ae44fc13",
            "isKey": false,
            "numCitedBy": 799,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Introduction: Notation, Elementary Results.- Convex Sets: Generalities Convex Sets Attached to a Convex Set Projection onto Closed Convex Sets Separation and Applications Conical Approximations of Convex Sets.- Convex Functions: Basic Definitions and Examples Functional Operations Preserving Convexity Local and Global Behaviour of a Convex Function First- and Second-Order Differentiation.- Sublinearity and Support Functions: Sublinear Functions The Support Function of a Nonempty Set Correspondence Between Convex Sets and Sublinear Functions.- Subdifferentials of Finite Convex Functions: The Subdifferential: Definitions and Interpretations Local Properties of the Subdifferential First Examples Calculus Rules with Subdifferentials Further Examples The Subdifferential as a Multifunction.- Conjugacy in Convex Analysis: The Convex Conjugate of a Function Calculus Rules on the Conjugacy Operation Various Examples Differentiability of a Conjugate Function."
            },
            "slug": "Fundamentals-of-Convex-Analysis-Hiriart-Urruty-Lemar\u00e9chal",
            "title": {
                "fragments": [],
                "text": "Fundamentals of Convex Analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1853084"
                        ],
                        "name": "H. Georgii",
                        "slug": "H.-Georgii",
                        "structuredName": {
                            "firstName": "Hans-Otto",
                            "lastName": "Georgii",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Georgii"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[199] provide sufficient conditions for convergence, based on contraction arguments such as those used for ordinary sumproduct [225, 87, 175, 115]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": ", Dobrushin\u2019s condition or Simon\u2019s condition [87])."
                    },
                    "intents": []
                }
            ],
            "corpusId": 60742687,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "a94f0df561c8b2431cf5922b5f8b9067093b13e7",
            "isKey": false,
            "numCitedBy": 1617,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "From a review of the first edition: \"This book [...] covers in depth a broad range of topics in the mathematical theory of phase transition in statistical mechanics. [...] It is in fact one of the author's stated aims that this comprehensive monograph should serve both as an introductory text and as a reference for the expert.\" (F. Papangelou, \"Zentralblatt MATH\"). The second edition has been extended by a new section on large deviations and some comments on the more recent developments in the area."
            },
            "slug": "Gibbs-Measures-and-Phase-Transitions-Georgii",
            "title": {
                "fragments": [],
                "text": "Gibbs Measures and Phase Transitions"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This comprehensive monograph covers in depth a broad range of topics in the mathematical theory of phase transition in statistical mechanics and serves both as an introductory text and as a reference for the expert."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2588854"
                        ],
                        "name": "M. Gr\u00f6tschel",
                        "slug": "M.-Gr\u00f6tschel",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Gr\u00f6tschel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gr\u00f6tschel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2555258"
                        ],
                        "name": "K. Truemper",
                        "slug": "K.-Truemper",
                        "structuredName": {
                            "firstName": "Klaus",
                            "lastName": "Truemper",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Truemper"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 98
                            }
                        ],
                        "text": "There is a rich literature in combinatorics on the structure of these codeword or cycle polytopes [8, 210, 100, 66]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 42176839,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "33db45e56460b6f5fff57c107192e830aa210a8f",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Decomposition-and-optimization-over-cycles-in-Gr\u00f6tschel-Truemper",
            "title": {
                "fragments": [],
                "text": "Decomposition and optimization over cycles in binary matroids"
            },
            "venue": {
                "fragments": [],
                "text": "J. Comb. Theory, Ser. B"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2566577"
                        ],
                        "name": "P. Vontobel",
                        "slug": "P.-Vontobel",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Vontobel",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Vontobel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7715701"
                        ],
                        "name": "R. Koetter",
                        "slug": "R.-Koetter",
                        "structuredName": {
                            "firstName": "Ralf",
                            "lastName": "Koetter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Koetter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3258940,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce997ac540edb4ec33c8fa5c83f1bf5038f303bd",
            "isKey": false,
            "numCitedBy": 92,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider linear-programming (LP) decoding of low-density parity-check (LDPC) codes. While it is clear that one can use any general-purpose LP solver to solve the LP that appears in the decoding problem, we argue in this paper that the LP at hand is equipped with a lot of structure that one should take advantage of. Towards this goal, we study the dual LP and show how coordinate-ascent methods lead to very simple update rules that are tightly connected to the min-sum algorithm. Moreover, replacing minima in the formula of the dual LP with soft-minima one obtains update rules that are tightly connected to the sum-product algorithm. This shows that LP solvers with complexity similar to the min-sum algorithm and the sum-product algorithm are feasible. Finally, we also discuss some sub-gradient-based methods."
            },
            "slug": "Towards-Low-Complexity-Linear-Programming-Decoding-Vontobel-Koetter",
            "title": {
                "fragments": [],
                "text": "Towards Low-Complexity Linear-Programming Decoding"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is argued in this paper that the LP at hand is equipped with a lot of structure that one should take advantage of and shows that LP solvers with complexity similar to the min-sum algorithm and the sum-product algorithm are feasible."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144197258"
                        ],
                        "name": "A. Krogh",
                        "slug": "A.-Krogh",
                        "structuredName": {
                            "firstName": "Anders",
                            "lastName": "Krogh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krogh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068607634"
                        ],
                        "name": "B. Larsson",
                        "slug": "B.-Larsson",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Larsson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Larsson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3300090"
                        ],
                        "name": "G. von Heijne",
                        "slug": "G.-von-Heijne",
                        "structuredName": {
                            "firstName": "Gunnar",
                            "lastName": "von Heijne",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. von Heijne"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3148925"
                        ],
                        "name": "E. Sonnhammer",
                        "slug": "E.-Sonnhammer",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Sonnhammer",
                            "middleNames": [
                                "L.",
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Sonnhammer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "These and other biological facts are used to design the states and state transition matrix of the transmembrane hidden Markov model, an HMM for modeling membrane proteins [138]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15769874,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "05e7f7d5d5a08e0bcaca7497951c9560c546353d",
            "isKey": false,
            "numCitedBy": 10603,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe and validate a new membrane protein topology prediction method, TMHMM, based on a hidden Markov model. We present a detailed analysis of TMHMM's performance, and show that it correctly predicts 97-98 % of the transmembrane helices. Additionally, TMHMM can discriminate between soluble and membrane proteins with both specificity and sensitivity better than 99 %, although the accuracy drops when signal peptides are present. This high degree of accuracy allowed us to predict reliably integral membrane proteins in a large collection of genomes. Based on these predictions, we estimate that 20-30 % of all genes in most genomes encode membrane proteins, which is in agreement with previous estimates. We further discovered that proteins with N(in)-C(in) topologies are strongly preferred in all examined organisms, except Caenorhabditis elegans, where the large number of 7TM receptors increases the counts for N(out)-C(in) topologies. We discuss the possible relevance of this finding for our understanding of membrane protein assembly mechanisms. A TMHMM prediction service is available at http://www.cbs.dtu.dk/services/TMHMM/."
            },
            "slug": "Predicting-transmembrane-protein-topology-with-a-to-Krogh-Larsson",
            "title": {
                "fragments": [],
                "text": "Predicting transmembrane protein topology with a hidden Markov model: application to complete genomes."
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "A new membrane protein topology prediction method, TMHMM, based on a hidden Markov model is described and validated, and it is discovered that proteins with N(in)-C(in) topologies are strongly preferred in all examined organisms, except Caenorhabditis elegans, where the large number of 7TM receptors increases the counts for N(out)-C-in topologies."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of molecular biology"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2374377"
                        ],
                        "name": "M. Fisher",
                        "slug": "M.-Fisher",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Fisher",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fisher"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": ", Ising models of the form p\u03b8(x) \u221d exp{ \u2211 (s,t)\u2208E \u03b8stxsxt}), then it is possible to compute the cumulant function A(\u03b8) exactly, using clever combinatorial reductions due independently to Fisher [78] and Kastelyn [129]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 121287035,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a21b236577bbfacadcaf3e3c62413f72fb4379ad",
            "isKey": false,
            "numCitedBy": 259,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Derivations of the partition function of the Ising model on a general planar lattice L, which proceed via an associated dimer problem and use Pfaffians, are simplified by constructing a lattice L\u0394 (the ``terminal lattice'' derived from an ``expanded lattice'' of L) for which (A) the allowed dimer configurations are in one\u2010one correspondence with allowed Ising polygon configurations on L, and which (B) is planar if L is planar so that Kasteleyn's theorem may be used directly to construct the appropriate Pfaffian. This is in contrast to previous use of nonplanar associated dimer lattices for which the correspondence is not one\u2010one, so that is has been necessary to prove a somewhat obscure ``cancellation theorem.''"
            },
            "slug": "On-the-Dimer-Solution-of-Planar-Ising-Models-Fisher",
            "title": {
                "fragments": [],
                "text": "On the Dimer Solution of Planar Ising Models"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1966
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144653004"
                        ],
                        "name": "V. Kolmogorov",
                        "slug": "V.-Kolmogorov",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Kolmogorov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Kolmogorov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Various forms of these reweighted maxproduct algorithms have been applied in problems such as segmentation and disparity problems in computer vision [165, 134, 136, 246, 222, 260], error-control coding [73], side-chain prediction [261, 246], sensor fusion [43, 46]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "[240], and later resolved by Kolmogorov [134], who provided a counterexample, involving non-binary variables, for which a TRW max-product fixed point does not correspond to a dual-optimal solution."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Kolmogorov [134] also developed a clever sequential scheduling of TRW updates, and established certain convergence guarantees for these so-called TRW-S updates, and showed empirically that the sequential updates tend to outperform a standard parallel scheduling of the TRW max-product updates (8."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In addition to the basic TRW algorithm [240] and the TRWS scheduling studied by Kolmogorov [134], other researchers have proposed distributed algorithms for solving the tree-based LP relax-"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8616813,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0bcc580a1e9e32b3329363bab43331ed9c5a7d4",
            "isKey": true,
            "numCitedBy": 1302,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Algorithms for discrete energy minimization are of fundamental importance in computer vision. In this paper, we focus on the recent technique proposed by Wainwright et al. (Nov. 2005)- tree-reweighted max-product message passing (TRW). It was inspired by the problem of maximizing a lower bound on the energy. However, the algorithm is not guaranteed to increase this bound - it may actually go down. In addition, TRW does not always converge. We develop a modification of this algorithm which we call sequential tree-reweighted message passing. Its main property is that the bound is guaranteed not to decrease. We also give a weak tree agreement condition which characterizes local maxima of the bound with respect to TRW algorithms. We prove that our algorithm has a limit point that achieves weak tree agreement. Finally, we show that, our algorithm requires half as much memory as traditional message passing approaches. Experimental results demonstrate that on certain synthetic and real problems, our algorithm outperforms both the ordinary belief propagation and tree-reweighted algorithm in (M. J. Wainwright, et al., Nov. 2005). In addition, on stereo problems with Potts interactions, we obtain a lower energy than graph cuts"
            },
            "slug": "Convergent-Tree-Reweighted-Message-Passing-for-Kolmogorov",
            "title": {
                "fragments": [],
                "text": "Convergent Tree-Reweighted Message Passing for Energy Minimization"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This paper develops a modification of the recent technique proposed by Wainwright et al. (Nov. 2005), called sequential tree-reweighted message passing, which outperforms both the ordinary belief propagation and tree- reweighted algorithm in both synthetic and real problems."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103572659"
                        ],
                        "name": "R. Kikuchi",
                        "slug": "R.-Kikuchi",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Kikuchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kikuchi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 141
                            }
                        ],
                        "text": "We then describe various natural generalizations of the Bethe approximation, including Kikuchi clustering and other hypergraph-based methods [130, 264]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 131
                            }
                        ],
                        "text": "The origins underlying ideas lie in the statistical physics literature, where they were referred to as cluster variational methods [6, 224, 130]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 119505101,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "aa59898d5d643aec5cc523523f07b42452cd514e",
            "isKey": false,
            "numCitedBy": 1426,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method of approximation for order-disorder phenomena is developed. In Sec. A, the method is explained for the one-dimensional Ising lattice. Sections B and C cover the approximations already known, such as those of Bethe (Sec. B) and of Kramers-Wannier (Sec. C), which are shown to be derived as special cases of the method with suitable choices of variables. In Sec. D, an improved treatment is explained for the three-dimensional simple cubic Ising lattice. This approximation is found to agree with the rigorous expansion of the partition function up to the fourth moment by Kirkwood's moment method, so far as the disordered state is concerned. In Sec. E the general formula for the entropy is given. In Sec. H an improved treatment of the face-centered lattice (Ising model) is given."
            },
            "slug": "A-Theory-of-Cooperative-Phenomena-Kikuchi",
            "title": {
                "fragments": [],
                "text": "A Theory of Cooperative Phenomena"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1951
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705564"
                        ],
                        "name": "G. Nemhauser",
                        "slug": "G.-Nemhauser",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nemhauser",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nemhauser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736128"
                        ],
                        "name": "L. Wolsey",
                        "slug": "L.-Wolsey",
                        "structuredName": {
                            "firstName": "Laurence",
                            "lastName": "Wolsey",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Wolsey"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "which is another classical LP relaxation from the combinatorics literature [177]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The field of polyhedral combinatorics [66, 101, 177, 207] is devoted to understanding the structure of such polytopes arising from various classes of discrete problems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Many problems in satisfiability and combinatorial optimization [177] are defined in graph-theoretic terms, and thus are naturally recast in the graphical model formalism."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This LP relaxation is the classical one for the independent set problem [177, 231]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "17) have studied in past and ongoing work by various authors, including the special cases of {0, 1}-quadratic programs [102], metric labeling with Potts models [132, 45], error-control coding problems [73, 75, 234, 223, 47, 59], independent set problems [177, 202], and various types of matching problems [13, 113, 201]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Frequently, LP relaxations are developed in a manner tailored to specific subclasses of combinatorial problems [177, 231]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "When applied to combinatorial problems, the first-order LP relaxation recovers various known methods from the integer programming and approximation literature [177, 231]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 42076848,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "8a7e30d08fbc2cfc19dce0f3b3524fe664675d67",
            "isKey": true,
            "numCitedBy": 4678,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "FOUNDATIONS. The Scope of Integer and Combinatorial Optimization. Linear Programming. Graphs and Networks. Polyhedral Theory. Computational Complexity. Polynomial-Time Algorithms for Linear Programming. Integer Lattices. GENERAL INTEGER PROGRAMMING. The Theory of Valid Inequalities. Strong Valid Inequalities and Facets for Structured Integer Programs. Duality and Relaxation. General Algorithms. Special-Purpose Algorithms. Applications of Special- Purpose Algorithms. COMBINATORIAL OPTIMIZATION. Integral Polyhedra. Matching. Matroid and Submodular Function Optimization. References. Indexes."
            },
            "slug": "Integer-and-Combinatorial-Optimization-Nemhauser-Wolsey",
            "title": {
                "fragments": [],
                "text": "Integer and Combinatorial Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "This chapter discusses the Scope of Integer and Combinatorial Optimization, as well as applications of Special-Purpose Algorithms and Matching."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145980949"
                        ],
                        "name": "S. Verd\u00fa",
                        "slug": "S.-Verd\u00fa",
                        "structuredName": {
                            "firstName": "Sergio",
                            "lastName": "Verd\u00fa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Verd\u00fa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40228025"
                        ],
                        "name": "V. Poor",
                        "slug": "V.-Poor",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Poor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Poor"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 104
                            }
                        ],
                        "text": "More generally, updates of this form apply to arbitrary commutative semirings on tree-structured graphs [106, 97, 29, 1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 121014287,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0a0a5b8eff2a7039b867045bbb58392751d3e4d1",
            "isKey": false,
            "numCitedBy": 88,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The unifying purpose of the abstract dynamic programming models is to find sufficient conditions on the recursive definition of the objective function that guarantee the validity of the dynamic programming iteration. This paper presents backward, forward, and backward-forward models that weaken previous sufficient conditions and that include, but are not restricted to, optimization problems. The backward-forward model is devoted to the simultaneous solution of a collection of interrelated sequential problems based on the independent computation of a cost-to-arrive function and a cost-to-go function. Several extremization and nonextremization problems illustrate the applicability of the proposed models."
            },
            "slug": "Abstract-dynamic-programming-models-under-Verd\u00fa-Poor",
            "title": {
                "fragments": [],
                "text": "Abstract dynamic programming models under commutativity conditions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1932728"
                        ],
                        "name": "T. Richardson",
                        "slug": "T.-Richardson",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Richardson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Richardson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727633"
                        ],
                        "name": "R. Urbanke",
                        "slug": "R.-Urbanke",
                        "structuredName": {
                            "firstName": "R\u00fcdiger",
                            "lastName": "Urbanke",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Urbanke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 514746,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f2b32222ec8955c4378fd2804757f4f8449d9241",
            "isKey": false,
            "numCitedBy": 3014,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a general method for determining the capacity of low-density parity-check (LDPC) codes under message-passing decoding when used over any binary-input memoryless channel with discrete or continuous output alphabets. Transmitting at rates below this capacity, a randomly chosen element of the given ensemble will achieve an arbitrarily small target probability of error with a probability that approaches one exponentially fast in the length of the code. (By concatenating with an appropriate outer code one can achieve a probability of error that approaches zero exponentially fast in the length of the code with arbitrarily small loss in rate.) Conversely, transmitting at rates above this capacity the probability of error is bounded away from zero by a strictly positive constant which is independent of the length of the code and of the number of iterations performed. Our results are based on the observation that the concentration of the performance of the decoder around its average performance, as observed by Luby et al. in the case of a binary-symmetric channel and a binary message-passing algorithm, is a general phenomenon. For the particularly important case of belief-propagation decoders, we provide an effective algorithm to determine the corresponding capacity to any desired degree of accuracy. The ideas presented in this paper are broadly applicable and extensions of the general method to low-density parity-check codes over larger alphabets, turbo codes, and other concatenated coding schemes are outlined."
            },
            "slug": "The-capacity-of-low-density-parity-check-codes-Richardson-Urbanke",
            "title": {
                "fragments": [],
                "text": "The capacity of low-density parity-check codes under message-passing decoding"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The results are based on the observation that the concentration of the performance of the decoder around its average performance, as observed by Luby et al. in the case of a binary-symmetric channel and a binary message-passing algorithm, is a general phenomenon."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708061"
                        ],
                        "name": "E. Boros",
                        "slug": "E.-Boros",
                        "structuredName": {
                            "firstName": "Endre",
                            "lastName": "Boros",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Boros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692448"
                        ],
                        "name": "P. Hammer",
                        "slug": "P.-Hammer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hammer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hammer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In the special case of binary variables, there are a number of links to work in the literature on pseudo-Boolean optimization [102, 34]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11157651,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7b57d8ca6b0eadcb2689c4963e698bb4db1f23a7",
            "isKey": false,
            "numCitedBy": 804,
            "numCiting": 214,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Pseudo-Boolean-optimization-Boros-Hammer",
            "title": {
                "fragments": [],
                "text": "Pseudo-Boolean optimization"
            },
            "venue": {
                "fragments": [],
                "text": "Discret. Appl. Math."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749650"
                        ],
                        "name": "B. Frey",
                        "slug": "B.-Frey",
                        "structuredName": {
                            "firstName": "Brendan",
                            "lastName": "Frey",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Frey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7715701"
                        ],
                        "name": "R. Koetter",
                        "slug": "R.-Koetter",
                        "structuredName": {
                            "firstName": "Ralf",
                            "lastName": "Koetter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Koetter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688009"
                        ],
                        "name": "A. Vardy",
                        "slug": "A.-Vardy",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Vardy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vardy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Among other connections, the fractional vertices of the first-order LP relaxation have a very specific interpretation as pseudocodewords of the underlying code, studied in earlier work on iterative decoding [80, 252, 83]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2629101,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ebb8bf7807d28685945bac3158aad8e649933031",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "By tracing the flow of computations in the iterative decoders for low-density parity-check codes, we formulate a signal-space view for a finite number of iterations in a finite-length code. On a Gaussian channel, maximum a posteriori (MAP) codeword decoding (or \"maximum-likelihood decoding\") decodes to the codeword signal that is closest to the channel output in Euclidean distance. In contrast, we show that iterative decoding decodes to the \"pseudosignal\" that has highest correlation with the channel output. The set of pseudosignals corresponds to \"pseudocodewords\", only a vanishingly small number of which correspond to codewords. We show that some pseudocodewords cause decoding errors, but that there are also pseudocodewords that frequently correct the deleterious effects of other pseudocodewords."
            },
            "slug": "Signal-space-characterization-of-iterative-decoding-Frey-Koetter",
            "title": {
                "fragments": [],
                "text": "Signal-space characterization of iterative decoding"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "By tracing the flow of computations in the iterative decoders for low-density parity-check codes, this work forms a signal-space view for a finite number of iterations in a finite-length code and shows that some pseudocodewords cause decoding errors, but that there are also pseudocODewords that frequently correct the deleterious effects of other pseudocods."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720384"
                        ],
                        "name": "V. Vazirani",
                        "slug": "V.-Vazirani",
                        "structuredName": {
                            "firstName": "Vijay",
                            "lastName": "Vazirani",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vazirani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In this case, one can imagine various types of rounding procedures for producing near-optimal solutions [231]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "When applied to combinatorial problems, the first-order LP relaxation recovers various known methods from the integer programming and approximation literature [177, 231]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Frequently, LP relaxations are developed in a manner tailored to specific subclasses of combinatorial problems [177, 231]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This LP relaxation is the classical one for the independent set problem [177, 231]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 834161,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "112e14d8f5d9e9b1cd99ae862cefc085566fb580",
            "isKey": true,
            "numCitedBy": 3976,
            "numCiting": 71,
            "paperAbstract": {
                "fragments": [],
                "text": "Covering the basic techniques used in the latest research work, the author consolidates progress made so far, including some very recent and promising results, and conveys the beauty and excitement of work in the field. He gives clear, lucid explanations of key results and ideas, with intuitive proofs, and provides critical examples and numerous illustrations to help elucidate the algorithms. Many of the results presented have been simplified and new insights provided. Of interest to theoretical computer scientists, operations researchers, and discrete mathematicians."
            },
            "slug": "Approximation-Algorithms-Vazirani",
            "title": {
                "fragments": [],
                "text": "Approximation Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Covering the basic techniques used in the latest research work, the author consolidates progress made so far, including some very recent and promising results, and conveys the beauty and excitement of work in the field."
            },
            "venue": {
                "fragments": [],
                "text": "Springer Berlin Heidelberg"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2718299"
                        ],
                        "name": "N. Wiberg",
                        "slug": "N.-Wiberg",
                        "structuredName": {
                            "firstName": "Niclas",
                            "lastName": "Wiberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Wiberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143681410"
                        ],
                        "name": "H. Loeliger",
                        "slug": "H.-Loeliger",
                        "structuredName": {
                            "firstName": "Hans-Andrea",
                            "lastName": "Loeliger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Loeliger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7715701"
                        ],
                        "name": "R. Koetter",
                        "slug": "R.-Koetter",
                        "structuredName": {
                            "firstName": "Ralf",
                            "lastName": "Koetter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Koetter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[253], is via the computation tree associated with the messagepassing updates."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 36630145,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "848822f6c3446842730587cb4373a53f69e38720",
            "isKey": false,
            "numCitedBy": 350,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Until recently, most known decoding procedures for error-correcting codes were based either on algebraically calculating the error pattern or on some sort of tree or trellis search. With the advent of turbo coding, a third decoding principle has finally had its breakthrough: iterative decoding. With respect to Viterbi decoding, a code is most naturally described by means of a trellis diagram. The main thesis of the present paper is that, with respect to iterative decoding, the natural way of describing a code is by means of a Tanner graph, which may be viewed as a generalized trellis. More precisely, it is the \"time axis\" of a trellis that is generalized to a Tanner graph."
            },
            "slug": "Codes-and-iterative-decoding-on-general-graphs-Wiberg-Loeliger",
            "title": {
                "fragments": [],
                "text": "Codes and iterative decoding on general graphs"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The main thesis of the present paper is that, with respect to iterative decoding, the natural way of describing a code is by means of a Tanner graph, which may be viewed as a generalized trellis."
            },
            "venue": {
                "fragments": [],
                "text": "Eur. Trans. Telecommun."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752732"
                        ],
                        "name": "T. Cover",
                        "slug": "T.-Cover",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Cover",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Cover"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115282352"
                        ],
                        "name": "Joy A. Thomas",
                        "slug": "Joy-A.-Thomas",
                        "structuredName": {
                            "firstName": "Joy",
                            "lastName": "Thomas",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joy A. Thomas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "the KL divergence [54] between two distributions with densities q and p with respect to a base measure \u03bd is"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The entropy of such a multivariate Gaussian takes the form [54]"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "An important characterization of the multivariate Gaussian is as the maximum entropy distribution subject to covariance constraints [54]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 190432,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7dbdb4209626fd92d2436a058663206216036e68",
            "isKey": true,
            "numCitedBy": 42794,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface to the Second Edition. Preface to the First Edition. Acknowledgments for the Second Edition. Acknowledgments for the First Edition. 1. Introduction and Preview. 1.1 Preview of the Book. 2. Entropy, Relative Entropy, and Mutual Information. 2.1 Entropy. 2.2 Joint Entropy and Conditional Entropy. 2.3 Relative Entropy and Mutual Information. 2.4 Relationship Between Entropy and Mutual Information. 2.5 Chain Rules for Entropy, Relative Entropy, and Mutual Information. 2.6 Jensen's Inequality and Its Consequences. 2.7 Log Sum Inequality and Its Applications. 2.8 Data-Processing Inequality. 2.9 Sufficient Statistics. 2.10 Fano's Inequality. Summary. Problems. Historical Notes. 3. Asymptotic Equipartition Property. 3.1 Asymptotic Equipartition Property Theorem. 3.2 Consequences of the AEP: Data Compression. 3.3 High-Probability Sets and the Typical Set. Summary. Problems. Historical Notes. 4. Entropy Rates of a Stochastic Process. 4.1 Markov Chains. 4.2 Entropy Rate. 4.3 Example: Entropy Rate of a Random Walk on a Weighted Graph. 4.4 Second Law of Thermodynamics. 4.5 Functions of Markov Chains. Summary. Problems. Historical Notes. 5. Data Compression. 5.1 Examples of Codes. 5.2 Kraft Inequality. 5.3 Optimal Codes. 5.4 Bounds on the Optimal Code Length. 5.5 Kraft Inequality for Uniquely Decodable Codes. 5.6 Huffman Codes. 5.7 Some Comments on Huffman Codes. 5.8 Optimality of Huffman Codes. 5.9 Shannon-Fano-Elias Coding. 5.10 Competitive Optimality of the Shannon Code. 5.11 Generation of Discrete Distributions from Fair Coins. Summary. Problems. Historical Notes. 6. Gambling and Data Compression. 6.1 The Horse Race. 6.2 Gambling and Side Information. 6.3 Dependent Horse Races and Entropy Rate. 6.4 The Entropy of English. 6.5 Data Compression and Gambling. 6.6 Gambling Estimate of the Entropy of English. Summary. Problems. Historical Notes. 7. Channel Capacity. 7.1 Examples of Channel Capacity. 7.2 Symmetric Channels. 7.3 Properties of Channel Capacity. 7.4 Preview of the Channel Coding Theorem. 7.5 Definitions. 7.6 Jointly Typical Sequences. 7.7 Channel Coding Theorem. 7.8 Zero-Error Codes. 7.9 Fano's Inequality and the Converse to the Coding Theorem. 7.10 Equality in the Converse to the Channel Coding Theorem. 7.11 Hamming Codes. 7.12 Feedback Capacity. 7.13 Source-Channel Separation Theorem. Summary. Problems. Historical Notes. 8. Differential Entropy. 8.1 Definitions. 8.2 AEP for Continuous Random Variables. 8.3 Relation of Differential Entropy to Discrete Entropy. 8.4 Joint and Conditional Differential Entropy. 8.5 Relative Entropy and Mutual Information. 8.6 Properties of Differential Entropy, Relative Entropy, and Mutual Information. Summary. Problems. Historical Notes. 9. Gaussian Channel. 9.1 Gaussian Channel: Definitions. 9.2 Converse to the Coding Theorem for Gaussian Channels. 9.3 Bandlimited Channels. 9.4 Parallel Gaussian Channels. 9.5 Channels with Colored Gaussian Noise. 9.6 Gaussian Channels with Feedback. Summary. Problems. Historical Notes. 10. Rate Distortion Theory. 10.1 Quantization. 10.2 Definitions. 10.3 Calculation of the Rate Distortion Function. 10.4 Converse to the Rate Distortion Theorem. 10.5 Achievability of the Rate Distortion Function. 10.6 Strongly Typical Sequences and Rate Distortion. 10.7 Characterization of the Rate Distortion Function. 10.8 Computation of Channel Capacity and the Rate Distortion Function. Summary. Problems. Historical Notes. 11. Information Theory and Statistics. 11.1 Method of Types. 11.2 Law of Large Numbers. 11.3 Universal Source Coding. 11.4 Large Deviation Theory. 11.5 Examples of Sanov's Theorem. 11.6 Conditional Limit Theorem. 11.7 Hypothesis Testing. 11.8 Chernoff-Stein Lemma. 11.9 Chernoff Information. 11.10 Fisher Information and the Cram-er-Rao Inequality. Summary. Problems. Historical Notes. 12. Maximum Entropy. 12.1 Maximum Entropy Distributions. 12.2 Examples. 12.3 Anomalous Maximum Entropy Problem. 12.4 Spectrum Estimation. 12.5 Entropy Rates of a Gaussian Process. 12.6 Burg's Maximum Entropy Theorem. Summary. Problems. Historical Notes. 13. Universal Source Coding. 13.1 Universal Codes and Channel Capacity. 13.2 Universal Coding for Binary Sequences. 13.3 Arithmetic Coding. 13.4 Lempel-Ziv Coding. 13.5 Optimality of Lempel-Ziv Algorithms. Compression. Summary. Problems. Historical Notes. 14. Kolmogorov Complexity. 14.1 Models of Computation. 14.2 Kolmogorov Complexity: Definitions and Examples. 14.3 Kolmogorov Complexity and Entropy. 14.4 Kolmogorov Complexity of Integers. 14.5 Algorithmically Random and Incompressible Sequences. 14.6 Universal Probability. 14.7 Kolmogorov complexity. 14.9 Universal Gambling. 14.10 Occam's Razor. 14.11 Kolmogorov Complexity and Universal Probability. 14.12 Kolmogorov Sufficient Statistic. 14.13 Minimum Description Length Principle. Summary. Problems. Historical Notes. 15. Network Information Theory. 15.1 Gaussian Multiple-User Channels. 15.2 Jointly Typical Sequences. 15.3 Multiple-Access Channel. 15.4 Encoding of Correlated Sources. 15.5 Duality Between Slepian-Wolf Encoding and Multiple-Access Channels. 15.6 Broadcast Channel. 15.7 Relay Channel. 15.8 Source Coding with Side Information. 15.9 Rate Distortion with Side Information. 15.10 General Multiterminal Networks. Summary. Problems. Historical Notes. 16. Information Theory and Portfolio Theory. 16.1 The Stock Market: Some Definitions. 16.2 Kuhn-Tucker Characterization of the Log-Optimal Portfolio. 16.3 Asymptotic Optimality of the Log-Optimal Portfolio. 16.4 Side Information and the Growth Rate. 16.5 Investment in Stationary Markets. 16.6 Competitive Optimality of the Log-Optimal Portfolio. 16.7 Universal Portfolios. 16.8 Shannon-McMillan-Breiman Theorem (General AEP). Summary. Problems. Historical Notes. 17. Inequalities in Information Theory. 17.1 Basic Inequalities of Information Theory. 17.2 Differential Entropy. 17.3 Bounds on Entropy and Relative Entropy. 17.4 Inequalities for Types. 17.5 Combinatorial Bounds on Entropy. 17.6 Entropy Rates of Subsets. 17.7 Entropy and Fisher Information. 17.8 Entropy Power Inequality and Brunn-Minkowski Inequality. 17.9 Inequalities for Determinants. 17.10 Inequalities for Ratios of Determinants. Summary. Problems. Historical Notes. Bibliography. List of Symbols. Index."
            },
            "slug": "Elements-of-Information-Theory-Cover-Thomas",
            "title": {
                "fragments": [],
                "text": "Elements of Information Theory"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The author examines the role of entropy, inequality, and randomness in the design of codes and the construction of codes in the rapidly changing environment."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770859"
                        ],
                        "name": "R. Gallager",
                        "slug": "R.-Gallager",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gallager",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gallager"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Problems of constraint satisfaction and combinatorial optimization arise in a wide variety of areas, among them artificial intelligence [63, 188], communication theory [84], computational complexity theory [52], statistical image processing [86], and bioinformatics [190]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "One important domain in which hard-core constraints arise is communication theory, and in particular the problem of error-control coding [84, 164, 196]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": ") A classical way of studying the ordinary sum- and max-product algorithms, dating back to the work of Gallager [84] and Wiberg et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12709402,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "206f827fad201506c315d40c1469b41a45141893",
            "isKey": false,
            "numCitedBy": 10568,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "A low-density parity-check code is a code specified by a parity-check matrix with the following properties: each column contains a small fixed number j \\geq 3 of l's and each row contains a small fixed number k > j of l's. The typical minimum distance of these codes increases linearly with block length for a fixed rate and fixed j . When used with maximum likelihood decoding on a sufficiently quiet binary-input symmetric channel, the typical probability of decoding error decreases exponentially with block length for a fixed rate and fixed j . A simple but nonoptimum decoding scheme operating directly from the channel a posteriori probabilities is described. Both the equipment complexity and the data-handling capacity in bits per second of this decoder increase approximately linearly with block length. For j > 3 and a sufficiently low rate, the probability of error using this decoder on a binary symmetric channel is shown to decrease at least exponentially with a root of the block length. Some experimental results show that the actual probability of decoding error is much smaller than this theoretical bound."
            },
            "slug": "Low-density-parity-check-codes-Gallager",
            "title": {
                "fragments": [],
                "text": "Low-density parity-check codes"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A simple but nonoptimum decoding scheme operating directly from the channel a posteriori probabilities is described and the probability of error using this decoder on a binary symmetric channel is shown to decrease at least exponentially with a root of the block length."
            },
            "venue": {
                "fragments": [],
                "text": "IRE Trans. Inf. Theory"
            },
            "year": 1962
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2243078"
                        ],
                        "name": "J. Felsenstein",
                        "slug": "J.-Felsenstein",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Felsenstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Felsenstein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "subsumes the classical recursive algorithms, including the pruning and peeling algorithms from computational genetics [76], the forwardbackward algorithms for hidden Markov models [192], and the Kalman filtering-smoothing algorithms for state-space models [123]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The conditional probabilities in the tree are obtained from evolutionary substitution models, and the computation of likelihoods are achieved by a recursion on the tree known as \u201cpruning\u201d [76]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8024924,
            "fieldsOfStudy": [
                "Biology",
                "Computer Science"
            ],
            "id": "e0cbb949d062a1134c4d98924f51312090e76514",
            "isKey": false,
            "numCitedBy": 10808,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "SummaryThe application of maximum likelihood techniques to the estimation of evolutionary trees from nucleic acid sequence data is discussed. A computationally feasible method for finding such maximum likelihood estimates is developed, and a computer program is available. This method has advantages over the traditional parsimony algorithms, which can give misleading results if rates of evolution differ in different lineages. It also allows the testing of hypotheses about the constancy of evolutionary rates by likelihood ratio tests, and gives rough indication of the error of the estimate of the tree."
            },
            "slug": "Evolutionary-trees-from-DNA-sequences:-A-maximum-Felsenstein",
            "title": {
                "fragments": [],
                "text": "Evolutionary trees from DNA sequences: A maximum likelihood approach"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A computationally feasible method for finding such maximum likelihood estimates is developed, and a computer program is available that allows the testing of hypotheses about the constancy of evolutionary rates by likelihood ratio tests."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Molecular Evolution"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688323"
                        ],
                        "name": "S. Tatikonda",
                        "slug": "S.-Tatikonda",
                        "structuredName": {
                            "firstName": "Sekhar",
                            "lastName": "Tatikonda",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Tatikonda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[199] provide sufficient conditions for convergence, based on contraction arguments such as those used for ordinary sumproduct [225, 87, 175, 115]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Tatikonda and Jordan [225] established an elegant connection between convergence of parallel updates and Gibbs measures on the infinitely unwrapped computation tree, thereby showing that sufficient conditions for convergence can be obtained from classical conditions for uniqueness of Gibbs measures (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9800468,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0f2936643a7fb618ccd10061996c8e370b57056e",
            "isKey": false,
            "numCitedBy": 216,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the question of convergence in the loopy belief propagation (LBP) algorithm. Specifically, we relate convergence of LBP to the existence of a weak limit for a sequence of Gibbs measures defined on the LBP's associated computation tree. Using tools from the theory of Gibbs measures we develop easily testable sufficient conditions for convergence. The failure of convergence of LBP implies the existence of multiple phases for the associated Gibbs specification. These results give new insight into the mechanics of the algorithm."
            },
            "slug": "Loopy-Belief-Propogation-and-Gibbs-Measures-Tatikonda-Jordan",
            "title": {
                "fragments": [],
                "text": "Loopy Belief Propogation and Gibbs Measures"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "This work relates convergence of LBP to the existence of a weak limit for a sequence of Gibbs measures defined on the LBP's associated computation tree, and develops easily testable sufficient conditions for convergence."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2519704"
                        ],
                        "name": "M. Taghavi",
                        "slug": "M.-Taghavi",
                        "structuredName": {
                            "firstName": "Mohammad",
                            "lastName": "Taghavi",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Taghavi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739020"
                        ],
                        "name": "P. Siegel",
                        "slug": "P.-Siegel",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Siegel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Siegel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1561523,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e049ae34d069a2199f2b824c13843db679678bea",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "The ability of linear programming (LP) decoding to detect failures, and its potential for improvement by the addition of new constraints, motivates the use of an adaptive approach in selecting the constraints for the underlying LP problem. In this paper, we show that the application of such adaptive methods can significantly reduce the complexity of the LP decoding algorithm, which, in the standard formulation, is exponential in the maximum row weight of the parity-check matrix. We further show that adaptively adding new constraints, e.g. by combining parity checks, can provide large gains in LP decoder performance"
            },
            "slug": "Adaptive-Linear-Programming-Decoding-Taghavi-Siegel",
            "title": {
                "fragments": [],
                "text": "Adaptive Linear Programming Decoding"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The application of such adaptive methods can significantly reduce the complexity of the LP decoding algorithm, which, in the standard formulation, is exponential in the maximum row weight of the parity-check matrix."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE International Symposium on Information Theory"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52626911"
                        ],
                        "name": "T. Minka",
                        "slug": "T.-Minka",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Minka",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Minka"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 84
                            }
                        ],
                        "text": "With different motivations, not directly related to convexity and uniqueness, Minka [170] has discussed reweighted forms of EP, referred to as \u201cpower EP."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8114569,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "85fa166aff2aba59247d2c315153b3403e883b78",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "This note describes power EP, an extension of Expectation Propagation (EP) that makes the computations more tractable. In this way, power EP is applicable to a wide variety of models, much more than EP. Instead of minimizing KL-divergence at each step, power EP minimizes \u03b1-divergence. This minimization turns out to be equivalent to minimizing KL-divergence with the exact distribution raised to a power. By choosing this power to cancel exponents, the problem may be substantially simplified. The resulting approximation is not the same as regular EP, but in practice is still very good, and allows tackling problems which are intractable under regular EP."
            },
            "slug": "Power-EP-Minka",
            "title": {
                "fragments": [],
                "text": "Power EP"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "This note describes power EP, an extension of Expectation Propagation that makes the computations more tractable and allows tackling problems which are intractable under regular EP."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144418438"
                        ],
                        "name": "Hinrich Sch\u00fctze",
                        "slug": "Hinrich-Sch\u00fctze",
                        "structuredName": {
                            "firstName": "Hinrich",
                            "lastName": "Sch\u00fctze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hinrich Sch\u00fctze"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Here the state variables are the parts of speech, and the transition matrix is estimated from a corpus via the EM algorithm [160]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 52800448,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "084c55d6432265785e3ff86a2e900a49d501c00a",
            "isKey": false,
            "numCitedBy": 7802,
            "numCiting": 294,
            "paperAbstract": {
                "fragments": [],
                "text": "Statistical approaches to processing natural language text have become dominant in recent years. This foundational text is the first comprehensive introduction to statistical natural language processing (NLP) to appear. The book contains all the theory and algorithms needed for building NLP tools. It provides broad but rigorous coverage of mathematical and linguistic foundations, as well as detailed discussion of statistical methods, allowing students and researchers to construct their own implementations. The book covers collocation finding, word sense disambiguation, probabilistic parsing, information retrieval, and other applications."
            },
            "slug": "Foundations-of-statistical-natural-language-Manning-Sch\u00fctze",
            "title": {
                "fragments": [],
                "text": "Foundations of statistical natural language processing"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "This foundational text is the first comprehensive introduction to statistical natural language processing (NLP) to appear and provides broad but rigorous coverage of mathematical and linguistic foundations, as well as detailed discussion of statistical methods, allowing students and researchers to construct their own implementations."
            },
            "venue": {
                "fragments": [],
                "text": "SGMD"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725557"
                        ],
                        "name": "L. Lov\u00e1sz",
                        "slug": "L.-Lov\u00e1sz",
                        "structuredName": {
                            "firstName": "L\u00e1szl\u00f3",
                            "lastName": "Lov\u00e1sz",
                            "middleNames": [
                                "Mikl\u00f3s"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Lov\u00e1sz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1975444,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "3a95e74c1c1ad861cb107a0dfcba5abc2d542c2f",
            "isKey": false,
            "numCitedBy": 1533,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "It is proved that the Shannon zero-error capacity of the pentagon is \\sqrt{5} . The method is then generalized to obtain upper bounds on the capacity of an arbitrary graph. A well-characterized, and in a sense easily computable, function is introduced which bounds the capacity from above and equals the capacity in a large number of cases. Several results are obtained on the capacity of special graphs; for example, the Petersen graph has capacity four and a self-complementary graph with n points and with a vertex-transitive automorphism group has capacity \\sqrt{5} ."
            },
            "slug": "On-the-Shannon-capacity-of-a-graph-Lov\u00e1sz",
            "title": {
                "fragments": [],
                "text": "On the Shannon capacity of a graph"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "It is proved that the Shannon zero-error capacity of the pentagon is \\sqrt{5} and a well-characterized, and in a sense easily computable, function is introduced which bounds the capacity from above and equals the capacity in a large number of cases."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725557"
                        ],
                        "name": "L. Lov\u00e1sz",
                        "slug": "L.-Lov\u00e1sz",
                        "structuredName": {
                            "firstName": "L\u00e1szl\u00f3",
                            "lastName": "Lov\u00e1sz",
                            "middleNames": [
                                "Mikl\u00f3s"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Lov\u00e1sz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689196"
                        ],
                        "name": "A. Schrijver",
                        "slug": "A.-Schrijver",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Schrijver",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Schrijver"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 96
                            }
                        ],
                        "text": "This sequence is known as the Lasserre sequence of relaxations [144, 147]; Lov\u00e1sz and Schrijver [156] describe a related class of lifting procedure."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17998142,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "f885d0d44177550421e79d5f5fbab524d275495d",
            "isKey": false,
            "numCitedBy": 1112,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "A system, method, and apparatus for facilitating a self-organizing workforce of one or more workers through payment and recognition incentives, a set of configurable operating rules, and a set of credentials to represent the reputations and organizational capital of individual workers. The system includes a worksite having one or more configurable worksite rules where the one or more workers may work on an idea. Work includes posting to a discussion about the idea, voting on the idea, and recommending an outcome for the idea. Worker credentials for each worker are updated based on a worker's work on the idea within the worksite. The worker credentials include merit, which is a measure of the quantity, quality, and significance of work done; links, which is a function of what one worker thinks of another worker's work; wisdom, which reflects the worker's ability to spot a good idea; and, influence, which is a function of merit, links, and wisdom, and which reflects a worker's overall organizational capital within the system."
            },
            "slug": "Cones-of-Matrices-and-Set-Functions-and-0-1-Lov\u00e1sz-Schrijver",
            "title": {
                "fragments": [],
                "text": "Cones of Matrices and Set-Functions and 0-1 Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A system, method, and apparatus for facilitating a self-organizing workforce of one or more workers through payment and recognition incentives, a set of configurable operating rules, and a setof credentials to represent the reputations and organizational capital of individual workers."
            },
            "venue": {
                "fragments": [],
                "text": "SIAM J. Optim."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765456"
                        ],
                        "name": "S. Cook",
                        "slug": "S.-Cook",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Cook",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Cook"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Problems of constraint satisfaction and combinatorial optimization arise in a wide variety of areas, among them artificial intelligence [63, 188], communication theory [84], computational complexity theory [52], statistical image processing [86], and bioinformatics [190]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Let us illustrate by considering what is perhaps the best-known example of satisfiability, namely the 3-SAT problem [52]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7573663,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "1a8d2e5bb9c646d85308fbd6ce33fce8765e2c26",
            "isKey": false,
            "numCitedBy": 6570,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "It is shown that any recognition problem solved by a polynomial time-bounded nondeterministic Turing machine can be \u201creduced\u201d to the problem of determining whether a given propositional formula is a tautology. Here \u201creduced\u201d means, roughly speaking, that the first problem can be solved deterministically in polynomial time provided an oracle is available for solving the second. From this notion of reducible, polynomial degrees of difficulty are defined, and it is shown that the problem of determining tautologyhood has the same polynomial degree as the problem of determining whether the first of two given graphs is isomorphic to a subgraph of the second. Other examples are discussed. A method of measuring the complexity of proof procedures for the predicate calculus is introduced and discussed."
            },
            "slug": "The-complexity-of-theorem-proving-procedures-Cook",
            "title": {
                "fragments": [],
                "text": "The complexity of theorem-proving procedures"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "It is shown that any recognition problem solved by a polynomial time-bounded nondeterministic Turing machine can be \u201creduced\u201d to the problem of determining whether a given propositional formula is a tautology."
            },
            "venue": {
                "fragments": [],
                "text": "STOC"
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46491690"
                        ],
                        "name": "M. Bayati",
                        "slug": "M.-Bayati",
                        "structuredName": {
                            "firstName": "Mohsen",
                            "lastName": "Bayati",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bayati"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145040228"
                        ],
                        "name": "Chandra Nair",
                        "slug": "Chandra-Nair",
                        "structuredName": {
                            "firstName": "Chandra",
                            "lastName": "Nair",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chandra Nair"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 940793,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f7b44e7354a7a105f5da863e9acaa95afdc961e6",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we rigorously prove the validity of the cavity method for the problem of counting the number of matchings in graphs with large girth. Cavity method is an important heuristic developed by statistical physicists that has lead to the development of faster distributed algorithms for problems in various combinatorial optimization problems. The validity of the approach has been supported mostly by numerical simulations. In this paper we prove the validity of cavity method for the problem of counting matchings using rigorous techniques. We hope that these rigorous approaches will finally help us establish the validity of the cavity method in general."
            },
            "slug": "A-rigorous-proof-of-the-cavity-method-for-counting-Bayati-Nair",
            "title": {
                "fragments": [],
                "text": "A rigorous proof of the cavity method for counting matchings"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "This paper rigorously proves the validity of cavity method for the problem of counting the number of matchings in graphs with large girth using rigorous techniques."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790356"
                        ],
                        "name": "T. Heskes",
                        "slug": "T.-Heskes",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Heskes",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Heskes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In subsequent work, other researchers [115, 175, 199] have used various types of contraction arguments to obtain sharper conditions for convergence, or uniqueness of fixed points [106]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1482331,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "617af3008c413078f2ac4f2cc23cd1ea3a35f72f",
            "isKey": false,
            "numCitedBy": 156,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We derive sufficient conditions for the uniqueness of loopy belief propagation fixed points. These conditions depend on both the structure of the graph and the strength of the potentials and naturally extend those for convexity of the Bethe free energy. We compare them with (a strengthened version of) conditions derived elsewhere for pairwise potentials. We discuss possible implications for convergent algorithms, as well as for other approximate free energies."
            },
            "slug": "On-the-Uniqueness-of-Loopy-Belief-Propagation-Fixed-Heskes",
            "title": {
                "fragments": [],
                "text": "On the Uniqueness of Loopy Belief Propagation Fixed Points"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "Qualifying conditions for the uniqueness of loopy belief propagation fixed points are derived and possible implications for convergent algorithms, as well as for other approximate free energies, are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145052965"
                        ],
                        "name": "G. Parisi",
                        "slug": "G.-Parisi",
                        "structuredName": {
                            "firstName": "Giorgio",
                            "lastName": "Parisi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Parisi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48215291"
                        ],
                        "name": "R. Shankar",
                        "slug": "R.-Shankar",
                        "structuredName": {
                            "firstName": "Ramamurti",
                            "lastName": "Shankar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Shankar"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 119396873,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "cf2af6e45d25f62bc52bb1ecae86a2c3d0aae72b",
            "isKey": false,
            "numCitedBy": 865,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Classical equilibrium statistical mechanics magnetic systems the Ising model the low-temperature and high-temperature expansions the Landau-Ginsberg model near the transition the renormalization group perturbative evaluation of the critical exponents near four dimensions on spontaneous symmetry breaking other models the transfer matrix path integrals for quantum mechanics semiclassical methods relativistic quantum field theory particle-field duality time dependent correlations the approach to equilibrium the stochastic approach to equilibrium the stochastic approach computer simulation."
            },
            "slug": "Statistical-Field-Theory-Parisi-Shankar",
            "title": {
                "fragments": [],
                "text": "Statistical Field Theory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681338"
                        ],
                        "name": "R. Stanley",
                        "slug": "R.-Stanley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Stanley",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Stanley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118416802,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "9fff71ca45728fbccffd2ea8e46825b620a2c1b8",
            "isKey": false,
            "numCitedBy": 3493,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "The basic problem of enumerative combinatorics is that of counting the number of elements of a finite set. Usually are given an infinite class of finite sets S i where i ranges over some index set I (such as the nonnegative integers \u2115), and we wish to count the number \u0192(i) of elements of each S i \u201csimultaneously.\u201d Immediate philosophical difficulties arise. What does it mean to \u201ccount\u201d the number of elements of S i ? There is no definitive answer to this question. Only through experience does one develop an idea of what is meant by a \u201cdetermination\u201d of a counting function \u0192(i)."
            },
            "slug": "What-Is-Enumerative-Combinatorics-Stanley",
            "title": {
                "fragments": [],
                "text": "What Is Enumerative Combinatorics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35180576"
                        ],
                        "name": "L. Bregman",
                        "slug": "L.-Bregman",
                        "structuredName": {
                            "firstName": "Lev",
                            "lastName": "Bregman",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bregman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 95
                            }
                        ],
                        "text": "This interpretation shows that the KL divergence is a particular example of a Bregman distance [16, 19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 121309410,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "44a6b76e5cbc61330663d0a9f393caf91a3a1be8",
            "isKey": false,
            "numCitedBy": 2440,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-relaxation-method-of-finding-the-common-point-Bregman",
            "title": {
                "fragments": [],
                "text": "The relaxation method of finding the common point of convex sets and its application to the solution of problems in convex programming"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072619001"
                        ],
                        "name": "Kellen Petersen August",
                        "slug": "Kellen-Petersen-August",
                        "structuredName": {
                            "firstName": "Kellen",
                            "lastName": "August",
                            "middleNames": [
                                "Petersen"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kellen Petersen August"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 138
                            }
                        ],
                        "text": "Interchanging the order of di erentiation and integration can be justi ed via a standard argument using the dominated convergence theorem [93], from which derivatives can be calculated by chain rule."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 49
                            }
                        ],
                        "text": "Lower semi-continuity follows from Fatou's lemma [93]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 10538072,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "9e27708a299604a24d81bef700f12002009ef86c",
            "isKey": false,
            "numCitedBy": 2714,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "\u2013 Weierstrass Theorem Theorem If f is a continuous real-valued function on [a, b] and if any is given, then there exists a polynomial p on [a, b] s.t. |f(x)\u2212 p(x)| < for all x \u2208 [a, b]. In other words, any continuous function on a closed and bounded interval can be uniformly approximated on that interval by polynomials to ay degree of accuracy. Proof 1. Simple to interval [0, 1] 2. Bernstein polynomials Pn k=0 `n k \u0301 xk(1\u2212 x)n\u2212k = 1 Pn k=0 `n k \u0301 xk(1\u2212 x)n\u2212k(k \u2212 nx) = 0 Bn(x) = Pn k=0 `n k \u0301 xk(1\u2212 x)n\u2212kf( k n ) =\u21d2 |f(x)\u2212Bn(x)| \u2264 Pn k=0 `n k \u0301 xk(1\u2212 x)n\u2212k|f(x)\u2212 f( k n )| 3. Split sum into |x\u2212 k n | \u2264 \u03b4 (I) and |x\u2212 k n | > \u03b4 (II) 4. Then (I) < and (II) \u2264 2M P |x\u2212 k n |>\u03b4 `n k \u0301 xk(1\u2212 x)n\u2212k \u2264 2M \u03b42 P |x\u2212 k n |>\u03b4 `n k \u0301 xk(1\u2212 x)n\u2212k(x\u2212 k n )2 \u2264 2M \u03b42 Pn k=0 `n k \u0301 xk(1\u2212 x)n\u2212k(x\u2212 k n )2 \u2264 M 2\u03b42n |f(x)\u2212Bn(x)| \u2264 + M 2\u03b42n Choose n large enough so \u2264 2 Alternative Proof Idea: Use Landau kernel Kn = cn(1\u2212 x2)n Lemma If f is continuous on [\u22121, 1] then Kn \u2217 f is a polynomial Lemma (Kn \u2217 f) \u2192 f in d\u221e Examples: ex grows to fast and sin x grows too slowly (and infinitely many zeros so can\u2019t be approximated by a polynomial. Note: |x| is continuous but not differentiable at x = 0. You can approximate by polynomials but the uniform limit is not differentiable =\u21d2 Uniform limit of differentiable functions need not be differentiable."
            },
            "slug": "Real-Analysis-August",
            "title": {
                "fragments": [],
                "text": "Real Analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144241259"
                        ],
                        "name": "Sunyonga Kim",
                        "slug": "Sunyonga-Kim",
                        "structuredName": {
                            "firstName": "Sunyonga",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sunyonga Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2687592"
                        ],
                        "name": "M. Kojima",
                        "slug": "M.-Kojima",
                        "structuredName": {
                            "firstName": "Masakazu",
                            "lastName": "Kojima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kojima"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The resulting second-order cone programming (SOCP) relaxations of the mode-finding problem (as well as more general non-convex optimization problems) have been studied by various researchers [143, 131]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Kim and Kojima [131] study the use of SOC constraints in deriving relaxations for fairly general classes of non-convex quadratic programming problems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1197877,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "edd4ca9748d853c9597851c7f9698c8307e29181",
            "isKey": false,
            "numCitedBy": 123,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "A disadvantage of the SDP (semidefinite programming) relaxation method for quadratic and/or combinatorial optimization problems lies in its expensive computational cost. This paper proposes a SOCP (second-order-cone programming) relaxation method, which strengthens the lift-and-project LP (linear programming) relaxation method by adding convex quadratic valid inequalities for the positive semidefinite cone involved in the SDP relaxation. Numerical experiments show that our SOCP relaxation is a reasonable compromise between the effectiveness of the SDP relaxation and the low computational cost of the lift-and-project LP relaxation."
            },
            "slug": "Second-order-cone-programming-relaxation-of-Kim-Kojima",
            "title": {
                "fragments": [],
                "text": "Second order cone programming relaxation of nonconvex quadratic optimization problems"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A SOCP relaxation method is proposed, which strengthens the lift-and-project LP (linear programming) relaxation method by adding convex quadratic valid inequalities for the positive semidefinite cone involved in the SDP relaxation."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2505902"
                        ],
                        "name": "N. Komodakis",
                        "slug": "N.-Komodakis",
                        "structuredName": {
                            "firstName": "Nikos",
                            "lastName": "Komodakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Komodakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680727"
                        ],
                        "name": "N. Paragios",
                        "slug": "N.-Paragios",
                        "structuredName": {
                            "firstName": "Nikos",
                            "lastName": "Paragios",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Paragios"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2441655"
                        ],
                        "name": "G. Tziritas",
                        "slug": "G.-Tziritas",
                        "structuredName": {
                            "firstName": "Georgios",
                            "lastName": "Tziritas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Tziritas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Various forms of these reweighted maxproduct algorithms have been applied in problems such as segmentation and disparity problems in computer vision [165, 134, 136, 246, 222, 260], error-control coding [73], side-chain prediction [261, 246], sensor fusion [43, 46]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "5), including subgradient methods [73, 136], dual coordinate ascent methods [94, 234], annealing-type methods [121, 246], proximal optimization schemes [193], and adaptive LP solvers [223]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6596960,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "38649fa7ab5b237dc65290f20e16adc648363bc2",
            "isKey": false,
            "numCitedBy": 336,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "A new message-passing scheme for MRF optimization is proposed in this paper. This scheme inherits better theoretical properties than all other state-of-the-art message passing methods and in practice performs equally well/outperforms them. It is based on the very powerful technique of Dual Decomposition [1] and leads to an elegant and general framework for understanding/designing message-passing algorithms that can provide new insights into existing techniques. Promising experimental results and comparisons with the state of the art demonstrate the extreme theoretical and practical potentials of our approach."
            },
            "slug": "MRF-Optimization-via-Dual-Decomposition:-Revisited-Komodakis-Paragios",
            "title": {
                "fragments": [],
                "text": "MRF Optimization via Dual Decomposition: Message-Passing Revisited"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "A new message-passing scheme for MRF optimization that inherits better theoretical properties than all other state-of-the-art message passing methods and in practice performs equally well/outperforms them."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE 11th International Conference on Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3696176"
                        ],
                        "name": "P. Seymour",
                        "slug": "P.-Seymour",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Seymour",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Seymour"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 25249972,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "4801c5f845eb6fc4ee15cdf8c143aed63c58a4f4",
            "isKey": false,
            "numCitedBy": 149,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Matroids-and-Multicommodity-Flows-Seymour",
            "title": {
                "fragments": [],
                "text": "Matroids and Multicommodity Flows"
            },
            "venue": {
                "fragments": [],
                "text": "Eur. J. Comb."
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2663587"
                        ],
                        "name": "E. Berlekamp",
                        "slug": "E.-Berlekamp",
                        "structuredName": {
                            "firstName": "Elwyn",
                            "lastName": "Berlekamp",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Berlekamp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723150"
                        ],
                        "name": "R. McEliece",
                        "slug": "R.-McEliece",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "McEliece",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. McEliece"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693227"
                        ],
                        "name": "H. V. Tilborg",
                        "slug": "H.-V.-Tilborg",
                        "structuredName": {
                            "firstName": "Henk",
                            "lastName": "Tilborg",
                            "middleNames": [
                                "C.",
                                "A.",
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. V. Tilborg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 123
                            }
                        ],
                        "text": "The problem of maximum likelihood (ML) decoding is an integer program that is well known to be computationally intractable [16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 34892814,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5e29000d24d5ded11e7a32216a91bdadaa9877f1",
            "isKey": false,
            "numCitedBy": 1330,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "MEMBER, IEEE, AND HENK C. A. V~ TILBORG The fact that the general decoding problem for linear codes and the general problem of finding the weights of a linear code are both NP-complete is shown. This strongly suggests, but does not rigorously imply, that no algorithm for either of these problems which runs in polynomial time exists."
            },
            "slug": "On-the-inherent-intractability-of-certain-coding-Berlekamp-McEliece",
            "title": {
                "fragments": [],
                "text": "On the inherent intractability of certain coding problems (Corresp.)"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "The fact that the general decoding problem for linear codes and the general problem of finding the weights of a linear code are both NP-complete is shown strongly suggests, but does not rigorously imply, that no algorithm for either of these problems which runs in polynomial time exists."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144018201"
                        ],
                        "name": "G. Forney",
                        "slug": "G.-Forney",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Forney",
                            "middleNames": [
                                "David"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Forney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7715701"
                        ],
                        "name": "R. Koetter",
                        "slug": "R.-Koetter",
                        "structuredName": {
                            "firstName": "Ralf",
                            "lastName": "Koetter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Koetter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1889982"
                        ],
                        "name": "F. Kschischang",
                        "slug": "F.-Kschischang",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Kschischang",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Kschischang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2171418135"
                        ],
                        "name": "Alexander Reznik",
                        "slug": "Alexander-Reznik",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Reznik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexander Reznik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 220,
                                "start": 207
                            }
                        ],
                        "text": "Among other connections, the fractional vertices of the first-order LP relaxation have a very specific interpretation as pseudocodewords of the underlying code, studied in earlier work on iterative decoding [80, 252, 83]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 118154721,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5ae961bbc96f4ce0a6017fc6d8e8cb4a3347a4aa",
            "isKey": false,
            "numCitedBy": 135,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The behavior of an iterative decoding algorithm for a code defined on a graph with cycles and a given decoding schedule is characterized by a cycle-free computation tree. The pseudocodewords of such a tree are the words that satisfy all tree constraintsj pseudocodewords govern decoding performance. Wiberg [12] determined the effective weight of pseudocodewords for binary codewords on an AWGN channel. This paper extends Wiberg\u2019s formula for AWGN channels to nonbinary codes, develops similar results for BSC and BEC channels, and gives upper and lower bounds on the effective weight. The 16-state tail-biting trellis of the Golay code [2] is used for exampIes. Although in this case no pseudocodeword is found with effective weight less than the minimum Hamming weight of the Golay code on an AWGN channel, it is shown by example that the minimum effective pseudocodeword weight can be less than the minimum codeword weight."
            },
            "slug": "On-the-Effective-Weights-of-Pseudocodewords-for-on-Forney-Koetter",
            "title": {
                "fragments": [],
                "text": "On the Effective Weights of Pseudocodewords for Codes Defined on Graphs with Cycles"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper extends Wiberg\u2019s formula for AWGN channels to nonbinary codes, develops similar results for BSC and BEC channels, and gives upper and lower bounds on the effective weight."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2514597"
                        ],
                        "name": "C. Moallemi",
                        "slug": "C.-Moallemi",
                        "structuredName": {
                            "firstName": "Ciamac",
                            "lastName": "Moallemi",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Moallemi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731282"
                        ],
                        "name": "Benjamin Van Roy",
                        "slug": "Benjamin-Van-Roy",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Van Roy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benjamin Van Roy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 94
                            }
                        ],
                        "text": "[158], using the notions of walk-summability and pairwise normalizability; see also the paper [173] for further refinements."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14539837,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "61167b491749cfbd289af3f21c834b25820b5e7e",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We establish the convergence of the min-sum message passing algorithm for minimization of a broad class of quadratic objective functions: those that admit a convex decomposition. Our results also apply to the equivalent problem of the convergence of Gaussian belief propagation."
            },
            "slug": "Convergence-of-the-Min-Sum-Message-Passing-for-Moallemi-Roy",
            "title": {
                "fragments": [],
                "text": "Convergence of the Min-Sum Message Passing Algorithm for Quadratic Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "The convergence of the min-sum message passing algorithm for minimization of a broad class of quadratic objective functions: those that admit a convex decomposition is established."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2880434"
                        ],
                        "name": "Feng Guangzeng",
                        "slug": "Feng-Guangzeng",
                        "structuredName": {
                            "firstName": "Feng",
                            "lastName": "Guangzeng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Feng Guangzeng"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 0
                            }
                        ],
                        "text": "[36, 37] have applied the tree-based relaxation (155) to the task of decoding turbo and low-density parity check (LDPC) codes, and provided analytical results to characterize its decoding performance."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 124992769,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d5302a69c32ef7bc4527b7f08ab2132eaa209b90",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The basic principles of linear programming algorithm for the maximum likelihood decoding of LDPC codes are analyzed,and the ways to construct the codeword polytope based on the factor graph expression of parity check matrix of LDPC codes are described.Since these descriptions are too complex with redundancy,a simplified constraint description is introduced hereafter.Derived from the fact that the code word must be subordinate to check equations,an optimized model based on syndrome is obtained for the maximum likelihood decoding of LDPC codes."
            },
            "slug": "Using-Linear-Programming-to-Decode-LDPC-Codes-Guangzeng",
            "title": {
                "fragments": [],
                "text": "Using Linear Programming to Decode LDPC Codes"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Derived from the fact that the code word must be subordinate to check equations, an optimized model based on syndrome is obtained for the maximum likelihood decoding of LDPC codes."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102835246"
                        ],
                        "name": "J. Hiriart-Urruty",
                        "slug": "J.-Hiriart-Urruty",
                        "structuredName": {
                            "firstName": "Jean-Baptiste",
                            "lastName": "Hiriart-Urruty",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hiriart-Urruty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8773884"
                        ],
                        "name": "C. Lemar\u00e9chal",
                        "slug": "C.-Lemar\u00e9chal",
                        "structuredName": {
                            "firstName": "Claude",
                            "lastName": "Lemar\u00e9chal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lemar\u00e9chal"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118755909,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "065c019bb27e23ed10492ca61b186eb9375dd5de",
            "isKey": false,
            "numCitedBy": 2940,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "IX. Inner Construction of the Subdifferential.- X. Conjugacy in Convex Analysis.- XI. Approximate Subdifferentials of Convex Functions.- XII. Abstract Duality for Practitioners.- XIII. Methods of ?-Descent.- XIV. Dynamic Construction of Approximate Subdifferentials: Dual Form of Bundle Methods.- XV. Acceleration of the Cutting-Plane Algorithm: Primal Forms of Bundle Methods.- Bibliographical Comments.- References."
            },
            "slug": "Convex-analysis-and-minimization-algorithms-Hiriart-Urruty-Lemar\u00e9chal",
            "title": {
                "fragments": [],
                "text": "Convex analysis and minimization algorithms"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713217"
                        ],
                        "name": "D. Bertsimas",
                        "slug": "D.-Bertsimas",
                        "structuredName": {
                            "firstName": "Dimitris",
                            "lastName": "Bertsimas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bertsimas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144224173"
                        ],
                        "name": "J. Tsitsiklis",
                        "slug": "J.-Tsitsiklis",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Tsitsiklis",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tsitsiklis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In order to show that \u03c6(y) is also a vertex of L(G), it suffices [22] to show that there are d constraints of L(G) that are active at \u03c6(y), and are also linearly independent."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "A classical technique for computing such projections is Fourier-Motzkin elimination [22, 266]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Therefore, by strong duality for linear programs [22], the pair (\u03bc\u2217, \u03bb\u2217) is primal-dual optimal."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60706246,
            "fieldsOfStudy": [
                "Biology",
                "Medicine"
            ],
            "id": "c8557a70ecdeec83f70954c5f169393c7f04fc9e",
            "isKey": false,
            "numCitedBy": 2692,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "p. 27, l. \u221211, replace \u201cSchwartz\u201d by \u201cSchwarz\u201d p. 69, l. \u221213: \u201cai\u2217x = bi\u201d should be \u201cai\u2217x = bi\u2217\u201d p. 126, l. 16, replace \u201cinequality constraints\u201d by \u201clinear inequality constraints\u201d p. 153, l. \u22128, replace aix 6= bi by aix 6= bi p. 163, Example 4.9, first line: replace \u201cfrom\u201d with \u201cform\u201d p. 165, l. 11, replace p\u2032Ax \u2265 0 by p\u2032Ax \u2265 0 p. 175, l. 1, replace \u201cTo this see\u201d by \u201cTo see this\u201d p. 203, l. 12: replace x \u2265 0 by x \u2265 0, xn+1 \u2265 0 p. 216, l. \u22126: replace \u201c\u2264 c}\u201d by \u201c\u2264 c\u2032}\u201d p. 216, l. \u22123: replace c\u2032 by (c1)\u2032 p. 216, l. \u22122: replace c\u2032 by (c2)\u2032 p. 216, l. \u22121: right-hand side should be \u03bb(c1)\u2032 + (1\u2212 \u03bb)(c2)\u2032 p. 220, l. \u221212: replace \u201cadded to the pivot row\u201d by \u201cadded to the zeroth row\u201d"
            },
            "slug": "Introduction-to-linear-optimization-Bertsimas-Tsitsiklis",
            "title": {
                "fragments": [],
                "text": "Introduction to linear optimization"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703039"
                        ],
                        "name": "Paat Rusmevichientong",
                        "slug": "Paat-Rusmevichientong",
                        "structuredName": {
                            "firstName": "Paat",
                            "lastName": "Rusmevichientong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paat Rusmevichientong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731282"
                        ],
                        "name": "Benjamin Van Roy",
                        "slug": "Benjamin-Van-Roy",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Van Roy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benjamin Van Roy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2749292,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "efa3492756d36303370d40c1de80fc790b3451d7",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We provide an analysis of the turbo decoding algorithm (TDA) in a setting involving Gaussian densities. In this context, we are able to show that the algorithm converges and that - somewhat surprisingly - though the density generated by the TDA may differ significantly from the desired posterior density, the means of these two densities coincide."
            },
            "slug": "An-Analysis-of-Turbo-Decoding-with-Gaussian-Rusmevichientong-Roy",
            "title": {
                "fragments": [],
                "text": "An Analysis of Turbo Decoding with Gaussian Densities"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "It is shown that the turbo decoding algorithm converges and that - somewhat surprisingly - though the density generated by the TDA may differ significantly from the desired posterior density, the means of these two densities coincide."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10151581"
                        ],
                        "name": "T. Plefka",
                        "slug": "T.-Plefka",
                        "structuredName": {
                            "firstName": "T",
                            "lastName": "Plefka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Plefka"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123236717,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "753761f39e455948779771e9a6b25ade1a4456f1",
            "isKey": false,
            "numCitedBy": 264,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "It is shown that the power expansion of the Gibbs potential of the SK model up to second order in the exchange couplings leads to the TAP equation. This result remains valid for the general (including a ferromagnetic exchange) SK model. Theorems of power expansions and resolvent techniques are employed to solve the convergence problem. The convergence condition is presented for the whole temperature range and for general distributions of the local magnetisations."
            },
            "slug": "Convergence-condition-of-the-TAP-equation-for-the-Plefka",
            "title": {
                "fragments": [],
                "text": "Convergence condition of the TAP equation for the infinite-ranged Ising spin glass model"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145884132"
                        ],
                        "name": "J. Edmonds",
                        "slug": "J.-Edmonds",
                        "structuredName": {
                            "firstName": "Jack",
                            "lastName": "Edmonds",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Edmonds"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "More generally, the set of valid edge appearance vectors \u03c1e must belong to the so-called spanning tree polytope [70, 51] associated with G, which we denote by S(G)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5599224,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "492ff2e9cab852a8fc46225f2e764007f8e5cb72",
            "isKey": false,
            "numCitedBy": 764,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Linear-algebra rank is the solution to an especially tractable optimization problem. This tractability is viewed abstractly, and extended to certain more general optimization problems which are linear programs relative to certain derived polyhedra."
            },
            "slug": "Matroids-and-the-greedy-algorithm-Edmonds",
            "title": {
                "fragments": [],
                "text": "Matroids and the greedy algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "Linear-algebra rank is the solution to an especially tractable optimization problem which are linear programs relative to certain derived polyhedra."
            },
            "venue": {
                "fragments": [],
                "text": "Math. Program."
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2566577"
                        ],
                        "name": "P. Vontobel",
                        "slug": "P.-Vontobel",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Vontobel",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Vontobel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7715701"
                        ],
                        "name": "R. Koetter",
                        "slug": "R.-Koetter",
                        "structuredName": {
                            "firstName": "Ralf",
                            "lastName": "Koetter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Koetter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16296453,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5cd50262d2468ae0f02a0caba26392e8549de985",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper discusses the two techniques for obtaining lower bounds on the (AWGN channel) pseudo-weight of binary linear codes. Whereas the first bound is based on the largest and second-largest eigenvalues of a matrix associated with the parity-check matrix of a code, the second bound is given by the solution to a linear program."
            },
            "slug": "Lower-bounds-on-the-minimum-pseudoweight-of-linear-Vontobel-Koetter",
            "title": {
                "fragments": [],
                "text": "Lower bounds on the minimum pseudoweight of linear codes"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "This paper discusses the two techniques for obtaining lower bounds on the (AWGN channel) pseudo-weight of binary linear codes using the largest and second-largest eigenvalues of a matrix associated with the parity-check matrix of a code."
            },
            "venue": {
                "fragments": [],
                "text": "International Symposium onInformation Theory, 2004. ISIT 2004. Proceedings."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29989822"
                        ],
                        "name": "T. Speed",
                        "slug": "T.-Speed",
                        "structuredName": {
                            "firstName": "Terence",
                            "lastName": "Speed",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Speed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3288569"
                        ],
                        "name": "H. Kiiveri",
                        "slug": "H.-Kiiveri",
                        "structuredName": {
                            "firstName": "Harri",
                            "lastName": "Kiiveri",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kiiveri"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 121496994,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "94cb65e2534ad017f35d2fd666f68d38eeb4eeb6",
            "isKey": false,
            "numCitedBy": 307,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "On s'interesse aux modeles de selection de covariance introduites par Dempster (1972) et etudies par Wermuth (1976)"
            },
            "slug": "Gaussian-Markov-Distributions-over-Finite-Graphs-Speed-Kiiveri",
            "title": {
                "fragments": [],
                "text": "Gaussian Markov Distributions over Finite Graphs"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145650848"
                        ],
                        "name": "Nailong Wu",
                        "slug": "Nailong-Wu",
                        "structuredName": {
                            "firstName": "Nailong",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nailong Wu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "One way in which to motivate exponential family representations of graphical models is through the principle of maximum entropy [120, 259]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 117774793,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "68b3a5adc8a5119f1fc7e1a57278debcb3cf16c7",
            "isKey": false,
            "numCitedBy": 184,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Introduction.- 1.1 What is the Maximum Entropy Method.- 1.2 Definition of Entropy.- 1.3 Rationale of the Maximum Entropy Method.- 1.4 Present and Future Research.- 2. Maximum Entropy Method MEM1 and Its Application in Spectral Analysis.- 2.1 Definition and Expressions of Entropy H1.- 2.1.1 Approach 1.- 2.1.2 Approach 2.- 2.1.3 Discussion.- 2.2 Formulation and Solution.- 2.2.1 Formulation.- 2.2.2 Solution.- 2.2.3 Discussion.- 2.3 Equivalents and Signal Model.- 2.3.1 ACF Extension Subject to the Nonnegativity Constraint.- 2.3.2 Principle of MCE.- 2.3.3 AR Process (Signal Model).- 2.3.4 Bayesian Method.- 2.3.5 Wiener Filter and Approximation Theoretic Approach.- 2.4 Algorithms and Numerical Example (Given ACF).- 2.4.1 Levinson's Recursion for 1-D Noiseless Data.- 2.4.2 Lim-Malik Algorithm for 2-D Noiseless Data.- 2.4.3 Wernecke-D'Addario Algorithm for 2-D Noisy Data.- 2.4.4 Numerical Example.- 2.5 Algorithms and Numerical Example (Given Time Series).- 2.5.1 Burg Algorithm.- 2.5.2 Marple Algorithm.- 2.5.3 Other Fast Algorithms.- 2.5.4 Numerical Example.- 2.6 Order Selection.- 2.6.1 FPE Criterion.- 2.6.2 AIC Criterion.- 2.6.3 Other Criteria.- 2.6.4 Summary.- 3. Maximum Entropy Method MEM2 and Its Application in Image Restoration.- 3.1 Definition and Expressions of Entropy H2.- 3.1.1 MLM.- 3.1.2 Direct Definition Method.- 3.1.3 Discussion.- 3.2 Formulation and Implicit Solution.- 3.2.1 Formulation.- 3.2.2 Implicit Solution.- 3.2.3 Iterative Algorithm.- 3.2.4 Discussion.- 3.3 Explicit Solution.- 3.3.1 Explicit Solution.- 3.3.2 Discussion.- 3.3.3 Examples.- 3.4 Equivalents and Signal Model.- 3.4.1 ACF Extension Subject to the Nonnegativity Constraint.- 3.4.2 Principle of MCE.- 3.4.3 Exponential Process (Signal Model).- 3.4.4 Bayesian Method.- 3.4.5 MLM.- 3.5 R - ? Procedure.- 3.5.1 Statements of the MEM2 Problem.- 3.5.2 R - ? Procedure.- 3.5.3 Example.- 3.6 Algorithms and Numerical Examples (I).- 3.6.1 Frieden Algorithm.- 3.6.2 Gull-Daniell Algorithm.- 3.6.3 Revised GD Algorithm.- 3.6.4 Simplified Newton-Raphson Algorithm.- 3.6.5 Numerical Example.- 3.7 Algorithms and Numerical Examples (II).- 3.7.1 Skilling-Bryan Algorithm.- 3.7.2 Differential Equation Approach.- 3.8 Algorithms and Numerical Examples (III).- 3.8.1 MEM/MemSys5 Package.- 3.8.2 MEM Task in IRAF.- 3.8.3 Restoration with Variable Resolution.- 3.8.4 Numerical Examples.- 3.8.5 Other Algorithms.- 4. Analysis and Comparison of the Maximum Entropy Method.- 4.1 Generalized MEM.- 4.1.1 Formulation of GMEM.- 4.1.2 \"Entropy\" Expressions in GMEM.- 4.1.3 Properties of GMEM.- 4.2 Expressions of Entropy.- 4.3 Solution's Properties.- 4.3.1 Existence.- 4.3.2 Uniqueness.- 4.3.3 Consistency.- 4.3.4 Statistical Properties.- 4.4 Resolution Enhancement and Data Extension (Experimental Results).- 4.4.1 Examples.- 4.4.2 Resolvability in 1-D Spectral Estimation.- 4.4.3 Resolvability in 2-D Spectral Estimation.- 4.4.4 Super resolut ion and Spectral Line Splitting.- 4.5 Resolution Enhancement and Data Extension (Theoretical Analysis).- 4.5.1 Data Extension in MEM1 and MEM2.- 4.5.2 Resolution Enhancement of MEM1 and MEM2.- 4.5.3 MEM1 and MEM2 Spectra at Low SNR.- 4.5.4 Line Splitting of MEM1.- 4.6 Peak Location and Relative Power Estimation (Experimental Results).- 4.6.1 Peak Location (Given ACF).- 4.6.2 Peak Location (Given Time Series).- 4.6.3 Relative Power Estimation (Given ACF).- 4.6.4 Summary and Comments.- 4.7 Peak Location and Relative Power Estimation (Theoretical Analysis).- 4.7.1 Interference Between Peaks Causes Peak Shifting.- 4.7.2 Explanation of the Peak Shifting in MEMI Spectra.- 4.7.3 Relative Power Estimation for MEMI.- 4.7.4 Summary for Sects. 4.4-4.7.- 4.8 Comments on the Three Schools of Thought on MEM.- 5. Applications of the Maximum Entropy Method in Mathematics and Physics.- 5.1 Solution of Moment Problems.- 5.1.1 General Theory.- 5.1.2 Numerical Methods.- 5.1.3 Noisy Moment Problems.- 5.1.4 Numerical Examples.- 5.2 Solution of Integral Equations.- 5.2.1 Conversion of Integral Equations to Moment Problems.- 5.2.2 Solution of Moment Problems by MEM.- 5.2.3 Numerical Examples.- 5.2.4 Discussion.- 5.3 Solution of Partial Differential Equations.- 5.3.1 Theory.- 5.3.2 Numerical Example.- 5.3.3 Discussion.- 5.4 Predictive Statistical Mechanics.- 5.4.1 Formulation and Solution.- 5.4.2 Useful Formulae.- 5.5 Distributions of Particles Among Energy Levels.- 5.5.1 Boltzmann Distribution.- 5.5.2 Fermi-Dirac and Bose-Einstein Distributions.- 5.6 Classical Statistical Ensembles.- 5.6.1 Microcanonical Ensemble.- 5.6.2 Canonical Ensemble.- 5.6.3 Grand Canonical Ensemble.- 5.7 Quantum Statistical Ensembles.- 5.7.1 Microcanonical Ensemble.- 5.7.2 Canonical Ensemble.- 5.7.3 Grand Canonical Ensemble.- Appendices.- A. Cepstral Analysis.- A.1 Cepstral Analysis System.- A.2 I/O Relationship.- A.3 Properties of the Complex Cepstrum.- A.4 I/O Relationship for Minimum-Phase Input.- B. Image Restoration.- B.1 Image Formation.- B.2 Image Restoration.- B.3 Relationship Between Image Restoration and Spectral Estimation.- References."
            },
            "slug": "The-Maximum-Entropy-Method-Wu",
            "title": {
                "fragments": [],
                "text": "The Maximum Entropy Method"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The Maximum Entropy Method MEM1 and Its Application in Spectral Analysis and Analysis and Comparison of the Nonnegativity Constraint is presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689196"
                        ],
                        "name": "A. Schrijver",
                        "slug": "A.-Schrijver",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Schrijver",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Schrijver"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This maximum weight matching (MWM) problem is well known to be solvable in polynomial time for any graph [207]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This LP relaxation is a classical one for the matching problem, known to be tight for any bipartite graph but loose for non-bipartite graphs [207]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Although the polytope S(G) has a prohibitively large number of inequalities, it is possible to maximize a linear function over it\u2014equivalently, to solving a maximum weight spanning tree problem\u2014by a greedy algorithm (see, for instance, Schrijver [207])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The field of polyhedral combinatorics [66, 101, 177, 207] is devoted to understanding the structure of such polytopes arising from various classes of discrete problems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 209100259,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "f9e591692d6aab0e1cf0c1ea4948597195657edf",
            "isKey": true,
            "numCitedBy": 3419,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Reading a book is also kind of better solution when you have no enough money or time to get your own adventure. This is one of the reasons we show the combinatorial optimization polyhedra and efficiency as your friend in spending the time. For more representative collections, this book not only offers it's strategically book resource. It can be a good friend, really good friend with much knowledge."
            },
            "slug": "Combinatorial-optimization.-Polyhedra-and-Schrijver",
            "title": {
                "fragments": [],
                "text": "Combinatorial optimization. Polyhedra and efficiency."
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This book shows the combinatorial optimization polyhedra and efficiency as your friend in spending the time in reading a book."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144101487"
                        ],
                        "name": "C. Berge",
                        "slug": "C.-Berge",
                        "structuredName": {
                            "firstName": "Claude",
                            "lastName": "Berge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Berge"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 119499595,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a98f508786064d07b4aa6c4d7482e97fe9bf4a11",
            "isKey": false,
            "numCitedBy": 402,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This book on the theory of graphs provides the reader with a mathematical tool which can be used in the behavioral sciences, in the theory of information, cybernetics, games, transport networks, as well as in set theory and matrix theory."
            },
            "slug": "The-theory-of-graphs-and-its-applications-Berge",
            "title": {
                "fragments": [],
                "text": "The Theory of Graphs and Its Applications."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1963
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144243047"
                        ],
                        "name": "J. Oxley",
                        "slug": "J.-Oxley",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Oxley",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Oxley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 63
                            }
                        ],
                        "text": "Any binary linear code can be identified with a binary matroid [182], in which context the codeword polytope is referred to as the cycle polytope of the binary matroid."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8808097,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "c83733d62364b412ed05013466685271f422724a",
            "isKey": false,
            "numCitedBy": 2279,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "The comments below apply to all printings of the book dated 2005 or earlier. The table following contains more than just a list of typing errors. Some statements and proofs have been corrected, simplified, or clarified. Moreover, the current status has been given for all the unsolved problems or conjectures that appear in Chapter 14. For those changes that simply involve the insertion of extra words, the corrected text is given with the inserted words underlined. It is planned to update this table at regular intervals and, eventually, these changes should be incorporated into the next printing of the book. The reader is encouraged to send the author <oxley@math.lsu.edu> corrections that do not appear in the table below."
            },
            "slug": "Matroid-theory-Oxley",
            "title": {
                "fragments": [],
                "text": "Matroid theory"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The current status has been given for all the unsolved problems or conjectures that appear in Chapter 14 and the corrected text is given with the inserted words underlined."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "146475034"
                        ],
                        "name": "D. Chandler",
                        "slug": "D.-Chandler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Chandler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Chandler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2402995"
                        ],
                        "name": "J. Percus",
                        "slug": "J.-Percus",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Percus",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Percus"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 55
                            }
                        ],
                        "text": "We begin with the Ising model from statistical physics [6, 20, 83], which is a particular kind of Markov random eld."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 53128002,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "c6b9a95f672b1ef0a2b3d4eae61c46696e157958",
            "isKey": false,
            "numCitedBy": 2385,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Thermodynamics, fundamentals conditions for equilibrium and stability statistical mechanics non-interacting (ideal) systems statistical mechanical theory of phase transitions Monte Carlo method in statistical mechanics classical fluids statistical mechanics of non-equilibrium systems."
            },
            "slug": "Introduction-To-Modern-Statistical-Mechanics-Chandler-Percus",
            "title": {
                "fragments": [],
                "text": "Introduction To Modern Statistical Mechanics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786843"
                        ],
                        "name": "A. Globerson",
                        "slug": "A.-Globerson",
                        "structuredName": {
                            "firstName": "Amir",
                            "lastName": "Globerson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Globerson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35132120"
                        ],
                        "name": "T. Jaakkola",
                        "slug": "T.-Jaakkola",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Jaakkola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jaakkola"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "For instance, Globerson and Jaakkola [92] exploit the notion of conditional entropy decomposition in order to construct whole families of upper bounds on the entropy, including as a special case the hypertree-based entropy bounds that underlie the reweighted Bethe/Kikuchi approaches."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Finally, there are other convex variational relaxations that are not directly based on convex combinations of tractable distributions, including the method of conditional entropy decompositions [92], and methods based on semidefinite constraints and log-determinant programming [243]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6788625,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d1425c4c8b5cfafa1c3fe9e643f9f3454ef77438",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a novel method for estimating the partition function and marginals of distributions defined using graphical models. The method uses the entropy chain rule to obtain an upper bound on the entropy of a distribution given marginal distributions of variable subsets. The structure of the bound is determined by a permutation, or elimination order, of the model variables. Optimizing this bound results in an upper bound on the log partition function, and also yields an approximation to the model marginals. The optimization problem is convex, and is in fact a dual of a geometric program. We evaluate the method on a 2D Ising model with a wide range of parameters, and show that it compares favorably with previous methods in terms of both partition function bound, and accuracy of marginals. Graphical models are a powerful tool for representing multivariate distributions, and have been used with considerable success in numerous domains from coding algorithms to image processing. Although graphical models yield compact representations of distributions, it is often very difficult to infer simple properties of these distributions, such as the marginals over single variables, or the MAP assignment. This difficulty stems from the fact that these problems involve enumeration over an exponential number of assignments, and has motivated extensive research into approximate inference algorithms. Another problem, which turns out to have a key role in developing inference algorithms, is the calculation of the partition function. Recent works (Wainwright & Jordan, 2003; Yedidia et al., 2005) have illustrated that a variational view of partition function estimation can be used to analyze most of the previously introduced approximate inference algorithms, such as mean field, belief propagation (BP) and the tree re-weighting (TRW) framework (Wainwright et al., 2005). The above analyzes emphasize that a key ingredient in most approximate inference algorithms is the estimation of the entropy of a graphical model given marginals over subsets of its variables. This approximation may be an upper bound on the true entropy, as in the TRW framework, or one which is not guaranteed to be a bound as in the Kikuchi entropies used in Generalized Belief Propagation (GBP) (Yedidia et al., 2005). Another important property of entropy approximation is convexity. The TRW entropies are convex whereas those of GBP are not necessarily convex. In the current work, we introduce a novel upper bound on graphical model entropy, which results in a convex upper bound on the partition function. The bound is constructed by decomposing the full model entropy into a sum of conditional entropies using the entropy chain rule (Cover & Thomas, 1991), and then discarding some of the conditioning variables, thus potentially increasing the entropy. This entropy bound is then plugged into the variational formulation, resulting in a convex optimization problem that yields an upper bound on the partition function. As with previous methods (Yedidia et al., 2005; Wainwright et al., 2005), a byproduct of this optimization problem is a set of pseudo-marginals which can be used to approximate the true model marginals. We evaluate our Conditional Entropy Decomposition (CED) method on a two dimensional Ising grid, and show that it performs well for a wide range of parameters, improving on both TRW and belief propagation. 1 Definitions and Notation We shall be interested in multivariate distributions over a set of variables x = {x1, . . . , xn}. Consider a set C of subsets C \u2286 {1, . . . , n}. Denote by xC an assignment to the variables xi such that i \u2208 C. A distribution over x will be parameterized using functions \u03b8(xC). We denote by \u03b8 the vector of all parameters for C \u2208 C. These can be used to define an exponential distribution over x given by"
            },
            "slug": "Approximate-inference-using-conditional-entropy-Globerson-Jaakkola",
            "title": {
                "fragments": [],
                "text": "Approximate inference using conditional entropy decompositions"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A novel upper bound is introduced on graphical model entropy, which results in a convex upper bound on the partition function, and the Conditional Entropy Decomposition (CED) method is evaluated, which performs well for a wide range of parameters, improving on both TRW and belief propagation."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143871349"
                        ],
                        "name": "F. Barahona",
                        "slug": "F.-Barahona",
                        "structuredName": {
                            "firstName": "Francisco",
                            "lastName": "Barahona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Barahona"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2588854"
                        ],
                        "name": "M. Gr\u00f6tschel",
                        "slug": "M.-Gr\u00f6tschel",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Gr\u00f6tschel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gr\u00f6tschel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "There is a rich literature in combinatorics on the structure of these codeword or cycle polytopes [8, 210, 100, 66]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 528438,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "80d5b27567de8f32a6897622824a046d0b0be07a",
            "isKey": false,
            "numCitedBy": 78,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-the-cycle-polytope-of-a-binary-matroid-Barahona-Gr\u00f6tschel",
            "title": {
                "fragments": [],
                "text": "On the cycle polytope of a binary matroid"
            },
            "venue": {
                "fragments": [],
                "text": "J. Comb. Theory, Ser. B"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51072723"
                        ],
                        "name": "Guozhong An",
                        "slug": "Guozhong-An",
                        "structuredName": {
                            "firstName": "Guozhong",
                            "lastName": "An",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guozhong An"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The origins underlying ideas lie in the statistical physics literature, where they were referred to as cluster variational methods [6, 224, 130]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 121788151,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "01091d57ff84dcdbc7aaefed1c33bb95e1109432",
            "isKey": false,
            "numCitedBy": 95,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Kikuchi's cluster variation method (CVM) is reformulated as the truncation of a M\u00f6bius inversion. An attempt is made to explicate and simplify the various approaches to the CVM. This formulation makes apparent the connection of the method with other types of cluster approximation. An illustration of the procedure is provided."
            },
            "slug": "A-note-on-the-cluster-variation-method-An",
            "title": {
                "fragments": [],
                "text": "A note on the cluster variation method"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696158"
                        ],
                        "name": "J. Mooij",
                        "slug": "J.-Mooij",
                        "structuredName": {
                            "firstName": "Joris",
                            "lastName": "Mooij",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mooij"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792269"
                        ],
                        "name": "H. Kappen",
                        "slug": "H.-Kappen",
                        "structuredName": {
                            "firstName": "Hilbert",
                            "lastName": "Kappen",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kappen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[199] provide sufficient conditions for convergence, based on contraction arguments such as those used for ordinary sumproduct [225, 87, 175, 115]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In subsequent work, other researchers [115, 175, 199] have used various types of contraction arguments to obtain sharper conditions for convergence, or uniqueness of fixed points [106]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12494625,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "23a0bb7a14c21bc1884d7f91dc97ff134e30324f",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We derive novel sufficient conditions for convergence of Loopy Belief Propagation (also known as the Sum-Product algorithm) to a unique fixed point. Our results improve upon previously known conditions. For binary variables with (anti-)ferromagnetic interactions, our conditions seem to be sharp."
            },
            "slug": "Sufficient-Conditions-for-Convergence-of-Loopy-Mooij-Kappen",
            "title": {
                "fragments": [],
                "text": "Sufficient Conditions for Convergence of Loopy Belief Propagation"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "Novel sufficient conditions for convergence of Loopy Belief Propagation to a unique fixed point are derived and the results improve upon previously known conditions."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35043531"
                        ],
                        "name": "A. Dempster",
                        "slug": "A.-Dempster",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Dempster",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dempster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7890796"
                        ],
                        "name": "N. Laird",
                        "slug": "N.-Laird",
                        "structuredName": {
                            "firstName": "Nan",
                            "lastName": "Laird",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Laird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235217"
                        ],
                        "name": "D. Rubin",
                        "slug": "D.-Rubin",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Rubin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rubin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[65] provides a general approach to computing MLEs in this partially observed setting."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4193919,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "d36efb9ad91e00faa334b549ce989bfae7e2907a",
            "isKey": false,
            "numCitedBy": 48406,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "Vibratory power unit for vibrating conveyers and screens comprising an asynchronous polyphase motor, at least one pair of associated unbalanced masses disposed on the shaft of said motor, with the first mass of a pair of said unbalanced masses being rigidly fastened to said shaft and with said second mass of said pair being movably arranged relative to said first mass, means for controlling and regulating the conveying rate during conveyer operation by varying the rotational speed of said motor between predetermined minimum and maximum values, said second mass being movably outwardly by centrifugal force against the pressure of spring means, said spring means being prestressed in such a manner that said second mass is, at rotational motor speeds lower than said minimum speed, held in its initial position, and at motor speeds between said lower and upper values in positions which are radially offset with respect to the axis of said motor to an extent depending on the value of said rotational motor speed."
            },
            "slug": "Maximum-likelihood-from-incomplete-data-via-the-EM-Dempster-Laird",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood from incomplete data via the EM - algorithm plus discussions on the paper"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143676697"
                        ],
                        "name": "Y. Nesterov",
                        "slug": "Y.-Nesterov",
                        "structuredName": {
                            "firstName": "Yurii",
                            "lastName": "Nesterov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Nesterov"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121309892,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "3f9f16982b9b1777f2f39d9cb82054c6c2b27b6b",
            "isKey": false,
            "numCitedBy": 429,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we consider the semidefinite relaxation of some global optimization problems. We prove that in some cases this relaxation provides us with a constant relative accuracy estimate for the exact solution."
            },
            "slug": "Semidefinite-relaxation-and-nonconvex-quadratic-Nesterov",
            "title": {
                "fragments": [],
                "text": "Semidefinite relaxation and nonconvex quadratic optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "It is proved that in some cases this semidefinite relaxation of some global optimization problems provides us with a constant relative accuracy estimate for the exact solution."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700326"
                        ],
                        "name": "J. Demmel",
                        "slug": "J.-Demmel",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Demmel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Demmel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In practice, of course, one would not compute the mode of a Gaussian problem by solving this semidefinite program, since it can be computed by more direct methods, including Kalman filtering [123], corresponding to the sum-product algorithm on trees, by numerical methods such as conjugate gradient [64], by the max-product/min-sum algorithm (see Section 8."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "21) are guaranteed to converge whenever \u2212\u0398 is strictly diagonally dominant; see Demmel [64] for further details on such Gauss-Jacobi and Gauss-Seidel iterations for solving matrix-vector equations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "the particular ordering used, to either the Gauss-Jacobi or the GaussSeidel methods [64] for solving the normal equations \u03bc = \u2212\u0398\u22121\u03b8."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 40064452,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "59a0d7ca66f5bd7d31c7c96d36c31033a075e246",
            "isKey": false,
            "numCitedBy": 2962,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface 1. Introduction 2. Linear equation solving 3. Linear least squares problems 4. Nonsymmetric Eigenvalue problems 5. The symmetric Eigenproblem and singular value decomposition 6. Iterative methods for linear systems 7. Iterative methods for Eigenvalue problems Bibliography Index."
            },
            "slug": "Applied-Numerical-Linear-Algebra-Demmel",
            "title": {
                "fragments": [],
                "text": "Applied Numerical Linear Algebra"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The symmetric Eigenproblem and singular value decomposition and the Iterative methods for linear systems Bibliography Index."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681843"
                        ],
                        "name": "J. Dauwels",
                        "slug": "J.-Dauwels",
                        "structuredName": {
                            "firstName": "Justin",
                            "lastName": "Dauwels",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dauwels"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143681410"
                        ],
                        "name": "H. Loeliger",
                        "slug": "H.-Loeliger",
                        "structuredName": {
                            "firstName": "Hans-Andrea",
                            "lastName": "Loeliger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Loeliger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3073742"
                        ],
                        "name": "Patrick Merkli",
                        "slug": "Patrick-Merkli",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Merkli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Patrick Merkli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3018905"
                        ],
                        "name": "Maja Ostojic",
                        "slug": "Maja-Ostojic",
                        "structuredName": {
                            "firstName": "Maja",
                            "lastName": "Ostojic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Maja Ostojic"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 59925428,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dca10857081747209d024fda998218e4406e229d",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "A general idea\u2014message passing with messages that have some nontrivial Markov structure\u2014is outlined. This general idea is worked out for one particular application, viz., the synchronization (state estimation) of \u201cnoisy\u201d linear-feedback shift register sequences. For this application, the flexible tradeo between performance and complexity is demonstrated by simulation results. Generalizations to lowcomplexity approximations of the BCJR algorithm are outlined."
            },
            "slug": "On-Structured-Summary-Propagation,-LFSR-and-Trellis-Dauwels-Loeliger",
            "title": {
                "fragments": [],
                "text": "On Structured-Summary Propagation, LFSR Synchronization, and Low-Complexity Trellis Decoding"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "A general idea\u2014message passing with messages that have some nontrivial Markov structure\u2014is outlined for one particular application, viz., the synchronization (state estimation) of \u201cnoisy\u201d linear-feedback shift register sequences."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741169"
                        ],
                        "name": "H. Bodlaender",
                        "slug": "H.-Bodlaender",
                        "structuredName": {
                            "firstName": "Hans",
                            "lastName": "Bodlaender",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bodlaender"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 33329367,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "84ac739385ee34066e9a5e14795606dfde29bfe9",
            "isKey": false,
            "numCitedBy": 720,
            "numCiting": 171,
            "paperAbstract": {
                "fragments": [],
                "text": "A short overview is given of many recent results in algorithmic graph theory that deal with the notions treewidth, and pathwidth. We discuss algorithms that find tree-decompositions, algorithms that use tree-decompositions to solve hard problems efficiently, graph minor theory, and some applications. The paper contains an extensive bibliography."
            },
            "slug": "A-Tourist-Guide-through-Treewidth-Bodlaender",
            "title": {
                "fragments": [],
                "text": "A Tourist Guide through Treewidth"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "A short overview is given of many recent results in algorithmic graph theory that deal with the notions treewidth, and pathwidth, and algorithms that find tree-decompositions, algorithms that use tree-DECOMpositions to solve hard problems efficiently, graph minor theory, and some applications."
            },
            "venue": {
                "fragments": [],
                "text": "Acta Cybern."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2514597"
                        ],
                        "name": "C. Moallemi",
                        "slug": "C.-Moallemi",
                        "structuredName": {
                            "firstName": "Ciamac",
                            "lastName": "Moallemi",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Moallemi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731282"
                        ],
                        "name": "Benjamin Van Roy",
                        "slug": "Benjamin-Van-Roy",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Van Roy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benjamin Van Roy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 76
                            }
                        ],
                        "text": "For this family of pairwise separable convex programs, Moallemi and van Roy [174] established convergence of the max-product updates under a certain scaled diagonal dominance condition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 21
                            }
                        ],
                        "text": "Moallemi and van Roy [174] consider the more general problem of maximizing an arbitrary function of the form (8."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14552791,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bade4639444b261da9fed525f6c1c9cd01757918",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We establish that the min-sum message-passing algorithm and its asynchronous variants converge for a large class of unconstrained convex optimization problems."
            },
            "slug": "Convergence-of-the-Min-Sum-Algorithm-for-Convex-Moallemi-Roy",
            "title": {
                "fragments": [],
                "text": "Convergence of the Min-Sum Algorithm for Convex Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "It is established that the min-sum message-passing algorithm and its asynchronous variants converge for a large class of unconstrained convex optimization problems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 136
                            }
                        ],
                        "text": "Problems of constraint satisfaction and combinatorial optimization arise in a wide variety of areas, among them artificial intelligence [63, 188], communication theory [84], computational complexity theory [52], statistical image processing [86], and bioinformatics [190]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 16
                            }
                        ],
                        "text": "It can be shown [188] that for tree-structured graphs, iterates generated by the update (2."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 57437891,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5bf6f01402e1648b7d1e6c9200ede6cb1af30123",
            "isKey": false,
            "numCitedBy": 4579,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Probabilistic-reasoning-in-intelligent-systems-Pearl",
            "title": {
                "fragments": [],
                "text": "Probabilistic reasoning in intelligent systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117231104"
                        ],
                        "name": "Junli Hu",
                        "slug": "Junli-Hu",
                        "structuredName": {
                            "firstName": "Junli",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Junli Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143681410"
                        ],
                        "name": "H. Loeliger",
                        "slug": "H.-Loeliger",
                        "structuredName": {
                            "firstName": "Hans-Andrea",
                            "lastName": "Loeliger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Loeliger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681843"
                        ],
                        "name": "J. Dauwels",
                        "slug": "J.-Dauwels",
                        "structuredName": {
                            "firstName": "Justin",
                            "lastName": "Dauwels",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dauwels"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1889982"
                        ],
                        "name": "F. Kschischang",
                        "slug": "F.-Kschischang",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Kschischang",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Kschischang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 100
                            }
                        ],
                        "text": "As with assumed density filtering, expectationpropagation [172, 171] and various related algorithms [181, 61, 112] are typically described in terms of moment-matching operations."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 103
                            }
                        ],
                        "text": "Finally, we describe expectation-propagation algorithms [180, 172] and related moment-matching methods [181, 61, 112]; these are also varia-"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 110
                            }
                        ],
                        "text": "3, the family of expectation-propagation algorithms [169, 172], as well as related moment-matching algorithms [181, 61, 112], can be understood in terms of term-by-term entropy approximations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 266,
                                "start": 257
                            }
                        ],
                        "text": "Examples of such algorithms include the family of expectationpropagation algorithms due to Minka [172], the related class of assumed density filtering methods [149, 161, 37], expectation-consistent inference [181], structured summary-propagation algorithms [61, 112], and"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15166076,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1f21ecd14cbc4323359a3e92457f71f29989292b",
            "isKey": true,
            "numCitedBy": 31,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Elaborating on prior work by Minka, we formu- late a general computation rule for lossy messages. An impor- tant special case (with many applications in communications) is the conversion of \"soft-bit\" messages to Gaussian messages. By this method, the performance of a Kalman equalizer is improved, both for uncoded and coded transmission."
            },
            "slug": "A-general-computation-rule-for-lossy-with-examples-Hu-Loeliger",
            "title": {
                "fragments": [],
                "text": "A general computation rule for lossy summaries/messages with examples from equalization"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "By this method, the performance of a Kalman equalizer is improved, both for uncoded and coded transmission."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3151044"
                        ],
                        "name": "C. Burge",
                        "slug": "C.-Burge",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Burge",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Burge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145737605"
                        ],
                        "name": "S. Karlin",
                        "slug": "S.-Karlin",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Karlin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Karlin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "HMMs have been the methodology of choice for attacking this problem, with designers choosing states and state transitions to reflect biological knowledge concerning gene structure [41]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15275320,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "22568d6cd1feb27394f3137437986607ebe90b62",
            "isKey": false,
            "numCitedBy": 573,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Finding-the-genes-in-genomic-DNA.-Burge-Karlin",
            "title": {
                "fragments": [],
                "text": "Finding the genes in genomic DNA."
            },
            "venue": {
                "fragments": [],
                "text": "Current opinion in structural biology"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13625645"
                        ],
                        "name": "S. Chopra",
                        "slug": "S.-Chopra",
                        "structuredName": {
                            "firstName": "Sunil",
                            "lastName": "Chopra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Chopra"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "More generally, the set of valid edge appearance vectors \u03c1e must belong to the so-called spanning tree polytope [70, 51] associated with G, which we denote by S(G)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 122550186,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "6576a5235eceb306c3eb157edae9fba57210e931",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-the-spanning-tree-polyhedron-Chopra",
            "title": {
                "fragments": [],
                "text": "On the spanning tree polyhedron"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143604406"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "Biing-Hwang",
                            "lastName": "Juang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "subsumes the classical recursive algorithms, including the pruning and peeling algorithms from computational genetics [76], the forwardbackward algorithms for hidden Markov models [192], and the Kalman filtering-smoothing algorithms for state-space models [123]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In the HMM context, this algorithm is often referred to as the forward-backward algorithm [192]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7788300,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "id": "df50c6e1903b1e2d657f78c28ab041756baca86a",
            "isKey": false,
            "numCitedBy": 8924,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Fundamentals of Speech Recognition. 2. The Speech Signal: Production, Perception, and Acoustic-Phonetic Characterization. 3. Signal Processing and Analysis Methods for Speech Recognition. 4. Pattern Comparison Techniques. 5. Speech Recognition System Design and Implementation Issues. 6. Theory and Implementation of Hidden Markov Models. 7. Speech Recognition Based on Connected Word Models. 8. Large Vocabulary Continuous Speech Recognition. 9. Task-Oriented Applications of Automatic Speech Recognition."
            },
            "slug": "Fundamentals-of-speech-recognition-Rabiner-Juang",
            "title": {
                "fragments": [],
                "text": "Fundamentals of speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This book presents a meta-modelling framework for speech recognition that automates the very labor-intensive and therefore time-heavy and therefore expensive and expensive process of manually modeling speech."
            },
            "venue": {
                "fragments": [],
                "text": "Prentice Hall signal processing series"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723644"
                        ],
                        "name": "A. Acero",
                        "slug": "A.-Acero",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Acero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Acero"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47932744"
                        ],
                        "name": "Xuedong Huang",
                        "slug": "Xuedong-Huang",
                        "structuredName": {
                            "firstName": "Xuedong",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xuedong Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145058181"
                        ],
                        "name": "H. Hon",
                        "slug": "H.-Hon",
                        "structuredName": {
                            "firstName": "Hsiao-Wuen",
                            "lastName": "Hon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hon"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 54
                            }
                        ],
                        "text": "Large-scale systems are built by composing elementary HMMs into larger graphical models."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 58
                            }
                        ],
                        "text": "This variant is widely used in speech recognition systems [55]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 91
                            }
                        ],
                        "text": "Moreover, essentially all modern speech recognition systems are built on the foundation of HMMs [117]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "In language problems, HMMs also play a fundamental role."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 96
                            }
                        ],
                        "text": "Moreover, essentially all modern speech recognition systems are built on the foundation of HMMs [55]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59832957,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "74fe8a40571758823eb1858ccc9411e2b43fe7ea",
            "isKey": true,
            "numCitedBy": 959,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "A filling assembly for vacuum filling impervious open mouth paper bags with finely divided particulate material. A filling head is provided with at least two independent vertically extending chambers through which a selective vacuum or relief may be applied. Particulate material is fed through a central opening in the filling head whereby interstitial air is withdrawn from between the particles of particulate material as the material falls downwardly into an impervious open mouth bag. Clamping jaws serve to seal the bag against the filler head during the filling operation and include clamping flanges which extend outwardly from the jaws and tightly close the outer edges of the open mouth bag. A shroud extends from the clamping jaws to provide a sealed enclosure about the bag during the vacuum filling operation. A vacuum source is selectively applied to the shroud to open the impervious bag and keep the bag open during the vacuum filling operation."
            },
            "slug": "Spoken-Language-Processing-Acero-Huang",
            "title": {
                "fragments": [],
                "text": "Spoken Language Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A filling assembly for vacuum filling impervious open mouth paper bags with finely divided particulate material is provided with at least two independent vertically extending chambers through which a selective vacuum or relief may be applied."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2097157832"
                        ],
                        "name": "Martin S. Kochmanski",
                        "slug": "Martin-S.-Kochmanski",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Kochmanski",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin S. Kochmanski"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 100601644,
            "fieldsOfStudy": [
                "Mathematics",
                "Physics"
            ],
            "id": "b8558e5a179728b33ac4b5671a128923ca761980",
            "isKey": false,
            "numCitedBy": 79,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "In this brief note some inaccuracy which occured in wellknown paper by E. Ising [1] is discussed."
            },
            "slug": "NOTE-ON-THE-E.-ISING'S-PAPER-,,BEITRAG-ZUR-THEORIE-Kochmanski",
            "title": {
                "fragments": [],
                "text": "NOTE ON THE E. ISING'S PAPER ,,BEITRAG ZUR THEORIE DES FERROMAGNETISMUS\" (Zs. Physik, 31, 253 (1925))"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49346190"
                        ],
                        "name": "Kazuyuki Tanaka",
                        "slug": "Kazuyuki-Tanaka",
                        "structuredName": {
                            "firstName": "Kazuyuki",
                            "lastName": "Tanaka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kazuyuki Tanaka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143611832"
                        ],
                        "name": "T. Morita",
                        "slug": "T.-Morita",
                        "structuredName": {
                            "firstName": "Tohru",
                            "lastName": "Morita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Morita"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121049236,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "3643f5f2506b6615d2425cbc50ac62809b457284",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Cluster-variation-method-and-image-restoration-Tanaka-Morita",
            "title": {
                "fragments": [],
                "text": "Cluster variation method and image restoration problem"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145724968"
                        ],
                        "name": "M. \u00c7etin",
                        "slug": "M.-\u00c7etin",
                        "structuredName": {
                            "firstName": "M\u00fcjdat",
                            "lastName": "\u00c7etin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. \u00c7etin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2097799595"
                        ],
                        "name": "Lei Chen",
                        "slug": "Lei-Chen",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Lei Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lei Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31496901"
                        ],
                        "name": "John W. Fisher III",
                        "slug": "John-W.-Fisher-III",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Fisher III",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John W. Fisher III"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740137"
                        ],
                        "name": "A. Ihler",
                        "slug": "A.-Ihler",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Ihler",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ihler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727456"
                        ],
                        "name": "R. Moses",
                        "slug": "R.-Moses",
                        "structuredName": {
                            "firstName": "Randolph",
                            "lastName": "Moses",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Moses"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721860"
                        ],
                        "name": "M. Wainwright",
                        "slug": "M.-Wainwright",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Wainwright",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wainwright"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701607"
                        ],
                        "name": "A. Willsky",
                        "slug": "A.-Willsky",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Willsky",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Willsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Various forms of these reweighted maxproduct algorithms have been applied in problems such as segmentation and disparity problems in computer vision [165, 134, 136, 246, 222, 260], error-control coding [73], side-chain prediction [261, 246], sensor fusion [43, 46]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6486779,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b664abd2a95b4ee53fcf662063829a1181df8c64",
            "isKey": false,
            "numCitedBy": 182,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an overview of research conducted to bridge the rich field of graphical models with the emerging field of data fusion for sensor networks. Both theoretical issues and prototyping applications are discussed in addition to suggesting new lines of reasoning."
            },
            "slug": "Distributed-fusion-in-sensor-networks-\u00c7etin-Chen",
            "title": {
                "fragments": [],
                "text": "Distributed fusion in sensor networks"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper presents an overview of research conducted to bridge the rich field of graphical models with the emerging field of data fusion for sensor networks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Signal Processing Magazine"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Now let us consider the case \u03bc / \u2208 M = [0, 1]; concretely, let us suppose that \u03bc > 1."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "33) corresponding to dth central moments of a Bernoulli variable with parameter \u03c4s \u2208 [0, 1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Bernoulli R log[1 + exp(\u03b8)] [0, 1] \u03bc log \u03bc+ (1\u2212 \u03bc) log(1\u2212 \u03bc"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Contingency tables are a central tool in categorical data analysis [148, 77, 1], dating back to the seminal work of Pearson, Yule and Fisher."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "1(b), the marginal polytope M(C3) is strictly contained within the scaled cube [0, 1 2 ] 3."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "5 on each of the configurations [ 0 0 0 0 ] and [ 1 1 1 1 ] ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": ",\u03bcm)\u2208[0,1] {\u2211"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "max \u03bc\u2208[0,1] {\u03bc \u00b7 \u03b8 \u2212 \u03bc log\u03bc\u2212 (1\u2212 \u03bc) log(1\u2212 \u03bc)} ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": ") Turning to the verification of Theorem 2(b), since A\u2217(\u03bc) = +\u221e unless \u03bc \u2208 [0, 1], the optimization problem (3."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "For any \u03bb \u2208 [0, 1], the convex combination \u03bc(\u03bb) = \u03bb\u03bc+ (1\u2212 \u03bb)\u03bc\u2032 is realized by the mixture distribution"
                    },
                    "intents": []
                }
            ],
            "corpusId": 120060268,
            "fieldsOfStudy": [],
            "id": "46af404d4a81238fb77f85005b3f3ef22635cc4b",
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Categorical Data Analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786249"
                        ],
                        "name": "D. Bertsekas",
                        "slug": "D.-Bertsekas",
                        "structuredName": {
                            "firstName": "Dimitri",
                            "lastName": "Bertsekas",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bertsekas"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Recall that Danskin\u2019s theorem [19] shows that the convex surrogate B is differentiable, with \u2207B(\u03b8) = \u03c4(\u03b8)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Using this fact, it is possible [241] to develop a version of the conditional gradient algorithm [19] for efficiently computing the optimal choice of edge appearance probabilities."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Since the maximum is uniquely attained for every coordinate update, known results on coordinate ascent methods [19] imply that any sequence {\u03bc0, \u03bc1, ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "To see this fact, note that if \u03bb\u2217 is Lagrange multiplier vector for the BVP, then any optimal solution \u03c4\u2217 must maximize the Lagrangian L(\u03c4, \u03bb\u2217) over the positive orthant \u03c4 \u2265 0 (see Bertsekas [19])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Consequently, standard theory on blockwise coordinate ascent methods [19] can be used to establish convergence of the IPF procedure."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "is uniquely attained, so that Danskin\u2019s theorem [19] ensures that B is differentiable."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 64649729,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "11106aadd1c133477b163f08de6c9436cd5468fe",
            "isKey": true,
            "numCitedBy": 9680,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Nonlinear-Programming-Bertsekas",
            "title": {
                "fragments": [],
                "text": "Nonlinear Programming"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 26
                            }
                        ],
                        "text": "Kolmogorov and Wainwright [135] showed that for pairwise MRFs with binary variables, the equivalence between TRW message-passing and the LP relaxation is exact in all cases: any fixed point of TRW max-product specifies a dual-optimal solution to the first-order LP relaxation (8."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 62
                            }
                        ],
                        "text": "19)\u2014where the interactions between variables are supermodular [102, 135]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 47
                            }
                        ],
                        "text": "Among other results, Kolmogorov and Wainwright [135] establish that the tree-reweighted max-product is exact for any regular binary QP."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 49
                            }
                        ],
                        "text": "When \u03b2st > 0 for all (s, t) \u2208 E, it can be shown [135] that the first-order LP relaxation (8."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On optimality properties of treereweighted message-passing"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Conference on Uncertainty in Artificial Intelligence, pages 316\u2013322. AUAI Press,"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 38
                            }
                        ],
                        "text": "The field of polyhedral combinatorics [66, 101, 177, 207] is devoted to understanding the structure of such polytopes arising from various classes of discrete problems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 98
                            }
                        ],
                        "text": "There is a rich literature in combinatorics on the structure of these codeword or cycle polytopes [8, 210, 100, 66]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "1 of Deza and Laurent [66] for a complete discussion."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 111
                            }
                        ],
                        "text": "In the polyhedral combinatorics literature, this set is known as the correlation polytope, or the cut polytope [66, 183]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 178
                            }
                        ],
                        "text": "However, with the exception of tree-structured graphs, the number of facets for M(G) is not known in general, even for relatively simple cases like the Ising model (see the book [66] for background on the cut or correlation polytope, which is equivalent to the marginal polytope for an Ising model."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 21
                            }
                        ],
                        "text": "See Deza and Laurent [66] for more details."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 140
                            }
                        ],
                        "text": "Sontag and Jaakkola [214] examine the effect of tightened outer bounds on the marginal polytope, including the so-called cycle inequalities [66, 183]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 70
                            }
                        ],
                        "text": "For the special case of the Ising model, the book by Deza and Laurent [66] contains a wealth of information about the correlation/cut polytope."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Geometry of Cuts and Metric Embeddings"
            },
            "venue": {
                "fragments": [],
                "text": "Springer- Verlag, New York,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 80
                            }
                        ],
                        "text": "In this section, we begin by presenting the tree-reweighted max-product updates [240], and describing their connection to the first-order LP relaxation (8."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 39
                            }
                        ],
                        "text": "In addition to the basic TRW algorithm [240] and the TRWS scheduling studied by Kolmogorov [134], other researchers have proposed distributed algorithms for solving the tree-based LP relax-"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 112
                            }
                        ],
                        "text": "In this section, we discuss the parallel link between the ordinary max-product algorithm and linear programming [240]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 25
                            }
                        ],
                        "text": "As detailed in the paper [240], the most general sufficient condition is that there exists a configuration x\u0302 = x\u0302TRW that is nodewise and edgewise optimal across the entire graph, meaning that"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "[240], and later resolved by Kolmogorov [134], who provided a counterexample, involving non-binary variables, for which a TRW max-product fixed point does not correspond to a dual-optimal solution."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 21
                            }
                        ],
                        "text": "The following result [240] gives an affirmative answer to the question above: for tree-structured graphs, the max-product updates (8."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 70
                            }
                        ],
                        "text": "In general, this conjecture is false, as the following counterexample [240] shows:"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 123
                            }
                        ],
                        "text": "For general MRFs, max-product itself is not a method for solving this LP, as we demonstrate with a concrete counterexample [240]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Exact MAP estimates via agreement on (hyper)trees: Linear programming and message-passing"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Information Theory, 51(11):3697\u20133717,"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 5
                            }
                        ],
                        "text": "Both Bethe-type and mean field methods are based on nonconvex optimization problems, which typically have multiple solutions."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 60
                            }
                        ],
                        "text": "Although this approximation dates back to the work of Bethe [27], the connection to the sum-product algorithm was first elucidated by Yedidia, Freeman and Weiss [263, 264]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 52
                            }
                        ],
                        "text": "In Section 4, we discuss the connection between the Bethe approximation and the sum-product algorithm, including both its exact form for trees and approximate form for graphs with cycles."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 40
                            }
                        ],
                        "text": "We also develop the connections between Bethe-like approximations and other algorithms, including generalized sum-product, expectationpropagation and related moment-matching methods."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistics theory of superlattices"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Royal Soc. London, Series A, 150(871):552\u2013575,"
            },
            "year": 1935
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 114
                            }
                        ],
                        "text": "Rockafellar [198] is a standard reference on convex analysis; see also the books by Hiriart-Urruty and Lemar\u00e9chal [109, 110], Boyd and Vandenberghe [36], and Bertsekas [21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 125
                            }
                        ],
                        "text": ", either compactness of the constraint sets, or coercivity of the function; see Section VII of Hiriart-Urruty and Lemar\u00e9chal [109]), we can exchange the sup and inf to obtain"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 39
                            }
                        ],
                        "text": "Under this assumption, it can be shown [236, 109] that the output \u03c4(\u03b8) = \u2207B(\u03b8) of the variational method is Lipschitz stable, in the sense of definition (7."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 34
                            }
                        ],
                        "text": "7 in HiriartUrruty and Lemar\u00e9chal [109])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 54
                            }
                        ],
                        "text": "Conjugate duality is a cornerstone of convex analysis [198, 109], and is a natural source for variational representations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 174
                            }
                        ],
                        "text": "This condition implies var\u03b8[\u3008a, \u03c6(x)\u3009] = a T\u22072A(\u03b8)a > 0 for all a \u2208 Rd and \u03b8 \u2208 \u03a9; this strict positive definiteness of the Hessian on the open set \u03a9 implies strict convexity [109]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 35
                            }
                        ],
                        "text": "1 of Hiriart-Urruty and Lemar\u00e9chal [109])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 119
                            }
                        ],
                        "text": "(In fact, an equivalent characterization of strong convexity is to require that the function f(z) \u2212 c 2\u2016z\u2016 2 be convex [109]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 151
                            }
                        ],
                        "text": "Taking the perspective of exponential families illuminates some fundamental connections between inference algorithms and the theory of convex analysis [35, 109, 198]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Convex Analysis and Minimization Algorithms, volume 1"
            },
            "venue": {
                "fragments": [],
                "text": "Springer-Verlag, New York,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This is without loss of generality, because any regular, minimal exponential family can be reparameterized in such a canonical form [40]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Brown [40])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In our view, the most promising avenue towards a variational methodology tuned to statistics is to build on existing links between variational analysis and the exponential family of distributions [4, 10, 40, 71]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This property is also referred to as steepness in some statistical treatments [40]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Although there do exist exponential families for which \u03a9 is closed (for instance, see Brown [40]), herein we restrict our attention to regular exponential families."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fundamentals of Statistical Exponential Families"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 151
                            }
                        ],
                        "text": "Overall, this intuition suggests that the max-product algorithm on trees should be related to the tree-structured LP (146), which the following result [111] makes precise:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "[111] derive a tree-reweighted analog of the max-product algorithm, analogous to the tree-reweighted sum-product algorithm of Section 8."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 195,
                                "start": 190
                            }
                        ],
                        "text": "This relaxation can also be derived as a Lagrangian dual formulation of nding the tightest upper bound on the support function A1( ) = maxx2Xnh ; (x)i based on a convex combination of trees [111]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Exact MAP estimates via agreement on (hyper)trees: Linear programming and message-passing approaches"
            },
            "venue": {
                "fragments": [],
                "text": "Technical report, UC Berkeley, UCB/CSD-3-1269, August"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 208
                            }
                        ],
                        "text": "4 A convenient graphical representation of a hypergraph is in terms of a diagram of its hyperedges, with directed edges representing the inclusion relations; such a representation is known as a poset diagram [163, 184, 216]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 55
                            }
                        ],
                        "text": "[263, 264] and further explored by various researchers [184, 163, 108, 235, 265], that improves both components simultaneously."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 103
                            }
                        ],
                        "text": "Further details on different variants of generalized sumproduct updates can be found in various papers [263, 264, 184, 163, 125]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 61
                            }
                        ],
                        "text": "However, with the exception of trees and other special cases [184, 163, 107], the Bethe variational problem is usually a nonconvex problem, in that HBethe fails to be concave."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 26
                            }
                        ],
                        "text": "Various other researchers [107, 163, 184, 185] also discuss the choice edge/clique weights in Bethe/Kikuchi approximations, and its consequences for convexity."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 57
                            }
                        ],
                        "text": "In contrast, with the exception of certain special cases [107, 184, 185, 163], Kikuchi and other hypergraph-based entropy approximations are typically not convex."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Iterative algorithms and free energy minimization"
            },
            "venue": {
                "fragments": [],
                "text": "Annual Conference on Information Sciences and Systems, Princeton, NJ,"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712211"
                        ],
                        "name": "G. Golub",
                        "slug": "G.-Golub",
                        "structuredName": {
                            "firstName": "Gene",
                            "lastName": "Golub",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Golub"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Consequently, the matrix-inverse-vector problem P\u22121\u03b8 can often be solved very quickly, by specialized methods that exploit the graph structure of P (see, for instance, Golub and van Loan [96])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 126299280,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b9efffc63f81bf3f6cb6357ddc15e9cd9da75d16",
            "isKey": false,
            "numCitedBy": 27000,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Matrix-computations-Golub",
            "title": {
                "fragments": [],
                "text": "Matrix computations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691022"
                        ],
                        "name": "M. Opper",
                        "slug": "M.-Opper",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Opper",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Opper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064612704"
                        ],
                        "name": "David Saad",
                        "slug": "David-Saad",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Saad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Saad"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 125252825,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dddcd20d663ebbdd1ed53ac3cf65b9e49058c958",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Adaptive-TAP-Equations-Opper-Saad",
            "title": {
                "fragments": [],
                "text": "Adaptive TAP Equations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149111788"
                        ],
                        "name": "X. Jin",
                        "slug": "X.-Jin",
                        "structuredName": {
                            "firstName": "Xiaowei",
                            "lastName": "Jin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Jin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 140
                            }
                        ],
                        "text": "The formalism of factor graphs provides an alternative graphical representation, one which emphasizes the factorization of the distribution [140, 154]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 123845045,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8e617b8c63dd35d9913bbc104d0666ffd10e9e6a",
            "isKey": false,
            "numCitedBy": 2903,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Factor-graphs-and-the-Sum-Product-Algorithm-Jin",
            "title": {
                "fragments": [],
                "text": "Factor graphs and the Sum-Product Algorithm"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "81313996"
                        ],
                        "name": "G. Fournet",
                        "slug": "G.-Fournet",
                        "structuredName": {
                            "firstName": "G\u00e9rard",
                            "lastName": "Fournet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Fournet"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122677603,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "88810e8b1cdded09e32fd34bec6fdba1cd614966",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Theory-of-Cooperative-Phenomena-Fournet",
            "title": {
                "fragments": [],
                "text": "Theory of Cooperative Phenomena"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1952
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69474817"
                        ],
                        "name": "D. A. Kappos",
                        "slug": "D.-A.-Kappos",
                        "structuredName": {
                            "firstName": "Demetrios",
                            "lastName": "Kappos",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. A. Kappos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145737605"
                        ],
                        "name": "S. Karlin",
                        "slug": "S.-Karlin",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Karlin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Karlin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2636336"
                        ],
                        "name": "W. J. Studden",
                        "slug": "W.-J.-Studden",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Studden",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. J. Studden"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 80
                            }
                        ],
                        "text": "The study of moment matrices and their properties has an extremely rich history [3, 127], particularly in the context of scalar random variables."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 121243851,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "32d3b95733ea29c08ece3d81d0277e951987082d",
            "isKey": false,
            "numCitedBy": 1117,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Tchebycheff-Systems:-With-Applications-in-Analysis-Kappos-Karlin",
            "title": {
                "fragments": [],
                "text": "Tchebycheff Systems: With Applications in Analysis and Statistics."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1966
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49223598"
                        ],
                        "name": "J. Darroch",
                        "slug": "J.-Darroch",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Darroch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Darroch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "12360582"
                        ],
                        "name": "D. Ratcliff",
                        "slug": "D.-Ratcliff",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Ratcliff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ratcliff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "More generally, this iterative proportional fitting procedure is a special case of a broader class of iterative scaling, or successive projection algorithms; see papers [58, 56, 57] or the book [42] for further details on such algorithms and their properties."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "As an illustration, here we describe the iterative proportional fitting (IPF) algorithm [58, 57], a type of coordinate ascent method with particularly intuitive updates."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 120862597,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "37c931cbaa9217b829596dd196520a838562a109",
            "isKey": false,
            "numCitedBy": 1329,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Generalized-Iterative-Scaling-for-Log-Linear-Models-Darroch-Ratcliff",
            "title": {
                "fragments": [],
                "text": "Generalized Iterative Scaling for Log-Linear Models"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Here we collect some basic definitions and results on graphs and hypergraphs; see the standard books [15, 31, 32] for further background."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 202791797,
            "fieldsOfStudy": [],
            "id": "c435e8b419ac1ea502e82432e625682235f9a385",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The theory of graphs and its applications"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1962
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756798"
                        ],
                        "name": "I. Csisz\u00e1r",
                        "slug": "I.-Csisz\u00e1r",
                        "structuredName": {
                            "firstName": "Imre",
                            "lastName": "Csisz\u00e1r",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Csisz\u00e1r"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 119460543,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "2a64dbd2fa289013b56d04621c5be72f14a44cf7",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-geometric-interpretation-of-Darroch-and-iterative-Csisz\u00e1r",
            "title": {
                "fragments": [],
                "text": "A geometric interpretation of Darroch and Ratcliff's generalized iterative scaling"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786249"
                        ],
                        "name": "D. Bertsekas",
                        "slug": "D.-Bertsekas",
                        "structuredName": {
                            "firstName": "Dimitri",
                            "lastName": "Bertsekas",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bertsekas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800855"
                        ],
                        "name": "A. Nedi\u0107",
                        "slug": "A.-Nedi\u0107",
                        "structuredName": {
                            "firstName": "Angelia",
                            "lastName": "Nedi\u0107",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Nedi\u0107"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145744184"
                        ],
                        "name": "A. Ozdaglar",
                        "slug": "A.-Ozdaglar",
                        "structuredName": {
                            "firstName": "Asuman",
                            "lastName": "Ozdaglar",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ozdaglar"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Rockafellar [198] is a standard reference on convex analysis; see also the books by Hiriart-Urruty and Lemar\u00e9chal [109, 110], Boyd and Vandenberghe [36], and Bertsekas [21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 118270092,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d5d5e60d7f5a804f7b8cd6eb006b6d1d61f15d9d",
            "isKey": false,
            "numCitedBy": 1016,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Convex-Analysis-and-Optimization-Bertsekas-Nedi\u0107",
            "title": {
                "fragments": [],
                "text": "Convex Analysis and Optimization"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2508221"
                        ],
                        "name": "A. V. D. Vaart",
                        "slug": "A.-V.-D.-Vaart",
                        "structuredName": {
                            "firstName": "Aad",
                            "lastName": "Vaart",
                            "middleNames": [
                                "van",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. V. D. Vaart"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118838539,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "4519d38567e37ede04f7d3851cbce770bd4aed3b",
            "isKey": false,
            "numCitedBy": 715,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Asymptotic-Statistics:-U-Statistics-Vaart",
            "title": {
                "fragments": [],
                "text": "Asymptotic Statistics: U -Statistics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050895"
                        ],
                        "name": "S. Lauritzen",
                        "slug": "S.-Lauritzen",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Lauritzen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lauritzen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Contingency tables are a central tool in categorical data analysis [148, 77, 1], dating back to the seminal work of Pearson, Yule and Fisher."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 117974235,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "dca0e2c5c80033c3787d80f2946d79902d47d183",
            "isKey": false,
            "numCitedBy": 59,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Lectures-on-Contingency-Tables-Lauritzen",
            "title": {
                "fragments": [],
                "text": "Lectures on Contingency Tables"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145409928"
                        ],
                        "name": "J. Hammersley",
                        "slug": "J.-Hammersley",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Hammersley",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hammersley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145578421"
                        ],
                        "name": "P. Clifford",
                        "slug": "P.-Clifford",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Clifford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Clifford"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Moreover, by the Hammersley-Clifford theorem [103, 23, 99], the precision matrix P has the same sparsity pattern as the graph adjacency matrix (i."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 118635048,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ec75e3ca906681bd900218a348a4a35dfed3d6fd",
            "isKey": false,
            "numCitedBy": 946,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Markov-fields-on-finite-graphs-and-lattices-Hammersley-Clifford",
            "title": {
                "fragments": [],
                "text": "Markov fields on finite graphs and lattices"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398951619"
                        ],
                        "name": "O. Barndorff-Nielsen",
                        "slug": "O.-Barndorff-Nielsen",
                        "structuredName": {
                            "firstName": "Ole",
                            "lastName": "Barndorff-Nielsen",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Barndorff-Nielsen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 194
                            }
                        ],
                        "text": "In our view, the most promising avenue towards variational methodology tuned to statistics is to build on existing links between variational analysis and the exponential family of distributions [3, 5, 17, 35]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 93
                            }
                        ],
                        "text": "Further details on exponential families and their properties can be found in various sources [4, 5, 17, 35]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 116833160,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a51f480b9e3190c0e849a91d14a4527c72ecdc1b",
            "isKey": false,
            "numCitedBy": 313,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Information-And-Exponential-Families-Barndorff-Nielsen",
            "title": {
                "fragments": [],
                "text": "Information And Exponential Families"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49026551"
                        ],
                        "name": "D. Greig",
                        "slug": "D.-Greig",
                        "structuredName": {
                            "firstName": "Darryl",
                            "lastName": "Greig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Greig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "146294528"
                        ],
                        "name": "B. Porteous",
                        "slug": "B.-Porteous",
                        "structuredName": {
                            "firstName": "Baroness",
                            "lastName": "Porteous",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Porteous"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1887111"
                        ],
                        "name": "A. Seheult",
                        "slug": "A.-Seheult",
                        "structuredName": {
                            "firstName": "Allan",
                            "lastName": "Seheult",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Seheult"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Moreover, the Ising model and variations on it have been used in image processing and spatial statistics [25, 86, 98], where Xs might correspond to pixel values in a black-and-white image."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "It is easily solved by conversion to a maximum flow problem, using the classical Ford-Fulkerson duality theorem [20, 98]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 115691220,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a717b20e99b76cb228b47694140ed3dce082b530",
            "isKey": false,
            "numCitedBy": 1257,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Exact-Maximum-A-Posteriori-Estimation-for-Binary-Greig-Porteous",
            "title": {
                "fragments": [],
                "text": "Exact Maximum A Posteriori Estimation for Binary Images"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1902488"
                        ],
                        "name": "U. Bertel\u00e8",
                        "slug": "U.-Bertel\u00e8",
                        "structuredName": {
                            "firstName": "Umberto",
                            "lastName": "Bertel\u00e8",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Bertel\u00e8"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075112170"
                        ],
                        "name": "F. Brioschi",
                        "slug": "F.-Brioschi",
                        "structuredName": {
                            "firstName": "Francesco",
                            "lastName": "Brioschi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Brioschi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Sum-product algorithm: The sum-product algorithm is a form of non-serial dynamic programming [17], which generalizes the usual serial form of deterministic dynamic programming [18] to arbitrary tree-structured graphs."
                    },
                    "intents": []
                }
            ],
            "corpusId": 61409023,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "599fecdb5fec6bf5c99de76088a9a3c37af6f11e",
            "isKey": false,
            "numCitedBy": 450,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Nonserial-Dynamic-Programming-Bertel\u00e8-Brioschi",
            "title": {
                "fragments": [],
                "text": "Nonserial Dynamic Programming"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In this sense, it represents a generalization of the Viterbi algorithm [79] from chains to arbitrary tree-structured graphs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Similarly, the maximum a posteriori state sequence can also be computed by the junction tree algorithm (with summation replaced by maximization)\u2014 in the HMM context the resulting algorithm is generally referred to as the Viterbi algorithm [79]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62282319,
            "fieldsOfStudy": [],
            "id": "d87a423334afb20747c367b2d907069d7f3b4ed2",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The viterbi algorithm"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "87883481"
                        ],
                        "name": "D\u016brbin",
                        "slug": "D\u016brbin",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "D\u016brbin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D\u016brbin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Gene-finding provides an important example of the application of the HMM [69]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 215767402,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "3e260903650e0739b908f6e9dc403727adc67226",
            "isKey": false,
            "numCitedBy": 751,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Biological-Sequence-Analysis-D\u016brbin",
            "title": {
                "fragments": [],
                "text": "Biological Sequence Analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 240,
                                "start": 230
                            }
                        ],
                        "text": "Various forms of these reweighted maxproduct algorithms have been applied in problems such as segmentation and disparity problems in computer vision [165, 134, 136, 246, 222, 260], error-control coding [73], side-chain prediction [261, 246], sensor fusion [43, 46]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 25795547,
            "fieldsOfStudy": [],
            "id": "cd58eb9995ff7ff5bb5cbbdf95df52795976f583",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Minimizing and Learning Energy Functions for Side-Chain Prediction"
            },
            "venue": {
                "fragments": [],
                "text": "J. Comput. Biol."
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144362425"
                        ],
                        "name": "S. Amari",
                        "slug": "S.-Amari",
                        "structuredName": {
                            "firstName": "Shun\u2010ichi",
                            "lastName": "Amari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Amari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145930529"
                        ],
                        "name": "H. Nagaoka",
                        "slug": "H.-Nagaoka",
                        "structuredName": {
                            "firstName": "Hiroshi",
                            "lastName": "Nagaoka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Nagaoka"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In this section, we describe how many graphical models are naturally viewed as exponential families, a broad class of distributions that have been extensively studied in the statistics literature [5, 10, 40, 71]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 116976027,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "617111ed3746c4304c87b188ba155b160e9f082e",
            "isKey": false,
            "numCitedBy": 2370,
            "numCiting": 201,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Methods-of-information-geometry-Amari-Nagaoka",
            "title": {
                "fragments": [],
                "text": "Methods of information geometry"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49165342"
                        ],
                        "name": "Zhe Jiang",
                        "slug": "Zhe-Jiang",
                        "structuredName": {
                            "firstName": "Zhe",
                            "lastName": "Jiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhe Jiang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 69
                            }
                        ],
                        "text": ", 258, 104, 55, 86], as well as in spatial statistics more generally [23, 24, 197, 25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5076462,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "eb7a0617fa8b88dd4680b3f690220a93f0c56d1e",
            "isKey": false,
            "numCitedBy": 787,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Spatial-Statistics-Jiang",
            "title": {
                "fragments": [],
                "text": "Spatial Statistics"
            },
            "venue": {
                "fragments": [],
                "text": "Encyclopedia of Database Systems"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3072213"
                        ],
                        "name": "J. Besag",
                        "slug": "J.-Besag",
                        "structuredName": {
                            "firstName": "Julian",
                            "lastName": "Besag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Besag"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Moreover, by the Hammersley-Clifford theorem [103, 23, 99], the precision matrix P has the same sparsity pattern as the graph adjacency matrix (i."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": ", 258, 104, 55, 86], as well as in spatial statistics more generally [23, 24, 197, 25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 42087677,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "8bf730243ed967afd5349bef053641a6043517a0",
            "isKey": false,
            "numCitedBy": 6165,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Spatial-Interaction-and-the-Statistical-Analysis-of-Besag",
            "title": {
                "fragments": [],
                "text": "Spatial Interaction and the Statistical Analysis of Lattice Systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66418228"
                        ],
                        "name": "\u4e38\u5c71 \u5fb9",
                        "slug": "\u4e38\u5c71-\u5fb9",
                        "structuredName": {
                            "firstName": "\u4e38\u5c71",
                            "lastName": "\u5fb9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u4e38\u5c71 \u5fb9"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 66
                            }
                        ],
                        "text": "For further background on convex analysis, we refer the reader to [14, 53, 92]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 117573922,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b272701e77ddb860741a193ac1701ca382853680",
            "isKey": false,
            "numCitedBy": 7928,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Convex-Analysis\u306e\u4e8c,\u4e09\u306e\u9032\u5c55\u306b\u3064\u3044\u3066-\u4e38\u5c71",
            "title": {
                "fragments": [],
                "text": "Convex Analysis\u306e\u4e8c,\u4e09\u306e\u9032\u5c55\u306b\u3064\u3044\u3066"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 131
                            }
                        ],
                        "text": "[202] discuss some connections between the ordinary max-product algorithm and this LP relaxation, as well as to auction algorithms [20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 112
                            }
                        ],
                        "text": "It is easily solved by conversion to a maximum flow problem, using the classical Ford-Fulkerson duality theorem [20, 98]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Network Optimization: Continuous and Discrete Methods"
            },
            "venue": {
                "fragments": [],
                "text": "Athena Scientific, Belmont, MA,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 246,
                                "start": 237
                            }
                        ],
                        "text": "Although the EM algorithm is often presented as an alternation between an expectation step (E step) and a maximization step (M step), it is also possible to take a variational perspective on EM, and view both steps as maximization steps [56, 176]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 169
                            }
                        ],
                        "text": "More generally, this iterative proportional fitting procedure is a special case of a broader class of iterative scaling, or successive projection algorithms; see papers [58, 56, 57] or the book [42] for further details on such algorithms and their properties."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Information geometry and alternating minimization procedures"
            },
            "venue": {
                "fragments": [],
                "text": "Statistics and Decisions, Supplemental Issue 1, pages 205\u2013 237,"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 195
                            }
                        ],
                        "text": "There also turn out to be a number of interesting connections between TRW max-product and a line of research, due to Schlesinger and collaborators, previously published in the Russian literature [205, 137]; Werner [251] provides a detailed overview of this line of work, and some connections to reweighted max-product and LP relaxation."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Two-dimensional programming in image analysis problems"
            },
            "venue": {
                "fragments": [],
                "text": "USSR Academy of Science, Automatics and Telemechanics, 8:149\u2013168,"
            },
            "year": 1976
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Markov random eld texture models"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans PAMI, 5:25{39,"
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "However, the SDP-based formulation (C.6) provides"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 24
                            }
                        ],
                        "text": "A parallel line of work [265, 249, 108] has explored alternatives to sum-product that are guaranteed to converge, albeit at the price of increased computational cost."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 67
                            }
                        ],
                        "text": "Another possibility would be to adapt other double-loop algorithms [265, 249, 108, 107], originally developed for the ordinary Bethe/Kikuchi problems, to solve these convex minimization problems; see Hazan and Shashua [105] for some recent work along these lines."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 108
                            }
                        ],
                        "text": "63), possibly along the lines of convergent algorithms developed for the ordinary Bethe variational problem [265, 249, 108]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Belief optimization: A stable alternative to loopy belief propagation"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Conference on Uncertainty in Artificial Intelligence, pages 554\u2013561. Morgan Kaufmann,"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Semide nite relaxation and non-convex quadratic optimization"
            },
            "venue": {
                "fragments": [],
                "text": "Optimization Methods and Software, 12:1{20,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Biological sequence analysis: Contents"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 61
                            }
                        ],
                        "text": "Moreover, by standard results on asymptotics of M-estimators [228], the MLE \u03b8\u0302 is consistent, in that it converges in probability to \u03b8 as the sample size n tends to infinity."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Asymptotic statistics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On the e ective weights of pseudocodewords for codes de ned on graphs with cycles. In Codes, systems and graphical models, pages 101{112"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 43
                            }
                        ],
                        "text": "to maximum likelihood parameter estimation [31]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood from incomplete data via the EM algorithm (with discussion)"
            },
            "venue": {
                "fragments": [],
                "text": "J. Royal Stat. Soc. B, 39:1{38,"
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Tree consistency and bounds on the max - product algorithm and its generalizations"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Ninth International Conference on Artificial Intelligence and Statistics"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 195
                            }
                        ],
                        "text": "There also turn out to be a number of interesting connections between TRW max-product and a line of research, due to Schlesinger and collaborators, previously published in the Russian literature [205, 137]; Werner [251] provides a detailed overview of this line of work, and some connections to reweighted max-product and LP relaxation."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Syntactic analysis of two-dimensional visual signals in noisy conditions"
            },
            "venue": {
                "fragments": [],
                "text": "Kibernetika, 4:113\u2013130,"
            },
            "year": 1976
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 124
                            }
                        ],
                        "text": "Here the state variables are the parts of speech, and the transition matrix is estimated from a corpus via the EM algorithm [73]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Sch\u007f  utze. Foundations of Statistical Natural Language Processing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 41
                            }
                        ],
                        "text": "The Ising model from statistical physics [11, 116] is a classical example of a graphical model in exponential form."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Beitrag zur theorie der ferromagnetismus"
            },
            "venue": {
                "fragments": [],
                "text": "Zeitschrift f\u00fcr Physik, 31:253\u2013258,"
            },
            "year": 1925
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Convergence condition of the TAP equation for the infinite-ranged Ising model"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Physics A"
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 98
                            }
                        ],
                        "text": "There is a rich literature in combinatorics on the structure of these codeword or cycle polytopes [8, 210, 100, 66]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Matroids and multi-commodity flows"
            },
            "venue": {
                "fragments": [],
                "text": "European J. Combin., 2:257\u2013290,"
            },
            "year": 1981
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 133
                            }
                        ],
                        "text": "Figure 2(a) shows a hidden Markov phylogeny, an HMM in which the observations are sets of nucleotides related by a phylogenetic tree [74, 86, 99]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Gene nding with a hidden Markov model of genome structure and evolution"
            },
            "venue": {
                "fragments": [],
                "text": "Bioinformatics, 19:219{227,"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Guessing facets: Improved LP decoding and polytope structure"
            },
            "venue": {
                "fragments": [],
                "text": "International Symposium on Information Theory"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 302,
                                "start": 298
                            }
                        ],
                        "text": "A line of recent research has established close links between the LP relaxation and the ordinary max-product algorithm, including the case of bipartite weighted matching [13], bipartite weighted b-matching [113], weighted matching on general graphs [201], and weighted b-matching on general graphs [12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Belief-propagation for weighted b-matchings on arbitrary graphs and its relation to linear programs 279  280 References with integer solutions"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Report arxiv:0709.1190, Microsoft Research, September"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 56
                            }
                        ],
                        "text": "Finally, we describe expectation-propagation algorithms [180, 172] and related moment-matching methods [181, 61, 112]; these are also varia-"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 45
                            }
                        ],
                        "text": "the adaptive TAP method of Opper and Winther [179, 180]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Tractable approximations for probabilistic models: The adaptive Thouless-Anderson-Palmer approach"
            },
            "venue": {
                "fragments": [],
                "text": "Physical Review Letters, 64:3695,"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 166
                            }
                        ],
                        "text": "The correctness of Gaussian max-product for mean computation also follows as a consequence of the reparameterization properties of the sum- and maxproduct algorithms [237, 239]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 122
                            }
                        ],
                        "text": "Given these max-marginals, it is straightforward to compute a mode x\u0302 \u2208 arg maxx p(x) of the distribution; see the papers [62, 239] for further details."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Tree consistency and bounds on the max-product algorithm and its generalizations"
            },
            "venue": {
                "fragments": [],
                "text": "Statistics and Computing, 14:143\u2013166,"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 237
                            }
                        ],
                        "text": "Although the EM algorithm is often presented as an alternation between an expectation step (E step) and a maximization step (M step), it is also possible to take a variational perspective on EM, and view both steps as maximization steps [25, 78]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Tusn  ady. Information geometry and alternating minimization procedures"
            },
            "venue": {
                "fragments": [],
                "text": "Recent results in estimation theory and related topics"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "E\u00c6cient learning in Boltzmann machines using linear response theory"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation, 10:1137{1156,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Appoximate graph coloring by semide nite programming"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Symposium Foundations of Computer Science,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Exact MAP estimates via agreement on ( hyper ) trees : Linear programming and message - passing"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Information Theory"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 201
                            }
                        ],
                        "text": "17) have studied in past and ongoing work by various authors, including the special cases of {0, 1}-quadratic programs [102], metric labeling with Potts models [132, 45], error-control coding problems [73, 75, 234, 223, 47, 59], independent set problems [177, 202], and various types of matching problems [13, 113, 201]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Loop calculus helps to improve belief propagation and linear programming decoding of LDPC codes"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Allerton Conference on Control, Communication and Computing, Monticello, IL, September"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 81
                            }
                        ],
                        "text": "The survey propagation algorithm, developed in the statistical physics community [168, 167], turns out to be very successful in solving random instances of 3-SAT."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Random K-satisfiability: From an analytic solution to an efficient algorithm"
            },
            "venue": {
                "fragments": [],
                "text": "Physical Review E, 66:056126,"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 98
                            }
                        ],
                        "text": "Studying the SDP relaxation (157) in application to the MAX-CUT problem,16 Goemans and Williamson [48] provided a random sampling scheme for generating solutions, and proved a strong guarantee on its expected performance."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Improved approximation algorithms for maximum cut and satis ability problems using semide nite programming"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the ACM, 42:1115{1145,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 60
                            }
                        ],
                        "text": "The resulting optimization problem is a semide nite program [104], since it entails optimizing a linear function subject to linear matrix inequalities."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 21
                            }
                        ],
                        "text": "Semide nite programs [104] entail maximizing a linear function subject to linear matrix inequalities (see Section 9)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Semide nite programming"
            },
            "venue": {
                "fragments": [],
                "text": "SIAM Review, 38:49{95,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 55
                            }
                        ],
                        "text": "We begin with the Ising model from statistical physics [6, 20, 83], which is a particular kind of Markov random eld."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical eld theory"
            },
            "venue": {
                "fragments": [],
                "text": "Addison-Wesley,"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Convergence condition of the TAP equation for the in nite-ranged Ising model"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Physics A, 15(6):1971{1978,"
            },
            "year": 1982
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 157,
            "methodology": 115,
            "result": 6
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 307,
        "totalPages": 31
    },
    "page_url": "https://www.semanticscholar.org/paper/Graphical-Models,-Exponential-Families,-and-Wainwright-Jordan/d98d0d1900b13b87aa4ffd6b69c046beb63f0434?sort=total-citations"
}