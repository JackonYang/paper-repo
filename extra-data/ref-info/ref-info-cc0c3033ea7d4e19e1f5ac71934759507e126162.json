{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680292"
                        ],
                        "name": "P. Resnik",
                        "slug": "P.-Resnik",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Resnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Resnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1752785,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "265be00bf112c6cb2fa3e8176bff8394a114dbde",
            "isKey": false,
            "numCitedBy": 3890,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new measure of semantic similarity in an IS-A taxonomy, based on the notion of information content. Experimental evaluation suggests that the measure performs encouragingly well (a correlation of r = 0.79 with a benchmark set of human similarity judgments, with an upper bound of r = 0.90 for human subjects performing the same task), and significantly better than the traditional edge counting approach (r = 0.66)."
            },
            "slug": "Using-Information-Content-to-Evaluate-Semantic-in-a-Resnik",
            "title": {
                "fragments": [],
                "text": "Using Information Content to Evaluate Semantic Similarity in a Taxonomy"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This paper presents a new measure of semantic similarity in an IS-A taxonomy, based on the notion of information content, which performs encouragingly well and is significantly better than the traditional edge counting approach."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116657970"
                        ],
                        "name": "J. Lee",
                        "slug": "J.-Lee",
                        "structuredName": {
                            "firstName": "Joon",
                            "lastName": "Lee",
                            "middleNames": [
                                "Ho"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714259"
                        ],
                        "name": "Myoung-Ho Kim",
                        "slug": "Myoung-Ho-Kim",
                        "structuredName": {
                            "firstName": "Myoung-Ho",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Myoung-Ho Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110392249"
                        ],
                        "name": "Yoon-Joon Lee",
                        "slug": "Yoon-Joon-Lee",
                        "structuredName": {
                            "firstName": "Yoon-Joon",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoon-Joon Lee"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 226,
                                "start": 210
                            }
                        ],
                        "text": "\u2026such as information content [Resnik, 1995b], mutual information [Hindle, 1990], Dice coefficient [Frakes and Baeza-Yates, 1992], cosine coefficient [Frakes and Baeza-Yates, 1992], distance-based measurements [Lee et al., 1989; Rada et al., 1989], and feature contrast model [Tversky, 1977]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 290,
                                "start": 253
                            }
                        ],
                        "text": "Many similarity measures have been proposed, such as information content[Resnik, 1995b ], mutual information [Hindle, 1990], Dice coefficient[Frakes and Baeza-Yates, 1992], cosine coefficient [Frakes and Baeza-Yates, 1992 ], distance-based measurements [Lee et al., 1989; Rada et al., 1989], and feature contrast model [Tversky, 1977]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 121
                            }
                        ],
                        "text": "There have been many proposals to use the distance between two concepts in a taxonomy as the basis for their similarity [Lee et al., 1989; Rada et al., 1989]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 67
                            }
                        ],
                        "text": "For example, distance-based measures of concept similarity (e.g., [Lee et al., 1989; Rada et al., 1989]) assume that the domain is represented in a network."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 20403380,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "604ea32f139a36631d8cc9f79e678baa4b38db08",
            "isKey": true,
            "numCitedBy": 337,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "There have been several document ranking methods to calculate the conceptual distance or closeness between a Boolean query and a document. Though they provide good retrieval effectiveness in many cases, they do not support effective weighting schemes for queries and documents and also have several problems resulting from inappropriate evaluation of Boolean operators. We propose a new method called Knowledge\u2010Based Extended Boolean Model (kb\u2010ebm) in which Salton's extended Boolean model is incorporated. kb\u2010ebm evaluates weighted queries and documents effectively, and avoids the problems of the previous methods. kb\u2010ebm provides high quality document rankings by using term dependence information from is\u2010a hierarchies The performance experiments show that the proposed method closely simulates human behaviour."
            },
            "slug": "Information-Retrieval-Based-on-Conceptual-Distance-Lee-Kim",
            "title": {
                "fragments": [],
                "text": "Information Retrieval Based on Conceptual Distance in is-a Hierarchies"
            },
            "venue": {
                "fragments": [],
                "text": "J. Documentation"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144096985"
                        ],
                        "name": "G. Miller",
                        "slug": "G.-Miller",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Miller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34729490"
                        ],
                        "name": "W. Charles",
                        "slug": "W.-Charles",
                        "structuredName": {
                            "firstName": "Walter",
                            "lastName": "Charles",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Charles"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 145580646,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "402627e4eb8c95e4aae3026fd921aa08cd792006",
            "isKey": false,
            "numCitedBy": 1678,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract The relationship between semantic and contextual similarity is investigated for pairs of nouns that vary from high to low semantic similarity. Semantic similarity is estimated by subjective ratings; contextual similarity is estimated by the method of sorting sentential contexts. The results show an inverse linear relationship between similarity of meaning and the discriminability of contexts. This relation, is obtained for two separate corpora of sentence contexts. It is concluded that, on average, for words in the same language drawn from the same syntactic and semantic categories, the more often two words can be substituted into the same contexts the more similar in meaning they are judged to be."
            },
            "slug": "Contextual-correlates-of-semantic-similarity-Miller-Charles",
            "title": {
                "fragments": [],
                "text": "Contextual correlates of semantic similarity"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064181"
                        ],
                        "name": "A. Tversky",
                        "slug": "A.-Tversky",
                        "structuredName": {
                            "firstName": "Amos",
                            "lastName": "Tversky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Tversky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 88
                            }
                        ],
                        "text": "We demonstrate how our definition can be used to measure the similarity in a number of different domains."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9173202,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f718309706172d6fb1e89f583927274f9a4cdf4f",
            "isKey": false,
            "numCitedBy": 7350,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "The metric and dimensional assumptions that underlie the geometric representation of similarity are questioned on both theoretical and empirical grounds. A new set-theoretical approach to similarity is developed in which objects are represented as collections of features, and similarity is described as a feature-matching process. Specifically, a set of qualitative assumptions is shown to imply the contrast model, which expresses the similarity between objects as a linear combination of the measures of their common and distinctive features. Several predictions of the contrast model are tested in studies of similarity with both semantic and perceptual stimuli. The model is used to uncover, analyze, and explain a variety of empirical phenomena such as the role of common and distinctive features, the relations between judgments of similarity and difference, the presence of asymmetric similarities, and the effects of context on judgments of similarity. The contrast model generalizes standard representations of similarity data in terms of clusters and trees. It is also used to analyze the relations of prototypicality and family resemblance"
            },
            "slug": "Features-of-Similarity-Tversky",
            "title": {
                "fragments": [],
                "text": "Features of Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The metric and dimensional assumptions that underlie the geometric representation of similarity are questioned on both theoretical and empirical grounds and a set of qualitative assumptions are shown to imply the contrast model, which expresses the similarity between objects as a linear combination of the measures of their common and distinctive features."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1766712"
                        ],
                        "name": "R. Rada",
                        "slug": "R.-Rada",
                        "structuredName": {
                            "firstName": "Roy",
                            "lastName": "Rada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rada"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116204"
                        ],
                        "name": "H. Mili",
                        "slug": "H.-Mili",
                        "structuredName": {
                            "firstName": "Hafedh",
                            "lastName": "Mili",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Mili"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144494841"
                        ],
                        "name": "E. Bicknell",
                        "slug": "E.-Bicknell",
                        "structuredName": {
                            "firstName": "Ellen",
                            "lastName": "Bicknell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Bicknell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7519237"
                        ],
                        "name": "M. Blettner",
                        "slug": "M.-Blettner",
                        "structuredName": {
                            "firstName": "Maria",
                            "lastName": "Blettner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Blettner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 228
                            }
                        ],
                        "text": "\u2026such as information content [Resnik, 1995b], mutual information [Hindle, 1990], Dice coefficient [Frakes and Baeza-Yates, 1992], cosine coefficient [Frakes and Baeza-Yates, 1992], distance-based measurements [Lee et al., 1989; Rada et al., 1989], and feature contrast model [Tversky, 1977]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 290,
                                "start": 253
                            }
                        ],
                        "text": "Many similarity measures have been proposed, such as information content[Resnik, 1995b ], mutual information [Hindle, 1990], Dice coefficient[Frakes and Baeza-Yates, 1992], cosine coefficient [Frakes and Baeza-Yates, 1992 ], distance-based measurements [Lee et al., 1989; Rada et al., 1989], and feature contrast model [Tversky, 1977]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 139
                            }
                        ],
                        "text": "There have been many proposals to use the distance between two concepts in a taxonomy as the basis for their similarity [Lee et al., 1989; Rada et al., 1989]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 85
                            }
                        ],
                        "text": "For example, distance-based measures of concept similarity (e.g., [Lee et al., 1989; Rada et al., 1989]) assume that the domain is represented in a network."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18702948,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e41fe310351f5d2f6ff2f930f9c062ba43cbe0f",
            "isKey": true,
            "numCitedBy": 2033,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "Motivated by the properties of spreading activation and conceptual distance, the authors propose a metric, called distance, on the power set of nodes in a semantic net. Distance is the average minimum path length over all pairwise combinations of nodes between two subsets of nodes. Distance can be successfully used to assess the conceptual distance between sets of concepts when used on a semantic net of hierarchical relations. When other kinds of relationships, like 'cause', are used, distance must be amended but then can again be effective. The judgements of distance significantly correlate with the distance judgements that people make and help to determine whether one semantic net is better or worse than another. The authors focus on the mathematical characteristics of distance that presents novel cases and interpretations. Experiments in which distance is applied to pairs of concepts and to sets of concepts in a hierarchical knowledge base show the power of hierarchical relations in representing information about the conceptual distance between concepts. >"
            },
            "slug": "Development-and-application-of-a-metric-on-semantic-Rada-Mili",
            "title": {
                "fragments": [],
                "text": "Development and application of a metric on semantic nets"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Experiments in which distance is applied to pairs of concepts and to sets of concepts in a hierarchical knowledge base show the power of hierarchical relations in representing information about the conceptual distance between concepts."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Syst. Man Cybern."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "119515866"
                        ],
                        "name": "G. Ruge",
                        "slug": "G.-Ruge",
                        "structuredName": {
                            "firstName": "Gerd",
                            "lastName": "Ruge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Ruge"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Suppose two objects can be described with two numerical vectors and\nAnother class of similarity measures is based a distance metric."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5517932,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4966f2d75734b4abd4ad105b85eff675cb781b5d",
            "isKey": false,
            "numCitedBy": 177,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Experiments-on-Linguistically-Based-Term-Ruge",
            "title": {
                "fragments": [],
                "text": "Experiments on Linguistically-Based Term Associations"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Process. Manag."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21169546"
                        ],
                        "name": "Donald Hindle",
                        "slug": "Donald-Hindle",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Hindle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Donald Hindle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15862538,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "f3f3dcfcaa960ec201e0381f4d026e57e64bea76",
            "isKey": false,
            "numCitedBy": 689,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "A method of determining the similarity of nouns on the basis of a metric derived from the distribution of subject, verb and object in a large text corpus is described. The resulting quasi-semantic classification of nouns demonstrates the plausibility of the distributional hypothesis, and has potential application to a variety of tasks, including automatic indexing, resolving nominal compounds, and determining the scope of modification."
            },
            "slug": "Noun-Classification-from-Predicate-Argument-Hindle",
            "title": {
                "fragments": [],
                "text": "Noun Classification from Predicate-Argument Structures"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The resulting quasi-semantic classification of nouns demonstrates the plausibility of the distributional hypothesis, and has potential application to a variety of tasks, including automatic indexing, resolving nominal compounds, and determining the scope of modification."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3163834"
                        ],
                        "name": "W. Frakes",
                        "slug": "W.-Frakes",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Frakes",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Frakes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1389957009"
                        ],
                        "name": "R. Baeza-Yates",
                        "slug": "R.-Baeza-Yates",
                        "structuredName": {
                            "firstName": "Ricardo",
                            "lastName": "Baeza-Yates",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Baeza-Yates"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62157473,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3f133e39f3fb543f25a1a75400b81c0d42c6a91c",
            "isKey": false,
            "numCitedBy": 1720,
            "numCiting": 211,
            "paperAbstract": {
                "fragments": [],
                "text": "An edited volume containing data structures and algorithms for information retrieved including a disk with examples written in C. For programmers and students interested in parsing text, automated indexing, its the first collection in book form of the basic data structures and algorithms that are critical to the storage and retrieval of documents."
            },
            "slug": "Information-Retrieval:-Data-Structures-and-Frakes-Baeza-Yates",
            "title": {
                "fragments": [],
                "text": "Information Retrieval: Data Structures and Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "For programmers and students interested in parsing text, automated indexing, its the first collection in book form of the basic data structures and algorithms that are critical to the storage and retrieval of documents."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788050"
                        ],
                        "name": "R. Grishman",
                        "slug": "R.-Grishman",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Grishman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Grishman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144360624"
                        ],
                        "name": "J. Sterling",
                        "slug": "J.-Sterling",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Sterling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sterling"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10774324,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4d50134461d7e48714ef822f2b70e215f0487ef3",
            "isKey": false,
            "numCitedBy": 91,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Frequency information on co-occurrence patterns can be automatically collected from a syntactically analyzed corpus; this information can then serve as the basis for selectional constraints when analyzing new text from the same domain. This information, however, is necessarily incomplete. We report on measurements of the degree of selectional coverage obtained with different sizes of corpora. We then describe a technique for using the corpus to identify selectionally similar terms, and for using this similarity to broaden the selectional coverage for a fixed corpus size."
            },
            "slug": "Generalizing-Automatically-Generated-Selectional-Grishman-Sterling",
            "title": {
                "fragments": [],
                "text": "Generalizing Automatically Generated Selectional Patterns"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Measurements of the degree of selectional coverage obtained with different sizes of corpora are reported on and a technique for using the corpus to identify selectionally similar terms and for using this similarity to broaden the selectional Coverage for a fixed corpus size is described."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736882"
                        ],
                        "name": "F. Bacchus",
                        "slug": "F.-Bacchus",
                        "structuredName": {
                            "firstName": "Fahiem",
                            "lastName": "Bacchus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Bacchus"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122204141,
            "fieldsOfStudy": [
                "Philosophy",
                "Computer Science"
            ],
            "id": "a4b53dee0e2cfb00d3e2c13a84714c8fd5b8a0d0",
            "isKey": false,
            "numCitedBy": 264,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "This thesis presents a logical formalism for representing and reasoning with probabilistic knowledge. The formalism differs from previous efforts in this area in a number of ways. Most previous work has investigated ways of assigning probabilities to the sentences of a logical language. Such an assignment fails to capture an important class of probabilistic assertions, empirical generalizations. Such generalizations are particularly important for AI, since they can be accumulated through experience with the world. Thus, they offer the possibility of reasoning in very general domains, domains where no experts are available to gather subjective probabilities from. \nA logic is developed which can represent these empirical generalizations. Reasoning can be performed through a proof theory which is shown to be sound and complete. Furthermore, the logic can represent and reason with a very general set of assertions, including many non-numeric assertions. This also is important for AI as numbers are usually not available. \nThe logic makes it clear that there is an essential difference between empirical, or statistical, probabilities and probabilities assigned to sentences, e.g., subjective probabilities. The second part of the formalism is an inductive mechanism for assigning degrees of belief to sentences based on the empirical generalizations expressed in the logic. these degrees of belief have a strong advantage over subjective probabilities: they are founded on objective statistical knowledge about the world. Furthermore, the mechanism of assigning degrees of belief gives a natural answer to the question \"Where do the probabilities come from:\" they come from our experience with the world. \nThe two parts of the formalism offer combined, interacting, but still clearly separated, plausible inductive inference and sound deductive inference."
            },
            "slug": "Representing-and-reasoning-with-probabilistic-Bacchus",
            "title": {
                "fragments": [],
                "text": "Representing and reasoning with probabilistic knowledge"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "This thesis presents a logical formalism for representing and reasoning with probabilistic knowledge which offers combined, interacting, but still clearly separated, plausible inductive inference and sound deductive inference."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690956"
                        ],
                        "name": "Dekang Lin",
                        "slug": "Dekang-Lin",
                        "structuredName": {
                            "firstName": "Dekang",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dekang Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 120
                            }
                        ],
                        "text": "Suppose two objects can be described with two numerical vectors and\nAnother class of similarity measures is based a distance metric."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6106375,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b8e5d7da8441f0d44dac7ac3b87050d653bfa1a",
            "isKey": false,
            "numCitedBy": 155,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an efficient, broad-coverage, principle-based parser for English. The parser has been implemented in C++ and runs on SUN Sparcstations with X-windows. It contains a lexicon with over 90,000 entries, constructed automatically by applying a set of extraction and conversion rules to entries from machine readable dictionaries."
            },
            "slug": "PRINCIPAR-An-Efficient,-Broad-coverage,-Parser-Lin",
            "title": {
                "fragments": [],
                "text": "PRINCIPAR - An Efficient, Broad-coverage, Principle-based Parser"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "An efficient, broad-coverage, principle-based parser for English that contains a lexicon with over 90,000 entries, constructed automatically by applying a set of extraction and conversion rules to entries from machine readable dictionaries."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777660"
                        ],
                        "name": "Naftali Tishby",
                        "slug": "Naftali-Tishby",
                        "structuredName": {
                            "firstName": "Naftali",
                            "lastName": "Tishby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naftali Tishby"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145810617"
                        ],
                        "name": "Lillian Lee",
                        "slug": "Lillian-Lee",
                        "structuredName": {
                            "firstName": "Lillian",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lillian Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6713452,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5eb328cf7e94995199e4c82a1f4d0696430a80b5",
            "isKey": false,
            "numCitedBy": 1193,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe and evaluate experimentally a method for clustering words according to their distribution in particular syntactic contexts. Words are represented by the relative frequency distributions of contexts in which they appear, and relative entropy between those distributions is used as the similarity measure for clustering. Clusters are represented by average context distributions derived from the given words according to their probabilities of cluster membership. In many cases, the clusters can be thought of as encoding coarse sense distinctions. Deterministic annealing is used to find lowest distortion sets of clusters: as the annealing parameter increases, existing clusters become unstable and subdivide, yielding a hierarchical \"soft\" clustering of the data. Clusters are used as the basis for class models of word coocurrence, and the models evaluated with respect to held-out test data."
            },
            "slug": "Distributional-Clustering-of-English-Words-Pereira-Tishby",
            "title": {
                "fragments": [],
                "text": "Distributional Clustering of English Words"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Deterministic annealing is used to find lowest distortion sets of clusters: as the annealed parameter increases, existing clusters become unstable and subdivide, yielding a hierarchical \"soft\" clustering of the data."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767307"
                        ],
                        "name": "H. Alshawi",
                        "slug": "H.-Alshawi",
                        "structuredName": {
                            "firstName": "Hiyan",
                            "lastName": "Alshawi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Alshawi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35408831"
                        ],
                        "name": "D. Carter",
                        "slug": "D.-Carter",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Carter",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Carter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1714108,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3376bc52798561e74f82ae92d2ea55bdf8b2bcce",
            "isKey": false,
            "numCitedBy": 90,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an automatic method for weighting the contributions of preference functions used in disambiguation. Initial scaling factors are derived as the solution to a least squares minimization problem, and improvements are then made by hill climbing. The method is applied to disambiguating sentences in the Air Travel Information System corpus, and the performance of the resulting scaling factors is compared with hand-tuned factors. We then focus on one class of preference function, those based on semantic lexical collocations. Experimental results are presented showing that such functions vary considerably in selecting correct analyses. In particular, we define a function that performs significantly better than ones based on mutual information and likelihood ratios of lexical associations."
            },
            "slug": "Training-and-Scaling-Preference-Functions-for-Alshawi-Carter",
            "title": {
                "fragments": [],
                "text": "Training and Scaling Preference Functions for Disambiguation"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "An automatic method for weighting the contributions of preference functions used in disambiguation is presented, and a function that performs significantly better than ones based on mutual information and likelihood ratios of lexical associations is defined."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680292"
                        ],
                        "name": "P. Resnik",
                        "slug": "P.-Resnik",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Resnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Resnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 410080,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2eae0f08186952643c3a7ead2eba2d41fda58cec",
            "isKey": false,
            "numCitedBy": 314,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Word groupings useful for language processing tasks are increasingly available, as thesauri appear on-line, and as distributional word clustering techniques improve. However, for many tasks, one is interested in relationships among word senses, not words. This paper presents a method for automatic sense disambiguation of nouns appearing within sets of related nouns \u2014 the kind of data one finds in on-line thesauri, or as the output of distributional clustering algorithms. Disambiguation is performed with respect to WordNet senses, which are fairly fine-grained; however, the method also permits the assignment of higher-level WordNet categories rather than sense labels. The method is illustrated primarily by example, though results of a more rigorous evaluation are also presented."
            },
            "slug": "Disambiguating-Noun-Groupings-with-Respect-to-Resnik",
            "title": {
                "fragments": [],
                "text": "Disambiguating Noun Groupings with Respect to Wordnet Senses"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A method for automatic sense disambiguation of nouns appearing within sets of related nouns \u2014 the kind of data one finds in on-line thesauri, or as the output of distributional clustering algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "VLC@ACL"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2146254443"
                        ],
                        "name": "Zhibiao Wu",
                        "slug": "Zhibiao-Wu",
                        "structuredName": {
                            "firstName": "Zhibiao",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhibiao Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145755155"
                        ],
                        "name": "Martha Palmer",
                        "slug": "Martha-Palmer",
                        "structuredName": {
                            "firstName": "Martha",
                            "lastName": "Palmer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martha Palmer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12009057,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "0e3e3c3d8ae5cb7c4636870d69967c197484d3bb",
            "isKey": false,
            "numCitedBy": 3703,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper will focus on the semantic representation of verbs in computer systems and its impact on lexical selection problems in machine translation (MT). Two groups of English and Chinese verbs are examined to show that lexical selection must be based on interpretation of the sentences as well as selection restrictions placed on the verb arguments. A novel representation scheme is suggested, and is compared to representations with selection restrictions used in transfer-based MT. We see our approach as closely aligned with knowledge-based MT approaches (KBMT), and as a separate component that could be incorporated into existing systems. Examples and experimental results will show that, using this scheme, inexact matches can achieve correct lexical selection."
            },
            "slug": "Verb-Semantics-and-Lexical-Selection-Wu-Palmer",
            "title": {
                "fragments": [],
                "text": "Verb Semantics and Lexical Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This paper will focus on the semantic representation of verbs in computer systems and its impact on lexical selection problems in machine translation (MT), and sees the approach as closely aligned with knowledge-based MT approaches (KBMT), and as a separate component that could be incorporated into existing systems."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690956"
                        ],
                        "name": "Dekang Lin",
                        "slug": "Dekang-Lin",
                        "structuredName": {
                            "firstName": "Dekang",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dekang Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 154
                            }
                        ],
                        "text": "We parsed a 22-million-word corpus consisting of Wall Street Journal and San Jose Mercury with a principle-based broad-coverage parser, called PRINCIPAR [Lin, 1993; Lin, 1994]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9541345,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d431d03433275a68bd4ccd6b97af665bb979294d",
            "isKey": false,
            "numCitedBy": 202,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Overgeneration is the main source of computational complexity in previous principle-based parsers. This paper presents a message passing algorithm for principle-based parsing that avoids the overgeneration problem. This algorithm has been implemented in C++ and successfully tested with example sentences from (van Riemsdijk and Williams, 1986)."
            },
            "slug": "Principle-Based-Parsing-without-Overgeneration-Lin",
            "title": {
                "fragments": [],
                "text": "Principle-Based Parsing without Overgeneration"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A message passing algorithm for principle-based parsing that avoids the overgeneration problem is presented and has been implemented in C++ and successfully tested with example sentences from (van Riemsdijk and Williams, 1986)."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144096985"
                        ],
                        "name": "G. Miller",
                        "slug": "G.-Miller",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Miller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66511259"
                        ],
                        "name": "R. Beckwith",
                        "slug": "R.-Beckwith",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Beckwith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Beckwith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721801"
                        ],
                        "name": "C. Fellbaum",
                        "slug": "C.-Fellbaum",
                        "structuredName": {
                            "firstName": "Christiane",
                            "lastName": "Fellbaum",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fellbaum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145386345"
                        ],
                        "name": "Derek Gross",
                        "slug": "Derek-Gross",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Gross",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Gross"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113623689"
                        ],
                        "name": "K. Miller",
                        "slug": "K.-Miller",
                        "structuredName": {
                            "firstName": "Katherine",
                            "lastName": "Miller",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Miller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2146137,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "4bd970a37c59c97804ff93cbb2c108e081de3a37",
            "isKey": false,
            "numCitedBy": 5335,
            "numCiting": 133,
            "paperAbstract": {
                "fragments": [],
                "text": "Standard alphabetical procedures for organizing lexical information put together words that are spelled alike and scatter words with similar or related meanings haphazardly through the list. Unfortunately, there is no obvious alternative, no other simple way for lexicographers to keep track of what has been done or for readers to find the word they are looking for. But a frequent objection to this solution is that finding things on an alphabetical list can be tedious and time-consuming. Many people who would like to refer to a dictionary decide not to bother with it because finding the information would interrupt their work and break their train of thought."
            },
            "slug": "Introduction-to-WordNet:-An-On-line-Lexical-Miller-Beckwith",
            "title": {
                "fragments": [],
                "text": "Introduction to WordNet: An On-line Lexical Database"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Standard alphabetical procedures for organizing lexical information put together words that are spelled alike and scatter words with similar or related meanings haphazardly through the list."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 149
                            }
                        ],
                        "text": "\u2026probability theory can be integrated with many kinds of knowledge representations, such as first order logic [Bacchus, 1988] and semantic networks [Pearl, 1988], our definition of similarity can be applied to many different domains where very different similarity measures had previously been\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 175
                            }
                        ],
                        "text": "\u2026such as information content [Resnik, 1995b], mutual information [Hindle, 1990], Dice coefficient [Frakes and Baeza-Yates, 1992], cosine coefficient [Frakes and Baeza-Yates, 1992], distance-based measurements [Lee et al., 1989; Rada et al., 1989], and feature contrast model [Tversky, 1977]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 32583695,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "70ef29e6f0ce082bb8a47fd85b9bfb7cc0f20c93",
            "isKey": false,
            "numCitedBy": 18219,
            "numCiting": 230,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nProbabilistic Reasoning in Intelligent Systems is a complete andaccessible account of the theoretical foundations and computational methods that underlie plausible reasoning under uncertainty. The author provides a coherent explication of probability as a language for reasoning with partial belief and offers a unifying perspective on other AI approaches to uncertainty, such as the Dempster-Shafer formalism, truth maintenance systems, and nonmonotonic logic. The author distinguishes syntactic and semantic approaches to uncertainty\u0097and offers techniques, based on belief networks, that provide a mechanism for making semantics-based systems operational. Specifically, network-propagation techniques serve as a mechanism for combining the theoretical coherence of probability theory with modern demands of reasoning-systems technology: modular declarative inputs, conceptually meaningful inferences, and parallel distributed computation. Application areas include diagnosis, forecasting, image interpretation, multi-sensor fusion, decision support systems, plan recognition, planning, speech recognition\u0097in short, almost every task requiring that conclusions be drawn from uncertain clues and incomplete information. \nProbabilistic Reasoning in Intelligent Systems will be of special interest to scholars and researchers in AI, decision theory, statistics, logic, philosophy, cognitive psychology, and the management sciences. Professionals in the areas of knowledge-based systems, operations research, engineering, and statistics will find theoretical and computational tools of immediate practical use. The book can also be used as an excellent text for graduate-level courses in AI, operations research, or applied probability."
            },
            "slug": "Probabilistic-reasoning-in-intelligent-systems-of-Pearl",
            "title": {
                "fragments": [],
                "text": "Probabilistic reasoning in intelligent systems - networks of plausible inference"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The author provides a coherent explication of probability as a language for reasoning with partial belief and offers a unifying perspective on other AI approaches to uncertainty, such as the Dempster-Shafer formalism, truth maintenance systems, and nonmonotonic logic."
            },
            "venue": {
                "fragments": [],
                "text": "Morgan Kaufmann series in representation and reasoning"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2928927"
                        ],
                        "name": "C. Stanfill",
                        "slug": "C.-Stanfill",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Stanfill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Stanfill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788375"
                        ],
                        "name": "D. Waltz",
                        "slug": "D.-Waltz",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Waltz",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Waltz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 11
                            }
                        ],
                        "text": "Similar to [Alshawi and Carter, 1994; Grishman and Sterling, 1994; Ruge, 1992], we use a parser to extract dependency triples from the text corpus."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16624499,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "123a726f6feb2bce29708b68ab2db5cdf9fcdaf4",
            "isKey": false,
            "numCitedBy": 1436,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "The intensive use of memory to recall specific episodes from the past\u2014rather than rules\u2014should be the foundation of machine reasoning."
            },
            "slug": "Toward-memory-based-reasoning-Stanfill-Waltz",
            "title": {
                "fragments": [],
                "text": "Toward memory-based reasoning"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The intensive use of memory to recall specific episodes from the past\u2014rather than rules\u2014should be the foundation of machine reasoning."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51083583"
                        ],
                        "name": "J. Stein",
                        "slug": "J.-Stein",
                        "structuredName": {
                            "firstName": "Jess",
                            "lastName": "Stein",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Stein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47493483"
                        ],
                        "name": "S. B. Flexner",
                        "slug": "S.-B.-Flexner",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Flexner",
                            "middleNames": [
                                "Berg"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. B. Flexner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "147547309"
                        ],
                        "name": "Random House",
                        "slug": "Random-House",
                        "structuredName": {
                            "firstName": "Random",
                            "lastName": "House",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Random House"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60388471,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "71fd6b0d10d6480cbe90eceb4a54508e03c677ca",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Random-House-college-thesaurus-Stein-Flexner",
            "title": {
                "fragments": [],
                "text": "Random House college thesaurus"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144169170"
                        ],
                        "name": "D. Harman",
                        "slug": "D.-Harman",
                        "structuredName": {
                            "firstName": "Donna",
                            "lastName": "Harman",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Harman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 251,
                                "start": 238
                            }
                        ],
                        "text": "Wu and Palmer [Wu and Palmer, 1994] proposed a measure for semantic similarity that could be regarded as a special case of sim :\nsimWu&Palmer\nwhere and are the number of IS-A links from A and B to their most specific common superclass C; is the number of IS-A links from to the root of the taxonomy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 209397707,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e57f223c680d3d3e424a576ea705af8d205fcb92",
            "isKey": false,
            "numCitedBy": 147,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Overview-of-the-First-Text-REtrieval-Conference.-Harman",
            "title": {
                "fragments": [],
                "text": "Overview of the First Text REtrieval Conference."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR 1993"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144321599"
                        ],
                        "name": "M. McGill",
                        "slug": "M.-McGill",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "McGill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. McGill"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 57545095,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0e7a7aaa4a44fc3bf7bdb37a644b71624472ac8",
            "isKey": false,
            "numCitedBy": 91,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-Evaluation-of-Factors-Affecting-Document-Ranking-McGill",
            "title": {
                "fragments": [],
                "text": "An Evaluation of Factors Affecting Document Ranking by Information Retrieval Systems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752732"
                        ],
                        "name": "T. Cover",
                        "slug": "T.-Cover",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Cover",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Cover"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115282352"
                        ],
                        "name": "Joy A. Thomas",
                        "slug": "Joy-A.-Thomas",
                        "structuredName": {
                            "firstName": "Joy",
                            "lastName": "Thomas",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joy A. Thomas"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 38
                            }
                        ],
                        "text": "In this section, we first make a set of additional assumptions about similarity that we believe to be reasonable."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 53827957,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "67b6fd4dd2c5a5bdd87797a4b6caab253267f92b",
            "isKey": false,
            "numCitedBy": 1801,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Elements-of-Information-Theory-(Wiley-Series-in-and-Cover-Thomas",
            "title": {
                "fragments": [],
                "text": "Elements of Information Theory (Wiley Series in Telecommunications and Signal Processing)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Random House College Thesaurus. Random House"
            },
            "venue": {
                "fragments": [],
                "text": "Random House College Thesaurus. Random House"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 140
                            }
                        ],
                        "text": "Column Miller&Charles lists the average similarity scores (on a scale of 0 to 4) assigned by human subjects in Miller&Charles\u2019s experiments [Miller and Charles, 1991]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 188
                            }
                        ],
                        "text": "Resnik [Resnik, 1995a] evaluated three different similarity measures by correlating their similarity scores on 28 pairs of concepts in the WordNet with assessments made by human subjects [Miller and Charles, 1991]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Contextual correlates of semantic similarity. Language and Cognitive Processes"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 7,
            "methodology": 6
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 25,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/An-Information-Theoretic-Definition-of-Similarity-Lin/cc0c3033ea7d4e19e1f5ac71934759507e126162?sort=total-citations"
}