{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47002621"
                        ],
                        "name": "Yuhua Li",
                        "slug": "Yuhua-Li",
                        "structuredName": {
                            "firstName": "Yuhua",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuhua Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144960578"
                        ],
                        "name": "D. Mclean",
                        "slug": "D.-Mclean",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mclean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mclean"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1829501"
                        ],
                        "name": "Z. Bandar",
                        "slug": "Z.-Bandar",
                        "structuredName": {
                            "firstName": "Zuhair",
                            "lastName": "Bandar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Bandar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1410239467"
                        ],
                        "name": "J. O'Shea",
                        "slug": "J.-O'Shea",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "O'Shea",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. O'Shea"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2627074"
                        ],
                        "name": "Keeley A. Crockett",
                        "slug": "Keeley-A.-Crockett",
                        "structuredName": {
                            "firstName": "Keeley",
                            "lastName": "Crockett",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Keeley A. Crockett"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 128
                            }
                        ],
                        "text": "The first dataset includes 65 sentence pairs which correspond to the dictionary definitions for the 65 word pairs in Similarity(Rubenstein and Goodenough, 1965)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 144
                            }
                        ],
                        "text": "The authors showed brief video segments to Annotators from Amazon Mechanical Turk (AMT) and were asked\n1http://search.cpan.org/\u02dcmlehmann/ String-Similarity-1."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 220,
                                "start": 189
                            }
                        ],
                        "text": "The output of the systems performance is evaluated using the Pearson product-moment correlation coefficient between the system scores and the human scores, as customary in text similarity (Rubenstein and Goodenough, 1965)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 17
                            }
                        ],
                        "text": "Semantic Textual Similarity (STS) measures the degree of semantic equivalence between two sentences."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 3
                            }
                        ],
                        "text": "04/Similarity.pm\nto provide a one-sentence description of the main action or event in the video (Chen and Dolan, 2011)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 0
                            }
                        ],
                        "text": "Similarity of vectors was computed using cosine similarity."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 83
                            }
                        ],
                        "text": "This paper presents the SemEval 2012 pilot evaluation exercise on Semantic Textual Similarity."
                    },
                    "intents": []
                }
            ],
            "corpusId": 12007882,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "58331d76610488c64ce104fbc361e30d8f0f8704",
            "isKey": true,
            "numCitedBy": 841,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Sentence similarity measures play an increasingly important role in text-related research and applications in areas such as text mining, Web page retrieval, and dialogue systems. Existing methods for computing sentence similarity have been adopted from approaches used for long text documents. These methods process sentences in a very high-dimensional space and are consequently inefficient, require human input, and are not adaptable to some application domains. This paper focuses directly on computing the similarity between very short texts of sentence length. It presents an algorithm that takes account of semantic information and word order information implied in the sentences. The semantic similarity of two sentences is calculated using information from a structured lexical database and from corpus statistics. The use of a lexical database enables our method to model human common sense knowledge and the incorporation of corpus statistics allows our method to be adaptable to different domains. The proposed method can be used in a variety of applications that involve text knowledge representation and discovery. Experiments on two sets of selected sentence pairs demonstrate that the proposed method provides a similarity measure that shows a significant correlation to human intuition"
            },
            "slug": "Sentence-similarity-based-on-semantic-nets-and-Li-Mclean",
            "title": {
                "fragments": [],
                "text": "Sentence similarity based on semantic nets and corpus statistics"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Experiments demonstrate that the proposed method provides a similarity measure that shows a significant correlation to human intuition and can be used in a variety of applications that involve text knowledge representation and discovery."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Knowledge and Data Engineering"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "83415753"
                        ],
                        "name": "W. Dolan",
                        "slug": "W.-Dolan",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Dolan",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Dolan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2596310"
                        ],
                        "name": "Chris Quirk",
                        "slug": "Chris-Quirk",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Quirk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Quirk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3125776"
                        ],
                        "name": "Chris Brockett",
                        "slug": "Chris-Brockett",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Brockett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Brockett"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 17
                            }
                        ],
                        "text": "Section 4 investigates the evaluation of STS systems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 114
                            }
                        ],
                        "text": "It contains 5801 pairs of sentences gleaned over a period of 18 months from thousands of news sources on the web (Dolan et al., 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10181753,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7acfdc905f734abf966aed58abb983bc015ff7fe",
            "isKey": false,
            "numCitedBy": 795,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate unsupervised techniques for acquiring monolingual sentence-level paraphrases from a corpus of temporally and topically clustered news articles collected from thousands of web-based news sources. Two techniques are employed: (1) simple string edit distance, and (2) a heuristic strategy that pairs initial (presumably summary) sentences from different news stories in the same cluster. We evaluate both datasets using a word alignment algorithm and a metric borrowed from machine translation. Results show that edit distance data is cleaner and more easily-aligned than the heuristic data, with an overall alignment error rate (AER) of 11.58% on a similarly-extracted test set. On test data extracted by the heuristic strategy, however, performance of the two training sets is similar, with AERs of 13.2% and 14.7% respectively. Analysis of 100 pairs of sentences from each set reveals that the edit distance data lacks many of the complex lexical and syntactic alternations that characterize monolingual paraphrase. The summary sentences, while less readily alignable, retain more of the non-trivial alternations that are of greatest interest learning paraphrase relationships."
            },
            "slug": "Unsupervised-Construction-of-Large-Paraphrase-News-Dolan-Quirk",
            "title": {
                "fragments": [],
                "text": "Unsupervised Construction of Large Paraphrase Corpora: Exploiting Massively Parallel News Sources"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "Investigation of unsupervised techniques for acquiring monolingual sentence-level paraphrases from a corpus of temporally and topically clustered news articles collected from thousands of web-based news sources shows that edit distance data is cleaner and more easily-aligned than the heuristic data."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763608"
                        ],
                        "name": "Chris Callison-Burch",
                        "slug": "Chris-Callison-Burch",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Callison-Burch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Callison-Burch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2927234"
                        ],
                        "name": "C. Fordyce",
                        "slug": "C.-Fordyce",
                        "structuredName": {
                            "firstName": "Cameron",
                            "lastName": "Fordyce",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fordyce"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755162"
                        ],
                        "name": "Philipp Koehn",
                        "slug": "Philipp-Koehn",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Koehn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Koehn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696402"
                        ],
                        "name": "Christof Monz",
                        "slug": "Christof-Monz",
                        "structuredName": {
                            "firstName": "Christof",
                            "lastName": "Monz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christof Monz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152324671"
                        ],
                        "name": "J. Schroeder",
                        "slug": "J.-Schroeder",
                        "structuredName": {
                            "firstName": "Josh",
                            "lastName": "Schroeder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schroeder"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 157
                            }
                        ],
                        "text": "We selected pairs from the translation shared task of the 2007 and 2008 ACL Workshops on Statistical Machine Translation (WMT) (Callison-Burch et al., 2007; Callison-Burch et al., 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Finally, Section 6 draws the conclusions."
                    },
                    "intents": []
                }
            ],
            "corpusId": 26255400,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "be9bca1e9b0192fc49b316f2701242b50d98d456",
            "isKey": false,
            "numCitedBy": 287,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper analyzes the translation quality of machine translation systems for 10 language pairs translating between Czech, English, French, German, Hungarian, and Spanish. We report the translation quality of over 30 diverse translation systems based on a large-scale manual evaluation involving hundreds of hours of effort. We use the human judgments of the systems to analyze automatic evaluation metrics for translation quality, and we report the strength of the correlation with human judgments at both the system-level and at the sentence-level. We validate our manual evaluation methodology by measuring intra- and inter-annotator agreement, and collecting timing information."
            },
            "slug": "Further-Meta-Evaluation-of-Machine-Translation-Callison-Burch-Fordyce",
            "title": {
                "fragments": [],
                "text": "Further Meta-Evaluation of Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "This paper analyzes the translation quality of machine translation systems for 10 language pairs translating between Czech, English, French, German, Hungarian, and Spanish and uses the human judgments of the systems to analyze automatic evaluation metrics for translation quality."
            },
            "venue": {
                "fragments": [],
                "text": "WMT@ACL"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2657103"
                        ],
                        "name": "M. Lee",
                        "slug": "M.-Lee",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Lee",
                            "middleNames": [
                                "David"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1891812"
                        ],
                        "name": "B. Pincombe",
                        "slug": "B.-Pincombe",
                        "structuredName": {
                            "firstName": "Brandon",
                            "lastName": "Pincombe",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Pincombe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066005714"
                        ],
                        "name": "Matthew Welsh",
                        "slug": "Matthew-Welsh",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Welsh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew Welsh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 49
                            }
                        ],
                        "text": "Existing datasets include (Li et al., 2006) and (Lee et al., 2005)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 78
                            }
                        ],
                        "text": "Semantic Textual Similarity (STS) measures the degree of semantic equivalence between two sentences."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 645710,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4ea172b778c0d75f5610fb457eee915dd53f93e1",
            "isKey": false,
            "numCitedBy": 240,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "An Empirical Evaluation of Models of Text Document Similarity Michael D. Lee (michael.lee@adelaide.edu.au) Department of Psychology, University of Adelaide South Australia, 5005, AUSTRALIA Brandon Pincombe (brandon.pincombe@dsto.defence.gov.au) Intelligence Surveillance and Reconnaissance Division, Defence Science and Technology Organisation PO Box 1500, Edinburgh SA 5111 AUSTRALIA Matthew Welsh (matthew.welsh@adelaide.edu.au) Australian School of Petroleum Engineering, University of Adelaide South Australia, 5005, AUSTRALIA Abstract Modeling the semantic similarity between text docu- ments presents a significant theoretical challenge for cognitive science, with ready-made applications in in- formation handling and decision support systems deal- ing with text. While a number of candidate models exist, they have generally not been assessed in terms of their ability to emulate human judgments of simi- larity. To address this problem, we conducted an ex- periment that collected repeated similarity measures for each pair of documents in a small corpus of short news documents. An analysis of human performance showed inter-rater correlations of about 0.6. We then considered the ability of existing models\u2014using word- based, n-gram and Latent Semantic Analysis (LSA) approaches\u2014to model these human judgments. The best performed LSA model produced correlations of about 0.6, consistent with human performance, while the best performed word-based and n-gram models achieved correlations closer to 0.5. Many of the re- maining models showed almost no correlation with hu- man performance. Based on our results, we provide some discussion of the key strengths and weaknesses of the models we examined. Introduction Modeling the semantic similarity between text docu- ments is an interesting problem for cognitive science, for both theoretical and practical reasons. Theoret- ically, it involves the study of a basic cognitive pro- cess with richly structured natural stimuli. Practically, search engines, text corpus visualizations, and a vari- ety of other applications for filtering, sorting, retriev- ing, and generally handling text rely fundamentally on similarity measures. For this reason, the ability to as- sess semantic similarity in an accurate, automated, and scalable way is a key determinant of the effectiveness of most information handling and decision support soft- ware that deals with text. A variety of different approaches have been devel- oped for modeling text document similarity. These in- clude simple word-based, keyword-based and n-gram measures (e.g., Salton, 1989; Damashek, 1995), and more complicated approaches such as Latent Seman- tic Analysis (LSA: Deerwester et al., 1990; Landauer and Dumais, 1997). While all of these approaches have achieved some level of practical success, they have gen- erally not been assessed in terms of their ability to model human judgments of text document similarity. The most likely reason for this failure is that no suit- able empirical data exist, and considerable effort is in- volved in collecting pairwise ratings of text document similarity for even a moderate number of documents. This paper reports the collection of data that give ten independent ratings of the similarity of every pair of 50 short text documents, and so represents an attempt to establish a \u2018psychological ground truth\u2019 for evaluating models. Using the new data, we report a first eval- uation of the ability of word-based, n-gram and LSA approaches to model human judgments. Experiment Materials The text corpus evaluated by human judges contained 50 documents selected from the Australian Broadcast- ing Corporation\u2019s news mail service, which provides text e-mails of headline stories. The documents varied in length from 51 to 126 words, and covered a number of broad topics. A further 314 documents from the same were collected to act as a larger \u2018backgrounding\u2019 corpus for LSA. Both document sets were assessed against a stan- dard corpus of five English texts using four models of language. These were the log-normal, generalized in- verse Gauss-Poisson (with \u03b3 = \u22120.5), Yule-Simon and Zipfian models (Baayen, 2001). Both document sets were within the normal range of English text for word frequency spectrum and vocabulary growth and were therefore regarded as representative of normal English texts. Subjects The subjects were 83 University of Adelaide students (29 males and 54 females), with a mean age of 19.7 years. They were each paid with a ten (Australian) dollar gift voucher for every 100 document pair ratings made."
            },
            "slug": "An-Empirical-Evaluation-of-Models-of-Text-Document-Lee-Pincombe",
            "title": {
                "fragments": [],
                "text": "An Empirical Evaluation of Models of Text Document Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An attempt to establish a \u2018psychological ground truth\u2019 for evaluating models of the ability of word-based, n-gram and Latent Semantic Analysis approaches to model human judgments of text document similarity is reported."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153642390"
                        ],
                        "name": "David L. Chen",
                        "slug": "David-L.-Chen",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Chen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David L. Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "83415753"
                        ],
                        "name": "W. Dolan",
                        "slug": "W.-Dolan",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Dolan",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Dolan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 97
                            }
                        ],
                        "text": "04/Similarity.pm\nto provide a one-sentence description of the main action or event in the video (Chen and Dolan, 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Finally, Section 6 draws the conclusions."
                    },
                    "intents": []
                }
            ],
            "corpusId": 215717103,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "554a31ce91189cf6022ac677413ef2f8b9b40ca7",
            "isKey": false,
            "numCitedBy": 650,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "A lack of standard datasets and evaluation metrics has prevented the field of paraphrasing from making the kind of rapid progress enjoyed by the machine translation community over the last 15 years. We address both problems by presenting a novel data collection framework that produces highly parallel text data relatively inexpensively and on a large scale. The highly parallel nature of this data allows us to use simple n-gram comparisons to measure both the semantic adequacy and lexical dissimilarity of paraphrase candidates. In addition to being simple and efficient to compute, experiments show that these metrics correlate highly with human judgments."
            },
            "slug": "Collecting-Highly-Parallel-Data-for-Paraphrase-Chen-Dolan",
            "title": {
                "fragments": [],
                "text": "Collecting Highly Parallel Data for Paraphrase Evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel data collection framework is presented that produces highly parallel text data relatively inexpensively and on a large scale that allows for simple n-gram comparisons to measure both the semantic adequacy and lexical dissimilarity of paraphrase candidates."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763608"
                        ],
                        "name": "Chris Callison-Burch",
                        "slug": "Chris-Callison-Burch",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Callison-Burch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Callison-Burch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2927234"
                        ],
                        "name": "C. Fordyce",
                        "slug": "C.-Fordyce",
                        "structuredName": {
                            "firstName": "Cameron",
                            "lastName": "Fordyce",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fordyce"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755162"
                        ],
                        "name": "Philipp Koehn",
                        "slug": "Philipp-Koehn",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Koehn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Koehn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696402"
                        ],
                        "name": "Christof Monz",
                        "slug": "Christof-Monz",
                        "structuredName": {
                            "firstName": "Christof",
                            "lastName": "Monz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christof Monz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152324671"
                        ],
                        "name": "J. Schroeder",
                        "slug": "J.-Schroeder",
                        "structuredName": {
                            "firstName": "Josh",
                            "lastName": "Schroeder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schroeder"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 128
                            }
                        ],
                        "text": "We selected pairs from the translation shared task of the 2007 and 2008 ACL Workshops on Statistical Machine Translation (WMT) (Callison-Burch et al., 2007; Callison-Burch et al., 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7130985,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "20c11546a035d2fa2fa1121a7b31e890d20d6b6b",
            "isKey": false,
            "numCitedBy": 425,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper evaluates the translation quality of machine translation systems for 8 language pairs: translating French, German, Spanish, and Czech to English and back. We carried out an extensive human evaluation which allowed us not only to rank the different MT systems, but also to perform higher-level analysis of the evaluation process. We measured timing and intra- and inter-annotator agreement for three types of subjective evaluation. We measured the correlation of automatic evaluation metrics with human judgments. This meta-evaluation reveals surprising facts about the most commonly used methodologies."
            },
            "slug": "(Meta-)-Evaluation-of-Machine-Translation-Callison-Burch-Fordyce",
            "title": {
                "fragments": [],
                "text": "(Meta-) Evaluation of Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An extensive human evaluation was carried out not only to rank the different MT systems, but also to perform higher-level analysis of the evaluation process, revealing surprising facts about the most commonly used methodologies."
            },
            "venue": {
                "fragments": [],
                "text": "WMT@ACL"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721801"
                        ],
                        "name": "C. Fellbaum",
                        "slug": "C.-Fellbaum",
                        "structuredName": {
                            "firstName": "Christiane",
                            "lastName": "Fellbaum",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fellbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 290,
                                "start": 276
                            }
                        ],
                        "text": "\u2026of all the human ranked fr-en system submissions from the WMT 2007 news conversation test set, resulting in 351 unique system reference pairs.2 The second set is radically different as it comprised 750 pairs of glosses from OntoNotes 4.0 (Hovy et al., 2006) and WordNet 3.1 (Fellbaum, 1998) senses."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Finally, Section 6 draws the conclusions."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5958691,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d87ceda3042f781c341ac17109d1e94a717f5f60",
            "isKey": true,
            "numCitedBy": 13578,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Part 1 The lexical database: nouns in WordNet, George A. Miller modifiers in WordNet, Katherine J. Miller a semantic network of English verbs, Christiane Fellbaum design and implementation of the WordNet lexical database and searching software, Randee I. Tengi. Part 2: automated discovery of WordNet relations, Marti A. Hearst representing verb alterations in WordNet, Karen T. Kohl et al the formalization of WordNet by methods of relational concept analysis, Uta E. Priss. Part 3 Applications of WordNet: building semantic concordances, Shari Landes et al performance and confidence in a semantic annotation task, Christiane Fellbaum et al WordNet and class-based probabilities, Philip Resnik combining local context and WordNet similarity for word sense identification, Claudia Leacock and Martin Chodorow using WordNet for text retrieval, Ellen M. Voorhees lexical chains as representations of context for the detection and correction of malapropisms, Graeme Hirst and David St-Onge temporal indexing through lexical chaining, Reem Al-Halimi and Rick Kazman COLOR-X - using knowledge from WordNet for conceptual modelling, J.F.M. Burg and R.P. van de Riet knowledge processing on an extended WordNet, Sanda M. Harabagiu and Dan I Moldovan appendix - obtaining and using WordNet."
            },
            "slug": "WordNet-:-an-electronic-lexical-database-Fellbaum",
            "title": {
                "fragments": [],
                "text": "WordNet : an electronic lexical database"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "The lexical database: nouns in WordNet, Katherine J. Miller a semantic network of English verbs, and applications of WordNet: building semantic concordances are presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144547315"
                        ],
                        "name": "E. Hovy",
                        "slug": "E.-Hovy",
                        "structuredName": {
                            "firstName": "Eduard",
                            "lastName": "Hovy",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hovy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734174"
                        ],
                        "name": "M. Marcus",
                        "slug": "M.-Marcus",
                        "structuredName": {
                            "firstName": "Mitchell",
                            "lastName": "Marcus",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Marcus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145755155"
                        ],
                        "name": "Martha Palmer",
                        "slug": "Martha-Palmer",
                        "structuredName": {
                            "firstName": "Martha",
                            "lastName": "Palmer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martha Palmer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744313"
                        ],
                        "name": "L. Ramshaw",
                        "slug": "L.-Ramshaw",
                        "structuredName": {
                            "firstName": "Lance",
                            "lastName": "Ramshaw",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Ramshaw"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732071"
                        ],
                        "name": "R. Weischedel",
                        "slug": "R.-Weischedel",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Weischedel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Weischedel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 257,
                                "start": 240
                            }
                        ],
                        "text": "\u2026of all the human ranked fr-en system submissions from the WMT 2007 news conversation test set, resulting in 351 unique system reference pairs.2 The second set is radically different as it comprised 750 pairs of glosses from OntoNotes 4.0 (Hovy et al., 2006) and WordNet 3.1 (Fellbaum, 1998) senses."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Finally, Section 6 draws the conclusions."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8508974,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "e54d8b07ef659f9ee2671441c4355e414e408836",
            "isKey": true,
            "numCitedBy": 852,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the OntoNotes methodology and its result, a large multilingual richly-annotated corpus constructed at 90% interannotator agreement. An initial portion (300K words of English newswire and 250K words of Chinese newswire) will be made available to the community during 2007."
            },
            "slug": "OntoNotes:-The-90-Solution-Hovy-Marcus",
            "title": {
                "fragments": [],
                "text": "OntoNotes: The 90% Solution"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "It is described the OntoNotes methodology and its result, a large multilingual richly-annotated corpus constructed at 90% interannotator agreement, which will be made available to the community during 2007."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47709773"
                        ],
                        "name": "H. Rubenstein",
                        "slug": "H.-Rubenstein",
                        "structuredName": {
                            "firstName": "Herbert",
                            "lastName": "Rubenstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Rubenstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1898344"
                        ],
                        "name": "J. Goodenough",
                        "slug": "J.-Goodenough",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Goodenough",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Goodenough"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 128
                            }
                        ],
                        "text": "The first dataset includes 65 sentence pairs which correspond to the dictionary definitions for the 65 word pairs in Similarity(Rubenstein and Goodenough, 1965)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 144
                            }
                        ],
                        "text": "The authors showed brief video segments to Annotators from Amazon Mechanical Turk (AMT) and were asked\n1http://search.cpan.org/\u02dcmlehmann/ String-Similarity-1."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 220,
                                "start": 189
                            }
                        ],
                        "text": "The output of the systems performance is evaluated using the Pearson product-moment correlation coefficient between the system scores and the human scores, as customary in text similarity (Rubenstein and Goodenough, 1965)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 69
                            }
                        ],
                        "text": "We did the annotation, and the pairwise Pearson ranged from 84% to 87% among ourselves."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 17
                            }
                        ],
                        "text": "Semantic Textual Similarity (STS) measures the degree of semantic equivalence between two sentences."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 3
                            }
                        ],
                        "text": "04/Similarity.pm\nto provide a one-sentence description of the main action or event in the video (Chen and Dolan, 2011)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 0
                            }
                        ],
                        "text": "Similarity of vectors was computed using cosine similarity."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 83
                            }
                        ],
                        "text": "This paper presents the SemEval 2012 pilot evaluation exercise on Semantic Textual Similarity."
                    },
                    "intents": []
                }
            ],
            "corpusId": 18309234,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "7ef3ac14cdb484aaa2b039850093febd5cf73a21",
            "isKey": true,
            "numCitedBy": 1460,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Experimentol corroboration was obtained for the hypothesis that the proportion of words common to the contexts of word A and to the contexts of word B is a function of the degree to which A and B are similar in meaning. The tests were carried out for variously defined contexts. The shapes of the functions, however, indicate that similarity of context is reliable as criterion only for detecting pairs of words that are very similar in meaning."
            },
            "slug": "Contextual-correlates-of-synonymy-Rubenstein-Goodenough",
            "title": {
                "fragments": [],
                "text": "Contextual correlates of synonymy"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The shapes of the functions indicate that similarity of context is reliable as criterion only for detecting pairs of words that are very similar in meaning."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722211"
                        ],
                        "name": "E. Ukkonen",
                        "slug": "E.-Ukkonen",
                        "structuredName": {
                            "firstName": "Esko",
                            "lastName": "Ukkonen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Ukkonen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 79
                            }
                        ],
                        "text": "We used the implementation readily accessible at CPAN1 of a well-known metric (Ukkonen, 1985)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 205886218,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "530f4487992599b3598bd4bb45d74de8436fc3fc",
            "isKey": false,
            "numCitedBy": 647,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Algorithms-for-Approximate-String-Matching-Ukkonen",
            "title": {
                "fragments": [],
                "text": "Algorithms for Approximate String Matching"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Control."
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 79
                            }
                        ],
                        "text": "We used the implementation readily accessible at CPAN1 of a well-known metric (Ukkonen, 1985)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Algorithms for approximate string matching. Information and Contro"
            },
            "venue": {
                "fragments": [],
                "text": "Algorithms for approximate string matching. Information and Contro"
            },
            "year": 1985
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 5,
            "methodology": 6
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 11,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/SemEval-2012-Task-6:-A-Pilot-on-Semantic-Textual-Agirre-Cer/528fa9bb03644ba752fb9491be49b9dd1bce1d52?sort=total-citations"
}