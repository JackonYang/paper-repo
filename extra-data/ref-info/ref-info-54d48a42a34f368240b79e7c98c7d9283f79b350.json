{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47655614"
                        ],
                        "name": "G. Griffin",
                        "slug": "G.-Griffin",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Griffin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Griffin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144160673"
                        ],
                        "name": "Alex Holub",
                        "slug": "Alex-Holub",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Holub",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Holub"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 131
                            }
                        ],
                        "text": "Along the line, there are quite a few benchmark datasets for image classification, such as MNIST [1], Caltech 101 [9], Caltech 256 [11], PASCAL VOC [7], LabelMe[19], etc."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 118828957,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5a5effa909cdeafaddbbb7855037e02f8e25d632",
            "isKey": false,
            "numCitedBy": 2545,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a challenging set of 256 object categories containing a total of 30607 images. The original Caltech-101 [1] was collected by choosing a set of object categories, downloading examples from Google Images and then manually screening out all images that did not fit the category. Caltech-256 is collected in a similar manner with several improvements: a) the number of categories is more than doubled, b) the minimum number of images in any category is increased from 31 to 80, c) artifacts due to image rotation are avoided and d) a new and larger clutter category is introduced for testing background rejection. We suggest several testing paradigms to measure classification performance, then benchmark the dataset using two simple metrics as well as a state-of-the-art spatial pyramid matching [2] algorithm. Finally we use the clutter category to train an interest detector which rejects uninformative background regions."
            },
            "slug": "Caltech-256-Object-Category-Dataset-Griffin-Holub",
            "title": {
                "fragments": [],
                "text": "Caltech-256 Object Category Dataset"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "A challenging set of 256 object categories containing a total of 30607 images is introduced and the clutter category is used to train an interest detector which rejects uninformative background regions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153302678"
                        ],
                        "name": "Jia Deng",
                        "slug": "Jia-Deng",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39668247"
                        ],
                        "name": "A. Berg",
                        "slug": "A.-Berg",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Berg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "94451829"
                        ],
                        "name": "K. Li",
                        "slug": "K.-Li",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 43
                            }
                        ],
                        "text": "As a result, we achieve state-of-the-art performance on the ImageNet 1000-class classification, i.e., 52.9% in classification accuracy and 71.8% in top 5 hit rate."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1274537,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9800e3c3394c569be83379ee2ebe3424e09c2919",
            "isKey": true,
            "numCitedBy": 528,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Image classification is a critical task for both humans and computers. One of the challenges lies in the large scale of the semantic space. In particular, humans can recognize tens of thousands of object classes and scenes. No computer vision algorithm today has been tested at this scale. This paper presents a study of large scale categorization including a series of challenging experiments on classification with more than 10, 000 image classes. We find that a) computational issues become crucial in algorithm design; b) conventional wisdom from a couple of hundred image categories on relative performance of different classifiers does not necessarily hold when the number of categories increases; c) there is a surprisingly strong relationship between the structure of WordNet (developed for studying language) and the difficulty of visual categorization; d) classification can be improved by exploiting the semantic hierarchy. Toward the future goal of developing automatic vision algorithms to recognize tens of thousands or even millions of image categories, we make a series of observations and arguments about dataset scale, category density, and image hierarchy."
            },
            "slug": "What-Does-Classifying-More-Than-10,-000-Image-Tell-Deng-Berg",
            "title": {
                "fragments": [],
                "text": "What Does Classifying More Than 10, 000 Image Categories Tell Us?"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A study of large scale categorization including a series of challenging experiments on classification with more than 10,000 image classes finds that computational issues become crucial in algorithm design and conventional wisdom from a couple of hundred image categories does not necessarily hold when the number of categories increases."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145160921"
                        ],
                        "name": "Bryan C. Russell",
                        "slug": "Bryan-C.-Russell",
                        "structuredName": {
                            "firstName": "Bryan",
                            "lastName": "Russell",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bryan C. Russell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056417995"
                        ],
                        "name": "K. Murphy",
                        "slug": "K.-Murphy",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Murphy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Murphy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 153
                            }
                        ],
                        "text": "Along the line, there are quite a few benchmark datasets for image classification, such as MNIST [1], Caltech 101 [9], Caltech 256 [11], PASCAL VOC [7], LabelMe[19], etc. Researchers have developed a wide spectrum of different local descriptors [17, 16, 5, 22], bag-of-words models [14, 24] and classification methods [4], and they compared to the best available results on those publicly available datasets \u2013 for PASCAL VOC, many teams from all over the world participate in the PASCAL Challenge each year to compete for the best performance."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 160
                            }
                        ],
                        "text": "Along the line, there are quite a few benchmark datasets for image classification, such as MNIST [1], Caltech 101 [9], Caltech 256 [11], PASCAL VOC [7], LabelMe[19], etc."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1900911,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "092c275005ae49dc1303214f6d02d134457c7053",
            "isKey": false,
            "numCitedBy": 3076,
            "numCiting": 82,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract\nWe seek to build a large collection of images with ground truth labels to be used for object detection and recognition research. Such data is useful for supervised learning and quantitative evaluation. To achieve this, we developed a web-based tool that allows easy image annotation and instant sharing of such annotations. Using this annotation tool, we have collected a large dataset that spans many object categories, often containing multiple instances over a wide variety of images. We quantify the contents of the dataset and compare against existing state of the art datasets used for object recognition and detection. Also, we show how to extend the dataset to automatically enhance object labels with WordNet, discover object parts, recover a depth ordering of objects in a scene, and increase the number of labels using minimal user supervision and images from the web.\n"
            },
            "slug": "LabelMe:-A-Database-and-Web-Based-Tool-for-Image-Russell-Torralba",
            "title": {
                "fragments": [],
                "text": "LabelMe: A Database and Web-Based Tool for Image Annotation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A web-based tool that allows easy image annotation and instant sharing of such annotations is developed and a large dataset that spans many object categories, often containing multiple instances over a wide variety of images is collected."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46185316"
                        ],
                        "name": "Hsiang-Fu Yu",
                        "slug": "Hsiang-Fu-Yu",
                        "structuredName": {
                            "firstName": "Hsiang-Fu",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hsiang-Fu Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793529"
                        ],
                        "name": "Cho-Jui Hsieh",
                        "slug": "Cho-Jui-Hsieh",
                        "structuredName": {
                            "firstName": "Cho-Jui",
                            "lastName": "Hsieh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cho-Jui Hsieh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2782886"
                        ],
                        "name": "Kai-Wei Chang",
                        "slug": "Kai-Wei-Chang",
                        "structuredName": {
                            "firstName": "Kai-Wei",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai-Wei Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711460"
                        ],
                        "name": "Chih-Jen Lin",
                        "slug": "Chih-Jen-Lin",
                        "structuredName": {
                            "firstName": "Chih-Jen",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chih-Jen Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 100
                            }
                        ],
                        "text": "Indeed, LIBLINEAR recently released an extended version that explicitly considered the memory issue [25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 28204,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "99082796c9e5e93575b48cbac711c5e6e2fa6b3d",
            "isKey": false,
            "numCitedBy": 135,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent advances in linear classification have shown that for applications such as document classification, the training process can be extremely efficient. However, most of the existing training methods are designed by assuming that data can be stored in the computer memory. These methods cannot be easily applied to data larger than the memory capacity due to the random access to the disk. We propose and analyze a block minimization framework for data larger than the memory size. At each step a block of data is loaded from the disk and handled by certain learning methods. We investigate two implementations of the proposed framework for primal and dual SVMs, respectively. Because data cannot fit in memory, many design considerations are very different from those for traditional algorithms. We discuss and compare with existing approaches that are able to handle data larger than memory. Experiments using data sets 20 times larger than the memory demonstrate the effectiveness of the proposed method."
            },
            "slug": "Large-Linear-Classification-When-Data-Cannot-Fit-in-Yu-Hsieh",
            "title": {
                "fragments": [],
                "text": "Large Linear Classification When Data Cannot Fit in Memory"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work proposes and analyzes a block minimization framework for data larger than the memory size, and investigates two implementations of the proposed framework for primal and dual SVMs, respectively."
            },
            "venue": {
                "fragments": [],
                "text": "TKDD"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109615009"
                        ],
                        "name": "Xi Zhou",
                        "slug": "Xi-Zhou",
                        "structuredName": {
                            "firstName": "Xi",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xi Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144782042"
                        ],
                        "name": "Kai Yu",
                        "slug": "Kai-Yu",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49104973"
                        ],
                        "name": "Tong Zhang",
                        "slug": "Tong-Zhang",
                        "structuredName": {
                            "firstName": "Tong",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tong Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 178
                            }
                        ],
                        "text": "We apply two state-of-the-art \u2018coding + pooling\u2019 pipelines in our system, one is based on local coordinate coding (LCC) [26], and the other is based on super-vector coding (SVC) [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 122
                            }
                        ],
                        "text": "Then, each local descriptor is coded either using local coordinate coding (LCC) [26] or Gaussian model supervector coding [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 4
                            }
                        ],
                        "text": "The SVC can be seen as expanding VQ with local tangent directions, and is thus a smoother coding scheme."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 75
                            }
                        ],
                        "text": "This system follows the approaches described in a number of previous works [24, 28] that showed state-of-the-art performance on medium-scale image classification datasets (such as PASCAL VOC and Caltech101&256)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 62
                            }
                        ],
                        "text": "For the reported best performers on the medium-scale datasets [28, 24], extracting image features on one image takes at least a couple of seconds (and even minutes [24])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "SVC is another way to extend VQ, which explores the geometry of data distribution."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7405065,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4e65c9f0a64b6a4333b12e2adc3861ad75aca83b",
            "isKey": false,
            "numCitedBy": 555,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces a new framework for image classification using local visual descriptors. The pipeline first performs a non-linear feature transformation on descriptors, then aggregates the results together to form image-level representations, and finally applies a classification model. For all the three steps we suggest novel solutions which make our approach appealing in theory, more scalable in computation, and transparent in classification. Our experiments demonstrate that the proposed classification method achieves state-of-the-art accuracy on the well-known PASCAL benchmarks."
            },
            "slug": "Image-Classification-Using-Super-Vector-Coding-of-Zhou-Yu",
            "title": {
                "fragments": [],
                "text": "Image Classification Using Super-Vector Coding of Local Image Descriptors"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "This paper introduces a new framework for image classification using local visual descriptors that first performs a non-linear feature transformation on descriptors, then aggregates the results together to form image-level representations, and finally applies a classification model."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749609"
                        ],
                        "name": "S. Lazebnik",
                        "slug": "S.-Lazebnik",
                        "structuredName": {
                            "firstName": "Svetlana",
                            "lastName": "Lazebnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lazebnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 111
                            }
                        ],
                        "text": "Researchers have developed a wide spectrum of different local descriptors [17, 16, 5, 22], bag-of-words models [14, 24] and classification methods [4], and they compared to the best available results on those publicly available datasets \u2013 for PASCAL VOC, many teams from all over the world participate in the PASCAL Challenge each year to compete for the best performance."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2421251,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6dbaff29d3898cf60f63f5a34cb9610ebb75220c",
            "isKey": false,
            "numCitedBy": 8328,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for recognizing scene categories based on approximate global geometric correspondence. This technique works by partitioning the image into increasingly fine sub-regions and computing histograms of local features found inside each sub-region. The resulting \"spatial pyramid\" is a simple and computationally efficient extension of an orderless bag-of-features image representation, and it shows significantly improved performance on challenging scene categorization tasks. Specifically, our proposed method exceeds the state of the art on the Caltech-101 database and achieves high accuracy on a large database of fifteen natural scene categories. The spatial pyramid framework also offers insights into the success of several recently proposed image descriptions, including Torralba\u2019s \"gist\" and Lowe\u2019s SIFT descriptors."
            },
            "slug": "Beyond-Bags-of-Features:-Spatial-Pyramid-Matching-Lazebnik-Schmid",
            "title": {
                "fragments": [],
                "text": "Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural Scene Categories"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper presents a method for recognizing scene categories based on approximate global geometric correspondence that exceeds the state of the art on the Caltech-101 database and achieves high accuracy on a large database of fifteen natural scene categories."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48950628"
                        ],
                        "name": "N. Dalal",
                        "slug": "N.-Dalal",
                        "structuredName": {
                            "firstName": "Navneet",
                            "lastName": "Dalal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Dalal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 50
                            }
                        ],
                        "text": "We tested it with a simplified image feature set (HOG descriptor only with coding dimension of 4,096, which generated 80GB training data)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 141
                            }
                        ],
                        "text": "Both features have been proven successful in various vision tasks such as object classification, texture analysis and face recognition, etc. HOG and LBP are complementary in the sense that HOG focuses more on shape information while LBP emphasizes texture information within each patch."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 74
                            }
                        ],
                        "text": "Researchers have developed a wide spectrum of different local descriptors [17, 16, 5, 22], bag-of-words models [14, 24] and classification methods [4], and they compared to the best available results on those publicly available datasets \u2013 for PASCAL VOC, many teams from all over the world participate in the PASCAL Challenge each year to compete for the best performance."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 77
                            }
                        ],
                        "text": "Given an input image, the system first extracts dense local descriptors, HOG [5] or LBP (local binary pattern [22])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 57
                            }
                        ],
                        "text": "2, given an input image, our system first extracts dense HOG (histogram of oriented gradients [5])\nand LBP (local binary pattern [22]) local descriptors."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 49
                            }
                        ],
                        "text": "We used three scales of patch size for computing HOG and LBP, namely, 16\u00d716, 24\u00d724 and 32\u00d732."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 94
                            }
                        ],
                        "text": "2, given an input image, our system first extracts dense HOG (histogram of oriented gradients [5])"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206590483,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cec734d7097ab6b1e60d95228ffd64248eb89d66",
            "isKey": true,
            "numCitedBy": 29264,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the question of feature sets for robust visual object recognition; adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds."
            },
            "slug": "Histograms-of-oriented-gradients-for-human-Dalal-Triggs",
            "title": {
                "fragments": [],
                "text": "Histograms of oriented gradients for human detection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection, and the influence of each stage of the computation on performance is studied."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1735300"
                        ],
                        "name": "S. Haykin",
                        "slug": "S.-Haykin",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Haykin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Haykin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713858"
                        ],
                        "name": "B. Kosko",
                        "slug": "B.-Kosko",
                        "structuredName": {
                            "firstName": "Bart",
                            "lastName": "Kosko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Kosko"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 107
                            }
                        ],
                        "text": "The proposed ASGD algorithm is a modification of conventional stochastic gradient descent (SGD) algorithms [15, 27]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 64294544,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f42b865e20e61a954239f421b42007236e671f19",
            "isKey": false,
            "numCitedBy": 3516,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilayer Neural Networks trained with the backpropagation algorithm constitute the best example of a successful Gradient-Based Learning technique. Given an appropriate network architecture, Gradient-Based Learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional Neural Networks, that are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation, recognition, and language modeling. A new learning paradigm, called Graph Transformer Networks (GTN), allows such multi-module systems to be trained globally using Gradient-Based methods so as to minimize an overall performance measure. Two systems for on-line handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of Graph Transformer Networks. A Graph Transformer Network for reading bank check is also described. It uses Convolutional Neural Network character recognizers combined with global training techniques to provides record accuracy on business and personal checks. It is deployed commercially and reads several million checks per day."
            },
            "slug": "GradientBased-Learning-Applied-to-Document-Haykin-Kosko",
            "title": {
                "fragments": [],
                "text": "GradientBased Learning Applied to Document Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Various methods applied to handwritten character recognition are reviewed and compared and Convolutional Neural Networks, that are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The proposed ASGD algorithm is a modification of conventional stochastic gradient descent (SGD) algorithms [15, 27]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14542261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "162d958ff885f1462aeda91cd72582323fd6a1f4",
            "isKey": false,
            "numCitedBy": 35271,
            "numCiting": 248,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day."
            },
            "slug": "Gradient-based-learning-applied-to-document-LeCun-Bottou",
            "title": {
                "fragments": [],
                "text": "Gradient-based learning applied to document recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task, and Convolutional neural networks are shown to outperform all other techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 104
                            }
                        ],
                        "text": "Therefore, there have been extensive research efforts on developing effective visual object recognizers [10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5745749,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62837ab473124ea43cb8d7c6a4b4ee0f6f14e8c5",
            "isKey": false,
            "numCitedBy": 2487,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method to learn and recognize object class models from unlabeled and unsegmented cluttered scenes in a scale invariant manner. Objects are modeled as flexible constellations of parts. A probabilistic representation is used for all aspects of the object: shape, appearance, occlusion and relative scale. An entropy-based feature detector is used to select regions and their scale within the image. In learning the parameters of the scale-invariant object model are estimated. This is done using expectation-maximization in a maximum-likelihood setting. In recognition, this model is used in a Bayesian manner to classify images. The flexible nature of the model is demonstrated by excellent results over a range of datasets including geometrically constrained classes (e.g. faces, cars) and flexible objects (such as animals)."
            },
            "slug": "Object-class-recognition-by-unsupervised-learning-Fergus-Perona",
            "title": {
                "fragments": [],
                "text": "Object class recognition by unsupervised scale-invariant learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The flexible nature of the model is demonstrated by excellent results over a range of datasets including geometrically constrained classes (e.g. faces, cars) and flexible objects (such as animals)."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118775664"
                        ],
                        "name": "Xiaoyu Wang",
                        "slug": "Xiaoyu-Wang",
                        "structuredName": {
                            "firstName": "Xiaoyu",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaoyu Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3244463"
                        ],
                        "name": "T. Han",
                        "slug": "T.-Han",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Han",
                            "middleNames": [
                                "X."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143653681"
                        ],
                        "name": "Shuicheng Yan",
                        "slug": "Shuicheng-Yan",
                        "structuredName": {
                            "firstName": "Shuicheng",
                            "lastName": "Yan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shuicheng Yan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 30
                            }
                        ],
                        "text": "and LBP (local binary pattern [22]) local descriptors."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 110
                            }
                        ],
                        "text": "Given an input image, the system first extracts dense local descriptors, HOG [5] or LBP (local binary pattern [22])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "The advantage of such combination was also reported in [22] for human detection task."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 74
                            }
                        ],
                        "text": "Researchers have developed a wide spectrum of different local descriptors [17, 16, 5, 22], bag-of-words models [14, 24] and classification methods [4], and they compared to the best available results on those publicly available datasets \u2013 for PASCAL VOC, many teams from all over the world participate in the PASCAL Challenge each year to compete for the best performance."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2475434,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bd9446d2b61139867662442147d81181e84ab4f2",
            "isKey": true,
            "numCitedBy": 1700,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "By combining Histograms of Oriented Gradients (HOG) and Local Binary Pattern (LBP) as the feature set, we propose a novel human detection approach capable of handling partial occlusion. Two kinds of detectors, i.e., global detector for whole scanning windows and part detectors for local regions, are learned from the training data using linear SVM. For each ambiguous scanning window, we construct an occlusion likelihood map by using the response of each block of the HOG feature to the global detector. The occlusion likelihood map is then segmented by Mean-shift approach. The segmented portion of the window with a majority of negative response is inferred as an occluded region. If partial occlusion is indicated with high likelihood in a certain scanning window, part detectors are applied on the unoccluded regions to achieve the final classification on the current scanning window. With the help of the augmented HOG-LBP feature and the global-part occlusion handling method, we achieve a detection rate of 91.3% with FPPW= 10\u22126, 94.7% with FPPW= 10\u22125, and 97.9% with FPPW= 10\u22124 on the INRIA dataset, which, to our best knowledge, is the best human detection performance on the INRIA dataset. The global-part occlusion handling method is further validated using synthesized occlusion data constructed from the INRIA and Pascal dataset."
            },
            "slug": "An-HOG-LBP-human-detector-with-partial-occlusion-Wang-Han",
            "title": {
                "fragments": [],
                "text": "An HOG-LBP human detector with partial occlusion handling"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "By combining Histograms of Oriented Gradients (HOG) and Local Binary Pattern (LBP) as the feature set, this work proposes a novel human detection approach capable of handling partial occlusion and achieves the best human detection performance on the INRIA dataset."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5155714,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "427b168f490b56716f22b129ac93aba5425ea08f",
            "isKey": false,
            "numCitedBy": 2113,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Linear Support Vector Machines (SVMs) have become one of the most prominent machine learning techniques for high-dimensional sparse data commonly encountered in applications like text classification, word-sense disambiguation, and drug design. These applications involve a large number of examples n as well as a large number of features N, while each example has only s << N non-zero features. This paper presents a Cutting Plane Algorithm for training linear SVMs that provably has training time 0(s,n) for classification problems and o(sn log (n))for ordinal regression problems. The algorithm is based on an alternative, but equivalent formulation of the SVM optimization problem. Empirically, the Cutting-Plane Algorithm is several orders of magnitude faster than decomposition methods like svm light for large datasets."
            },
            "slug": "Training-linear-SVMs-in-linear-time-Joachims",
            "title": {
                "fragments": [],
                "text": "Training linear SVMs in linear time"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A Cutting Plane Algorithm for training linear SVMs that provably has training time 0(s,n) for classification problems and o(sn log (n)) for ordinal regression problems and several orders of magnitude faster than decomposition methods like svm light for large datasets."
            },
            "venue": {
                "fragments": [],
                "text": "KDD '06"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 65
                            }
                        ],
                        "text": "Although there exist many off-the-shelf SVM solvers, such as SVM [12], SVM [13] or LibSVM/LIBLINEAR [8], they are not feasible for such huge training data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61116019,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7550a05bf00f7b24aed9c1ac3ef000575388d21c",
            "isKey": false,
            "numCitedBy": 5454,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Training a support vector machine SVM leads to a quadratic optimization problem with bound constraints and one linear equality constraint. Despite the fact that this type of problem is well understood, there are many issues to be considered in designing an SVM learner. In particular, for large learning tasks with many training examples on the shelf optimization techniques for general quadratic programs quickly become intractable in their memory and time requirements. SVM light is an implementation of an SVM learner which addresses the problem of large tasks. This chapter presents algorithmic and computational results developed for SVM light V 2.0, which make large-scale SVM training more practical. The results give guidelines for the application of SVMs to large domains."
            },
            "slug": "Making-large-scale-SVM-learning-practical-Joachims",
            "title": {
                "fragments": [],
                "text": "Making large scale SVM learning practical"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This chapter presents algorithmic and computational results developed for SVM light V 2.0, which make large-scale SVM training more practical and give guidelines for the application of SVMs to large domains."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059876008"
                        ],
                        "name": "Matthijs C. Dorst",
                        "slug": "Matthijs-C.-Dorst",
                        "structuredName": {
                            "firstName": "Matthijs",
                            "lastName": "Dorst",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthijs C. Dorst"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 74
                            }
                        ],
                        "text": "Researchers have developed a wide spectrum of different local descriptors [17, 16, 5, 22], bag-of-words models [14, 24] and classification methods [4], and they compared to the best available results on those publicly available datasets \u2013 for PASCAL VOC, many teams from all over the world participate in the PASCAL Challenge each year to compete for the best performance."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 130535382,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bcae70dce393c1796d4f15c7b8bbf0ed6f468be1",
            "isKey": false,
            "numCitedBy": 15903,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The Scale-Invariant Feature Transform (or SIFT) algorithm is a highly robust method to extract and consequently match distinctive invariant features from images. These features can then be used to reliably match objects in diering images. The algorithm was rst proposed by Lowe [12] and further developed to increase performance resulting in the classic paper [13] that served as foundation for SIFT which has played an important role in robotic and machine vision in the past decade."
            },
            "slug": "Distinctive-Image-Features-from-Scale-Invariant-Dorst",
            "title": {
                "fragments": [],
                "text": "Distinctive Image Features from Scale-Invariant Keypoints"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "The Scale-Invariant Feature Transform (or SIFT) algorithm is a highly robust method to extract and consequently match distinctive invariant features from images that can then be used to reliably match objects in diering images."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145115014"
                        ],
                        "name": "Corinna Cortes",
                        "slug": "Corinna-Cortes",
                        "structuredName": {
                            "firstName": "Corinna",
                            "lastName": "Cortes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Corinna Cortes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 147
                            }
                        ],
                        "text": "Researchers have developed a wide spectrum of different local descriptors [17, 16, 5, 22], bag-of-words models [14, 24] and classification methods [4], and they compared to the best available results on those publicly available datasets \u2013 for PASCAL VOC, many teams from all over the world participate in the PASCAL Challenge each year to compete for the best performance."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 52874011,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "52b7bf3ba59b31f362aa07f957f1543a29a4279e",
            "isKey": false,
            "numCitedBy": 33436,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "The support-vector network is a new learning machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very high-dimension feature space. In this feature space a linear decision surface is constructed. Special properties of the decision surface ensures high generalization ability of the learning machine. The idea behind the support-vector network was previously implemented for the restricted case where the training data can be separated without errors. We here extend this result to non-separable training data.High generalization ability of support-vector networks utilizing polynomial input transformations is demonstrated. We also compare the performance of the support-vector network to various classical learning algorithms that all took part in a benchmark study of Optical Character Recognition."
            },
            "slug": "Support-Vector-Networks-Cortes-Vapnik",
            "title": {
                "fragments": [],
                "text": "Support-Vector Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "High generalization ability of support-vector networks utilizing polynomial input transformations is demonstrated and the performance of the support- vector network is compared to various classical learning algorithms that all took part in a benchmark study of Optical Character Recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33794424"
                        ],
                        "name": "E. Chang",
                        "slug": "E.-Chang",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Chang",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37553409"
                        ],
                        "name": "Kaihua Zhu",
                        "slug": "Kaihua-Zhu",
                        "structuredName": {
                            "firstName": "Kaihua",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaihua Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48016595"
                        ],
                        "name": "Hao Wang",
                        "slug": "Hao-Wang",
                        "structuredName": {
                            "firstName": "Hao",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hao Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1843448"
                        ],
                        "name": "Hongjie Bai",
                        "slug": "Hongjie-Bai",
                        "structuredName": {
                            "firstName": "Hongjie",
                            "lastName": "Bai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hongjie Bai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2151965429"
                        ],
                        "name": "Jian Li",
                        "slug": "Jian-Li",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3330876"
                        ],
                        "name": "Zhihuan Qiu",
                        "slug": "Zhihuan-Qiu",
                        "structuredName": {
                            "firstName": "Zhihuan",
                            "lastName": "Qiu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhihuan Qiu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112820296"
                        ],
                        "name": "Hang Cui",
                        "slug": "Hang-Cui",
                        "structuredName": {
                            "firstName": "Hang",
                            "lastName": "Cui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hang Cui"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 36787117,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5699b38d8cf40ae1bbaa94d5e6e2774cadd28c6c",
            "isKey": false,
            "numCitedBy": 245,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Support Vector Machines (SVMs) suffer from a widely recognized scalability problem in both memory use and computational time. To improve scalability, we have developed a parallel SVM algorithm (PSVM), which reduces memory use through performing a row-based, approximate matrix factorization, and which loads only essential data to each machine to perform parallel computation. Let n denote the number of training instances, p the reduced matrix dimension after factorization (p is significantly smaller than n), and m the number of machines. PSVM reduces the memory requirement from O(n2) to O(np/m), and improves computation time to O(np2/m). Empirical study shows PSVM to be effective. PSVM Open Source is available for download at http://code.google.com/p/psvm/."
            },
            "slug": "Parallelizing-Support-Vector-Machines-on-Computers-Chang-Zhu",
            "title": {
                "fragments": [],
                "text": "Parallelizing Support Vector Machines on Distributed Computers"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A parallel SVM algorithm (PSVM), which reduces memory use through performing a row-based, approximate matrix factorization, and which loads only essential data to each machine to perform parallel computation."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054933466"
                        ],
                        "name": "Tom White",
                        "slug": "Tom-White",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "White",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom White"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 37
                            }
                        ],
                        "text": "For feature extraction, we develop a Hadoop scheme that performs feature extraction in parallel using hundreds of mappers."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 32
                            }
                        ],
                        "text": "The most important advantage of Hadoop is that, it provides a reliable infrastructure for large scale computation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 7
                            }
                        ],
                        "text": "In our Hadoop cluster, we only use 6 workers on each machine because of some limitation of the machines."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "Hadoop is an open source implementation of MapReduce computation framework and a distributed file system [3]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 57
                            }
                        ],
                        "text": "We develop a fast feature extraction scheme using Hadoop [21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 77
                            }
                        ],
                        "text": "To speedup the computation and accommodate the data, we choose Apache Hadoop [21] to distribute computation over 20 machines and store data on Hadoop distributed file system (HDFS)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "Hadoop: The Definitive Guide."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 17
                            }
                        ],
                        "text": "With the help of Hadoop parallel computing, the feature sets took 6 hours to 2 days to compute, depending on coding settings."
                    },
                    "intents": []
                }
            ],
            "corpusId": 58458964,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f3eb8b1c6928ddee3638b1cba47551de6974dd7d",
            "isKey": true,
            "numCitedBy": 4023,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "Hadoop: The Definitive Guide helps you harness the power of your data. Ideal for processing large datasets, the Apache Hadoop framework is an open source implementation of the MapReduce algorithm on which Google built its empire. This comprehensive resource demonstrates how to use Hadoop to build reliable, scalable, distributed systems: programmers will find details for analyzing large datasets, and administrators will learn how to set up and run Hadoop clusters. Complete with case studies that illustrate how Hadoop solves specific problems, this book helps you: Use the Hadoop Distributed File System (HDFS) for storing large datasets, and run distributed computations over those datasets using MapReduce Become familiar with Hadoop's data and I/O building blocks for compression, data integrity, serialization, and persistence Discover common pitfalls and advanced features for writing real-world MapReduce programs Design, build, and administer a dedicated Hadoop cluster, or run Hadoop in the cloud Use Pig, a high-level query language for large-scale data processing Take advantage of HBase, Hadoop's database for structured and semi-structured data Learn ZooKeeper, a toolkit of coordination primitives for building distributed systems If you have lots of data -- whether it's gigabytes or petabytes -- Hadoop is the perfect solution. Hadoop: The Definitive Guide is the most thorough book available on the subject. \"Now you have the opportunity to learn about Hadoop from a master-not only of the technology, but also of common sense and plain talk.\" -- Doug Cutting, Hadoop Founder, Yahoo!"
            },
            "slug": "Hadoop:-The-Definitive-Guide-White",
            "title": {
                "fragments": [],
                "text": "Hadoop: The Definitive Guide"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This comprehensive resource demonstrates how to use Hadoop to build reliable, scalable, distributed systems: programmers will find details for analyzing large datasets, and administrators will learn how to set up and run Hadoops clusters."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33794424"
                        ],
                        "name": "E. Chang",
                        "slug": "E.-Chang",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Chang",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37553409"
                        ],
                        "name": "Kaihua Zhu",
                        "slug": "Kaihua-Zhu",
                        "structuredName": {
                            "firstName": "Kaihua",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaihua Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48016595"
                        ],
                        "name": "Hao Wang",
                        "slug": "Hao-Wang",
                        "structuredName": {
                            "firstName": "Hao",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hao Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1843448"
                        ],
                        "name": "Hongjie Bai",
                        "slug": "Hongjie-Bai",
                        "structuredName": {
                            "firstName": "Hongjie",
                            "lastName": "Bai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hongjie Bai"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 103
                            }
                        ],
                        "text": "Another important issue is how to parallelize the computation for training 1000 binary SVM classifiers [2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15690554,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3b79c240fc93ef9f46ed80f0c51b488bbc78951d",
            "isKey": false,
            "numCitedBy": 154,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Support Vector Machines (SVMs) suffer from a widely recognized scalability problem in both memory use and computational time. To improve scalability, we have developed a parallel SVM algorithm (PSVM), which reduces memory use through performing a row-based, approximate matrix factorization, and which loads only essential data to each machine to perform parallel computation. Let n denote the number of training instances, p the reduced matrix dimension after factorization (p is significantly smaller than n), and m the number of machines. PSVM reduces the memory requirement from O(n2) to O(np/m), and improves computation time to O(np2/m). Empirical study shows PSVM to be effective. PSVM Open Source is available for download at http://code.google.com/p/psvm/."
            },
            "slug": "PSVM-:-Parallelizing-Support-Vector-Machines-on-Chang-Zhu",
            "title": {
                "fragments": [],
                "text": "PSVM : Parallelizing Support Vector Machines on Distributed Computers"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A parallel SVM algorithm (PSVM), which reduces memory use through performing a row-based, approximate matrix factorization, and which loads only essential data to each machine to perform parallel computation."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145738410"
                        ],
                        "name": "W. Xu",
                        "slug": "W.-Xu",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Xu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 44
                            }
                        ],
                        "text": "We adopt the following step size scheduling [23]:"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17311241,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a7e2d53c47bdef073add879557270d915d80a098",
            "isKey": false,
            "numCitedBy": 149,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "For large scale learning problems, it is desirable if we can obtain the optimal model parameters by going through the data in only one pass. Polyak and Juditsky (1992) showed that asymptotically the test performance of the simple average of the parameters obtained by stochastic gradient descent (SGD) is as good as that of the parameters which minimize the empirical cost. However, to our knowledge, despite its optimal asymptotic convergence rate, averaged SGD (ASGD) received little attention in recent research on large scale learning. One possible reason is that it may take a prohibitively large number of training samples for ASGD to reach its asymptotic region for most real problems. In this paper, we present a finite sample analysis for the method of Polyak and Juditsky (1992). Our analysis shows that it indeed usually takes a huge number of samples for ASGD to reach its asymptotic region for improperly chosen learning rate. More importantly, based on our analysis, we propose a simple way to properly set learning rate so that it takes a reasonable amount of data for ASGD to reach its asymptotic region. We compare ASGD using our proposed learning rate with other well known algorithms for training large scale linear classifiers. The experiments clearly show the superiority of ASGD."
            },
            "slug": "Towards-Optimal-One-Pass-Large-Scale-Learning-with-Xu",
            "title": {
                "fragments": [],
                "text": "Towards Optimal One Pass Large Scale Learning with Averaged Stochastic Gradient Descent"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A finite sample analysis for the method of Polyak and Juditsky (1992) shows that it indeed usually takes a huge number of samples for ASGD to reach its asymptotic region for improperly chosen learning rate, and a simple way to properly set learning rate is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144522420"
                        ],
                        "name": "T. Ojala",
                        "slug": "T.-Ojala",
                        "structuredName": {
                            "firstName": "Timo",
                            "lastName": "Ojala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Ojala"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145962204"
                        ],
                        "name": "M. Pietik\u00e4inen",
                        "slug": "M.-Pietik\u00e4inen",
                        "structuredName": {
                            "firstName": "Matti",
                            "lastName": "Pietik\u00e4inen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pietik\u00e4inen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145298122"
                        ],
                        "name": "D. Harwood",
                        "slug": "D.-Harwood",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Harwood",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Harwood"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 74
                            }
                        ],
                        "text": "Researchers have developed a wide spectrum of different local descriptors [17, 16, 5, 22], bag-of-words models [14, 24] and classification methods [4], and they compared to the best available results on those publicly available datasets \u2013 for PASCAL VOC, many teams from all over the world participate in the PASCAL Challenge each year to compete for the best performance."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 26881819,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5985014dda6d502469614aae17349b4d08f9f74c",
            "isKey": false,
            "numCitedBy": 6554,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-comparative-study-of-texture-measures-with-based-Ojala-Pietik\u00e4inen",
            "title": {
                "fragments": [],
                "text": "A comparative study of texture measures with classification based on featured distributions"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1389955537"
                        ],
                        "name": "S. Shalev-Shwartz",
                        "slug": "S.-Shalev-Shwartz",
                        "structuredName": {
                            "firstName": "Shai",
                            "lastName": "Shalev-Shwartz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Shalev-Shwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740765"
                        ],
                        "name": "Y. Singer",
                        "slug": "Y.-Singer",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Singer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706280"
                        ],
                        "name": "Nathan Srebro",
                        "slug": "Nathan-Srebro",
                        "structuredName": {
                            "firstName": "Nathan",
                            "lastName": "Srebro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nathan Srebro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145658292"
                        ],
                        "name": "Andrew Cotter",
                        "slug": "Andrew-Cotter",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Cotter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Cotter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 101
                            }
                        ],
                        "text": "Meanwhile, we plan to systematically compare the ASGD method with other SGD methods (such as Pegasos [20]) for large-scale image classification."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 0
                            }
                        ],
                        "text": "Pegasos: Pri-\nmal estimated sub-gradient solver for svm."
                    },
                    "intents": []
                }
            ],
            "corpusId": 53306004,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb4ffd271451a8fbed752582543bd34925fa4396",
            "isKey": false,
            "numCitedBy": 2004,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe and analyze a simple and effective stochastic sub-gradient descent algorithm for solving the optimization problem cast by Support Vector Machines (SVM). We prove that the number of iterations required to obtain a solution of accuracy $${\\epsilon}$$ is $${\\tilde{O}(1 / \\epsilon)}$$, where each iteration operates on a single training example. In contrast, previous analyses of stochastic gradient descent methods for SVMs require $${\\Omega(1 / \\epsilon^2)}$$ iterations. As in previously devised SVM solvers, the number of iterations also scales linearly with 1/\u03bb, where \u03bb is the regularization parameter of SVM. For a linear kernel, the total run-time of our method is $${\\tilde{O}(d/(\\lambda \\epsilon))}$$, where d is a bound on the number of non-zero features in each example. Since the run-time does not depend directly on the size of the training set, the resulting algorithm is especially suited for learning from large datasets. Our approach also extends to non-linear kernels while working solely on the primal objective function, though in this case the runtime does depend linearly on the training set size. Our algorithm is particularly well suited for large text classification problems, where we demonstrate an order-of-magnitude speedup over previous SVM learning methods."
            },
            "slug": "Pegasos:-primal-estimated-sub-gradient-solver-for-Shalev-Shwartz-Singer",
            "title": {
                "fragments": [],
                "text": "Pegasos: primal estimated sub-gradient solver for SVM"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A simple and effective stochastic sub-gradient descent algorithm for solving the optimization problem cast by Support Vector Machines, which is particularly well suited for large text classification problems, and demonstrates an order-of-magnitude speedup over previous SVM learning methods."
            },
            "venue": {
                "fragments": [],
                "text": "Math. Program."
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1849128"
                        ],
                        "name": "Rong-En Fan",
                        "slug": "Rong-En-Fan",
                        "structuredName": {
                            "firstName": "Rong-En",
                            "lastName": "Fan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rong-En Fan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2782886"
                        ],
                        "name": "Kai-Wei Chang",
                        "slug": "Kai-Wei-Chang",
                        "structuredName": {
                            "firstName": "Kai-Wei",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai-Wei Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793529"
                        ],
                        "name": "Cho-Jui Hsieh",
                        "slug": "Cho-Jui-Hsieh",
                        "structuredName": {
                            "firstName": "Cho-Jui",
                            "lastName": "Hsieh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cho-Jui Hsieh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144799660"
                        ],
                        "name": "Xiang-Rui Wang",
                        "slug": "Xiang-Rui-Wang",
                        "structuredName": {
                            "firstName": "Xiang-Rui",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiang-Rui Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711460"
                        ],
                        "name": "Chih-Jen Lin",
                        "slug": "Chih-Jen-Lin",
                        "structuredName": {
                            "firstName": "Chih-Jen",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chih-Jen Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 84
                            }
                        ],
                        "text": "However, even on such a small dataset (as compared to our largest one, 1.37TB), the LIBLINEAR solver was not able to provide useful results after 2 weeks of running on a dual quad-core 2GHz Intel Xeon CPU machine with 16G memory."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 20
                            }
                        ],
                        "text": "The slowness of the LIBLINEAR solver is not only due to its inefficient inner-outer loop iterative structure but also because it needs to learn as many as 1000 binary classifiers."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 8
                            }
                        ],
                        "text": "Indeed, LIBLINEAR recently released an extended version that explicitly considered the memory issue [25]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 100
                            }
                        ],
                        "text": "Although there exist many off-the-shelf SVM solvers, such as SVM [12], SVM [13] or LibSVM/LIBLINEAR [8], they are not feasible for such huge training data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 99
                            }
                        ],
                        "text": "Although there exist many off-the-shelf SVM solvers, such as SVMlight [12], SVMperf [13] or LibSVM/LIBLINEAR [8], they are not feasible for such huge training data."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 16
                            }
                        ],
                        "text": "using LIBLINEAR [8]) would take more than 1 hour if we use the features that are employed in those state-of-the-art methods (without dimensionality reduction, e."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 68
                            }
                        ],
                        "text": "To our experience, training SVM for this PASCAL dataset (e.g. using LIBLINEAR [8]) would take more than 1 hour if we use the features that are employed in those state-of-the-art methods (without dimensionality reduction, e.g., by kernel trick)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 3116168,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "268a4f8da15a42f3e0e71691f760ff5edbf9cec8",
            "isKey": true,
            "numCitedBy": 7765,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "LIBLINEAR is an open source library for large-scale linear classification. It supports logistic regression and linear support vector machines. We provide easy-to-use command-line tools and library calls for users and developers. Comprehensive documents are available for both beginners and advanced users. Experiments demonstrate that LIBLINEAR is very efficient on large sparse data sets."
            },
            "slug": "LIBLINEAR:-A-Library-for-Large-Linear-Fan-Chang",
            "title": {
                "fragments": [],
                "text": "LIBLINEAR: A Library for Large Linear Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "LIBLINEAR is an open source library for large-scale linear classification that supports logistic regression and linear support vector machines and provides easy-to-use command-line tools and library calls for users and developers."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144782042"
                        ],
                        "name": "Kai Yu",
                        "slug": "Kai-Yu",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49104973"
                        ],
                        "name": "Tong Zhang",
                        "slug": "Tong-Zhang",
                        "structuredName": {
                            "firstName": "Tong",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tong Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144768792"
                        ],
                        "name": "Yihong Gong",
                        "slug": "Yihong-Gong",
                        "structuredName": {
                            "firstName": "Yihong",
                            "lastName": "Gong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yihong Gong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 120
                            }
                        ],
                        "text": "We apply two state-of-the-art \u2018coding + pooling\u2019 pipelines in our system, one is based on local coordinate coding (LCC) [26], and the other is based on super-vector coding (SVC) [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 80
                            }
                        ],
                        "text": "Then, each local descriptor is coded either using local coordinate coding (LCC) [26] or Gaussian model supervector coding [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 28
                            }
                        ],
                        "text": "In general, the features by LCC are sparse even after pooling and they are much smaller than the ones generated by supervector coding."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 75
                            }
                        ],
                        "text": "On the other hand, we empirically find that the performance of this simple LCC coding is often comparable or better than traditional sparse coding for image classification."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 26
                            }
                        ],
                        "text": "Like many coding methods, LCC seeks a linear combination of bases in B to reconstruct z, namely z \u2248 B\u03b1, and then use the coefficients \u03b1 as the coding result for z. Typically \u03b1 is sparse and its dimensionality is higher than that of z."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 14
                            }
                        ],
                        "text": "The theory of LCC points out that, under a mild manifold assumption, a good coding should satisfy two properties:\n\u2022 The approximation z \u2248 B\u03b1 is sufficiently accurate;\n\u2022 The coding \u03b1 should be sufficiently local \u2013 only those bases close to z are activated;\nBased on the theory, we develop a very simple algorithm here."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1045818,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a5e23ef59eaf3fd897c460c28d23a982c72e8f65",
            "isKey": false,
            "numCitedBy": 775,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces a new method for semi-supervised learning on high dimensional nonlinear manifolds, which includes a phase of unsupervised basis learning and a phase of supervised function learning. The learned bases provide a set of anchor points to form a local coordinate system, such that each data point x on the manifold can be locally approximated by a linear combination of its nearby anchor points, and the linear weights become its local coordinate coding. We show that a high dimensional nonlinear function can be approximated by a global linear function with respect to this coding scheme, and the approximation quality is ensured by the locality of such coding. The method turns a difficult nonlinear learning problem into a simple global linear learning problem, which overcomes some drawbacks of traditional local learning methods."
            },
            "slug": "Nonlinear-Learning-using-Local-Coordinate-Coding-Yu-Zhang",
            "title": {
                "fragments": [],
                "text": "Nonlinear Learning using Local Coordinate Coding"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that a high dimensional nonlinear function can be approximated by a global linear function with respect to this coding scheme, and the approximation quality is ensured by the locality of such coding."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117881943"
                        ],
                        "name": "Tong Zhang",
                        "slug": "Tong-Zhang",
                        "structuredName": {
                            "firstName": "Tong",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tong Zhang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 107
                            }
                        ],
                        "text": "The proposed ASGD algorithm is a modification of conventional stochastic gradient descent (SGD) algorithms [15, 27]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5306879,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0ef7d9e618cbb507d69f8ebcdc60b8a1f3135bff",
            "isKey": false,
            "numCitedBy": 1008,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Linear prediction methods, such as least squares for regression, logistic regression and support vector machines for classification, have been extensively used in statistics and machine learning. In this paper, we study stochastic gradient descent (SGD) algorithms on regularized forms of linear prediction methods. This class of methods, related to online algorithms such as perceptron, are both efficient and very simple to implement. We obtain numerical rate of convergence for such algorithms, and discuss its implications. Experiments on text data will be provided to demonstrate numerical and statistical consequences of our theoretical findings."
            },
            "slug": "Solving-large-scale-linear-prediction-problems-Zhang",
            "title": {
                "fragments": [],
                "text": "Solving large scale linear prediction problems using stochastic gradient descent algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Stochastic gradient descent algorithms on regularized forms of linear prediction methods, related to online algorithms such as perceptron, are studied, and numerical rate of convergence for such algorithms is obtained."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703847"
                        ],
                        "name": "Boris Polyak",
                        "slug": "Boris-Polyak",
                        "structuredName": {
                            "firstName": "Boris",
                            "lastName": "Polyak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Boris Polyak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754887"
                        ],
                        "name": "A. Juditsky",
                        "slug": "A.-Juditsky",
                        "structuredName": {
                            "firstName": "Anatoli",
                            "lastName": "Juditsky",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Juditsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 151
                            }
                        ],
                        "text": "It was shown that, asymptotically the ASGD algorithm is able to achieve similar convergence rate as second-order stochastic gradient descent algorithm [18], which is often much faster than its firstorder counterpart."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3548228,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6dc61f37ecc552413606d8c89ffbc46ec98ed887",
            "isKey": false,
            "numCitedBy": 1536,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "A new recursive algorithm of stochastic approximation type with the averaging of trajectories is investigated. Convergence with probability one is proved for a variety of classical optimization and identification problems. It is also demonstrated for these problems that the proposed algorithm achieves the highest possible rate of convergence."
            },
            "slug": "Acceleration-of-stochastic-approximation-by-Polyak-Juditsky",
            "title": {
                "fragments": [],
                "text": "Acceleration of stochastic approximation by averaging"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "Convergence with probability one is proved for a variety of classical optimization and identification problems and it is demonstrated for these problems that the proposed algorithm achieves the highest possible rate of convergence."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 144
                            }
                        ],
                        "text": "Along the line, there are quite a few benchmark datasets for image classification, such as MNIST [1], Caltech 101 [9], Caltech 256 [11], PASCAL VOC [7], LabelMe[19], etc. Researchers have developed a wide spectrum of different local descriptors [17, 16, 5, 22], bag-of-words models [14, 24] and classification methods [4], and they compared to the best available results on those publicly available datasets \u2013 for PASCAL VOC, many teams from all over the world participate in the PASCAL Challenge each year to compete for the best performance."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 16
                            }
                        ],
                        "text": "Let\u2019s use PASCAL VOC 2010 for comparison."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 49
                            }
                        ],
                        "text": "The PASCAL Visual Object Classes Challenge 2010 (VOC2010) Results. http://www.pascalnetwork.org/challenges/VOC/voc2010/workshop/index.html."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 187
                            }
                        ],
                        "text": "This system follows the approaches described in a number of previous works [24, 28] that showed state-of-the-art performance on medium-scale image classification datasets (such as PASCAL VOC and Caltech101&256)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 73
                            }
                        ],
                        "text": "However, compared to those previous mediumscale datasets (such as PASCAL VOC datasets and Caltech101&256, which can fit into desktop memory), large-scale ImageNet dataset poses more challenges in image classification."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 148
                            }
                        ],
                        "text": "Along the line, there are quite a few benchmark datasets for image classification, such as MNIST [1], Caltech 101 [9], Caltech 256 [11], PASCAL VOC [7], LabelMe[19], etc."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and A"
            },
            "venue": {
                "fragments": [],
                "text": "Zisserman. The PASCAL Visual Object Classes Challenge 2010 "
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2141732326"
                        ],
                        "name": "Jianguo Zhang",
                        "slug": "Jianguo-Zhang",
                        "structuredName": {
                            "firstName": "Jianguo",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianguo Zhang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 56
                            }
                        ],
                        "text": "Second, large-scale classification is hard because it poses more challenges than its medium-scale counterparts."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 63925014,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "0ec48ac86456cea3d6d6172ca81ef68e98b21a61",
            "isKey": false,
            "numCitedBy": 3322,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-PASCAL-Visual-Object-Classes-Challenge-Zhang",
            "title": {
                "fragments": [],
                "text": "The PASCAL Visual Object Classes Challenge"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145039030"
                        ],
                        "name": "J. Platt",
                        "slug": "J.-Platt",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Platt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Platt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153379696"
                        ],
                        "name": "T. Hofmann",
                        "slug": "T.-Hofmann",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Hofmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hofmann"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 105
                            }
                        ],
                        "text": "Hadoop is an open source implementation of MapReduce computation framework and a distributed file system [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62963320,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "571929abb1f8dbb244f416ee470c4a30d255cde7",
            "isKey": false,
            "numCitedBy": 385,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Map-Reduce-for-Machine-Learning-on-Multicore-Sch\u00f6lkopf-Platt",
            "title": {
                "fragments": [],
                "text": "Map-Reduce for Machine Learning on Multicore"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 94
                            }
                        ],
                        "text": "Indeed, we see a huge improvement in performance from the baseline that was reported recently [6], which achieved about 20% in classification rate."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 32
                            }
                        ],
                        "text": "Newly released ImageNet dataset [6] goes a big step further, as shown in Fig."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and L"
            },
            "venue": {
                "fragments": [],
                "text": "Fei-Fei. What does classifying more than 10,000 image categories tell us? ECCV"
            },
            "year": 2010
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 13,
            "methodology": 18
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 29,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Large-scale-image-classification:-Fast-feature-and-Lin-Lv/54d48a42a34f368240b79e7c98c7d9283f79b350?sort=total-citations"
}