{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2121009"
                        ],
                        "name": "J. Puzicha",
                        "slug": "J.-Puzicha",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Puzicha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Puzicha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 78
                            }
                        ],
                        "text": "Work based on shape contexts is indeed aimed at first finding correspondences [Belongie et al., 2001][Mori et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8446909,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "500db68171e4a961d7fa87b8020b3a3e62133caf",
            "isKey": false,
            "numCitedBy": 324,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel approach to measuring similarity between shapes and exploit it for object recognition. In our framework, the measurement of similarity is preceded by (1) solving for correspondences between points on the two shapes, (2) using the correspondences to estimate an aligning transform. In order to solve the correspondence problem, we attach a descriptor, the shape context, to each point. The shape context at a reference point captures the distribution of the remaining points relative to it, thus offering a globally discriminative characterization. Corresponding points on two similar shapes will have similar shape contexts, enabling us to solve for correspondences as an optimal assignment problem. Given the point correspondences, we estimate the transformation that best aligns the two shapes; regularized thin-plate splines provide a flexible class of transformation maps for this purpose. Dis-similarity between two shapes is computed as a sum of matching errors between corresponding points, together with a term measuring the magnitude of the aligning transform. We treat recognition in a nearest-neighbor classification framework. Results are presented for silhouettes, trademarks, handwritten digits and the COIL dataset."
            },
            "slug": "Matching-shapes-Belongie-Malik",
            "title": {
                "fragments": [],
                "text": "Matching shapes"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A novel approach to measuring similarity between shapes and exploiting it for object recognition in a nearest-neighbor classification framework that applies regularized thin-plate splines to the transformation maps for this purpose."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39668247"
                        ],
                        "name": "A. Berg",
                        "slug": "A.-Berg",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Berg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685538"
                        ],
                        "name": "Tamara L. Berg",
                        "slug": "Tamara-L.-Berg",
                        "structuredName": {
                            "firstName": "Tamara",
                            "lastName": "Berg",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tamara L. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 54
                            }
                        ],
                        "text": ", 2003] (in a temporal instead of spatial domain) and [Berg et al., 2005] and others ([Ren et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6055435,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "12c7fc38debaf3589e712973642246bd54fe63b3",
            "isKey": false,
            "numCitedBy": 956,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We approach recognition in the framework of deformable shape matching, relying on a new algorithm for finding correspondences between feature points. This algorithm sets up correspondence as an integer quadratic programming problem, where the cost function has terms based on similarity of corresponding geometric blur point descriptors as well as the geometric distortion between pairs of corresponding feature points. The algorithm handles outliers, and thus enables matching of exemplars to query images in the presence of occlusion and clutter. Given the correspondences, we estimate an aligning transform, typically a regularized thin plate spline, resulting in a dense correspondence between the two shapes. Object recognition is then handled in a nearest neighbor framework where the distance between exemplar and query is the matching cost between corresponding points. We show results on two datasets. One is the Caltech 101 dataset (Fei-Fei, Fergus and Perona), an extremely challenging dataset with large intraclass variation. Our approach yields a 48% correct classification rate, compared to Fei-Fei et al 's 16%. We also show results for localizing frontal and profile faces that are comparable to special purpose approaches tuned to faces."
            },
            "slug": "Shape-matching-and-object-recognition-using-low-Berg-Berg",
            "title": {
                "fragments": [],
                "text": "Shape matching and object recognition using low distortion correspondences"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This work approaches recognition in the framework of deformable shape matching, relying on a new algorithm for finding correspondences between feature points, and shows results for localizing frontal and profile faces that are comparable to special purpose approaches tuned to faces."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10771328"
                        ],
                        "name": "Greg Mori",
                        "slug": "Greg-Mori",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Mori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Greg Mori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 7
                            }
                        ],
                        "text": ", 2001][Mori et al., 2001] and is close to the spirit of this work."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 5247828,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0b8be52a054a5a3800e65170c02d688a80e6bab3",
            "isKey": false,
            "numCitedBy": 197,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we demonstrate that a recently introduced shape descriptor, the \"shape context\", can be used to quickly prune a search for similar shapes. Our representation for a shape is a discrete set of n points sampled from its internal and external contours. For each of these points, the shape context is a histogram of the relative positions of the n - 1 remaining points. We present two methods for rapid shape retrieval: one that does comparisons based on a small number of shape contexts and another that uses vector quantization in the space of shape contexts. We verify the discriminative power of these methods with tests on the Columbia (COIL-100) 3D object database and the Snodgrass and Vanderwart line drawings. The shape context-based methods are shown to quickly produce an accurate shortlist of candidates suitable for a more exact matching engine in spite of pose variation and occlusion."
            },
            "slug": "Shape-contexts-enable-efficient-retrieval-of-shapes-Mori-Belongie",
            "title": {
                "fragments": [],
                "text": "Shape contexts enable efficient retrieval of similar shapes"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "It is demonstrated that a recently introduced shape descriptor, the \"shape context\", can be used to quickly prune a search for similar shapes, and two methods for rapid shape retrieval are presented: one that does comparisons based on a small number of shape contexts and another that uses vector quantization in the space of shapes."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "SIFT is usually used in conjunction with a region of interest operator based on finding local maxima of a scale space operator based on the difference of Gaussians applied to pixel values."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 12
                            }
                        ],
                        "text": "We will use SIFT as an example to illustrate the differences.5\nThe first difference is the region of interest operator."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 14
                            }
                        ],
                        "text": "Generally the SIFT type descriptors are suited to identifying parts of the same object from multiple views, while the geometric blur based descriptor described here is designed to evaluate potential similarity under intra-class variation exploiting larger support and spatially varying blur."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 102
                            }
                        ],
                        "text": "Finally the underlying features for the geometric blur based descriptor described in this chapter and SIFT are both based on oriented edge maps, with slightly different details in engineering."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 119
                            }
                        ],
                        "text": "It is worth noting that in general the scale relative to the edge features is much larger that commonly found with the SIFT region of interest operator."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 24
                            }
                        ],
                        "text": "One way to think of the SIFT descriptor is as constant blur with a grid subsampling pattern (4x4) instead of the dart-board pattern used for the geometric blur descriptor."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 73
                            }
                        ],
                        "text": "This is quite different from other contemporary descriptors such as SIFT [20] that rely on an interest point operator to select similar locations for potential matches."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5258236,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9f836d28f52ad260213d32224a6d227f8e8849a",
            "isKey": true,
            "numCitedBy": 16258,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "An object recognition system has been developed that uses a new class of local image features. The features are invariant to image scaling, translation, and rotation, and partially invariant to illumination changes and affine or 3D projection. These features share similar properties with neurons in inferior temporal cortex that are used for object recognition in primate vision. Features are efficiently detected through a staged filtering approach that identifies stable points in scale space. Image keys are created that allow for local geometric deformations by representing blurred image gradients in multiple orientation planes and at multiple scales. The keys are used as input to a nearest neighbor indexing method that identifies candidate object matches. Final verification of each match is achieved by finding a low residual least squares solution for the unknown model parameters. Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds."
            },
            "slug": "Object-recognition-from-local-scale-invariant-Lowe",
            "title": {
                "fragments": [],
                "text": "Object recognition from local scale-invariant features"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2084269"
                        ],
                        "name": "H. Chui",
                        "slug": "H.-Chui",
                        "structuredName": {
                            "firstName": "Haili",
                            "lastName": "Chui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Chui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145257017"
                        ],
                        "name": "Anand Rangarajan",
                        "slug": "Anand-Rangarajan",
                        "structuredName": {
                            "firstName": "Anand",
                            "lastName": "Rangarajan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anand Rangarajan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 52
                            }
                        ],
                        "text": "Another approach is the non-rigid point matching of [Chui and Rangarajan, 2003] based on thin plate splines and \u201csoftassign\u201d."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7442835,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9511b4e7a3d64b9737ea25b5c268478e3d248209",
            "isKey": false,
            "numCitedBy": 1574,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-new-point-matching-algorithm-for-non-rigid-Chui-Rangarajan",
            "title": {
                "fragments": [],
                "text": "A new point matching algorithm for non-rigid registration"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713089"
                        ],
                        "name": "D. Huttenlocher",
                        "slug": "D.-Huttenlocher",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Huttenlocher",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Huttenlocher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2901136"
                        ],
                        "name": "G. Klanderman",
                        "slug": "G.-Klanderman",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Klanderman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Klanderman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116003"
                        ],
                        "name": "W. Rucklidge",
                        "slug": "W.-Rucklidge",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Rucklidge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Rucklidge"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8027136,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "85efeeb25d8e363606d94c8fadaa922ba9b93a37",
            "isKey": false,
            "numCitedBy": 3913,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "The Hausdorff distance measures the extent to which each point of a model set lies near some point of an image set and vice versa. Thus, this distance can be used to determine the degree of resemblance between two objects that are superimposed on one another. Efficient algorithms for computing the Hausdorff distance between all possible relative positions of a binary image and a model are presented. The focus is primarily on the case in which the model is only allowed to translate with respect to the image. The techniques are extended to rigid motion. The Hausdorff distance computation differs from many other shape comparison methods in that no correspondence between the model and the image is derived. The method is quite tolerant of small position errors such as those that occur with edge detectors and other feature extraction methods. It is shown that the method extends naturally to the problem of comparing a portion of a model against an image. >"
            },
            "slug": "Comparing-Images-Using-the-Hausdorff-Distance-Huttenlocher-Klanderman",
            "title": {
                "fragments": [],
                "text": "Comparing Images Using the Hausdorff Distance"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Efficient algorithms for computing the Hausdorff distance between all possible relative positions of a binary image and a model are presented and it is shown that the method extends naturally to the problem of comparing a portion of a model against an image."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145310607"
                        ],
                        "name": "Jo\u00e3o Maciel",
                        "slug": "Jo\u00e3o-Maciel",
                        "structuredName": {
                            "firstName": "Jo\u00e3o",
                            "lastName": "Maciel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jo\u00e3o Maciel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145848221"
                        ],
                        "name": "J. Costeira",
                        "slug": "J.-Costeira",
                        "structuredName": {
                            "firstName": "Jo\u00e3o",
                            "lastName": "Costeira",
                            "middleNames": [
                                "Paulo"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Costeira"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": "Maciel and Costeira [22]) and solve it using fast-approximate techniques."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 80
                            }
                        ],
                        "text": "We purposely construct this to be an integer quadratic programming problem (cf. Maciel and Costeira [22]) and solve it using fast-approximate techniques.1\nWe address two object recognition problems, multi-class recognition and face detection."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 26
                            }
                        ],
                        "text": "This construction follows [22], and is a standard bound for a quadratic program."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13321667,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9e118bbbfa7756c7050aa8664a6ec73514e81c9a",
            "isKey": true,
            "numCitedBy": 200,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new methodology for reliably solving the correspondence problem between sparse sets of points of two or more images. This is a key step inmost problems of computer vision and, so far, no general method exists to solve it. Our methodology is able to handle most of the commonly used assumptions in a unique formulation, independent of the domain of application and type of features. It performs correspondence and outlier rejection in a single step and achieves global optimality with feasible computation. Feature selection and correspondence are first formulated as an integer optimization problem. This is a blunt formulation, which considers the whole combinatorial space of possible point selections and correspondences. To find its global optimal solution, we build a concave objective function and relax the search domain into its convex-hull. The special structure of this extended problem assures its equivalence to the original one, but it can be optimally solved by efficient algorithms that avoid combinatorial search. This methodology can use any criterion provided it can be translated into cost functions with continuous second derivatives."
            },
            "slug": "A-Global-Solution-to-Sparse-Correspondence-Problems-Maciel-Costeira",
            "title": {
                "fragments": [],
                "text": "A Global Solution to Sparse Correspondence Problems"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A new methodology for reliably solving the correspondence problem between sparse sets of points of two or more images is proposed, which performs correspondence and outlier rejection in a single step and achieves global optimality with feasible computation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39668247"
                        ],
                        "name": "A. Berg",
                        "slug": "A.-Berg",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Berg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 25
                            }
                        ],
                        "text": "The work by Berg & Malik [5] concentrates mainly on this aspect of geometric blur."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12650942,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "af220e04f193ed2a44e89e2cfd45a4e28ab35a52",
            "isKey": false,
            "numCitedBy": 348,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of finding point correspondences in images by way of an approach to template matching that is robust under affine distortions. This is achieved by applying \"geometric blur\" to both the template and the image, resulting in a fall-off in similarity that is close to linear in the norm of the distortion between the template and the image. Results in wide baseline stereo correspondence, face detection, and feature correspondence are included."
            },
            "slug": "Geometric-blur-for-template-matching-Berg-Malik",
            "title": {
                "fragments": [],
                "text": "Geometric blur for template matching"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "This work addresses the problem of finding point correspondences in images by way of an approach to template matching that is robust under affine distortions by applying \"geometric blur\" to both the template and the image, resulting in a fall-off in similarity."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 31
                            }
                        ],
                        "text": "Each 4 Images are from work by Mikolajczyk and Schmid [25] on region of interest operators\nand descriptors for wide-baseline matching.\nsmall block in the figure represents the covariance of all the pixels in one patch of edge map with respect to a particular pixel in the corresponding patch of edge map."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 49
                            }
                        ],
                        "text": "4 Images are from work by Mikolajczyk and Schmid [25] on region of interest operators and descriptors for wide-baseline matching."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2572455,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "69401bfdafab7cde00bb8e5b2f6c28e9d72d8cfb",
            "isKey": false,
            "numCitedBy": 3666,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we compare the performance of descriptors computed for local interest regions, as, for example, extracted by the Harris-Affine detector [Mikolajczyk, K and Schmid, C, 2004]. Many different descriptors have been proposed in the literature. It is unclear which descriptors are more appropriate and how their performance depends on the interest region detector. The descriptors should be distinctive and at the same time robust to changes in viewing conditions as well as to errors of the detector. Our evaluation uses as criterion recall with respect to precision and is carried out for different image transformations. We compare shape context [Belongie, S, et al., April 2002], steerable filters [Freeman, W and Adelson, E, Setp. 1991], PCA-SIFT [Ke, Y and Sukthankar, R, 2004], differential invariants [Koenderink, J and van Doorn, A, 1987], spin images [Lazebnik, S, et al., 2003], SIFT [Lowe, D. G., 1999], complex filters [Schaffalitzky, F and Zisserman, A, 2002], moment invariants [Van Gool, L, et al., 1996], and cross-correlation for different types of interest regions. We also propose an extension of the SIFT descriptor and show that it outperforms the original method. Furthermore, we observe that the ranking of the descriptors is mostly independent of the interest region detector and that the SIFT-based descriptors perform best. Moments and steerable filters show the best performance among the low dimensional descriptors."
            },
            "slug": "A-performance-evaluation-of-local-descriptors-Mikolajczyk-Schmid",
            "title": {
                "fragments": [],
                "text": "A performance evaluation of local descriptors"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "It is observed that the ranking of the descriptors is mostly independent of the interest region detector and that the SIFT-based descriptors perform best and Moments and steerable filters show the best performance among the low dimensional descriptors."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3096453"
                        ],
                        "name": "Y. Lamdan",
                        "slug": "Y.-Lamdan",
                        "structuredName": {
                            "firstName": "Yehezkel",
                            "lastName": "Lamdan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Lamdan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035149"
                        ],
                        "name": "J. Schwartz",
                        "slug": "J.-Schwartz",
                        "structuredName": {
                            "firstName": "Jacob",
                            "lastName": "Schwartz",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756534"
                        ],
                        "name": "H. Wolfson",
                        "slug": "H.-Wolfson",
                        "structuredName": {
                            "firstName": "Haim",
                            "lastName": "Wolfson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wolfson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 21
                            }
                        ],
                        "text": "In geometric hashing [Lamdan et al., 1990], these configurations are used to vote for a model without explicitly solving (1)It is worth noting that this formulation is amenable to various probabilistic interpretations, maximum likelihood estimation for a product of Gaussian models among others."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 26551855,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0578e3d82416b0b15b6aaca19e92e18ea62218b7",
            "isKey": false,
            "numCitedBy": 343,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "New techniques are described for model-based recognition of the objects in 3-D space. The recognition is performed from single gray-scale images taken from unknown viewpoints. The objects in the scene may be overlapping and partially occluded. An efficient matching algorithm, which assumes affine approximation to the prospective viewing transformation, is proposed. The algorithm has an offline model preprocessing (shape representation) phase which is independent of the scene information and a recognition phase based on efficient indexing. It has a straightforward parallel implementation. The algorithm was successfully tested in recognition of industrial objects appearing in composite occluded scenes. >"
            },
            "slug": "Affine-invariant-model-based-object-recognition-Lamdan-Schwartz",
            "title": {
                "fragments": [],
                "text": "Affine invariant model-based object recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An efficient matching algorithm, which assumes affine approximation to the prospective viewing transformation, is proposed and was successfully tested in recognition of industrial objects appearing in composite occluded scenes."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Robotics Autom."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145257017"
                        ],
                        "name": "Anand Rangarajan",
                        "slug": "Anand-Rangarajan",
                        "structuredName": {
                            "firstName": "Anand",
                            "lastName": "Rangarajan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anand Rangarajan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2084269"
                        ],
                        "name": "H. Chui",
                        "slug": "H.-Chui",
                        "structuredName": {
                            "firstName": "Haili",
                            "lastName": "Chui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Chui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705072"
                        ],
                        "name": "E. Mjolsness",
                        "slug": "E.-Mjolsness",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Mjolsness",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Mjolsness"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 162
                            }
                        ],
                        "text": "7 It is possible to construct a pairwise distortion measure based on bending energy which is compatible with the thin plate spline we use alter for interpolation [29], however we are interested in more structured transformations such as rotation and scaling, resulting in the simple distortion measure presented here."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2235226,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d533af383a80478b52c89b5ca1f49eb0776e1689",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Deformable models are central to non-rigid motion analysis, shape matching and non-rigid medical image registration. Spline-based deformations are a very popular class of parameterizations of deformable models and have been heavily used in multiple domains. In a somewhat separate sub-field, weighted graphs are a frequently used object parameterization. Graph matching using weighted graph object parameterizations finds application in a spectrum ranging from rigid pose estimation to deformable object recognition. Here, we demonstrate a hitherto unsuspected relationship between spline-based deformable models and weighted graphs. It turns out that spline parameterizations in the kernel representation can be used to construct equivalent weighted graphs. With this connection established, we envision a cross-fertilization between these two seemingly disparate sub-fields of computer vision."
            },
            "slug": "A-relationship-between-spline-based-deformable-and-Rangarajan-Chui",
            "title": {
                "fragments": [],
                "text": "A relationship between spline-based deformable models and weighted graphs in non-rigid matching"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It turns out that spline parameterizations in the kernel representation can be used to construct equivalent weighted graphs, and a cross-fertilization is envisioned between these two seemingly disparate sub-fields of computer vision."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736489"
                        ],
                        "name": "Fred Rothganger",
                        "slug": "Fred-Rothganger",
                        "structuredName": {
                            "firstName": "Fred",
                            "lastName": "Rothganger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fred Rothganger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749609"
                        ],
                        "name": "S. Lazebnik",
                        "slug": "S.-Lazebnik",
                        "structuredName": {
                            "firstName": "Svetlana",
                            "lastName": "Lazebnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lazebnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 42
                            }
                        ],
                        "text": ", 2004], and to three-dimensional objects [Rothganger et al., 2003]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2046294,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1468251456faef0ef2dfa87937fda2aea0bacb90",
            "isKey": false,
            "numCitedBy": 163,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a representation for three-dimensional objects in terms of affine-invariant image patches and their spatial relationships. Multi-view constraints associated with groups of patches are combined with a normalized representation of their appearance to guide matching and reconstruction, allowing the acquisition of true three-dimensional affine and Euclidean models from multiple images and their recognition in a single photograph taken from an arbitrary viewpoint. The proposed approach does not require a separate segmentation stage and is applicable to cluttered scenes. Preliminary modeling and recognition results are presented."
            },
            "slug": "3D-object-modeling-and-recognition-using-patches-Rothganger-Lazebnik",
            "title": {
                "fragments": [],
                "text": "3D object modeling and recognition using affine-invariant patches and multi-view spatial constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "Multi-view constraints associated with groups of patches are combined with a normalized representation of their appearance to guide matching and reconstruction, allowing the acquisition of true three-dimensional affine and Euclidean models from multiple images and their recognition in a single photograph taken from an arbitrary viewpoint."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4801654"
                        ],
                        "name": "Y. Amit",
                        "slug": "Y.-Amit",
                        "structuredName": {
                            "firstName": "Yali",
                            "lastName": "Amit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Amit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35651617"
                        ],
                        "name": "Kenneth Wilder",
                        "slug": "Kenneth-Wilder",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Wilder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Wilder"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2023689,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9f7c640ea1fe32e017c68005ef5e18969039b3f4",
            "isKey": false,
            "numCitedBy": 209,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a very large family of binary features for two-dimensional shapes. The salient ones for separating particular shapes are determined by inductive learning during the construction of classification trees. There is a feature for every possible geometric arrangement of local topographic codes. The arrangements express coarse constraints on relative angles and distances among the code locations and are nearly invariant to substantial affine and nonlinear deformations. They are also partially ordered, which makes it possible to narrow the search for informative ones at each node of the tree. Different trees correspond to different aspects of shape. They are statistically and weakly dependent due to randomization and are aggregated in a simple way. Adapting the algorithm to a shape family is then fully automatic once training samples are provided. As an illustration, we classified handwritten digits from the NIST database; the error rate was 0.7 percent."
            },
            "slug": "Joint-Induction-of-Shape-Features-and-Tree-Amit-Wilder",
            "title": {
                "fragments": [],
                "text": "Joint Induction of Shape Features and Tree Classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A very large family of binary features for two-dimensional shapes determined by inductive learning during the construction of classification trees is introduced, which makes it possible to narrow the search for informative ones at each node of the tree."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2862374"
                        ],
                        "name": "U. Grenander",
                        "slug": "U.-Grenander",
                        "structuredName": {
                            "firstName": "Ulf",
                            "lastName": "Grenander",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Grenander"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2661433"
                        ],
                        "name": "Yunshyong Chow",
                        "slug": "Yunshyong-Chow",
                        "structuredName": {
                            "firstName": "Yunshyong",
                            "lastName": "Chow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yunshyong Chow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1963249"
                        ],
                        "name": "D. M. Keenan",
                        "slug": "D.-M.-Keenan",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Keenan",
                            "middleNames": [
                                "Macrae"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. M. Keenan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 213
                            }
                        ],
                        "text": "Back in the 1970s, at least three different research groups working in different communities initiated such an approach: in computer vision, Fischler and Elschlager [12], in statistical image analysis, Grenander ([14]and earlier), and in neural networks, von der Malsburg ([17] and earlier)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 195592621,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ac891dff9effb37aeb5800406addc8f71f86b0b6",
            "isKey": false,
            "numCitedBy": 407,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The text develops a global shape model and applies it to the analysis of real pictures acquired with a visible light camera under varying conditions of optical degradation. Computational feasibility of the algorithms derived from this model is achieved by analytical means. The aim is to develop methods for image understanding based on structured restoration, for example automatic detection of abnormalities. The limits of applicability of the algorithms are also traced by making the optical degradations more and more severe until the algorithms no longer succeed in their task. This book is suitable for an advanced undergraduate or graduate seminar in pattern theory, or as an accompanying book for applied probability, computer vision or pattern recognition."
            },
            "slug": "Hands:-A-Pattern-Theoretic-Study-of-Biological-Grenander-Chow",
            "title": {
                "fragments": [],
                "text": "Hands: A Pattern Theoretic Study of Biological Shapes"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "The text develops a global shape model and applies it to the analysis of real pictures acquired with a visible light camera under varying conditions of optical degradation to develop methods for image understanding based on structured restoration, for example automatic detection of abnormalities."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 58
                            }
                        ],
                        "text": "Recent work extends this approach to category recognition [Fergus et al., 2003] [Fei-Fei et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5745749,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62837ab473124ea43cb8d7c6a4b4ee0f6f14e8c5",
            "isKey": false,
            "numCitedBy": 2487,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method to learn and recognize object class models from unlabeled and unsegmented cluttered scenes in a scale invariant manner. Objects are modeled as flexible constellations of parts. A probabilistic representation is used for all aspects of the object: shape, appearance, occlusion and relative scale. An entropy-based feature detector is used to select regions and their scale within the image. In learning the parameters of the scale-invariant object model are estimated. This is done using expectation-maximization in a maximum-likelihood setting. In recognition, this model is used in a Bayesian manner to classify images. The flexible nature of the model is demonstrated by excellent results over a range of datasets including geometrically constrained classes (e.g. faces, cars) and flexible objects (such as animals)."
            },
            "slug": "Object-class-recognition-by-unsupervised-learning-Fergus-Perona",
            "title": {
                "fragments": [],
                "text": "Object class recognition by unsupervised scale-invariant learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The flexible nature of the model is demonstrated by excellent results over a range of datasets including geometrically constrained classes (e.g. faces, cars) and flexible objects (such as animals)."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105170368"
                        ],
                        "name": "Laurence Commissaire divisionnaire",
                        "slug": "Laurence-Commissaire-divisionnaire",
                        "structuredName": {
                            "firstName": "Laurence",
                            "lastName": "divisionnaire",
                            "middleNames": [
                                "Commissaire"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laurence Commissaire divisionnaire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2103199437"
                        ],
                        "name": "Ren\u00e9 Commissaire divisionnaire",
                        "slug": "Ren\u00e9-Commissaire-divisionnaire",
                        "structuredName": {
                            "firstName": "Ren\u00e9",
                            "lastName": "divisionnaire",
                            "middleNames": [
                                "Commissaire"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ren\u00e9 Commissaire divisionnaire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2099430423"
                        ],
                        "name": "St\u00e9phane Journaliste",
                        "slug": "St\u00e9phane-Journaliste",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Journaliste",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "St\u00e9phane Journaliste"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 210,
                                "start": 192
                            }
                        ],
                        "text": "In addition it has been used as a local model of shapes to improve edge detection with mid-level cues, providing the best improvement out of techniques compared on a dataset of natural images [Ren et al., 2005]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5858579,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6ffd7378b4c0baa63d48fdd3bb71bf8e34354af5",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "While mid-level perceptual cues have long been of interest in the human vision community, their role in computer vision has remained limited. In this report, we evaluate several algorithms which make use of mid-level processing in order to improve boundary detection. Our first technique builds a probabilistic model of the relation between prototypical local shapes of edges and the presence or absence of a boundary. We also present a more explicit local model of curvilinear continuity using piecewise linear representations of contours and the Constrained Delaunay Triangulation (CDT). Lastly we consider a global random field on the whole CDT which captures continuity along with the frequency of different of junction types. All three models are trained on human labeled groundtruth. We measure how each model, by incorporating mid-level structure, improves boundary detection. To our knowledge, this is the first time that such cues have been shown quantitatively useful for a large set of natural images. Better boundary detection has immediate application in the problem of object recognition."
            },
            "slug": "Mid-level-Cues-Improve-Boundary-Detection-divisionnaire-divisionnaire",
            "title": {
                "fragments": [],
                "text": "Mid-level Cues Improve Boundary Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This report evaluates several algorithms which make use of mid-level processing in order to improve boundary detection, and is the first time that such cues have been shown quantitatively useful for a large set of natural images."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35146156"
                        ],
                        "name": "M. Lades",
                        "slug": "M.-Lades",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Lades",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lades"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3189439"
                        ],
                        "name": "J. Vorbr\u00fcggen",
                        "slug": "J.-Vorbr\u00fcggen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Vorbr\u00fcggen",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Vorbr\u00fcggen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682548"
                        ],
                        "name": "J. Buhmann",
                        "slug": "J.-Buhmann",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Buhmann",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Buhmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075388397"
                        ],
                        "name": "J. Lange",
                        "slug": "J.-Lange",
                        "structuredName": {
                            "firstName": "J\u00f6rg",
                            "lastName": "Lange",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lange"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3038814"
                        ],
                        "name": "R. W\u00fcrtz",
                        "slug": "R.-W\u00fcrtz",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "W\u00fcrtz",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. W\u00fcrtz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34993891"
                        ],
                        "name": "W. Konen",
                        "slug": "W.-Konen",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Konen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Konen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 277,
                                "start": 273
                            }
                        ],
                        "text": "Back in the 1970s, at least three different research groups working in different communities initiated such an approach: in computer vision, Fischler and Elschlager [12], in statistical image analysis, Grenander ([14]and earlier), and in neural networks, von der Malsburg ([17] and earlier)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1266405,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4fb52984078d75ec5655962dc94dc7848182286b",
            "isKey": false,
            "numCitedBy": 2072,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "An object recognition system based on the dynamic link architecture, an extension to classical artificial neural networks (ANNs), is presented. The dynamic link architecture exploits correlations in the fine-scale temporal structure of cellular signals to group neurons dynamically into higher-order entities. These entities represent a rich structure and can code for high-level objects. To demonstrate the capabilities of the dynamic link architecture, a program was implemented that can recognize human faces and other objects from video images. Memorized objects are represented by sparse graphs, whose vertices are labeled by a multiresolution description in terms of a local power spectrum, and whose edges are labeled by geometrical distance vectors. Object recognition can be formulated as elastic graph matching, which is performed here by stochastic optimization of a matching cost function. The implementation on a transputer network achieved recognition of human faces and office objects from gray-level camera images. The performance of the program is evaluated by a statistical analysis of recognition results from a portrait gallery comprising images of 87 persons. >"
            },
            "slug": "Distortion-Invariant-Object-Recognition-in-the-Link-Lades-Vorbr\u00fcggen",
            "title": {
                "fragments": [],
                "text": "Distortion Invariant Object Recognition in the Dynamic Link Architecture"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "An object recognition system based on the dynamic link architecture, an extension to classical artificial neural networks (ANNs), is presented and the implementation on a transputer network achieved recognition of human faces and office objects from gray-level camera images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Computers"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111328101"
                        ],
                        "name": "Michael Jones",
                        "slug": "Michael-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 51
                            }
                        ],
                        "text": "For faces and cars the class specific detectors of [Viola and Jones, 2001] [Schneiderman and Kanade, 2000] [Schneiderman, 2004] have been very successful."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 235084,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4cb4d685b47001652b29dc41c1b3e786277e7647",
            "isKey": false,
            "numCitedBy": 4016,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a visual object detection framework that is capable of processing images extremely rapidly while achieving high detection rates. There are three key contributions. The first is the introduction of a new image representation called the \u201cIntegral Image\u201d which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features and yields extremely efficient classifiers [4]. The third contribution is a method for combining classifiers in a \u201ccascade\u201d which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. A set of experiments in the domain of face detection are presented. The system yields face detection performance comparable to the best previous systems [16, 11, 14, 10, 1]. Implemented on a conventional desktop, face detection proceeds at 15 frames per second. Author email: fPaul.Viola,Mike.J.Jonesg@compaq.com c Compaq Computer Corporation, 2001 This work may not be copied or reproduced in whole or in part for any commercial purpose. Permission to copy in whole or in part without payment of fee is granted for nonprofit educational and research purposes provided that all such whole or partial copies include the following: a notice that such copying is by permission of the Cambridge Research Laboratory of Compaq Computer Corporation in Cambridge, Massachusetts; an acknowledgment of the authors and individual contributors to the work; and all applicable portions of the copyright notice. Copying, reproducing, or republishing for any other purpose shall require a license with payment of fee to the Cambridge Research Laboratory. All rights reserved. CRL Technical reports are available on the CRL\u2019s web page at http://crl.research.compaq.com. Compaq Computer Corporation Cambridge Research Laboratory One Cambridge Center Cambridge, Massachusetts 02142 USA"
            },
            "slug": "Robust-Real-time-Object-Detection-Viola-Jones",
            "title": {
                "fragments": [],
                "text": "Robust Real-time Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "A visual object detection framework that is capable of processing images extremely rapidly while achieving high detection rates is described, with the introduction of a new image representation called the \u201cIntegral Image\u201d which allows the features used by the detector to be computed very quickly."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111328101"
                        ],
                        "name": "Michael Jones",
                        "slug": "Michael-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2796017,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b09ec0b350f8352bce46a2f5bf7ae97c83a7b9ca",
            "isKey": false,
            "numCitedBy": 11229,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a face detection framework that is capable of processing images extremely rapidly while achieving high detection rates. There are three key contributions. The first is the introduction of a new image representation called the \u201cIntegral Image\u201d which allows the features used by our detector to be computed very quickly. The second is a simple and efficient classifier which is built using the AdaBoost learning algorithm (Freund and Schapire, 1995) to select a small number of critical visual features from a very large set of potential features. The third contribution is a method for combining classifiers in a \u201ccascade\u201d which allows background regions of the image to be quickly discarded while spending more computation on promising face-like regions. A set of experiments in the domain of face detection is presented. The system yields face detection performance comparable to the best previous systems (Sung and Poggio, 1998; Rowley et al., 1998; Schneiderman and Kanade, 2000; Roth et al., 2000). Implemented on a conventional desktop, face detection proceeds at 15 frames per second."
            },
            "slug": "Robust-Real-Time-Face-Detection-Viola-Jones",
            "title": {
                "fragments": [],
                "text": "Robust Real-Time Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new image representation called the \u201cIntegral Image\u201d is introduced which allows the features used by the detector to be computed very quickly and a method for combining classifiers in a \u201ccascade\u201d which allows background regions of the image to be quickly discarded while spending more computation on promising face-like regions."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39668247"
                        ],
                        "name": "A. Berg",
                        "slug": "A.-Berg",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Berg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10771328"
                        ],
                        "name": "Greg Mori",
                        "slug": "Greg-Mori",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Mori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Greg Mori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 104
                            }
                        ],
                        "text": "We originally introduced geometric blur in [Berg and Malik, 2001], and these ideas have been applied in [Efros et al., 2003] (in a temporal instead of spatial domain) and [Berg et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 85
                            }
                        ],
                        "text": "If Ga(x) is a Gaussian (1)As an example of an alternate feature channel, our work in [Efros et al., 2003] uses sparse channels derived from optical flow, followed by \u201cgeometric\u201d blur in the temporal domain."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1350374,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "804d86dd7ab3498266922244e73a88c1add5a6ab",
            "isKey": false,
            "numCitedBy": 1470,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Our goal is to recognize human action at a distance, at resolutions where a whole person may be, say, 30 pixels tall. We introduce a novel motion descriptor based on optical flow measurements in a spatiotemporal volume for each stabilized human figure, and an associated similarity measure to be used in a nearest-neighbor framework. Making use of noisy optical flow measurements is the key challenge, which is addressed by treating optical flow not as precise pixel displacements, but rather as a spatial pattern of noisy measurements which are carefully smoothed and aggregated to form our spatiotemporal motion descriptor. To classify the action being performed by a human figure in a query sequence, we retrieve nearest neighbor(s) from a database of stored, annotated video sequences. We can also use these retrieved exemplars to transfer 2D/3D skeletons onto the figures in the query sequence, as well as two forms of data-based action synthesis \"do as I do\" and \"do as I say\". Results are demonstrated on ballet, tennis as well as football datasets."
            },
            "slug": "Recognizing-action-at-a-distance-Efros-Berg",
            "title": {
                "fragments": [],
                "text": "Recognizing action at a distance"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A novel motion descriptor based on optical flow measurements in a spatiotemporal volume for each stabilized human figure is introduced, and an associated similarity measure to be used in a nearest-neighbor framework is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685538"
                        ],
                        "name": "Tamara L. Berg",
                        "slug": "Tamara-L.-Berg",
                        "structuredName": {
                            "firstName": "Tamara",
                            "lastName": "Berg",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tamara L. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39668247"
                        ],
                        "name": "A. Berg",
                        "slug": "A.-Berg",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Berg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34497462"
                        ],
                        "name": "Jaety Edwards",
                        "slug": "Jaety-Edwards",
                        "structuredName": {
                            "firstName": "Jaety",
                            "lastName": "Edwards",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jaety Edwards"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145854440"
                        ],
                        "name": "M. Maire",
                        "slug": "M.-Maire",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Maire",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Maire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109562930"
                        ],
                        "name": "Ryan White",
                        "slug": "Ryan-White",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "White",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan White"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725303"
                        ],
                        "name": "Y. Teh",
                        "slug": "Y.-Teh",
                        "structuredName": {
                            "firstName": "Yee",
                            "lastName": "Teh",
                            "middleNames": [
                                "Whye"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Teh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1389846455"
                        ],
                        "name": "E. Learned-Miller",
                        "slug": "E.-Learned-Miller",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Learned-Miller",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Learned-Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 71
                            }
                        ],
                        "text": "The face dataset we use is sampled from the very large dataset used in [6] consisting of news photographs collected from yahoo."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 224
                            }
                        ],
                        "text": "With only 20 exemplar faces our generic system provides a ROC curve with slightly better generalization, and slightly worse false detection rate than the quite effective specialized face detector of Mikolajczyk [24] used in [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 59
                            }
                        ],
                        "text": "The face dataset is sampled from the very large dataset in [6] consisting of A."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 71
                            }
                        ],
                        "text": "The face dataset we use is sampled from the very large dataset used in [6] consisting of news photographs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17113597,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "804db97075c4e371177e5bfffe8012de237ae44d",
            "isKey": false,
            "numCitedBy": 278,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We show quite good face clustering is possible for a dataset of inaccurately and ambiguously labelled face images. Our dataset is 44,773 face images, obtained by applying a face finder to approximately half a million captioned news images. This dataset is more realistic than usual face recognition datasets, because it contains faces captured \"in the wild\" in a variety of configurations with respect to the camera, taking a variety of expressions, and under illumination of widely varying color. Each face image is associated with a set of names, automatically extracted from the associated caption. Many, but not all such sets contain the correct name. We cluster face images in appropriate discriminant coordinates. We use a clustering procedure to break ambiguities in labelling and identify incorrectly labelled faces. A merging procedure then identifies variants of names that refer to the same individual. The resulting representation can be used to label faces in news images or to organize news pictures by individuals present. An alternative view of our procedure is as a process that cleans up noisy supervised data. We demonstrate how to use entropy measures to evaluate such procedures."
            },
            "slug": "Names-and-faces-in-the-news-Berg-Berg",
            "title": {
                "fragments": [],
                "text": "Names and faces in the news"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "It is shown quite good face clustering is possible for a dataset of inaccurately and ambiguously labelled face images, obtained by applying a face finder to approximately half a million captioned news images."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266088"
                        ],
                        "name": "T. Leung",
                        "slug": "T.-Leung",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Leung",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Leung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2511655"
                        ],
                        "name": "M. Burl",
                        "slug": "M.-Burl",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Burl",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Burl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 0
                            }
                        ],
                        "text": "[Leung et al., 1995], Schmid and Mohr [Schmid and Mohr, 1997], and Lowe [Lowe, 2004] additionally use gray level information at the keypoints to provide greater discriminative power."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2904067,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0d50d0e2af0b45cc7ed25fe4aa97af900c9bd32a",
            "isKey": false,
            "numCitedBy": 389,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm for locating quasi-frontal views of human faces in cluttered scenes is presented. The algorithm works by coupling a set of local feature detectors with a statistical model of the mutual distances between facial features it is invariant with respect to translation, rotation (in the plane), and scale and can handle partial occlusions of the face. On a challenging database with complicated and varied backgrounds, the algorithm achieved a correct localization rate of 95% in images where the face appeared quasi-frontally.<<ETX>>"
            },
            "slug": "Finding-faces-in-cluttered-scenes-using-random-Leung-Burl",
            "title": {
                "fragments": [],
                "text": "Finding faces in cluttered scenes using random labeled graph matching"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "An algorithm for locating quasi-frontal views of human faces in cluttered scenes is presented and it is found that it is invariant with respect to translation, rotation, and scale and can handle partial occlusions of the face."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144891282"
                        ],
                        "name": "David R. Martin",
                        "slug": "David-R.-Martin",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Martin",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David R. Martin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143800213"
                        ],
                        "name": "Charless C. Fowlkes",
                        "slug": "Charless-C.-Fowlkes",
                        "structuredName": {
                            "firstName": "Charless",
                            "lastName": "Fowlkes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charless C. Fowlkes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 61
                            }
                        ],
                        "text": "The best results are obtained using the boundary detector of [Martin et al., 2004]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 99
                            }
                        ],
                        "text": "Caltech dataset where significant texture and clutter are present, we use the boundary detector of [Martin et al., 2004] at a scale of 2% of the image diagonal."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8165754,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "33a7a59f785ef46091c30c4c85ef88c6bdabab51",
            "isKey": false,
            "numCitedBy": 2381,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "The goal of this work is to accurately detect and localize boundaries in natural scenes using local image measurements. We formulate features that respond to characteristic changes in brightness, color, and texture associated with natural boundaries. In order to combine the information from these features in an optimal way, we train a classifier using human labeled images as ground truth. The output of this classifier provides the posterior probability of a boundary at each image location and orientation. We present precision-recall curves showing that the resulting detector significantly outperforms existing approaches. Our two main results are 1) that cue combination can be performed adequately with a simple linear model and 2) that a proper, explicit treatment of texture is required to detect boundaries in natural images."
            },
            "slug": "Learning-to-detect-natural-image-boundaries-using-Martin-Fowlkes",
            "title": {
                "fragments": [],
                "text": "Learning to detect natural image boundaries using local brightness, color, and texture cues"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The two main results are that cue combination can be performed adequately with a simple linear model and that a proper, explicit treatment of texture is required to detect boundaries in natural images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144160673"
                        ],
                        "name": "Alex Holub",
                        "slug": "Alex-Holub",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Holub",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Holub"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678311"
                        ],
                        "name": "M. Welling",
                        "slug": "M.-Welling",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Welling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Welling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 87
                            }
                        ],
                        "text": "At press, the best results from the Caltech group are 40% using discriminative methods [15]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1093842,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ff412399f71d907cea8b15e3ecde14e249e358cb",
            "isKey": false,
            "numCitedBy": 123,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning models for detecting and classifying object categories is a challenging problem in machine vision. While discriminative approaches to learning and classification have, in principle, superior performance, generative approaches provide many useful features, one of which is the ability to naturally establish explicit correspondence between model components and scene features - this, in turn, allows for the handling of missing data and unsupervised learning in clutter. We explore a hybrid generative/discriminative approach using 'Fisher kernels' by Jaakkola and Haussler (1999) which retains most of the desirable properties of generative methods, while increasing the classification performance through a discriminative setting. Furthermore, we demonstrate how this kernel framework can be used to combine different types of features and models into a single classifier. Our experiments, conducted on a number of popular benchmarks, show strong performance improvements over the corresponding generative approach and are competitive with the best results reported in the literature."
            },
            "slug": "Combining-generative-models-and-Fisher-kernels-for-Holub-Welling",
            "title": {
                "fragments": [],
                "text": "Combining generative models and Fisher kernels for object recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work explores a hybrid generative/discriminative approach using 'Fisher kernels' by Jaakkola and Haussler (1999) which retains most of the desirable properties of generative methods, while increasing the classification performance through a discriminative setting."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144854796"
                        ],
                        "name": "D. Gavrila",
                        "slug": "D.-Gavrila",
                        "structuredName": {
                            "firstName": "Dariu",
                            "lastName": "Gavrila",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gavrila"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762260"
                        ],
                        "name": "V. Philomin",
                        "slug": "V.-Philomin",
                        "structuredName": {
                            "firstName": "Vasanth",
                            "lastName": "Philomin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Philomin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 46
                            }
                        ],
                        "text": "Methods based on Distance Transforms, such as [Gavrila and Philomin, 1999], are similar in spirit and behavior in practice."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 766556,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb490d879512b3d43b267e3ac8931c099a5a2fd3",
            "isKey": false,
            "numCitedBy": 760,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an efficient shape-based object detection method based on Distance Transforms and describes its use for real-time vision on-board vehicles. The method uses a template hierarchy to capture the variety of object shapes; efficient hierarchies can be generated offline for given shape distributions using stochastic optimization techniques (i.e. simulated annealing). Online, matching involves a simultaneous coarse-to-fine approach over the shape hierarchy and over the transformation parameters. Very large speed-up factors are typically obtained when comparing this approach with the equivalent brute-force formulation; we have measured gains of several orders of magnitudes. We present experimental results on the real-time detection of traffic signs and pedestrians from a moving vehicle. Because of the highly time sensitive nature of these vision tasks, we also discuss some hardware-specific implementations of the proposed method as far as SIMD parallelism is concerned."
            },
            "slug": "Real-time-object-detection-for-\"smart\"-vehicles-Gavrila-Philomin",
            "title": {
                "fragments": [],
                "text": "Real-time object detection for \"smart\" vehicles"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "An efficient shape-based object detection method based on Distance Transforms is presented and its use for real-time vision on-board vehicles and some hardware-specific implementations of the proposed method as far as SIMD parallelism is concerned are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085375589"
                        ],
                        "name": "H. Schneiderman",
                        "slug": "H.-Schneiderman",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Schneiderman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Schneiderman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 107
                            }
                        ],
                        "text": "For faces and cars the class specific detectors of [Viola and Jones, 2001] [Schneiderman and Kanade, 2000] [Schneiderman, 2004] have been very successful."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2804322,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "881f2d7b835a7d9dcf33ee2c3e5949c496c4f77b",
            "isKey": false,
            "numCitedBy": 111,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a cascaded method for object detection. This approach uses a novel organization of the first cascade stage called \"feature-centric\" evaluation which re-uses feature evaluations across multiple candidate windows. We minimize the cost of this evaluation through several simplifications: (1) localized lighting normalization, (2) representation of the classifier as an additive model and (3) discrete-valued features. Such a method also incorporates a unique feature representation. The early stages in the cascade use simple fast feature evaluations and the later stages use more complex discriminative features. In particular, we propose features based on sparse coding and ordinal relationships among filter responses. This combination of cascaded feature-centric evaluation with features of increasing complexity achieves both computational efficiency and accuracy. We describe object detection experiments on ten objects including faces and automobiles. These results include 97% recognition at equal error rate on the UIUC image database for car detection."
            },
            "slug": "Feature-centric-evaluation-for-efficient-cascaded-Schneiderman",
            "title": {
                "fragments": [],
                "text": "Feature-centric evaluation for efficient cascaded object detection"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A cascaded method for object detection using a novel organization of the first cascade stage called \"feature-centric\" evaluation which re-uses feature evaluations across multiple candidate windows achieves both computational efficiency and accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2465976"
                        ],
                        "name": "M. Fischler",
                        "slug": "M.-Fischler",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Fischler",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fischler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3394928"
                        ],
                        "name": "R. Elschlager",
                        "slug": "R.-Elschlager",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Elschlager",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Elschlager"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 165
                            }
                        ],
                        "text": "Back in the 1970s, at least three different research groups working in different communities initiated such an approach: in computer vision, Fischler and Elschlager [12], in statistical image analysis, Grenander ([14]and earlier), and in neural networks, von der Malsburg ([17] and earlier)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14554383,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "719da2a0ddd38e78151e1cb2db31703ea8b2e490",
            "isKey": false,
            "numCitedBy": 1527,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "The primary problem dealt with in this paper is the following. Given some description of a visual object, find that object in an actual photograph. Part of the solution to this problem is the specification of a descriptive scheme, and a metric on which to base the decision of \"goodness\" of matching or detection."
            },
            "slug": "The-Representation-and-Matching-of-Pictorial-Fischler-Elschlager",
            "title": {
                "fragments": [],
                "text": "The Representation and Matching of Pictorial Structures"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "The primary problem dealt with in this paper is the specification of a descriptive scheme, and a metric on which to base the decision of \"goodness\" of matching or detection."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computers"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2156851,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aedb8df8f953429ec5a6df99fda5c5d71dbee4ff",
            "isKey": false,
            "numCitedBy": 2326,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-Generative-Visual-Models-from-Few-Training-Fei-Fei-Fergus",
            "title": {
                "fragments": [],
                "text": "Learning Generative Visual Models from Few Training Examples: An Incremental Bayesian Approach Tested on 101 Object Categories"
            },
            "venue": {
                "fragments": [],
                "text": "2004 Conference on Computer Vision and Pattern Recognition Workshop"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085375589"
                        ],
                        "name": "H. Schneiderman",
                        "slug": "H.-Schneiderman",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Schneiderman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Schneiderman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 75
                            }
                        ],
                        "text": "For faces and cars the class specific detectors of [Viola and Jones, 2001] [Schneiderman and Kanade, 2000] [Schneiderman, 2004] have been very successful."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12209481,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3565c5a65842f26091578b9d71d496cc1561239d",
            "isKey": false,
            "numCitedBy": 1292,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe a statistical method for 3D object detection. We represent the statistics of both object appearance and \"non-object\" appearance using a product of histograms. Each histogram represents the joint statistics of a subset of wavelet coefficients and their position on the object. Our approach is to use many such histograms representing a wide variety of visual attributes. Using this method, we have developed the first algorithm that can reliably detect human faces with out-of-plane rotation and the first algorithm that can reliably detect passenger cars over a wide range of viewpoints."
            },
            "slug": "A-statistical-method-for-3D-object-detection-to-and-Schneiderman-Kanade",
            "title": {
                "fragments": [],
                "text": "A statistical method for 3D object detection applied to faces and cars"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Using this method, this work has developed the first algorithm that can reliably detect human faces with out-of-plane rotation and the first algorithms thatCan reliably detect passenger cars over a wide range of viewpoints."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10771328"
                        ],
                        "name": "Greg Mori",
                        "slug": "Greg-Mori",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Mori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Greg Mori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 265,
                                "start": 246
                            }
                        ],
                        "text": "In addition the mathematical development showing that geometric blur is a method to obtain robustness to small affine transforms has been applied to understanding of a shape contexts, and has inspired some of the generalization of shape contexts [Mori et al., 2005]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 58433,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "83c26bdfa1981b1bd8632258d4efedf3ba06910f",
            "isKey": false,
            "numCitedBy": 439,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "We demonstrate that shape contexts can be used to quickly prune a search for similar shapes. We present two algorithms for rapid shape retrieval: representative shape contexts, performing comparisons based on a small number of shape contexts, and shapemes, using vector quantization in the space of shape contexts to obtain prototypical shape pieces."
            },
            "slug": "Efficient-shape-matching-using-shape-contexts-Mori-Belongie",
            "title": {
                "fragments": [],
                "text": "Efficient shape matching using shape contexts"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "It is demonstrated that shape contexts can be used to quickly prune a search for similar shapes, and shapemes are used, using vector quantization in the space of shape contexts to obtain prototypical shape pieces."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145299933"
                        ],
                        "name": "R. Mohr",
                        "slug": "R.-Mohr",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Mohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mohr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 325871,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "49fcd806450d947e56c82ef2b438ad9c484069dc",
            "isKey": false,
            "numCitedBy": 1792,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of retrieving images from large image databases. The method is based on local grayvalue invariants which are computed at automatically detected interest points. A voting algorithm and semilocal constraints make retrieval possible. Indexing allows for efficient retrieval from a database of more than 1,000 images. Experimental results show correct retrieval in the case of partial visibility, similarity transformations, extraneous features, and small perspective deformations."
            },
            "slug": "Local-Grayvalue-Invariants-for-Image-Retrieval-Schmid-Mohr",
            "title": {
                "fragments": [],
                "text": "Local Grayvalue Invariants for Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "This paper addresses the problem of retrieving images from large image databases with a method based on local grayvalue invariants which are computed at automatically detected interest points and allows for efficient retrieval from a database of more than 1,000 images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2331666"
                        ],
                        "name": "A. Slater",
                        "slug": "A.-Slater",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Slater",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Slater"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6271242"
                        ],
                        "name": "V. Morison",
                        "slug": "V.-Morison",
                        "structuredName": {
                            "firstName": "Victoria",
                            "lastName": "Morison",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Morison"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 136
                            }
                        ],
                        "text": "Studies of \u201cshape constancy\u201d indicate that small variations in viewing angle are usually discounted by human observers [Thouless, 1931] [Slater and Morison, 1985]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 45136303,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "e1b600acfaf5db66283b9af3ce3b6b1f28933016",
            "isKey": false,
            "numCitedBy": 126,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Two experiments are described the object of which was to investigate whether perception of shape at birth is determined solely by proximal (retinal) stimulation, or whether newborn babies have the ability to perceive objective, real shape across changes in slant. In experiment 1 looking at (ie preference for) one stimulus, a square, when paired with either of two trapeziums, was found to change in a consistent manner with changes in slant, indicating that these changes in stimulation are detected and can cause considerable changes in looking behaviour. In experiment 2 newborns were desensitized to changes in slant during familiarization trials, and subsequently strongly preferred a different shape to the familiarized shape in a new orientation. This suggests that the real shape had been perceived as invariant across the retinal changes caused by the changes in slant, and further suggests that shape constancy is an organizing feature of perception which is present at birth."
            },
            "slug": "Shape-Constancy-and-Slant-Perception-at-Birth-Slater-Morison",
            "title": {
                "fragments": [],
                "text": "Shape Constancy and Slant Perception at Birth"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "In experiment 2 newborns were desensitized to changes in slant during familiarization trials, and subsequently strongly preferred a different shape to the familiarized shape in a new orientation, suggesting that shape constancy is an organizing feature of perception which is present at birth."
            },
            "venue": {
                "fragments": [],
                "text": "Perception"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056417995"
                        ],
                        "name": "K. Murphy",
                        "slug": "K.-Murphy",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Murphy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Murphy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 32
                            }
                        ],
                        "text": "Recent work on sharing features [Torralba et al., 2004] has 62"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11194336,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "42de22c119f25d303032396b8f7d962f62d6498b",
            "isKey": false,
            "numCitedBy": 441,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of detecting a large number of different object classes in cluttered scenes. Traditional approaches require applying a battery of different classifiers to the image, which can be slow and require much training data. We present a multi-class boosting procedure (joint boosting) that reduces both the computational and sample complexity, by finding common features that can be shared across the classes. The detectors for each class are trained jointly, rather than independently. For a given performance level, the total number of features required is observed to scale approximately logarithmically with the number of classes. In addition, we find that the features selected by independently trained classifiers are often specific to the class, whereas the features selected by the jointly trained classifiers are more generic features, such as lines and edges."
            },
            "slug": "Sharing-features:-efficient-boosting-procedures-for-Torralba-Murphy",
            "title": {
                "fragments": [],
                "text": "Sharing features: efficient boosting procedures for multiclass object detection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A multi-class boosting procedure (joint boosting) is presented that reduces both the computational and sample complexity, by finding common features that can be shared across the classes."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38361753"
                        ],
                        "name": "M. Concetta Morrone",
                        "slug": "M.-Concetta-Morrone",
                        "structuredName": {
                            "firstName": "Maria",
                            "lastName": "Concetta Morrone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Concetta Morrone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2299127"
                        ],
                        "name": "D. Burr",
                        "slug": "D.-Burr",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Burr",
                            "middleNames": [
                                "Charles"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Burr"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 54
                            }
                        ],
                        "text": "derivative of Gaussian filters is used for comparison [27]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 32945737,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "992f61cd4b86fd5f1415308cacda7cdc0280511b",
            "isKey": false,
            "numCitedBy": 741,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a simple and biologically plausible model of how mammalian visual systems could detect and identify features in an image. We suggest that the points in a waveform that have unique perceptual significance as \u2018lines\u2019 and \u2018edges\u2019 are the points where the Fourier components of the waveform come into phase with each other. At these points \u2018local energy\u2019 is maximal. Local energy is defined as the square root of the sum of the squared response of sets of matched filters, of identical amplitude spectrum but differing in phase spectrum by 90\u00b0: one filter type has an even-symmetric line-spread function, the other an odd-symmetric line-spread function. For a line the main contribution to the local energy peak is in the output of the even-symmetric filters, whereas for edges it is in the output of the odd-symmetric filters. If both filter types respond at the peak of local energy, both edges and lines are seen, either simultaneously or alternating in time. The model was tested with a series of images, and shown to predict well the position of perceived features and the organization of the images."
            },
            "slug": "Feature-detection-in-human-vision:-a-energy-model-Morrone-Burr",
            "title": {
                "fragments": [],
                "text": "Feature detection in human vision: a phase-dependent energy model"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A simple and biologically plausible model of how mammalian visual systems could detect and identify features in an image is presented and it is suggested that the points in a waveform that have unique perceptual significance as \u2018lines\u2019 and \u2018edges\u2019 are the points where the Fourier components of the waveform come into phase with each other."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Royal Society of London. Series B. Biological Sciences"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743045"
                        ],
                        "name": "S. Ullman",
                        "slug": "S.-Ullman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Ullman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ullman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398995671"
                        ],
                        "name": "Michel Vidal-Naquet",
                        "slug": "Michel-Vidal-Naquet",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Vidal-Naquet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michel Vidal-Naquet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35195550"
                        ],
                        "name": "E. Sali",
                        "slug": "E.-Sali",
                        "structuredName": {
                            "firstName": "Erez",
                            "lastName": "Sali",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Sali"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 154
                            }
                        ],
                        "text": "One can do without extracting either keypoints or edge points: Ullman et al propose using intermediate complexity features, a collection of image patches,[Ullman et al., 2002]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 205441432,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d52be22dc0033293d335b6dc5cf3e3588c1fc0bc",
            "isKey": false,
            "numCitedBy": 655,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "The human visual system analyzes shapes and objects in a series of stages in which stimulus features of increasing complexity are extracted and analyzed. The first stages use simple local features, and the image is subsequently represented in terms of larger and more complex features. These include features of intermediate complexity and partial object views. The nature and use of these higher-order representations remains an open question in the study of visual processing by the primate cortex. Here we show that intermediate complexity (IC) features are optimal for the basic visual task of classification. Moderately complex features are more informative for classification than very simple or very complex ones, and so they emerge naturally by the simple coding principle of information maximization with respect to a class of images. Our findings suggest a specific role for IC features in visual processing and a principle for their extraction."
            },
            "slug": "Visual-features-of-intermediate-complexity-and-use-Ullman-Vidal-Naquet",
            "title": {
                "fragments": [],
                "text": "Visual features of intermediate complexity and their use in classification"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that intermediate complexity (IC) features are optimal for the basic visual task of classification and suggest a specific role for IC features in visual processing and a principle for their extraction."
            },
            "venue": {
                "fragments": [],
                "text": "Nature Neuroscience"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644050191"
                        ],
                        "name": "G. LoweDavid",
                        "slug": "G.-LoweDavid",
                        "structuredName": {
                            "firstName": "G",
                            "lastName": "LoweDavid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. LoweDavid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 217
                            }
                        ],
                        "text": "nothing special about these points \u2013 they are not required to be keypoints such as those found using a Harris/Forstner type of operator or scale-space extrema of a Laplacian of Gaussian operator, such as used by Lowe [21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 233,
                                "start": 229
                            }
                        ],
                        "text": "Note that there is\nnothing special about these points \u2013 they are not required to be keypoints such as those found using a Harris/Forstner type of operator or scale-space extrema of a Laplacian of Gaussian operator, such as used by Lowe [21]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 174065,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4cab9c4b571761203ed4c3a4c5a07dd615f57a91",
            "isKey": false,
            "numCitedBy": 25506,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are ..."
            },
            "slug": "Distinctive-Image-Features-from-Scale-Invariant-LoweDavid",
            "title": {
                "fragments": [],
                "text": "Distinctive Image Features from Scale-Invariant Keypoints"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2173059291"
                        ],
                        "name": "Leon N Piotrowski",
                        "slug": "Leon-N-Piotrowski",
                        "structuredName": {
                            "firstName": "Leon",
                            "lastName": "Piotrowski",
                            "middleNames": [
                                "N"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Leon N Piotrowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4800025"
                        ],
                        "name": "F. Campbell",
                        "slug": "F.-Campbell",
                        "structuredName": {
                            "firstName": "Fergus",
                            "lastName": "Campbell",
                            "middleNames": [
                                "William"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Campbell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 269,
                                "start": 238
                            }
                        ],
                        "text": "Using the location and orientation of edge-like structures in images is consistent with studies showing that the location of an edge, or phase, contains a great deal of the information in an image, at least as far as humans are concerned [Piotrowski and Campbell, 1982]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 42378919,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "428d2f1c12ac1d4bcac4b64b18bee2b428e35fb5",
            "isKey": false,
            "numCitedBy": 177,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "To establish how little information the human visual system requires for recognition, common objects were digitally manipulated in the Fourier domain. The results demonstrate that it is not only possible, but also quite efficient, for a (biological) visual system to exist with very few phase relationships among the component spatial frequencies of the (retinal) image. A visual example is then presented which illustrates how certain phase relationships can hinder, or completely eliminate, the recognition of visual scenes."
            },
            "slug": "A-Demonstration-of-the-Visual-Importance-and-of-and-Piotrowski-Campbell",
            "title": {
                "fragments": [],
                "text": "A Demonstration of the Visual Importance and Flexibility of Spatial-Frequency Amplitude and Phase"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "To establish how little information the human visual system requires for recognition, common objects were digitally manipulated in the Fourier domain to demonstrate that it is not only possible, but also quite efficient, for a (biological) visual system to exist with very few phase relationships among the component spatial frequencies of the (retinal) image."
            },
            "venue": {
                "fragments": [],
                "text": "Perception"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 215,
                                "start": 211
                            }
                        ],
                        "text": "With only 20 exemplar faces our generic system provides a ROC curve with slightly better generalization, and slightly worse false detection rate than the quite effective specialized face detector of Mikolajczyk [24] used in [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 31
                            }
                        ],
                        "text": "Each 4 Images are from work by Mikolajczyk and Schmid [25] on region of interest operators\nand descriptors for wide-baseline matching.\nsmall block in the figure represents the covariance of all the pixels in one patch of edge map with respect to a particular pixel in the corresponding patch of edge map."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 60
                            }
                        ],
                        "text": "A comparison of the ROC curves for our detector and that of [24] is found in Figure 12."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 91
                            }
                        ],
                        "text": "The test set was selected randomly from the remaining images on which the face detector of [24] found at least one 86\u00d786 pixels or larger face."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10531237,
            "fieldsOfStudy": [
                "Philosophy",
                "Computer Science"
            ],
            "id": "81e0b2275413d77ca21edc0442393d298db804b1",
            "isKey": true,
            "numCitedBy": 91,
            "numCiting": 136,
            "paperAbstract": {
                "fragments": [],
                "text": "Une des approches dominantes pour la reconnaissance d'objets est basee sur les caracteristiques locales. La methode utilise la description locale calculee au voisinage de points d'interet. La detection de points d'interet est une premiere etape dans le processus de la mise en correspondance et de la reconnaissance. L'approche par apparences locales a permis d'ameliorer et d'accelerer considerablement la recherche d'images dans des bases de donnees. Dans cette these, nous proposons une nouvelle approche pour la detection de points caracteristiques d'une image. Cette approche est invariante aux transformations geometriques et photometriques, qui apparaissent frequemment entre les images prises dans des conditions differentes. Nous nous concentrons sur le probleme d'invariance aux transformations affines. Cette transformation est particulierement importante parce qu'elle permet de s'affranchir des problemes de changements perspectives. Les approches precedentes apportent des solutions partielles, car certains parametres de points d'interet ne sont pas estimes de facon invariante aux changements affines. Nous avons propose une solution generique a ces problemes. Notre methode est reellement invariante aux transformations affines, y compris aux changements d'echelle importants. Les images sont caracterisees par des ensembles de descripteurs calcules en des points caracteristiques detectes automatiquement. Une mesure de ressemblance permet d'etablir des correspondances entre les points. Ces correspondances sont ensuite utilisees pour calculer la geometrie qui lie les images. Dans le contexte de la recherche d'images les descripteurs sont utilises pour retrouver des points similaires dans la base et par consequent des images similaires aux images requetes. Les resultats experimentaux pour la mise en correspondance et la recherche d'images montrent que notre approche est tres robuste et efficace meme dans les cas de changements importants. Plusieurs etudes comparatives effectuees dans cette these montrent l'avantage de cette methode par rapport aux approches existantes presentees recemment dans la litterature."
            },
            "slug": "Detection-of-local-features-invariant-to-affines-Mikolajczyk",
            "title": {
                "fragments": [],
                "text": "Detection of local features invariant to affines transformations"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "Une des approches dominantes pour the reconnaissance d'objets est basee sur les caracteristiques locales, y compris aux changements d'echelle importants, que notre approche est tres robuste and efficace meme dans les cas of changements importants."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39535769"
                        ],
                        "name": "M. F.",
                        "slug": "M.-F.",
                        "structuredName": {
                            "firstName": "M",
                            "lastName": "F.",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. F."
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1455573056"
                        ],
                        "name": "Pemikiran Karl Marx",
                        "slug": "Pemikiran-Karl-Marx",
                        "structuredName": {
                            "firstName": "Pemikiran",
                            "lastName": "Marx",
                            "middleNames": [
                                "Karl"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pemikiran Karl Marx"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1455403858"
                        ],
                        "name": "Dari Sosialis",
                        "slug": "Dari-Sosialis",
                        "structuredName": {
                            "firstName": "Dari",
                            "lastName": "Sosialis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dari Sosialis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1455151864"
                        ],
                        "name": "Utopis ke Perselisihan",
                        "slug": "Utopis-ke-Perselisihan",
                        "structuredName": {
                            "firstName": "Utopis",
                            "lastName": "Perselisihan",
                            "middleNames": [
                                "ke"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Utopis ke Perselisihan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 208786267,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "f86c0a4caae451dc8ba319013e30f14987fa5b26",
            "isKey": false,
            "numCitedBy": 9902,
            "numCiting": 123,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Bibliography-M.-Marx",
            "title": {
                "fragments": [],
                "text": "Bibliography"
            },
            "venue": {
                "fragments": [],
                "text": "Experimental Gerontology"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40018119"
                        ],
                        "name": "R. Tootell",
                        "slug": "R.-Tootell",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Tootell",
                            "middleNames": [
                                "B.",
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Tootell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47660376"
                        ],
                        "name": "M. Silverman",
                        "slug": "M.-Silverman",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Silverman",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Silverman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4602910"
                        ],
                        "name": "E. Switkes",
                        "slug": "E.-Switkes",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Switkes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Switkes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2087168416"
                        ],
                        "name": "R. D. De Valois",
                        "slug": "R.-D.-De-Valois",
                        "structuredName": {
                            "firstName": "R",
                            "lastName": "De Valois",
                            "middleNames": [
                                "L"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. D. De Valois"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 197
                            }
                        ],
                        "text": "In fact using edge-like features and the spatially varying geometric blur fits well with what is known about the log polar structure of retinotopic maps in the first part of the visual cortex (V1) [Tootell et al., 1982]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13971727,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "1573dd9596eb7276f94c2bbbfa731c806aaa7617",
            "isKey": false,
            "numCitedBy": 454,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We have anatomically analyzed retinotopic organization using the 14C-labeled 2-deoxy-D-glucose method. The method has several advantages over conventional electrophysiological mapping techniques. In the striate cortex, the anatomical substrate for retinotopic organization is surprisingly well ordered, and there seems to be a systematic relationship between ocular dominance strips and cortical magnification. The 2-deoxyglucose maps in this area appear to be largely uninfluenced by known differences in long-term metabolic activity. This method should prove useful in analyzing retinotopic organization in various visual areas of the brain and in different species."
            },
            "slug": "Deoxyglucose-analysis-of-retinotopic-organization-Tootell-Silverman",
            "title": {
                "fragments": [],
                "text": "Deoxyglucose analysis of retinotopic organization in primate striate cortex."
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "The 14C-labeled 2-deoxy-D-glucose method has several advantages over conventional electrophysiological mapping techniques and should prove useful in analyzing retinotopic organization in various visual areas of the brain and in different species."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40632624"
                        ],
                        "name": "W. Peddie",
                        "slug": "W.-Peddie",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Peddie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Peddie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 119
                            }
                        ],
                        "text": "Studies of \u201cshape constancy\u201d indicate that small variations in viewing angle are usually discounted by human observers [Thouless, 1931] [Slater and Morison, 1985]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4074235,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "8a4c52b41af5d549f54b95657479b501e51cde7b",
            "isKey": false,
            "numCitedBy": 108,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "DR. THOULESS's interesting article in NATURE of February 25 on this subject is of special interest at the present time when physicists, physiologists, and psychologists are co-operating in the solution of problems regarding vision. The terminology and modes of expression are not unusually quite different in the respective branches of investigation, and this makes it very imperative that there should be full mutual discussion regarding the statements involved so as to avoid the possibility of misunderstanding."
            },
            "slug": "Phenomenal-Regression-to-the-Real-Object-Peddie",
            "title": {
                "fragments": [],
                "text": "Phenomenal Regression to the Real Object"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1933
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 25
                            }
                        ],
                        "text": ", 1995], Schmid and Mohr [Schmid and Mohr, 1997], and Lowe [Lowe, 2004] additionally use gray level information at the keypoints to provide greater discriminative power."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "19(5):530\u2013535"
            },
            "venue": {
                "fragments": [],
                "text": "May"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Pers. comm"
            },
            "venue": {
                "fragments": [],
                "text": "Pers. comm"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 92
                            }
                        ],
                        "text": "Extend the correspondence on m points to a smooth map using a regularized thin plate spline [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A thin plate spline method for mapping curves into curves in two dimensions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 124
                            }
                        ],
                        "text": "Also studies of the ambiguity of parts without context support an approach where multiple parts are combined in recognition [Palmer, 1975]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Visual perception and world knowledge: Notes on a model of sensory cognitive interaction"
            },
            "venue": {
                "fragments": [],
                "text": "D. A. Norman and D. E. Rumelhart, editors, Explorations in cognition, page 279307. San Francisco: W. H. Freeman"
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 215
                            }
                        ],
                        "text": "The core idea that related but not identical shapes can be deformed into alignment using simple coordinate transformations dates even further back, at least to D\u2019Arcy Thompson, in the 1910\u2019s with On Growth and Form [34]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On Growth and Form. Dover, 1917"
            },
            "venue": {
                "fragments": [],
                "text": "Shape Matching and Object Recognition"
            },
            "year": 1917
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 145
                            }
                        ],
                        "text": "2 Additional details and derivations concerning geometric blur, including motivation as an approximation to Bayesian estimation, can be found in [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 105
                            }
                        ],
                        "text": "because the choice of interest point operator effects the type of variation the descriptor must tolerate [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Shape Matching and Object Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "PhD thesis, U.C. Berkeley,"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 127
                            }
                        ],
                        "text": "At the level of object recognition, the ideas of recognition by prototypes [Rosch, 1973] (and later) and of prototypical views [Palmer et al., 1981] are consistent with some of the simple recognition strategies presented in this work based on exemplar images."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Canonical perspective and the perception of objects"
            },
            "venue": {
                "fragments": [],
                "text": "J. Long and A. Baddeley, editors, Attention and Performance, volume 9, pages 135\u2013151. Hillsdale, NJ: Erlbaum"
            },
            "year": 1981
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 75
                            }
                        ],
                        "text": "At the level of object recognition, the ideas of recognition by prototypes [Rosch, 1973] (and later) and of prototypical views [Palmer et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Natural categories"
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive Psychology, 4(3):328\u2013350"
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 50
                            }
                        ],
                        "text": "developed methods based on the Hausdorff distance [Huttenlocher et al., 1993]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "15(9):850\u2013 863"
            },
            "venue": {
                "fragments": [],
                "text": "Sept."
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning generative visual models from few training examples: an incremental bayesian approach tested on BIBLIOGRAPHY 101 object categories"
            },
            "venue": {
                "fragments": [],
                "text": "CVPR, Workshop on Generative-Model Based Vision"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 36
                            }
                        ],
                        "text": "Texture Baseline Recently Hao Zhang [Zhang, 2005] and others have conducted similar experiments using texture resulting in recognition rates of 17%."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 85
                            }
                        ],
                        "text": "Recent work on learning local classifiers to improve nearest neighbor classification [Zhang, 2005] improves the results on texture from 17% to 25%, and for the second geometric blur method from 40% to 56%."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Pers"
            },
            "venue": {
                "fragments": [],
                "text": "comm., Dec."
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 0
                            }
                        ],
                        "text": "[Amit et al., 1997] train decision trees for recognition by learning discriminative spatial configurations of keypoints."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "19(11):1300\u20131305"
            },
            "venue": {
                "fragments": [],
                "text": "November"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 271,
                                "start": 263
                            }
                        ],
                        "text": "Back in the 1970s, at least three different research groups working in different communities initiated such an approach: in computer vision, Fischler and Elschlager [12], in statistical image analysis, Grenander ([14]and earlier), and in neural networks, von der Malsburg ([17] and earlier)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 64
                            }
                        ],
                        "text": ", 1991] (and earlier), and in neural networks, von der Malsburg [Lades et al., 1993] (and earlier)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "42(3):300\u2013311"
            },
            "venue": {
                "fragments": [],
                "text": "March"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Caltech 101 dataset www.vision.caltech.edu/feifeili/101 ObjectCategories"
            },
            "venue": {
                "fragments": [],
                "text": "Caltech 101 dataset www.vision.caltech.edu/feifeili/101 ObjectCategories"
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 24,
            "methodology": 19,
            "result": 3
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 55,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/Shape-Matching-and-Object-Recognition-Berg-Malik/cc1d7345c22c17735222762ba8bac4ffa348b85d?sort=total-citations"
}