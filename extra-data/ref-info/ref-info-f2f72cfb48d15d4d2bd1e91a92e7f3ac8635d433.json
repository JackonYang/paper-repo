{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 35
                            }
                        ],
                        "text": ", 2011) and recursive autoencoders (Bottou, 2011; Socher et al., 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 145
                            }
                        ],
                        "text": "The architecture of our system is also related to recent work on gated models (Sutskever et al., 2011) and recursive autoencoders (Bottou, 2011; Socher et al., 2011)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9923502,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "81b3b3fe994a9eda6d3f9d2149aa4492d1933975",
            "isKey": false,
            "numCitedBy": 316,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Natural language parsing has typically been done with small sets of discrete categories such as NP and VP, but this representation does not capture the full syntactic nor semantic richness of linguistic phrases, and attempts to improve on this by lexicalizing phrases only partly address the problem at the cost of huge feature spaces and sparseness. To address this, we introduce a recursive neural network architecture for jointly parsing natural language and learning vector space representations for variable-sized inputs. At the core of our architecture are context-sensitive recursive neural networks (CRNN). These networks can induce distributed feature representations for unseen phrases and provide syntactic information to accurately predict phrase structure trees. Most excitingly, the representation of each phrase also captures semantic information: For instance, the phrases \u201cdecline to comment\u201d and \u201cwould not disclose the terms\u201d are close by in the induced embedding space. Our current system achieves an unlabeled bracketing F-measure of 92.1% on the Wall Street Journal dataset for sentences up to length 15."
            },
            "slug": "Learning-Continuous-Phrase-Representations-and-with-Socher-Manning",
            "title": {
                "fragments": [],
                "text": "Learning Continuous Phrase Representations and Syntactic Parsing with Recursive Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A recursive neural network architecture for jointly parsing natural language and learning vector space representations for variable-sized inputs and captures semantic information: For instance, the phrases \u201cdecline to comment\u201d and \u201cwould not disclose the terms\u201d are close by in the induced embedding space."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713934"
                        ],
                        "name": "Antoine Bordes",
                        "slug": "Antoine-Bordes",
                        "structuredName": {
                            "firstName": "Antoine",
                            "lastName": "Bordes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antoine Bordes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939803"
                        ],
                        "name": "Ronan Collobert",
                        "slug": "Ronan-Collobert",
                        "structuredName": {
                            "firstName": "Ronan",
                            "lastName": "Collobert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronan Collobert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 90
                            }
                        ],
                        "text": "Columns 2 and 3 of Table 1 present the comparative results, together with performance of (Bordes et al., 2011) (SE)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 9
                            }
                        ],
                        "text": "However, Bordes et al. (2011) stack a Kernel Density Estimator (KDE) on top of their structured embeddings to improve prediction."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 9
                            }
                        ],
                        "text": "Finally, Bordes et al. (2011) describe an entity embedding model for knowledge acquisition: given relation\ntraining triplets, they also measure how well the model generalizes to new relations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 715463,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1f4a4769e4d2fb846e59c2f185e0377190739f18",
            "isKey": false,
            "numCitedBy": 754,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Many Knowledge Bases (KBs) are now readily available and encompass colossal quantities of information thanks to either a long-term funding effort (e.g. WordNet, OpenCyc) or a collaborative process (e.g. Freebase, DBpedia). However, each of them is based on a different rigid symbolic framework which makes it hard to use their data in other systems. It is unfortunate because such rich structured knowledge might lead to a huge leap forward in many other areas of AI like natural language processing (word-sense disambiguation, natural language understanding, ...), vision (scene classification, image semantic annotation, ...) or collaborative filtering. In this paper, we present a learning process based on an innovative neural network architecture designed to embed any of these symbolic representations into a more flexible continuous vector space in which the original knowledge is kept and enhanced. These learnt embeddings would allow data from any KB to be easily used in recent machine learning methods for prediction and information retrieval. We illustrate our method on WordNet and Freebase and also present a way to adapt it to knowledge extraction from raw text."
            },
            "slug": "Learning-Structured-Embeddings-of-Knowledge-Bases-Bordes-Weston",
            "title": {
                "fragments": [],
                "text": "Learning Structured Embeddings of Knowledge Bases"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A learning process based on an innovative neural network architecture designed to embed any of these symbolic representations into a more flexible continuous vector space in which the original knowledge is kept and enhanced would allow data from any KB to be easily used in recent machine learning methods for prediction and information retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143696281"
                        ],
                        "name": "David Mart\u00ednez",
                        "slug": "David-Mart\u00ednez",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mart\u00ednez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Mart\u00ednez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715983"
                        ],
                        "name": "Oier Lopez de Lacalle",
                        "slug": "Oier-Lopez-de-Lacalle",
                        "structuredName": {
                            "firstName": "Oier",
                            "lastName": "Lacalle",
                            "middleNames": [
                                "Lopez",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oier Lopez de Lacalle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733049"
                        ],
                        "name": "Eneko Agirre",
                        "slug": "Eneko-Agirre",
                        "structuredName": {
                            "firstName": "Eneko",
                            "lastName": "Agirre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eneko Agirre"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 129
                            }
                        ],
                        "text": "Finally, several previous works have targeted to improve WSD by using extra-knowledge by either automatically acquiring examples (Martinez et al., 2008) or by connecting different knowledge bases (Havasi et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 130
                            }
                        ],
                        "text": "Finally, several previous works have targeted to improve WSD by using extra-knowledge by either automatically acquiring examples (Martinez et al., 2008) or by connecting different knowledge bases (Havasi et al., 2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2117914,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "12f17c64eb20f051552295d2c928f036f5b8163b",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "This article focuses on Word Sense Disambiguation (WSD), which is a Natural Language Processing task that is thought to be important for many Language Technology applications, such as Information Retrieval, Information Extraction, or Machine Translation. One of the main issues preventing the deployment of WSD technology is the lack of training examples for Machine Learning systems, also known as the Knowledge Acquisition Bottleneck. A method which has been shown to work for small samples of words is the automatic acquisition of examples. We have previously shown that one of the most promising example acquisition methods scales up and produces a freely available database of 150 million examples from Web snippets for all polysemous nouns in WordNet. This paper focuses on the issues that arise when using those examples, all alone or in addition to manually tagged examples, to train a supervised WSD system for all nouns. The extensive evaluation on both lexical-sample and all-words Senseval benchmarks shows that we are able to improve over commonly used baselines and to achieve top-rank performance. The good use of the prior distributions from the senses proved to be a crucial factor."
            },
            "slug": "On-the-Use-of-Automatically-Acquired-Examples-for-Mart\u00ednez-Lacalle",
            "title": {
                "fragments": [],
                "text": "On the Use of Automatically Acquired Examples for All-Nouns Word Sense Disambiguation"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper focuses on the issues that arise when using those examples, all alone or in addition to manually tagged examples, to train a supervised WSD system for all nouns, and improves over commonly used baselines and to achieve top-rank performance."
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif. Intell. Res."
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110920850"
                        ],
                        "name": "Fei Wu",
                        "slug": "Fei-Wu",
                        "structuredName": {
                            "firstName": "Fei",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fei Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780531"
                        ],
                        "name": "Daniel S. Weld",
                        "slug": "Daniel-S.-Weld",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Weld",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel S. Weld"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 111
                            }
                        ],
                        "text": "Automatic information extraction is the topic of many models and demos (Snow et al., 2006; Yates et al., 2007; Wu and Weld, 2010; Suchanek et al., 2008) but none of them relies on a joint embedding model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15015161,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "233d861338cfcd479b1d21897453fcc66418d5e1",
            "isKey": false,
            "numCitedBy": 648,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Information-extraction (IE) systems seek to distill semantic relations from natural-language text, but most systems use supervised learning of relation-specific examples and are thus limited by the availability of training data. Open IE systems such as TextRunner, on the other hand, aim to handle the unbounded number of relations found on the Web. But how well can these open systems perform? \n \nThis paper presents WOE, an open IE system which improves dramatically on TextRunner's precision and recall. The key to WOE's performance is a novel form of self-supervised learning for open extractors -- using heuristic matches between Wikipedia infobox attribute values and corresponding sentences to construct training data. Like TextRunner, WOE's extractor eschews lexicalized features and handles an unbounded set of semantic relations. WOE can operate in two modes: when restricted to POS tag features, it runs as quickly as TextRunner, but when set to use dependency-parse features its precision and recall rise even higher."
            },
            "slug": "Open-Information-Extraction-Using-Wikipedia-Wu-Weld",
            "title": {
                "fragments": [],
                "text": "Open Information Extraction Using Wikipedia"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "WOE is presented, an open IE system which improves dramatically on TextRunner's precision and recall and is a novel form of self-supervised learning for open extractors -- using heuristic matches between Wikipedia infobox attribute values and corresponding sentences to construct training data."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117205254"
                        ],
                        "name": "Lei Shi",
                        "slug": "Lei-Shi",
                        "structuredName": {
                            "firstName": "Lei",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lei Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145557251"
                        ],
                        "name": "Rada Mihalcea",
                        "slug": "Rada-Mihalcea",
                        "structuredName": {
                            "firstName": "Rada",
                            "lastName": "Mihalcea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rada Mihalcea"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 68
                            }
                        ],
                        "text": "We employ WordNet for defining REL and Ai arguments as proposed in (Shi and Mihalcea, 2004)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 0
                            }
                        ],
                        "text": "Shi and Mihalcea (2004) proposed a rule-based system for open-text semantic parsing using WordNet and FrameNet (Baker et al., 1998) while Giuglea and Moschitti (2006) proposed a model to connect WordNet, VerbNet and PropBank (Kingsbury and Palmer, 2002) for semantic parsing using tree kernels."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 74
                            }
                        ],
                        "text": "wards learning to associate a MR to any kind of natural language sentence (Shi and Mihalcea, 2004; Poon and Domingos, 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 175
                            }
                        ],
                        "text": "Alternatively, a second line of research, which could be termed open-domain (or open-text), works towards learning to associate a MR to any kind of natural language sentence (Shi and Mihalcea, 2004; Poon and Domingos, 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1221886,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "8486b673f614078396a1b79578daf106ad0f7f71",
            "isKey": true,
            "numCitedBy": 24,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a rule-based semantic parser that relies on a frame dataset (FrameNet), and a semantic network (WordNet), to identify semantic relations between words in open text, as well as shallow semantic features associated with concepts in the text. Parsing semantic structures allows semantic units and constituents to be accessed and processed in a more meaningful way than syntactic parsing, moving the automation of understanding natural language text to a higher level."
            },
            "slug": "Open-Text-Semantic-Parsing-Using-FrameNet-and-Shi-Mihalcea",
            "title": {
                "fragments": [],
                "text": "Open Text Semantic Parsing Using FrameNet and WordNet"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A rule-based semantic parser that relies on a frame dataset (FrameNet), and a semantic network (WordNet), to identify semantic relations between words in open text, as well as shallow semantic features associated with concepts in the text."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 31
                            }
                        ],
                        "text": "However, instead of connecting MRs to an existing ontology as the proposed method does, it constructs a new one and does not leverage pre-existing knowledge."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 97
                            }
                        ],
                        "text": "This paper presented a large-scale system for semantic parsing mapping raw text to disambiguated MRs."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 34
                            }
                        ],
                        "text": "As a result, models infer simpler MRs; this is also referred to as shallow semantic parsing."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 12
                            }
                        ],
                        "text": "In this way MRs induced from text and relations between entities are embedded (and integrated) in the same space."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 65
                            }
                        ],
                        "text": "Thanks to our multi-task training and unified representation for MRs and WordNet/ConceptNet relations, our model is potentially able to generalize to such relations that do not exist in WordNet."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 106
                            }
                        ],
                        "text": "In this case, the supervision is weaker because it is infeasible to label large amounts of free text with MRs that capture deep semantic structure."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 24
                            }
                        ],
                        "text": "For our final predicted MRs, we will represent REL and Ai arguments as tuples of WordNet synsets (hence REL can for example be any verb, and is not constrained to one of the 18 WordNet relations)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 4
                            }
                        ],
                        "text": "The MRs we consider for semantic parsing are simple logical expressions of the form REL(A0, . . . , An)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 121
                            }
                        ],
                        "text": "Using the protocol of Section 2.2, we processed these sentences and collected 47,957 lemma triplets for which the synset MRs were known."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 56
                            }
                        ],
                        "text": "Since the model is structured around relation triplets, MRs and WordNet relations are cast into the same scheme."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 58
                            }
                        ],
                        "text": "Since this requires highly annotated training data and/or MRs built specifically for one domain, such approaches typically have a restricted vocabulary (a few hundred words) and a correspondingly limited MR representation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 111
                            }
                        ],
                        "text": "For example, the WordNet relation ( score NN 2 , has part, musical notation NN 1) fits the same pattern as our MRs, with the WordNet relation type has part playing the role of the verb."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 51
                            }
                        ],
                        "text": "Hence, in our proposed semantic parsing framework, MRs correspond to triplets of synsets (lhssyn, relsyn, rhssyn), which can be reorganized to the form relsyn (lhssyn, rhssyn), as shown in Figure 1."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 18
                            }
                        ],
                        "text": "We aim to produce MRs of the following form: relation(subject, object), i.e. relations with subject and object arguments, where each component of the resulting triplet refers to a disambiguated entity."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 133
                            }
                        ],
                        "text": "The first one, which could be termed in-domain, aims at learning to build highly evolved and comprehensive MRs (Ge and Mooney, 2009; Zettlemoyer and Collins, 2009; Liang et al., 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1950452,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "07216ee1119f61b351b69e94b2e7c3698d96b026",
            "isKey": true,
            "numCitedBy": 194,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of learning context-dependent mappings from sentences to logical form. The training examples are sequences of sentences annotated with lambda-calculus meaning representations. We develop an algorithm that maintains explicit, lambda-calculus representations of salient discourse entities and uses a context-dependent analysis pipeline to recover logical forms. The method uses a hidden-variable variant of the perception algorithm to learn a linear model used to select the best analysis. Experiments on context-dependent utterances from the ATIS corpus show that the method recovers fully correct logical forms with 83.7% accuracy."
            },
            "slug": "Learning-Context-Dependent-Mappings-from-Sentences-Zettlemoyer-Collins",
            "title": {
                "fragments": [],
                "text": "Learning Context-Dependent Mappings from Sentences to Logical Form"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An algorithm is developed that maintains explicit, lambda-calculus representations of salient discourse entities and uses a context-dependent analysis pipeline to recover logical forms and a hidden-variable variant of the perception algorithm to learn a linear model used to select the best analysis."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36037226"
                        ],
                        "name": "R\u00e9jean Ducharme",
                        "slug": "R\u00e9jean-Ducharme",
                        "structuredName": {
                            "firstName": "R\u00e9jean",
                            "lastName": "Ducharme",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R\u00e9jean Ducharme"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120247189"
                        ],
                        "name": "Pascal Vincent",
                        "slug": "Pascal-Vincent",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Vincent",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pascal Vincent"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1909943744"
                        ],
                        "name": "Christian Janvin",
                        "slug": "Christian-Janvin",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Janvin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Janvin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 135
                            }
                        ],
                        "text": "However, contrary to our system, TextRunner does not disambiguate different senses of a lemma, and thus it cannot connect its knowledge to an existing resource to enrich it."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 0
                            }
                        ],
                        "text": "Bengio et al. (2003) developed a neural word embedding approach for language modeling (they only model words, not entities)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 221275765,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c2b28f9354f667cd5bd07afc0471d8334430da7",
            "isKey": false,
            "numCitedBy": 6011,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "A goal of statistical language modeling is to learn the joint probability function of sequences of words in a language. This is intrinsically difficult because of the curse of dimensionality: a word sequence on which the model will be tested is likely to be different from all the word sequences seen during training. Traditional but very successful approaches based on n-grams obtain generalization by concatenating very short overlapping sequences seen in the training set. We propose to fight the curse of dimensionality by learning a distributed representation for words which allows each training sentence to inform the model about an exponential number of semantically neighboring sentences. The model learns simultaneously (1) a distributed representation for each word along with (2) the probability function for word sequences, expressed in terms of these representations. Generalization is obtained because a sequence of words that has never been seen before gets high probability if it is made of words that are similar (in the sense of having a nearby representation) to words forming an already seen sentence. Training such large models (with millions of parameters) within a reasonable time is itself a significant challenge. We report on experiments using neural networks for the probability function, showing on two text corpora that the proposed approach significantly improves on state-of-the-art n-gram models, and that the proposed approach allows to take advantage of longer contexts."
            },
            "slug": "A-Neural-Probabilistic-Language-Model-Bengio-Ducharme",
            "title": {
                "fragments": [],
                "text": "A Neural Probabilistic Language Model"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work proposes to fight the curse of dimensionality by learning a distributed representation for words which allows each training sentence to inform the model about an exponential number of semantically neighboring sentences."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939803"
                        ],
                        "name": "Ronan Collobert",
                        "slug": "Ronan-Collobert",
                        "structuredName": {
                            "firstName": "Ronan",
                            "lastName": "Collobert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronan Collobert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 83
                            }
                        ],
                        "text": "The approach we follow here has already been used successfully in ranking settings (Collobert and Weston, 2008; Collobert et al., 2011) and corresponds to performing two approximations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 0
                            }
                        ],
                        "text": "Collobert and Weston (2008) developed word embedding models further and applied them to various NLP tasks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2617020,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "57458bc1cffe5caa45a885af986d70f723f406b4",
            "isKey": false,
            "numCitedBy": 5024,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, semantically similar words and the likelihood that the sentence makes sense (grammatically and semantically) using a language model. The entire network is trained jointly on all these tasks using weight-sharing, an instance of multitask learning. All the tasks use labeled data except the language model which is learnt from unlabeled text and represents a novel form of semi-supervised learning for the shared tasks. We show how both multitask learning and semi-supervised learning improve the generalization of the shared tasks, resulting in state-of-the-art-performance."
            },
            "slug": "A-unified-architecture-for-natural-language-deep-Collobert-Weston",
            "title": {
                "fragments": [],
                "text": "A unified architecture for natural language processing: deep neural networks with multitask learning"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "This work describes a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, semantically similar words and the likelihood that the sentence makes sense using a language model."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075292388"
                        ],
                        "name": "P. Liang",
                        "slug": "P.-Liang",
                        "structuredName": {
                            "firstName": "Percy",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Liang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38666915"
                        ],
                        "name": "D. Klein",
                        "slug": "D.-Klein",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Klein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Klein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 31
                            }
                        ],
                        "text": "However, instead of connecting MRs to an existing ontology as the proposed method does, it constructs a new one and does not leverage pre-existing knowledge."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 97
                            }
                        ],
                        "text": "This paper presented a large-scale system for semantic parsing mapping raw text to disambiguated MRs."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 34
                            }
                        ],
                        "text": "As a result, models infer simpler MRs; this is also referred to as shallow semantic parsing."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 12
                            }
                        ],
                        "text": "In this way MRs induced from text and relations between entities are embedded (and integrated) in the same space."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 65
                            }
                        ],
                        "text": "Thanks to our multi-task training and unified representation for MRs and WordNet/ConceptNet relations, our model is potentially able to generalize to such relations that do not exist in WordNet."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 106
                            }
                        ],
                        "text": "In this case, the supervision is weaker because it is infeasible to label large amounts of free text with MRs that capture deep semantic structure."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 24
                            }
                        ],
                        "text": "For our final predicted MRs, we will represent REL and Ai arguments as tuples of WordNet synsets (hence REL can for example be any verb, and is not constrained to one of the 18 WordNet relations)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 4
                            }
                        ],
                        "text": "The MRs we consider for semantic parsing are simple logical expressions of the form REL(A0, . . . , An)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 121
                            }
                        ],
                        "text": "Using the protocol of Section 2.2, we processed these sentences and collected 47,957 lemma triplets for which the synset MRs were known."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 56
                            }
                        ],
                        "text": "Since the model is structured around relation triplets, MRs and WordNet relations are cast into the same scheme."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 58
                            }
                        ],
                        "text": "Since this requires highly annotated training data and/or MRs built specifically for one domain, such approaches typically have a restricted vocabulary (a few hundred words) and a correspondingly limited MR representation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 111
                            }
                        ],
                        "text": "For example, the WordNet relation ( score NN 2 , has part, musical notation NN 1) fits the same pattern as our MRs, with the WordNet relation type has part playing the role of the verb."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 51
                            }
                        ],
                        "text": "Hence, in our proposed semantic parsing framework, MRs correspond to triplets of synsets (lhssyn, relsyn, rhssyn), which can be reorganized to the form relsyn (lhssyn, rhssyn), as shown in Figure 1."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 18
                            }
                        ],
                        "text": "We aim to produce MRs of the following form: relation(subject, object), i.e. relations with subject and object arguments, where each component of the resulting triplet refers to a disambiguated entity."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 164
                            }
                        ],
                        "text": "The first one, which could be termed in-domain, aims at learning to build highly evolved and comprehensive MRs (Ge and Mooney, 2009; Zettlemoyer and Collins, 2009; Liang et al., 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 340852,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3ecd3e00bbbfd94446c3adc9c6878de27e250f7c",
            "isKey": true,
            "numCitedBy": 568,
            "numCiting": 81,
            "paperAbstract": {
                "fragments": [],
                "text": "Suppose we want to build a system that answers a natural language question by representing its semantics as a logical forxm and computing the answer given a structured database of facts. The core part of such a system is the semantic parser that maps questions to logical forms. Semantic parsers are typically trained from examples of questions annotated with their target logical forms, but this type of annotation is expensive.Our goal is to instead learn a semantic parser from question\u2013answer pairs, where the logical form is modeled as a latent variable. We develop a new semantic formalism, dependency-based compositional semantics (DCS) and define a log-linear distribution over DCS logical forms. The model parameters are estimated using a simple procedure that alternates between beam search and numerical optimization. On two standard semantic parsing benchmarks, we show that our system obtains comparable accuracies to even state-of-the-art systems that do require annotated logical forms."
            },
            "slug": "Learning-Dependency-Based-Compositional-Semantics-Liang-Jordan",
            "title": {
                "fragments": [],
                "text": "Learning Dependency-Based Compositional Semantics"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A new semantic formalism, dependency-based compositional semantics (DCS) is developed and a log-linear distribution over DCS logical forms is defined and it is shown that the system obtains comparable accuracies to even state-of-the-art systems that do require annotated logical forms."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759772"
                        ],
                        "name": "Hoifung Poon",
                        "slug": "Hoifung-Poon",
                        "structuredName": {
                            "firstName": "Hoifung",
                            "lastName": "Poon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hoifung Poon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740213"
                        ],
                        "name": "Pedro M. Domingos",
                        "slug": "Pedro-M.-Domingos",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Domingos",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pedro M. Domingos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 154
                            }
                        ],
                        "text": "A method based on Markov-Logic Networks has been recently introduced for unsupervised semantic parsing that can be also used for information acquisition (Poon and Domingos, 2009, 2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1473515,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "db328685d00ec35fe35f9350f884c7b4b8db3f4c",
            "isKey": false,
            "numCitedBy": 141,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Extracting knowledge from unstructured text is a long-standing goal of NLP. Although learning approaches to many of its subtasks have been developed (e.g., parsing, taxonomy induction, information extraction), all end-to-end solutions to date require heavy supervision and/or manual engineering, limiting their scope and scalability. We present OntoUSP, a system that induces and populates a probabilistic ontology using only dependency-parsed text as input. OntoUSP builds on the USP unsupervised semantic parser by jointly forming ISA and IS-PART hierarchies of lambda-form clusters. The ISA hierarchy allows more general knowledge to be learned, and the use of smoothing for parameter estimation. We evaluate OntoUSP by using it to extract a knowledge base from biomedical abstracts and answer questions. OntoUSP improves on the recall of USP by 47% and greatly outperforms previous state-of-the-art approaches."
            },
            "slug": "Unsupervised-Ontology-Induction-from-Text-Poon-Domingos",
            "title": {
                "fragments": [],
                "text": "Unsupervised Ontology Induction from Text"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "OntoUSP builds on the USP unsupervised semantic parser by jointly forming ISA and IS-PART hierarchies of lambda-form clusters and improves on the recall of USP by 47% and greatly outperforms previous state-of-the-art approaches."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939803"
                        ],
                        "name": "Ronan Collobert",
                        "slug": "Ronan-Collobert",
                        "structuredName": {
                            "firstName": "Ronan",
                            "lastName": "Collobert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronan Collobert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21432929"
                        ],
                        "name": "Michael Karlen",
                        "slug": "Michael-Karlen",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Karlen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Karlen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2645384"
                        ],
                        "name": "K. Kavukcuoglu",
                        "slug": "K.-Kavukcuoglu",
                        "structuredName": {
                            "firstName": "Koray",
                            "lastName": "Kavukcuoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kavukcuoglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46283650"
                        ],
                        "name": "P. Kuksa",
                        "slug": "P.-Kuksa",
                        "structuredName": {
                            "firstName": "Pavel",
                            "lastName": "Kuksa",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Kuksa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 29
                            }
                        ],
                        "text": "We use the SENNA software(2) (Collobert et al., 2011) to perform part-of-speech (POS) tagging, chunking, lemmatization(3) and semantic role labeling (SRL)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 28
                            }
                        ],
                        "text": "We use the SENNA software2 (Collobert et al., 2011) to perform part-of-speech (POS) tagging, chunking, lemmatization3 and semantic role labeling (SRL)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 84
                            }
                        ],
                        "text": "The approach we follow here has already been used successfully in ranking settings (Collobert et al., 2011) and corresponds to performing two approximations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 351666,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bc1022b031dc6c7019696492e8116598097a8c12",
            "isKey": false,
            "numCitedBy": 6658,
            "numCiting": 108,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements."
            },
            "slug": "Natural-Language-Processing-(Almost)-from-Scratch-Collobert-Weston",
            "title": {
                "fragments": [],
                "text": "Natural Language Processing (Almost) from Scratch"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "A unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including part-of-speech tagging, chunking, named entity recognition, and semantic role labeling is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144096985"
                        ],
                        "name": "G. Miller",
                        "slug": "G.-Miller",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Miller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Miller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 24
                            }
                        ],
                        "text": "Resources like WordNet (Miller, 1995) and ConceptNet (Liu and Singh, 2004) encode common-sense knowledge in the form of relations between entities (e.g. has part( car, wheel) ) but do not link this knowledge to raw text (sentences)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 23
                            }
                        ],
                        "text": "Resources like WordNet (Miller, 1995) and ConceptNet (Liu and Singh, 2004) encode common-sense knowledge in the form of relations between entities (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1671874,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "68c03788224000794d5491ab459be0b2a2c38677",
            "isKey": false,
            "numCitedBy": 13889,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Because meaningful sentences are composed of meaningful words, any system that hopes to process natural languages as people do must have information about words and their meanings. This information is traditionally provided through dictionaries, and machine-readable dictionaries are now widely available. But dictionary entries evolved for the convenience of human readers, not for machines. WordNet1 provides a more effective combination of traditional lexicographic information and modern computing. WordNet is an online lexical database designed for use under program control. English nouns, verbs, adjectives, and adverbs are organized into sets of synonyms, each representing a lexicalized concept. Semantic relations link the synonym sets [4]."
            },
            "slug": "WordNet:-A-Lexical-Database-for-English-Miller",
            "title": {
                "fragments": [],
                "text": "WordNet: A Lexical Database for English"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "WordNet1 provides a more effective combination of traditional lexicographic information and modern computing, and is an online lexical database designed for use under program control."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759772"
                        ],
                        "name": "Hoifung Poon",
                        "slug": "Hoifung-Poon",
                        "structuredName": {
                            "firstName": "Hoifung",
                            "lastName": "Poon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hoifung Poon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 74
                            }
                        ],
                        "text": "wards learning to associate a MR to any kind of natural language sentence (Shi and Mihalcea, 2004; Poon and Domingos, 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 222,
                                "start": 199
                            }
                        ],
                        "text": "Alternatively, a second line of research, which could be termed open-domain (or open-text), works towards learning to associate a MR to any kind of natural language sentence (Shi and Mihalcea, 2004; Poon and Domingos, 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 154
                            }
                        ],
                        "text": "A method based on Markov-Logic Networks has been recently introduced for unsupervised semantic parsing that can be also used for information acquisition (Poon and Domingos, 2009, 2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5337047,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6df733a3274c55414629c5e90debef629631fcaa",
            "isKey": false,
            "numCitedBy": 294,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We present the first unsupervised approach to the problem of learning a semantic parser, using Markov logic. Our USP system transforms dependency trees into quasi-logical forms, recursively induces lambda forms from these, and clusters them to abstract away syntactic variations of the same meaning. The MAP semantic parse of a sentence is obtained by recursively assigning its parts to lambda-form clusters and composing them. We evaluate our approach by using it to extract a knowledge base from biomedical abstracts and answer questions. USP substantially outperforms TextRunner, DIRT and an informed baseline on both precision and recall on this task."
            },
            "slug": "Unsupervised-Semantic-Parsing-Poon",
            "title": {
                "fragments": [],
                "text": "Unsupervised Semantic Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This work presents the first unsupervised approach to the problem of learning a semantic parser, using Markov logic, and substantially outperforms TextRunner, DIRT and an informed baseline on both precision and recall on this task."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 35
                            }
                        ],
                        "text": ", 2011) and recursive autoencoders (Bottou, 2011; Socher et al., 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 131
                            }
                        ],
                        "text": "The architecture of our system is also related to recent work on gated models (Sutskever et al., 2011) and recursive autoencoders (Bottou, 2011; Socher et al., 2011)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1067591,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cb7853c5d609081ea12cd4db3863a87da2d51808",
            "isKey": false,
            "numCitedBy": 209,
            "numCiting": 80,
            "paperAbstract": {
                "fragments": [],
                "text": "A\u00a0plausible definition of \u201creasoning\u201d could be \u201calgebraically manipulating previously acquired knowledge in order to answer a new question\u201d. This definition covers first-order logical inference or probabilistic inference. It also includes much simpler manipulations commonly used to build large learning systems. For instance, we can build an optical character recognition system by first training a character segmenter, an isolated character recognizer, and a language model, using appropriate labelled training sets. Adequately concatenating these modules and fine tuning the resulting system can be viewed as an algebraic operation in a space of models. The resulting model answers a new question, that is, converting the image of a text page into a computer readable text.This observation suggests a conceptual continuity between algebraically rich inference systems, such as logical or probabilistic inference, and simple manipulations, such as the mere concatenation of trainable learning systems. Therefore, instead of trying to bridge the gap between machine learning systems and sophisticated \u201call-purpose\u201d inference mechanisms, we can instead algebraically enrich the set of manipulations applicable to training systems, and build reasoning capabilities from the ground up."
            },
            "slug": "From-machine-learning-to-machine-reasoning-Bottou",
            "title": {
                "fragments": [],
                "text": "From machine learning to machine reasoning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Instead of trying to bridge the gap between machine learning systems and sophisticated \u201call-purpose\u201d inference mechanisms, the set of manipulations applicable to training systems can be algebraically enriched, and reasoning capabilities from the ground up are built."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 18
                            }
                        ],
                        "text": "Semantic parsing (Mooney, 2004) precisely aims at building such systems to interpret statements expressed in natural language."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7756383,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "fa37f8c8bb5e1ba52f0f2f2101f72de99bb4061c",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Computational systems that learn to transform naturallanguage sentences into semantic representations have important practical applications in building naturallanguage interfaces. They can also provide insight into important issues in human language acquisition. However, within AI, computational linguistics, and machine learning, there has been relatively little research on developing systems that learn such semantic parsers. This paper briefly reviews our own work in this area and presents semantic-parser acquistion as an important challenge problem for AI."
            },
            "slug": "Learning-Semantic-Parsers:-An-Important-but-Problem-Mooney",
            "title": {
                "fragments": [],
                "text": "Learning Semantic Parsers: An Important but Under-Studied Problem"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The author's own work in this area is reviewed and semantic-parser acquistion is presented as an important challenge problem for AI."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144621026"
                        ],
                        "name": "R. Snow",
                        "slug": "R.-Snow",
                        "structuredName": {
                            "firstName": "Rion",
                            "lastName": "Snow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Snow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 72
                            }
                        ],
                        "text": "Automatic information extraction is the topic of many models and demos (Snow et al., 2006; Yates et al., 2007; Wu and Weld, 2010; Suchanek et al., 2008) but none of them relies on a joint embedding model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14680675,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "93bb6228776eafa606965e21f229d548de1998eb",
            "isKey": false,
            "numCitedBy": 540,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel algorithm for inducing semantic taxonomies. Previous algorithms for taxonomy induction have typically focused on independent classifiers for discovering new single relationships based on hand-constructed or automatically discovered textual patterns. By contrast, our algorithm flexibly incorporates evidence from multiple classifiers over heterogenous relationships to optimize the entire structure of the taxonomy, using knowledge of a word's coordinate terms to help in determining its hypernyms, and vice versa. We apply our algorithm on the problem of sense-disambiguated noun hyponym acquisition, where we combine the predictions of hypernym and coordinate term classifiers with the knowledge in a preexisting semantic taxonomy (WordNet 2.1). We add 10,000 novel synsets to WordNet 2.1 at 84% precision, a relative error reduction of 70% over a non-joint algorithm using the same component classifiers. Finally, we show that a taxonomy built using our algorithm shows a 23% relative F-score improvement over WordNet 2.1 on an independent testset of hypernym pairs."
            },
            "slug": "Semantic-Taxonomy-Induction-from-Heterogenous-Snow-Jurafsky",
            "title": {
                "fragments": [],
                "text": "Semantic Taxonomy Induction from Heterogenous Evidence"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "This work proposes a novel algorithm for inducing semantic taxonomies that flexibly incorporates evidence from multiple classifiers over heterogenous relationships to optimize the entire structure of the taxonomy, using knowledge of a word's coordinate terms to help in determining its hypernyms, and vice versa."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2232845"
                        ],
                        "name": "Catherine Havasi",
                        "slug": "Catherine-Havasi",
                        "structuredName": {
                            "firstName": "Catherine",
                            "lastName": "Havasi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Catherine Havasi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145696766"
                        ],
                        "name": "R. Speer",
                        "slug": "R.-Speer",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Speer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Speer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707726"
                        ],
                        "name": "J. Pustejovsky",
                        "slug": "J.-Pustejovsky",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Pustejovsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pustejovsky"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 51
                            }
                        ],
                        "text": ", 2008) or by connecting different knowledge bases (Havasi et al., 2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 197
                            }
                        ],
                        "text": "Finally, several previous works have targeted to improve WSD by using extra-knowledge by either automatically acquiring examples (Martinez et al., 2008) or by connecting different knowledge bases (Havasi et al., 2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 11
                            }
                        ],
                        "text": "Following (Havasi et al., 2010), we created two other versions of this\ndataset to leverage WN in order to also learn lemma embeddings: \u201cAmbiguated\u201d WN and \u201cBridge\u201d WN."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 10
                            }
                        ],
                        "text": "Following (Havasi et al., 2010), we created two other versions of this dataset to leverage WN in order to also learn lemma embeddings: \u201cAmbiguated\u201d WN and \u201cBridge\u201d WN."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15166983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6f5e816654d2b01e4b4f2c8ecee95b242a23d68f",
            "isKey": true,
            "numCitedBy": 20,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Coarse word sense disambiguation (WSD) is an NLP task that is both important and practical: it aims to distinguish senses of a word that have very different meanings, while avoiding the complexity that comes from trying to finely distinguish every possible word sense. Reasoning techniques that make use of common sense information can help to solve the WSD problem by taking word meaning and context into account. We have created a system for coarse word sense disambiguation using blending, a common sense reasoning technique, to combine information from SemCor, WordNet, ConceptNet and Extended WordNet. Within that space, a correct sense is suggested based on the similarity of the ambiguous word to each of its possible word senses. The general blending-based system performed well at the task, achieving an f-score of 80.8\\% on the 2007 SemEval Coarse Word Sense Disambiguation task."
            },
            "slug": "Coarse-Word-Sense-Disambiguation-Using-Common-Sense-Havasi-Speer",
            "title": {
                "fragments": [],
                "text": "Coarse Word-Sense Disambiguation Using Common Sense"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work has created a system for coarse word sense disambiguation using blending, a common sense reasoning technique, to combine information from SemCor, WordNet, ConceptNet and Extended WordNet to create a correct sense within that space."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI Fall Symposium: Commonsense Knowledge"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749194"
                        ],
                        "name": "Collin F. Baker",
                        "slug": "Collin-F.-Baker",
                        "structuredName": {
                            "firstName": "Collin",
                            "lastName": "Baker",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Collin F. Baker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2912454"
                        ],
                        "name": "C. Fillmore",
                        "slug": "C.-Fillmore",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Fillmore",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fillmore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1406118956"
                        ],
                        "name": "John B. Lowe",
                        "slug": "John-B.-Lowe",
                        "structuredName": {
                            "firstName": "John B.",
                            "lastName": "Lowe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John B. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 112
                            }
                        ],
                        "text": "Shi and Mihalcea (2004) proposed a rule-based system for open-text semantic parsing using WordNet and FrameNet (Baker et al., 1998) while Giuglea and Moschitti (2006) proposed a model to connect WordNet, VerbNet and PropBank (Kingsbury and Palmer, 2002) for semantic parsing using tree kernels."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 147
                            }
                        ],
                        "text": "Future work should explore the capabilities of such systems further including other semantic tasks, and more evolved grammars, e.g. with FrameNet (Baker et al., 1998; Coppola and Moschitti, 2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2505531,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "547f23597f9ec8a93f66cedaa6fbfb73960426b1",
            "isKey": false,
            "numCitedBy": 2882,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "FrameNet is a three-year NSF-supported project in corpus-based computational lexicography, now in its second year (NSF IRI-9618838, \"Tools for Lexicon Building\"). The project's key features are (a) a commitment to corpus evidence for semantic and syntactic generalizations, and (b) the representation of the valences of its target words (mostly nouns, adjectives, and verbs) in which the semantic portion makes use of frame semantics. The resulting database will contain (a) descriptions of the semantic frames underlying the meanings of the words described, and (b) the valence representation (semantic and syntactic) of several thousand words and phrases, each accompanied by (c) a representative collection of annotated corpus attestations, which jointly exemplify the observed linkings between \"frame elements\" and their syntactic realizations (e.g. grammatical function, phrase type, and other syntactic traits). This report will present the project's goals and workflow, and information about the computational tools that have been adapted or created in-house for this work."
            },
            "slug": "The-Berkeley-FrameNet-Project-Baker-Fillmore",
            "title": {
                "fragments": [],
                "text": "The Berkeley FrameNet Project"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This report will present the project's goals and workflow, and information about the computational tools that have been adapted or created in-house for this work."
            },
            "venue": {
                "fragments": [],
                "text": "COLING-ACL"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39783117"
                        ],
                        "name": "Bonaventura Coppola",
                        "slug": "Bonaventura-Coppola",
                        "structuredName": {
                            "firstName": "Bonaventura",
                            "lastName": "Coppola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bonaventura Coppola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719404"
                        ],
                        "name": "Alessandro Moschitti",
                        "slug": "Alessandro-Moschitti",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Moschitti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alessandro Moschitti"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8545813,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dbbfb8403cc3d0949b7d63f9e22708ac943b827b",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a new FrameNet-based Shallow Semantic Parser. Shallow Semantic Parsing has been a popular Natural Language Processing task since the 2004 and 2005 CoNLL Shared Task editions on Semantic Role Labeling, which were based on the PropBank lexical-semantic resource. Nonetheless, efforts in extending such task to the FrameNet setting have been constrained by practical software engineering issues. We hereby analyze these issues, identify desirable requirements for a practical parsing framework, and show the results of our software implementation. In particular, we attempt at meeting requirements arising from both a) the need of a flexible environment supporting current ongoing research, and b) the willingness of providing an effective platform supporting preliminary application prototypes in the field. After introducing the task of FrameNet-based Shallow Semantic Parsing, we sketch the system processing workflow and summarize a set of successful experimental results, directing the reader to previous published papers for extended experiment descriptions and wider discussion of the achieved results."
            },
            "slug": "A-General-Purpose-FrameNet-based-Shallow-Semantic-Coppola-Moschitti",
            "title": {
                "fragments": [],
                "text": "A General Purpose FrameNet-based Shallow Semantic Parser"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A new FrameNet-based Shallow Semantic Parser is presented, meeting requirements arising from both a) the need of a flexible environment supporting current ongoing research, and b) the willingness of providing an effective platform supporting preliminary application prototypes in the field."
            },
            "venue": {
                "fragments": [],
                "text": "LREC"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2340091"
                        ],
                        "name": "Ana-Maria Giuglea",
                        "slug": "Ana-Maria-Giuglea",
                        "structuredName": {
                            "firstName": "Ana-Maria",
                            "lastName": "Giuglea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ana-Maria Giuglea"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719404"
                        ],
                        "name": "Alessandro Moschitti",
                        "slug": "Alessandro-Moschitti",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Moschitti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alessandro Moschitti"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 138
                            }
                        ],
                        "text": "Shi and Mihalcea (2004) proposed a rule-based system for open-text semantic parsing using WordNet and FrameNet (Baker et al., 1998) while Giuglea and Moschitti (2006) proposed a model to connect WordNet, VerbNet and PropBank (Kingsbury and Palmer, 2002) for semantic parsing using tree kernels."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 237,
                                "start": 159
                            }
                        ],
                        "text": "Alternatively, a second line of research, which could be termed open-domain, works towards learning to associate a MR to any kind of natural language sentence (Shi and Mihalcea, 2004; Giuglea and Moschitti, 2006; Poon and Domingos, 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5121651,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "02e4745b29502268550ba215eb690bbd641f4c00",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "This article describes a semantic parser based on FrameNet semantic roles that uses a broad knowledge base created by interconnecting three major resources: FrameNet, VerbNet and PropBank. We link the above resources through a mapping between Intersective Levin classes, which are part of PropBank's annotation, and the FrameNet frames. By using Levin classes, we successfully detect FrameNet semantic roles without relying on the frame information. At the same time, the combined usage of the above resources increases the verb coverage and confers more robustness to our parser. The experiments with Support Vector Machines on automatic Levin class detection suggest that (a) tree kernels are well suited for the task and (b) Intersective Levin classes can be used to improve the accuracy of semantic parsing based on FrameNet roles."
            },
            "slug": "Shallow-Semantic-Parsing-Based-on-FrameNet,-VerbNet-Giuglea-Moschitti",
            "title": {
                "fragments": [],
                "text": "Shallow Semantic Parsing Based on FrameNet, VerbNet and PropBank"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "A semantic parser based on FrameNet semantic roles that uses a broad knowledge base created by interconnecting three major resources: FrameNet, VerbNet and PropBank, which successfully detects Frame net semantic roles without relying on the frame information."
            },
            "venue": {
                "fragments": [],
                "text": "ECAI"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2585821"
                        ],
                        "name": "Cliff Chiung-Yu Lin",
                        "slug": "Cliff-Chiung-Yu-Lin",
                        "structuredName": {
                            "firstName": "Cliff",
                            "lastName": "Lin",
                            "middleNames": [
                                "Chiung-Yu"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cliff Chiung-Yu Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 145
                            }
                        ],
                        "text": "The architecture of our system is also related to recent work on gated models (Sutskever et al., 2011) and recursive autoencoders (Bottou, 2011; Socher et al., 2011)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18690358,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9c0ddf74f87d154db88d79c640578c1610451eec",
            "isKey": false,
            "numCitedBy": 1320,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Recursive structure is commonly found in the inputs of different modalities such as natural scene images or natural language sentences. Discovering this recursive structure helps us to not only identify the units that an image or sentence contains but also how they interact to form a whole. We introduce a max-margin structure prediction architecture based on recursive neural networks that can successfully recover such structure both in complex scene images as well as sentences. The same algorithm can be used both to provide a competitive syntactic parser for natural language sentences from the Penn Treebank and to outperform alternative approaches for semantic scene segmentation, annotation and classification. For segmentation and annotation our algorithm obtains a new level of state-of-the-art performance on the Stanford background dataset (78.1%). The features from the image parse tree outperform Gist descriptors for scene classification by 4%."
            },
            "slug": "Parsing-Natural-Scenes-and-Natural-Language-with-Socher-Lin",
            "title": {
                "fragments": [],
                "text": "Parsing Natural Scenes and Natural Language with Recursive Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A max-margin structure prediction architecture based on recursive neural networks that can successfully recover such structure both in complex scene images as well as sentences is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733049"
                        ],
                        "name": "Eneko Agirre",
                        "slug": "Eneko-Agirre",
                        "structuredName": {
                            "firstName": "Eneko",
                            "lastName": "Agirre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eneko Agirre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2650591"
                        ],
                        "name": "O. Ansa",
                        "slug": "O.-Ansa",
                        "structuredName": {
                            "firstName": "Olatz",
                            "lastName": "Ansa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Ansa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144547315"
                        ],
                        "name": "E. Hovy",
                        "slug": "E.-Hovy",
                        "structuredName": {
                            "firstName": "Eduard",
                            "lastName": "Hovy",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hovy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143696281"
                        ],
                        "name": "David Mart\u00ednez",
                        "slug": "David-Mart\u00ednez",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mart\u00ednez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Mart\u00ednez"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 286,
                                "start": 278
                            }
                        ],
                        "text": "To assess the performance w.r.t. choices made with the multi-task joint training and the diverse data sources, we evaluated models trained with several combinations of data sources on two benchmark tasks: WordNet knowledge encoding and WSD. WN denotes our model trained only on WordNet, \u201cAmbiguated\u201d WordNet and \u201cBridge\u201d WordNet, WN+CN+Wk is also trained on CN and Wk datasets, and All is trained on all sources."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 195
                            }
                        ],
                        "text": "Shi and Mihalcea (2004) proposed a rule-based system for open-text semantic parsing using WordNet and FrameNet (Baker et al., 1998) while Giuglea and Moschitti (2006) proposed a model to connect WordNet, VerbNet and PropBank (Kingsbury and Palmer, 2002) for semantic parsing using tree kernels."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 104
                            }
                        ],
                        "text": "Some approaches have been directly targeting to enrich existing resources, as we do here with WordNet, (Agirre et al., 2000; Cuadros and Rigau, 2008; Cimiano, 2006) but these never use learning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59687,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0800ab91a4bb07d4f63fc91cde2bea59b09567b",
            "isKey": false,
            "numCitedBy": 374,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper explores the possibility to exploit text on the world wide web in order to enrich the concepts in existing ontologies. First, a method to retrieve documents from the WWW related to a concept is described. These document collections are used 1) to construct topic signatures (lists of topically related words) for each concept in WordNet, and 2) to build hierarchical clusters of the concepts (the word senses) that lexicalize a given word. The overall goal is to overcome two shortcomings of WordNet: the lack of topical links among concepts, and the proliferation of senses. Topic signatures are validated on a word sense disambiguation task with good results, which are improved when the hierarchical clusters are used."
            },
            "slug": "Enriching-very-large-ontologies-using-the-WWW-Agirre-Ansa",
            "title": {
                "fragments": [],
                "text": "Enriching very large ontologies using the WWW"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The overall goal is to overcome two shortcomings of WordNet: the lack of topical links among concepts, and the proliferation of senses, which are improved when the hierarchical clusters are used."
            },
            "venue": {
                "fragments": [],
                "text": "ECAI Workshop on Ontology Learning"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2489901"
                        ],
                        "name": "Paul R. Kingsbury",
                        "slug": "Paul-R.-Kingsbury",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Kingsbury",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul R. Kingsbury"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145755155"
                        ],
                        "name": "Martha Palmer",
                        "slug": "Martha-Palmer",
                        "structuredName": {
                            "firstName": "Martha",
                            "lastName": "Palmer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martha Palmer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 101
                            }
                        ],
                        "text": ", 1998) while Giuglea and Moschitti (2006) proposed a model to connect WordNet, VerbNet and PropBank (Kingsbury and Palmer, 2002) for semantic parsing using tree kernels."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 252,
                                "start": 226
                            }
                        ],
                        "text": "Shi and Mihalcea (2004) proposed a rule-based system for open-text semantic parsing using WordNet and FrameNet (Baker et al., 1998) while Giuglea and Moschitti (2006) proposed a model to connect WordNet, VerbNet and PropBank (Kingsbury and Palmer, 2002) for semantic parsing using tree kernels."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14810207,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fc090a68e45e0e6337136777d21c87b76a90ae72",
            "isKey": false,
            "numCitedBy": 696,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes our approach to the development of a Proposition Bank, which involves the addition of semantic information to the Penn English Treebank. Our primary goal is the labeling of syntactic nodes with specific argument labels that preserve the similarity of roles such as the window in John broke the window and the window broke. After motivating the need for explicit predicate argument structure labels, we briefly discuss the theoretical considerations of predicate argument structure and the need to maintain consistency across syntactic alternations. The issues of consistency of argument structure across both polysemous and synonymous verbs are also discussed and we present our actual guidelines for these types of phenomena, along with numerous examples of tagged sentences and verb frames. Metaframes are introduced as a technique for handling similar frames among near\u2212 synonymous verbs. We conclude with a summary of the current status of annotation process."
            },
            "slug": "From-TreeBank-to-PropBank-Kingsbury-Palmer",
            "title": {
                "fragments": [],
                "text": "From TreeBank to PropBank"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "This paper describes the approach to the development of a Proposition Bank, which involves the addition of semantic information to the Penn English Treebank and introduces metaframes as a technique for handling similar frames among near\u2212 synonymous verbs."
            },
            "venue": {
                "fragments": [],
                "text": "LREC"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679784"
                        ],
                        "name": "Fabian M. Suchanek",
                        "slug": "Fabian-M.-Suchanek",
                        "structuredName": {
                            "firstName": "Fabian",
                            "lastName": "Suchanek",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fabian M. Suchanek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686448"
                        ],
                        "name": "Gjergji Kasneci",
                        "slug": "Gjergji-Kasneci",
                        "structuredName": {
                            "firstName": "Gjergji",
                            "lastName": "Kasneci",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gjergji Kasneci"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751591"
                        ],
                        "name": "G. Weikum",
                        "slug": "G.-Weikum",
                        "structuredName": {
                            "firstName": "Gerhard",
                            "lastName": "Weikum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Weikum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 130
                            }
                        ],
                        "text": "Automatic information extraction is the topic of many models and demos (Snow et al., 2006; Yates et al., 2007; Wu and Weld, 2010; Suchanek et al., 2008) but none of them relies on a joint embedding model."
                    },
                    "intents": []
                }
            ],
            "corpusId": 205702077,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "09f6fa1869be4d3d9188d1313061602038cb97d4",
            "isKey": false,
            "numCitedBy": 869,
            "numCiting": 188,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "YAGO:-A-Large-Ontology-from-Wikipedia-and-WordNet-Suchanek-Kasneci",
            "title": {
                "fragments": [],
                "text": "YAGO: A Large Ontology from Wikipedia and WordNet"
            },
            "venue": {
                "fragments": [],
                "text": "J. Web Semant."
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1787006"
                        ],
                        "name": "Ruifang Ge",
                        "slug": "Ruifang-Ge",
                        "structuredName": {
                            "firstName": "Ruifang",
                            "lastName": "Ge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ruifang Ge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 112
                            }
                        ],
                        "text": "The first one, which could be termed in-domain, aims at learning to build highly evolved and comprehensive MRs (Ge and Mooney, 2009; Zettlemoyer and Collins, 2009; Liang et al., 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14703535,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4d920bde096e2a9d9a6c689a9fbbaddaba1aa452",
            "isKey": false,
            "numCitedBy": 57,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new approach to learning a semantic parser (a system that maps natural language sentences into logical form). Unlike previous methods, it exploits an existing syntactic parser to produce disambiguated parse trees that drive the compositional semantic interpretation. The resulting system produces improved results on standard corpora on natural language interfaces for database querying and simulated robot control."
            },
            "slug": "Learning-a-Compositional-Semantic-Parser-using-an-Ge-Mooney",
            "title": {
                "fragments": [],
                "text": "Learning a Compositional Semantic Parser using an Existing Syntactic Parser"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "A new approach to learning a semantic parser that exploits an existing syntactic parser to produce disambiguated parse trees that drive the compositional semantic interpretation."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3321874"
                        ],
                        "name": "A. Yates",
                        "slug": "A.-Yates",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Yates",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yates"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2339397"
                        ],
                        "name": "Michele Banko",
                        "slug": "Michele-Banko",
                        "structuredName": {
                            "firstName": "Michele",
                            "lastName": "Banko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michele Banko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50452701"
                        ],
                        "name": "M. Broadhead",
                        "slug": "M.-Broadhead",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Broadhead",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Broadhead"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725561"
                        ],
                        "name": "Michael J. Cafarella",
                        "slug": "Michael-J.-Cafarella",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Cafarella",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Cafarella"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741101"
                        ],
                        "name": "Oren Etzioni",
                        "slug": "Oren-Etzioni",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Etzioni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Etzioni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144295318"
                        ],
                        "name": "S. Soderland",
                        "slug": "S.-Soderland",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Soderland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Soderland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 91
                            }
                        ],
                        "text": "Automatic information extraction is the topic of many models and demos (Snow et al., 2006; Yates et al., 2007; Wu and Weld, 2010; Suchanek et al., 2008) but none of them relies on a joint embedding model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 51
                            }
                        ],
                        "text": "We also compare with lists returned by TextRunner (Yates et al., 2007) (an information extraction tool having extracted information from 100M webpages, to be compared with our 50k Wikipedia articles)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 33
                            }
                        ],
                        "text": "However, contrary to our system, TextRunner does not disambiguate different senses of a lemma, and thus it cannot connect its knowledge to an existing resource to enrich it."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1455080,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ad10607412e196279bf056d13c8b6fa27fd61f26",
            "isKey": false,
            "numCitedBy": 341,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Traditional information extraction systems have focused on satisfying precise, narrow, pre-specified requests from small, homogeneous corpora. In contrast, the TextRunner system demonstrates a new kind of information extraction, called Open Information Extraction (OIE), in which the system makes a single, data-driven pass over the entire corpus and extracts a large set of relational tuples, without requiring any human input. (Banko et al., 2007) TextRunner is a fully-implemented, highly scalable example of OIE. TextRunner's extractions are indexed, allowing a fast query mechanism."
            },
            "slug": "TextRunner:-Open-Information-Extraction-on-the-Web-Yates-Banko",
            "title": {
                "fragments": [],
                "text": "TextRunner: Open Information Extraction on the Web"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The TextRunner system demonstrates a new kind of information extraction, called Open Information Extraction (OIE), in which the system makes a single, data-driven pass over the entire corpus and extracts a large set of relational tuples, without requiring any human input."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748977"
                        ],
                        "name": "P. Cimiano",
                        "slug": "P.-Cimiano",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Cimiano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Cimiano"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 286,
                                "start": 278
                            }
                        ],
                        "text": "To assess the performance w.r.t. choices made with the multi-task joint training and the diverse data sources, we evaluated models trained with several combinations of data sources on two benchmark tasks: WordNet knowledge encoding and WSD. WN denotes our model trained only on WordNet, \u201cAmbiguated\u201d WordNet and \u201cBridge\u201d WordNet, WN+CN+Wk is also trained on CN and Wk datasets, and All is trained on all sources."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 195
                            }
                        ],
                        "text": "Shi and Mihalcea (2004) proposed a rule-based system for open-text semantic parsing using WordNet and FrameNet (Baker et al., 1998) while Giuglea and Moschitti (2006) proposed a model to connect WordNet, VerbNet and PropBank (Kingsbury and Palmer, 2002) for semantic parsing using tree kernels."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 150
                            }
                        ],
                        "text": "Some approaches have been directly targeting to enrich existing resources, as we do here with WordNet, (Agirre et al., 2000; Cuadros and Rigau, 2008; Cimiano, 2006) but these never use learning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 28114065,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "996e591bbeab149a8f624a89048c7a10be8322d6",
            "isKey": false,
            "numCitedBy": 600,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "In the last decade, ontologies have received much attention within computer science and related disciplines, most often as the semantic web. Ontology Learning and Population from Text: Algorithms, Evaluation and Applications discusses ontologies for the semantic web, as well as knowledge management, information retrieval, text clustering and classification, as well as natural language processing. Ontology Learning and Population from Text: Algorithms, Evaluation and Applications is structured for research scientists and practitioners in industry. This book is also suitable for graduate-level students in computer science."
            },
            "slug": "Ontology-learning-and-population-from-text-and-Cimiano",
            "title": {
                "fragments": [],
                "text": "Ontology learning and population from text - algorithms, evaluation and applications"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "Ontology Learning and Population from Text: Algorithms, Evaluation and Applications discusses ontologies for the semantic web, aswell as knowledge management, information retrieval, text clustering and classification, as well as natural language processing."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145704247"
                        ],
                        "name": "James Martens",
                        "slug": "James-Martens",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Martens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Martens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 78
                            }
                        ],
                        "text": "The architecture of our system is also related to recent work on gated models (Sutskever et al., 2011) and recursive autoencoders (Bottou, 2011; Socher et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 79
                            }
                        ],
                        "text": "The architecture of our system is also related to recent work on gated models (Sutskever et al., 2011) and recursive autoencoders (Bottou, 2011; Socher et al., 2011)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8843166,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0e5dd8b206806372b3e20b9a2fbdbd0cf9ce1de",
            "isKey": false,
            "numCitedBy": 1254,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Recurrent Neural Networks (RNNs) are very powerful sequence models that do not enjoy widespread use because it is extremely difficult to train them properly. Fortunately, recent advances in Hessian-free optimization have been able to overcome the difficulties associated with training RNNs, making it possible to apply them successfully to challenging sequence problems. In this paper we demonstrate the power of RNNs trained with the new Hessian-Free optimizer (HF) by applying them to character-level language modeling tasks. The standard RNN architecture, while effective, is not ideally suited for such tasks, so we introduce a new RNN variant that uses multiplicative (or \"gated\") connections which allow the current input character to determine the transition matrix from one hidden state vector to the next. After training the multiplicative RNN with the HF optimizer for five days on 8 high-end Graphics Processing Units, we were able to surpass the performance of the best previous single method for character-level language modeling \u2013 a hierarchical non-parametric sequence model. To our knowledge this represents the largest recurrent neural network application to date."
            },
            "slug": "Generating-Text-with-Recurrent-Neural-Networks-Sutskever-Martens",
            "title": {
                "fragments": [],
                "text": "Generating Text with Recurrent Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The power of RNNs trained with the new Hessian-Free optimizer by applying them to character-level language modeling tasks is demonstrated, and a new RNN variant that uses multiplicative connections which allow the current input character to determine the transition matrix from one hidden state vector to the next is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1815154"
                        ],
                        "name": "G. Bakir",
                        "slug": "G.-Bakir",
                        "structuredName": {
                            "firstName": "G\u00f6khan",
                            "lastName": "Bakir",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Bakir"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153379696"
                        ],
                        "name": "T. Hofmann",
                        "slug": "T.-Hofmann",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Hofmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hofmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "118460398"
                        ],
                        "name": "Taskar B Smola Aj",
                        "slug": "Taskar-B-Smola-Aj",
                        "structuredName": {
                            "firstName": "Taskar",
                            "lastName": "Smola Aj",
                            "middleNames": [
                                "B"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Taskar B Smola Aj"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145713874"
                        ],
                        "name": "S. Vishwanathan",
                        "slug": "S.-Vishwanathan",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Vishwanathan",
                            "middleNames": [
                                "V.",
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Vishwanathan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5671144,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2e75ad22a6865c3402925f12317dd0897c67ebe6",
            "isKey": false,
            "numCitedBy": 423,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Machine learning develops intelligent computer systems that are able to generalize from previously seen examples. A new domain of machine learning, in which the prediction must satisfy the additional constraints found in structured data, poses one of machine learning's greatest challenges: learning functional dependencies between arbitrary input and output domains. This volume presents and analyzes the state of the art in machine learning algorithms and theory in this novel field. The contributors discuss applications as diverse as machine translation, document markup, computational biology, and information extraction, among others, providing a timely overview of an exciting field. Contributors Yasemin Altun, Gokhan Bakir [no dot over i], Olivier Bousquet, Sumit Chopra, Corinna Cortes, Hal Daume III, Ofer Dekel, Zoubin Ghahramani, Raia Hadsell, Thomas Hofmann, Fu Jie Huang, Yann LeCun, Tobias Mann, Daniel Marcu, David McAllester, Mehryar Mohri, William Stafford Noble, Fernando Perez-Cruz, Massimiliano Pontil, Marc'Aurelio Ranzato, Juho Rousu, Craig Saunders, Bernhard Scholkopf, Matthias W. Seeger, Shai Shalev-Shwartz, John Shawe-Taylor, Yoram Singer, Alexander J. Smola, Sandor Szedmak, Ben Taskar, Ioannis Tsochantaridis, S.V.N Vishwanathan, Jason Weston Gokhan Bakir [no dot over i] is Research Scientist at the Max Planck Institute for Biological Cybernetics in Tubingen, Germany. Thomas Hofmann is a Director of Engineering at Google's Engineering Center in Zurich and Adjunct Associate Professor of Computer Science at Brown University. Bernhard Scholkopf is Director of the Max Planck Institute for Biological Cybernetics and Professor at the Technical University Berlin. Alexander J. Smola is Senior Principal Researcher and Machine Learning Program Leader at National ICT Australia/Australian National University, Canberra. Ben Taskar is Assistant Professor in the Computer and Information Science Department at the University of Pennsylvania. S. V. N. Vishwanathan is Senior Researcher in the Statistical Machine Learning Program, National ICT Australia with an adjunct appointment at the Research School for Information Sciences and Engineering, Australian National University."
            },
            "slug": "Predicting-Structured-Data-Bakir-Hofmann",
            "title": {
                "fragments": [],
                "text": "Predicting Structured Data"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This volume presents the state of the art in machine learning algorithms and theory in this novel field and discusses applications as diverse as machine translation, document markup, computational biology, and information extraction, providing a timely overview of an exciting field."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1996444"
                        ],
                        "name": "A. Paccanaro",
                        "slug": "A.-Paccanaro",
                        "structuredName": {
                            "firstName": "Alberto",
                            "lastName": "Paccanaro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Paccanaro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 0
                            }
                        ],
                        "text": "Paccanaro and Hinton (2001) developed entity embedding for learning logical relations (but do not model words)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 200844,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b27153da18537bd7ec7fd8205d24a34d1c64883",
            "isKey": false,
            "numCitedBy": 112,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce linear relational embedding as a means of learning a distributed representation of concepts from data consisting of binary relations between these concepts. The key idea is to represent concepts as vectors, binary relations as matrices, and the operation of applying a relation to a concept as a matrix-vector multiplication that produces an approximation to the related concept. A representation for concepts and relations is learned by maximizing an appropriate discriminative goodness function using gradient ascent. On a task involving family relationships, learning is fast and leads to good generalization."
            },
            "slug": "Learning-Distributed-Representations-of-Concepts-Paccanaro-Hinton",
            "title": {
                "fragments": [],
                "text": "Learning Distributed Representations of Concepts Using Linear Relational Embedding"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Knowl. Data Eng."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3200516"
                        ],
                        "name": "B. Decadt",
                        "slug": "B.-Decadt",
                        "structuredName": {
                            "firstName": "Bart",
                            "lastName": "Decadt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Decadt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2653729"
                        ],
                        "name": "Veronique Hoste",
                        "slug": "Veronique-Hoste",
                        "structuredName": {
                            "firstName": "Veronique",
                            "lastName": "Hoste",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Veronique Hoste"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1735272"
                        ],
                        "name": "Walter Daelemans",
                        "slug": "Walter-Daelemans",
                        "structuredName": {
                            "firstName": "Walter",
                            "lastName": "Daelemans",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Walter Daelemans"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145977875"
                        ],
                        "name": "Antal van den Bosch",
                        "slug": "Antal-van-den-Bosch",
                        "structuredName": {
                            "firstName": "Antal",
                            "lastName": "van den Bosch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antal van den Bosch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 7
                            }
                        ],
                        "text": "Hence, Gamble performs worse than during the challenge and is outperformed by MFS.\nextract meaningful information from text to disambiguate some words (WN+CN+Wk is significantly above Random and WN)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 46
                            }
                        ],
                        "text": "Finally, we also report the results of Gamble (Decadt et al., 2004), winner of Senseval-3, on our subset of its data."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 32
                            }
                        ],
                        "text": "This is easier for MFS than for Gamble because Gamble is efficient on rare terms."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 47
                            }
                        ],
                        "text": "Finally, we also report the results of Gamble (Decadt et al., 2004), winner of Senseval-3, on our subset of its data.5\nF1 scores are presented in Table 1 (cols. 4-5)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 12425280,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0e1f63fb5ca375760c1162d33d9336dfd0e440c6",
            "isKey": true,
            "numCitedBy": 114,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "GAMBL is a word expert approach to WSD in which each word expert is trained using memory based learning. Joint feature selection and algorithm parameter optimization are achieved with a genetic algorithm (GA). We use a cascaded classifier approach in which the GA optimizes local context features and the output of a separate keyword classifier (rather than also optimizing the keyword features together with the local context features). A further innovation on earlier versions of memory based WSD is the use of grammatical relation and chunk features. This paper presents the architecture of the system briefly, and discusses its performance on the English lexical sample and all words tasks in SENSEVAL-3."
            },
            "slug": "GAMBL,-genetic-algorithm-optimization-of-WSD-Decadt-Hoste",
            "title": {
                "fragments": [],
                "text": "GAMBL, genetic algorithm optimization of memory-based WSD"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "The architecture of the GAMBL system is presented briefly, and its performance on the English lexical sample and all words tasks in SENSEVAL-3 is discussed."
            },
            "venue": {
                "fragments": [],
                "text": "SENSEVAL@ACL"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3295092"
                        ],
                        "name": "S. Chopra",
                        "slug": "S.-Chopra",
                        "structuredName": {
                            "firstName": "Sumit",
                            "lastName": "Chopra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Chopra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2315504"
                        ],
                        "name": "R. Hadsell",
                        "slug": "R.-Hadsell",
                        "structuredName": {
                            "firstName": "Raia",
                            "lastName": "Hadsell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hadsell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70478759"
                        ],
                        "name": "Aurelio Ranzato",
                        "slug": "Aurelio-Ranzato",
                        "structuredName": {
                            "firstName": "Aurelio",
                            "lastName": "Ranzato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aurelio Ranzato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13919023"
                        ],
                        "name": "F. Huang",
                        "slug": "F.-Huang",
                        "structuredName": {
                            "firstName": "Fu",
                            "lastName": "Huang",
                            "middleNames": [
                                "Jie"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Huang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8531544,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7fc604e1a3e45cd2d2742f96d62741930a363efa",
            "isKey": false,
            "numCitedBy": 794,
            "numCiting": 107,
            "paperAbstract": {
                "fragments": [],
                "text": "Energy-Based Models (EBMs) capture dependencies between variables by associating a scalar energy to each configuration of the variab les. Inference consists in clamping the value of observed variables and finding config urations of the remaining variables that minimize the energy. Learning consists in finding an energy function in which observed configurations of the variables a re given lower energies than unobserved ones. The EBM approach provides a common theoretical framework for many learning models, including traditional discr iminative and generative approaches, as well as graph-transformer networks, co nditional random fields, maximum margin Markov networks, and several manifold learning methods. Probabilistic models must be properly normalized, which sometimes requires evaluating intractable integrals over the space of all poss ible variable configurations. Since EBMs have no requirement for proper normalization, this problem is naturally circumvented. EBMs can be viewed as a form of non-probabilistic factor graphs, and they provide considerably more flexibility in th e design of architectures and training criteria than probabilistic approaches ."
            },
            "slug": "A-Tutorial-on-Energy-Based-Learning-LeCun-Chopra",
            "title": {
                "fragments": [],
                "text": "A Tutorial on Energy-Based Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The EBM approach provides a common theoretical framework for many learning models, including traditional discr iminative and generative approaches, as well as graph-transformer networks, co nditional random fields, maximum margin Markov networks, and several manifold learning methods."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 222,
                                "start": 208
                            }
                        ],
                        "text": "\u2022 Named symbolic entities (synsets, relation types, and lemmas) are all associated with a joint ddimensional vector space, termed the \u201cembedding space\u201d, following previous work in neural language models (see (Bengio, 2008))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 272,
                                "start": 260
                            }
                        ],
                        "text": "Our model is designed with the following key concepts:\n\u2022 Named symbolic entities (synsets, relation types, and lemmas) are all associated with a joint ddimensional vector space, termed the \u201cembedding space\u201d, following previous work in neural language models (see (Bengio, 2008))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 35313960,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "98449bcf80e52e0e902efd288b68c701d5392099",
            "isKey": false,
            "numCitedBy": 102,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Neural-net-language-models-Bengio",
            "title": {
                "fragments": [],
                "text": "Neural net language models"
            },
            "venue": {
                "fragments": [],
                "text": "Scholarpedia"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145648751"
                        ],
                        "name": "H. Robbins",
                        "slug": "H.-Robbins",
                        "structuredName": {
                            "firstName": "Herbert",
                            "lastName": "Robbins",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Robbins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 134
                            }
                        ],
                        "text": "To train the parameters of the energy function E we loop over all of the training data resources and use stochastic gradient descent (Robbins and Monro, 1951)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16945044,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "34ddd8865569c2c32dec9bf7ffc817ff42faaa01",
            "isKey": false,
            "numCitedBy": 6432,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Let M(x) denote the expected value at level x of the response to a certain experiment. M(x) is assumed to be a monotone function of x but is unknown tot he experiment, and it is desire to find the solution x=0 of the equation M(x) = a, where x is a given constant. we give a method for making successive experiments at levels x1, x2,... in such a way that x, will tend to 0 in probability."
            },
            "slug": "A-Stochastic-Approximation-Method-Robbins",
            "title": {
                "fragments": [],
                "text": "A Stochastic Approximation Method"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713428"
                        ],
                        "name": "S. Harabagiu",
                        "slug": "S.-Harabagiu",
                        "structuredName": {
                            "firstName": "Sanda",
                            "lastName": "Harabagiu",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Harabagiu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40497400"
                        ],
                        "name": "D. Moldovan",
                        "slug": "D.-Moldovan",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Moldovan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Moldovan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 79
                            }
                        ],
                        "text": "Word Sense Disambiguation Performance on WSD is assessed on two test sets: the XWN test set and a subset of English All-words WSD task of SensEval-3."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 61
                            }
                        ],
                        "text": "The above algorithm was used for all the data sources except XWN and Wku."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 28
                            }
                        ],
                        "text": "EXtended WordNet (XWN) XWN (Harabagiu and Moldovan, 2002) is built from WordNet glosses (i.e. definitions), syntactically parsed and with content words semantically linked to WN synsets."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 76
                            }
                        ],
                        "text": "%) and yields performance better than MFS (a strong baseline in WSD) on the XWN test set."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 27
                            }
                        ],
                        "text": "EXtended WordNet (XWN) XWN (Harabagiu and Moldovan, 2002) is built from WordNet glosses (i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 50
                            }
                        ],
                        "text": "But this is not enough, the labeled examples from XWN and Wku are crucial (+30"
                    },
                    "intents": []
                }
            ],
            "corpusId": 57245129,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "89a5322bc0b71c642810af7f0b1070607fbc6468",
            "isKey": true,
            "numCitedBy": 66,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Knowledge-processing-on-an-extended-wordnet-Harabagiu-Moldovan",
            "title": {
                "fragments": [],
                "text": "Knowledge processing on an extended wordnet"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 54
                            }
                        ],
                        "text": "Resources like WordNet (Miller, 1995) and ConceptNet (Liu and Singh, 2004) encode common-sense knowledge in the form of relations between entities (e.g. has part( car, wheel) ) but do not link this knowledge to raw text (sentences)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 81
                            }
                        ],
                        "text": "Thanks to our multi-task training and unified representation for MRs and WordNet/ConceptNet relations, our model is potentially able to generalize to such relations that do not exist in WordNet."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 53
                            }
                        ],
                        "text": "Resources like WordNet (Miller, 1995) and ConceptNet (Liu and Singh, 2004) encode common-sense knowledge in the form of relations between entities (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 31
                            }
                        ],
                        "text": "WordNet Enrichment WordNet and ConceptNet use a limited number of relation types (less than 20 of them, e.g. has part and hypernym), and so they do not consider most verbs as relations."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 4
                            }
                        ],
                        "text": "CN (Liu and Singh, 2004) is a common-sense knowledge base in which lemmas or groups of lemmas are linked together with rich semantic relations, for example ( kitchen table NN, used for, eat VB breakfast NN)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 0
                            }
                        ],
                        "text": "ConceptNet v2."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Focusing on conceptnet\u2019s natural language knowledge representation"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of the 8th Intl Conf. on Knowledge-Based Intelligent Information and Engineering Syst."
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 160
                            }
                        ],
                        "text": "This section presents the main contribution of this paper: an energy function which we use to embed lemmas and WordNet entities into the same vector space (see (Lecun et al., 2006) for an introduction to energybased learning)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 161
                            }
                        ],
                        "text": "This section presents the main contribution of this paper: an energy function which we use to embed lemmas and WordNet entities into the same vector space\n(see (Lecun et al., 2006) for an introduction to energybased learning)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "marc\u2019aurelio, and f"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 286,
                                "start": 278
                            }
                        ],
                        "text": "To assess the performance w.r.t. choices made with the multi-task joint training and the diverse data sources, we evaluated models trained with several combinations of data sources on two benchmark tasks: WordNet knowledge encoding and WSD. WN denotes our model trained only on WordNet, \u201cAmbiguated\u201d WordNet and \u201cBridge\u201d WordNet, WN+CN+Wk is also trained on CN and Wk datasets, and All is trained on all sources."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 195
                            }
                        ],
                        "text": "Shi and Mihalcea (2004) proposed a rule-based system for open-text semantic parsing using WordNet and FrameNet (Baker et al., 1998) while Giuglea and Moschitti (2006) proposed a model to connect WordNet, VerbNet and PropBank (Kingsbury and Palmer, 2002) for semantic parsing using tree kernels."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 125
                            }
                        ],
                        "text": "Some approaches have been directly targeting to enrich existing resources, as we do here with WordNet, (Agirre et al., 2000; Cuadros and Rigau, 2008; Cimiano, 2006) but these never use learning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Knownet: using topic signatures acquired from the web for building automatically highly dense knowledge bases"
            },
            "venue": {
                "fragments": [],
                "text": "COLING\u201908 ."
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 39
                            }
                        ],
                        "text": "All code was implemented using Theano (Bergstra et al., 2010)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Theano: a CPU and GPU math expression compiler"
            },
            "venue": {
                "fragments": [],
                "text": "SciPy\u201910 . Oral."
            },
            "year": 2010
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 23,
            "methodology": 17,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 39,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Joint-Learning-of-Words-and-Meaning-Representations-Bordes-Glorot/f2f72cfb48d15d4d2bd1e91a92e7f3ac8635d433?sort=total-citations"
}