{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3230391"
                        ],
                        "name": "A. Georghiades",
                        "slug": "A.-Georghiades",
                        "structuredName": {
                            "firstName": "Athinodoros",
                            "lastName": "Georghiades",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Georghiades"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765887"
                        ],
                        "name": "D. Kriegman",
                        "slug": "D.-Kriegman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kriegman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kriegman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767767"
                        ],
                        "name": "P. Belhumeur",
                        "slug": "P.-Belhumeur",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Belhumeur",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Belhumeur"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 17
                            }
                        ],
                        "text": "This task can be cast into a minimization problem given by\nmin B ;S jjX B Sjj\n2 (6)\nwhere X = [x1; : : : ;xk] is the data matrix for k images of a face (in vector form), and S is a 3 k matrix whose columns, si, are the light source directions scaled by their corresponding source intensities for all\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 66
                            }
                        ],
                        "text": "If the object is non-convex, such as a face, then shadowing in the modeling images is likely to be more pronounced."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 761294,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a7401db2d9c664bb5500e79e7a5d9d97f6829711",
            "isKey": false,
            "numCitedBy": 251,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Due to illumination variability, the same object can appear dramatically different even when viewed in fixed pose. To handle this variability, an object recognition system must employ a representation that is either invariant to, or models this variability. This paper presents an appearance-based method for modeling the variability due to illumination in the images of objects. The method differs from past appearance-based methods, however, in that a small set of training images is used to generate a representation-the illumination cone-which models the complete set of images of an object with Lambertian reflectance map under an arbitrary combination of point light sources at infinity. This method is both an implementation and extension (an extension in that it models cast shadows) of the illumination cone representation proposed in Belhumeur and Kriegman (1996). The method is tested on a database of 660 images of 10 faces, and the results exceed those of popular existing methods."
            },
            "slug": "Illumination-cones-for-recognition-under-variable-Georghiades-Kriegman",
            "title": {
                "fragments": [],
                "text": "Illumination cones for recognition under variable lighting: faces"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This method is both an implementation and extension (an extension in that it models cast shadows) of the illumination cone representation proposed in Belhumeur and Kriegman (1996), and the results exceed those of popular existing methods."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3230391"
                        ],
                        "name": "A. Georghiades",
                        "slug": "A.-Georghiades",
                        "structuredName": {
                            "firstName": "Athinodoros",
                            "lastName": "Georghiades",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Georghiades"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767767"
                        ],
                        "name": "P. Belhumeur",
                        "slug": "P.-Belhumeur",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Belhumeur",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Belhumeur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765887"
                        ],
                        "name": "D. Kriegman",
                        "slug": "D.-Kriegman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kriegman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kriegman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 29
                            }
                        ],
                        "text": "This task can be cast into a minimization problem given by\nmin B ;S jjX B Sjj\n2 (6)\nwhere X = [x1; : : : ;xk] is the data matrix for k images of a face (in vector form), and S is a 3 k matrix whose columns, si, are the light source directions scaled by their corresponding source intensities for all\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 72
                            }
                        ],
                        "text": "If the object is non-convex, such as a face, then shadowing in the modeling images is likely to be more pronounced."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14127241,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3a2faa145c5fe63ab906568a29fa4100220e03d9",
            "isKey": false,
            "numCitedBy": 294,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Image variability due to changes in pose and illumination can seriously impair object recognition. This paper presents appearance-based methods which, unlike previous appearance-based approaches, require only a small set of training images to generate a rich representation that models this variability. Specifically, from as few as three images of an object in fixed pose seen under slightly varying but unknown lighting, a surface and an albedo map are reconstructed. These are then used to generate synthetic images with large variations in pose and illumination and thus build a representation useful for object recognition. Our methods have been tested within the domain of face recognition on a subset of the Yale Face Database B containing 4050 images of 10 faces seen under variable pose and illumination. This database was specifically gathered for testing these generative methods. Their performance is shown to exceed that of popular existing methods."
            },
            "slug": "From-few-to-many:-generative-models-for-recognition-Georghiades-Belhumeur",
            "title": {
                "fragments": [],
                "text": "From few to many: generative models for recognition under variable pose and illumination"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Appearances-based methods which, unlike previous appearance-based approaches, require only a small set of training images to generate a rich representation that models this variability, are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "117481816"
                        ],
                        "name": "D. Mumford",
                        "slug": "D.-Mumford",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mumford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mumford"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36427051"
                        ],
                        "name": "Peter W. Hallinan",
                        "slug": "Peter-W.-Hallinan",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hallinan",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter W. Hallinan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118557991,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "07df055035fb3e877c28efe4d2300b697c3b225a",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Successful recognition systems must be able to handle not only variations in the geometry of the objects they model, but also arbitrary variations in lighting. We propose a deformable template for unoccluded, frontally-viewed human faces that handles both kinds of variation. Lighting is modeled by finding a basis for face space that can be used to synthesize a face image given lighting conditions, or to determine lighting conditions given a face image. Geometric distortions are captured by automatically \"morphing\" the input face to the synthesized face. Each of several different face models representing both individuals and average faces was tested on two tasks: discriminating the individual represented by the model from all other faces and nonfaces (about 63 positive examples and 1100 negative examples) and discriminating faces from nonfaces (about 755 positive examples and 450 negative examples). Nonfaces here means patches from random natural and artificial scenes. Each model performed extremely well; for false alarm rates of about 0-3 percent miss rates typically fell in 0-5 percent range indicating that distributions of goodness of fit criteria for negative and positive exemplars are actually very well separated. Nothing about the recognition strategy advocated here is particular to faces; in principle, the model is easily extendible to any other viewpoint or to any other object."
            },
            "slug": "A-deformable-model-for-the-recognition-of-human-Mumford-Hallinan",
            "title": {
                "fragments": [],
                "text": "A deformable model for the recognition of human faces under arbitrary illumination"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work proposes a deformable template for unoccluded, frontally-viewed human faces that handles both kinds of variation in lighting and geometry, and in principle is easily extendible to any other viewpoint or toAny other object."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1830709"
                        ],
                        "name": "A. Lanitis",
                        "slug": "A.-Lanitis",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Lanitis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lanitis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 207
                            }
                        ],
                        "text": "These partial derivatives can also be expressed as a series, giving\nz x (x; y; c 1 (w)) =\nX c\n1 (w) x(x; y;w) (11)\nand\nz y (x; y; c 2 (w)) =\nX c\n2 (w) y(x; y;w): (12)\nNote that in general c 1 (w) 6= c 2 (w), which implies that z xy (x; y) 6= z yx (x; y)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 699530,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b7e722de154fa30da9d534a935ed7c5dc233ff9",
            "isKey": false,
            "numCitedBy": 724,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Face images are difficult to interpret because they are highly variable. Sources of variability include individual appearance, 3D pose, facial expression, and lighting. We describe a compact parametrized model of facial appearance which takes into account all these sources of variability. The model represents both shape and gray-level appearance, and is created by performing a statistical analysis over a training set of face images. A robust multiresolution search algorithm is used to fit the model to faces in new images. This allows the main facial features to be located, and a set of shape, and gray-level appearance parameters to be recovered. A good approximation to a given face can be reconstructed using less than 100 of these parameters. This representation can be used for tasks such as image coding, person identification, 3D pose recovery, gender recognition, and expression recognition. Experimental results are presented for a database of 690 face images obtained under widely varying conditions of 3D pose, lighting, and facial expression. The system performs well on all the tasks listed above."
            },
            "slug": "Automatic-Interpretation-and-Coding-of-Face-Images-Lanitis-Taylor",
            "title": {
                "fragments": [],
                "text": "Automatic Interpretation and Coding of Face Images Using Flexible Models"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A compact parametrized model of facial appearance which takes into account all sources of variability and can be used for tasks such as image coding, person identification, 3D pose recovery, gender recognition, and expression recognition is described."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205216"
                        ],
                        "name": "Y. Adini",
                        "slug": "Y.-Adini",
                        "structuredName": {
                            "firstName": "Yael",
                            "lastName": "Adini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Adini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2957934"
                        ],
                        "name": "Y. Moses",
                        "slug": "Y.-Moses",
                        "structuredName": {
                            "firstName": "Yael",
                            "lastName": "Moses",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Moses"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743045"
                        ],
                        "name": "S. Ullman",
                        "slug": "S.-Ullman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Ullman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ullman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms: Face Recognition, Image-Based Rendering, Appearance-Based Vision, Face Modeling, Illumination and Pose Modeling, Lighting, Illumination Cones, Generative Models."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6519687,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "59e9ef8b61182acace9e37f41f9c2a03db69c15b",
            "isKey": false,
            "numCitedBy": 905,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "A face recognition system must recognize a face from a novel image despite the variations between images of the same face. A common approach to overcoming image variations because of changes in the illumination conditions is to use image representations that are relatively insensitive to these variations. Examples of such representations are edge maps, image intensity derivatives, and images convolved with 2D Gabor-like filters. Here we present an empirical study that evaluates the sensitivity of these representations to changes in illumination, as well as viewpoint and facial expression. Our findings indicated that none of the representations considered is sufficient by itself to overcome image variations because of a change in the direction of illumination. Similar results were obtained for changes due to viewpoint and expression. Image representations that emphasized the horizontal features were found to be less sensitive to changes in the direction of illumination. However, systems based only on such representations failed to recognize up to 20 percent of the faces in our database. Humans performed considerably better under the same conditions. We discuss possible reasons for this superiority and alternative methods for overcoming illumination effects in recognition."
            },
            "slug": "Face-Recognition:-The-Problem-of-Compensating-for-Adini-Moses",
            "title": {
                "fragments": [],
                "text": "Face Recognition: The Problem of Compensating for Changes in Illumination Direction"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Evaluating the sensitivity of image representations to changes in illumination, as well as viewpoint and facial expression, indicated that none of the representations considered is sufficient by itself to overcome image variations because of a change in the direction of illumination."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38480590"
                        ],
                        "name": "Wenyi Zhao",
                        "slug": "Wenyi-Zhao",
                        "structuredName": {
                            "firstName": "Wenyi",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wenyi Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9215658"
                        ],
                        "name": "R. Chellappa",
                        "slug": "R.-Chellappa",
                        "structuredName": {
                            "firstName": "Rama",
                            "lastName": "Chellappa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chellappa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 268,
                                "start": 264
                            }
                        ],
                        "text": "\u2026y; c(w)) = X c(w) x(x; y;w) (9)\nand\nzy(x; y; c(w)) = X c(w) y(x; y;w): (10)\nSince the partial derivatives of the basis functions, x(x; y;w) and y(x; y;w), are integrable and the expansions of zx(x; y) and zy(x; y) share the same coefficients c(w), it is easy to see that zxy(x; y) = zyx(x; y)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7316199,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5ae6c0c09bdb6b76034b6c529f9d8baf2a173188",
            "isKey": false,
            "numCitedBy": 154,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Sensitivity to variations in pose is a challenging problem in face recognition using appearance-based methods. More specifically, the appearance of a face changes dramatically when viewing and/or lighting directions change. Various approaches have been proposed to solve this difficult problem. They can be broadly divided into three classes: (1) multiple image-based methods where multiple images of various poses per person are available; (2) hybrid methods where multiple example images are available during learning but only one database image per person is available during recognition; and (3) single image-based methods where no example-based learning is carried out. We present a method that comes under class 3. This method, based on shape-from-shading (SFS), improves the performance of a face recognition system in handling variations due to pose and illumination via image synthesis."
            },
            "slug": "SFS-based-view-synthesis-for-robust-face-Zhao-Chellappa",
            "title": {
                "fragments": [],
                "text": "SFS based view synthesis for robust face recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This method, based on shape-from-shading (SFS), improves the performance of a face recognition system in handling variations due to pose and illumination via image synthesis."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740300"
                        ],
                        "name": "D. Beymer",
                        "slug": "D.-Beymer",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Beymer",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Beymer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "totypical faces, and then direct template matching is used to recognize faces [ 4 , 5, 68, 67]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This method for handling pose variability differs from [ 4 , 38, 30, 43] in that we warp synthetic"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2546027,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9e5949d95c53dd041c721bf40e67b3966805e385",
            "isKey": false,
            "numCitedBy": 488,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "Researchers in computer vision and pattern recognition have worked on automatic techniques for recognizing human faces for the last 20 years. While some systems, especially template-based ones, have been quite successful on expressionless, frontal views of faces with controlled lighting, not much work has taken face recognizers beyond these narrow imaging conditions. Our goal is to build a face recognizer that works under varying pose, the difficult part of which is to handle face relations in depth. Building on successful template-based systems, our basic approach is to represent faces with templates from multiple model views that cover different poses from the viewing sphere. To recognize a novel view, the recognizer locates the eyes and nose features, uses these locations to geometrically register the input with model views, and then uses correlation on model templates to find the best match in the data base of people. Our system has achieved a recognition rate of 98% on a data base of 62 people containing 10 testing and 15 modeling views per person.<<ETX>>"
            },
            "slug": "Face-recognition-under-varying-pose-Beymer",
            "title": {
                "fragments": [],
                "text": "Face recognition under varying pose"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The goal is to build a face recognizer that works under varying pose, the difficult part of which is to handle face relations in depth."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750470"
                        ],
                        "name": "S. Nayar",
                        "slug": "S.-Nayar",
                        "structuredName": {
                            "firstName": "Shree",
                            "lastName": "Nayar",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nayar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "82910116"
                        ],
                        "name": "H. Murase",
                        "slug": "H.-Murase",
                        "structuredName": {
                            "firstName": "Hiroshi",
                            "lastName": "Murase",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Murase"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 39351466,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "702bec6cb3269d4cece8efbbba7a8e17210be42d",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Appearance matching was recently demonstrated as a robust and efficient approach to 3D object recognition and pose estimation. Each object is represented as a continuous appearance manifold in a low-dimensional subspace parametrized by object pose and illumination direction. Here, the structural properties of appearance manifolds are analyzed with the aim of making appearance representation efficient in off-line computation, storage requirements, and on-line recognition time. In particular, the effect of illumination on the structure of the appearance manifold is studied. For an ideal diffuse surface of arbitrary texture, the appearance manifold is linear and of dimensionality 3.This enables the construction of the entire illumination manifold from just three images of the object taken using linearly independent light sources. This result is shown to hold even for illumination by multiple light sources and for concave surfaces that exhibit interreflections. Finally, a simple but efficient algorithm is presented that uses just three manifold points for recognizing images taken under novel illuminations."
            },
            "slug": "Dimensionality-of-Illumination-Manifolds-in-Nayar-Murase",
            "title": {
                "fragments": [],
                "text": "Dimensionality of Illumination Manifolds in Appearance Matching"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The structural properties of appearance manifolds are analyzed with the aim of making appearance representation efficient in off-line computation, storage requirements, and on-line recognition time."
            },
            "venue": {
                "fragments": [],
                "text": "Object Representation in Computer Vision"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1830709"
                        ],
                        "name": "A. Lanitis",
                        "slug": "A.-Lanitis",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Lanitis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lanitis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 196
                            }
                        ],
                        "text": "\u2026stated in Equation 6 can then be reformulated into:\nmin b j ;si X ij wijjxij < b j ; si > j 2 (7)\nwhere xij is the j-th pixel of the i-th image, b j is the j-th row of matrix B 2 IRn 3, si is the light source direction and strength in the i-th image, and\nwij =\n1 xij valid measurement, 0 otherwise."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 165
                            }
                        ],
                        "text": "A conservative threshold is then chosen to determine shadows, making it almost certain that no invalid data is included in the estimation process, at the small expense of throwing away a few valid measurements."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18648884,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bf474fd5b89b6b38bec83cd1e8d3b11166ba2a1a",
            "isKey": false,
            "numCitedBy": 220,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Face images are difficult to interpret because they are highly variable. Sources of variability include individual appearance, 3D pose, facial expression and lighting. We describe a compact parametrised model of facial appearance which takes into account all these sources of variability. The model represents both shape and grey-level appearance and is created by performing a statistical analysis over a training set of face images. A robust multi-resolution search algorithm is used to fit the model to faces in new images. This allows the main facial features to be located and a set of shape and grey-level appearance parameters to be recovered. A good approximation to a given face can be reconstructed using less than 100 of these parameters. This representation can be used for tasks such as image coding, person identification, pose recovery, gender recognition and expression recognition. The system performs well on all the tasks listed above.<<ETX>>"
            },
            "slug": "A-unified-approach-to-coding-and-interpreting-face-Lanitis-Taylor",
            "title": {
                "fragments": [],
                "text": "A unified approach to coding and interpreting face images"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A compact parametrised model of facial appearance which takes into account all sources of variability and can be used for tasks such as image coding, person identification, pose recovery, gender recognition and expression recognition is described."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36427051"
                        ],
                        "name": "Peter W. Hallinan",
                        "slug": "Peter-W.-Hallinan",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hallinan",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter W. Hallinan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 52
                            }
                        ],
                        "text": "When the surface reflectance can be approximated as Lambertian, this illumination cone can\nbe constructed from a handful of images acquired under variable lighting [1]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 155
                            }
                        ],
                        "text": "Since the images have shadows (both cast and attached), and possibly saturations, we first have to determine which data values do not satisfy the Lambertian assumption."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 50
                            }
                        ],
                        "text": "In this paper, we have assumed that faces exhibit Lambertian reflectance which, as demonstrated by the recognition results, is a good approximation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 195,
                                "start": 186
                            }
                        ],
                        "text": "This 1ftp://plucky.cs.yale.edu/CVC/pub/images/yalefacesB/\ncone, termed the illumination cone, can be constructed from as few as three images [1] if the object is convex in shape and has Lambertian reflectance."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 10
                            }
                        ],
                        "text": "Under the Lambertian model of reflectance, the image x is given by\nx = max(Bs; 0); (2)\nwhere max(Bs; 0) sets to zero all negative components of the vector Bs."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 23
                            }
                        ],
                        "text": "Let the surface have a Lambertian reflectance [37] with albedo (x; y) and be viewed orthographically."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 103
                            }
                        ],
                        "text": "Nevertheless, applying our method to the recognition of other object classes will require to relax the Lambertian assumption allowing for more complex bi-directional reflectance distribution functions (BRDFs)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 46
                            }
                        ],
                        "text": "When SVD is used to find B from images with shadows, these systematic errors can bias its estimate significantly."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms: Face Recognition, Image-Based Rendering, Appearance-Based Vision, Face Modeling, Illumination and Pose Modeling, Lighting, Illumination Cones, Generative Models."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 72
                            }
                        ],
                        "text": "Due to this superposition, the set of all possible images C of a convex Lambertian surface created by varying the direction and strength of an arbitrary number of point light sources at infinity is a convex cone."
                    },
                    "intents": []
                }
            ],
            "corpusId": 46324024,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "236c132eda073ad7e80fcc45a248ac2baea9a786",
            "isKey": true,
            "numCitedBy": 342,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "When recognizing a fixed object from a fixed viewpoint, the dominant source of variation in image intensity is lighting changes. We propose a low-dimensional model for human faces that can both synthesize a face image when given lighting conditions and can estimate lighting conditions when given a face image. The model can handle non-Lambertian and self-shadowing surfaces such as faces because it does not make any assumptions about either the surface geometry or bidirectional reflectance function. The model can be adapted to handle any arbitrary lighting condition, and is easily extendable to any other viewpoint or to any other object.<<ETX>>"
            },
            "slug": "A-low-dimensional-representation-of-human-faces-for-Hallinan",
            "title": {
                "fragments": [],
                "text": "A low-dimensional representation of human faces for arbitrary lighting conditions"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A low-dimensional model for human faces is proposed that can both synthesize a face image when given lighting conditions and can estimate lighting conditions when given a face images."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2275441"
                        ],
                        "name": "K. Yow",
                        "slug": "K.-Yow",
                        "structuredName": {
                            "firstName": "Kin",
                            "lastName": "Yow",
                            "middleNames": [
                                "Choong"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Yow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745672"
                        ],
                        "name": "R. Cipolla",
                        "slug": "R.-Cipolla",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Cipolla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cipolla"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Furthermore, we assume that the face to be recognized has been located (but not necessarily accurately aligned) within the image, as there are numerous methods for finding faces in images [13], [55], [60], [38], [9], [41], [44], [40], [32], [22], [ 72 ], [45], [58], [57], [71]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16932868,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "30e2f29d26f31846d6e0294cfa3733adfc618bbb",
            "isKey": false,
            "numCitedBy": 432,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Feature-based-human-face-detection-Yow-Cipolla",
            "title": {
                "fragments": [],
                "text": "Feature-based human face detection"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740300"
                        ],
                        "name": "D. Beymer",
                        "slug": "D.-Beymer",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Beymer",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Beymer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 150
                            }
                        ],
                        "text": "\u2026terms of this expansion,\ngiving\nzx(x; y; c(w)) = X c(w) x(x; y;w) (9)\nand\nzy(x; y; c(w)) = X c(w) y(x; y;w): (10)\nSince the partial derivatives of the basis functions, x(x; y;w) and y(x; y;w), are integrable and the expansions of zx(x; y) and zy(x; y) share the same coefficients c(w), it is easy\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14814282,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "66505cb708b098a93331471f079965f6ded4ea7f",
            "isKey": false,
            "numCitedBy": 449,
            "numCiting": 76,
            "paperAbstract": {
                "fragments": [],
                "text": "To create a pose-invariant face recognizer, one strategy is the view-based approach, which uses a set of real example views at different poses. But what if we only have one real view available, such as a scanned passport photo-can we still recognize faces under different poses? Given one real view at a known pose, it is still possible to use the view-based approach by exploiting prior knowledge of faces to generate virtual views, or views of the face as seen from different poses. To represent prior knowledge, we use 2D example views of prototype faces under different rotations. We develop example-based techniques for applying the rotation seen in the prototypes to essentially \"rotate\" the single real view which is available. Next, the combined set of one real and multiple virtual views is used as example views for a view-based, pose-invariant face recognizer. Oar experiments suggest that among the techniques for expressing prior knowledge of faces, 2D example-based approaches should be considered alongside the more standard 3D modeling techniques.<<ETX>>"
            },
            "slug": "Face-recognition-from-one-example-view-Beymer-Poggio",
            "title": {
                "fragments": [],
                "text": "Face recognition from one example view"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Oar experiments suggest that among the techniques for expressing prior knowledge of faces, 2D example-based approaches should be considered alongside the more standard 3D modeling techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715634"
                        ],
                        "name": "Ming-Hsuan Yang",
                        "slug": "Ming-Hsuan-Yang",
                        "structuredName": {
                            "firstName": "Ming-Hsuan",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming-Hsuan Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145237406"
                        ],
                        "name": "N. Ahuja",
                        "slug": "N.-Ahuja",
                        "structuredName": {
                            "firstName": "Narendra",
                            "lastName": "Ahuja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ahuja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765887"
                        ],
                        "name": "D. Kriegman",
                        "slug": "D.-Kriegman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kriegman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kriegman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16705499,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29fe0a5209ad7c538aeaf9819644abac532bcce9",
            "isKey": false,
            "numCitedBy": 120,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "We present two methods using mixtures of linear sub-spaces for face detection in gray level images. One method uses a mixture of factor analyzers to concurrently perform clustering and, within each cluster, perform local dimensionality reduction. The parameters of the mixture model are estimated using an EM algorithm. A face is detected if the probability of an input sample is above a predefined threshold. The other mixture of subspaces method uses Kohonen's self-organizing map for clustering and Fisher linear discriminant to find the optimal projection for pattern classification, and a Gaussian distribution to model the class-conditioned density function of the projected samples for each class. The parameters of the class-conditioned density functions are maximum likelihood estimates and the decision rule is also based on maximum likelihood. A wide range of face images including ones in different poses, with different expressions and under different lighting conditions are used as the training set to capture the variations of human faces. Our methods have been tested on three sets of 225 images which contain 871 faces. Experimental results on the first two datasets show that our methods perform as well as the best methods in the literature, yet have fewer false detects."
            },
            "slug": "Face-detection-using-mixtures-of-linear-subspaces-Yang-Ahuja",
            "title": {
                "fragments": [],
                "text": "Face detection using mixtures of linear subspaces"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "Two methods using mixtures of linear sub-spaces for face detection in gray level images using Kohonen's self-organizing map for clustering and Fisher linear discriminant to find the optimal projection for pattern classification are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118025322"
                        ],
                        "name": "Hansen F. Chen",
                        "slug": "Hansen-F.-Chen",
                        "structuredName": {
                            "firstName": "Hansen",
                            "lastName": "Chen",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hansen F. Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767767"
                        ],
                        "name": "P. Belhumeur",
                        "slug": "P.-Belhumeur",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Belhumeur",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Belhumeur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34734622"
                        ],
                        "name": "D. Jacobs",
                        "slug": "D.-Jacobs",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Jacobs",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Jacobs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 59
                            }
                        ],
                        "text": "For the purpose of this estimation, any invalid data will be treated as missing measurements."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9980512,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "9cab8e79ee34b346fae514310ad0402cf5e3119c",
            "isKey": false,
            "numCitedBy": 360,
            "numCiting": 82,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of determining functions of an image of an object that are insensitive to illumination changes. We first show that for an object with Lambertian reflectance there are no discriminative functions that are invariant to illumination. This result leads as to adopt a probabilistic approach in which we analytically determine a probability distribution for the image gradient as a function of the surface's geometry and reflectance. Our distribution reveals that the direction of the image gradient is insensitive to changes in illumination direction. We verify this empirically by constructing a distribution for the image gradient from more than 20 million samples of gradients in a database of 1,280 images of 20 inanimate objects taken under varying lighting condition. Using this distribution we develop an illumination insensitive measure of image comparison and test it on the problem of face recognition."
            },
            "slug": "In-search-of-illumination-invariants-Chen-Belhumeur",
            "title": {
                "fragments": [],
                "text": "In search of illumination invariants"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "An illumination insensitive measure of image comparison is developed and tested on the problem of face recognition by analytically determining a probability distribution for the image gradient as a function of the surface's geometry and reflectance."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3230391"
                        ],
                        "name": "A. Georghiades",
                        "slug": "A.-Georghiades",
                        "structuredName": {
                            "firstName": "Athinodoros",
                            "lastName": "Georghiades",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Georghiades"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767767"
                        ],
                        "name": "P. Belhumeur",
                        "slug": "P.-Belhumeur",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Belhumeur",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Belhumeur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765887"
                        ],
                        "name": "D. Kriegman",
                        "slug": "D.-Kriegman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kriegman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kriegman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "This task can be cast into a minimization problem given by\nmin B ;S jjX B Sjj\n2 (6)\nwhere X = [x1; : : : ;xk] is the data matrix for k images of a face (in vector form), and S is a 3 k matrix whose columns, si, are the light source directions scaled by their corresponding source intensities for all\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17347397,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e8c21e69440e3f1d03a1f50e136967a1971d81bc",
            "isKey": false,
            "numCitedBy": 77,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an illumination-based method for synthesizing images of an object under novel viewing conditions. Our method requires as few as three images of the object taken under variable illumination, but from a fixed viewpoint. Unlike multi-view based image synthesis, our method does not require the determination of point or line correspondences. Furthermore, our method is able to synthesize not simply novel viewpoints, but novel illumination conditions as well. We demonstrate the effectiveness of our approach by generating synthetic images of human faces."
            },
            "slug": "Illumination-based-image-synthesis:-creating-novel-Georghiades-Belhumeur",
            "title": {
                "fragments": [],
                "text": "Illumination-based image synthesis: creating novel images of human faces under differing pose and lighting"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "An illumination-based method for synthesizing images of an object under novel viewing conditions that requires as few as three images of the object taken under variable illumination, but from a fixed viewpoint is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Workshop on Multi-View Modeling and Analysis of Visual Scenes (MVIEW'99)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140335"
                        ],
                        "name": "A. Shashua",
                        "slug": "A.-Shashua",
                        "structuredName": {
                            "firstName": "Amnon",
                            "lastName": "Shashua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shashua"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743045"
                        ],
                        "name": "S. Ullman",
                        "slug": "S.-Ullman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Ullman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ullman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 116478939,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0075fa2e7d8f341f497e6a6fa126b9afa6396a34",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This thesis addresses the problem of visual recognition under two sources of variability: geometric and photometric. The geometric deals with the relation between 3D objects and their views under parallel, perspective, and central projection. The photometric deals with the relation between 3D matte objects and their images under changing illumination conditions. Taken together, an alignment-based method is presented for recognizing objects viewed from arbitrary viewing positions and illuminated by arbitrary settings of light sources. \nIn the first part of the thesis we show that a relative non-metric structure invariant that holds under both parallel and central projection models can be defined relative to four points in space and, moreover, can be uniquely recovered from two views regardless of whether one or the other was created by means of parallel or central projection. As a result, we propose a method that is useful for purposes of recognition (via alignment) and structure from motion, and that has the following properties: (i) the transition between projection models is natural and transparent, (ii) camera calibration is not required, and (iii) structure is defined relative to the object and does not involve the center of projection. \nThe second part of this thesis addresses the photometric aspect of recognition under changing illumination. First, we argue that image properties alone do not appear to be generally sufficient for dealing with the effects of changing illumination; we propose a model-based approach instead. Second, we observe that the process responsible for factoring out the illumination during the recognition process appears to require more than just contour information, but just slightly more. Taken together, we introduce a model-based alignment method that compensates for the effects of changing illumination by linearly combining model images of the object. The model images, each taken from a different illumination condition, can be converted onto novel images of the object regardless of whether the image is represented by grey-values, sign-bits, or other forms of reduced representations. \nThe third part of this thesis addresses the problem of achieving full correspondence between model views and puts together the geometric and photometric components into a single recognition system. The method for achieving correspondence is based on combining affine or projective geometry and optical flow techniques into a single working framework. (Copies available exclusively from MIT Libraries, Rm. 14-0551, Cambridge, MA 02139-4307. Ph. 617-253-5668; Fax 617-253-1690.)"
            },
            "slug": "Geometry-and-photometry-in-three-dimensional-visual-Shashua-Ullman",
            "title": {
                "fragments": [],
                "text": "Geometry and photometry in three-dimensional visual recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A model-based alignment method that compensates for the effects of changing illumination by linearly combining model images of the object and the method for achieving correspondence is based on combining affine or projective geometry and optical flow techniques into a single working framework."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716933"
                        ],
                        "name": "I. Cox",
                        "slug": "I.-Cox",
                        "structuredName": {
                            "firstName": "Ingemar",
                            "lastName": "Cox",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Cox"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2864754"
                        ],
                        "name": "J. Ghosn",
                        "slug": "J.-Ghosn",
                        "structuredName": {
                            "firstName": "Joumana",
                            "lastName": "Ghosn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ghosn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3203897"
                        ],
                        "name": "P. Yianilos",
                        "slug": "P.-Yianilos",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Yianilos",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Yianilos"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms: Face Recognition, Image-Based Rendering, Appearance-Based Vision, Face Modeling, Illumination and Pose Modeling, Lighting, Illumination Cones, Generative Models."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15344386,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb55f2c02ada7b3e79d54baffccb38a71290b844",
            "isKey": false,
            "numCitedBy": 298,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of feature-based face recognition in the setting where only a single example of each face is available for training. The mixture-distance technique we introduce achieves a recognition rate of 95% on a database of 685 people in which each face is represented by 30 measured distances. This is currently the best recorded recognition rate for a feature-based system applied to a database of this size. By comparison, nearest neighbor search using Euclidean distance yields 84%. In our work a novel distance function is constructed based on local second order statistics as estimated by modeling the training data as a mixture of normal densities. We report on the results from mixtures of several sizes. We demonstrate that a flat mixture of mixtures performs as well as the best model and therefore represents an effective solution to the model selection problem. A mixture perspective is also taken for individual Gaussians to choose between first order (variance) and second order (covariance) models. Here an approximation to flat combination is proposed and seen to perform well in practice. Our results demonstrate that even in the absence of multiple training examples for each class, it is sometimes possible to infer from a statistical model of training data, a significantly improved distance function for use in pattern recognition."
            },
            "slug": "Feature-based-face-recognition-using-Cox-Ghosn",
            "title": {
                "fragments": [],
                "text": "Feature-based face recognition using mixture-distance"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The results demonstrate that even in the absence of multiple training examples for each class, it is sometimes possible to infer from a statistical model of training data, a significantly improved distance function for use in pattern recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398079691"
                        ],
                        "name": "Tammy Riklin-Raviv",
                        "slug": "Tammy-Riklin-Raviv",
                        "structuredName": {
                            "firstName": "Tammy",
                            "lastName": "Riklin-Raviv",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tammy Riklin-Raviv"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140335"
                        ],
                        "name": "A. Shashua",
                        "slug": "A.-Shashua",
                        "structuredName": {
                            "firstName": "Amnon",
                            "lastName": "Shashua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shashua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 129
                            }
                        ],
                        "text": "Therefore, an alternative method is needed to find B , one that takes into account the fact that some data values are invalid and should not be used in the estimation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1756283,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7f18c9a9859b0b7f78a1a5ffc158b4f717565fff",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper addresses the problem of \"class-based\" recognition and image-synthesis with varying illumination. The class-based synthesis and recognition tasks are defined as follows: given a single input image of an object, and a sample of images with varying illumination conditions of other objects of the same general class, capture the equivalence relationship (by generation of new images or by invariants) among all images of the object corresponding to new illumination conditions. The key result in our approach is based on a definition of an illumination invariant signature image, we call the \"quotient\" image, which enables an analytic generation of the image space with varying illumination from a single input image and a very small sample of other objects of the class-in our experiments as few as two objects. In many cases the recognition results outperform by far conventional methods and the image-synthesis is of remarkable quality considering the size of the database of example images and the mild pre-process required for making the algorithm work."
            },
            "slug": "The-quotient-image:-Class-based-recognition-and-Riklin-Raviv-Shashua",
            "title": {
                "fragments": [],
                "text": "The quotient image: Class based recognition and synthesis under varying illumination conditions"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "The key result in this approach is based on a definition of an illumination invariant signature image, which enables an analytic generation of the image space with varying illumination from a single input image and a very small sample of other objects of the class-in the authors' experiments as few as two objects."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "82910116"
                        ],
                        "name": "H. Murase",
                        "slug": "H.-Murase",
                        "structuredName": {
                            "firstName": "Hiroshi",
                            "lastName": "Murase",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Murase"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750470"
                        ],
                        "name": "S. Nayar",
                        "slug": "S.-Nayar",
                        "structuredName": {
                            "firstName": "Shree",
                            "lastName": "Nayar",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nayar"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms: Face Recognition, Image-Based Rendering, Appearance-Based Vision, Face Modeling, Illumination and Pose Modeling, Lighting, Illumination Cones, Generative Models."
                    },
                    "intents": []
                }
            ],
            "corpusId": 61999742,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c5648d1f511a5180cc0bf7af80a42d3dea3a4680",
            "isKey": false,
            "numCitedBy": 322,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors address the problem of automatically learning object models for recognition and pose estimation. In contrast to the traditional approach, they formulate the recognition problem as one of matching visual appearance rather than shape. The appearance of an object in a two-dimensional image depends on its shape, reflectance properties, pose in the scene, and the illumination conditions. While shape and reflectance are intrinsic properties of an object and are constant, pose and illumination vary from scene to scene. They present a new compact representation of object appearance that is parameterized by pose and illumination. They have conducted experiments using several objects with complex appearance characteristics.<<ETX>>"
            },
            "slug": "Learning-and-recognition-of-3D-objects-from-Murase-Nayar",
            "title": {
                "fragments": [],
                "text": "Learning and recognition of 3D objects from appearance"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The authors address the problem of automatically learning object models for recognition and pose estimation as one of matching visual appearance rather than shape and present a new compact representation of object appearance that is parameterized by pose and illumination."
            },
            "venue": {
                "fragments": [],
                "text": "[1993] Proceedings IEEE Workshop on Qualitative Vision"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107496353"
                        ],
                        "name": "W. Zhao",
                        "slug": "W.-Zhao",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9215658"
                        ],
                        "name": "R. Chellappa",
                        "slug": "R.-Chellappa",
                        "structuredName": {
                            "firstName": "Rama",
                            "lastName": "Chellappa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chellappa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2103240750"
                        ],
                        "name": "P. J. PhillipsCenter",
                        "slug": "P.-J.-PhillipsCenter",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "PhillipsCenter",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. J. PhillipsCenter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 13341931,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aea16acb0677c83149742e547bcdc531e55bdd6b",
            "isKey": false,
            "numCitedBy": 261,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe a holistic face recognition method based on subspace Linear Dis-criminant Analysis (LDA). The method consists of two steps: rst we project the face image from the original vector space to a face subspace via Principal Component Analysis where the subspace dimension is carefully chosen, and then we use LDA to obtain a linear classiier in the subspace. The criterion we use to choose the subspace dimension enables us to generate class-separable features via LDA from the full subspace representation. Hence we are able to solve the generalization/overrtting problem when we perform face recognition on a large face dataset but with very few training face images available per testing person. In addition, we employ a weighted distance metric guided by the LDA eigenvalues to improve the performance of the subspace LDA method. Finally, the improved performance of the subspace LDA approach is demonstrated through experiments using the FERET dataset for face recognition/veriication, a large mugshot dataset for person veriication, and the MPEG-7 dataset. We believe that this approach provides a useful framework for other image recognition tasks as well."
            },
            "slug": "Subspace-Linear-Discriminant-Analysis-for-Face-Zhao-Chellappa",
            "title": {
                "fragments": [],
                "text": "Subspace Linear Discriminant Analysis for Face RecognitionW"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "The holistic face recognition method based on subspace Linear Dis-criminant Analysis (LDA) is described, which is able to solve the generalization/overrtting problem when the authors perform face recognition on a large face dataset but with very few training face images available per testing person."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1841911"
                        ],
                        "name": "Yizhou Yu",
                        "slug": "Yizhou-Yu",
                        "structuredName": {
                            "firstName": "Yizhou",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yizhou Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 129
                            }
                        ],
                        "text": "In the first set, tests were performed under variable illumination but fixed pose, and the goal was, first, to compare the illumination cones representation with three other popular methods, and second, to test the accuracy of the subspace approximation of illumination cones."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8460642,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ec203963f65100b84b10361b3fc5c123c3d89c6c",
            "isKey": false,
            "numCitedBy": 220,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a new approach to producing photorealistic computer renderings of real architectural scenes under novel lighting conditions, such as at different times of day, starting from a small set of photographs of the real scene. Traditional texture mapping approaches to image-based modeling and rendering are unable to do this because texture maps are the product of the interaction between lighting and surface reflectance and one cannot deal with novel lighting without dissecting their respective contributions. To obtain this decomposition into lighting and reflectance, our basic approach is to solve a series of optimization problems to find the parameters of appropriate lighting and reflectance models that best explain the measured values in the various photographs of the scene. The lighting models include the radiance distributions from the sun and the sky, as well as the landscape to consider the effect of secondary illumination from the environment. The reflectance models are for the surfaces of the architecture. Photographs are taken for the sun, the sky, the landscape, as well as the architecture at a few different times of day to collect enough data for recovering the various lighting and reflectance models. We can predict novel illumination conditions with the recovered lighting models and use these together with the recovered reflectance values to produce renderings of the scene. Our results show that our goal of generating photorealistic renderings of real architectural scenes under novel lighting conditions has been achieved. CR Categories: I.2.10 [Artificial Intelligence]: Vision and Scene Understanding\u2014modeling and recovery of physical attributes I.3.7 [Computer Graphics]: Three-dimensional Graphics and Realism\u2014color, shading, shadowing, and texture , visible line/surface algorithms I.4.8 [Image Processing]: Scene Analysis\u2014color, photometry, shading"
            },
            "slug": "Recovering-photometric-properties-of-architectural-Yu-Malik",
            "title": {
                "fragments": [],
                "text": "Recovering photometric properties of architectural scenes from photographs"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "The goal of generating photorealistic renderings of real architectural scenes under novel lighting conditions has been achieved and the basic approach to solving a series of optimization problems to find the parameters of appropriate lighting and reflectance models that best explain the measured values in the various photographs of the scene."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115899190"
                        ],
                        "name": "C. Lee",
                        "slug": "C.-Lee",
                        "structuredName": {
                            "firstName": "Choong",
                            "lastName": "Lee",
                            "middleNames": [
                                "Hwan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109319119"
                        ],
                        "name": "Jun Sung Kim",
                        "slug": "Jun-Sung-Kim",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Kim",
                            "middleNames": [
                                "Sung"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jun Sung Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1400218066"
                        ],
                        "name": "Kyu Ho Park",
                        "slug": "Kyu-Ho-Park",
                        "structuredName": {
                            "firstName": "Kyu Ho",
                            "lastName": "Park",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kyu Ho Park"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 188
                            }
                        ],
                        "text": "A conservative threshold is then chosen to determine shadows, making it almost certain that no invalid data is included in the estimation process, at the small expense of throwing away a few valid measurements."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 205015249,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2350cb194cd3f29ff319613859159c54dfb18577",
            "isKey": false,
            "numCitedBy": 144,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Automatic-human-face-location-in-a-complex-using-Lee-Kim",
            "title": {
                "fragments": [],
                "text": "Automatic human face location in a complex background using motion and color information"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144097660"
                        ],
                        "name": "M. Turk",
                        "slug": "M.-Turk",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Turk",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Turk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "niques such as SLAM [47] and Eigenfaces [ 66 ] have demonstrated the power of appearance-based"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "See for example [36,  66 , 23, 51, 55, 47, 45, 25]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 26127529,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6f1dfcc44277d4cfd8507284d994c9283dc3a2f",
            "isKey": false,
            "numCitedBy": 14955,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We have developed a near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals. The computational approach taken in this system is motivated by both physiology and information theory, as well as by the practical requirements of near-real-time performance and accuracy. Our approach treats the face recognition problem as an intrinsically two-dimensional (2-D) recognition problem rather than requiring recovery of three-dimensional geometry, taking advantage of the fact that faces are normally upright and thus may be described by a small set of 2-D characteristic views. The system functions by projecting face images onto a feature space that spans the significant variations among known face images. The significant features are known as \"eigenfaces,\" because they are the eigenvectors (principal components) of the set of faces; they do not necessarily correspond to features such as eyes, ears, and noses. The projection operation characterizes an individual face by a weighted sum of the eigenface features, and so to recognize a particular face it is necessary only to compare these weights to those of known individuals. Some particular advantages of our approach are that it provides for the ability to learn and later recognize new faces in an unsupervised manner, and that it is easy to implement using a neural network architecture."
            },
            "slug": "Eigenfaces-for-Recognition-Turk-Pentland",
            "title": {
                "fragments": [],
                "text": "Eigenfaces for Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals, and that is easy to implement using a neural network architecture."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Cognitive Neuroscience"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "122439944"
                        ],
                        "name": "Qian Chen",
                        "slug": "Qian-Chen",
                        "structuredName": {
                            "firstName": "Qian",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qian Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794240"
                        ],
                        "name": "Haiyuan Wu",
                        "slug": "Haiyuan-Wu",
                        "structuredName": {
                            "firstName": "Haiyuan",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Haiyuan Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1735941"
                        ],
                        "name": "M. Yachida",
                        "slug": "M.-Yachida",
                        "structuredName": {
                            "firstName": "Masahiko",
                            "lastName": "Yachida",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Yachida"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 171
                            }
                        ],
                        "text": "A conservative threshold is then chosen to determine shadows, making it almost certain that no invalid data is included in the estimation process, at the small expense of throwing away a few valid measurements."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 31690449,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "857b32ba2a3b10855db4051adc379af7c74cb795",
            "isKey": false,
            "numCitedBy": 151,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper describes an approach to detect faces whose size and position are unknown in an image with a complex background. The candidates of faces are detected by finding out \"face like\" regions in the input image using the fuzzy pattern matching method. The perceptually uniform color space is used in our research in order to obtain reliable results. The skin color that is used to detect face like regions, is represented by a model developed by us called skin color distribution function. The skin color regions are then extracted by estimating a measure that describes how well the color of a pixel looks like the skin color for each pixel in the input image. The faces which appear in images are modeled as several 2 dimensional patterns. The face like regions are extracted by a fuzzy pattern matching approach using these face models. The face candidates are then verified by estimating how well the extracted facial features fit a face model which describes the geometrical relations among facial features.<<ETX>>"
            },
            "slug": "Face-detection-by-fuzzy-pattern-matching-Chen-Wu",
            "title": {
                "fragments": [],
                "text": "Face detection by fuzzy pattern matching"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "The paper describes an approach to detect faces whose size and position are unknown in an image with a complex background by finding out \"face like\" regions in the input image using the fuzzy pattern matching method."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34854785"
                        ],
                        "name": "Russell A. Epstein",
                        "slug": "Russell-A.-Epstein",
                        "structuredName": {
                            "firstName": "Russell",
                            "lastName": "Epstein",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Russell A. Epstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36427051"
                        ],
                        "name": "Peter W. Hallinan",
                        "slug": "Peter-W.-Hallinan",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hallinan",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter W. Hallinan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081362"
                        ],
                        "name": "A. Yuille",
                        "slug": "A.-Yuille",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Yuille",
                            "middleNames": [
                                "Loddon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yuille"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "subspace), and this was confirmed for faces in [ 15 , 1, 19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60509763,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "f3b2f204a5c38df91930390eff2e65441409029e",
            "isKey": false,
            "numCitedBy": 178,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, P.W. Hallinan (1994) proposed a low dimensional lighting\nmodel for describing the variations in face images due to altering the\nlighting conditions. It was found that five eigenimages were sufficient\nto model these variations. This report shows that this model can be\nextended to other objects, in particular to those with diffuse\nspecularities and shadows. We find that sharp specularities and shadows\ncannot be well represented by a low dimensional model. However, both\neffects can be adequately described as residuals to such a model. We can\ndeal with occluders in a similar way. We conclude that low dimensional\nmodels, using 5\u00b12 eigenimages, can be usefully extended to\nrepresent arbitrary lighting for many different objects. We discuss\napplications of these results to object recognition"
            },
            "slug": "5/spl-plusmn/2-eigenimages-suffice:-an-empirical-of-Epstein-Hallinan",
            "title": {
                "fragments": [],
                "text": "5/spl plusmn/2 eigenimages suffice: an empirical investigation of low-dimensional lighting models"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is found that sharp specularities and shadows cannot be well represented by a low dimensional model, but both effects can be adequately described as residuals to such a model."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Workshop on Physics-Based Modeling in Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38817267"
                        ],
                        "name": "K. Sung",
                        "slug": "K.-Sung",
                        "structuredName": {
                            "firstName": "Kah",
                            "lastName": "Sung",
                            "middleNames": [
                                "Kay"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Sung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms: Face Recognition, Image-Based Rendering, Appearance-Based Vision, Face Modeling, Illumination and Pose Modeling, Lighting, Illumination Cones, Generative Models."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 153
                            }
                        ],
                        "text": "A conservative threshold is then chosen to determine shadows, making it almost certain that no invalid data is included in the estimation process, at the small expense of throwing away a few valid measurements."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7164794,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "088eb2d102c6bb486f5270d0b2adff76961994cf",
            "isKey": false,
            "numCitedBy": 2061,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an example-based learning approach for locating vertical frontal views of human faces in complex scenes. The technique models the distribution of human face patterns by means of a few view-based \"face\" and \"nonface\" model clusters. At each image location, a difference feature vector is computed between the local image pattern and the distribution-based model. A trained classifier determines, based on the difference feature vector measurements, whether or not a human face exists at the current image location. We show empirically that the distance metric we adopt for computing difference feature vectors, and the \"nonface\" clusters we include in our distribution-based model, are both critical for the success of our system."
            },
            "slug": "Example-Based-Learning-for-View-Based-Human-Face-Sung-Poggio",
            "title": {
                "fragments": [],
                "text": "Example-Based Learning for View-Based Human Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "An example-based learning approach for locating vertical frontal views of human faces in complex scenes and shows empirically that the distance metric adopted for computing difference feature vectors, and the \"nonface\" clusters included in the distribution-based model, are both critical for the success of the system."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50024179"
                        ],
                        "name": "Yongmin Li",
                        "slug": "Yongmin-Li",
                        "structuredName": {
                            "firstName": "Yongmin",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yongmin Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144784813"
                        ],
                        "name": "S. Gong",
                        "slug": "S.-Gong",
                        "structuredName": {
                            "firstName": "Shaogang",
                            "lastName": "Gong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2934996"
                        ],
                        "name": "H. Liddell",
                        "slug": "H.-Liddell",
                        "structuredName": {
                            "firstName": "Heather",
                            "lastName": "Liddell",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Liddell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 208
                            }
                        ],
                        "text": "\u2026stated in Equation 6 can then be reformulated into:\nmin b j ;si X ij wijjxij < b j ; si > j 2 (7)\nwhere xij is the j-th pixel of the i-th image, b j is the j-th row of matrix B 2 IRn 3, si is the light source direction and strength in the i-th image, and\nwij =\n1 xij valid measurement, 0 otherwise."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1889567,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cf0a5ddc4e80359418e8a66f6f6c068efd12c1d3",
            "isKey": false,
            "numCitedBy": 276,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "A support vector machine-based multi-view face detection and recognition framework is described. Face detection is carried out by constructing several detectors, each of them in charge of one specific view. The symmetrical property of face images is employed to simplify the complexity of the modelling. The estimation of head pose, which is achieved by using the support vector regression technique, provides crucial information for choosing the appropriate face detector. This helps to improve the accuracy and reduce the computation in multi-view face detection compared to other methods. For video sequences, further computational reduction can be achieved by using a pose change smoothing strategy. When face detectors find a face in frontal view, a support vector machine-based multi-class classifier is activated for face recognition. All the above issues are integrated under a support vector machine framework. Test results on four video sequences are presented, among them the detection rate is above 95%, recognition accuracy is above 90%, average pose estimation error is around 10/spl deg/, and the full detection and recognition speed is up to 4 frames/second on a Pentium II 300 PC."
            },
            "slug": "Support-vector-regression-and-classification-based-Li-Gong",
            "title": {
                "fragments": [],
                "text": "Support vector regression and classification based multi-view face detection and recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The estimation of head pose, which is achieved by using the support vector regression technique, provides crucial information for choosing the appropriate face detector, which helps to improve the accuracy and reduce the computation in multi-view face detection compared to other methods."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266088"
                        ],
                        "name": "T. Leung",
                        "slug": "T.-Leung",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Leung",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Leung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2511655"
                        ],
                        "name": "M. Burl",
                        "slug": "M.-Burl",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Burl",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Burl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2904067,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0d50d0e2af0b45cc7ed25fe4aa97af900c9bd32a",
            "isKey": false,
            "numCitedBy": 389,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm for locating quasi-frontal views of human faces in cluttered scenes is presented. The algorithm works by coupling a set of local feature detectors with a statistical model of the mutual distances between facial features it is invariant with respect to translation, rotation (in the plane), and scale and can handle partial occlusions of the face. On a challenging database with complicated and varied backgrounds, the algorithm achieved a correct localization rate of 95% in images where the face appeared quasi-frontally.<<ETX>>"
            },
            "slug": "Finding-faces-in-cluttered-scenes-using-random-Leung-Burl",
            "title": {
                "fragments": [],
                "text": "Finding faces in cluttered scenes using random labeled graph matching"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "An algorithm for locating quasi-frontal views of human faces in cluttered scenes is presented and it is found that it is invariant with respect to translation, rotation, and scale and can handle partial occlusions of the face."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34734622"
                        ],
                        "name": "D. Jacobs",
                        "slug": "D.-Jacobs",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Jacobs",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Jacobs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 44
                            }
                        ],
                        "text": "To capture the images in this database, we have constructed the geodesic lighting rig shown in Figure 10 with 64 computer controlled xenon strobes whose positions in spherical coordinates are shown in Figure 11."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 27932915,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c1a51dfb9ea4f01b2d87e65f20e3602227cc4e20",
            "isKey": false,
            "numCitedBy": 153,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Several vision problems can be reduced to the problem of fitting a linear surface of low dimension to data, including the problems of structure-from-affine-motion, and of characterizing the intensity images of a Lambertian scene by constructing the intensity manifold. For these problems, one must deal with a data matrix with some missing elements. In structure-from-motion, missing elements will occur if some point features are not visible in some frames. To construct the intensity manifold missing matrix elements will arise when the surface normals of some scene points do not face the light source in some images. We propose a novel method for fitting a low rank matrix to a matrix with missing elements. We show experimentally that our method produces good results in the presence of noise. These results can be either used directly, or can serve as an excellent starting point for an iterative method."
            },
            "slug": "Linear-fitting-with-missing-data:-applications-to-Jacobs",
            "title": {
                "fragments": [],
                "text": "Linear fitting with missing data: applications to structure-from-motion and to characterizing intensity images"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work proposes a novel method for fitting a low rank matrix to a matrix with missing elements, and shows experimentally that this method produces good results in the presence of noise."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47694291"
                        ],
                        "name": "Hideki Hayakawa",
                        "slug": "Hideki-Hayakawa",
                        "structuredName": {
                            "firstName": "Hideki",
                            "lastName": "Hayakawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hideki Hayakawa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In Section 4.2, we present the first set of experiments under variable illumination but fixed pose, while in Section 4.3, we describe the second set under variable illumination and pose."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 123
                            }
                        ],
                        "text": "In the first set, tests were performed under variable illumination but fixed pose, and the goal was, first, to compare the illumination cones representation with three other popular methods, and second, to test the accuracy of the subspace approximation of illumination cones."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18203298,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "72397ddcde088745e0e4ee52212db9e54535ba18",
            "isKey": true,
            "numCitedBy": 261,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "A new photometric-stereo method for estimating the surface normal and the surface reflectance of objects without a priori knowledge of the light-source direction or the light-source intensity is proposed. First, I construct a p \u00d7 f image data matrix I from p pixel image intensity data through f frames by moving a light source arbitrarily. Under the Lambertian assumption the image data matrix I can be written as the product of two matrices S and L, with S representing the surface normal and the surface reflectance and L representing the light-source direction and the light-source intensity. Using this formulation, I show that the image data matrix I is of rank 3. On the basis of this observation, I use a singular-value decomposition technique and useful constraints to factorize the image data matrix. This method can also be used to treat cast shadows and self-shadows without assumptions. The effectiveness of this method is demonstrated through performance analysis, laboratory experiment, and out-of-laboratory experiment."
            },
            "slug": "Photometric-stereo-under-a-light-source-with-motion-Hayakawa",
            "title": {
                "fragments": [],
                "text": "Photometric stereo under a light source with arbitrary motion"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9215658"
                        ],
                        "name": "R. Chellappa",
                        "slug": "R.-Chellappa",
                        "structuredName": {
                            "firstName": "Rama",
                            "lastName": "Chellappa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chellappa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144286385"
                        ],
                        "name": "Charles L. Wilson",
                        "slug": "Charles-L.-Wilson",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Wilson",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charles L. Wilson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2503366"
                        ],
                        "name": "S. Sirohey",
                        "slug": "S.-Sirohey",
                        "structuredName": {
                            "firstName": "Saad",
                            "lastName": "Sirohey",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sirohey"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms: Face Recognition, Image-Based Rendering, Appearance-Based Vision, Face Modeling, Illumination and Pose Modeling, Lighting, Illumination Cones, Generative Models."
                    },
                    "intents": []
                }
            ],
            "corpusId": 62185766,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aa1755e87301af36485ca01e3454bf8888dde8d1",
            "isKey": false,
            "numCitedBy": 3007,
            "numCiting": 177,
            "paperAbstract": {
                "fragments": [],
                "text": "The goal of this paper is to present a critical survey of existing literature on human and machine recognition of faces. Machine recognition of faces has several applications, ranging from static matching of controlled photographs as in mug shots matching and credit card verification to surveillance video images. Such applications have different constraints in terms of complexity of processing requirements and thus present a wide range of different technical challenges. Over the last 20 years researchers in psychophysics, neural sciences and engineering, image processing analysis and computer vision have investigated a number of issues related to face recognition by humans and machines. Ongoing research activities have been given a renewed emphasis over the last five years. Existing techniques and systems have been tested on different sets of images of varying complexities. But very little synergism exists between studies in psychophysics and the engineering literature. Most importantly, there exists no evaluation or benchmarking studies using large databases with the image quality that arises in commercial and law enforcement applications In this paper, we first present different applications of face recognition in commercial and law enforcement sectors. This is followed by a brief overview of the literature on face recognition in the psychophysics community. We then present a detailed overview of move than 20 years of research done in the engineering community. Techniques for segmentation/location of the face, feature extraction and recognition are reviewed. Global transform and feature based methods using statistical, structural and neural classifiers are summarized. >"
            },
            "slug": "Human-and-machine-recognition-of-faces:-a-survey-Chellappa-Wilson",
            "title": {
                "fragments": [],
                "text": "Human and machine recognition of faces: a survey"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "A critical survey of existing literature on human and machine recognition of faces is presented, followed by a brief overview of the literature on face recognition in the psychophysics community and a detailed overview of move than 20 years of research done in the engineering community."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144517651"
                        ],
                        "name": "T. Vetter",
                        "slug": "T.-Vetter",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Vetter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Vetter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 149
                            }
                        ],
                        "text": "\u2026of this expansion,\ngiving\nzx(x; y; c(w)) = X c(w) x(x; y;w) (9)\nand\nzy(x; y; c(w)) = X c(w) y(x; y;w): (10)\nSince the partial derivatives of the basis functions, x(x; y;w) and y(x; y;w), are integrable and the expansions of zx(x; y) and zy(x; y) share the same coefficients c(w), it is easy to see\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10047234,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "617b34332fcd1cb196f93656ee1d49561b81ebf8",
            "isKey": false,
            "numCitedBy": 471,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "The need to generate new views of a 3D object from a single real image arises in several fields, including graphics and object recognition. While the traditional approach relies on the use of 3D models, simpler techniques are applicable under restricted conditions. The approach exploits image transformations that are specific to the relevant object class, and learnable from example views of other \"prototypical\" objects of the same class. In this paper, we introduce such a technique by extending the notion of linear class proposed by the authors (1992). For linear object classes, it is shown that linear transformations can be learned exactly from a basis set of 2D prototypical views. We demonstrate the approach on artificial objects and then show preliminary evidence that the technique can effectively \"rotate\" high-resolution face images from a single 2D view."
            },
            "slug": "Linear-Object-Classes-and-Image-Synthesis-From-a-Vetter-Poggio",
            "title": {
                "fragments": [],
                "text": "Linear Object Classes and Image Synthesis From a Single Example Image"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "For linear object classes, it is shown that linear transformations can be learned exactly from a basis set of 2D prototypical views and preliminary evidence that the technique can effectively \"rotate\" high-resolution face images from a single 2D view is shown."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13919023"
                        ],
                        "name": "F. Huang",
                        "slug": "F.-Huang",
                        "structuredName": {
                            "firstName": "Fu",
                            "lastName": "Huang",
                            "middleNames": [
                                "Jie"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40894914"
                        ],
                        "name": "Tsuhan Chen",
                        "slug": "Tsuhan-Chen",
                        "structuredName": {
                            "firstName": "Tsuhan",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tsuhan Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145624000"
                        ],
                        "name": "Zhi-Hua Zhou",
                        "slug": "Zhi-Hua-Zhou",
                        "structuredName": {
                            "firstName": "Zhi-Hua",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhi-Hua Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108698841"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This method for handling pose variability differs from [4, 38,  30 , 43] in that we warp synthetic"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8877735,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0d86e76f986ea062af483e8f6ae20ec50725687a",
            "isKey": false,
            "numCitedBy": 149,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a novel neural network architecture, which can recognize human faces with any view in a certain viewing angle range (from left 30 degrees to right 30 degrees out of plane rotation). View-specific eigenface analysis is used as the front-end of the system to extract features, and the neural network ensemble is used for recognition. Experimental results show that the recognition accuracy of our network ensemble is higher than conventional methods such as using a single neural network to recognize faces of a specific view."
            },
            "slug": "Pose-invariant-face-recognition-Huang-Chen",
            "title": {
                "fragments": [],
                "text": "Pose invariant face recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A novel neural network architecture is described, which can recognize human faces with any view in a certain viewing angle range (from left 30 degrees to right 30 degrees out of plane rotation)."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738894"
                        ],
                        "name": "T. Starner",
                        "slug": "T.-Starner",
                        "structuredName": {
                            "firstName": "Thad",
                            "lastName": "Starner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Starner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms: Face Recognition, Image-Based Rendering, Appearance-Based Vision, Face Modeling, Illumination and Pose Modeling, Lighting, Illumination Cones, Generative Models."
                    },
                    "intents": []
                }
            ],
            "corpusId": 136280,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b0bf5d558220d39698ce96d59ee5772e8e1a0663",
            "isKey": false,
            "numCitedBy": 2234,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe experiments with eigenfaces for recognition and interactive search in a large-scale face database. Accurate visual recognition is demonstrated using a database of O(10/sup 3/) faces. The problem of recognition under general viewing orientation is also examined. A view-based multiple-observer eigenspace technique is proposed for use in face recognition under variable pose. In addition, a modular eigenspace description technique is used which incorporates salient features such as the eyes, nose and mouth, in an eigenfeature layer. This modular representation yields higher recognition rates as well as a more robust framework for face recognition. An automatic feature extraction technique using feature eigentemplates is also demonstrated.<<ETX>>"
            },
            "slug": "View-based-and-modular-eigenspaces-for-face-Pentland-Moghaddam",
            "title": {
                "fragments": [],
                "text": "View-based and modular eigenspaces for face recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A modular eigenspace description technique is used which incorporates salient features such as the eyes, nose and mouth, in an eigenfeature layer, which yields higher recognition rates as well as a more robust framework for face recognition."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144013393"
                        ],
                        "name": "A. Samal",
                        "slug": "A.-Samal",
                        "structuredName": {
                            "firstName": "Ashok",
                            "lastName": "Samal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Samal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32130323"
                        ],
                        "name": "Prasana A. Iyengar",
                        "slug": "Prasana-A.-Iyengar",
                        "structuredName": {
                            "firstName": "Prasana",
                            "lastName": "Iyengar",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Prasana A. Iyengar"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 159
                            }
                        ],
                        "text": "A conservative threshold is then chosen to determine shadows, making it almost certain that no invalid data is included in the estimation process, at the small expense of throwing away a few valid measurements."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 26186431,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3c3592f4cb1c182ef0536f87a6695ed9aa960e2e",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Face detection is integral to any automatic face recognition system. The goal of this research is to develop a system that performs the task of human face detection automatically in a scene. A system to correctly locate and identify human faces will find several applications, some examples are criminal identification and authentication in secure systems. This work presents a new approach based on principal component analysis. Face silhouettes instead of intensity images are used for this research. It results in reduction in both space and processing time. A set of basis face silhouettes are obtained using principal component analysis. These are then used with a Hough-like technique to detect faces. The results show that the approach is robust, accurate and reasonably fast."
            },
            "slug": "Human-Face-Detection-Using-Silhouettes-Samal-Iyengar",
            "title": {
                "fragments": [],
                "text": "Human Face Detection Using Silhouettes"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Face silhouettes instead of intensity images are used for this research, which results in reduction in both space and processing time and shows that the approach is robust, accurate and reasonably fast."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Pattern Recognit. Artif. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50564384"
                        ],
                        "name": "G. Edwards",
                        "slug": "G.-Edwards",
                        "structuredName": {
                            "firstName": "Gareth",
                            "lastName": "Edwards",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Edwards"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "parameters are used as a feature vector for classification [10, 39,  14 , 11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18147808,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ec5ad4297e20b1f25b98eb8a45757d0c33eabde7",
            "isKey": false,
            "numCitedBy": 104,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents advances in the construction and use of Active Appearance Models (AAMs) for image interpretation. AAMs are photo-realistic generative models of object appearance that can be used to rapidly locate deformable objects in images. We extend the AAM method to include coloured texture and present an enhanced search algorithm with the ability to locate partially occluded objects. Previously, AAMs have been limited by the need for good manual initialisation. In this paper, we describe a hierarchical search algorithm that overcomes this drawback. The extended AAM method provides a complete, unified scheme for model based image interpretation. We demonstrate the application of the scheme to the task of locating faces in images."
            },
            "slug": "Advances-in-active-appearance-models-Edwards-Cootes",
            "title": {
                "fragments": [],
                "text": "Advances in active appearance models"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "The extended AAM method provides a complete, unified scheme for model based image interpretation and is extended to include coloured texture and present an enhanced search algorithm with the ability to locate partially occluded objects."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144013393"
                        ],
                        "name": "A. Samal",
                        "slug": "A.-Samal",
                        "structuredName": {
                            "firstName": "Ashok",
                            "lastName": "Samal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Samal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32130323"
                        ],
                        "name": "Prasana A. Iyengar",
                        "slug": "Prasana-A.-Iyengar",
                        "structuredName": {
                            "firstName": "Prasana",
                            "lastName": "Iyengar",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Prasana A. Iyengar"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms: Face Recognition, Image-Based Rendering, Appearance-Based Vision, Face Modeling, Illumination and Pose Modeling, Lighting, Illumination Cones, Generative Models."
                    },
                    "intents": []
                }
            ],
            "corpusId": 205013679,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0be360a2964c4bb91aaad0cc6d1baa6639746028",
            "isKey": false,
            "numCitedBy": 1067,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Automatic-recognition-and-analysis-of-human-faces-a-Samal-Iyengar",
            "title": {
                "fragments": [],
                "text": "Automatic recognition and analysis of human faces and facial expressions: a survey"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70044319"
                        ],
                        "name": "G. V. Wheeler",
                        "slug": "G.-V.-Wheeler",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Wheeler",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. V. Wheeler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29063598"
                        ],
                        "name": "K. N. Walker",
                        "slug": "K.-N.-Walker",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Walker",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. N. Walker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 219
                            }
                        ],
                        "text": "These partial derivatives can also be expressed as a series, giving\nz x (x; y; c 1 (w)) =\nX c\n1 (w) x(x; y;w) (11)\nand\nz y (x; y; c 2 (w)) =\nX c\n2 (w) y(x; y;w): (12)\nNote that in general c 1 (w) 6= c 2 (w), which implies that z xy (x; y) 6= z yx (x; y)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 121708892,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ee22010e4e8139df9c2e62944759837b48f58cae",
            "isKey": false,
            "numCitedBy": 348,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We demonstrate that a small number of 2D statistical models are sufficient to capture the shape and appearance of a face from any viewpoint (full profile to front-to-parallel). Each model is linear and can be matched rapidly to new images using the active appearance model algorithm. We show how such a set of models can be used to estimate head pose, to track faces through large angles of head rotation and to synthesize faces from unseen viewpoints."
            },
            "slug": "View-based-active-appearance-models-Cootes-Wheeler",
            "title": {
                "fragments": [],
                "text": "View-based active appearance models"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A small number of 2D statistical models are demonstrated to capture the shape and appearance of a face from any viewpoint (full profile to front-to-parallel) and to estimate head pose and to synthesize faces from unseen viewpoints."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143862946"
                        ],
                        "name": "A. Goldstein",
                        "slug": "A.-Goldstein",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Goldstein",
                            "middleNames": [
                                "Jay"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Goldstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7351757"
                        ],
                        "name": "L. D. Harmon",
                        "slug": "L.-D.-Harmon",
                        "structuredName": {
                            "firstName": "Leon",
                            "lastName": "Harmon",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. D. Harmon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48586543"
                        ],
                        "name": "A. Lesk",
                        "slug": "A.-Lesk",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Lesk",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lesk"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms: Face Recognition, Image-Based Rendering, Appearance-Based Vision, Face Modeling, Illumination and Pose Modeling, Lighting, Illumination Cones, Generative Models."
                    },
                    "intents": []
                }
            ],
            "corpusId": 57690561,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "50a541a6b7736dee7b96438f2b049a4f6c1bf555",
            "isKey": false,
            "numCitedBy": 334,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "How well can human faces be identified by humans and by computers, using subjectively judged \"feature\" descriptions like long ears, wide-set eyes, etc.? Three classes of experiments are reported: 1) Gathering, analysis, and assessment of face-feature data for 255 faces. 2) Computer identification-studies. 3) Human identification-studies. A set of 22 features was evolved from an initially larger set to provide relevant, distinctive, relatively independent measures which can be judged reliably. Computer studies and a mathematical model established limits of performance of a person attempting to isolate a face from a population using feature descriptions. The model predicts that under certain conditions approximately 6 of an individual's features are required to isolate him from a population of 255. Human experiments under similar conditions showed unique identification occurred with an average of about 7 features. The model predicts that for a population of 4\u00d7106, only 14 feature-descriptions are required. These studies form a foundation for continuing research on real-time man-machine interaction for computer classification and identification of multidimensional vectors specified by noisy components."
            },
            "slug": "Identification-of-human-faces-Goldstein-Harmon",
            "title": {
                "fragments": [],
                "text": "Identification of human faces"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "These studies form a foundation for continuing research on real-time man-machine interaction for computer classification and identification of multidimensional vectors specified by noisy components."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34679741"
                        ],
                        "name": "S. Li",
                        "slug": "S.-Li",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "150152476"
                        ],
                        "name": "Juwei Lu",
                        "slug": "Juwei-Lu",
                        "structuredName": {
                            "firstName": "Juwei",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Juwei Lu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5959423,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f570e77bc9a6e9362b7eec366e98448d96e4c5a4",
            "isKey": false,
            "numCitedBy": 582,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a novel classification method, called the nearest feature line (NFL), for face recognition. Any two feature points of the same class (person) are generalized by the feature line (FL) passing through the two points. The derived FL can capture more variations of face images than the original points and thus expands the capacity of the available database. The classification is based on the nearest distance from the query feature point to each FL. With a combined face database, the NFL error rate is about 43.7-65.4% of that of the standard eigenface method. Moreover, the NFL achieves the lowest error rate reported to date for the ORL face database."
            },
            "slug": "Face-recognition-using-the-nearest-feature-line-Li-Lu",
            "title": {
                "fragments": [],
                "text": "Face recognition using the nearest feature line method"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A novel classification method, called the nearest feature line (NFL), for face recognition, based on the nearest distance from the query feature point to each FL, which achieves the lowest error rate reported for the ORL face database."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40582834"
                        ],
                        "name": "Gerald J. Kaufman",
                        "slug": "Gerald-J.-Kaufman",
                        "structuredName": {
                            "firstName": "Gerald",
                            "lastName": "Kaufman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gerald J. Kaufman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3067787"
                        ],
                        "name": "K. J. Breeding",
                        "slug": "K.-J.-Breeding",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Breeding",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. J. Breeding"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms: Face Recognition, Image-Based Rendering, Appearance-Based Vision, Face Modeling, Illumination and Pose Modeling, Lighting, Illumination Cones, Generative Models."
                    },
                    "intents": []
                }
            ],
            "corpusId": 22606575,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7406107d59e35bddb16fb2d5e825fa319afbd77e",
            "isKey": false,
            "numCitedBy": 92,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "A pattern recognition system is described which is capable of identifying human faces from their full profile silhouettes. Each silhouette is preprocessed to remove noise, smooth edges, and extract the front edge. The processed silhouettes are then represented by a 12-dimensional feature vector, the components of which are obtained by a circular autocorrelation function. Using a weighted k-nearest neighbor decision rule it is shown that a recognition accuracy of 90 percent is attainable in a ten-class problem. An adaptive training procedure is also described which is used for setting up the authority files. This training procedure appears to identify those feature vectors representing a class which are either most important, from an information content point of view, or are observed most often. Finally, a comparison is made between the recognition accuracy obtained using circular autocorrelation features and moment invariant features. It is shown that the former outperforms, in this problem, the latter. The system is also compared to human observers with the result that the system performs no worse than the human observers."
            },
            "slug": "The-Automatic-Recognition-of-Human-Faces-from-Kaufman-Breeding",
            "title": {
                "fragments": [],
                "text": "The Automatic Recognition of Human Faces from Profile Silhouettes"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A pattern recognition system is described which is capable of identifying human faces from their full profile silhouettes and is compared to human observers with the result that the system performs no worse than the human observers."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Systems, Man, and Cybernetics"
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1852820"
                        ],
                        "name": "T. Fromherz",
                        "slug": "T.-Fromherz",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Fromherz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Fromherz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms: Face Recognition, Image-Based Rendering, Appearance-Based Vision, Face Modeling, Illumination and Pose Modeling, Lighting, Illumination Cones, Generative Models."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15013836,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a7a118d73101ec5f26dd24fe39922f3e3432ffad",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "The development of face recognition over the past years allows an organization into three types of r ecognition algorithms, namely frontal, profile, and v iew-tolerant recognition, depending on the kind o f imagery and the according recognition algorithms. While frontal recognition certainly is the c lassical approach, view-tolerant algorithms usually p erform recognition in a more sophisticated fashion by taking into consideration some of the underlying phy sics, geometry, and statistics. Profile schemes as s tand-alone systems have a rather marginal significance for identification. However, they are very p ractical either f or f ast coarse pre-searches of large face databases to reduce the c omputational l oad for a subsequent sophisticated algorithm, or as part of a hybrid recognition scheme. Such hyb rid approaches have a special status among face recognition systems as they combine different recognition approaches in an either serial or parallel order to ov ercome the shortcomings of the individual components."
            },
            "slug": "Face-Recognition:-a-Summary-of-1995-1997-Fromherz",
            "title": {
                "fragments": [],
                "text": "Face Recognition: a Summary of 1995 - 1997"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The development of face recognition over the past years allows an organization into three types of recognition algorithms, namely frontal, profile, and v iew-tolerant recognition, depending on the kind of imagery and the according recognition algorithms."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736245"
                        ],
                        "name": "Laurenz Wiskott",
                        "slug": "Laurenz-Wiskott",
                        "structuredName": {
                            "firstName": "Laurenz",
                            "lastName": "Wiskott",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laurenz Wiskott"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145893752"
                        ],
                        "name": "J. Fellous",
                        "slug": "J.-Fellous",
                        "structuredName": {
                            "firstName": "Jean-Marc",
                            "lastName": "Fellous",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Fellous"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721722"
                        ],
                        "name": "N. Kr\u00fcger",
                        "slug": "N.-Kr\u00fcger",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Kr\u00fcger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Kr\u00fcger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms: Face Recognition, Image-Based Rendering, Appearance-Based Vision, Face Modeling, Illumination and Pose Modeling, Lighting, Illumination Cones, Generative Models."
                    },
                    "intents": []
                }
            ],
            "corpusId": 10223132,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5c27487c3e0894b65e976a287e6f8c9aa40f089c",
            "isKey": false,
            "numCitedBy": 2136,
            "numCiting": 89,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a system for recognizing human faces from single images out of a large database containing one image per person. Faces are represented by labeled graphs, based on a Gabor wavelet transform. Image graphs of new faces are extracted by an elastic graph matching process and can be compared by a simple similarity function. The system differs from Lades et al. (1993) in three respects. Phase information is used for accurate node positioning. Object-adapted graphs are used to handle large rotations in depth. Image graph extraction is based on a novel data structure, the bunch graph, which is constructed from a small set of sample image graphs."
            },
            "slug": "Face-recognition-by-elastic-bunch-graph-matching-Wiskott-Fellous",
            "title": {
                "fragments": [],
                "text": "Face recognition by elastic bunch graph matching"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A system for recognizing human faces from single images out of a large database containing one image per person, based on a Gabor wavelet transform, which differs from Lades et al. (1993) in three respects."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of International Conference on Image Processing"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39682833"
                        ],
                        "name": "H. Rowley",
                        "slug": "H.-Rowley",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Rowley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Rowley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767244"
                        ],
                        "name": "S. Baluja",
                        "slug": "S.-Baluja",
                        "structuredName": {
                            "firstName": "Shumeet",
                            "lastName": "Baluja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baluja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 7
                            }
                        ],
                        "text": "Any invalid data (both shadows and saturations) are treated as missing measurements by the following estimation method:\n1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1619589,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2fd1c99edbb3d22cec4adc9ba9319cfc2360e903",
            "isKey": false,
            "numCitedBy": 348,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a neural network-based face detection system. Unlike similar systems which are limited to detecting upright, frontal faces, this system detects faces at any degree of rotation in the image plane. The system employs multiple networks; a \"router\" network first processes each input window to determine its orientation and then uses this information to prepare the window for one or more \"detector\" networks. We present the training methods for both types of networks. We also perform sensitivity analysis on the networks, and present empirical results on a large test set. Finally, we present preliminary results for detecting faces rotated out of the image plane, such as profiles and semi-profiles."
            },
            "slug": "Rotation-invariant-neural-network-based-face-Rowley-Baluja",
            "title": {
                "fragments": [],
                "text": "Rotation invariant neural network-based face detection"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This paper presents a neural network-based face detection system, which is limited to detecting upright, frontal faces, and presents preliminary results for detecting faces rotated out of the image plane, such as profiles and semi-profiles."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144154486"
                        ],
                        "name": "H. Shum",
                        "slug": "H.-Shum",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Shum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Shum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739452"
                        ],
                        "name": "K. Ikeuchi",
                        "slug": "K.-Ikeuchi",
                        "structuredName": {
                            "firstName": "Katsushi",
                            "lastName": "Ikeuchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Ikeuchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145502114"
                        ],
                        "name": "R. Reddy",
                        "slug": "R.-Reddy",
                        "structuredName": {
                            "firstName": "Raj",
                            "lastName": "Reddy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Reddy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 27
                            }
                        ],
                        "text": "To capture the images in this database, we have constructed the geodesic lighting rig shown in Figure 10 with 64 computer controlled xenon strobes whose positions in spherical coordinates are shown in Figure 11."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10468852,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c7191b7ca5c4e7504bf3fc8666d732ea7d380d92",
            "isKey": false,
            "numCitedBy": 227,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Observation-based object modeling often requires integration of shape descriptions from different views. To overcome the problems of errors and their accumulation, we have developed a weighted least-squares (WLS) approach which simultaneously recovers object shape and transformation among different views without recovering interframe motion. We show that object modeling from a range image sequence is a problem of principal component analysis with missing data (PCAMD), which can be generalized as a WLS minimization problem. An efficient algorithm is devised. After we have segmented planar surface regions in each view and tracked them over the image sequence, we construct a normal measurement matrix of surface normals, and a distance measurement matrix of normal distances to the origin for all visible regions over the whole sequence of views, respectively. These two matrices, which have many missing elements due to noise, occlusion, and mismatching, enable us to formulate multiple view merging as a combination of two WLS problems. A two-step algorithm is presented. After surface equations are extracted, spatial connectivity among the surfaces is established to enable the polyhedral object model to be constructed. Experiments using synthetic data and real range images show that our approach is robust against noise and mismatching and generates accurate polyhedral object models. >"
            },
            "slug": "Principal-Component-Analysis-with-Missing-Data-and-Shum-Ikeuchi",
            "title": {
                "fragments": [],
                "text": "Principal Component Analysis with Missing Data and Its Application to Polyhedral Object Modeling"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A weighted least-squares (WLS) approach which simultaneously recovers object shape and transformation among different views without recovering interframe motion is developed and is robust against noise and mismatching and generates accurate polyhedral object models."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688682"
                        ],
                        "name": "R. Woodham",
                        "slug": "R.-Woodham",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Woodham",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Woodham"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "images with novel lighting and viewpoints is a variant of photometric stereo [64,  70 , 29, 28, 73]"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 39727983,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b9b1e1fe8fde669285a21ace6a892d37e955e568",
            "isKey": false,
            "numCitedBy": 195,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Analysing-Images-of-Curved-Surfaces-Woodham",
            "title": {
                "fragments": [],
                "text": "Analysing Images of Curved Surfaces"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102816145"
                        ],
                        "name": "B. Herbst",
                        "slug": "B.-Herbst",
                        "structuredName": {
                            "firstName": "Ben",
                            "lastName": "Herbst",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Herbst"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2096470352"
                        ],
                        "name": "Peter L. Hallinan",
                        "slug": "Peter-L.-Hallinan",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hallinan",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter L. Hallinan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40302807"
                        ],
                        "name": "G. Gordon",
                        "slug": "G.-Gordon",
                        "structuredName": {
                            "firstName": "Gaile",
                            "lastName": "Gordon",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Gordon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081362"
                        ],
                        "name": "A. Yuille",
                        "slug": "A.-Yuille",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Yuille",
                            "middleNames": [
                                "Loddon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yuille"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772090"
                        ],
                        "name": "P. Giblin",
                        "slug": "P.-Giblin",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Giblin",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Giblin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2082087031"
                        ],
                        "name": "David Mumford",
                        "slug": "David-Mumford",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mumford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Mumford"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms: Face Recognition, Image-Based Rendering, Appearance-Based Vision, Face Modeling, Illumination and Pose Modeling, Lighting, Illumination Cones, Generative Models."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 58
                            }
                        ],
                        "text": "When SVD is used to find B from images with shadows, these systematic errors can bias its estimate significantly."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 167
                            }
                        ],
                        "text": "Since the images have shadows (both cast and attached), and possibly saturations, we first have to determine which data values do not satisfy the Lambertian assumption."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 123826368,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "8d9eeb302f3a11f6d92581809cfd53d2f24770c5",
            "isKey": false,
            "numCitedBy": 215,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The human face is perhaps the most familiar and easily recognized object in the world, yet both its three-dimensional shape and its two-dimensional images are complex and hard to characterize. This book develops the vocabulary of ridges and parabolic curves, of illumination eigenfaces and elastic warpings for describing the perceptually salient features of a face and its images. The book also explores the underlying mathematics and applies these mathematical techniques to the computer vision problem of face recognition, using both optical and range images."
            },
            "slug": "Two-and-Three-Dimensional-Patterns-of-the-Face-Herbst-Hallinan",
            "title": {
                "fragments": [],
                "text": "Two- and Three-Dimensional Patterns of the Face"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms: Face Recognition, Image-Based Rendering, Appearance-Based Vision, Face Modeling, Illumination and Pose Modeling, Lighting, Illumination Cones, Generative Models."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 1
                            }
                        ],
                        "text": "Any invalid data (both shadows and saturations) are treated as missing measurements by the following estimation method:\n1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "To enforce integrability, the possibly non-integrable vector field induced by the current estimate of B is, in each iteration, projected down to the space of integrable vector fields, or gradient fields [16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 483975,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74b312560b79929540734067e58de46966b96130",
            "isKey": false,
            "numCitedBy": 1684,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an unsupervised technique for visual learning, which is based on density estimation in high-dimensional spaces using an eigenspace decomposition. Two types of density estimates are derived for modeling the training data: a multivariate Gaussian (for unimodal distributions) and a mixture-of-Gaussians model (for multimodal distributions). Those probability densities are then used to formulate a maximum-likelihood estimation framework for visual search and target detection for automatic object recognition and coding. Our learning technique is applied to the probabilistic visual modeling, detection, recognition, and coding of human faces and nonrigid objects, such as hands."
            },
            "slug": "Probabilistic-Visual-Learning-for-Object-Moghaddam-Pentland",
            "title": {
                "fragments": [],
                "text": "Probabilistic Visual Learning for Object Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "An unsupervised technique for visual learning is presented, which is based on density estimation in high-dimensional spaces using an eigenspace decomposition and is applied to the probabilistic visual modeling, detection, recognition, and coding of human faces and nonrigid objects."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39682833"
                        ],
                        "name": "H. Rowley",
                        "slug": "H.-Rowley",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Rowley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Rowley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767244"
                        ],
                        "name": "S. Baluja",
                        "slug": "S.-Baluja",
                        "structuredName": {
                            "firstName": "Shumeet",
                            "lastName": "Baluja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baluja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 13
                            }
                        ],
                        "text": "Any invalid data (both shadows and saturations) are treated as missing measurements by the following estimation method:\n1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 40120983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a3885c13438132b516e5ffc8b640d20b4e41a7a4",
            "isKey": false,
            "numCitedBy": 4156,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a neural network-based face detection system. A retinally connected neural network examines small windows of an image and decides whether each window contains a face. The system arbitrates between multiple networks to improve performance over a single network. We use a bootstrap algorithm for training the networks, which adds false detections into the training set as training progresses. This eliminates the difficult task of manually selecting non-face training examples, which must be chosen to span the entire space of non-face images. Comparisons with other state-of-the-art face detection systems are presented; our system has better performance in terms of detection and false-positive rates."
            },
            "slug": "Neural-network-based-face-detection-Rowley-Baluja",
            "title": {
                "fragments": [],
                "text": "Neural network-based face detection"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A neural network-based face detection system that arbitrates between multiple networks to improve performance over a single network using a bootstrap algorithm, which eliminates the difficult task of manually selecting non-face training examples."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140335"
                        ],
                        "name": "A. Shashua",
                        "slug": "A.-Shashua",
                        "structuredName": {
                            "firstName": "Amnon",
                            "lastName": "Shashua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shashua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "All cropped images, used for both training and testing, were finally sub-sampled by 4 down to a resolution of 36 42 pixels, and then masked using the binary mask shown in Figure 12."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 123
                            }
                        ],
                        "text": "Therefore, an alternative method is needed to find B , one that takes into account the fact that some data values are invalid and should not be used in the estimation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 120989821,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "39c1352a5b70ad3c2dbe29f5f0ceebf163b414bd",
            "isKey": false,
            "numCitedBy": 211,
            "numCiting": 193,
            "paperAbstract": {
                "fragments": [],
                "text": "The report addresses the problem of visual recognition under two sources of variability: geometric and photometric. The geometric deals with the relation between 3D objects and their views under orthographic and perspective projection. The photometric deals with the relation between 3D matte objects and their images under changing illumination conditions. Taken together, an alignment-based method is presented for recognizing objects viewed from arbitrary viewing positions and illuminated by arbitrary settings of light sources."
            },
            "slug": "Geometry-and-Photometry-in-3D-Visual-Recognition-Shashua",
            "title": {
                "fragments": [],
                "text": "Geometry and Photometry in 3D Visual Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691986"
                        ],
                        "name": "P. Phillips",
                        "slug": "P.-Phillips",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Phillips",
                            "middleNames": [
                                "Jonathon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143979395"
                        ],
                        "name": "H. Wechsler",
                        "slug": "H.-Wechsler",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Wechsler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wechsler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152292143"
                        ],
                        "name": "Jeffrey R. Huang",
                        "slug": "Jeffrey-R.-Huang",
                        "structuredName": {
                            "firstName": "Jeffrey R.",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeffrey R. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3313513"
                        ],
                        "name": "Patrick J. Rauss",
                        "slug": "Patrick-J.-Rauss",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Rauss",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Patrick J. Rauss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 21
                            }
                        ],
                        "text": "Since the images have shadows (both cast and attached), and possibly saturations, we first have to determine which data values do not satisfy the Lambertian assumption."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17779599,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc8b25e35a3acb812beb499844734081722319b4",
            "isKey": false,
            "numCitedBy": 2398,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-FERET-database-and-evaluation-procedure-for-Phillips-Wechsler",
            "title": {
                "fragments": [],
                "text": "The FERET database and evaluation procedure for face-recognition algorithms"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1400601690"
                        ],
                        "name": "A. O'Toole",
                        "slug": "A.-O'Toole",
                        "structuredName": {
                            "firstName": "Alice",
                            "lastName": "O'Toole",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. O'Toole"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144517651"
                        ],
                        "name": "T. Vetter",
                        "slug": "T.-Vetter",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Vetter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Vetter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2932365"
                        ],
                        "name": "N. Troje",
                        "slug": "N.-Troje",
                        "structuredName": {
                            "firstName": "Nikolaus",
                            "lastName": "Troje",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Troje"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153905429"
                        ],
                        "name": "H. B\u00fclthoff",
                        "slug": "H.-B\u00fclthoff",
                        "structuredName": {
                            "firstName": "H",
                            "lastName": "B\u00fclthoff",
                            "middleNames": [
                                "H"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. B\u00fclthoff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 31
                            }
                        ],
                        "text": "in the space of all 3-D shapes [49], and then find the three GBR parameters which minimize the distance of the face reconstruction to this subspace."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12357698,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "badc5fca885c8e732c755d41a6e5f34259c4455c",
            "isKey": false,
            "numCitedBy": 133,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "The sex of a face is perhaps its most salient feature. A principal components analysis (PCA) was applied separately to the three-dimensional (3-D) structure and graylevel image (GLI) data from laser-scanned human heads. Individual components from both analyses captured information related to the sex of the face. Notably, single projection coefficients characterized complex differences between the 3-D structure of male and female heads and between male and female GLI maps. In a series of simulations, the quality of the information available in the 3-D head versus GLI data for predicting the sex of the face has been compared. The results indicated that the 3-D head data supported more accurate sex classification than the GLI data, across a range of PCA-compressed (dimensionality-reduced) representations of the heads. This kind of dual face representation can give insight into the nature of the information available to humans for categorizing and remembering faces."
            },
            "slug": "Sex-Classification-is-Better-with-Three-Dimensional-O'Toole-Vetter",
            "title": {
                "fragments": [],
                "text": "Sex Classification is Better with Three-Dimensional Head Structure Than with Image Intensity Information"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The results indicated that the 3-D head data supported more accurate sex classification than the GLI data, across a range of PCA-compressed (dimensionality-reduced) representations of the heads."
            },
            "venue": {
                "fragments": [],
                "text": "Perception"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691986"
                        ],
                        "name": "P. Phillips",
                        "slug": "P.-Phillips",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Phillips",
                            "middleNames": [
                                "Jonathon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40638847"
                        ],
                        "name": "Hyeonjoon Moon",
                        "slug": "Hyeonjoon-Moon",
                        "structuredName": {
                            "firstName": "Hyeonjoon",
                            "lastName": "Moon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hyeonjoon Moon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2958806"
                        ],
                        "name": "S. A. Rizvi",
                        "slug": "S.-A.-Rizvi",
                        "structuredName": {
                            "firstName": "Syed",
                            "lastName": "Rizvi",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. A. Rizvi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3313513"
                        ],
                        "name": "Patrick J. Rauss",
                        "slug": "Patrick-J.-Rauss",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Rauss",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Patrick J. Rauss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 9
                            }
                        ],
                        "text": "Since the images have shadows (both cast and attached), and possibly saturations, we first have to determine which data values do not satisfy the Lambertian assumption."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 497801,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "791e530f6a4098bb39696d1476032821a7a1c569",
            "isKey": false,
            "numCitedBy": 2335,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Two of the most critical requirements in support of producing reliable face-recognition systems are a large database of facial images and a testing procedure to evaluate systems. The Face Recognition Technology (FERET) program has addressed both issues through the FERET database of facial images and the establishment of the FERET tests. To date, 14,126 images from 1199 individuals are included in the FERET database, which is divided into development and sequestered portions. In September 1996, the FERET program administered the third in a series of FERET face-recognition tests. The primary objectives of the third test were to (1) assess the state of the art, (2) identify future areas of research, and (3) measure algorithm performance on large databases."
            },
            "slug": "The-FERET-evaluation-methodology-for-algorithms-Phillips-Moon",
            "title": {
                "fragments": [],
                "text": "The FERET evaluation methodology for face-recognition algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Two of the most critical requirements in support of producing reliable face-recognition systems are a large database of facial images and a testing procedure to evaluate systems."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 182
                            }
                        ],
                        "text": "A conservative threshold is then chosen to determine shadows, making it almost certain that no invalid data is included in the estimation process, at the small expense of throwing away a few valid measurements."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9242811,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e49ad8354bdd2fd6e8babd348df9e9a5b30bf3a6",
            "isKey": false,
            "numCitedBy": 461,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an unsupervised technique for visual learning which is based on density estimation in high-dimensional spaces using an eigenspace decomposition. Two types of density estimates are derived for modeling the training data: a multivariate Gaussian (for a unimodal distributions) and a multivariate Mixture-of-Gaussians model (for multimodal distributions). These probability densities are then used to formulate a maximum-likelihood estimation framework for visual search and target detection for automatic object recognition. This learning technique is tested in experiments with modeling and subsequent detection of human faces and non-rigid objects such as hands.<<ETX>>"
            },
            "slug": "Probabilistic-visual-learning-for-object-detection-Moghaddam-Pentland",
            "title": {
                "fragments": [],
                "text": "Probabilistic visual learning for object detection"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "An unsupervised technique for visual learning which is based on density estimation in high-dimensional spaces using an eigenspace decomposition and a multivariate Mixture-of-Gaussians model is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2283680"
                        ],
                        "name": "P. Juell",
                        "slug": "P.-Juell",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Juell",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Juell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145127047"
                        ],
                        "name": "R. Marsh",
                        "slug": "R.-Marsh",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Marsh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Marsh"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 194
                            }
                        ],
                        "text": "A conservative threshold is then chosen to determine shadows, making it almost certain that no invalid data is included in the estimation process, at the small expense of throwing away a few valid measurements."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 43374055,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "64b0c20b2737f71b995750b00578ae79e08724bf",
            "isKey": false,
            "numCitedBy": 113,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-hierarchical-neural-network-for-human-face-Juell-Marsh",
            "title": {
                "fragments": [],
                "text": "A hierarchical neural network for human face detection"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7351757"
                        ],
                        "name": "L. D. Harmon",
                        "slug": "L.-D.-Harmon",
                        "structuredName": {
                            "firstName": "Leon",
                            "lastName": "Harmon",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. D. Harmon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153229478"
                        ],
                        "name": "M. K. Khan",
                        "slug": "M.-K.-Khan",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Khan",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. K. Khan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2666876"
                        ],
                        "name": "Richard Lasch",
                        "slug": "Richard-Lasch",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Lasch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Richard Lasch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2691270"
                        ],
                        "name": "P. F. Ramig",
                        "slug": "P.-F.-Ramig",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Ramig",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. F. Ramig"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "For decades, geometric feature-based methods [21], [33], [35], [34], [27], [ 26 ], [59], [6], [69], [42] have used properties and relations (e.g., distances and angles) between facial features such as eyes, mouth, nose, and chin to perform recognition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12872827,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "33fb3a21fa0380114fd5fc0f360d4c6559d17f7f",
            "isKey": false,
            "numCitedBy": 174,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Machine-identification-of-human-faces-Harmon-Khan",
            "title": {
                "fragments": [],
                "text": "Machine identification of human faces"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143814637"
                        ],
                        "name": "Berthold K. P. Horn",
                        "slug": "Berthold-K.-P.-Horn",
                        "structuredName": {
                            "firstName": "Berthold",
                            "lastName": "Horn",
                            "middleNames": [
                                "K.",
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Berthold K. P. Horn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688682"
                        ],
                        "name": "R. Woodham",
                        "slug": "R.-Woodham",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Woodham",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Woodham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "104915782"
                        ],
                        "name": "M. Silverwilliam",
                        "slug": "M.-Silverwilliam",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Silverwilliam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Silverwilliam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 105
                            }
                        ],
                        "text": "In the first set, tests were performed under variable illumination but fixed pose, and the goal was, first, to compare the illumination cones representation with three other popular methods, and second, to test the accuracy of the subspace approximation of illumination cones."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 129417530,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "a750e60a696f934168a022c01dd41d6aecc1a8be",
            "isKey": false,
            "numCitedBy": 220,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : Distribution of surface orientation and reflectance factor on the surface of an object can be determined from scene radiances observed by a fixed sensor under varying lighting conditions. Such techniques have potential application to the automatic inspection of industrial parts, the determination of the attitude of a rigid body in space and the analysis of images returned from planetary explorers. A comparison is made of this method with techniques based on images obtained from different viewpoints with fixed lighting. (Author)"
            },
            "slug": "Determining-Shape-and-Reflectance-Using-Multiple-Horn-Woodham",
            "title": {
                "fragments": [],
                "text": "Determining Shape and Reflectance Using Multiple Images"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3141674"
                        ],
                        "name": "R. Frankot",
                        "slug": "R.-Frankot",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Frankot",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Frankot"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9215658"
                        ],
                        "name": "R. Chellappa",
                        "slug": "R.-Chellappa",
                        "structuredName": {
                            "firstName": "Rama",
                            "lastName": "Chellappa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chellappa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 124
                            }
                        ],
                        "text": "In our experiments, all images were manually cropped to include only the face with as little hair and background as possible."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 179
                            }
                        ],
                        "text": "To capture the images in this database, we have constructed the geodesic lighting rig shown in Figure 10 with 64 computer controlled xenon strobes whose positions in spherical coordinates are shown in Figure 11."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 191,
                                "start": 187
                            }
                        ],
                        "text": "From a set of face images labeled with the person\u2019s identity (the training set) and an unlabeled set of face images from the same group of people (the test set), each algorithm was used to identify the person in the test images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8191817,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "270f3061be9c54e5faa6b4d50969c15afedcb4fc",
            "isKey": false,
            "numCitedBy": 1032,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "An approach for enforcing integrability, a particular implementation of the approach, an example of its application to extending an existing shape-from-shading algorithm, and experimental results showing the improvement that results from enforcing integrability are presented. A possibly nonintegrable estimate of surface slopes is represented by a finite set of basis functions, and integrability is enforced by calculating the orthogonal projection onto a vector subspace spanning the set of integrable slopes. The integrability projection constraint was applied to extending an iterative shape-from-shading algorithm of M.J. Brooks and B.K.P. Horn (1985). Experimental results show that the extended algorithm converges faster and with less error than the original version. Good surface reconstructions were obtained with and without known boundary conditions and for fairly complicated surfaces. >"
            },
            "slug": "A-Method-for-Enforcing-Integrability-in-Shape-from-Frankot-Chellappa",
            "title": {
                "fragments": [],
                "text": "A Method for Enforcing Integrability in Shape from Shading Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "An approach for enforcing integrability, a particular implementation of the approach, an example of its application to extending an existing shape-from-shading algorithm, and experimental results showing the improvement that results from enforcingIntegrability are presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7351757"
                        ],
                        "name": "L. D. Harmon",
                        "slug": "L.-D.-Harmon",
                        "structuredName": {
                            "firstName": "Leon",
                            "lastName": "Harmon",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. D. Harmon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "98147487"
                        ],
                        "name": "S. Kuo",
                        "slug": "S.-Kuo",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Kuo",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kuo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2691270"
                        ],
                        "name": "P. F. Ramig",
                        "slug": "P.-F.-Ramig",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Ramig",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. F. Ramig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2102087"
                        ],
                        "name": "U. Raudkivi",
                        "slug": "U.-Raudkivi",
                        "structuredName": {
                            "firstName": "U.",
                            "lastName": "Raudkivi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Raudkivi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "For decades, geometric feature-based methods [21], [33], [35], [34], [ 27 ], [26], [59], [6], [69], [42] have used properties and relations (e.g., distances and angles) between facial features such as eyes, mouth, nose, and chin to perform recognition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 28480864,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7435fb0253479cf27194e55133c42cc8567dbb92",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Identification-of-human-face-profiles-by-computer-Harmon-Kuo",
            "title": {
                "fragments": [],
                "text": "Identification of human face profiles by computer"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081362"
                        ],
                        "name": "A. Yuille",
                        "slug": "A.-Yuille",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Yuille",
                            "middleNames": [
                                "Loddon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yuille"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144626092"
                        ],
                        "name": "D. Snow",
                        "slug": "D.-Snow",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Snow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Snow"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 35
                            }
                        ],
                        "text": "The images from each pose were divided into 4 subsets (12\u00c6, 25\u00c6, 50\u00c6, and 77\u00c6) according to the angle the light source direction\nmakes with the camera\u2019s axis; see Figure 4."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8213757,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "557ade1ddc4679ec3eacd9167752416c296de655",
            "isKey": false,
            "numCitedBy": 123,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Previous work has developed an approach for estimating shape and albedo from multiple images assuming Lambertian reflectance with single light sources. The main contributions of this paper are: (i) to show how the approach can be generalized to include ambient background illumination, (ii) to demonstrate the use of the integrability constraint for solving this problem, and (iii) an iterative algorithm which is able to improve the analysis by finding shadows and rejecting them."
            },
            "slug": "Shape-and-albedo-from-multiple-images-using-Yuille-Snow",
            "title": {
                "fragments": [],
                "text": "Shape and albedo from multiple images using integrability"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This paper shows how the approach for estimating shape and albedo from multiple images assuming Lambertian reflectance with single light sources can be generalized to include ambient background illumination, and demonstrates the use of the integrability constraint for solving this problem."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47246616"
                        ],
                        "name": "R. Brunelli",
                        "slug": "R.-Brunelli",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Brunelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Brunelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[ 6 ]. An image in the test set is recognized (classified) by assigning to it the label of the closest"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "inferring identity by the geometric relations of these features are ineffective [ 6 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16859093,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "239beb3861ceceb4c7c7f229234d97198d5c7697",
            "isKey": false,
            "numCitedBy": 2828,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Two new algorithms for computer recognition of human faces, one based on the computation of a set of geometrical features, such as nose width and length, mouth position, and chin shape, and the second based on almost-gray-level template matching, are presented. The results obtained for the testing sets show about 90% correct recognition using geometrical features and perfect recognition using template matching. >"
            },
            "slug": "Face-Recognition:-Features-Versus-Templates-Brunelli-Poggio",
            "title": {
                "fragments": [],
                "text": "Face Recognition: Features Versus Templates"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Two new algorithms for computer recognition of human faces, one based on the computation of a set of geometrical features, such as nose width and length, mouth position, and chin shape, and the second based on almost-gray-level template matching are presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49555086"
                        ],
                        "name": "L. Sirovich",
                        "slug": "L.-Sirovich",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Sirovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Sirovich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053520352"
                        ],
                        "name": "M. Kirby",
                        "slug": "M.-Kirby",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kirby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kirby"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms: Face Recognition, Image-Based Rendering, Appearance-Based Vision, Face Modeling, Illumination and Pose Modeling, Lighting, Illumination Cones, Generative Models."
                    },
                    "intents": []
                }
            ],
            "corpusId": 982857,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2a62d0cca2fabf1d6f6ee15e4c14cef415b657d1",
            "isKey": false,
            "numCitedBy": 2592,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "A method is presented for the representation of (pictures of) faces. Within a specified framework the representation is ideal. This results in the characterization of a face, to within an error bound, by a relatively low-dimensional vector. The method is illustrated in detail by the use of an ensemble of pictures taken for this purpose."
            },
            "slug": "Low-dimensional-procedure-for-the-characterization-Sirovich-Kirby",
            "title": {
                "fragments": [],
                "text": "Low-dimensional procedure for the characterization of human faces."
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A method is presented for the representation of faces that results in the characterization of a face, to within an error bound, by a relatively low-dimensional vector."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Optical Society of America. A, Optics and image science"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691986"
                        ],
                        "name": "P. Phillips",
                        "slug": "P.-Phillips",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Phillips",
                            "middleNames": [
                                "Jonathon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40638847"
                        ],
                        "name": "Hyeonjoon Moon",
                        "slug": "Hyeonjoon-Moon",
                        "structuredName": {
                            "firstName": "Hyeonjoon",
                            "lastName": "Moon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hyeonjoon Moon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3313513"
                        ],
                        "name": "Patrick J. Rauss",
                        "slug": "Patrick-J.-Rauss",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Rauss",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Patrick J. Rauss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2958806"
                        ],
                        "name": "S. A. Rizvi",
                        "slug": "S.-A.-Rizvi",
                        "structuredName": {
                            "firstName": "Syed",
                            "lastName": "Rizvi",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. A. Rizvi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5129656,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0f04a95ec885cf98e7cee43eacff13de0c888d3b",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Two of the most critical requirements in support of producing reliable face-recognition systems are a large database of facial images and a testing procedure to evaluate systems. The Face Recognition Technology (FERET) program has addressed both issues through the FERET database of facial images and the establishment of the FERET tests. In this paper, we report on the FERET database and the September 1996 FERET test. This test is the third in a series of supervised face-recognition test administered under the FERET program."
            },
            "slug": "The-FERET-September-1996-Database-and-Evaluation-Phillips-Moon",
            "title": {
                "fragments": [],
                "text": "The FERET September 1996 Database and Evaluation Procedure"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The FERET database and the September 1996 FerET test are reported on, which is the third in a series of supervised face-recognition test administered under the FERGET program."
            },
            "venue": {
                "fragments": [],
                "text": "AVBPA"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144986880"
                        ],
                        "name": "I. Craw",
                        "slug": "I.-Craw",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Craw",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Craw"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3263505"
                        ],
                        "name": "D. Tock",
                        "slug": "D.-Tock",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Tock",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Tock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056963263"
                        ],
                        "name": "Alan Bennett",
                        "slug": "Alan-Bennett",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Bennett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alan Bennett"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Furthermore, we assume that the face to be recognized has been located (but not necessarily accurately aligned) within the image, as there are numerous methods for finding faces in images [ 13 ], [55], [60], [38], [9], [41], [44], [40], [32], [22], [72], [45], [58], [57], [71]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17481367,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e2e6bc4db498566a9f95f122970fb4488eaf3392",
            "isKey": false,
            "numCitedBy": 332,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a computer program which understands a greyscale image of a face well enough to locate individual face features such as eyes and mouth. The program has two distinct components: modules designed to locate particular face features, usually in a restricted area; and the overall control strategy which activates modules on the basis of the current solution state, and assesses and integrates the results of each module."
            },
            "slug": "Finding-Face-Features-Craw-Tock",
            "title": {
                "fragments": [],
                "text": "Finding Face Features"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A computer program which understands a greyscale image of a face well enough to locate individual face features such as eyes and mouth is described."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms: Face Recognition, Image-Based Rendering, Appearance-Based Vision, Face Modeling, Illumination and Pose Modeling, Lighting, Illumination Cones, Generative Models."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2591356,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f2b7a0c608ab2557b8897cddd1dd7ebd56978a85",
            "isKey": false,
            "numCitedBy": 458,
            "numCiting": 259,
            "paperAbstract": {
                "fragments": [],
                "text": "The research topic of looking at people, that is, giving machines the ability to detect, track, and identify people and more generally, to interpret human behavior, has become a central topic in machine vision research. Initially thought to be the research problem that would be hardest to solve, it has proven remarkably tractable and has even spawned several thriving commercial enterprises. The principle driving application for this technology is \"fourth generation\" embedded computing: \"smart\" environments and portable or wearable devices. The key technical goals are to determine the computer's context with respect to nearby humans (e.g., who, what, when, where, and why) so that the computer can act or respond appropriately without detailed instructions. The paper examines the mathematical tools that have proven successful, provides a taxonomy of the problem domain, and then examines the state of the art. Four areas receive particular attention: person identification, surveillance/monitoring, 3D methods, and smart rooms/perceptual user interfaces. Finally, the paper discusses some of the research challenges and opportunities."
            },
            "slug": "Looking-at-People:-Sensing-for-Ubiquitous-and-Pentland",
            "title": {
                "fragments": [],
                "text": "Looking at People: Sensing for Ubiquitous and Wearable Computing"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The paper examines the mathematical tools that have proven successful, provides a taxonomy of the problem domain, and then examines the state of the art: person identification, surveillance/monitoring, 3D methods, and smart rooms/perceptual user interfaces."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143766793"
                        ],
                        "name": "A. Rosenfeld",
                        "slug": "A.-Rosenfeld",
                        "structuredName": {
                            "firstName": "Azriel",
                            "lastName": "Rosenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rosenfeld"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 117
                            }
                        ],
                        "text": "In the first set, tests were performed under variable illumination but fixed pose, and the goal was, first, to compare the illumination cones representation with three other popular methods, and second, to test the accuracy of the subspace approximation of illumination cones."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 441278,
            "fieldsOfStudy": [
                "Computer Science",
                "Art"
            ],
            "id": "b441dd8fb25eddbaf92bc9938afda69627a281ab",
            "isKey": false,
            "numCitedBy": 3878,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Computer-Vision-Rosenfeld",
            "title": {
                "fragments": [],
                "text": "Computer Vision"
            },
            "venue": {
                "fragments": [],
                "text": "Adv. Comput."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2168816"
                        ],
                        "name": "D. Stuss",
                        "slug": "D.-Stuss",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Stuss",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Stuss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47248134"
                        ],
                        "name": "A. Hamer",
                        "slug": "A.-Hamer",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Hamer",
                            "middleNames": [
                                "M",
                                "P"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hamer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6918045"
                        ],
                        "name": "L. Palumbo",
                        "slug": "L.-Palumbo",
                        "structuredName": {
                            "firstName": "Letizia",
                            "lastName": "Palumbo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Palumbo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2080862548"
                        ],
                        "name": "C. Dempster",
                        "slug": "C.-Dempster",
                        "structuredName": {
                            "firstName": "C",
                            "lastName": "Dempster",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Dempster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "95349405"
                        ],
                        "name": "R. Binns",
                        "slug": "R.-Binns",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Binns",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Binns"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "93562020"
                        ],
                        "name": "M. Levine",
                        "slug": "M.-Levine",
                        "structuredName": {
                            "firstName": "Marvin",
                            "lastName": "Levine",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Levine"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1397844999"
                        ],
                        "name": "B. Izuakawa",
                        "slug": "B.-Izuakawa",
                        "structuredName": {
                            "firstName": "B",
                            "lastName": "Izuakawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Izuakawa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms: Face Recognition, Image-Based Rendering, Appearance-Based Vision, Face Modeling, Illumination and Pose Modeling, Lighting, Illumination Cones, Generative Models."
                    },
                    "intents": []
                }
            ],
            "corpusId": 889956,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "9b74a8d8da4a17096480b04192f467748b8be093",
            "isKey": false,
            "numCitedBy": 715,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "A functional neuroimaging study of the variables that generate category-specific object processing differences. On the interaction of selective attention and lexical knowledge: A connectionist account of neglect dyslexia. D 1998 The effects of focal anterior and posterior brain lesions on verbal fluency. The discipline has emerged in the 1990s at the interface between the neural sciences and the cognitive and computational sciences. On one side, it grows out of the traditions of cognitive psychology and neuro-psychology, which use behavioral experiments to uncover the processes and mechanisms lying behind human cognitive functions, and of computational approaches within cognitive psychology, which rely on computational models to develop explicit mech-anistic accounts of these functions. On the other side, it grows out of the traditions of behavioral, functional, and systems neuroscience, which use neurophysio-logical and neuroanatomical methods to explore the mechanisms underlying complex functions. It draws on findings and principles of cellular and molecular neuroscience. It joins these approaches with the use of new functional brain imaging methods, such as functional magnetic imaging (fMRI), positron emission tomography (PET), as well as other methods including electroencephalography (EEG) and mag-netoencephalography (MEG), and with a growing research tradition in computational neuroscience. A starting point for cognitive neuroscience is the idea that a cognitive or mental state consists of a pattern of activity distributed over many neurons. For example, the experience an individual has when holding, sniffing , and viewing a rose is a complex pattern of neural activity, distributed over many brain regions, including the participation of neurons in visual, somato-sensory, and olfactory, and possibly extending to language areas participating in representing the sound of the word 'rose' and\\or other areas where activity represents the content of an associated memory that may be evoked by the experience. These patterns of activation arise from excitatory and inhibitory interactions among the participating neurons, mediated by connections called synapses. The inputs neurons receive cause them to 'fire' or emit impulses called spikes or action potentials, which travel down their axons to synaptic terminals where they cause the release of chemicals that then have excitatory or inhibitory influences on the neurons on the other side of the synapse. The combined effect of the incoming signals to each neuron, together with its recent history, determines whether it will fire at a particular moment. Figure 1 indicates something of the fundamental circuitry involved, though it should be noted that only one out of \u2026"
            },
            "slug": "Cognitive-neuroscience.-Stuss-Hamer",
            "title": {
                "fragments": [],
                "text": "Cognitive neuroscience."
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Cognitive neuroscience has emerged in the 1990s at the interface between the neural sciences and the cognitive and computational sciences and joins these approaches with the use of new functional brain imaging methods, such as functional magnetic imaging (fMRI), positron emission tomography (PET), as well as other methods including electroencephalography (EEG) and mag-netoencephalographic (MEG)."
            },
            "venue": {
                "fragments": [],
                "text": "Current opinion in neurobiology"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 24
                            }
                        ],
                        "text": "[40], [32], [22], [72], [45], [58], [57], [71]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "This is in contrast to [45] where all faces are modeled by a single collection of lowdimensional subspaces, with each subspace modeling the appearance of all faces in one particular view."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 54
                            }
                        ],
                        "text": "See, for example, [36], [66], [23], [51], [55], [47], [45], [25]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 94
                            }
                        ],
                        "text": "We should point out that our dimensionality reduction techniques are similar to those used in [45], but they differ on three important counts."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aProbabilistic Visual Learning for Object Representation,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 177
                            }
                        ],
                        "text": "It is, in spirit, most closely related to the synthesis approaches suggested in [61, 56] and stands in stark contrast to the illumination insensitivity techniques argued for in [3, 8]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "For more details about the comparison algorithms, see [3] and [20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 213,
                                "start": 210
                            }
                        ],
                        "text": "This image is then converted into a synthesized image with virtual frontal view and frontal illumination, and this virtual image is finally fed into a system such as LDA [76] (similar to the Fisherfaces method [3]) for recognition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "Similar to the extrapolation experiments described in [3], each method was trained on images from Subset 1 (seven images per face in frontal pose with near-frontal illumination), and then tested on all 450 images from the frontal pose."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 53
                            }
                        ],
                        "text": "the dimensionality of the feature space is increased [3, 47]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 189
                            }
                        ],
                        "text": "One proposed method for handling illumination variation in PCA is to discard from W the three most significant principal components; in practice, this yields better recognition performance [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Eigenfaces vs"
            },
            "venue": {
                "fragments": [],
                "text": "Fisherfaces: Recognition using class specific linear projection. IEEE Trans. Pattern Anal. Mach. Intelligence, 19(7):711\u2013720,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 88
                            }
                        ],
                        "text": "This cone, termed the illumination cone, can be constructed from as few as three images [1] if the object is convex in shape and has Lambertian reflectance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 99
                            }
                        ],
                        "text": ", all points lie near a low-dimensional linear subspace) and this was confirmed for faces in [15], [1], [19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 208
                            }
                        ],
                        "text": "To get around this, we take advantage of the fact that, under fixed viewpoint, the set of all n-pixel images of a face (or any object), under arbitrary illumination, forms a convex cone in the image space IR [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 108
                            }
                        ],
                        "text": "First, we approximate each of the illumination cones with its own low-dimensional subspace, as suggested in [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 36
                            }
                        ],
                        "text": "It was empirically determined [15], [1], [19] that 11 dimensions capture over 99 percent of the variance in the sample extreme rays (images)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 83
                            }
                        ],
                        "text": "An illumination cone can be well-approximated by a low-dimensional linear subspace [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 47
                            }
                        ],
                        "text": "From an empirical study, it was conjectured in [1] that the cone \u0108p for typical objects is flat (i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 73
                            }
                        ],
                        "text": ", intersection of L with the nonnegative orthant(2)) forms a convex cone [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 163
                            }
                        ],
                        "text": "The set of images of an object in fixed pose but under all possible illumination conditions is a convex cone (termed the illumination cone) in the space of images [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 164
                            }
                        ],
                        "text": "When the surface reflectance can be approximated as Lambertian, this illumination cone can be constructed from a handful of images acquired under variable lighting [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aWhat Is the Set of Images of an Object under All Possible Illumination Conditions,o"
            },
            "venue": {
                "fragments": [],
                "text": "Int'l J. Computer Vision, vol. 28,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 43
                            }
                        ],
                        "text": "Although the Harvard Robotics Lab database [23, 24, 25] contains images of faces with large variations in illumination, the pose is fixed throughout."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 84
                            }
                        ],
                        "text": "This method for handling lighting variability in images of human faces differs from [23, 24, 25] in that our model is generative\u2014it requires only a few images to predict large image changes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 72
                            }
                        ],
                        "text": "(This test was also performed on the Harvard Robotics Lab face database [23, 24] and was reported on in [20]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 151
                            }
                        ],
                        "text": "We call this recognition scheme the Linear Subspace method [2]; it is a variant of the photometric alignment method proposed in [62] and is related to [24, 48]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Deformable Model for Face Recognition Under Arbitrary Lighting Conditions"
            },
            "venue": {
                "fragments": [],
                "text": "PhD thesis, Harvard University,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 99
                            }
                        ],
                        "text": "Since each cone is convex, the distance can be found by solving a convex optimization problem (see [20])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 124
                            }
                        ],
                        "text": "unknown positions, to estimate its surface geometry and albedo map up to a generalized bas-relief (GBR) transformation [2], [20], [18], [19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 62
                            }
                        ],
                        "text": "For more details about the comparison algorithms, see [3] and [20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 106
                            }
                        ],
                        "text": "(This test was also performed on the Harvard Robotics Lab face database [23], [24] and was reported on in [20]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 133
                            }
                        ],
                        "text": "The cone can be simplified in two ways: using a subset of the extreme rays and approximating it as a low-dimensional linear subspace [20], [19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 236503748,
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and P"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 151
                            }
                        ],
                        "text": "We call this recognition scheme the Linear Subspace method [2]; it is a variant of the photometric alignment method proposed in [62] and is related to [24], [48]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "database [23], [24], [25] contains images of faces with large"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 90
                            }
                        ],
                        "text": "This method for handling lighting variability in images of human faces differs from [23], [24], [25] in that our model is generative\u00d0it requires only a few images to predict large image changes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 78
                            }
                        ],
                        "text": "(This test was also performed on the Harvard Robotics Lab face database [23], [24] and was reported on in [20]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Deformable Model for Face Recognition under Arbitrary Lighting Conditions,o"
            },
            "venue": {
                "fragments": [],
                "text": "PhD thesis, Harvard Univ.,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "For more details about the comparison algorithms, see [3] and [20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 104
                            }
                        ],
                        "text": "(Recall that performance approaches correlation as the dimensionality of the feature space is increased [3], [47]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 189
                            }
                        ],
                        "text": "One proposed method for handling illumination variation in PCA is to discard from W the three most significant principal components; in practice, this yields better recognition performance [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 209
                            }
                        ],
                        "text": "This image is then converted into a synthesized image with virtual frontal view and frontal illumination and this virtual image is finally fed into a system such as LDA [76] (similar to the Fisherfaces method [3]) for recognition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 179
                            }
                        ],
                        "text": "It is, in spirit, most closely related to the synthesis approaches suggested in [61], [56] and stands in stark contrast to the illumination insensitivity techniques argued for in [3], [8]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "Similar to the extrapolation experiments described in [3], each method was trained on images from Subset 1 (seven images per face in frontal pose with near-frontal illumination) and then tested on all 450 images from the frontal pose."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aEigenfaces vs. Fisherfaces: Recognition Using Class Specific Linear Projection,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis Machine Intelligence,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 24
                            }
                        ],
                        "text": "Techniques such as SLAM [47] and Eigenfaces [66] have demonstrated the power of appearance-based methods both in ease of implementation and in accuracy."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 181
                            }
                        ],
                        "text": "Eigenfaces: A technique commonly used in computer vision\u00d0particularly in face recognition\u00d0is principal components analysis (PCA), which is popularly known as Eigenfaces [23], [36], [47], [66]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 109
                            }
                        ],
                        "text": "(Recall that performance approaches correlation as the dimensionality of the feature space is increased [3], [47]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 48
                            }
                        ],
                        "text": "See, for example, [36], [66], [23], [51], [55], [47], [45], [25]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aVisual Learning and Recognition of 3D Objects from Appearance,o"
            },
            "venue": {
                "fragments": [],
                "text": "Int'l J. Computer Vision,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 136
                            }
                        ],
                        "text": "unknown positions, to estimate its surface geometry and albedo map up to a generalized bas-relief (GBR) transformation [2], [20], [18], [19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 104
                            }
                        ],
                        "text": ", all points lie near a low-dimensional linear subspace) and this was confirmed for faces in [15], [1], [19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 41
                            }
                        ],
                        "text": "It was empirically determined [15], [1], [19] that 11 dimensions capture over 99 percent of the variance in the sample extreme rays (images)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 108
                            }
                        ],
                        "text": "(These experiments were also performed with 19 training images per face and the results were reported on in [19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 139
                            }
                        ],
                        "text": "The cone can be simplified in two ways: using a subset of the extreme rays and approximating it as a low-dimensional linear subspace [20], [19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and D"
            },
            "venue": {
                "fragments": [],
                "text": "Kriegman, aFrom Few to Many: Generative Models for Recognition under Variable Pose and Illumination,o Proc. IEEE Int'l Conf. Automatic Face and Gesture Recognition, pp. 277-284"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 191,
                                "start": 187
                            }
                        ],
                        "text": "Eigenfaces: A technique commonly used in computer vision\u00d0particularly in face recognition\u00d0is principal components analysis (PCA), which is popularly known as Eigenfaces [23], [36], [47], [66]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 26
                            }
                        ],
                        "text": "In our implementations of Eigenfaces, the dimensionality of the feature space was chosen to be 20, that is, we used 20 principal components."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 24
                            }
                        ],
                        "text": "See, for example, [36], [66], [23], [51], [55], [47], [45], [25]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 0
                            }
                        ],
                        "text": "Eigenfaces: A technique commonly used in computer vision\u2014particularly in face recognition\n\u2014is principal components analysis (PCA), which is popularly known as Eigenfaces [23, 36, 47, 66]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 30
                            }
                        ],
                        "text": "In fact, both Correlation and Eigenfaces methods break down under extreme illumination conditions."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 44
                            }
                        ],
                        "text": "Techniques such as SLAM [47] and Eigenfaces [66] have demonstrated the power of appearance-based methods both in ease of implementation and in accuracy."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 3
                            }
                        ],
                        "text": "In Eigenfaces, like Correlation, the images were normalized to have zero mean and unit variance, as this improved its performance."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aEigenfaces for Recognition,o"
            },
            "venue": {
                "fragments": [],
                "text": "J. Cognitive Neuroscience,"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767767"
                        ],
                        "name": "P. Belhumeur",
                        "slug": "P.-Belhumeur",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Belhumeur",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Belhumeur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765887"
                        ],
                        "name": "D. Kriegman",
                        "slug": "D.-Kriegman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kriegman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kriegman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081362"
                        ],
                        "name": "A. Yuille",
                        "slug": "A.-Yuille",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Yuille",
                            "middleNames": [
                                "Loddon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yuille"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We call this recognition scheme the Linear Subspace method [ 2 ];"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "shading and shadows) [ 2 , 74]. This means we cannot recover the true matrix and its corresponding"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "and albedo map up to a generalized bas-relief (GBR) transformation [ 2 , 20, 18, 19]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5126850,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "f2db9c27ef09052606b331fb92c1911bfcc0a21b",
            "isKey": false,
            "numCitedBy": 542,
            "numCiting": 86,
            "paperAbstract": {
                "fragments": [],
                "text": "AbstractWhen an unknown object with Lambertian reflectance is viewed orthographically, there is an implicit ambiguity in determining its 3-d structure: we show that the object's visible surface f(x, y) is indistinguishable from a \u201cgeneralized bas-relief\u201d transformation of the object's geometry, \n$$ {\\bar f} $$\n (x, y) = \u03bbf(x, y) + \u03bcx + \u03bdy, and a corresponding transformation on the object's albedo. For each image of the object illuminated by an arbitrary number of distant light sources, there exists an identical image of the transformed object illuminated by similarly transformed light sources. This result holds both for the illuminated regions of the object as well as those in cast and attached shadows. Furthermore, neither small motion of the object, nor of the viewer will resolve the ambiguity in determining the flattening (or scaling) \u03bb of the object's surface. Implications of this ambiguity on structure recovery and shape representation are discussed."
            },
            "slug": "The-Bas-Relief-Ambiguity-Belhumeur-Kriegman",
            "title": {
                "fragments": [],
                "text": "The Bas-Relief Ambiguity"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "It is shown that the object's visible surface f(x, y) is indistinguishable from a \u201cgeneralized bas-relief\u201d transformation of the object\u2019s geometry, and a corresponding transformation on theobject's albedo, which results in an identical image of the transformed object illuminated by similarly transformed light sources."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "For decades, geometric feature-based methods [21], [ 33 ], [35], [34], [27], [26], [59], [6], [69], [42] have used properties and relations (e.g., distances and angles) between facial features such as eyes, mouth, nose, and chin to perform recognition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62020702,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "52f869ade6ac2de7b86648f4cb72b5b3bb9862ac",
            "isKey": false,
            "numCitedBy": 414,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Picture-Processing-System-by-Computer-Complex-and-Kanade",
            "title": {
                "fragments": [],
                "text": "Picture Processing System by Computer Complex and Recognition of Human Faces"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms: Face Recognition, Image-Based Rendering, Appearance-Based Vision, Face Modeling, Illumination and Pose Modeling, Lighting, Illumination Cones, Generative Models."
                    },
                    "intents": []
                }
            ],
            "corpusId": 59895060,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0892bb0b8209cf0d7be9ee3041eac9e27f1499fd",
            "isKey": false,
            "numCitedBy": 340,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Computer-recognition-of-human-faces-Kanade",
            "title": {
                "fragments": [],
                "text": "Computer recognition of human faces"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691804"
                        ],
                        "name": "D. Ballard",
                        "slug": "D.-Ballard",
                        "structuredName": {
                            "firstName": "Dana",
                            "lastName": "Ballard",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ballard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48726084"
                        ],
                        "name": "Christopher M. Brown",
                        "slug": "Christopher-M.-Brown",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Brown",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher M. Brown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 195995446,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e26162d70f04da2091d1aa011f6999b76cbddff",
            "isKey": false,
            "numCitedBy": 4640,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Computer-Vision-Ballard-Brown",
            "title": {
                "fragments": [],
                "text": "Computer Vision"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "For decades, geometric feature-based methods [21], [33], [35], [34], [27], [26], [59], [6], [ 69 ], [42] have used properties and relations (e.g., distances and angles) between facial features such as eyes, mouth, nose, and chin to perform recognition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 30523165,
            "fieldsOfStudy": [],
            "id": "6f01963039d0a921b1930b4563d1601ff36b971f",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face Recognition by Elastic Bunch Graph Matching"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6435894"
                        ],
                        "name": "S. McKenna",
                        "slug": "S.-McKenna",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "McKenna",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. McKenna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144784813"
                        ],
                        "name": "S. Gong",
                        "slug": "S.-Gong",
                        "structuredName": {
                            "firstName": "Shaogang",
                            "lastName": "Gong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3038814"
                        ],
                        "name": "R. W\u00fcrtz",
                        "slug": "R.-W\u00fcrtz",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "W\u00fcrtz",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. W\u00fcrtz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144411844"
                        ],
                        "name": "J. Tanner",
                        "slug": "J.-Tanner",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Tanner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tanner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2220947"
                        ],
                        "name": "D. Banin",
                        "slug": "D.-Banin",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Banin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Banin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "Since the images have shadows (both cast and attached), and possibly saturations, we first have to determine which data values do not satisfy the Lambertian assumption."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8962129,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "144d056830387b04b8c5e5fa9e9bea84c4600d27",
            "isKey": false,
            "numCitedBy": 421,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Audio-and-Video-based-Biometric-Person-McKenna-Gong",
            "title": {
                "fragments": [],
                "text": "Audio- and Video-based Biometric Person Authentication"
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2141437395"
                        ],
                        "name": "Thomas Leung",
                        "slug": "Thomas-Leung",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Leung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Leung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2511655"
                        ],
                        "name": "M. Burl",
                        "slug": "M.-Burl",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Burl",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Burl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 176
                            }
                        ],
                        "text": "A conservative threshold is then chosen to determine shadows, making it almost certain that no invalid data is included in the estimation process, at the small expense of throwing away a few valid measurements."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 203665849,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9232bfb8109b3d3237be4a2cf870e6201519ce5d",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Finding-Faces-in-Cluttered-Scenes-Using-Labeled-Leung-Burl",
            "title": {
                "fragments": [],
                "text": "Finding Faces in Cluttered Scenes Using Labeled Random Graph Matching."
            },
            "venue": {
                "fragments": [],
                "text": "ICCV 1995"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "tity\u201d [ 46 ]. As is evident in Figures 1, 2, and 4, the same person, with the same facial expression,"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18971022,
            "fieldsOfStudy": [],
            "id": "59e9ef8b61182acace9e37f41f9c2a03db69c15b",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face Recognition: the Problem of Compensating for Changes in Illumination Direction"
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50564384"
                        ],
                        "name": "G. Edwards",
                        "slug": "G.-Edwards",
                        "structuredName": {
                            "firstName": "Gareth",
                            "lastName": "Edwards",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Edwards"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 180
                            }
                        ],
                        "text": "In another approach, an Active Appearance Model of a generic face is deformed to fit to the input image, and the control parameters are used as a feature vector for classification [10, 39, 14, 11]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2230657,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "76b532e2cb573fdf29f3ae68dc1372f3319c93c2",
            "isKey": false,
            "numCitedBy": 3787,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a new method of matching statistical models of appearance to images. A set of model parameters control modes of shape and gray-level variation learned from a training set. We construct an efficient iterative matching algorithm by learning the relationship between perturbations in the model parameters and the induced image errors."
            },
            "slug": "Active-Appearance-Models-Cootes-Edwards",
            "title": {
                "fragments": [],
                "text": "Active Appearance Models"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "A new method of matching statistical models of appearance to images by learning the relationship between perturbations in the model parameters and the induced image errors is described."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767767"
                        ],
                        "name": "P. Belhumeur",
                        "slug": "P.-Belhumeur",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Belhumeur",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Belhumeur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685300"
                        ],
                        "name": "J. Hespanha",
                        "slug": "J.-Hespanha",
                        "structuredName": {
                            "firstName": "Jo\u00e3o",
                            "lastName": "Hespanha",
                            "middleNames": [
                                "Pedro"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hespanha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765887"
                        ],
                        "name": "D. Kriegman",
                        "slug": "D.-Kriegman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kriegman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kriegman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "These partial derivatives can also be expressed as a series, giving\nz x (x; y; c 1 (w)) =\nX c\n1 (w) x(x; y;w) (11)\nand\nz y (x; y; c 2 (w)) =\nX c\n2 (w) y(x; y;w): (12)\nNote that in general c 1 (w) 6= c 2 (w), which implies that z xy (x; y) 6= z yx (x; y)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "For the purpose of this estimation, any invalid data will be treated as missing measurements."
                    },
                    "intents": []
                }
            ],
            "corpusId": 30582,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "be86da00efdd8c2a7fdeb2334605796c24b370f0",
            "isKey": false,
            "numCitedBy": 11723,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop a face recognition algorithm which is insensitive to large variation in lighting direction and facial expression. Taking a pattern classification approach, we consider each pixel in an image as a coordinate in a high-dimensional space. We take advantage of the observation that the images of a particular face, under varying illumination but fixed pose, lie in a 3D linear subspace of the high dimensional image space-if the face is a Lambertian surface without shadowing. However, since faces are not truly Lambertian surfaces and do indeed produce self-shadowing, images will deviate from this linear subspace. Rather than explicitly modeling this deviation, we linearly project the image into a subspace in a manner which discounts those regions of the face with large deviation. Our projection method is based on Fisher's linear discriminant and produces well separated classes in a low-dimensional subspace, even under severe variation in lighting and facial expressions. The eigenface technique, another method based on linearly projecting the image space to a low dimensional subspace, has similar computational requirements. Yet, extensive experimental results demonstrate that the proposed \"Fisherface\" method has error rates that are lower than those of the eigenface technique for tests on the Harvard and Yale face databases."
            },
            "slug": "Eigenfaces-vs.-Fisherfaces:-Recognition-Using-Class-Belhumeur-Hespanha",
            "title": {
                "fragments": [],
                "text": "Eigenfaces vs. Fisherfaces: Recognition Using Class Specific Linear Projection"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A face recognition algorithm which is insensitive to large variation in lighting direction and facial expression is developed, based on Fisher's linear discriminant and produces well separated classes in a low-dimensional subspace, even under severe variations in lighting and facial expressions."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 48
                            }
                        ],
                        "text": "Assume the surface has a Lambertian reflectance [37] with albedo (x; y) and is viewed orthographically."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Photometria Sive de Mensura et Gradibus Luminus, Colorum et Umbrae"
            },
            "venue": {
                "fragments": [],
                "text": "Eberhard Klett,"
            },
            "year": 1760
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 46
                            }
                        ],
                        "text": "for finding faces in images [13], [55], [60], [38], [9], [41], [44],"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 60
                            }
                        ],
                        "text": "This method for handling pose variability differs from [4], [38], [30], [43] in that we warp synthetic frontal-pose images of each face using its estimated surface geometry."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and T"
            },
            "venue": {
                "fragments": [],
                "text": "Cootes, aA Unified Approach to Coding and Interpreting Face Images,o Proc. Int'l Conf. Computer Vision, pp. 368-373"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 191
                            }
                        ],
                        "text": "\u2026stated in Equation 6 can then be reformulated into:\nmin b j ;si X ij wijjxij < b j ; si > j 2 (7)\nwhere xij is the j-th pixel of the i-th image, b j is the j-th row of matrix B 2 IRn 3, si is the light source direction and strength in the i-th image, and\nwij =\n1 xij valid measurement, 0 otherwise."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 148
                            }
                        ],
                        "text": "\u2026in terms of this expansion,\ngiving\nzx(x; y; c(w)) = X c(w) x(x; y;w) (9)\nand\nzy(x; y; c(w)) = X c(w) y(x; y;w): (10)\nSince the partial derivatives of the basis functions, x(x; y;w) and y(x; y;w), are integrable and the expansions of zx(x; y) and zy(x; y) share the same coefficients c(w), it is\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaFace Recognition under Varying Pose,\u00ba Proc. IEEE Conf. Computer Vision and Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaFace Recognition under Varying Pose,\u00ba Proc. IEEE Conf. Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 126
                            }
                        ],
                        "text": "At the core of our approach for generating images with novel lighting and viewpoints is a variant of photometric stereo [64], [70], [29], [28], [73] which simultaneously estimates geometry and albedo across the scene."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aAnalysing Images of Curved Surfaces,o"
            },
            "venue": {
                "fragments": [],
                "text": "Artificial Intelligence,"
            },
            "year": 1981
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Sex classification is better with three-dimensional head structure than with texture"
            },
            "venue": {
                "fragments": [],
                "text": "Perception"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 30
                            }
                        ],
                        "text": "[40], [32], [22], [72], [45], [58], [57], [71]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and T"
            },
            "venue": {
                "fragments": [],
                "text": "Kanade, aRotation Invariant Neural Network-Based Face Detection,o Proc. IEEE Conf. Computer Vision and Pattern Recognition, pp. 38-44"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "FFor further information on this or any computing topic, please visit our Digital Library at http://computer.org/publications/dlib"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 98
                            }
                        ],
                        "text": "For decades, geometric feature-based methods [21], [33], [35], [34], [27], [26], [59], [6], [69], [42] have used properties and relations (e."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aFace Recognition Using Nearest Feature Line,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 109
                            }
                        ],
                        "text": "Over the last few years, numerous algorithms have been proposed for face recognition, see surveys [59], [7], [17], [50]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aFace Recognition: A Summary of 1995-1997,o Int'l Computer Science Inst. ICSI TR-98-027"
            },
            "venue": {
                "fragments": [],
                "text": "Univ. of California,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 50
                            }
                        ],
                        "text": "typical head shapes in the space of all 3D shapes [49] and"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and H"
            },
            "venue": {
                "fragments": [],
                "text": "Bulthoff, aSex Classification is Better with Three-Dimensional Head Structure than with Texture,o Perception, vol. 26, pp. 75-84"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaOn Photometric Issues to Feature-Based Object Recognition,\u00ba Int'l"
            },
            "venue": {
                "fragments": [],
                "text": "J. Computer Vision"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 12
                            }
                        ],
                        "text": "[40], [32], [22], [72], [45], [58], [57], [71]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aLocating Human Faces in Photographs,o"
            },
            "venue": {
                "fragments": [],
                "text": "Int'l J. Computer Vision,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 52
                            }
                        ],
                        "text": "When SVD is used to find B from images with shadows, these systematic errors can bias its estimate significantly."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 161
                            }
                        ],
                        "text": "Since the images have shadows (both cast and attached), and possibly saturations, we first have to determine which data values do not satisfy the Lambertian assumption."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaA Deformable Model for Face Recognition under Arbitrary Lighting Conditions"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaA Deformable Model for Face Recognition under Arbitrary Lighting Conditions"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 45
                            }
                        ],
                        "text": "For decades, geometric feature-based methods [21, 33, 35, 34, 27, 26, 59, 6, 69, 42] have used properties and relations (e."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Picture processing by computer complex and recognition of human faces"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 12
                            }
                        ],
                        "text": "This task can be cast into a minimization problem given by\nmin B ;S jjX B Sjj\n2 (6)\nwhere X = [x1; : : : ;xk] is the data matrix for k images of a face (in vector form), and S is a 3 k matrix whose columns, si, are the light source directions scaled by their corresponding source intensities for all\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 30
                            }
                        ],
                        "text": "The images from each pose were divided into 4 subsets (12\u00c6, 25\u00c6, 50\u00c6, and 77\u00c6) according to the angle the light source direction\nmakes with the camera\u2019s axis; see Figure 4."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proc. IEEE Conf. Computer Vision and Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE Conf. Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms: Face Recognition, Image-Based Rendering, Appearance-Based Vision, Face Modeling, Illumination and Pose Modeling, Lighting, Illumination Cones, Generative Models."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaFace Recognition: Features vs. Templates"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 170
                            }
                        ],
                        "text": "For every sample pose p 2 f1; : : : ; Pg of the face, we generate its illumination cone Cp, and the union of all the cones forms its representation Rf = S P p=1 Cp, where P is the total number of sample poses."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Photometria Sive de Mensura et Gradibus Luminus, Colorum et Umbrae. Eberhard Klett"
            },
            "venue": {
                "fragments": [],
                "text": "Photometria Sive de Mensura et Gradibus Luminus, Colorum et Umbrae. Eberhard Klett"
            },
            "year": 1760
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 120
                            }
                        ],
                        "text": "At the core of our approach for generating images with novel lighting and viewpoints is a variant of photometric stereo [64], [70], [29], [28], [73] which simultaneously estimates geometry and albedo across the scene."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aDetermining Shape and Reflectance Using Multiple Images,o"
            },
            "venue": {
                "fragments": [],
                "text": "PhD thesis, Massachusetts Inst. of Technology,"
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 40
                            }
                        ],
                        "text": "for finding faces in images [13], [55], [60], [38], [9], [41], [44],"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aHuman Face Detection Using Silhouettes,o"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognition and Artificial Intelligence,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 38
                            }
                        ],
                        "text": "A variation of [63] (see, also, [31], [65]) which finds a basis for the 3D linear subspace L from image data with missing elements is used together with the method in [16] which enforces integrability in shape from shading."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aShape and Motion from Image Streams under Orthography: A Factorization Method,o"
            },
            "venue": {
                "fragments": [],
                "text": "Int'l J. Computer Vision, vol. 9,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "[40], [32], [22], [72], [45], [58], [57], [71]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aFeature-Based Human Face Detection,o"
            },
            "venue": {
                "fragments": [],
                "text": "Image Visual Computing,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 181
                            }
                        ],
                        "text": "It has also been claimed that methods for face recognition based on finding local image features and inferring identity by the geometric relations of these features are ineffective [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 96
                            }
                        ],
                        "text": "Correlation: The simplest recognition scheme is a nearestneighbor classifier in the image space [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 87
                            }
                        ],
                        "text": "For decades, geometric feature-based methods [21], [33], [35], [34], [27], [26], [59], [6], [69], [42] have used properties and relations (e."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aFace Recognition: Features vs. Templates,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 157
                            }
                        ],
                        "text": "We call this recognition scheme the Linear Subspace method [2]; it is a variant of the photometric alignment method proposed in [62] and is related to [24], [48]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 97
                            }
                        ],
                        "text": "shadowed, x lies in the 3D aillumination subspaceo L given by the span of the columns of B [23], [48], [62]; the subset L0 L having no shadows (i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aDimensionality of Illumination Manifolds in Appearance Matching,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Int'l Workshop Object Representations for Computer Vision,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 128
                            }
                        ],
                        "text": "We call this recognition scheme the Linear Subspace method [2]; it is a variant of the photometric alignment method proposed in [62] and is related to [24], [48]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 103
                            }
                        ],
                        "text": "shadowed, x lies in the 3D aillumination subspaceo L given by the span of the columns of B [23], [48], [62]; the subset L0 L having no shadows (i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aOn Photometric Issues to Feature-Based Object Recognition,o"
            },
            "venue": {
                "fragments": [],
                "text": "Int'l J. Computer Vision,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 184
                            }
                        ],
                        "text": "It is, in spirit, most closely related to the synthesis approaches suggested in [61], [56] and stands in stark contrast to the illumination insensitivity techniques argued for in [3], [8]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and D"
            },
            "venue": {
                "fragments": [],
                "text": "Jacobs, aIn Search of Illumination Invariants,o Proc. IEEE Conf. Computer Vision and Pattern Recognition, pp. 254-261"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 200
                            }
                        ],
                        "text": "A conservative threshold is then chosen to determine shadows, making it almost certain that no invalid data is included in the estimation process, at the small expense of throwing away a few valid measurements."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaLocating Human Faces in Photographs,\u00ba Int"
            },
            "venue": {
                "fragments": [],
                "text": "J. Computer Vision"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 220,
                                "start": 217
                            }
                        ],
                        "text": "In a recent approach, a 3D model of a face (shape and texture) is utilized to transform the input image into the same pose as the stored prototypical faces and then direct template matching is used to recognize faces [4], [5], [68], [67]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 55
                            }
                        ],
                        "text": "This method for handling pose variability differs from [4], [38], [30], [43] in that we warp synthetic frontal-pose images of each face using its estimated surface geometry."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aFace Recognition under Varying Pose,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE Conf. Computer Vision and Pattern Recognition,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 42
                            }
                        ],
                        "text": "[40], [32], [22], [72], [45], [58], [57], [71]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and D"
            },
            "venue": {
                "fragments": [],
                "text": "Kriegman, aMixture of Linear Subspaces for Face Detection,o Proc. IEEE Int'l Conf. Automatic Face and Gesture Recognition, pp. 196-201"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 36
                            }
                        ],
                        "text": "[40], [32], [22], [72], [45], [58], [57], [71]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aNeural Network-Based Face Detection,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 63
                            }
                        ],
                        "text": "for finding faces in images [13], [55], [60], [38], [9], [41], [44],"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aProbabilistic Visual Learning for Object Detection,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Int'l Conf. Computer Vision,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 175
                            }
                        ],
                        "text": "Eigenfaces: A technique commonly used in computer vision\u00d0particularly in face recognition\u00d0is principal components analysis (PCA), which is popularly known as Eigenfaces [23], [36], [47], [66]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "See, for example, [36], [66], [23], [51], [55], [47], [45], [25]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aLow-Dimensional Procedure for the Characterization of Human Faces,o"
            },
            "venue": {
                "fragments": [],
                "text": "J. Optical Soc. Am. A,"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 115
                            }
                        ],
                        "text": "Over the last few years, numerous algorithms have been proposed for face recognition, see surveys [59], [7], [17], [50]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aLooking at People: Sensing for Ubiquitous and Wearable Computing,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 52
                            }
                        ],
                        "text": ", B \u0088 BA; for any light source, x \u0088 Bs \u0088 \u0085BA\u0086\u0085A\u00ff1s\u0086 [28]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 138
                            }
                        ],
                        "text": "At the core of our approach for generating images with novel lighting and viewpoints is a variant of photometric stereo [64], [70], [29], [28], [73] which simultaneously estimates geometry and albedo across the scene."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aPhotometric Stereo under a Light-Source with Arbitrary Motion,o"
            },
            "venue": {
                "fragments": [],
                "text": "J. Optical Soc. Am. A,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 69
                            }
                        ],
                        "text": "For decades, geometric feature-based methods [21], [33], [35], [34], [27], [26], [59], [6], [69], [42] have used properties and relations (e."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and U"
            },
            "venue": {
                "fragments": [],
                "text": "Raudkivi, aIdentification of Human Face Profiles by Computer,o Pattern Recognition, vol. 10, pp. 301-312"
            },
            "year": 1978
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aShape and Albedo from Multiple Images Using Integrability,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE Conf. Computer Vision and Pattern Recognition,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 51
                            }
                        ],
                        "text": "For decades, geometric feature-based methods [21], [33], [35], [34], [27], [26], [59], [6], [69], [42] have used properties and relations (e."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aPicture Processing by Computer Complex and Recognition of Human Faces,o"
            },
            "venue": {
                "fragments": [],
                "text": "PhD thesis, Kyoto Univ.,"
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 48
                            }
                        ],
                        "text": "If there were no shadowing, X would have rank 3 [61] (assuming no image noise) and we could use SVD to factorize X into X \u0088 B S."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 80
                            }
                        ],
                        "text": "It is, in spirit, most closely related to the synthesis approaches suggested in [61], [56] and stands in stark contrast to the illumination insensitivity techniques argued for in [3], [8]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aGeometry and Photometry in 3D Visual Recognition,o"
            },
            "venue": {
                "fragments": [],
                "text": "PhD thesis, Massachusetts Inst. of Technology,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 167
                            }
                        ],
                        "text": "A variation of [63] (see, also, [31], [65]) which finds a basis for the 3D linear subspace L from image data with missing elements is used together with the method in [16] which enforces integrability in shape from shading."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 202
                            }
                        ],
                        "text": "To enforce integrability, the possibly nonintegrable vector field induced by the current estimate of B is, in each iteration, projected down to the space of integrable vector fields, or gradient fields [16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 59
                            }
                        ],
                        "text": "(For more details on how to perform this minimization, see [16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aA Method for Enforcing Integrabilty in Shape from Shading Algorithms,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 225,
                                "start": 222
                            }
                        ],
                        "text": "In a recent approach, a 3D model of a face (shape and texture) is utilized to transform the input image into the same pose as the stored prototypical faces and then direct template matching is used to recognize faces [4], [5], [68], [67]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aFace Recognition from One Example View,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Int'l Conf. Computer Vision,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 19
                            }
                        ],
                        "text": "Any invalid data (both shadows and saturations) are treated as missing measurements by the following estimation method:\n1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaMixture of Linear Subspaces for Face Detection"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE Int'l Conf. Automatic Face and Gesture Recognition"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 147
                            }
                        ],
                        "text": "A conservative threshold is then chosen to determine shadows, making it almost certain that no invalid data is included in the estimation process, at the small expense of throwing away a few valid measurements."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaFinding Face Features,\u00ba Proc. Int'l Conf. Computer Vision"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaFinding Face Features,\u00ba Proc. Int'l Conf. Computer Vision"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 133
                            }
                        ],
                        "text": "Note that when no part of the surface is shadowed, x lies in the 3-D \u201cillumination subspace\u201d L given by the span of the columns of B [23, 48, 62]; the subset L0 L having no shadows (i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 128
                            }
                        ],
                        "text": "We call this recognition scheme the Linear Subspace method [2]; it is a variant of the photometric alignment method proposed in [62] and is related to [24, 48]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On photometric issues to feature-based object recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Computer Vision, 21:99\u2013122,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 195,
                                "start": 191
                            }
                        ],
                        "text": "In another approach, an Active Appearance Model of a generic face is deformed to fit to the input image and the control parameters are used as a feature vector for classification [10], [39], [14], [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and C"
            },
            "venue": {
                "fragments": [],
                "text": "Taylor, aAdvances in Active Appearance Models,o Proc. Int'l Conf. Computer Vision, pp. 137- 142"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 144
                            }
                        ],
                        "text": "At the core of our approach for generating images with novel lighting and viewpoints is a variant of photometric stereo [64], [70], [29], [28], [73] which simultaneously estimates geometry and albedo across the scene."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aRecovering Photometric Properties of Architectural Scenes from Photographs,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Computer Graphics (SIGGRAPH),"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 52
                            }
                        ],
                        "text": "for finding faces in images [13], [55], [60], [38], [9], [41], [44],"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and M"
            },
            "venue": {
                "fragments": [],
                "text": "Yachida, aFace Detection by Fuzzy Pattern Matching,o Proc. Int'l Conf. Computer Vision, pp. 591-596"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Two-and Three-Dimensional Patterns of the Face. A.K.Peters"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 135
                            }
                        ],
                        "text": "In a similar approach, a simple, generic 3D model of a face is used to estimate the pose and light source direction in the input image [75]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Chellapa, aSFS Based View Synthesis for Robust Face Recognition,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE Int'l Conf. Automatic Face and Gesture Recognition,"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 92
                            }
                        ],
                        "text": "For decades, geometric feature-based methods [21], [33], [35], [34], [27], [26], [59], [6], [69], [42] have used properties and relations (e."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aFace Recognition by Elastic Bunch Graph Matching,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 144
                            }
                        ],
                        "text": "Suppose, now, we have the possibly non-integrable estimate B from which we can easily\ndeduce from Equation 1 the possibly non-integrable partial derivatives z x (x; y) and z y (x; y)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaSubspace Linear Discriminant Analysis for Face Recognition,\u00ba Center for Automation Research CAR-TR-914"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaSubspace Linear Discriminant Analysis for Face Recognition,\u00ba Center for Automation Research CAR-TR-914"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 213
                            }
                        ],
                        "text": "These partial derivatives can also be expressed as a series, giving\nz x (x; y; c 1 (w)) =\nX c\n1 (w) x(x; y;w) (11)\nand\nz y (x; y; c 2 (w)) =\nX c\n2 (w) y(x; y;w): (12)\nNote that in general c 1 (w) 6= c 2 (w), which implies that z xy (x; y) 6= z yx (x; y)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Active Appearance Models,\u00ba Proc. Int'l Conf. Computer Vision"
            },
            "venue": {
                "fragments": [],
                "text": "Active Appearance Models,\u00ba Proc. Int'l Conf. Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms: Face Recognition, Image-Based Rendering, Appearance-Based Vision, Face Modeling, Illumination and Pose Modeling, Lighting, Illumination Cones, Generative Models."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaAutomatic Recognition and Analysis of Human Faces and Facial Expressions: A Survey,\u00ba Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaAutomatic Recognition and Analysis of Human Faces and Facial Expressions: A Survey,\u00ba Pattern Recognition"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 66
                            }
                        ],
                        "text": "This method for handling pose variability differs from [4], [38], [30], [43] in that we warp synthetic frontal-pose images of each face using its estimated surface geometry."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and T"
            },
            "venue": {
                "fragments": [],
                "text": "Chen, aPose Invariant Face Recognition,o Proc. IEEE Int'l Conf. Automatic Face and Gesture Recognition, pp. 245-250"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 237,
                                "start": 233
                            }
                        ],
                        "text": "In a recent approach, a 3D model of a face (shape and texture) is utilized to transform the input image into the same pose as the stored prototypical faces and then direct template matching is used to recognize faces [4], [5], [68], [67]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aSynthesis of Novel Views from a Single Face Image,o"
            },
            "venue": {
                "fragments": [],
                "text": "Int'l J. Computer Vision,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Yuille, \u00aa5+/-2 Eigenimages Suffice: An Empirical Investigation of Low-Dimensional Lighting Models"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Physics-Based Modeling Workshop in Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms: Face Recognition, Image-Based Rendering, Appearance-Based Vision, Face Modeling, Illumination and Pose Modeling, Lighting, Illumination Cones, Generative Models."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face recognition using nearest feature line"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. on Neural Networks"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 57
                            }
                        ],
                        "text": "For decades, geometric feature-based methods [21], [33], [35], [34], [27], [26], [59], [6], [69], [42] have used properties and relations (e."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Breeding, aThe Automatic Recognition of Human Faces from Profile Silhouettes,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Systems, Man, and Cybernetics,"
            },
            "year": 1976
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaSex Classification is Better with Three-Dimensional Head Structure than with Texture,\u00ba Perception"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaSex Classification is Better with Three-Dimensional Head Structure than with Texture,\u00ba Perception"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms: Face Recognition, Image-Based Rendering, Appearance-Based Vision, Face Modeling, Illumination and Pose Modeling, Lighting, Illumination Cones, Generative Models."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaMachine Identification of Human Faces,\u00ba Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaMachine Identification of Human Faces,\u00ba Pattern Recognition"
            },
            "year": 1981
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 72
                            }
                        ],
                        "text": "This method for handling pose variability differs from [4], [38], [30], [43] in that we warp synthetic frontal-pose images of each face using its estimated surface geometry."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and H"
            },
            "venue": {
                "fragments": [],
                "text": "Liddell, aSupport Vector Regression and Classification Based Multi-View Face Detection and Recognition,o Proc. IEEE Int'l Conf. Automatic Face and Gesture Recognition, pp. 300-305"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 45
                            }
                        ],
                        "text": "For decades, geometric feature-based methods [21, 33, 35, 34, 27, 26, 59, 6, 69, 42] have used properties and relations (e."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 139
                            }
                        ],
                        "text": "Here, we only present short descriptions: Correlation: The simplest recognition scheme is a nearest neighbor classifier in the image space [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 181
                            }
                        ],
                        "text": "It has also been claimed that methods for face recognition based on finding local image features and inferring identity by the geometric relations of these features are ineffective [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face recognition: Features vs templates"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intelligence, 15(10):1042\u20131053,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Mixture of linear subspaces for face detection"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Int. Conf. on Automatic Face and Gesture Recognition"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 231,
                                "start": 227
                            }
                        ],
                        "text": "In a recent approach, a 3D model of a face (shape and texture) is utilized to transform the input image into the same pose as the stored prototypical faces and then direct template matching is used to recognize faces [4], [5], [68], [67]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aLinear Object Classes and Image Synthesis from a Single Example Image,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 201
                            }
                        ],
                        "text": "These partial derivatives can also be expressed as a series, giving\nz x (x; y; c 1 (w)) =\nX c\n1 (w) x(x; y;w) (11)\nand\nz y (x; y; c 2 (w)) =\nX c\n2 (w) y(x; y;w): (12)\nNote that in general c 1 (w) 6= c 2 (w), which implies that z xy (x; y) 6= z yx (x; y)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaActive Appearance Models,\u00ba Proc. European Conf. Computer Vision"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaActive Appearance Models,\u00ba Proc. European Conf. Computer Vision"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms: Face Recognition, Image-Based Rendering, Appearance-Based Vision, Face Modeling, Illumination and Pose Modeling, Lighting, Illumination Cones, Generative Models."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaPicture Processing by Computer Complex and Recognition of Human Faces"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaPicture Processing by Computer Complex and Recognition of Human Faces"
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 210,
                                "start": 206
                            }
                        ],
                        "text": "A conservative threshold is then chosen to determine shadows, making it almost certain that no invalid data is included in the estimation process, at the small expense of throwing away a few valid measurements."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaFeature-Based Human Face Detection,\u00ba Image Visual Computing"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaFeature-Based Human Face Detection,\u00ba Image Visual Computing"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 34
                            }
                        ],
                        "text": "for finding faces in images [13], [55], [60], [38], [9], [41], [44],"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 42
                            }
                        ],
                        "text": "See, for example, [36], [66], [23], [51], [55], [47], [45], [25]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aExample-Based Learning for View-Based Human Face Detection,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Image Understanding Workshop,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 111
                            }
                        ],
                        "text": "In the first set, tests were performed under variable illumination but fixed pose, and the goal was, first, to compare the illumination cones representation with three other popular methods, and second, to test the accuracy of the subspace approximation of illumination cones."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Images of Curved Surfaces,\u00ba Artificial Intelligence"
            },
            "venue": {
                "fragments": [],
                "text": "Images of Curved Surfaces,\u00ba Artificial Intelligence"
            },
            "year": 1981
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms: Face Recognition, Image-Based Rendering, Appearance-Based Vision, Face Modeling, Illumination and Pose Modeling, Lighting, Illumination Cones, Generative Models."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaFace Recognition Using Nearest Feature Line"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 98
                            }
                        ],
                        "text": "Over the last few years, numerous algorithms have been proposed for face recognition, see surveys [59], [7], [17], [50]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 81
                            }
                        ],
                        "text": "For decades, geometric feature-based methods [21], [33], [35], [34], [27], [26], [59], [6], [69], [42] have used properties and relations (e."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aAutomatic Recognition and Analysis of Human Faces and Facial Expressions: A Survey,o"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognition,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 202
                            }
                        ],
                        "text": "\u2026stated in Equation 6 can then be reformulated into:\nmin b j ;si X ij wijjxij < b j ; si > j 2 (7)\nwhere xij is the j-th pixel of the i-th image, b j is the j-th row of matrix B 2 IRn 3, si is the light source direction and strength in the i-th image, and\nwij =\n1 xij valid measurement, 0 otherwise."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaPose Invariant Face Recognition,\u00ba Proc. IEEE Int'l Conf. Automatic Face and Gesture Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaPose Invariant Face Recognition,\u00ba Proc. IEEE Int'l Conf. Automatic Face and Gesture Recognition"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Picture processing by computer complex and recogniton of human faces"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 185
                            }
                        ],
                        "text": "In another approach, an Active Appearance Model of a generic face is deformed to fit to the input image and the control parameters are used as a feature vector for classification [10], [39], [14], [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aAutomatic Interpretation and Coding of Face Images Using Flexible Models,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms: Face Recognition, Image-Based Rendering, Appearance-Based Vision, Face Modeling, Illumination and Pose Modeling, Lighting, Illumination Cones, Generative Models."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Raudkivi, \u00aaIdentification of Human Face Profiles by Computer,\u00ba Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Raudkivi, \u00aaIdentification of Human Face Profiles by Computer,\u00ba Pattern Recognition"
            },
            "year": 1978
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 94
                            }
                        ],
                        "text": ", all points lie near a low-dimensional linear subspace), and this was confirmed for faces in [15, 1, 19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 30
                            }
                        ],
                        "text": "It was empirically determined [15, 1, 19] that 11 dimensions capture over 99% of the variance in the sample extreme rays (images)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "5+/-2 eigenimages suffice: An empirical investigation of low-dimensional lighting models"
            },
            "venue": {
                "fragments": [],
                "text": "Physics Based Modeling Workshop in Computer Vision, Session 4,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 36
                            }
                        ],
                        "text": "See, for example, [36], [66], [23], [51], [55], [47], [45], [25]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and T"
            },
            "venue": {
                "fragments": [],
                "text": "Starner, aView-Based and Modular Eigenspaces for Face Recognition,o Proc. IEEE Conf. Computer Vision and Pattern Recognition, pp. 84-91"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 32
                            }
                        ],
                        "text": "A variation of [63] (see, also, [31], [65]) which finds a basis for the 3D linear subspace L from image data with missing elements is used together with the method in [16] which enforces integrability in shape from shading."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aLinear Fitting with Missing Data: Applications to Structure from Motion and Characterizing Intensity Images,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE Conf. Computer Vision and Pattern Recognition,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Sex classification is better with three-dimensional head structure than with texture"
            },
            "venue": {
                "fragments": [],
                "text": "Perception"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 179
                            }
                        ],
                        "text": "In another approach, an Active Appearance Model of a generic face is deformed to fit to the input image and the control parameters are used as a feature vector for classification [10], [39], [14], [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and C"
            },
            "venue": {
                "fragments": [],
                "text": "Taylor, aActive Appearance Models,o Proc. European Conf. Computer Vision, vol. 2, pp. 484- 498"
            },
            "year": 1998
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 69,
            "methodology": 59,
            "result": 4
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 165,
        "totalPages": 17
    },
    "page_url": "https://www.semanticscholar.org/paper/From-Few-to-Many:-Illumination-Cone-Models-for-Face-Georghiades-Belhumeur/6642e9c6cf7432e2d11b7edf7cd47f1285acd54e?sort=total-citations"
}