{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48615144"
                        ],
                        "name": "Yan Xu",
                        "slug": "Yan-Xu",
                        "structuredName": {
                            "firstName": "Yan",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yan Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38956216"
                        ],
                        "name": "Lili Mou",
                        "slug": "Lili-Mou",
                        "structuredName": {
                            "firstName": "Lili",
                            "lastName": "Mou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lili Mou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1410115257"
                        ],
                        "name": "Ge Li",
                        "slug": "Ge-Li",
                        "structuredName": {
                            "firstName": "Ge",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ge Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691213"
                        ],
                        "name": "Yunchuan Chen",
                        "slug": "Yunchuan-Chen",
                        "structuredName": {
                            "firstName": "Yunchuan",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yunchuan Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1818378366"
                        ],
                        "name": "Hao Peng",
                        "slug": "Hao-Peng",
                        "structuredName": {
                            "firstName": "Hao",
                            "lastName": "Peng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hao Peng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700880"
                        ],
                        "name": "Zhi Jin",
                        "slug": "Zhi-Jin",
                        "structuredName": {
                            "firstName": "Zhi",
                            "lastName": "Jin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhi Jin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5403702,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "032fbcb58e2282f02426a0f09c6d5b42787936ec",
            "isKey": false,
            "numCitedBy": 509,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Relation classification is an important research arena in the field of natural language processing (NLP). In this paper, we present SDP-LSTM, a novel neural network to classify the relation of two entities in a sentence. Our neural architecture leverages the shortest dependency path (SDP) between two entities; multichannel recurrent neural networks, with long short term memory (LSTM) units, pick up heterogeneous information along the SDP. Our proposed model has several distinct features: (1) The shortest dependency paths retain most relevant information (to relation classification), while eliminating irrelevant words in the sentence. (2) The multichannel LSTM networks allow effective information integration from heterogeneous sources over the dependency paths. (3) A customized dropout strategy regularizes the neural network to alleviate overfitting. We test our model on the SemEval 2010 relation classification task, and achieve an $F_1$-score of 83.7\\%, higher than competing methods in the literature."
            },
            "slug": "Classifying-Relations-via-Long-Short-Term-Memory-Xu-Mou",
            "title": {
                "fragments": [],
                "text": "Classifying Relations via Long Short Term Memory Networks along Shortest Dependency Paths"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "This paper presents SDP-LSTM, a novel neural network to classify the relation of two entities in a sentence, which leverages the shortest dependency path (SDP) between two entities; multichannel recurrent neural networks, with long short term memory (L STM) units, pick up heterogeneous information along the SDP."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3109481"
                        ],
                        "name": "Zhiheng Huang",
                        "slug": "Zhiheng-Huang",
                        "structuredName": {
                            "firstName": "Zhiheng",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhiheng Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145738410"
                        ],
                        "name": "W. Xu",
                        "slug": "W.-Xu",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2150332252"
                        ],
                        "name": "Kai Yu",
                        "slug": "Kai-Yu",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Yu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 10
                            }
                        ],
                        "text": "Recently, Huang et al. (2015) showed that\nbuilding a conditional random field (CRF) layer on top of bidirectional LSTM-RNNs performs comparably to the state-of-the-art methods in the partof-speech (POS) tagging, chunking, and NER."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12740621,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "af88ce6116c2cd2927a4198745e99e5465173783",
            "isKey": false,
            "numCitedBy": 2424,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a variety of Long Short-Term Memory (LSTM) based models for sequence tagging. These models include LSTM networks, bidirectional LSTM (BI-LSTM) networks, LSTM with a Conditional Random Field (CRF) layer (LSTM-CRF) and bidirectional LSTM with a CRF layer (BI-LSTM-CRF). Our work is the first to apply a bidirectional LSTM CRF (denoted as BI-LSTM-CRF) model to NLP benchmark sequence tagging data sets. We show that the BI-LSTM-CRF model can efficiently use both past and future input features thanks to a bidirectional LSTM component. It can also use sentence level tag information thanks to a CRF layer. The BI-LSTM-CRF model can produce state of the art (or close to) accuracy on POS, chunking and NER data sets. In addition, it is robust and has less dependence on word embedding as compared to previous observations."
            },
            "slug": "Bidirectional-LSTM-CRF-Models-for-Sequence-Tagging-Huang-Xu",
            "title": {
                "fragments": [],
                "text": "Bidirectional LSTM-CRF Models for Sequence Tagging"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work is the first to apply a bidirectional LSTM CRF model to NLP benchmark sequence tagging data sets and it is shown that the BI-LSTM-CRF model can efficiently use both past and future input features thanks to a biddirectional L STM component."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790831"
                        ],
                        "name": "C. D. Santos",
                        "slug": "C.-D.-Santos",
                        "structuredName": {
                            "firstName": "C\u00edcero",
                            "lastName": "Santos",
                            "middleNames": [
                                "Nogueira",
                                "dos"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. D. Santos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144028698"
                        ],
                        "name": "Bing Xiang",
                        "slug": "Bing-Xiang",
                        "structuredName": {
                            "firstName": "Bing",
                            "lastName": "Xiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bing Xiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145218984"
                        ],
                        "name": "Bowen Zhou",
                        "slug": "Bowen-Zhou",
                        "structuredName": {
                            "firstName": "Bowen",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bowen Zhou"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15620570,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c8434b04acfe1d300b56c0d369092038ec899a2b",
            "isKey": false,
            "numCitedBy": 475,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Relation classification is an important semantic processing task for which state-ofthe-art systems still rely on costly handcrafted features. In this work we tackle the relation classification task using a convolutional neural network that performs classification by ranking (CR-CNN). We propose a new pairwise ranking loss function that makes it easy to reduce the impact of artificial classes. We perform experiments using the the SemEval-2010 Task 8 dataset, which is designed for the task of classifying the relationship between two nominals marked in a sentence. Using CRCNN, we outperform the state-of-the-art for this dataset and achieve a F1 of 84.1 without using any costly handcrafted features. Additionally, our experimental results show that: (1) our approach is more effective than CNN followed by a softmax classifier; (2) omitting the representation of the artificial class Other improves both precision and recall; and (3) using only word embeddings as input features is enough to achieve state-of-the-art results if we consider only the text between the two target nominals."
            },
            "slug": "Classifying-Relations-by-Ranking-with-Convolutional-Santos-Xiang",
            "title": {
                "fragments": [],
                "text": "Classifying Relations by Ranking with Convolutional Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work proposes a new pairwise ranking loss function that makes it easy to reduce the impact of artificial classes and shows that it is more effective than CNN followed by a softmax classifier and using only word embeddings as input features is enough to achieve state-of-the-art results."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118912383"
                        ],
                        "name": "Qi Li",
                        "slug": "Qi-Li",
                        "structuredName": {
                            "firstName": "Qi",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qi Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016781"
                        ],
                        "name": "Heng Ji",
                        "slug": "Heng-Ji",
                        "structuredName": {
                            "firstName": "Heng",
                            "lastName": "Ji",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Heng Ji"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 20744,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b156bdce947783b8c7071f02557b414ab7b5276",
            "isKey": false,
            "numCitedBy": 336,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an incremental joint framework to simultaneously extract entity mentions and relations using structured perceptron with efficient beam-search. A segment-based decoder based on the idea of semi-Markov chain is adopted to the new framework as opposed to traditional token-based tagging. In addition, by virtue of the inexact search, we developed a number of new and effective global features as soft constraints to capture the interdependency among entity mentions and relations. Experiments on Automatic Content Extraction (ACE) 1 corpora demonstrate that our joint model significantly outperforms a strong pipelined baseline, which attains better performance than the best-reported end-to-end system."
            },
            "slug": "Incremental-Joint-Extraction-of-Entity-Mentions-and-Li-Ji",
            "title": {
                "fragments": [],
                "text": "Incremental Joint Extraction of Entity Mentions and Relations"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "An incremental joint framework to simultaneously extract entity mentions and relations using structured perceptron with efficient beam-search is presented, which significantly outperforms a strong pipelined baseline, which attains better performance than the best-reported end-to-end system."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8421815"
                        ],
                        "name": "Kai Sheng Tai",
                        "slug": "Kai-Sheng-Tai",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Tai",
                            "middleNames": [
                                "Sheng"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Sheng Tai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 147
                            }
                        ],
                        "text": "Among these, RNNs can directly represent essential linguistic structures, i.e., word sequences (Hammerton, 2001) and constituent/dependency trees (Tai et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 39
                            }
                        ],
                        "text": "Research on tree-structured LSTM-RNNs (Tai et al., 2015) fixes the direction of information propagation from bottom to top, and also cannot handle an arbitrary number of typed children as in a typed dependency tree."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 147
                            }
                        ],
                        "text": "\u2026the top of the tree to such near-leaf nodes (unlike in standard bottom-up LSTM-RNNs).2 Note that the two variants of tree-structured LSTM-RNNs by Tai et al. (2015) are not able to represent our target structures which have a variable number of typed children: the Child-Sum Tree-LSTM does not\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We then compare our tree-structured LSTM-RNN (SPTree) with the Child-Sum treestructured LSTM-RNN on the shortest path of Tai et al. (2015). Child-Sum performs worse than our SPTree model, but not with as big of a decrease as above."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "2 Note that the two variants of tree-structured LSTM-RNNs by Tai et al. (2015) are not able to represent our target structures which have a variable number of typed children: the Child-Sum Tree-LSTM does not deal with types and the N -ary Tree assumes a fixed number of children."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 121
                            }
                        ],
                        "text": "We then compare our tree-structured LSTM-RNN (SPTree) with the Child-Sum treestructured LSTM-RNN on the shortest path of Tai et al. (2015)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": ", word sequences (Hammerton, 2001) and constituent/dependency trees (Tai et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3033526,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "32de44f01a96d4473d21099d15e25bc2b9f08e2f",
            "isKey": true,
            "numCitedBy": 2501,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Because of their superior ability to preserve sequence information over time, Long Short-Term Memory (LSTM) networks, a type of recurrent neural network with a more complex computational unit, have obtained strong results on a variety of sequence modeling tasks. The only underlying LSTM structure that has been explored so far is a linear chain. However, natural language exhibits syntactic properties that would naturally combine words to phrases. We introduce the Tree-LSTM, a generalization of LSTMs to tree-structured network topologies. Tree-LSTMs outperform all existing systems and strong LSTM baselines on two tasks: predicting the semantic relatedness of two sentences (SemEval 2014, Task 1) and sentiment classification (Stanford Sentiment Treebank)."
            },
            "slug": "Improved-Semantic-Representations-From-Long-Memory-Tai-Socher",
            "title": {
                "fragments": [],
                "text": "Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The Tree-LSTM is introduced, a generalization of LSTMs to tree-structured network topologies that outperform all existing systems and strong LSTM baselines on two tasks: predicting the semantic relatedness of two sentences and sentiment classification."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "151485141"
                        ],
                        "name": "Kun Xu",
                        "slug": "Kun-Xu",
                        "structuredName": {
                            "firstName": "Kun",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kun Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717629"
                        ],
                        "name": "Yansong Feng",
                        "slug": "Yansong-Feng",
                        "structuredName": {
                            "firstName": "Yansong",
                            "lastName": "Feng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yansong Feng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2410938"
                        ],
                        "name": "Songfang Huang",
                        "slug": "Songfang-Huang",
                        "structuredName": {
                            "firstName": "Songfang",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Songfang Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144060462"
                        ],
                        "name": "Dongyan Zhao",
                        "slug": "Dongyan-Zhao",
                        "structuredName": {
                            "firstName": "Dongyan",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dongyan Zhao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12203896,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "84af5095e7269d6ed70de78e2c0027ff6aab4d42",
            "isKey": false,
            "numCitedBy": 248,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Syntactic features play an essential role in identifying relationship in a sentence. Previous neural network models directly work on raw word sequences or constituent parse trees, thus often suffer from irrelevant information introduced when subjects and objects are in a long distance. In this paper, we propose to learn more robust relation representations from shortest dependency paths through a convolution neural network. We further take the relation directionality into account and propose a straightforward negative sampling strategy to improve the assignment of subjects and objects. Experimental results show that our method outperforms the state-of-theart approaches on the SemEval-2010 Task 8 dataset."
            },
            "slug": "Semantic-Relation-Classification-via-Convolutional-Xu-Feng",
            "title": {
                "fragments": [],
                "text": "Semantic Relation Classification via Convolutional Neural Networks with Simple Negative Sampling"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper proposes to learn more robust relation representations from shortest dependency paths through a convolution neural network, takes the relation directionality into account and proposes a straightforward negative sampling strategy to improve the assignment of subjects and objects."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50188017"
                        ],
                        "name": "Xiaofeng Yu",
                        "slug": "Xiaofeng-Yu",
                        "structuredName": {
                            "firstName": "Xiaofeng",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaofeng Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144594306"
                        ],
                        "name": "Wai Lam",
                        "slug": "Wai-Lam",
                        "structuredName": {
                            "firstName": "Wai",
                            "lastName": "Lam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wai Lam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6814450,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4cf12a88248b35a742ee1605b395a9f4f69370ef",
            "isKey": false,
            "numCitedBy": 78,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we investigate the problem of entity identification and relation extraction from encyclopedia articles, and we propose a joint discriminative probabilistic model with arbitrary graphical structure to optimize all relevant subtasks simultaneously. This modeling offers a natural formalism for exploiting rich dependencies and interactions between relevant subtasks to capture mutual benefits, as well as a great flexibility to incorporate a large collection of arbitrary, overlapping and non-independent features. We show the parameter estimation algorithm of this model. Moreover, we propose a new inference method, namely collective iterative classification (CIC), to find the most likely assignments for both entities and relations. We evaluate our model on real-world data from Wikipedia for this task, and compare with current state-of-the-art pipeline and joint models, demonstrating the effectiveness and feasibility of our approach."
            },
            "slug": "Jointly-Identifying-Entities-and-Extracting-in-Text-Yu-Lam",
            "title": {
                "fragments": [],
                "text": "Jointly Identifying Entities and Extracting Relations in Encyclopedia Text via A Graphical Model Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "A joint discriminative probabilistic model with arbitrary graphical structure to optimize all relevant subtasks simultaneously and a new inference method, namely collective iterative classification (CIC), to find the most likely assignments for both entities and relations are proposed."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49298465"
                        ],
                        "name": "Jiwei Li",
                        "slug": "Jiwei-Li",
                        "structuredName": {
                            "firstName": "Jiwei",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiwei Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1821711"
                        ],
                        "name": "Thang Luong",
                        "slug": "Thang-Luong",
                        "structuredName": {
                            "firstName": "Thang",
                            "lastName": "Luong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thang Luong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144547315"
                        ],
                        "name": "E. Hovy",
                        "slug": "E.-Hovy",
                        "structuredName": {
                            "firstName": "Eduard",
                            "lastName": "Hovy",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hovy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 97
                            }
                        ],
                        "text": "We follow the settings by (Li and Ji, 2014), and we did not use the full mention boundary unlike Lu and Roth (2015)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9283982,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df77714269f1f88182092f8535b1bc290fcd835d",
            "isKey": false,
            "numCitedBy": 211,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "Recursive neural models, which use syntactic parse trees to recursively generate representations bottom-up, are a popular architecture. However there have not been rigorous evaluations showing for exactly which tasks this syntax-based method is appropriate. In this paper, we benchmark recursive neural models against sequential recurrent neural models, enforcing applesto-apples comparison as much as possible. We investigate 4 tasks: (1) sentiment classification at the sentence level and phrase level; (2) matching questions to answerphrases; (3) discourse parsing; (4) semantic relation extraction. Our goal is to understand better when, and why, recursive models can outperform simpler models. We find that recursive models help mainly on tasks (like semantic relation extraction) that require longdistance connection modeling, particularly on very long sequences. We then introduce a method for allowing recurrent models to achieve similar performance: breaking long sentences into clause-like units at punctuation and processing them separately before combining. Our results thus help understand the limitations of both classes of models, and suggest directions for improving recurrent models."
            },
            "slug": "When-Are-Tree-Structures-Necessary-for-Deep-of-Li-Luong",
            "title": {
                "fragments": [],
                "text": "When Are Tree Structures Necessary for Deep Learning of Representations?"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper benchmarks recursive neural models against sequential recurrent neural models, enforcing applesto-apples comparison as much as possible, and introduces a method for allowing recurrent models to achieve similar performance: breaking long sentences into clause-like units at punctuation and processing them separately before combining."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143740945"
                        ],
                        "name": "Guodong Zhou",
                        "slug": "Guodong-Zhou",
                        "structuredName": {
                            "firstName": "Guodong",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guodong Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144538026"
                        ],
                        "name": "J. Su",
                        "slug": "J.-Su",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Su",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Su"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2159189624"
                        ],
                        "name": "Jie Zhang",
                        "slug": "Jie-Zhang",
                        "structuredName": {
                            "firstName": "Jie",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jie Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2156053331"
                        ],
                        "name": "Min Zhang",
                        "slug": "Min-Zhang",
                        "structuredName": {
                            "firstName": "Min",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Min Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 1105\u20131116, Berlin, Germany, August 7-12, 2016. c\u00a92016 Association for Computational Linguistics"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3160937,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "68cd1c7c0651b116a83abab8a7a46a29975d3b5f",
            "isKey": false,
            "numCitedBy": 710,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Extracting semantic relationships between entities is challenging. This paper investigates the incorporation of diverse lexical, syntactic and semantic knowledge in feature-based relation extraction using SVM. Our study illustrates that the base phrase chunking information is very effective for relation extraction and contributes to most of the performance improvement from syntactic aspect while additional information from full parsing gives limited further enhancement. This suggests that most of useful information in full parse trees for relation extraction is shallow and can be captured by chunking. We also demonstrate how semantic information such as WordNet and Name List, can be used in feature-based relation extraction to further improve the performance. Evaluation on the ACE corpus shows that effective incorporation of diverse features enables our system outperform previously best-reported systems on the 24 ACE relation subtypes and significantly outperforms tree kernel-based systems by over 20 in F-measure on the 5 ACE relation types."
            },
            "slug": "Exploring-Various-Knowledge-in-Relation-Extraction-Zhou-Su",
            "title": {
                "fragments": [],
                "text": "Exploring Various Knowledge in Relation Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "This paper investigates the incorporation of diverse lexical, syntactic and semantic knowledge in feature-based relation extraction using SVM and illustrates that the base phrase chunking information is very effective for relation extraction and contributes to most of the performance improvement from syntactic aspect while additional information from full parsing gives limited further enhancement."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143844110"
                        ],
                        "name": "Wei Lu",
                        "slug": "Wei-Lu",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Lu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5818711,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "908030653ab2d2010aaea94ea61130ddfe22a499",
            "isKey": false,
            "numCitedBy": 111,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel model for the task of joint mention extraction and classification. Unlike existing approaches, our model is able to effectively capture overlapping mentions with unbounded lengths. The model is highly scalable, with a time complexity that is linear in the number of words in the input sentence and linear in the number of possible mention classes. Our model can be extended to additionally capture mention heads explicitly in a joint manner under the same time complexity. We demonstrate the effectiveness of our model through extensive experiments on standard datasets."
            },
            "slug": "Joint-Mention-Extraction-and-Classification-with-Lu-Roth",
            "title": {
                "fragments": [],
                "text": "Joint Mention Extraction and Classification with Mention Hypergraphs"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A novel model is presented for the task of joint mention extraction and classification that is able to effectively capture overlapping mentions with unbounded lengths and can be extended to additionally capture mention heads explicitly in a joint manner under the same time complexity."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108641"
                        ],
                        "name": "Rohit J. Kate",
                        "slug": "Rohit-J.-Kate",
                        "structuredName": {
                            "firstName": "Rohit",
                            "lastName": "Kate",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rohit J. Kate"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 215746894,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e565c1ffccad46edc9d0b2e94cca994fa046bb9e",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Both entity and relation extraction can benefit from being performed jointly, allowing each task to correct the errors of the other. We present a new method for joint entity and relation extraction using a graph we call a \"card-pyramid.\" This graph compactly encodes all possible entities and relations in a sentence, reducing the task of their joint extraction to jointly labeling its nodes. We give an efficient labeling algorithm that is analogous to parsing using dynamic programming. Experimental results show improved results for our joint extraction method compared to a pipelined approach."
            },
            "slug": "Joint-Entity-and-Relation-Extraction-Using-Parsing-Kate-Mooney",
            "title": {
                "fragments": [],
                "text": "Joint Entity and Relation Extraction Using Card-Pyramid Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A new method for joint entity and relation extraction using a graph the authors call a \"card-pyramid\" that compactly encodes all possible entities and relations in a sentence, reducing the task of their joint extraction to jointly labeling its nodes."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20851195"
                        ],
                        "name": "Kazuma Hashimoto",
                        "slug": "Kazuma-Hashimoto",
                        "structuredName": {
                            "firstName": "Kazuma",
                            "lastName": "Hashimoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kazuma Hashimoto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1918552"
                        ],
                        "name": "Pontus Stenetorp",
                        "slug": "Pontus-Stenetorp",
                        "structuredName": {
                            "firstName": "Pontus",
                            "lastName": "Stenetorp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pontus Stenetorp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731657"
                        ],
                        "name": "Makoto Miwa",
                        "slug": "Makoto-Miwa",
                        "structuredName": {
                            "firstName": "Makoto",
                            "lastName": "Miwa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Makoto Miwa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143946906"
                        ],
                        "name": "Yoshimasa Tsuruoka",
                        "slug": "Yoshimasa-Tsuruoka",
                        "structuredName": {
                            "firstName": "Yoshimasa",
                            "lastName": "Tsuruoka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshimasa Tsuruoka"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10109787,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "78f0281c5c5a067c6a86c73335822c86b8107745",
            "isKey": false,
            "numCitedBy": 46,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel learning method for word embeddings designed for relation classification. Our word embeddings are trained by predicting words between noun pairs using lexical relation-specific features on a large unlabeled corpus. This allows us to explicitly incorporate relation-specific information into the word embeddings. The learned word embeddings are then used to construct feature vectors for a relation classification model. On a well-established semantic relation classification task, our method significantly outperforms a baseline based on a previously introduced word embedding method, and compares favorably to previous state-of-the-art models that use syntactic information or manually constructed external resources."
            },
            "slug": "Task-Oriented-Learning-of-Word-Embeddings-for-Hashimoto-Stenetorp",
            "title": {
                "fragments": [],
                "text": "Task-Oriented Learning of Word Embeddings for Semantic Relation Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "This work presents a novel learning method for word embeddings designed for relation classification that significantly outperforms a baseline based on a previously introduced word embedding method, and compares favorably to previous state-of-the-art models that use syntactic information or manually constructed external resources."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731657"
                        ],
                        "name": "Makoto Miwa",
                        "slug": "Makoto-Miwa",
                        "structuredName": {
                            "firstName": "Makoto",
                            "lastName": "Miwa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Makoto Miwa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115075487"
                        ],
                        "name": "Yutaka Sasaki",
                        "slug": "Yutaka-Sasaki",
                        "structuredName": {
                            "firstName": "Yutaka",
                            "lastName": "Sasaki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yutaka Sasaki"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 42
                            }
                        ],
                        "text": "Such models include structured prediction (Li and Ji, 2014; Miwa and Sasaki, 2014), integer linear programming (Roth and Yih, 2007; Yang and Cardie, 2013), card-pyramid parsing (Kate and Mooney, 2010), and global probabilistic graphical models (Yu and Lam, 2010; Singh et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 123
                            }
                        ],
                        "text": ", 2005), but recent studies show that end-to-end (joint) modeling of entity and relation is important for high performance (Li and Ji, 2014; Miwa and Sasaki, 2014) since relations interact closely with entity information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 955518,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1845a57621ba2ce9ff3c2d1dcaa1f7f4b04b2186",
            "isKey": false,
            "numCitedBy": 200,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a history-based structured learning approach that jointly extracts entities and relations in a sentence. We introduce a novel simple and flexible table representation of entities and relations. We investigate several feature settings, search orders, and learning methods with inexact search on the table. The experimental results demonstrate that a joint learning approach significantly outperforms a pipeline approach by incorporating global features and by selecting appropriate learning methods and search orders."
            },
            "slug": "Modeling-Joint-Entity-and-Relation-Extraction-with-Miwa-Sasaki",
            "title": {
                "fragments": [],
                "text": "Modeling Joint Entity and Relation Extraction with Table Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The experimental results demonstrate that a joint learning approach significantly outperforms a pipeline approach by incorporating global features and by selecting appropriate learning methods and search orders."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753223"
                        ],
                        "name": "A. Graves",
                        "slug": "A.-Graves",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Graves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Graves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40360972"
                        ],
                        "name": "Abdel-rahman Mohamed",
                        "slug": "Abdel-rahman-Mohamed",
                        "structuredName": {
                            "firstName": "Abdel-rahman",
                            "lastName": "Mohamed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abdel-rahman Mohamed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 75
                            }
                        ],
                        "text": "We represent the word sequence in a sentence with bidirectional LSTM-RNNs (Graves et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206741496,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4177ec52d1b80ed57f2e72b0f9a42365f1a8598d",
            "isKey": false,
            "numCitedBy": 6900,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Recurrent neural networks (RNNs) are a powerful model for sequential data. End-to-end training methods such as Connectionist Temporal Classification make it possible to train RNNs for sequence labelling problems where the input-output alignment is unknown. The combination of these methods with the Long Short-term Memory RNN architecture has proved particularly fruitful, delivering state-of-the-art results in cursive handwriting recognition. However RNN performance in speech recognition has so far been disappointing, with better results returned by deep feedforward networks. This paper investigates deep recurrent neural networks, which combine the multiple levels of representation that have proved so effective in deep networks with the flexible use of long range context that empowers RNNs. When trained end-to-end with suitable regularisation, we find that deep Long Short-term Memory RNNs achieve a test set error of 17.7% on the TIMIT phoneme recognition benchmark, which to our knowledge is the best recorded score."
            },
            "slug": "Speech-recognition-with-deep-recurrent-neural-Graves-Mohamed",
            "title": {
                "fragments": [],
                "text": "Speech recognition with deep recurrent neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper investigates deep recurrent neural networks, which combine the multiple levels of representation that have proved so effective in deep networks with the flexible use of long range context that empowers RNNs."
            },
            "venue": {
                "fragments": [],
                "text": "2013 IEEE International Conference on Acoustics, Speech and Signal Processing"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2896063"
                        ],
                        "name": "Romain Paulus",
                        "slug": "Romain-Paulus",
                        "structuredName": {
                            "firstName": "Romain",
                            "lastName": "Paulus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Romain Paulus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6269392,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "964153213e608b65ebd49684fa9dcbfe1c720fb4",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Recursive Neural Networks have recently obtained state of the art performance on several natural language processing tasks. However, because of their feedforward architecture they cannot correctly predict phrase or word labels that are determined by context. This is a problem in tasks such as aspect-specific sentiment classification which tries to, for instance, predict that the word Android is positive in the sentence Android beats iOS. We introduce global belief recursive neural networks (GB-RNNs) which are based on the idea of extending purely feedforward neural networks to include one feedbackward step during inference. This allows phrase level predictions and representations to give feedback to words. We show the effectiveness of this model on the task of contextual sentiment analysis. We also show that dropout can improve RNN training and that a combination of unsupervised and supervised word vector representations performs better than either alone. The feedbackward step improves F1 performance by 3% over the standard RNN on this task, obtains state-of-the-art performance on the SemEval 2013 challenge and can accurately predict the sentiment of specific entities."
            },
            "slug": "Global-Belief-Recursive-Neural-Networks-Paulus-Socher",
            "title": {
                "fragments": [],
                "text": "Global Belief Recursive Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Global belief recursive neural networks (GB-RNNs) are introduced which are based on the idea of extending purely feedforward neural networks to include one feedbackward step during inference, which allows phrase level predictions and representations to give feedback to words."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751569"
                        ],
                        "name": "Samy Bengio",
                        "slug": "Samy-Bengio",
                        "structuredName": {
                            "firstName": "Samy",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samy Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689108"
                        ],
                        "name": "Oriol Vinyals",
                        "slug": "Oriol-Vinyals",
                        "structuredName": {
                            "firstName": "Oriol",
                            "lastName": "Vinyals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oriol Vinyals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3111912"
                        ],
                        "name": "Navdeep Jaitly",
                        "slug": "Navdeep-Jaitly",
                        "structuredName": {
                            "firstName": "Navdeep",
                            "lastName": "Jaitly",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Navdeep Jaitly"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1846258"
                        ],
                        "name": "Noam M. Shazeer",
                        "slug": "Noam-M.-Shazeer",
                        "structuredName": {
                            "firstName": "Noam",
                            "lastName": "Shazeer",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Noam M. Shazeer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1820089,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df137487e20ba7c6e1e2b9a1e749f2a578b5ad99",
            "isKey": false,
            "numCitedBy": 1414,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Recurrent Neural Networks can be trained to produce sequences of tokens given some input, as exemplified by recent results in machine translation and image captioning. The current approach to training them consists of maximizing the likelihood of each token in the sequence given the current (recurrent) state and the previous token. At inference, the unknown previous token is then replaced by a token generated by the model itself. This discrepancy between training and inference can yield errors that can accumulate quickly along the generated sequence. We propose a curriculum learning strategy to gently change the training process from a fully guided scheme using the true previous token, towards a less guided scheme which mostly uses the generated token instead. Experiments on several sequence prediction tasks show that this approach yields significant improvements. Moreover, it was used succesfully in our winning entry to the MSCOCO image captioning challenge, 2015."
            },
            "slug": "Scheduled-Sampling-for-Sequence-Prediction-with-Bengio-Vinyals",
            "title": {
                "fragments": [],
                "text": "Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work proposes a curriculum learning strategy to gently change the training process from a fully guided scheme using the true previous token, towards a less guided scheme which mostly uses the generated token instead."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145365229"
                        ],
                        "name": "J. Hammerton",
                        "slug": "J.-Hammerton",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Hammerton",
                            "middleNames": [
                                "Alistair"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hammerton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 106
                            }
                        ],
                        "text": "Traditional systems treat this task as a pipeline of two separated tasks, i.e., named entity recognition (NER) (Nadeau and Sekine, 2007; Ratinov and Roth, 2009) and relation extraction (Zelenko et al., 2003; Zhou et al., 2005), but recent studies show that end-to-end\n(joint) modeling of entity and relation is important for high performance (Li and Ji, 2014; Miwa and Sasaki, 2014) since relations interact closely with entity information."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 226
                            }
                        ],
                        "text": "Recently, Huang et al. (2015) showed that\nbuilding a conditional random field (CRF) layer on top of bidirectional LSTM-RNNs performs comparably to the state-of-the-art methods in the partof-speech (POS) tagging, chunking, and NER."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 164
                            }
                        ],
                        "text": "LSTM-RNNs have been widely used for sequential labeling, such as clause identification (Hammerton, 2001), phonetic labeling (Graves and Schmidhuber, 2005), and NER (Hammerton, 2003)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1160080,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c95b747921f7afc88dec3721995c3624c6937c86",
            "isKey": false,
            "numCitedBy": 165,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "In this approach to named entity recognition, a recurrent neural network, known as Long Short-Term Memory, is applied. The network is trained to perform 2 passes on each sentence, outputting its decisions on the second pass. The first pass is used to acquire information for disambiguation during the second pass. SARDNET, a self-organising map for sequences is used to generate representations for the lexical items presented to the LSTM network, whilst orthogonal representations are used to represent the part of speech and chunk tags."
            },
            "slug": "Named-Entity-Recognition-with-Long-Short-Term-Hammerton",
            "title": {
                "fragments": [],
                "text": "Named Entity Recognition with Long Short-Term Memory"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "In this approach to named entity recognition, a recurrent neural network, known as Long Short-Term Memory, is applied, which is trained to perform 2 passes on each sentence, outputting its decisions on the second pass."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34650964"
                        ],
                        "name": "Sameer Singh",
                        "slug": "Sameer-Singh",
                        "structuredName": {
                            "firstName": "Sameer",
                            "lastName": "Singh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sameer Singh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48662861"
                        ],
                        "name": "Sebastian Riedel",
                        "slug": "Sebastian-Riedel",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Riedel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sebastian Riedel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114362162"
                        ],
                        "name": "Brian Martin",
                        "slug": "Brian-Martin",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Martin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brian Martin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2252856"
                        ],
                        "name": "Jiaping Zheng",
                        "slug": "Jiaping-Zheng",
                        "structuredName": {
                            "firstName": "Jiaping",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiaping Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13965810,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "193ad334f669737f421b58198f787470d506e698",
            "isKey": false,
            "numCitedBy": 98,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Although joint inference is an effective approach to avoid cascading of errors when inferring multiple natural language tasks, its application to information extraction has been limited to modeling only two tasks at a time, leading to modest improvements. In this paper, we focus on the three crucial tasks of automated extraction pipelines: entity tagging, relation extraction, and coreference. We propose a single, joint graphical model that represents the various dependencies between the tasks, allowing flow of uncertainty across task boundaries. Since the resulting model has a high tree-width and contains a large number of variables, we present a novel extension to belief propagation that sparsifies the domains of variables during inference. Experimental results show that our joint model consistently improves results on all three tasks as we represent more dependencies. In particular, our joint model obtains 12% error reduction on tagging over the isolated models."
            },
            "slug": "Joint-inference-of-entities,-relations,-and-Singh-Riedel",
            "title": {
                "fragments": [],
                "text": "Joint inference of entities, relations, and coreference"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A single, joint graphical model is proposed that represents the various dependencies between the tasks, allowing flow of uncertainty across task boundaries, and presents a novel extension to belief propagation that sparsifies the domains of variables during inference."
            },
            "venue": {
                "fragments": [],
                "text": "AKBC '13"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3139133"
                        ],
                        "name": "Razvan C. Bunescu",
                        "slug": "Razvan-C.-Bunescu",
                        "structuredName": {
                            "firstName": "Razvan",
                            "lastName": "Bunescu",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Razvan C. Bunescu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 126
                            }
                        ],
                        "text": "(2015b) showed that the shortest dependency paths between relation arguments, which were used in feature/kernel-based systems (Bunescu and Mooney, 2005), are also useful in NN-based models."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 88
                            }
                        ],
                        "text": "For relation classification, in addition to traditional feature/kernel-based approaches (Zelenko et al., 2003; Bunescu and Mooney, 2005), several neural models have been proposed in the SemEval-2010 Task 8 (Hendrickx et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5165854,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8a8832216fa59867aab8bb98270763fc2de3d8d8",
            "isKey": false,
            "numCitedBy": 949,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel approach to relation extraction, based on the observation that the information required to assert a relationship between two named entities in the same sentence is typically captured by the shortest path between the two entities in the dependency graph. Experiments on extracting top-level relations from the ACE (Automated Content Extraction) newspaper corpus show that the new shortest path dependency kernel outperforms a recent approach based on dependency tree kernels."
            },
            "slug": "A-Shortest-Path-Dependency-Kernel-for-Relation-Bunescu-Mooney",
            "title": {
                "fragments": [],
                "text": "A Shortest Path Dependency Kernel for Relation Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Experiments on extracting top-level relations from the ACE (Automated Content Extraction) newspaper corpus show that the new shortest path dependency kernel outperforms a recent approach based on dependency tree kernels."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2570381"
                        ],
                        "name": "Brody Huval",
                        "slug": "Brody-Huval",
                        "structuredName": {
                            "firstName": "Brody",
                            "lastName": "Huval",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brody Huval"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 806709,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "27e38351e48fe4b7da2775bf94341738bc4da07e",
            "isKey": false,
            "numCitedBy": 1265,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Single-word vector space models have been very successful at learning lexical information. However, they cannot capture the compositional meaning of longer phrases, preventing them from a deeper understanding of language. We introduce a recursive neural network (RNN) model that learns compositional vector representations for phrases and sentences of arbitrary syntactic type and length. Our model assigns a vector and a matrix to every node in a parse tree: the vector captures the inherent meaning of the constituent, while the matrix captures how it changes the meaning of neighboring words or phrases. This matrix-vector RNN can learn the meaning of operators in propositional logic and natural language. The model obtains state of the art performance on three different experiments: predicting fine-grained sentiment distributions of adverb-adjective pairs; classifying sentiment labels of movie reviews and classifying semantic relationships such as cause-effect or topic-message between nouns using the syntactic path between them."
            },
            "slug": "Semantic-Compositionality-through-Recursive-Spaces-Socher-Huval",
            "title": {
                "fragments": [],
                "text": "Semantic Compositionality through Recursive Matrix-Vector Spaces"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A recursive neural network model that learns compositional vector representations for phrases and sentences of arbitrary syntactic type and length and can learn the meaning of operators in propositional logic and natural language is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753223"
                        ],
                        "name": "A. Graves",
                        "slug": "A.-Graves",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Graves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Graves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 124
                            }
                        ],
                        "text": "LSTM-RNNs have been widely used for sequential labeling, such as clause identification (Hammerton, 2001), phonetic labeling (Graves and Schmidhuber, 2005), and NER (Hammerton, 2003)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1856462,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2f83f6e1afadf0963153974968af6b8342775d82",
            "isKey": false,
            "numCitedBy": 3296,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Framewise-phoneme-classification-with-bidirectional-Graves-Schmidhuber",
            "title": {
                "fragments": [],
                "text": "Framewise phoneme classification with bidirectional LSTM and other neural network architectures"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2563432"
                        ],
                        "name": "Wojciech Zaremba",
                        "slug": "Wojciech-Zaremba",
                        "structuredName": {
                            "firstName": "Wojciech",
                            "lastName": "Zaremba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wojciech Zaremba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The embedding layer handles embedding representations. nw, np, nd and ne-dimensional vectors v(w), v(p), v(d) and v(e) are embedded to words, part-of-speech (POS) tags, dependency types, and entity labels, respectively."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12730022,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0d0b3ff23fbf1ec7a0dfebd923a3ef224306491a",
            "isKey": false,
            "numCitedBy": 460,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Recurrent Neural Networks (RNNs) with Long Short-Term Memory units (LSTM) are widely used because they are expressive and are easy to train. Our interest lies in empirically evaluating the expressiveness and the learnability of LSTMs in the sequence-to-sequence regime by training them to evaluate short computer programs, a domain that has traditionally been seen as too complex for neural networks. We consider a simple class of programs that can be evaluated with a single left-to-right pass using constant memory. Our main result is that LSTMs can learn to map the character-level representations of such programs to their correct outputs. Notably, it was necessary to use curriculum learning, and while conventional curriculum learning proved ineffective, we developed a new variant of curriculum learning that improved our networks' performance in all experimental conditions. The improved curriculum had a dramatic impact on an addition problem, making it possible to train an LSTM to add two 9-digit numbers with 99% accuracy."
            },
            "slug": "Learning-to-Execute-Zaremba-Sutskever",
            "title": {
                "fragments": [],
                "text": "Learning to Execute"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "This work developed a new variant of curriculum learning that improved the networks' performance in all experimental conditions and had a dramatic impact on an addition problem, making an LSTM to add two 9-digit numbers with 99% accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7324641"
                        ],
                        "name": "Bishan Yang",
                        "slug": "Bishan-Yang",
                        "structuredName": {
                            "firstName": "Bishan",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bishan Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748501"
                        ],
                        "name": "Claire Cardie",
                        "slug": "Claire-Cardie",
                        "structuredName": {
                            "firstName": "Claire",
                            "lastName": "Cardie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Claire Cardie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 84
                            }
                        ],
                        "text": "Word sequence and tree structure are known to be complementary information for extracting relations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1594813,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eafaa68119f6877ecea56524a4c7958fceeae957",
            "isKey": false,
            "numCitedBy": 202,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the task of finegrained opinion extraction \u2010 the identification of opinion-related entities: the opinion expressions, the opinion holders, and the targets of the opinions, and the relations between opinion expressions and their targets and holders. Most existing approaches tackle the extraction of opinion entities and opinion relations in a pipelined manner, where the interdependencies among different extraction stages are not captured. We propose a joint inference model that leverages knowledge from predictors that optimize subtasks of opinion extraction, and seeks a globally optimal solution. Experimental results demonstrate that our joint inference approach significantly outperforms traditional pipeline methods and baselines that tackle subtasks in isolation for the problem of opinion extraction."
            },
            "slug": "Joint-Inference-for-Fine-grained-Opinion-Extraction-Yang-Cardie",
            "title": {
                "fragments": [],
                "text": "Joint Inference for Fine-grained Opinion Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Experimental results demonstrate that the joint inference approach significantly outperforms traditional pipeline methods and baselines that tackle subtasks in isolation for the problem of opinion extraction."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Such models include structured prediction (Li and Ji, 2014; Miwa and Sasaki, 2014), integer linear programming (Roth and Yih, 2007; Yang and Cardie, 2013), card-pyramid parsing (Kate and Mooney, 2010), and global probabilistic graphical models (Yu and Lam, 2010; Singh et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7653242,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ef753516b8c045150fc8a275740986f054b3293d",
            "isKey": false,
            "numCitedBy": 128,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Natural language decisions often involve assigning values to sets of variables, representing low level decisions and context dependent disambiguation. In most cases there are complex relationships among these variables representing dependencies that range from simple statistical correlations to those that are constrained by deeper structural, relational and semantic properties of the text. In this work we study a specific instantiation of this problem in the context of identifying named entities and relations between them in free form text. Given a collection of discrete random variables representing outcomes of learned local predictors for entities and relations, we seek an optimal global assignment to the variables that respects multiple constraints, including constraints on the type of arguments a relation can take, and the mutual activity of different relations. We develop a linear programming formulation to address this global inference problem and evaluate it in the context of simultaneously learning named entities and relations. We show that global inference improves stand-alone learning; in addition, our approach allows us to efficiently incorporate expressive domain and task specific constraints at decision time, resulting, beyond significant improvements in the accuracy, in \u201ccoherent\u201d quality of the inference."
            },
            "slug": "1-Global-Inference-for-Entity-and-Relation-via-a-Roth",
            "title": {
                "fragments": [],
                "text": "1 Global Inference for Entity and Relation Identification via a Linear Programming Formulation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that global inference improves stand-alone learning and allows us to efficiently incorporate expressive domain and task specific constraints at decision time, resulting, beyond significant improvements in the accuracy, in \u201ccoherent\u201d quality of the inference."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2862682"
                        ],
                        "name": "G. Doddington",
                        "slug": "G.-Doddington",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Doddington",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Doddington"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2449760"
                        ],
                        "name": "A. Mitchell",
                        "slug": "A.-Mitchell",
                        "structuredName": {
                            "firstName": "Alexis",
                            "lastName": "Mitchell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Mitchell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2282719"
                        ],
                        "name": "Mark A. Przybocki",
                        "slug": "Mark-A.-Przybocki",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Przybocki",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark A. Przybocki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744313"
                        ],
                        "name": "L. Ramshaw",
                        "slug": "L.-Ramshaw",
                        "structuredName": {
                            "firstName": "Lance",
                            "lastName": "Ramshaw",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Ramshaw"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754963"
                        ],
                        "name": "S. Strassel",
                        "slug": "S.-Strassel",
                        "structuredName": {
                            "firstName": "Stephanie",
                            "lastName": "Strassel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Strassel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732071"
                        ],
                        "name": "R. Weischedel",
                        "slug": "R.-Weischedel",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Weischedel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Weischedel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9776219,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0617dd6924df7a3491c299772b70e90507b195dc",
            "isKey": false,
            "numCitedBy": 933,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "The objective of the ACE program is to develop technology to automatically infer from human language data the entities being mentioned, the relations among these entities that are directly expressed, and the events in which these entities participate. Data sources include audio and image data in addition to pure text, and Arabic and Chinese in addition to English. The effort involves defining the research tasks in detail, collecting and annotating data needed for training, development, and evaluation, and supporting the research with evaluation tools and research workshops. This program began with a pilot study in 1999. The next evaluation is scheduled for September 2004. Introduction and Background Today\u2019s global web of electronic information, including most notably the www, provides a resource of unbounded information-bearing potential. But to fully exploit this potential requires the ability to extract content from human language automatically. That is the objective of the ACE program \u2013 to develop the capability to extract meaning from multimedia sources. These sources include text, audio and image data. The ACE program is a \u201ctechnocentric\u201d research effort, meaning that the emphasis is on developing core enabling technologies rather than solving the application needs that motivate the research. The program began in 1999 with a study intended to identify those key content extraction tasks to serve as the research targets for the remainder of the program. These tasks were identified in general as the extraction of the entities, relations and events being discussed in the language. In general objective, the ACE program is motivated by and addresses the same issues as the MUC program that preceded it (NIST 1999). The ACE program, however, attempts to take the task \u201coff the page\u201d in the sense that the research objectives are defined in terms of the target objects (i.e., the entities, the relations, and the events) rather than in terms of the words in the text. For example, the so-called \u201cnamed entity\u201d task, as defined in MUC, is to identify those words (on the page) that are names of entities. In ACE, on the other hand, the corresponding task is to identify the entity so named. This is a different task, one that is more abstract and that involves inference more explicitly in producing an answer. In a real sense, the task is to detect things that \u201caren\u2019t there\u201d. Reference resolution thus becomes an integral and critical part of solving the problem. During the period 2000-2001, the ACE effort was devoted solely to entity detection and tracking. During the period 2002-2003, relations were explored and added. 1 While the ACE program is directed toward extraction of information from audio and image sources in addition to pure text, the research effort is restricted to information extraction from text. The actual transduction of audio and image data into text is not part of the ACE research effort, although the processing of ASR and OCR output from such transducers is. Now, starting in 2004, events are being explored and added as the third of the three original tasks."
            },
            "slug": "The-Automatic-Content-Extraction-(ACE)-Program-and-Doddington-Mitchell",
            "title": {
                "fragments": [],
                "text": "The Automatic Content Extraction (ACE) Program - Tasks, Data, and Evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The objective of the ACE program is to develop technology to automatically infer from human language data the entities being mentioned, the relations among these entities that are directly expressed, and the events in which these entities participate."
            },
            "venue": {
                "fragments": [],
                "text": "LREC"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2335225"
                        ],
                        "name": "Lev-Arie Ratinov",
                        "slug": "Lev-Arie-Ratinov",
                        "structuredName": {
                            "firstName": "Lev-Arie",
                            "lastName": "Ratinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lev-Arie Ratinov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 118
                            }
                        ],
                        "text": "We assign an entity tag to each word using a commonly used encoding scheme BILOU (Begin, Inside, Last, Outside, Unit) (Ratinov and Roth, 2009), where each entity tag represents the entity type and the position of a word in the entity."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 33
                            }
                        ],
                        "text": ", named entity recognition (NER) (Nadeau and Sekine, 2007; Ratinov and Roth, 2009) and relation extraction (Zelenko et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 226
                            }
                        ],
                        "text": "Recently, Huang et al. (2015) showed that\nbuilding a conditional random field (CRF) layer on top of bidirectional LSTM-RNNs performs comparably to the state-of-the-art methods in the partof-speech (POS) tagging, chunking, and NER."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 106
                            }
                        ],
                        "text": "Traditional systems treat this task as a pipeline of two separated tasks, i.e., named entity recognition (NER) (Nadeau and Sekine, 2007; Ratinov and Roth, 2009) and relation extraction (Zelenko et al., 2003; Zhou et al., 2005), but recent studies show that end-to-end\n(joint) modeling of entity and relation is important for high performance (Li and Ji, 2014; Miwa and Sasaki, 2014) since relations interact closely with entity information."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 160
                            }
                        ],
                        "text": "LSTM-RNNs have been widely used for sequential labeling, such as clause identification (Hammerton, 2001), phonetic labeling (Graves and Schmidhuber, 2005), and NER (Hammerton, 2003)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1859014,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aa9efc8b2737eac0675ba5abb5feab8305482c12",
            "isKey": true,
            "numCitedBy": 1397,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We analyze some of the fundamental design challenges and misconceptions that underlie the development of an efficient and robust NER system. In particular, we address issues such as the representation of text chunks, the inference approach needed to combine local NER decisions, the sources of prior knowledge and how to use them within an NER system. In the process of comparing several solutions to these challenges we reach some surprising conclusions, as well as develop an NER system that achieves 90.8 F1 score on the CoNLL-2003 NER shared task, the best reported result for this dataset."
            },
            "slug": "Design-Challenges-and-Misconceptions-in-Named-Ratinov-Roth",
            "title": {
                "fragments": [],
                "text": "Design Challenges and Misconceptions in Named Entity Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "Some of the fundamental design challenges and misconceptions that underlie the development of an efficient and robust NER system are analyzed, and several solutions to these challenges are developed."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2988645"
                        ],
                        "name": "Yee Seng Chan",
                        "slug": "Yee-Seng-Chan",
                        "structuredName": {
                            "firstName": "Yee",
                            "lastName": "Chan",
                            "middleNames": [
                                "Seng"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yee Seng Chan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1491402,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5e46fc68ede1108529f4db78bc7e1def69d70ba3",
            "isKey": false,
            "numCitedBy": 143,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we observe that there exists a second dimension to the relation extraction (RE) problem that is orthogonal to the relation type dimension. We show that most of these second dimensional structures are relatively constrained and not difficult to identify. We propose a novel algorithmic approach to RE that starts by first identifying these structures and then, within these, identifying the semantic type of the relation. In the real RE problem where relation arguments need to be identified, exploiting these structures also allows reducing pipelined propagated errors. We show that this RE framework provides significant improvement in RE performance."
            },
            "slug": "Exploiting-Syntactico-Semantic-Structures-for-Chan-Roth",
            "title": {
                "fragments": [],
                "text": "Exploiting Syntactico-Semantic Structures for Relation Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A novel algorithmic approach to RE is proposed that starts by first identifying structures and then, within these, identifying the semantic type of the relation, which provides significant improvement in RE performance."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2754495"
                        ],
                        "name": "Massimiliano Ciaramita",
                        "slug": "Massimiliano-Ciaramita",
                        "structuredName": {
                            "firstName": "Massimiliano",
                            "lastName": "Ciaramita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Massimiliano Ciaramita"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783941"
                        ],
                        "name": "Y. Altun",
                        "slug": "Y.-Altun",
                        "structuredName": {
                            "firstName": "Yasemin",
                            "lastName": "Altun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Altun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 169
                            }
                        ],
                        "text": "All these LSTM-RNNs perform slightly worse than our SP-\n12When incorporating WordNet information into our model, we prepared embeddings for WordNet hypernyms extracted by SuperSenseTagger (Ciaramita and Altun, 2006) and concatenated the embeddings to the input vector (the concatenation of word and POS embeddings) of the sequence LSTM."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 151
                            }
                        ],
                        "text": "\u2026worse than our SP-\n12When incorporating WordNet information into our model, we prepared embeddings for WordNet hypernyms extracted by SuperSenseTagger (Ciaramita and Altun, 2006) and concatenated the embeddings to the input vector (the concatenation of word and POS embeddings) of the sequence LSTM."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14879921,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e83501ba08950912ab2c81d2a974898de2913b85",
            "isKey": false,
            "numCitedBy": 241,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we approach word sense disambiguation and information extraction as a unified tagging problem. The task consists of annotating text with the tagset defined by the 41 Wordnet supersense classes for nouns and verbs. Since the tagset is directly related to Wordnet synsets, the tagger returns partial word sense disambiguation. Furthermore, since the noun tags include the standard named entity detection classes -- person, location, organization, time, etc. -- the tagger, as a by-product, returns extended named entity information. We cast the problem of supersense tagging as a sequential labeling task and investigate it empirically with a discriminatively-trained Hidden Markov Model. Experimental evaluation on the main sense-annotated datasets available, i.e., Semcor and Senseval, shows considerable improvements over the best known \"first-sense\" baseline."
            },
            "slug": "Broad-Coverage-Sense-Disambiguation-and-Information-Ciaramita-Altun",
            "title": {
                "fragments": [],
                "text": "Broad-Coverage Sense Disambiguation and Information Extraction with a Supersense Sequence Tagger"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper casts the problem of supersense tagging as a sequential labeling task and investigate it empirically with a discriminatively-trained Hidden Markov Model."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50536468"
                        ],
                        "name": "Danqi Chen",
                        "slug": "Danqi-Chen",
                        "structuredName": {
                            "firstName": "Danqi",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Danqi Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11616343,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a14045a751f5d8ed387c8630a86a3a2861b90643",
            "isKey": false,
            "numCitedBy": 1640,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Almost all current dependency parsers classify based on millions of sparse indicator features. Not only do these features generalize poorly, but the cost of feature computation restricts parsing speed significantly. In this work, we propose a novel way of learning a neural network classifier for use in a greedy, transition-based dependency parser. Because this classifier learns and uses just a small number of dense features, it can work very fast, while achieving an about 2% improvement in unlabeled and labeled attachment scores on both English and Chinese datasets. Concretely, our parser is able to parse more than 1000 sentences per second at 92.2% unlabeled attachment score on the English Penn Treebank."
            },
            "slug": "A-Fast-and-Accurate-Dependency-Parser-using-Neural-Chen-Manning",
            "title": {
                "fragments": [],
                "text": "A Fast and Accurate Dependency Parser using Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work proposes a novel way of learning a neural network classifier for use in a greedy, transition-based dependency parser that can work very fast, while achieving an about 2% improvement in unlabeled and labeled attachment scores on both English and Chinese datasets."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40421028"
                        ],
                        "name": "David Nadeau",
                        "slug": "David-Nadeau",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Nadeau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Nadeau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714612"
                        ],
                        "name": "S. Sekine",
                        "slug": "S.-Sekine",
                        "structuredName": {
                            "firstName": "Satoshi",
                            "lastName": "Sekine",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sekine"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 106
                            }
                        ],
                        "text": "Traditional systems treat this task as a pipeline of two separated tasks, i.e., named entity recognition (NER) (Nadeau and Sekine, 2007; Ratinov and Roth, 2009) and relation extraction (Zelenko et al., 2003; Zhou et al., 2005), but recent studies show that end-to-end\n(joint) modeling of entity and relation is important for high performance (Li and Ji, 2014; Miwa and Sasaki, 2014) since relations interact closely with entity information."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 226
                            }
                        ],
                        "text": "Recently, Huang et al. (2015) showed that\nbuilding a conditional random field (CRF) layer on top of bidirectional LSTM-RNNs performs comparably to the state-of-the-art methods in the partof-speech (POS) tagging, chunking, and NER."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 160
                            }
                        ],
                        "text": "LSTM-RNNs have been widely used for sequential labeling, such as clause identification (Hammerton, 2001), phonetic labeling (Graves and Schmidhuber, 2005), and NER (Hammerton, 2003)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 33
                            }
                        ],
                        "text": ", named entity recognition (NER) (Nadeau and Sekine, 2007; Ratinov and Roth, 2009) and relation extraction (Zelenko et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8310135,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4a554da55fd9ff76c99e25d2ce937b225dc1100c",
            "isKey": true,
            "numCitedBy": 2307,
            "numCiting": 89,
            "paperAbstract": {
                "fragments": [],
                "text": "This survey covers fifteen years of research in the Named Entity Recognition and Classification (NERC) field, from 1991 to 2006. We report observations about languages, named entity types, domains and textual genres studied in the literature. From the start, NERC systems have been developed using hand-made rules, but now machine learning techniques are widely used. These techniques are surveyed along with other critical aspects of NERC such as features and evaluation methods. Features are word-level, dictionary-level and corpus-level representations of words in a document. Evaluation techniques, ranging from intuitive exact match to very complex matching techniques with adjustable cost of errors, are an indisputable key to progress."
            },
            "slug": "A-survey-of-named-entity-recognition-and-Nadeau-Sekine",
            "title": {
                "fragments": [],
                "text": "A survey of named entity recognition and classification"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Observations about languages, named entity types, domains and textual genres studied in the literature, along with other critical aspects of NERC such as features and evaluation methods, are reported."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2047446108"
                        ],
                        "name": "Tomas Mikolov",
                        "slug": "Tomas-Mikolov",
                        "structuredName": {
                            "firstName": "Tomas",
                            "lastName": "Mikolov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomas Mikolov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118440152"
                        ],
                        "name": "Kai Chen",
                        "slug": "Kai-Chen",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32131713"
                        ],
                        "name": "G. Corrado",
                        "slug": "G.-Corrado",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Corrado",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Corrado"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49959210"
                        ],
                        "name": "J. Dean",
                        "slug": "J.-Dean",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Dean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dean"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16447573,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "87f40e6f3022adbc1f1905e3e506abad05a9964f",
            "isKey": false,
            "numCitedBy": 26054,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. \n \nAn inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of \"Canada\" and \"Air\" cannot be easily combined to obtain \"Air Canada\". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible."
            },
            "slug": "Distributed-Representations-of-Words-and-Phrases-Mikolov-Sutskever",
            "title": {
                "fragments": [],
                "text": "Distributed Representations of Words and Phrases and their Compositionality"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper presents a simple method for finding phrases in text, and shows that learning good vector representations for millions of phrases is possible and describes a simple alternative to the hierarchical softmax called negative sampling."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708288"
                        ],
                        "name": "Iris Hendrickx",
                        "slug": "Iris-Hendrickx",
                        "structuredName": {
                            "firstName": "Iris",
                            "lastName": "Hendrickx",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Iris Hendrickx"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736741380"
                        ],
                        "name": "Su Nam Kim",
                        "slug": "Su-Nam-Kim",
                        "structuredName": {
                            "firstName": "Su Nam",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Su Nam Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714932"
                        ],
                        "name": "Zornitsa Kozareva",
                        "slug": "Zornitsa-Kozareva",
                        "structuredName": {
                            "firstName": "Zornitsa",
                            "lastName": "Kozareva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zornitsa Kozareva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683562"
                        ],
                        "name": "Preslav Nakov",
                        "slug": "Preslav-Nakov",
                        "structuredName": {
                            "firstName": "Preslav",
                            "lastName": "Nakov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Preslav Nakov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8311581"
                        ],
                        "name": "Diarmuid \u00d3 S\u00e9aghdha",
                        "slug": "Diarmuid-\u00d3-S\u00e9aghdha",
                        "structuredName": {
                            "firstName": "Diarmuid",
                            "lastName": "S\u00e9aghdha",
                            "middleNames": [
                                "\u00d3"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diarmuid \u00d3 S\u00e9aghdha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708581"
                        ],
                        "name": "Sebastian Pad\u00f3",
                        "slug": "Sebastian-Pad\u00f3",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Pad\u00f3",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sebastian Pad\u00f3"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145375801"
                        ],
                        "name": "M. Pennacchiotti",
                        "slug": "M.-Pennacchiotti",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Pennacchiotti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pennacchiotti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31790611"
                        ],
                        "name": "Lorenza Romano",
                        "slug": "Lorenza-Romano",
                        "structuredName": {
                            "firstName": "Lorenza",
                            "lastName": "Romano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lorenza Romano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1795595"
                        ],
                        "name": "S. Szpakowicz",
                        "slug": "S.-Szpakowicz",
                        "structuredName": {
                            "firstName": "Stan",
                            "lastName": "Szpakowicz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Szpakowicz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 436023,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "04221cd779dc8a9a2cc5d921a3449dbead8d7890",
            "isKey": false,
            "numCitedBy": 463,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "SemEval-2 Task 8 focuses on Multi-way classification of semantic relations between pairs of nominals. The task was designed to compare different approaches to semantic relation classification and to provide a standard testbed for future research. This paper defines the task, describes the training and test data and the process of their creation, lists the participating systems (10 teams, 28 runs), and discusses their results."
            },
            "slug": "SemEval-2010-Task-8:-Multi-Way-Classification-of-of-Hendrickx-Kim",
            "title": {
                "fragments": [],
                "text": "SemEval-2010 Task 8: Multi-Way Classification of Semantic Relations between Pairs of Nominals"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper defines the task, describes the training and test data and the process of their creation, lists the participating systems (10 teams, 28 runs), and discusses their results."
            },
            "venue": {
                "fragments": [],
                "text": "*SEMEVAL"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726807"
                        ],
                        "name": "Diederik P. Kingma",
                        "slug": "Diederik-P.-Kingma",
                        "structuredName": {
                            "firstName": "Diederik",
                            "lastName": "Kingma",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diederik P. Kingma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2503659"
                        ],
                        "name": "Jimmy Ba",
                        "slug": "Jimmy-Ba",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Ba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy Ba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 90
                            }
                        ],
                        "text": "We update the model parameters including weights, biases, and embeddings by BPTT and Adam (Kingma and Ba, 2015) with gradient clipping, parameter averaging, and L2-regularization (we regularize weights W and U , not the bias terms b)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6628106,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6cb366736791bcccc5c8639de5a8f9636bf87e8",
            "isKey": false,
            "numCitedBy": 90076,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm."
            },
            "slug": "Adam:-A-Method-for-Stochastic-Optimization-Kingma-Ba",
            "title": {
                "fragments": [],
                "text": "Adam: A Method for Stochastic Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This work introduces Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments, and provides a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2897313"
                        ],
                        "name": "Nitish Srivastava",
                        "slug": "Nitish-Srivastava",
                        "structuredName": {
                            "firstName": "Nitish",
                            "lastName": "Srivastava",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nitish Srivastava"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064160"
                        ],
                        "name": "A. Krizhevsky",
                        "slug": "A.-Krizhevsky",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Krizhevsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krizhevsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 22
                            }
                        ],
                        "text": "We also apply dropout (Srivastava et al., 2014) to the embedding layer and to the final hidden layers for entity detection and relation classification."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6844431,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "34f25a8704614163c4095b3ee2fc969b60de4698",
            "isKey": false,
            "numCitedBy": 28154,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different \"thinned\" networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets."
            },
            "slug": "Dropout:-a-simple-way-to-prevent-neural-networks-Srivastava-Hinton",
            "title": {
                "fragments": [],
                "text": "Dropout: a simple way to prevent neural networks from overfitting"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is shown that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3190501"
                        ],
                        "name": "D. Zelenko",
                        "slug": "D.-Zelenko",
                        "structuredName": {
                            "firstName": "Dmitry",
                            "lastName": "Zelenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Zelenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939759"
                        ],
                        "name": "Chinatsu Aone",
                        "slug": "Chinatsu-Aone",
                        "structuredName": {
                            "firstName": "Chinatsu",
                            "lastName": "Aone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chinatsu Aone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49754061"
                        ],
                        "name": "A. Richardella",
                        "slug": "A.-Richardella",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Richardella",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Richardella"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 88
                            }
                        ],
                        "text": "For relation classification, in addition to traditional feature/kernel-based approaches (Zelenko et al., 2003; Bunescu and Mooney, 2005), several neural models have been proposed in the SemEval2010 Task 8 (Hendrickx et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 107
                            }
                        ],
                        "text": ", named entity recognition (NER) (Nadeau and Sekine, 2007; Ratinov and Roth, 2009) and relation extraction (Zelenko et al., 2003; Zhou et al., 2005), but recent studies show that end-to-end (joint) modeling of entity and relation is important for high performance (Li and Ji, 2014; Miwa and Sasaki, 2014) since relations interact closely with entity information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11074539,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cc1cad12521b5aab43fdda5b4dec67586aef1f87",
            "isKey": false,
            "numCitedBy": 919,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an application of kernel methods to extracting relations from unstructured natural language sources. We introduce kernels defined over shallow parse representations of text, and design efficient algorithms for computing the kernels. We use the devised kernels in conjunction with Support Vector Machine and Voted Perceptron learning algorithms for the task of extracting person-affiliation and organization-location relations from text. We experimentally evaluate the proposed methods and compare them with feature-based learning algorithms, with promising results."
            },
            "slug": "Kernel-Methods-for-Relation-Extraction-Zelenko-Aone",
            "title": {
                "fragments": [],
                "text": "Kernel Methods for Relation Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This work introduces kernels defined over shallow parse representations of text, and design efficient algorithms for computing the kernels, and uses the devised kernels in conjunction with Support Vector Machine and Voted Perceptron learning algorithms for the task of extracting person-affiliation and organization-location relations from text."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2989149"
                        ],
                        "name": "Anastasia Pentina",
                        "slug": "Anastasia-Pentina",
                        "structuredName": {
                            "firstName": "Anastasia",
                            "lastName": "Pentina",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anastasia Pentina"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790503"
                        ],
                        "name": "V. Sharmanska",
                        "slug": "V.-Sharmanska",
                        "structuredName": {
                            "firstName": "Viktoriia",
                            "lastName": "Sharmanska",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Sharmanska"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1787591"
                        ],
                        "name": "Christoph H. Lampert",
                        "slug": "Christoph-H.-Lampert",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Lampert",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christoph H. Lampert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 104
                            }
                        ],
                        "text": "We follow the settings by (Li and Ji, 2014), and we did not use the full mention boundary unlike Lu and Roth (2015)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8502955,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "60184c071f782cc97d28f8a78b14405b3b3f1e28",
            "isKey": false,
            "numCitedBy": 167,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "Sharing information between multiple tasks enables algorithms to achieve good generalization performance even from small amounts of training data. However, in a realistic scenario of multi-task learning not all tasks are equally related to each other, hence it could be advantageous to transfer information only between the most related tasks. In this work we propose an approach that processes multiple tasks in a sequence with sharing between subsequent tasks instead of solving all tasks jointly. Subsequently, we address the question of curriculum learning of tasks, i.e. finding the best order of tasks to be learned. Our approach is based on a generalization bound criterion for choosing the task order that optimizes the average expected classification performance over all tasks. Our experimental results show that learning multiple related tasks sequentially can be more effective than learning them jointly, the order in which tasks are being solved affects the overall performance, and that our model is able to automatically discover a favourable order of tasks."
            },
            "slug": "Curriculum-learning-of-multiple-tasks-Pentina-Sharmanska",
            "title": {
                "fragments": [],
                "text": "Curriculum learning of multiple tasks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The experimental results show that learning multiple related tasks sequentially can be more effective than learning them jointly, the order in which tasks are being solved affects the overall performance, and that the model is able to automatically discover a favourable order of tasks."
            },
            "venue": {
                "fragments": [],
                "text": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47055692"
                        ],
                        "name": "P. Werbos",
                        "slug": "P.-Werbos",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Werbos",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Werbos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18470994,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "1a3d22599028a05669e884f3eaf19a342e190a87",
            "isKey": false,
            "numCitedBy": 4036,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Backpropagation is now the most widely used tool in the field of artificial neural networks. At the core of backpropagation is a method for calculating derivatives exactly and efficiently in any large system made up of elementary subsystems or calculations which are represented by known, differentiable functions; thus, backpropagation has many applications which do not involve neural networks as such. This paper first reviews basic backpropagation, a simple method which is now being widely used in areas like pattern recognition and fault diagnosis. Next, it presents the basic equations for backpropagation through time, and discusses applications to areas like pattern recognition involving dynamic systems, systems identification, and control. Finally, i t describes further extensions of this method, to deal with systems other than neural networks, systems involving simultaneous equations or true recurrent networks, and other practical issues which arise with this method. Pseudocode is provided to clarify the algorithms. The chain rule for ordered derivatives-the theorem which underlies backpropagation-is briefly discussed."
            },
            "slug": "Backpropagation-Through-Time:-What-It-Does-and-How-Werbos",
            "title": {
                "fragments": [],
                "text": "Backpropagation Through Time: What It Does and How to Do It"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper first reviews basic backpropagation, a simple method which is now being widely used in areas like pattern recognition and fault diagnosis, and describes further extensions of this method, to deal with systems other than neural networks, systems involving simultaneous equations or true recurrent networks, and other practical issues which arise with this method."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2373952"
                        ],
                        "name": "J. Louradour",
                        "slug": "J.-Louradour",
                        "structuredName": {
                            "firstName": "J\u00e9r\u00f4me",
                            "lastName": "Louradour",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Louradour"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939803"
                        ],
                        "name": "Ronan Collobert",
                        "slug": "Ronan-Collobert",
                        "structuredName": {
                            "firstName": "Ronan",
                            "lastName": "Collobert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronan Collobert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 48
                            }
                        ],
                        "text": "Our model also incorporates curriculum learning (Bengio et al., 2009) and scheduled sampling (Bengio et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 40
                            }
                        ],
                        "text": "We also incorporate curriculum learning (Bengio et al., 2009), where we pretrain the entity detection model using the training data to encourage building positive relation instances from the detected entities in training."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 873046,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "8de174ab5419b9d3127695405efd079808e956e8",
            "isKey": false,
            "numCitedBy": 3193,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Humans and animals learn much better when the examples are not randomly presented but organized in a meaningful order which illustrates gradually more concepts, and gradually more complex ones. Here, we formalize such training strategies in the context of machine learning, and call them \"curriculum learning\". In the context of recent research studying the difficulty of training in the presence of non-convex training criteria (for deep deterministic and stochastic neural networks), we explore curriculum learning in various set-ups. The experiments show that significant improvements in generalization can be achieved. We hypothesize that curriculum learning has both an effect on the speed of convergence of the training process to a minimum and, in the case of non-convex criteria, on the quality of the local minima obtained: curriculum learning can be seen as a particular form of continuation method (a general strategy for global optimization of non-convex functions)."
            },
            "slug": "Curriculum-learning-Bengio-Louradour",
            "title": {
                "fragments": [],
                "text": "Curriculum learning"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is hypothesized that curriculum learning has both an effect on the speed of convergence of the training process to a minimum and on the quality of the local minima obtained: curriculum learning can be seen as a particular form of continuation method (a general strategy for global optimization of non-convex functions)."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '09"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145365229"
                        ],
                        "name": "J. Hammerton",
                        "slug": "J.-Hammerton",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Hammerton",
                            "middleNames": [
                                "Alistair"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hammerton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 87
                            }
                        ],
                        "text": "LSTM-RNNs have been widely used for sequential labeling, such as clause identification (Hammerton, 2001), phonetic labeling (Graves and Schmidhuber, 2005), and NER (Hammerton, 2003)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 17
                            }
                        ],
                        "text": ", word sequences (Hammerton, 2001) and constituent/dependency trees (Tai et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1428985,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "0e43b8beff68845266755a650327bb48eea8995b",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "James Hammerton Department of Computer Science University College Dublin james.hammerton@ucd.ie"
            },
            "slug": "Clause-identification-with-long-short-term-memory-Hammerton",
            "title": {
                "fragments": [],
                "text": "Clause identification with long short-term memory"
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727849"
                        ],
                        "name": "S. Hanson",
                        "slug": "S.-Hanson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Hanson",
                            "middleNames": [
                                "Jose"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hanson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60565534,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "69d7086300e7f5322c06f2f242a565b3a182efb5",
            "isKey": false,
            "numCitedBy": 4651,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Bill Baird { Publications References 1] B. Baird. Bifurcation analysis of oscillating neural network model of pattern recognition in the rabbit olfactory bulb. In D. 3] B. Baird. Bifurcation analysis of a network model of the rabbit olfactory bulb with periodic attractors stored by a sequence learning algorithm. 5] B. Baird. Bifurcation theory methods for programming static or periodic attractors and their bifurcations in dynamic neural networks."
            },
            "slug": "In-Advances-in-Neural-Information-Processing-Hanson",
            "title": {
                "fragments": [],
                "text": "In Advances in Neural Information Processing Systems"
            },
            "venue": {
                "fragments": [],
                "text": "NIPS 1990"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143784545"
                        ],
                        "name": "Scott M. Smith",
                        "slug": "Scott-M.-Smith",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Smith",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Scott M. Smith"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 91
                            }
                        ],
                        "text": "Our statistical significance results are based on the Approximate Randomization (AR) test (Noreen, 1989)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 93
                            }
                        ],
                        "text": "15 Our statistical significance results are based on the Approximate Randomization (AR) test (Noreen, 1989)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 167772988,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "861fefddfaf6abedc285e2265f5b2bcd7a304c12",
            "isKey": false,
            "numCitedBy": 353,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Approximate Randomization Tests. Monte Carlo Sampling. Bootstrap Resampling. Conclusion. Appendices. References. Index."
            },
            "slug": "Book-Review:-Computer-Intensive-Methods-for-Testing-Smith",
            "title": {
                "fragments": [],
                "text": "Computer Intensive Methods for Testing Hypotheses: An Introduction"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144729741"
                        ],
                        "name": "K. J. Evans",
                        "slug": "K.-J.-Evans",
                        "structuredName": {
                            "firstName": "Katherine",
                            "lastName": "Evans",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. J. Evans"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 90
                            }
                        ],
                        "text": "Our statistical significance results are based on the Approximate Randomization (AR) test (Noreen, 1989)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62768333,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d8be229a32b27556efb32d0b9b352838dddafce6",
            "isKey": false,
            "numCitedBy": 319,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Computer-Intensive-Methods-for-Testing-Hypotheses:-Evans",
            "title": {
                "fragments": [],
                "text": "Computer Intensive Methods for Testing Hypotheses: An Introduction"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 131
                            }
                        ],
                        "text": "\u2026approaches (Zelenko et al., 2003; Bunescu and Mooney, 2005), several neural models have been proposed in the SemEval-2010 Task 8 (Hendrickx et al., 2010), including embedding-based models (Hashimoto et al., 2015), CNN-based models (dos Santos et al., 2015), and RNN-based models\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 295,
                                "start": 273
                            }
                        ],
                        "text": "\u20268 defines 9 relation types between nominals ( Cause-Effect, InstrumentAgency, Product-Producer, Content-Container, Entity-Origin, Entity-Destination, ComponentWhole, Member-Collection and Message-Topic), and a tenth type Other when two nouns have none of these relations (Hendrickx et al., 2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 130
                            }
                        ],
                        "text": "SemEval-2010 Task 8 defines 9 relation types between nominals and a tenth type Other when two nouns have none of these relations (Hendrickx et al., 2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 103
                            }
                        ],
                        "text": ", 2003; Bunescu and Mooney, 2005), several neural models have been proposed in the SemEval-2010 Task 8 (Hendrickx et al., 2010), including embedding-based models (Hashimoto et al."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Semeval2010 task 8: Multi-way classification"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746034"
                        ],
                        "name": "L. Getoor",
                        "slug": "L.-Getoor",
                        "structuredName": {
                            "firstName": "Lise",
                            "lastName": "Getoor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Getoor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685978"
                        ],
                        "name": "B. Taskar",
                        "slug": "B.-Taskar",
                        "structuredName": {
                            "firstName": "Ben",
                            "lastName": "Taskar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Taskar"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 111
                            }
                        ],
                        "text": "Such models include structured prediction (Li and Ji, 2014; Miwa and Sasaki, 2014), integer linear programming (Roth and Yih, 2007; Yang and Cardie, 2013), card-pyramid parsing (Kate and Mooney, 2010), and global probabilistic graphical models (Yu and Lam, 2010; Singh et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 112
                            }
                        ],
                        "text": "Such models include structured prediction (Li and Ji, 2014; Miwa and Sasaki, 2014), integer linear programming (Roth and Yih, 2007; Yang and Cardie, 2013), card-pyramid parsing (Kate and Mooney, 2010), and global probabilistic graphical models (Yu and Lam, 2010; Singh et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 125504208,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "e006283532a06aa99d44066a91c6c2cd3c54561d",
            "isKey": false,
            "numCitedBy": 124,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Global-Inference-for-Entity-and-Relation-via-Linear-Getoor-Taskar",
            "title": {
                "fragments": [],
                "text": "Global Inference for Entity and Relation Identification via Linear Programming Formulation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "73422065"
                        ],
                        "name": "I. Hendrickx",
                        "slug": "I.-Hendrickx",
                        "structuredName": {
                            "firstName": "Iris",
                            "lastName": "Hendrickx",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Hendrickx"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736741380"
                        ],
                        "name": "Su Nam Kim",
                        "slug": "Su-Nam-Kim",
                        "structuredName": {
                            "firstName": "Su Nam",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Su Nam Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714932"
                        ],
                        "name": "Zornitsa Kozareva",
                        "slug": "Zornitsa-Kozareva",
                        "structuredName": {
                            "firstName": "Zornitsa",
                            "lastName": "Kozareva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zornitsa Kozareva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683562"
                        ],
                        "name": "Preslav Nakov",
                        "slug": "Preslav-Nakov",
                        "structuredName": {
                            "firstName": "Preslav",
                            "lastName": "Nakov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Preslav Nakov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8311581"
                        ],
                        "name": "Diarmuid \u00d3 S\u00e9aghdha",
                        "slug": "Diarmuid-\u00d3-S\u00e9aghdha",
                        "structuredName": {
                            "firstName": "Diarmuid",
                            "lastName": "S\u00e9aghdha",
                            "middleNames": [
                                "\u00d3"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diarmuid \u00d3 S\u00e9aghdha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145375801"
                        ],
                        "name": "M. Pennacchiotti",
                        "slug": "M.-Pennacchiotti",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Pennacchiotti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pennacchiotti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31790611"
                        ],
                        "name": "Lorenza Romano",
                        "slug": "Lorenza-Romano",
                        "structuredName": {
                            "firstName": "Lorenza",
                            "lastName": "Romano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lorenza Romano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1795595"
                        ],
                        "name": "S. Szpakowicz",
                        "slug": "S.-Szpakowicz",
                        "structuredName": {
                            "firstName": "Stan",
                            "lastName": "Szpakowicz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Szpakowicz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 23
                            }
                        ],
                        "text": "For instance, to learn that Toefting and Bolton have an OrganizationAffiliation (ORG-AFF) relation in the sentence Toefting transferred to Bolton, the entity information that Toefting and Bolton are Person and Organization entities is important."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 52836516,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2768040d345e016c010312c7cd747c0959effb86",
            "isKey": false,
            "numCitedBy": 314,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a brief overview of the main challenges in the extraction of semantic relations from English text, and discuss the shortcomings of previous data sets and shared tasks. This leads us to introduce a new task, which will be part of SemEval-2010: multi-way classification of mutually exclusive semantic relations between pairs of common nominals. The task is designed to compare different approaches to the problem and to provide a standard testbed for future research, which can benefit many applications in Natural Language Processing."
            },
            "slug": "SemEval-2010-Task-8:-Multi-Way-Classification-of-of-Hendrickx-Kim",
            "title": {
                "fragments": [],
                "text": "SemEval-2010 Task 8: Multi-Way Classification of Semantic Relations Between Pairs of Nominals"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new task is introduced, which will be part of SemEval-2010: multi-way classification of mutually exclusive semantic relations between pairs of common nominals."
            },
            "venue": {
                "fragments": [],
                "text": "HLT-NAACL 2009"
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hyper-parameters include the initial learning rate"
            },
            "venue": {
                "fragments": [],
                "text": "Hyper-parameters include the initial learning rate"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 23
                            }
                        ],
                        "text": "We also apply dropout (Srivastava et al., 2014) to the embedding layer and to the final hidden layers for entity detection and relation classification."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Ilya Sutskever"
            },
            "venue": {
                "fragments": [],
                "text": "and Ruslan Salakhutdinov."
            },
            "year": 2014
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 42
                            }
                        ],
                        "text": "We initialized word vectors via word2vec (Mikolov et al., 2013) trained on Wikipedia8 and randomly initialized all other parameters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Greg S Corrado"
            },
            "venue": {
                "fragments": [],
                "text": "and Jeff Dean."
            },
            "year": 2013
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Chinatsu Aone"
            },
            "venue": {
                "fragments": [],
                "text": "and Anthony Richardella."
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "2e-3, 1e-3, 5e-4, 2e-4, 1e-4), the regularization parameter (1e-4, 1e-5, 1e-6, 1e-7), dropout probabilities (0.0, 0.1, 0.2, 0.3, 0.4, 0.5), the size of gradient clipping"
            },
            "venue": {
                "fragments": [],
                "text": "Hyper-parameters include the initial learning rate scheduled sampling parameter k (1, 5, 10, 50, 100), and the number of epochs for training and entity pretraining"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Clause identification with long short - term mem Named entity recognition with long short - term memory"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh Conference on Natural Language Learning at HLT - NAACL 2003"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and the embedding dimension of WordNet hypernym"
            },
            "venue": {
                "fragments": [],
                "text": "and the embedding dimension of WordNet hypernym"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and Christopher D"
            },
            "venue": {
                "fragments": [],
                "text": "Manning."
            },
            "year": 2015
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 131
                            }
                        ],
                        "text": "\u2026approaches (Zelenko et al., 2003; Bunescu and Mooney, 2005), several neural models have been proposed in the SemEval-2010 Task 8 (Hendrickx et al., 2010), including embedding-based models (Hashimoto et al., 2015), CNN-based models (dos Santos et al., 2015), and RNN-based models\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 295,
                                "start": 273
                            }
                        ],
                        "text": "\u20268 defines 9 relation types between nominals ( Cause-Effect, InstrumentAgency, Product-Producer, Content-Container, Entity-Origin, Entity-Destination, ComponentWhole, Member-Collection and Message-Topic), and a tenth type Other when two nouns have none of these relations (Hendrickx et al., 2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 130
                            }
                        ],
                        "text": "SemEval-2010 Task 8 defines 9 relation types between nominals and a tenth type Other when two nouns have none of these relations (Hendrickx et al., 2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Lorenza Romano"
            },
            "venue": {
                "fragments": [],
                "text": "and Stan Szpakowicz."
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dmitry Zelenko, Chinatsu Aone, and Anthony Richardella Kernel methods for relation extraction"
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of Machine Learning Research"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A.2 Hyper-parameter Settings Here we show the hyper-parameters and the range tried for the hyper-parameters in parentheses"
            },
            "venue": {
                "fragments": [],
                "text": "A.2 Hyper-parameter Settings Here we show the hyper-parameters and the range tried for the hyper-parameters in parentheses"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dan Jurafsky"
            },
            "venue": {
                "fragments": [],
                "text": "and Eduard Hovy."
            },
            "year": 2015
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning to execute. arXiv preprint arXiv:1410.4615"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2014
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bing Xiang"
            },
            "venue": {
                "fragments": [],
                "text": "and Bowen Zhou."
            },
            "year": 2015
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 84
                            }
                        ],
                        "text": "However, previous RNNbased models focus on only one of these linguistic structures (Socher et al., 2012)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 289,
                                "start": 270
                            }
                        ],
                        "text": "\u2026(Zelenko et al., 2003; Bunescu and Mooney, 2005), several neural models have been proposed in the SemEval-2010 Task 8 (Hendrickx et al., 2010), including embedding-based models (Hashimoto et al., 2015), CNN-based models (dos Santos et al., 2015), and RNN-based models (Socher et al., 2012)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and Andrew Y"
            },
            "venue": {
                "fragments": [],
                "text": "Ng."
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Wei Xu"
            },
            "venue": {
                "fragments": [],
                "text": "and Kai Yu."
            },
            "year": 2015
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 63
                            }
                        ],
                        "text": "ACE04 defines the same 7 coarse-grained entity types as ACE05 (Doddington et al., 2004), but defines 7 coarse-grained relation types."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 63
                            }
                        ],
                        "text": "ACE04 defines the same 7 coarse-grained entity types as ACE05 (Doddington et al., 2004), but de-\nfines 7 coarse-grained relation types: PYS, PERSOC, Employment / Membership / Subsidiary (EMP-ORG), ART, PER/ORG affiliation (OtherAFF), GPE affiliation (GPE-AFF), and Discourse (DISC)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Stephanie Strassel"
            },
            "venue": {
                "fragments": [],
                "text": "and Ralph Weischedel."
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Samy Bengio, Oriol Vinyals, Navdeep Jaitly, and Noam Shazeer. 2015. Scheduled sampling for sequence prediction with recurrent neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "Samy Bengio, Oriol Vinyals, Navdeep Jaitly, and Noam Shazeer. 2015. Scheduled sampling for sequence prediction with recurrent neural networks"
            },
            "year": 2015
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Makoto Miwa"
            },
            "venue": {
                "fragments": [],
                "text": "and Yoshimasa Tsuruoka."
            },
            "year": 2015
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 281,
                                "start": 263
                            }
                        ],
                        "text": "Such models include structured prediction (Li and Ji, 2014; Miwa and Sasaki, 2014), integer linear programming (Roth and Yih, 2007; Yang and Cardie, 2013), card-pyramid parsing (Kate and Mooney, 2010), and global probabilistic graphical models (Yu and Lam, 2010; Singh et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Jiaping Zheng"
            },
            "venue": {
                "fragments": [],
                "text": "and Andrew McCallum."
            },
            "year": 2013
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Navdeep Jaitly"
            },
            "venue": {
                "fragments": [],
                "text": "and Noam Shazeer."
            },
            "year": 2015
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and Christoph H"
            },
            "venue": {
                "fragments": [],
                "text": "Lampert."
            },
            "year": 2015
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Joint entity and relation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "We removed DISC and did 5-fold CV on bnews and nwire subsets (348 documents). We use the same preprocessing and evaluation metrics of ACE05. SemEval-2010 Task 8 defines 9 relation types"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2014
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hyper-parameter Settings Here we show the hyper-parameters and the range tried for the hyper-parameters in parentheses"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Richard Socher"
            },
            "venue": {
                "fragments": [],
                "text": "and Christopher D Manning."
            },
            "year": 2014
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Curriculum learning Scheduled sampling for sequence prediction with recurrent neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 26th Annual International Conference on Machine Learning, ICML '09"
            },
            "year": 2009
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 16,
            "methodology": 25
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 72,
        "totalPages": 8
    },
    "page_url": "https://www.semanticscholar.org/paper/End-to-End-Relation-Extraction-using-LSTMs-on-and-Miwa-Bansal/3899f87a2031f3434f89beb68c11a1ca6428328a?sort=total-citations"
}