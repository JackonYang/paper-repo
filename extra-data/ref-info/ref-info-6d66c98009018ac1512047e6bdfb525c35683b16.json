{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2880906"
                        ],
                        "name": "V. Blanz",
                        "slug": "V.-Blanz",
                        "structuredName": {
                            "firstName": "Volker",
                            "lastName": "Blanz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Blanz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3293655"
                        ],
                        "name": "S. Romdhani",
                        "slug": "S.-Romdhani",
                        "structuredName": {
                            "firstName": "Sami",
                            "lastName": "Romdhani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Romdhani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144517651"
                        ],
                        "name": "T. Vetter",
                        "slug": "T.-Vetter",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Vetter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Vetter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Face recognition, shape estimation, deformable model, 3D faces, pose invariance, illumination invariance."
                    },
                    "intents": []
                }
            ],
            "corpusId": 13175333,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "23fcdda2d12c982bcc0abb948ff835c370b8d75e",
            "isKey": false,
            "numCitedBy": 357,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel approach for recognizing faces in images taken from different directions and under different illumination. The method is based on a 3D morphable face model that encodes shape and texture in terms of model parameters, and an algorithm that recovers these parameters from a single image of a face. For face identification, we use the shape and texture parameters of the model that are separated from imaging parameters, such as pose and illumination. In addition to the identity, the system provides a measure of confidence. We report experimental results for more than 4000 images from the publicly available CMU-PIE database."
            },
            "slug": "Face-identification-across-different-poses-and-with-Blanz-Romdhani",
            "title": {
                "fragments": [],
                "text": "Face identification across different poses and illuminations with a 3D morphable model"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A novel approach for recognizing faces in images taken from different directions and under different illumination is presented, based on a 3D morphable face model that encodes shape and texture in terms of model parameters, and an algorithm that recovers these parameters from a single image of a face."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Fifth IEEE International Conference on Automatic Face Gesture Recognition"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144517651"
                        ],
                        "name": "T. Vetter",
                        "slug": "T.-Vetter",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Vetter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Vetter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2880906"
                        ],
                        "name": "V. Blanz",
                        "slug": "V.-Blanz",
                        "structuredName": {
                            "firstName": "Volker",
                            "lastName": "Blanz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Blanz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Paradigm 2. Three-dimension face reconstruction can also be employed to generate synthetic views from gallery or probe images [3], [ 35 ], [15], [38]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14316400,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "58d96fe13a791c9f62736b69aa9bac49095fdf44",
            "isKey": false,
            "numCitedBy": 95,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a method to derive 3D shape and surface texture of a human face from a single image. The method draws on a general flexible 3D face model which is \u201clearned\u201d from examples of individual 3D-face data (Cyberware-scans). In an analysis-by-synthesis loop, the flexible model is matched to the novel face image."
            },
            "slug": "Estimating-Coloured-3D-Face-Models-from-Single-An-Vetter-Blanz",
            "title": {
                "fragments": [],
                "text": "Estimating Coloured 3D Face Models from Single Images: An Example Based Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "A method to derive 3D shape and surface texture of a human face from a single image using a general flexible 3D face model which is \u201clearned\u201d from examples of individual 3D-face data (Cyberware-scans)."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144517651"
                        ],
                        "name": "T. Vetter",
                        "slug": "T.-Vetter",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Vetter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Vetter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11277929,
            "fieldsOfStudy": [
                "Computer Science",
                "Art"
            ],
            "id": "f8763a14e2b3c0658441d47008b4bb100f28cd90",
            "isKey": false,
            "numCitedBy": 159,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "Images formed by a human face change with viewpoint. A new technique is described for synthesizing images of faces from new viewpoints, when only a single 2D image is available. A novel 2D image of a face can be computed without explicitly computing the 3D structure of the head. The technique draws on a single generic 3D model of a human head and on prior knowledge of faces based on example images of other faces seen in different poses. The example images are used to \u201clearn\u201d a pose-invariant shape and texture description of a new face. The 3D model is used to solve the correspondence problem between images showing faces in different poses.The proposed method is interesting for view independent face recognition tasks as well as for image synthesis problems in areas like teleconferencing and virtualized reality."
            },
            "slug": "Synthesis-of-Novel-Views-from-a-Single-Face-Image-Vetter",
            "title": {
                "fragments": [],
                "text": "Synthesis of Novel Views from a Single Face Image"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "A new technique is described for synthesizing images of faces from new viewpoints, when only a single 2D image is available, which is interesting for view independent face recognition tasks as well as for image synthesis problems in areas like teleconferencing and virtualized reality."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "117481816"
                        ],
                        "name": "D. Mumford",
                        "slug": "D.-Mumford",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mumford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mumford"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36427051"
                        ],
                        "name": "Peter W. Hallinan",
                        "slug": "Peter-W.-Hallinan",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hallinan",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter W. Hallinan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Two-dimensional face models represent gray values and their image locations independently [3], [4], [18], [23], [13], [22]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "These models, however, do not distinguish between rotation angle and shape, and only some of them separate illumination from texture [18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 118557991,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "07df055035fb3e877c28efe4d2300b697c3b225a",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Successful recognition systems must be able to handle not only variations in the geometry of the objects they model, but also arbitrary variations in lighting. We propose a deformable template for unoccluded, frontally-viewed human faces that handles both kinds of variation. Lighting is modeled by finding a basis for face space that can be used to synthesize a face image given lighting conditions, or to determine lighting conditions given a face image. Geometric distortions are captured by automatically \"morphing\" the input face to the synthesized face. Each of several different face models representing both individuals and average faces was tested on two tasks: discriminating the individual represented by the model from all other faces and nonfaces (about 63 positive examples and 1100 negative examples) and discriminating faces from nonfaces (about 755 positive examples and 450 negative examples). Nonfaces here means patches from random natural and artificial scenes. Each model performed extremely well; for false alarm rates of about 0-3 percent miss rates typically fell in 0-5 percent range indicating that distributions of goodness of fit criteria for negative and positive exemplars are actually very well separated. Nothing about the recognition strategy advocated here is particular to faces; in principle, the model is easily extendible to any other viewpoint or to any other object."
            },
            "slug": "A-deformable-model-for-the-recognition-of-human-Mumford-Hallinan",
            "title": {
                "fragments": [],
                "text": "A deformable model for the recognition of human faces under arbitrary illumination"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work proposes a deformable template for unoccluded, frontally-viewed human faces that handles both kinds of variation in lighting and geometry, and in principle is easily extendible to any other viewpoint or toAny other object."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1830709"
                        ],
                        "name": "A. Lanitis",
                        "slug": "A.-Lanitis",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Lanitis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lanitis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Face recognition, shape estimation, deformable model, 3D faces, pose invariance, illumination invariance."
                    },
                    "intents": []
                }
            ],
            "corpusId": 10293011,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6bc436d2892be45fd16ba2620ca0a620bf9f52d7",
            "isKey": false,
            "numCitedBy": 299,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the use of flexible models for representing the shape and grey-level appearance of human faces. These models are controlled by a small number of parameters which can be used to code the overall appearance of a face for image compression and classification purposes. The model parameters control both inter-class and within-class variation. Discriminant analysis techniques are employed to enhance the effect of those parameters affecting inter-class variation, which are useful for classification. We have performed experiments on face coding and reconstruction and automatic face identification. Good recognition rates are obtained even when significant variation in lighting, expression and 3D viewpoint, is allowed. Human faces display significant variation in appearance due to changes in expression, 3D orientation, lighting conditions, hairstyles and so on. A successful automatic face identification system should be capable of suppressing the effect of these factors allowing any face image to be rendered expression-free with standardised 3D orientation and lighting. We describe how the variations in shape and grey-level appearance in face images can be modelled, and present results for a fully automatic face identification system which tolerates changes in expression, viewpoint and lighting."
            },
            "slug": "An-Automatic-Face-Identification-System-Using-Lanitis-Taylor",
            "title": {
                "fragments": [],
                "text": "An Automatic Face Identification System Using Flexible Appearance Models"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "How the variations in shape and grey-level appearance in face images can be modelled are described, and results for a fully automatic face identification system which tolerates changes in expression, viewpoint and lighting are presented."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3230391"
                        ],
                        "name": "A. Georghiades",
                        "slug": "A.-Georghiades",
                        "structuredName": {
                            "firstName": "Athinodoros",
                            "lastName": "Georghiades",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Georghiades"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767767"
                        ],
                        "name": "P. Belhumeur",
                        "slug": "P.-Belhumeur",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Belhumeur",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Belhumeur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765887"
                        ],
                        "name": "D. Kriegman",
                        "slug": "D.-Kriegman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kriegman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kriegman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 34
                            }
                        ],
                        "text": "To obtain a separate parameter for orientation, some methods parameterize the manifold formed by different views of an individual within the eigenspace of images [16], or define separate view-based eigenspaces [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9234219,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6642e9c6cf7432e2d11b7edf7cd47f1285acd54e",
            "isKey": false,
            "numCitedBy": 4696,
            "numCiting": 163,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a generative appearance-based method for recognizing human faces under variation in lighting and viewpoint. Our method exploits the fact that the set of images of an object in fixed pose, but under all possible illumination conditions, is a convex cone in the space of images. Using a small number of training images of each face taken with different lighting directions, the shape and albedo of the face can be reconstructed. In turn, this reconstruction serves as a generative model that can be used to render (or synthesize) images of the face under novel poses and illumination conditions. The pose space is then sampled and, for each pose, the corresponding illumination cone is approximated by a low-dimensional linear subspace whose basis vectors are estimated using the generative model. Our recognition algorithm assigns to a test image the identity of the closest approximated illumination cone. Test results show that the method performs almost without error, except on the most extreme lighting directions."
            },
            "slug": "From-Few-to-Many:-Illumination-Cone-Models-for-Face-Georghiades-Belhumeur",
            "title": {
                "fragments": [],
                "text": "From Few to Many: Illumination Cone Models for Face Recognition under Variable Lighting and Pose"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A generative appearance-based method for recognizing human faces under variation in lighting and viewpoint that exploits the fact that the set of images of an object in fixed pose but under all possible illumination conditions, is a convex cone in the space of images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50564384"
                        ],
                        "name": "G. Edwards",
                        "slug": "G.-Edwards",
                        "structuredName": {
                            "firstName": "Gareth",
                            "lastName": "Edwards",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Edwards"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Two-dimensional face models represent gray values and their image locations independently [3], [4], [18], [23], [ 13 ], [22]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2573397,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "248fb34a10dcd3cfb7e606692b920e4bbca0ea6a",
            "isKey": false,
            "numCitedBy": 455,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new framework for interpreting face images and image sequences using an Active Appearance Model (AAM). The AAM contains a statistical, photo-realistic model of the shape and grey-level appearance of faces. This paper demonstrates the use of the AAM's efficient iterative matching scheme for image interpretation. We use the AAM as a basis for face recognition, obtain good results for difficult images. We show how the AAM framework allows identity information to be decoupled from other variation, allowing evidence of identity to be integrated over a sequence. The AAM approach makes optimal use of the evidence from either a single image or image sequence. Since we derive a complete description of a given image our method can be used as the basis for a range of face image interpretation tasks."
            },
            "slug": "Face-Recognition-Using-Active-Appearance-Models-Edwards-Cootes",
            "title": {
                "fragments": [],
                "text": "Face Recognition Using Active Appearance Models"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper demonstrates the use of the AAM's efficient iterative matching scheme for image interpretation, which allows identity information to be decoupled from other variation, allowing evidence of identity to be integrated over a sequence."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38480590"
                        ],
                        "name": "Wenyi Zhao",
                        "slug": "Wenyi-Zhao",
                        "structuredName": {
                            "firstName": "Wenyi",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wenyi Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9215658"
                        ],
                        "name": "R. Chellappa",
                        "slug": "R.-Chellappa",
                        "structuredName": {
                            "firstName": "Rama",
                            "lastName": "Chellappa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chellappa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 40
                            }
                        ],
                        "text": "To obtain a separate parameter for orientation, some methods parameterize the manifold formed by different views of an individual within the eigenspace of images [16], or define separate view-based eigenspaces [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7316199,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5ae6c0c09bdb6b76034b6c529f9d8baf2a173188",
            "isKey": false,
            "numCitedBy": 154,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Sensitivity to variations in pose is a challenging problem in face recognition using appearance-based methods. More specifically, the appearance of a face changes dramatically when viewing and/or lighting directions change. Various approaches have been proposed to solve this difficult problem. They can be broadly divided into three classes: (1) multiple image-based methods where multiple images of various poses per person are available; (2) hybrid methods where multiple example images are available during learning but only one database image per person is available during recognition; and (3) single image-based methods where no example-based learning is carried out. We present a method that comes under class 3. This method, based on shape-from-shading (SFS), improves the performance of a face recognition system in handling variations due to pose and illumination via image synthesis."
            },
            "slug": "SFS-based-view-synthesis-for-robust-face-Zhao-Chellappa",
            "title": {
                "fragments": [],
                "text": "SFS based view synthesis for robust face recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This method, based on shape-from-shading (SFS), improves the performance of a face recognition system in handling variations due to pose and illumination via image synthesis."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33731953"
                        ],
                        "name": "R. Gross",
                        "slug": "R.-Gross",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Gross",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gross"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711695"
                        ],
                        "name": "I. Matthews",
                        "slug": "I.-Matthews",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Matthews",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Matthews"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145347688"
                        ],
                        "name": "S. Baker",
                        "slug": "S.-Baker",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Baker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Face recognition, shape estimation, deformable model, 3D faces, pose invariance, illumination invariance."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15170260,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "417d85b0d0dfa2a4e0095c86f67384587802d45e",
            "isKey": false,
            "numCitedBy": 130,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "In many face recognition tasks, the pose of the probe and gallery images are different. In other cases, multiple gallery or probe images may be available, each captured from a different pose. We propose a face recognition algorithm which can use any number of gallery images per subject, captured at arbitrary poses, and any number of probe images, again captured at arbitrary poses. The algorithm operates by estimating the eigen light-field of the subject's head from the input gallery or probe images. Matching between the probe and gallery is then performed using the eigen light-fields. We present results on the CMU (Carnegie-Mellon University) PIE (Pose, Illumination and Expression) and the FERET (FacE REcocnition Technology) face databases."
            },
            "slug": "Eigen-light-fields-and-face-recognition-across-pose-Gross-Matthews",
            "title": {
                "fragments": [],
                "text": "Eigen light-fields and face recognition across pose"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "This work proposes a face recognition algorithm which can use any number of gallery images per subject, captured at arbitrary poses, andAny number of probe images, again captured at arbitrarily poses, to solve face recognition problems."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Fifth IEEE International Conference on Automatic Face Gesture Recognition"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Face recognition, shape estimation, deformable model, 3D faces, pose invariance, illumination invariance."
                    },
                    "intents": []
                }
            ],
            "corpusId": 18882836,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "d11bf8b06cf96d90e1ee3dd6467c5c92ac53e9a1",
            "isKey": false,
            "numCitedBy": 999,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Model-based recognition and motion tracking depend upon the ability to solve for projection and model parameters that will best fit a 3-D model to matching 2-D image features. The author extends current methods of parameter solving to handle objects with arbitrary curved surfaces and with any number of internal parameters representing articulation, variable dimensions, or surface deformations. Numerical stabilization methods are developed that take account of inherent inaccuracies in the image measurements and allow useful solutions to be determined even when there are fewer matches than unknown parameters. The Levenberg-Marquardt method is used to always ensure convergence of the solution. These techniques allow model-based vision to be used for a much wider class of problems than was possible with previous methods. Their application is demonstrated for tracking the motion of curved, parameterized objects. >"
            },
            "slug": "Fitting-Parameterized-Three-Dimensional-Models-to-Lowe",
            "title": {
                "fragments": [],
                "text": "Fitting Parameterized Three-Dimensional Models to Images"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Current methods of parameter solving are extended to handle objects with arbitrary curved surfaces and with any number of internal parameters representing articulation, variable dimensions, or surface deformations to allow model-based vision to be used for a much wider class of problems than was possible with previous methods."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111328101"
                        ],
                        "name": "Michael Jones",
                        "slug": "Michael-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Face recognition, shape estimation, deformable model, 3D faces, pose invariance, illumination invariance."
                    },
                    "intents": []
                }
            ],
            "corpusId": 30020871,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1cae73ad58bafd04ac48cddd2a83861d56b0e463",
            "isKey": false,
            "numCitedBy": 126,
            "numCiting": 83,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a flexible model for representing images of objects of a certain class, known a priori, such as faces, and introduce a new algorithm for matching it to a novel image and thereby perform image analysis. The flexible model, known as a multidimensional morphable model, is learned from example images of objects of a class. In this paper we introduce an effective stochastic gradient descent algorithm that automatically matches a model to a novel image. Several experiments demonstrate the robustness and the broad range of applicability of morphable models. Our approach can provide novel solutions to several vision tasks, including the computation of image correspondence, object verification and image compression."
            },
            "slug": "Multidimensional-Morphable-Models:-A-Framework-for-Jones-Poggio",
            "title": {
                "fragments": [],
                "text": "Multidimensional Morphable Models: A Framework for Representing and Matching Object Classes"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "An effective stochastic gradient descent algorithm that automatically matches a model to a novel image and thereby perform image analysis is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2281877"
                        ],
                        "name": "J. Atick",
                        "slug": "J.-Atick",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Atick",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Atick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2385089"
                        ],
                        "name": "P. A. Griffin",
                        "slug": "P.-A.-Griffin",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Griffin",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. A. Griffin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144513847"
                        ],
                        "name": "A. Redlich",
                        "slug": "A.-Redlich",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Redlich",
                            "middleNames": [
                                "Norman"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Redlich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17146562,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b3d0aa18ce358c93f485cbe9264db515651ad483",
            "isKey": false,
            "numCitedBy": 289,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "The human visual system is proficient in perceiving three-dimensional shape from the shading patterns in a two-dimensional image. How it does this is not well understood and continues to be a question of fundamental and practical interest. In this paper we present a new quantitative approach to shape-from-shading that may provide some answers. We suggest that the brain, through evolution or prior experience, has discovered that objects can be classified into lower-dimensional object-classes as to their shape. Extraction of shape from shading is then equivalent to the much simpler problem of parameter estimation in a low-dimensional space. We carry out this proposal for an important class of three-dimensional (3D) objects: human heads. From an ensemble of several hundred laser-scanned 3D heads, we use principal component analysis to derive a low-dimensional parameterization of head shape space. An algorithm for solving shape-from-shading using this representation is presented. It works well even on real images where it is able to recover the 3D surface for a given person, maintaining facial detail and identity, from a single 2D image of his face. This algorithm has applications in face recognition and animation."
            },
            "slug": "Statistical-Approach-to-Shape-from-Shading:-of-Face-Atick-Griffin",
            "title": {
                "fragments": [],
                "text": "Statistical Approach to Shape from Shading: Reconstruction of Three-Dimensional Face Surfaces from Single Two-Dimensional Images"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is suggested that the brain, through evolution or prior experience, has discovered that objects can be classified into lower-dimensional object-classes as to their shape, and extraction of shape from shading is then equivalent to the much simpler problem of parameter estimation in a low-dimensional space."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740300"
                        ],
                        "name": "D. Beymer",
                        "slug": "D.-Beymer",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Beymer",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Beymer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14814282,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "66505cb708b098a93331471f079965f6ded4ea7f",
            "isKey": false,
            "numCitedBy": 449,
            "numCiting": 76,
            "paperAbstract": {
                "fragments": [],
                "text": "To create a pose-invariant face recognizer, one strategy is the view-based approach, which uses a set of real example views at different poses. But what if we only have one real view available, such as a scanned passport photo-can we still recognize faces under different poses? Given one real view at a known pose, it is still possible to use the view-based approach by exploiting prior knowledge of faces to generate virtual views, or views of the face as seen from different poses. To represent prior knowledge, we use 2D example views of prototype faces under different rotations. We develop example-based techniques for applying the rotation seen in the prototypes to essentially \"rotate\" the single real view which is available. Next, the combined set of one real and multiple virtual views is used as example views for a view-based, pose-invariant face recognizer. Oar experiments suggest that among the techniques for expressing prior knowledge of faces, 2D example-based approaches should be considered alongside the more standard 3D modeling techniques.<<ETX>>"
            },
            "slug": "Face-recognition-from-one-example-view-Beymer-Poggio",
            "title": {
                "fragments": [],
                "text": "Face recognition from one example view"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Oar experiments suggest that among the techniques for expressing prior knowledge of faces, 2D example-based approaches should be considered alongside the more standard 3D modeling techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055501916"
                        ],
                        "name": "Thomas Maurer",
                        "slug": "Thomas-Maurer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Maurer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Maurer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Face recognition, shape estimation, deformable model, 3D faces, pose invariance, illumination invariance."
                    },
                    "intents": []
                }
            ],
            "corpusId": 11534904,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "04c306621210fd9dc96b6106e1f5a6bd745ff5dd",
            "isKey": false,
            "numCitedBy": 70,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method for recognizing objects (faces) on the basis of just one stored view, in spite of rotation in depth. The method is not based on the construction of a three-dimensional model for the object. Our recognition results represent a signi cant improvement over a previous system developed in our laboratory. We achieve this with the help of a simple assumption about the transformation of local feature vectors with rotation in depth."
            },
            "slug": "Single-View-Based-Recognition-of-Faces-Rotated-in-Maurer-Malsburg",
            "title": {
                "fragments": [],
                "text": "Single-View Based Recognition of Faces Rotated in Depth"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This work presents a method for recognizing objects (faces) on the basis of just one stored view, in spite of rotation in depth, with the help of a simple assumption about the transformation of local feature vectors with rotation in Depth."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70044319"
                        ],
                        "name": "G. V. Wheeler",
                        "slug": "G.-V.-Wheeler",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Wheeler",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. V. Wheeler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29063598"
                        ],
                        "name": "K. N. Walker",
                        "slug": "K.-N.-Walker",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Walker",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. N. Walker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Face recognition, shape estimation, deformable model, 3D faces, pose invariance, illumination invariance."
                    },
                    "intents": []
                }
            ],
            "corpusId": 121708892,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1c950a984fc677cde0e51028269b8ae843a8a72f",
            "isKey": false,
            "numCitedBy": 348,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We demonstrate that a small number of 2D statistical models are sufficient to capture the shape and appearance of a face from any viewpoint (full profile to front-to-parallel). Each model is linear and can be matched rapidly to new images using the active appearance model algorithm. We show how such a set of models can be used to estimate head pose, to track faces through large angles of head rotation and to synthesize faces from unseen viewpoints."
            },
            "slug": "View-based-active-appearance-models-Cootes-Wheeler",
            "title": {
                "fragments": [],
                "text": "View-based active appearance models"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A small number of 2D statistical models are demonstrated to capture the shape and appearance of a face from any viewpoint (full profile to front-to-parallel) and to estimate head pose and to synthesize faces from unseen viewpoints."
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144517651"
                        ],
                        "name": "T. Vetter",
                        "slug": "T.-Vetter",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Vetter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Vetter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Face recognition, shape estimation, deformable model, 3D faces, pose invariance, illumination invariance."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 106
                            }
                        ],
                        "text": "In face recognition, the set of images that shows all individuals who are known to the system is often referred to as gallery [39], [30]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10047234,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "617b34332fcd1cb196f93656ee1d49561b81ebf8",
            "isKey": false,
            "numCitedBy": 471,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "The need to generate new views of a 3D object from a single real image arises in several fields, including graphics and object recognition. While the traditional approach relies on the use of 3D models, simpler techniques are applicable under restricted conditions. The approach exploits image transformations that are specific to the relevant object class, and learnable from example views of other \"prototypical\" objects of the same class. In this paper, we introduce such a technique by extending the notion of linear class proposed by the authors (1992). For linear object classes, it is shown that linear transformations can be learned exactly from a basis set of 2D prototypical views. We demonstrate the approach on artificial objects and then show preliminary evidence that the technique can effectively \"rotate\" high-resolution face images from a single 2D view."
            },
            "slug": "Linear-Object-Classes-and-Image-Synthesis-From-a-Vetter-Poggio",
            "title": {
                "fragments": [],
                "text": "Linear Object Classes and Image Synthesis From a Single Example Image"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "For linear object classes, it is shown that linear transformations can be learned exactly from a basis set of 2D prototypical views and preliminary evidence that the technique can effectively \"rotate\" high-resolution face images from a single 2D view is shown."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738894"
                        ],
                        "name": "T. Starner",
                        "slug": "T.-Starner",
                        "structuredName": {
                            "firstName": "Thad",
                            "lastName": "Starner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Starner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Face recognition, shape estimation, deformable model, 3D faces, pose invariance, illumination invariance."
                    },
                    "intents": []
                }
            ],
            "corpusId": 136280,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b0bf5d558220d39698ce96d59ee5772e8e1a0663",
            "isKey": false,
            "numCitedBy": 2234,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe experiments with eigenfaces for recognition and interactive search in a large-scale face database. Accurate visual recognition is demonstrated using a database of O(10/sup 3/) faces. The problem of recognition under general viewing orientation is also examined. A view-based multiple-observer eigenspace technique is proposed for use in face recognition under variable pose. In addition, a modular eigenspace description technique is used which incorporates salient features such as the eyes, nose and mouth, in an eigenfeature layer. This modular representation yields higher recognition rates as well as a more robust framework for face recognition. An automatic feature extraction technique using feature eigentemplates is also demonstrated.<<ETX>>"
            },
            "slug": "View-based-and-modular-eigenspaces-for-face-Pentland-Moghaddam",
            "title": {
                "fragments": [],
                "text": "View-based and modular eigenspaces for face recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A modular eigenspace description technique is used which incorporates salient features such as the eyes, nose and mouth, in an eigenfeature layer, which yields higher recognition rates as well as a more robust framework for face recognition."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691986"
                        ],
                        "name": "P. Phillips",
                        "slug": "P.-Phillips",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Phillips",
                            "middleNames": [
                                "Jonathon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143979395"
                        ],
                        "name": "H. Wechsler",
                        "slug": "H.-Wechsler",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Wechsler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wechsler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152292143"
                        ],
                        "name": "Jeffrey R. Huang",
                        "slug": "Jeffrey-R.-Huang",
                        "structuredName": {
                            "firstName": "Jeffrey R.",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeffrey R. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3313513"
                        ],
                        "name": "Patrick J. Rauss",
                        "slug": "Patrick-J.-Rauss",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Rauss",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Patrick J. Rauss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 20
                            }
                        ],
                        "text": "The\ngallery for the FERET set was formed by one front view\n(pose ba) per person."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 47
                            }
                        ],
                        "text": "Portions of the research in this paper use the\nFERET database of facial images collected under the FERET\nprogram, and the CMU-PIE database."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 34
                            }
                        ],
                        "text": "From the gray-level images of the FERET database\n[29], we selected a portion that contains 11 poses (labeled\nba \u2013 bk) per individual."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 64
                            }
                        ],
                        "text": "Table 4 lists the percentages of correct identifications on the FERET set, based on front view gallery images ba, along with the\nestimated head poses obtained from fitting."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 70
                            }
                        ],
                        "text": "Estimated\nfrom the CMU-PIE database, we apply these variations to\nthe FERET images and vice versa, using a method\nmotivated by Maximum-Likelihood Classifiers and Linear\nDiscriminant Analysis (see [12]): Deviations of each\npersons\u2019 coefficients c from their individual average are\npooled and analyzed by PCA."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 4
                            }
                        ],
                        "text": "For FERET, front views ba were gallery, and all other 1,746 images were probe images."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 93
                            }
                        ],
                        "text": "At 1 percent false alarm rate, the hit rate is 77.5 percent for CMU-PIE and 87.9 percent for FERET."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 64
                            }
                        ],
                        "text": "The reconstruction algorithm was run on all 4,488 PIE and 1,940 FERET images."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 49
                            }
                        ],
                        "text": "From the gray-level images of the FERET database [29], we selected a portion that contains 11 poses (labeled ba \u2013 bk) per individual."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 70
                            }
                        ],
                        "text": "Recognition results for the image databases of CMU-PIE [33] and FERET [29] are presented in Section 5."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 142
                            }
                        ],
                        "text": "Our system\ncurrently ignores glasses, beards, or strands of hair\ncovering part of the face, which are found in many images\nof the CMU-PIE and FERET sets."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 117
                            }
                        ],
                        "text": "We present results obtained with 4,488 images from the publicly available CMU-PIE database and 1,940 images from the FERET database."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 124
                            }
                        ],
                        "text": "Some of the\nfaces are partially occluded by hair and some individuals\nwear glasses (28 in the CMU-PIE database, none in the\nFERET database.)"
                    },
                    "intents": []
                }
            ],
            "corpusId": 17779599,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc8b25e35a3acb812beb499844734081722319b4",
            "isKey": true,
            "numCitedBy": 2398,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-FERET-database-and-evaluation-procedure-for-Phillips-Wechsler",
            "title": {
                "fragments": [],
                "text": "The FERET database and evaluation procedure for face-recognition algorithms"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2695566"
                        ],
                        "name": "Li-an Tang",
                        "slug": "Li-an-Tang",
                        "structuredName": {
                            "firstName": "Li-an",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li-an Tang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Some algorithms match a small number of feature vertices to image positions, and interpolate deformations of the surface in between [ 21 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 42179530,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f165292386ae5ed1606fbe8456c0d5ecdbb947b5",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes some issues in building a 3-D human face modeling system which mainly consists of three parts: \u2022 Modeling human faces; \u2022 Analyzing facial motions; \u2022 Synthesizing facial expressions. A variety of techniques developed for this system are described in detail in this paper. Some preliminary results of applying this system to computer animation, video sequence compression and human face recognition are also shown."
            },
            "slug": "3-D-Face-Modeling-and-Its-Applications-Huang-Tang",
            "title": {
                "fragments": [],
                "text": "3-D Face Modeling and Its Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A variety of techniques developed for this 3-D human face modeling system are described in detail and some preliminary results of applying this system to computer animation, video sequence compression and human face recognition are shown."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Pattern Recognit. Artif. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785317"
                        ],
                        "name": "W. Wells",
                        "slug": "W.-Wells",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Wells",
                            "middleNames": [
                                "M."
                            ],
                            "suffix": "III"
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Wells"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 153
                            }
                        ],
                        "text": "For the optimization of the cost function (21), we developed a stochastic version of Newton\u2019s algorithm [5] similar to stochastic gradient descent [32], [37], [22]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2499926,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ae466aae94b7fb9944056249d7c5be2e8cdef280",
            "isKey": false,
            "numCitedBy": 3427,
            "numCiting": 95,
            "paperAbstract": {
                "fragments": [],
                "text": "A new information-theoretic approach is presented for finding the pose of an object in an image. The technique does not require information about the surface properties of the object, besides its shape, and is robust with respect to variations of illumination. In our derivation few assumptions are made about the nature of the imaging process. As a result the algorithms are quite general and may foreseeably be used in a wide variety of imaging situations.Experiments are presented that demonstrate the approach registering magnetic resonance (MR) images, aligning a complex 3D object model to real scenes including clutter and occlusion, tracking a human head in a video sequence and aligning a view-based 2D object model to real images.The method is based on a formulation of the mutual information between the model and the image. As applied here the technique is intensity-based, rather than feature-based. It works well in domains where edge or gradient-magnitude based methods have difficulty, yet it is more robust than traditional correlation. Additionally, it has an efficient implementation that is based on stochastic approximation."
            },
            "slug": "Alignment-by-Maximization-of-Mutual-Information-Viola-Wells",
            "title": {
                "fragments": [],
                "text": "Alignment by Maximization of Mutual Information"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A new information-theoretic approach is presented for finding the pose of an object in an image that works well in domains where edge or gradient-magnitude based methods have difficulty, yet it is more robust than traditional correlation."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067071261"
                        ],
                        "name": "Terence Sim",
                        "slug": "Terence-Sim",
                        "structuredName": {
                            "firstName": "Terence",
                            "lastName": "Sim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Terence Sim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145347688"
                        ],
                        "name": "S. Baker",
                        "slug": "S.-Baker",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Baker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3240967"
                        ],
                        "name": "Maan Bsat",
                        "slug": "Maan-Bsat",
                        "structuredName": {
                            "firstName": "Maan",
                            "lastName": "Bsat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Maan Bsat"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 48
                            }
                        ],
                        "text": "The colored images in the PIE database from CMU [33] vary in pose and illumination."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "Recognition results for the image databases of CMU-PIE [33] and FERET [29] are presented in Section 5."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2091854,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b89f0e4f43570688dd983813c9a3efa2fa7e7ebc",
            "isKey": false,
            "numCitedBy": 1630,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Between October 2000 and December 2000, we collected a database of over 40,000 facial images of 68 people. Using the CMU (Carnegie Mellon University) 3D Room, we imaged each person across 13 different poses, under 43 different illumination conditions, and with four different expressions. We call this database the CMU Pose, Illumination and Expression (PIE) database. In this paper, we describe the imaging hardware, the collection procedure, the organization of the database, several potential uses of the database, and how to obtain the database."
            },
            "slug": "The-CMU-Pose,-Illumination,-and-Expression-(PIE)-Sim-Baker",
            "title": {
                "fragments": [],
                "text": "The CMU Pose, Illumination, and Expression (PIE) database"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "Between October 2000 and December 2000, a database of over 40,000 facial images of 68 people was collected, using the CMU 3D Room to imaged each person across 13 different poses, under 43 different illumination conditions, and with four different expressions."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Fifth IEEE International Conference on Automatic Face Gesture Recognition"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "98902637"
                        ],
                        "name": "Wen Zhao",
                        "slug": "Wen-Zhao",
                        "structuredName": {
                            "firstName": "Wen",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wen Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9215658"
                        ],
                        "name": "R. Chellappa",
                        "slug": "R.-Chellappa",
                        "structuredName": {
                            "firstName": "Rama",
                            "lastName": "Chellappa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chellappa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691986"
                        ],
                        "name": "P. Phillips",
                        "slug": "P.-Phillips",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Phillips",
                            "middleNames": [
                                "Jonathon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143766793"
                        ],
                        "name": "A. Rosenfeld",
                        "slug": "A.-Rosenfeld",
                        "structuredName": {
                            "firstName": "Azriel",
                            "lastName": "Rosenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rosenfeld"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Face recognition, shape estimation, deformable model, 3D faces, pose invariance, illumination invariance."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 6
                            }
                        ],
                        "text": "The model is learned from a set of textured 3D scans of heads."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 154
                            }
                        ],
                        "text": "IN face recognition from images, the gray-level or colorvalues provided to the recognition system depend not only on the identity of the person, but also on parameters such as head pose and illumination."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12331515,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "28312c3a47c1be3a67365700744d3d6665b86f22",
            "isKey": false,
            "numCitedBy": 6984,
            "numCiting": 418,
            "paperAbstract": {
                "fragments": [],
                "text": "As one of the most successful applications of image analysis and understanding, face recognition has recently received significant attention, especially during the past several years. At least two reasons account for this trend: the first is the wide range of commercial and law enforcement applications, and the second is the availability of feasible technologies after 30 years of research. Even though current machine recognition systems have reached a certain level of maturity, their success is limited by the conditions imposed by many real applications. For example, recognition of face images acquired in an outdoor environment with changes in illumination and/or pose remains a largely unsolved problem. In other words, current systems are still far away from the capability of the human perception system.This paper provides an up-to-date critical survey of still- and video-based face recognition research. There are two underlying motivations for us to write this survey paper: the first is to provide an up-to-date review of the existing literature, and the second is to offer some insights into the studies of machine recognition of faces. To provide a comprehensive survey, we not only categorize existing recognition techniques but also present detailed descriptions of representative methods within each category. In addition, relevant topics such as psychophysical studies, system evaluation, and issues of illumination and pose variation are covered."
            },
            "slug": "Face-recognition:-A-literature-survey-Zhao-Chellappa",
            "title": {
                "fragments": [],
                "text": "Face recognition: A literature survey"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper provides an up-to-date critical survey of still- and video-based face recognition research, and categorizes existing recognition techniques but also presents detailed descriptions of representative methods within each category."
            },
            "venue": {
                "fragments": [],
                "text": "CSUR"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2320082"
                        ],
                        "name": "C. Choi",
                        "slug": "C.-Choi",
                        "structuredName": {
                            "firstName": "Chang",
                            "lastName": "Choi",
                            "middleNames": [
                                "Seok"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Choi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50540918"
                        ],
                        "name": "T. Okazaki",
                        "slug": "T.-Okazaki",
                        "structuredName": {
                            "firstName": "Toru",
                            "lastName": "Okazaki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Okazaki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698996"
                        ],
                        "name": "H. Harashima",
                        "slug": "H.-Harashima",
                        "structuredName": {
                            "firstName": "Hiroshi",
                            "lastName": "Harashima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Harashima"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72636269"
                        ],
                        "name": "T. Takebe",
                        "slug": "T.-Takebe",
                        "structuredName": {
                            "firstName": "Tsuyosi",
                            "lastName": "Takebe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Takebe"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Face recognition, shape estimation, deformable model, 3D faces, pose invariance, illumination invariance."
                    },
                    "intents": []
                }
            ],
            "corpusId": 61405009,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f3458ce2e92102a721277e1208032f24c1a19f46",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "A system is presented which analyzes and synthesizes the facial images. This system is focused on analysis and synthesis of facial features. Any particular image is assumed to be a weighted sum of facial image bases. The weights represent the facial features of the particular image. A method which analyzes and synthesizes the facial images on the basis of a three-dimensional facial shape model is presented. The method is extended so that the features of parts as well as the whole of the face can be analyzed and synthesized. Moreover, a procedure is developed for orthogonalizing the image bases for optimal description.<<ETX>>"
            },
            "slug": "A-system-of-analyzing-and-synthesizing-facial-Choi-Okazaki",
            "title": {
                "fragments": [],
                "text": "A system of analyzing and synthesizing facial images"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "A method which analyzes and synthesizes the facial images on the basis of a three-dimensional facial shape model is presented, extended so that the features of parts as well as the whole of the face can be analyzed and synthesized."
            },
            "venue": {
                "fragments": [],
                "text": "1991., IEEE International Sympoisum on Circuits and Systems"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691986"
                        ],
                        "name": "P. Phillips",
                        "slug": "P.-Phillips",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Phillips",
                            "middleNames": [
                                "Jonathon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2136478"
                        ],
                        "name": "P. Grother",
                        "slug": "P.-Grother",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Grother",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Grother"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3107704"
                        ],
                        "name": "R. Micheals",
                        "slug": "R.-Micheals",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Micheals",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Micheals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32889627"
                        ],
                        "name": "D. Blackburn",
                        "slug": "D.-Blackburn",
                        "structuredName": {
                            "firstName": "Duane",
                            "lastName": "Blackburn",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blackburn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2326261"
                        ],
                        "name": "Elham Tabassi",
                        "slug": "Elham-Tabassi",
                        "structuredName": {
                            "firstName": "Elham",
                            "lastName": "Tabassi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Elham Tabassi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144505249"
                        ],
                        "name": "Mike Bone",
                        "slug": "Mike-Bone",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Bone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mike Bone"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 30512497,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "491472dcde6783f5607f69b7922fb4dcc21f4bcb",
            "isKey": false,
            "numCitedBy": 409,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Summary form only given. The face recognition vendor test (FRVT) 2002 is an independently administered technology evaluation of mature face recognition systems. FRVT 2002 provides performance measures for assessing the capability of face recognition systems to meet requirements for large-scale, real-world applications. Participation in FRVT 2002 was open to commercial and mature prototype systems from universities, research institutes, and companies. Ten companies submitted either commercial or prototype systems. FRVT 2002 computed performance statistics on an extremely large data set-121,589 operational facial images of 37,437 individuals. FRVT 2002 1) characterized identification and watch list performance as a function of database size, 2) estimated the variability in performance for different groups of people, 3) characterized performance as a function of elapsed time between enrolled and new images of a person, and 4) investigated the effect of demographics on performance. FRVT 2002 showed that recognition from indoor images has made substantial progress since FRVT 2000. Demographic results show that males are easier to recognize than females and that older people are easier to recognize than younger people. FRVT 2002 also assessed the impact of three new techniques for improving face recognition: three-dimensional morphable models, normalization of similarity scores, and face recognition from video sequences. Results show that three-dimensional morphable models and normalization increase performance and that face recognition from video sequences offers only a limited increase in performance over still images. A new XML-based evaluation protocol was developed for FRVT 2002. This protocol is flexible and supports evaluations of biometrics in general The FRVT 2002 reports can be found at http://www.frvt.org."
            },
            "slug": "Face-recognition-vendor-test-2002-Phillips-Grother",
            "title": {
                "fragments": [],
                "text": "Face recognition vendor test 2002"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Results show that recognition from indoor images has made substantial progress since FRVT 2000 and that three-dimensional morphable models and normalization increase performance and that face recognition from video sequences offers only a limited increase in performance over still images."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE International SOI Conference. Proceedings (Cat. No.03CH37443)"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40638847"
                        ],
                        "name": "Hyeonjoon Moon",
                        "slug": "Hyeonjoon-Moon",
                        "structuredName": {
                            "firstName": "Hyeonjoon",
                            "lastName": "Moon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hyeonjoon Moon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691986"
                        ],
                        "name": "P. Phillips",
                        "slug": "P.-Phillips",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Phillips",
                            "middleNames": [
                                "Jonathon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Phillips"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 90
                            }
                        ],
                        "text": "An alternative measure for similarity is the cosine of the angle between two vectors [6], [27]: dA 1\u20444 c1;c2 h i c1 k k c2 k k ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11563321,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f095554be869d80ff273f438875ecad391bfdae0",
            "isKey": false,
            "numCitedBy": 522,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Algorithms based on principal component analysis (PCA) form the basis of numerous studies in the psychological and algorithmic face-recognition literature. PCA is a statistical technique and its incorporation into a face-recognition algorithm requires numerous design decisions. We explicitly state the design decisions by introducing a generic modular PCA-algorithm. This allows us to investigate these decisions, including those not documented in the literature. We experimented with different implementations of each module, and evaluated the different implementations using the September 1996 FERET evaluation protocol (the de facto standard for evaluating face-recognition algorithms). We experimented with (i) changing the illumination normalization procedure; (ii) studying effects on algorithm performance of compressing images with JPEG and wavelet compression algorithms; (iii) varying the number of eigenvectors in the representation; and (iv) changing the similarity measure in the classification process. We performed two experiments. In the first experiment, we obtained performance results on the standard September 1996 FERET large-gallery image sets. In the second experiment, we examined the variability in algorithm performance on different sets of facial images. The study was performed on 100 randomly generated image sets (galleries) of the same size. Our two most significant results are (i) changing the similarity measure produced the greatest change in performance, and (ii) that difference in performance of \u00b110% is needed to distinguish between algorithms."
            },
            "slug": "Computational-and-Performance-Aspects-of-PCA-Based-Moon-Phillips",
            "title": {
                "fragments": [],
                "text": "Computational and Performance Aspects of PCA-Based Face-Recognition Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Two most significant results are that changing the similarity measure produced the greatest change in performance, and that difference in performance of \u00b110% is needed to distinguish between algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "Perception"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052858104"
                        ],
                        "name": "D. B. Graham",
                        "slug": "D.-B.-Graham",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Graham",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. B. Graham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50729465"
                        ],
                        "name": "N. Allinson",
                        "slug": "N.-Allinson",
                        "structuredName": {
                            "firstName": "Nigel",
                            "lastName": "Allinson",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Allinson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Face recognition, shape estimation, deformable model, 3D faces, pose invariance, illumination invariance."
                    },
                    "intents": []
                }
            ],
            "corpusId": 18246006,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "id": "eb74adf127e4325709cc7f82ff713706eab3d4f0",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "A framework for recognising human faces from unfamiliar views is described and a simple implementation of this framework evaluated. The interaction between training view and testing view is shown to compare with observations in human face recognition experiments. The ability of the system to learn from several training views, as available in video footage, is shown to improve the overall performance of the system as is the use of multiple testing images."
            },
            "slug": "Face-recognition-from-unfamiliar-views:-subspace-Graham-Allinson",
            "title": {
                "fragments": [],
                "text": "Face recognition from unfamiliar views: subspace methods and pose dependency"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The ability of the system to learn from several training views, as available in video footage, is shown to improve the overall performance of thesystem as is the use of multiple testing images."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Third IEEE International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40588702"
                        ],
                        "name": "B. D. Lucas",
                        "slug": "B.-D.-Lucas",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "Lucas",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. D. Lucas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 58
                            }
                        ],
                        "text": "each neighborhood R\u00f0x0; y0\u00de, and the following expression [25], [2] is minimized in each point \u00f0x0; y0\u00de:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 8
                            }
                        ],
                        "text": ", [20], [25], [2]) are based on the assumption that objects in image sequences I\u00f0x; y; t\u00de retain their bright-"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2121536,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "id": "a06547951c97b2a32f23a6c2b5f79c8c75c9b9bd",
            "isKey": false,
            "numCitedBy": 13329,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Image registration finds a variety of applications in computer vision. Unfortunately, traditional image registration techniques tend to be costly. We present a new image registration technique that makes use of the spatial intensity gradient of the images to find a good match using a type of Newton-Raphson iteration. Our technique is taster because it examines far fewer potential matches between the images than existing techniques Furthermore, this registration technique can be generalized to handle rotation, scaling and shearing. We show how our technique can be adapted tor use in a stereo vision system."
            },
            "slug": "An-Iterative-Image-Registration-Technique-with-an-Lucas-Kanade",
            "title": {
                "fragments": [],
                "text": "An Iterative Image Registration Technique with an Application to Stereo Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work presents a new image registration technique that makes use of the spatial intensity gradient of the images to find a good match using a type of Newton-Raphson iteration, and can be generalized to handle rotation, scaling and shearing."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2302358"
                        ],
                        "name": "P. Burt",
                        "slug": "P.-Burt",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Burt",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Burt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145358192"
                        ],
                        "name": "E. Adelson",
                        "slug": "E.-Adelson",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Adelson",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Adelson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 108
                            }
                        ],
                        "text": "For continuous transitions between the segments, we apply a modification of the image blending technique of [9]: x; y; z coordinates and colors R;G;B are stored in arrays x\u00f0h; \u00de, ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 120492525,
            "fieldsOfStudy": [
                "Environmental Science",
                "Computer Science"
            ],
            "id": "3482e6821f7d114fce202c8a0e7879932dd640be",
            "isKey": false,
            "numCitedBy": 153,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "It is frequently desirable to combine different sources of image information into a composite image prior to undertaking image analysis. For example, multiple images may be merged to extend the field of view or resolution, or to eliminate foreground obstacles. Or stereo images may be combined so that regions occluded in one camera's view are filled smoothly with regions seen by the other camera. The essential problem in image merging is \"pattern conservation\": important details of the component images must be preserved in the composite while no spurious pattern elements are introduced by the merging process. Simple approaches to image merging often create edge artifacts between regions taken from different source images, and these may confound subsequent image analysis. We describe an approach to image merging based on pattern decomposition. Each source image is first transformed into a set of primitive pattern elements. Pattern sets for the various source images are then combined to form a single set for the composite image. Finally the composite is reconstructed from its set of primitives. We illustrate the pattern decomposition technique with several practical applications. These include image merging to eliminate foreground objects, and merging to extend the depth of field. In all cases the Laplacian pyramid is used to encode images in terms of sets of primitives which resemble Gaussians of many scales."
            },
            "slug": "Merging-Images-Through-Pattern-Decomposition-Burt-Adelson",
            "title": {
                "fragments": [],
                "text": "Merging Images Through Pattern Decomposition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The Laplacian pyramid is used to encode images in terms of sets of primitives which resemble Gaussians of many scales, and these include image merging to eliminate foreground objects, and merging to extend the depth of field."
            },
            "venue": {
                "fragments": [],
                "text": "Optics & Photonics"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32889627"
                        ],
                        "name": "D. Blackburn",
                        "slug": "D.-Blackburn",
                        "structuredName": {
                            "firstName": "Duane",
                            "lastName": "Blackburn",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blackburn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144505249"
                        ],
                        "name": "Mike Bone",
                        "slug": "Mike-Bone",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Bone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mike Bone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691986"
                        ],
                        "name": "P. Phillips",
                        "slug": "P.-Phillips",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Phillips",
                            "middleNames": [
                                "Jonathon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Phillips"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In face recognition, the set of images that shows all individuals who are known to the system is often referred to as gallery [39], [30]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This paradigm has been evaluated with 10 face recognition systems in the Face Recognition Vendor Test 2002 [30]: For 9 out of 10 systems, our morphable model and fitting procedure (Sections 3 and 4) improved performance on nonfrontal faces substantially."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "[30])."
                    },
                    "intents": []
                }
            ],
            "corpusId": 62749895,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4a0eb886c51196409f6fc62f22cb89adf44bf5b7",
            "isKey": false,
            "numCitedBy": 268,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : The biggest change in the facial recognition community since the completion of the FERET program has been the introduction of facial recognition products to the commercial market. Open market competitiveness has driven numerous technological advances in automated face recognition since the FERET program and significantly lowered system costs. Today there are dozens of facial recognition systems available that have the potential to meet performance requirements for numerous applications. But which of these systems best meet the performance requirements for given applications? Repeated inquiries from numerous government agencies on the current state of facial recognition technology prompted the DoD Counterdrug Technology Development Program Office to establish a new set of evaluations. The Facial Recognition Vendor Test 2000 (FRVT 2000) was cosponsored by the DoD Counterdrug Technology Development Program Office, the National Institute of Justice and the Defense Advanced Research Projects Agency and was administered in May and June 2000."
            },
            "slug": "Face-Recognition-Vendor-Test-2000:-Evaluation-Blackburn-Bone",
            "title": {
                "fragments": [],
                "text": "Face Recognition Vendor Test 2000: Evaluation Report"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The Facial Recognition Vendor Test 2000 (FRVT 2000) was cosponsored by the DoD Counterdrug Technology Development Program Office, the National Institute of Justice and the Defense Advanced Research Projects Agency and was administered in May and June 2000."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1604429801"
                        ],
                        "name": "Robert M. Haralock",
                        "slug": "Robert-M.-Haralock",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralock",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert M. Haralock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809809"
                        ],
                        "name": "L. Shapiro",
                        "slug": "L.-Shapiro",
                        "structuredName": {
                            "firstName": "Linda",
                            "lastName": "Shapiro",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Shapiro"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61087042,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a9eaaecf23f3a4b7822e4bcca924e02cd5b4dc4e",
            "isKey": false,
            "numCitedBy": 3343,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nThis two-volume set is an authoritative, comprehensive, modern work on computer vision that covers all of the different areas of vision with a balanced and unified approach. The discussion in \"Volume I\" focuses on image in, and image out or feature set out. \"Volume II\" covers the higher level techniques of illumination, perspective projection, analytical photogrammetry, motion, image matching, consistent labeling, model matching, and knowledge-based vision systems."
            },
            "slug": "Computer-and-Robot-Vision-Haralock-Shapiro",
            "title": {
                "fragments": [],
                "text": "Computer and Robot Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "This two-volume set is an authoritative, comprehensive, modern work on computer vision that covers all of the different areas of vision with a balanced and unified approach."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740300"
                        ],
                        "name": "D. Beymer",
                        "slug": "D.-Beymer",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Beymer",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Beymer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Face recognition, shape estimation, deformable model, 3D faces, pose invariance, illumination invariance."
                    },
                    "intents": []
                }
            ],
            "corpusId": 62531491,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "89121ed4d0d3db9bc192fd79f541fc299eba7d6b",
            "isKey": false,
            "numCitedBy": 304,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Computer vision researchers are developing new approaches to object recognition and detection that are based almost directly on images and avoid the use of intermediate three-dimensional models. Many of these techniques depend on a representation of images that induces a linear vector space structure and in principle requires dense feature correspondence. This image representation allows the use of learning techniques for the analysis of images (for computer vision) as well as for the synthesis of images (for computer graphics)."
            },
            "slug": "Image-Representations-for-Visual-Learning-Beymer-Poggio",
            "title": {
                "fragments": [],
                "text": "Image Representations for Visual Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Computer vision researchers are developing new approaches to object recognition and detection that are based almost directly on images and avoid the use of intermediate three-dimensional models."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143814637"
                        ],
                        "name": "Berthold K. P. Horn",
                        "slug": "Berthold-K.-P.-Horn",
                        "structuredName": {
                            "firstName": "Berthold",
                            "lastName": "Horn",
                            "middleNames": [
                                "K.",
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Berthold K. P. Horn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717435"
                        ],
                        "name": "B. G. Schunck",
                        "slug": "B.-G.-Schunck",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Schunck",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. G. Schunck"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 2
                            }
                        ],
                        "text": ", [20], [25], [2]) are based on the assumption that objects in image sequences I\u00f0x; y; t\u00de retain their bright-"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1371968,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a3229dc33ecb80c59a75b906c46b586dd059b781",
            "isKey": false,
            "numCitedBy": 11344,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "Optical flow cannot be computed locally, since only one independent measurement is available from the image sequence at a point, while the flow velocity has two components. A second constraint is needed. A method for finding the optical flow pattern is presented which assumes that the apparent velocity of the brightness pattern varies smoothly almost everywhere in the image. An iterative implementation is shown which successfully computes the optical flow for a number of synthetic image sequences. The algorithm is robust in that it can handle image sequences that are quantized rather coarsely in space and time. It is also insensitive to quantization of brightness levels and additive noise. Examples are included where the assumption of smoothness is violated at singular points or along lines in the image."
            },
            "slug": "Determining-Optical-Flow-Horn-Schunck",
            "title": {
                "fragments": [],
                "text": "Determining Optical Flow"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An iterative implementation is shown which successfully computes the optical flow for a number of synthetic image sequences and is robust in that it can handle image sequences that are quantified rather coarsely in space and time."
            },
            "venue": {
                "fragments": [],
                "text": "Other Conferences"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145833095"
                        ],
                        "name": "S. Kothari",
                        "slug": "S.-Kothari",
                        "structuredName": {
                            "firstName": "Suresh",
                            "lastName": "Kothari",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kothari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681982"
                        ],
                        "name": "H. Oh",
                        "slug": "H.-Oh",
                        "structuredName": {
                            "firstName": "Heekuck",
                            "lastName": "Oh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Oh"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 104
                            }
                        ],
                        "text": "For the optimization of the cost function (21), we developed a stochastic version of Newton\u2019s algorithm [5] similar to stochastic gradient descent [32], [37], [22]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 47
                            }
                        ],
                        "text": "We therefore ignore off-diagonal elements (see [5]) of H and set H 1 diag\u00f01=Hi;i\u00de."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 177751,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dbc0a468ab103ae29717703d4aa9f682f6a2b664",
            "isKey": false,
            "numCitedBy": 15339,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Neural-Networks-for-Pattern-Recognition-Kothari-Oh",
            "title": {
                "fragments": [],
                "text": "Neural Networks for Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Adv. Comput."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144784290"
                        ],
                        "name": "T. Ertl",
                        "slug": "T.-Ertl",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Ertl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Ertl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60744504,
            "fieldsOfStudy": [
                "Education",
                "Art"
            ],
            "id": "459d0724afbcd591edde2dcc83e5e2750d878c0e",
            "isKey": false,
            "numCitedBy": 2423,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "These are the short notes for a two hour tutorial on principles and practice of computer graphics and scientific visualization. They are intended to summarize the contents of the tutorial transparencies and slides but they cannot completely replace them since restrictions in space and print quality do not permit the inclusion of figures and example images. For further reference the following standard text should be consulted: [3, 8, 5, 1, 6, 2, 9]"
            },
            "slug": "Computer-graphics\u2014principles-and-practice-Ertl",
            "title": {
                "fragments": [],
                "text": "Computer graphics\u2014principles and practice"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "These are the short notes for a two hour tutorial on principles and practice of computer graphics and scientific visualization and they cannot completely replace the contents of the tutorial transparencies and slides since restrictions in space and print quality do not permit the inclusion of figures and example images."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35674406"
                        ],
                        "name": "Shigeo Abe DrEng",
                        "slug": "Shigeo-Abe-DrEng",
                        "structuredName": {
                            "firstName": "Shigeo",
                            "lastName": "DrEng",
                            "middleNames": [
                                "Abe"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shigeo Abe DrEng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9384346,
            "fieldsOfStudy": [
                "Mathematics",
                "Environmental Science"
            ],
            "id": "65a69968bb8c41aad0113cec4c2d981bddf50bc8",
            "isKey": false,
            "numCitedBy": 13095,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Classification \u2022 Supervised \u2013 parallelpiped \u2013 minimum distance \u2013 maximum likelihood (Bayes Rule) > non-parametric > parametric \u2013 support vector machines \u2013 neural networks \u2013 context classification \u2022 Unsupervised (clustering) \u2013 K-Means \u2013 ISODATA \u2022 Pattern recognition in remote sensing has been based on the intuitive notion that pixels belonging to the same class should have similar gray values in a given band. \u2013 Given two spectral bands, pixels from the same class plotted in a two-dimensional histogram should appear as a localized cluster. \u2013 If n images, each in a different spectral band, are available, pixels from the same class should form a localized cluster in n-space."
            },
            "slug": "Pattern-Classification-DrEng",
            "title": {
                "fragments": [],
                "text": "Pattern Classification"
            },
            "venue": {
                "fragments": [],
                "text": "Springer London"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750195"
                        ],
                        "name": "E. Trucco",
                        "slug": "E.-Trucco",
                        "structuredName": {
                            "firstName": "Emanuele",
                            "lastName": "Trucco",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Trucco"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60788031,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0ab81a64aa4f5a9099e2099cd3fffbe21e5bcbb1",
            "isKey": false,
            "numCitedBy": 1741,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Computer and Robot Vision Vol. 1, by R.M. Haralick and Linda G. Shapiro, Addison-Wesley, 1992, ISBN 0-201-10887-1."
            },
            "slug": "Computer-and-Robot-Vision-Trucco",
            "title": {
                "fragments": [],
                "text": "Computer and Robot Vision"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2256718"
                        ],
                        "name": "W. Press",
                        "slug": "W.-Press",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Press",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Press"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48590121"
                        ],
                        "name": "S. Teukolsky",
                        "slug": "S.-Teukolsky",
                        "structuredName": {
                            "firstName": "Saul",
                            "lastName": "Teukolsky",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Teukolsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2608024"
                        ],
                        "name": "W. Vetterling",
                        "slug": "W.-Vetterling",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Vetterling",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Vetterling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35046585"
                        ],
                        "name": "B. Flannery",
                        "slug": "B.-Flannery",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Flannery",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Flannery"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Decomposition [ 31 ] of A. The eigenvalues of C, 2 S;1 2 S;2 . . . , are the variances of the data along each"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "To compute vs, we apply Conjugate Gradient Descent [ 31 ] to minimize the energy"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61769312,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "ca2832d2c30287a9ee5b8584cc498d2b1cb14753",
            "isKey": false,
            "numCitedBy": 16689,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Note: Includes bibliographical references, 3 appendixes and 2 indexes.- Diskette v 2.06, 3.5''[1.44M] for IBM PC, PS/2 and compatibles [DOS] Reference Record created on 2004-09-07, modified on 2016-08-08"
            },
            "slug": "Numerical-recipes-in-C-Press-Teukolsky",
            "title": {
                "fragments": [],
                "text": "Numerical recipes in C"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The Diskette v 2.06, 3.5''[1.44M] for IBM PC, PS/2 and compatibles [DOS] Reference Record created on 2004-09-07, modified on 2016-08-08."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 62
                            }
                        ],
                        "text": "In order to deal with large displacements v, the\nalgorithm of Bergen and Hingorani [2] employs a coarse-\nto-fine strategy using Gaussian pyramids of downsampled\nimages: With the gradient-based method described above,\nthe algorithm computes the flow field on the lowest level of\nresolution and refines it on each subsequent level."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 34
                            }
                        ],
                        "text": "algorithm of Bergen and Hingorani [2] employs a coarse-"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 64
                            }
                        ],
                        "text": "each neighborhood R\u00f0x0; y0\u00de, and the following expression [25], [2] is minimized in each point \u00f0x0; y0\u00de:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 14
                            }
                        ],
                        "text": ", [20], [25], [2]) are based on the assumption that objects in image sequences I\u00f0x; y; t\u00de retain their bright-"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hierarchical Motion-Based Frame Rate Conversion"
            },
            "venue": {
                "fragments": [],
                "text": "Princeton N.J"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113881386"
                        ],
                        "name": "M. Turk",
                        "slug": "M.-Turk",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Turk",
                            "middleNames": [
                                "R",
                                "obert"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Turk"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Face recognition, shape estimation, deformable model, 3D faces, pose invariance, illumination invariance."
                    },
                    "intents": []
                }
            ],
            "corpusId": 203705211,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "71d67283157475c4e6460c52408c00e9f6b8d2fe",
            "isKey": false,
            "numCitedBy": 2357,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-morphable-model-for-the-synthesis-of-3D-faces-Turk",
            "title": {
                "fragments": [],
                "text": "A morphable model for the synthesis of 3D faces"
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH 1999"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769645503"
                        ],
                        "name": "M. Carter",
                        "slug": "M.-Carter",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Carter",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Carter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122687088,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "319bef16b09502a4c6d374a947ad74006cc1cda2",
            "isKey": false,
            "numCitedBy": 3354,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Computer-graphics:-Principles-and-practice-Carter",
            "title": {
                "fragments": [],
                "text": "Computer graphics: Principles and practice"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1397917251"
                        ],
                        "name": "A. Kuijpers-Jagtman",
                        "slug": "A.-Kuijpers-Jagtman",
                        "structuredName": {
                            "firstName": "Anne",
                            "lastName": "Kuijpers-Jagtman",
                            "middleNames": [
                                "Marie"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kuijpers-Jagtman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 40027174,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "3627e41136a1435e0d7f6cd1959d48f6a4d06c02",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "[Illuminating-the-face].-Kuijpers-Jagtman",
            "title": {
                "fragments": [],
                "text": "[Illuminating the face]."
            },
            "venue": {
                "fragments": [],
                "text": "Nederlands tijdschrift voor tandheelkunde"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067074196"
                        ],
                        "name": "V. Blanz",
                        "slug": "V.-Blanz",
                        "structuredName": {
                            "firstName": "Volker",
                            "lastName": "Blanz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Blanz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 85
                            }
                        ],
                        "text": "An alternative measure for similarity is the cosine of the angle between two vectors [6], [27]: dA 1\u20444 c1;c2 h i c1 k k c2 k k ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1810275,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "22c338e544fab36d3fcdab64af8265684403c9ad",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Automatische-Rekonstruktion-der-dreidimensionalen-Blanz",
            "title": {
                "fragments": [],
                "text": "Automatische Rekonstruktion der dreidimensionalen Form von Gesichtern aus einem Einzelbild"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Face recognition, shape estimation, deformable model, 3D faces, pose invariance, illumination invariance."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 23
                            }
                        ],
                        "text": "To obtain a separate parameter for orientation, some methods parameterize the manifold formed by different views of an individual within the eigenspace of images [16], or define separate view-based eigenspaces [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face Recognition from One Model View"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Fifth Int'l Conf. Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Face recognition, shape estimation, deformable model, 3D faces, pose invariance, illumination invariance."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical Approach to Shape from Shading: Reconstruction of 3D Face Surfaces from Single 2D Images"
            },
            "venue": {
                "fragments": [],
                "text": "Computation in Neurological Systems"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 112
                            }
                        ],
                        "text": "Two-dimensional face models represent gray values and their image locations independently [3], [4], [18], [23], [13], [22]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face Recogition Using Active Appearance Models"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Conf. Computer Vision (ECCV '98)"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "For more information on this or any computing topic, please visit our Digital Library at http://computer.org/publications/dlib"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "NISTIR 6965, Nat'l Inst. of Standards and Technology"
            },
            "venue": {
                "fragments": [],
                "text": "NISTIR 6965, Nat'l Inst. of Standards and Technology"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Face recognition, shape estimation, deformable model, 3D faces, pose invariance, illumination invariance."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "3D Face Modeling and Its Applications"
            },
            "venue": {
                "fragments": [],
                "text": "Int'l J. Pattern Recognition and Artificial Intelligence"
            },
            "year": 1996
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 16,
            "methodology": 12
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 48,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/Face-Recognition-Based-on-Fitting-a-3D-Morphable-Blanz-Vetter/6d66c98009018ac1512047e6bdfb525c35683b16?sort=total-citations"
}