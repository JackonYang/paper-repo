{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "27130718"
                        ],
                        "name": "J. F. Arias",
                        "slug": "J.-F.-Arias",
                        "structuredName": {
                            "firstName": "Juan",
                            "lastName": "Arias",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. F. Arias"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3110392"
                        ],
                        "name": "R. Kasturi",
                        "slug": "R.-Kasturi",
                        "structuredName": {
                            "firstName": "Rangachar",
                            "lastName": "Kasturi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kasturi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 28238082,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ae1e63ac7d557d9c41db93294c856a4650609828",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract. The performance of the algorithms for the extraction of primitives for the interpretation of line drawings is usually affected by the degradation of the information contained in the document due to factors such as low print contrast, defocusing, skew, etc. In this paper, we are proposing two algorithms for the extraction of primitives with good performance under degradation. The application of the algorithms is restricted to line drawings composed of horizontal and vertical lines. The performance of the algorithms has been evaluated by using a protocol described in the literature."
            },
            "slug": "Efficient-extraction-of-primitives-from-line-of-and-Arias-Kasturi",
            "title": {
                "fragments": [],
                "text": "Efficient extraction of primitives from line drawings composed of horizontal and vertical lines"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "Two algorithms for the extraction of primitives with good performance under degradation are proposed for line drawings composed of horizontal and vertical lines."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Vision and Applications"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144799688"
                        ],
                        "name": "S. Taylor",
                        "slug": "S.-Taylor",
                        "structuredName": {
                            "firstName": "Suzanne",
                            "lastName": "Taylor",
                            "middleNames": [
                                "Liebowitz"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1910723"
                        ],
                        "name": "R. Fritzson",
                        "slug": "R.-Fritzson",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Fritzson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fritzson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053009875"
                        ],
                        "name": "J. A. Pastor",
                        "slug": "J.-A.-Pastor",
                        "structuredName": {
                            "firstName": "Jon",
                            "lastName": "Pastor",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. A. Pastor"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 30846697,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4e2f122cefaaac07009361797583b41795db6ec3",
            "isKey": false,
            "numCitedBy": 57,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The widespread use of printed forms for data acquisition makes the ability to automatically read and analyze their contents desirable. The components of a forms analysis system include conversion from paper to an image through scanning, image enhancement, document identification, data extraction, and data interpretation. This paper describes techniques for manipulating electronic images of forms in preparation for data interpretation. A combination feature extraction/model-based approach is used for forms identification, registration, and field extraction. Forms identification is implemented with a neural network. The system is demonstrated on United States Internal Revenue Service forms."
            },
            "slug": "Extraction-of-data-from-preprinted-forms-Taylor-Fritzson",
            "title": {
                "fragments": [],
                "text": "Extraction of data from preprinted forms"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A combination feature extraction/model-based approach is used for forms identification, registration, and field extraction, and the system is demonstrated on United States Internal Revenue Service forms."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Vision and Applications"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1500661115"
                        ],
                        "name": "Toyohide Watanabe",
                        "slug": "Toyohide-Watanabe",
                        "structuredName": {
                            "firstName": "Toyohide",
                            "lastName": "Watanabe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Toyohide Watanabe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2074293587"
                        ],
                        "name": "Q. Luo",
                        "slug": "Q.-Luo",
                        "structuredName": {
                            "firstName": "Qin",
                            "lastName": "Luo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Luo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692608"
                        ],
                        "name": "N. Sugie",
                        "slug": "N.-Sugie",
                        "structuredName": {
                            "firstName": "Noboru",
                            "lastName": "Sugie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sugie"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 23198522,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa208b677239912cb394e5dbc6e7483a75f16ea4",
            "isKey": false,
            "numCitedBy": 140,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Many approaches have reported that knowledge-based layout recognition methods are very successful in classifying the meaningful data from document images automatically. However, these approaches are applicable to only the same kind of documents because they are based on the paradigm that specifies the structure definition information in advance so as to be able to analyze a particular class of documents intelligently. In this paper, the authors propose a method to recognize the layout structures of multi-kinds of table-form document images. For this purpose, the authors introduce a classification tree to manage the relationships among different classes of layout structures. The authors' recognition system has two modes: layout knowledge acquisition and layout structure recognition. In the layout knowledge acquisition mode, table-form document images are distinguished according to this. Classification tree and then the structure description trees which specify the logical structures of table-form documents are generated automatically. While, in the layout structure recognition mode, individual item fields in the table-form document images are extracted and classified successfully by searching the classification tree and interpreting the structure description tree. >"
            },
            "slug": "Layout-Recognition-of-Multi-Kinds-of-Table-Form-Watanabe-Luo",
            "title": {
                "fragments": [],
                "text": "Layout Recognition of Multi-Kinds of Table-Form Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The authors introduce a classification tree to manage the relationships among different classes of layout structures and propose a method to recognize the layout structures of multi-kinds of table-form document images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 3,
        "totalPages": 1
    },
    "page_url": "https://www.semanticscholar.org/paper/Methodology-of-automatic-extraction-of-table-form-Neves-Facon/e17a70ab45f372bbd3a1c3f2f4e424db387706f1?sort=total-citations"
}