{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144854796"
                        ],
                        "name": "D. Gavrila",
                        "slug": "D.-Gavrila",
                        "structuredName": {
                            "firstName": "Dariu",
                            "lastName": "Gavrila",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gavrila"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17435119,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "79036203c360174b694314adab553aa00a6aeff3",
            "isKey": false,
            "numCitedBy": 516,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a prototype system for pedestrian detection on-board a moving vehicle. The system uses a generic two-step approach for efficient object detection. In the first step, contour features are used in a hierarchical template matching approach to efficiently \"lock\" onto candidate solutions. Shape matching is based on Distance Transforms. By capturing the objects shape variability by means of a template hierarchy and using a combined coarse-to-fine approach in shape and parameter space, this method achieves very large speed-ups compared to a brute-force method. We have measured gains of several orders of magnitude. The second step utilizes the richer set of intensity features in a pattern classification approach to verify the candidate solutions (i.e. using Radial Basis Functions). We present experimental results on pedestrian detection off-line and on-board our Urban Traffic Assistant vehicle and discuss the challenges that lie ahead."
            },
            "slug": "Pedestrian-Detection-from-a-Moving-Vehicle-Gavrila",
            "title": {
                "fragments": [],
                "text": "Pedestrian Detection from a Moving Vehicle"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "This paper presents a prototype system for pedestrian detection on-board a moving vehicle that uses a generic two-step approach for efficient object detection using a hierarchical template matching approach and achieves very large speed-ups compared to a brute-force method."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688865"
                        ],
                        "name": "A. Broggi",
                        "slug": "A.-Broggi",
                        "structuredName": {
                            "firstName": "Alberto",
                            "lastName": "Broggi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Broggi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780349"
                        ],
                        "name": "M. Bertozzi",
                        "slug": "M.-Bertozzi",
                        "structuredName": {
                            "firstName": "Massimo",
                            "lastName": "Bertozzi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bertozzi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758448"
                        ],
                        "name": "A. Fascioli",
                        "slug": "A.-Fascioli",
                        "structuredName": {
                            "firstName": "Alessandra",
                            "lastName": "Fascioli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Fascioli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "92610301"
                        ],
                        "name": "M. Sechi",
                        "slug": "M.-Sechi",
                        "structuredName": {
                            "firstName": "Maria",
                            "lastName": "Sechi",
                            "middleNames": [
                                "Laura"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sechi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7701071,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "70ba53d239a455d2396fe15334e8c80774e9f95a",
            "isKey": false,
            "numCitedBy": 265,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents the method for detecting pedestrian recently implemented on the ARGO vehicle. The perception of the environment is performed through the sole processing of images acquired from a vision system installed on board of the vehicle: the analysis of a monocular image delivers a first coarse detection, while a distance refinement is performed using the stereo vision technique."
            },
            "slug": "Shape-based-pedestrian-detection-Broggi-Bertozzi",
            "title": {
                "fragments": [],
                "text": "Shape-based pedestrian detection"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "This paper presents the method for detecting pedestrian recently implemented on the ARGO vehicle: the analysis of a monocular image delivers a first coarse detection, while a distance refinement is performed using the stereo vision technique."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE Intelligent Vehicles Symposium 2000 (Cat. No.00TH8511)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9413963"
                        ],
                        "name": "P. Reisman",
                        "slug": "P.-Reisman",
                        "structuredName": {
                            "firstName": "Pini",
                            "lastName": "Reisman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Reisman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7857367"
                        ],
                        "name": "O. Mano",
                        "slug": "O.-Mano",
                        "structuredName": {
                            "firstName": "O.",
                            "lastName": "Mano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Mano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1815078"
                        ],
                        "name": "S. Avidan",
                        "slug": "S.-Avidan",
                        "structuredName": {
                            "firstName": "Shai",
                            "lastName": "Avidan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Avidan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140335"
                        ],
                        "name": "A. Shashua",
                        "slug": "A.-Shashua",
                        "structuredName": {
                            "firstName": "Amnon",
                            "lastName": "Shashua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shashua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 924642,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "50c794f5c24b4f423bfadd52629e8d94ce672625",
            "isKey": false,
            "numCitedBy": 78,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a real-time system that detects moving crowd in a video sequence. Crowd detection differs from pedestrian detection in that we assume that no individual pedestrian can be properly segmented in the image. We propose a scheme that looks at the motion patterns of crowd in the spatio-temporal domain and give an efficient implementation that can detect crowd in real-time. In our experiments we detected crowd at distances of up to 70 m."
            },
            "slug": "Crowd-detection-in-video-sequences-Reisman-Mano",
            "title": {
                "fragments": [],
                "text": "Crowd detection in video sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A scheme that looks at the motion patterns of crowd in the spatio-temporal domain and gives an efficient implementation that can detect crowd in real-time that detects moving crowd in a video sequence."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Intelligent Vehicles Symposium, 2004"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2124866301"
                        ],
                        "name": "A. Mohan",
                        "slug": "A.-Mohan",
                        "structuredName": {
                            "firstName": "Anuj",
                            "lastName": "Mohan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Mohan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145030811"
                        ],
                        "name": "C. Papageorgiou",
                        "slug": "C.-Papageorgiou",
                        "structuredName": {
                            "firstName": "Constantine",
                            "lastName": "Papageorgiou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Papageorgiou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2559322,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "448bd4e124175ad358078a7b930ecad994c97812",
            "isKey": false,
            "numCitedBy": 1137,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a general example-based framework for detecting objects in static images by components. The technique is demonstrated by developing a system that locates people in cluttered scenes. The system is structured with four distinct example-based detectors that are trained to separately find the four components of the human body: the head, legs, left arm, and right arm. After ensuring that these components are present in the proper geometric configuration, a second example-based classifier combines the results of the component detectors to classify a pattern as either a \"person\" or a \"nonperson.\" We call this type of hierarchical architecture, in which learning occurs at multiple stages, an adaptive combination of classifiers (ACC). We present results that show that this system performs significantly better than a similar full-body person detector. This suggests that the improvement in performance is due to the component-based approach and the ACC data classification architecture. The algorithm is also more robust than the full-body person detection method in that it is capable of locating partially occluded views of people and people whose body parts have little contrast with the background."
            },
            "slug": "Example-Based-Object-Detection-in-Images-by-Mohan-Papageorgiou",
            "title": {
                "fragments": [],
                "text": "Example-Based Object Detection in Images by Components"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Results suggest that the improvement in performance is due to the component-based approach and the ACC data classification architecture, which is capable of locating partially occluded views of people and people whose body parts have little contrast with the background."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3019042"
                        ],
                        "name": "G. Stein",
                        "slug": "G.-Stein",
                        "structuredName": {
                            "firstName": "Gideon",
                            "lastName": "Stein",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Stein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7857367"
                        ],
                        "name": "O. Mano",
                        "slug": "O.-Mano",
                        "structuredName": {
                            "firstName": "O.",
                            "lastName": "Mano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Mano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140335"
                        ],
                        "name": "A. Shashua",
                        "slug": "A.-Shashua",
                        "structuredName": {
                            "firstName": "Amnon",
                            "lastName": "Shashua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shashua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14937027,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cbc7c12b970d9b3e9b81bc4666e22da33cb3b1b9",
            "isKey": false,
            "numCitedBy": 218,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a vision-based adaptive cruise control (ACC) system which uses a single camera as input. In particular, we discuss how to compute the range and range-rate from a single camera and discuss how the imaging geometry affects the range and range rate accuracy. We determine the bound on the accuracy given a particular configuration. These bounds in turn determine what steps must be made to achieve good performance. The system has been implemented on a test vehicle and driven on various highways over thousands of miles."
            },
            "slug": "Vision-based-ACC-with-a-single-camera:-bounds-on-Stein-Mano",
            "title": {
                "fragments": [],
                "text": "Vision-based ACC with a single camera: bounds on range and range rate accuracy"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The range and range-rate from a single camera is discussed and the bound on the accuracy given a particular configuration is determined, which determines what steps must be made to achieve good performance."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE IV2003 Intelligent Vehicles Symposium. Proceedings (Cat. No.03TH8683)"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145496686"
                        ],
                        "name": "E. Dagan",
                        "slug": "E.-Dagan",
                        "structuredName": {
                            "firstName": "E.",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Dagan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7857367"
                        ],
                        "name": "O. Mano",
                        "slug": "O.-Mano",
                        "structuredName": {
                            "firstName": "O.",
                            "lastName": "Mano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Mano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3019042"
                        ],
                        "name": "G. Stein",
                        "slug": "G.-Stein",
                        "structuredName": {
                            "firstName": "Gideon",
                            "lastName": "Stein",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Stein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140335"
                        ],
                        "name": "A. Shashua",
                        "slug": "A.-Shashua",
                        "structuredName": {
                            "firstName": "Amnon",
                            "lastName": "Shashua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shashua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11293317,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f7bd22e40b75b60cb7cc386af6a8906e7c60371d",
            "isKey": false,
            "numCitedBy": 277,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The large number of rear end collisions due to driver inattention has been identified as a major automotive safety issue. Even a short advance warning can significantly reduce the number and severity of the collisions. This paper describes a vision based forward collision warning (FCW) system for highway safety. The algorithm described in this paper computes time to contact (TTC) and possible collision course directly from the size and position of the vehicles in the image - which are the natural measurements for a vision based system - without having to compute a 3D representation of the scene. The use of a single low cost image sensor results in an affordable system which is simple to install. The system has been implemented on real-time hardware and has been test driven on highways. Collision avoidance tests have also been performed on test tracks."
            },
            "slug": "Forward-collision-warning-with-a-single-camera-Dagan-Mano",
            "title": {
                "fragments": [],
                "text": "Forward collision warning with a single camera"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A vision based forward collision warning system for highway safety that computes time to contact (TTC) and possible collision course directly from the size and position of the vehicles in the image - which are the natural measurements for a vision based system - without having to compute a 3D representation of the scene."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Intelligent Vehicles Symposium, 2004"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145328018"
                        ],
                        "name": "M. Oren",
                        "slug": "M.-Oren",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Oren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Oren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145030811"
                        ],
                        "name": "C. Papageorgiou",
                        "slug": "C.-Papageorgiou",
                        "structuredName": {
                            "firstName": "Constantine",
                            "lastName": "Papageorgiou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Papageorgiou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46597039"
                        ],
                        "name": "P. Sinha",
                        "slug": "P.-Sinha",
                        "structuredName": {
                            "firstName": "Pawan",
                            "lastName": "Sinha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sinha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781874"
                        ],
                        "name": "E. Osuna",
                        "slug": "E.-Osuna",
                        "structuredName": {
                            "firstName": "Edgar",
                            "lastName": "Osuna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Osuna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[2], [6], [8], [12]) with published performance figures."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "ferent window size of 64\u00d7 128 suggests that high detailed pictures of pedestrians were used as opposed to the often impoverished images our system must handle, (iv) training and test sets in [12] cover only rear and front poses whereas in our case all poses are covered, and (v) it is unclear what level of variability (i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "For example, [12] applies a global SVM on windows of size 64 \u00d7 128 and reports a detection rate of 81."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "ROC curves of three classifiers: our classifier is the top curve, the global SVM classifer [12] is the middle curve, and the 2-stage SVM classifier [8] is the bottom curve."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "the test set in [12] consisted of 165 positive examples only, (ii) negative examples were generated by systematically scanning the image \u2014 therefore many of the negative examples were \u201dvery easy\u201d, as opposed to the negative examples generated by our attention mechanism, (iii) dif-"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "2 corresponds to a quadratic polynomial classifier trained using SVM (with the quadratic kernel function) using the procedure described in [12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7967646,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bd0534a87e09b3d64b7e7462e2684c60c9aca1f5",
            "isKey": true,
            "numCitedBy": 837,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a trainable object detection architecture that is applied to detecting people in static images of cluttered scenes. This problem poses several challenges. People are highly non-rigid objects with a high degree of variability in size, shape, color, and texture. Unlike previous approaches, this system learns from examples and does not rely on any a priori (hand-crafted) models or on motion. The detection technique is based on the novel idea of the wavelet template that defines the shape of an object in terms of a subset of the wavelet coefficients of the image. It is invariant to changes in color and texture and can be used to robustly define a rich and complex class of objects such as people. We show how the invariant properties and computational efficiency of the wavelet template make it an effective tool for object detection."
            },
            "slug": "Pedestrian-detection-using-wavelet-templates-Oren-Papageorgiou",
            "title": {
                "fragments": [],
                "text": "Pedestrian detection using wavelet templates"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This paper presents a trainable object detection architecture that is applied to detecting people in static images of cluttered scenes and shows how the invariant properties and computational efficiency of the wavelet template make it an effective tool for object detection."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "88836465"
                        ],
                        "name": "R. Okada",
                        "slug": "R.-Okada",
                        "structuredName": {
                            "firstName": "Ryuzo",
                            "lastName": "Okada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Okada"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3093666"
                        ],
                        "name": "Y. Taniguchi",
                        "slug": "Y.-Taniguchi",
                        "structuredName": {
                            "firstName": "Yasuhiro",
                            "lastName": "Taniguchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Taniguchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49441359"
                        ],
                        "name": "K. Furukawa",
                        "slug": "K.-Furukawa",
                        "structuredName": {
                            "firstName": "Kenji",
                            "lastName": "Furukawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Furukawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34621875"
                        ],
                        "name": "K. Onoguchi",
                        "slug": "K.-Onoguchi",
                        "structuredName": {
                            "firstName": "Kazunori",
                            "lastName": "Onoguchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Onoguchi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2208382,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "333ca457fa45293ec0325ab4705489f0af56bb72",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel method for detecting vehicles as obstacles in various road scenes using a single onboard camera. Vehicles are detected by testing whether the motion of a set of three horizontal line segments, which are always on the vehicles, satisfies the motion constraint of the ground plane or that of the surface plane of the vehicles. The motion constraint of each plane is derived from the projective invariant combined with the vanishing line of the plane that is a prior knowledge of road scenes. The proposed method is implemented into a newly developed onboard LSI. Experimental results for real road scenes under various conditions show the effectiveness of the proposed method."
            },
            "slug": "Obstacle-detection-using-projective-invariant-and-Okada-Taniguchi",
            "title": {
                "fragments": [],
                "text": "Obstacle detection using projective invariant and vanishing lines"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A novel method for detecting vehicles as obstacles in various road scenes using a single onboard camera using the projective invariant combined with the vanishing line of the plane that is a prior knowledge of road scenes."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3019042"
                        ],
                        "name": "G. Stein",
                        "slug": "G.-Stein",
                        "structuredName": {
                            "firstName": "Gideon",
                            "lastName": "Stein",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Stein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7857367"
                        ],
                        "name": "O. Mano",
                        "slug": "O.-Mano",
                        "structuredName": {
                            "firstName": "O.",
                            "lastName": "Mano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Mano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140335"
                        ],
                        "name": "A. Shashua",
                        "slug": "A.-Shashua",
                        "structuredName": {
                            "firstName": "Amnon",
                            "lastName": "Shashua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shashua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17155135,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fd0e3bde64ea33afc8d39ab19351e2ac3748430c",
            "isKey": false,
            "numCitedBy": 142,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a robust method for computing the ego-motion of the vehicle relative to the road using input from a single camera mounted next to the rear view mirror. Since feature points are unreliable in cluttered scenes we use direct methods where image values in the two images are combined in a global probability function. Combined with the use of probability distribution matrices, this enables the formulation of a robust method that can ignore large number of outliers as one would encounter in real traffic situations. The method has been tested in real world environments and has been shown to be robust to glare, rain and moving objects in the scene."
            },
            "slug": "A-robust-method-for-computing-vehicle-ego-motion-Stein-Mano",
            "title": {
                "fragments": [],
                "text": "A robust method for computing vehicle ego-motion"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A robust method for computing the ego-motion of the vehicle relative to the road using input from a single camera mounted next to the rear view mirror, which has been tested in real world environments and has been shown to be robust to glare, rain and moving objects in the scene."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE Intelligent Vehicles Symposium 2000 (Cat. No.00TH8511)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39668247"
                        ],
                        "name": "A. Berg",
                        "slug": "A.-Berg",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Berg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10771328"
                        ],
                        "name": "Greg Mori",
                        "slug": "Greg-Mori",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Mori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Greg Mori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The accuracy requirements of the final decision depends on the location of the pedestrian and whether the pedestrian is stationary or moving laterally (inwards towards the host vehicle path)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1350374,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "804d86dd7ab3498266922244e73a88c1add5a6ab",
            "isKey": false,
            "numCitedBy": 1470,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Our goal is to recognize human action at a distance, at resolutions where a whole person may be, say, 30 pixels tall. We introduce a novel motion descriptor based on optical flow measurements in a spatiotemporal volume for each stabilized human figure, and an associated similarity measure to be used in a nearest-neighbor framework. Making use of noisy optical flow measurements is the key challenge, which is addressed by treating optical flow not as precise pixel displacements, but rather as a spatial pattern of noisy measurements which are carefully smoothed and aggregated to form our spatiotemporal motion descriptor. To classify the action being performed by a human figure in a query sequence, we retrieve nearest neighbor(s) from a database of stored, annotated video sequences. We can also use these retrieved exemplars to transfer 2D/3D skeletons onto the figures in the query sequence, as well as two forms of data-based action synthesis \"do as I do\" and \"do as I say\". Results are demonstrated on ballet, tennis as well as football datasets."
            },
            "slug": "Recognizing-action-at-a-distance-Efros-Berg",
            "title": {
                "fragments": [],
                "text": "Recognizing action at a distance"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A novel motion descriptor based on optical flow measurements in a spatiotemporal volume for each stabilized human figure is introduced, and an associated similarity measure to be used in a nearest-neighbor framework is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145952419"
                        ],
                        "name": "Ross Cutler",
                        "slug": "Ross-Cutler",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Cutler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross Cutler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693428"
                        ],
                        "name": "L. Davis",
                        "slug": "L.-Davis",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Davis",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Davis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1940219,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4e628aa75f319acf3c5b7f5108d80feb2c69fbb5",
            "isKey": false,
            "numCitedBy": 784,
            "numCiting": 82,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe new techniques to detect and analyze periodic motion as seen from both a static and a moving camera. By tracking objects of interest, we compute an object's self-similarity as it evolves in time. For periodic motion, the self-similarity measure is also periodic and we apply time-frequency analysis to detect and characterize the periodic motion. The periodicity is also analyzed robustly using the 2D lattice structures inherent in similarity matrices. A real-time system has been implemented to track and classify objects using periodicity. Examples of object classification (people, running dogs, vehicles), person counting, and nonstationary periodicity are provided."
            },
            "slug": "Robust-Real-Time-Periodic-Motion-Detection,-and-Cutler-Davis",
            "title": {
                "fragments": [],
                "text": "Robust Real-Time Periodic Motion Detection, Analysis, and Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "New techniques to detect and analyze periodic motion as seen from both a static and a moving camera are described and the periodicity is analyzed robustly using the 2D lattice structures inherent in similarity matrices."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2219581"
                        ],
                        "name": "B. Boser",
                        "slug": "B.-Boser",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Boser",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Boser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743797"
                        ],
                        "name": "I. Guyon",
                        "slug": "I.-Guyon",
                        "structuredName": {
                            "firstName": "Isabelle",
                            "lastName": "Guyon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Guyon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207165665,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2599131a4bc2fa957338732a37c744cfe3e17b24",
            "isKey": false,
            "numCitedBy": 10840,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "A training algorithm that maximizes the margin between the training patterns and the decision boundary is presented. The technique is applicable to a wide variety of the classification functions, including Perceptrons, polynomials, and Radial Basis Functions. The effective number of parameters is adjusted automatically to match the complexity of the problem. The solution is expressed as a linear combination of supporting patterns. These are the subset of training patterns that are closest to the decision boundary. Bounds on the generalization performance based on the leave-one-out method and the VC-dimension are given. Experimental results on optical character recognition problems demonstrate the good generalization obtained when compared with other learning algorithms."
            },
            "slug": "A-training-algorithm-for-optimal-margin-classifiers-Boser-Guyon",
            "title": {
                "fragments": [],
                "text": "A training algorithm for optimal margin classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A training algorithm that maximizes the margin between the training patterns and the decision boundary is presented, applicable to a wide variety of the classification functions, including Perceptrons, polynomials, and Radial Basis Functions."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '92"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644050191"
                        ],
                        "name": "G. LoweDavid",
                        "slug": "G.-LoweDavid",
                        "structuredName": {
                            "firstName": "G",
                            "lastName": "LoweDavid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. LoweDavid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 174065,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4cab9c4b571761203ed4c3a4c5a07dd615f57a91",
            "isKey": false,
            "numCitedBy": 25504,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are ..."
            },
            "slug": "Distinctive-Image-Features-from-Scale-Invariant-LoweDavid",
            "title": {
                "fragments": [],
                "text": "Distinctive Image Features from Scale-Invariant Keypoints"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703537"
                        ],
                        "name": "Y. Freund",
                        "slug": "Y.-Freund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Freund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1836349,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "68c1bfe375dde46777fe1ac8f3636fb651e3f0f8",
            "isKey": false,
            "numCitedBy": 8626,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "In an earlier paper, we introduced a new \"boosting\" algorithm called AdaBoost which, theoretically, can be used to significantly reduce the error of any learning algorithm that con- sistently generates classifiers whose performance is a little better than random guessing. We also introduced the related notion of a \"pseudo-loss\" which is a method for forcing a learning algorithm of multi-label concepts to concentrate on the labels that are hardest to discriminate. In this paper, we describe experiments we carried out to assess how well AdaBoost with and without pseudo-loss, performs on real learning problems. We performed two sets of experiments. The first set compared boosting to Breiman's \"bagging\" method when used to aggregate various classifiers (including decision trees and single attribute- value tests). We compared the performance of the two methods on a collection of machine-learning benchmarks. In the second set of experiments, we studied in more detail the performance of boosting using a nearest-neighbor classifier on an OCR problem."
            },
            "slug": "Experiments-with-a-New-Boosting-Algorithm-Freund-Schapire",
            "title": {
                "fragments": [],
                "text": "Experiments with a New Boosting Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper describes experiments carried out to assess how well AdaBoost with and without pseudo-loss, performs on real learning problems and compared boosting to Breiman's \"bagging\" method when used to aggregate various classifiers."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140335"
                        ],
                        "name": "A. Shashua",
                        "slug": "A.-Shashua",
                        "structuredName": {
                            "firstName": "Amnon",
                            "lastName": "Shashua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shashua"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145587209"
                        ],
                        "name": "N. Navab",
                        "slug": "N.-Navab",
                        "structuredName": {
                            "firstName": "Nassir",
                            "lastName": "Navab",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Navab"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206418573,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "26791051de2c8952ef28925ba0dc045ce05ac0c5",
            "isKey": false,
            "numCitedBy": 125,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose an affine framework for perspective views, captured by a single extremely simple equation based on a viewer-centered invariant we call relative affine structure. Via a number of corollaries of our main results we show that our framework unifies previous work-including Euclidean, projective and affine-in a natural and simple way, and introduces new, extremely simple algorithms for the tasks of reconstruction from multiple views, recognition by alignment, and certain image coding applications."
            },
            "slug": "Relative-Affine-Structure:-Canonical-Model-for-3D-Shashua-Navab",
            "title": {
                "fragments": [],
                "text": "Relative Affine Structure: Canonical Model for 3D From 2D Geometry and Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This work proposes an affine framework for perspective views, captured by a single extremely simple equation based on a viewer-centered invariant the authors call relative affine structure, and introduces new, extremely simple algorithms for the tasks of reconstruction from multiple views, recognition by alignment, and certain image coding applications."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32183271"
                        ],
                        "name": "A. E. Hoerl",
                        "slug": "A.-E.-Hoerl",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Hoerl",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. E. Hoerl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "94158926"
                        ],
                        "name": "R. Kennard",
                        "slug": "R.-Kennard",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Kennard",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kennard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 28142999,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "1473110f6c33b483251ade10b79416d3efee2da4",
            "isKey": false,
            "numCitedBy": 4991,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "In multiple regression it is shown that parameter estimates based on minimum residual sum of squares have a high probability of being unsatisfactory, if not incorrect, if the prediction vectors are not orthogonal. Proposed is an estimation procedure based on adding small positive quantities to the diagonal of X\u2032X. Introduced is the ridge trace, a method for showing in two dimensions the effects of nonorthogonality. It is then shown how to augment X\u2032X to obtain biased estimates with smaller mean square error."
            },
            "slug": "Ridge-Regression:-Biased-Estimation-for-Problems-Hoerl-Kennard",
            "title": {
                "fragments": [],
                "text": "Ridge Regression: Biased Estimation for Nonorthogonal Problems"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The ridge trace is introduced is the ridge trace, a method for showing in two dimensions the effects of nonorthogonality, and how to augment X\u2032X to obtain biased estimates with smaller mean square error."
            },
            "venue": {
                "fragments": [],
                "text": "Technometrics"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "S"
            },
            "venue": {
                "fragments": [],
                "text": "Avidan and A. Shashua. Crowd Detection in Video Sequences In  IEEE Intelligent Vehicles Symposium "
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Poggio Pedestrian detection using wavelet templates"
            },
            "venue": {
                "fragments": [],
                "text": "Cornputer Vision and Parrem Recognition (CVPR)"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Robust Real-Time Periodic Motion Detection, Analysis and Application"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans Putt. An. Mach. Int"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 56
                            }
                        ],
                        "text": "both dynamically (change of position of legs over time) [3], [17], [4] and statically (position of legs in a single frame)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Robust Real-Time Periodic Motion Detection, Analysis and Application\u201dIEEE"
            },
            "venue": {
                "fragments": [],
                "text": "Trans Patt. An. Mach. Int., ,"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Kennard. Ridge regression: Biased estimation for nonorthogonal problems. Tecbnometrics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 121
                            }
                        ],
                        "text": "The four basic steps above are also coupled with supporting functions such as host vehicle ego-motion (of Yaw and Pitch) [14], close range motion segmentation (for extracting strong inward motion regardless of shape classification), robust tracking (which can handle non-rigid motion and occlusions induced by pedestrians crossing each other) \u2014 and of primary importance the classification scores of background sub-classes which include licensed vehicles, poles, guard-rails, repetitive texture, lane mark interpretation, bridges and other man-made horizontal structures, and pedestrian walking zone areas."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 73
                            }
                        ],
                        "text": "periodicity, (ii) inward motion analysis scores (coupled with ego-motion [14]), (iii) motion parallax (when available), (iv) consistency measure of the single-frame classifier over time, and (v) tracking quality measures."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "O"
            },
            "venue": {
                "fragments": [],
                "text": "Mano and A. Shashua. A Robust Method for Computing Vehicle Ego-motion InIEEE Intelligent Vehicles Symposium "
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 67
                            }
                        ],
                        "text": "both dynamically (change of position of legs over time) [3], [17], [4] and statically (position of legs in a single frame)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "G"
            },
            "venue": {
                "fragments": [],
                "text": "Mori and J. Malik \u201cRecognizing Action at a Distance\u201dIEEE International Conference on Computer Vision (ICCV)  , pp. 726-733"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "E"
            },
            "venue": {
                "fragments": [],
                "text": "Dagan and A. Shashua. Forward Collision Warning with a Single Camera InEEE Intelligent Vehicles Symposium "
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Robust Real - Time Periodic Motion Detection , Analysis and Application"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans Putt . An . Mach . Int ."
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Crowd Detection in Video Sequences In IEEE Intelligent Vehicles Symposium (IV2004)"
            },
            "venue": {
                "fragments": [],
                "text": "Crowd Detection in Video Sequences In IEEE Intelligent Vehicles Symposium (IV2004)"
            },
            "year": 2004
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 5,
            "methodology": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 26,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Pedestrian-detection-for-driving-assistance-and-Shashua-Gdalyahu/37a15ce03c26ec83d95bf4aaf756a41370d50353?sort=total-citations"
}