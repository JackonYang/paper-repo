{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691986"
                        ],
                        "name": "P. Phillips",
                        "slug": "P.-Phillips",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Phillips",
                            "middleNames": [
                                "Jonathon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40638847"
                        ],
                        "name": "Hyeonjoon Moon",
                        "slug": "Hyeonjoon-Moon",
                        "structuredName": {
                            "firstName": "Hyeonjoon",
                            "lastName": "Moon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hyeonjoon Moon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2958806"
                        ],
                        "name": "S. A. Rizvi",
                        "slug": "S.-A.-Rizvi",
                        "structuredName": {
                            "firstName": "Syed",
                            "lastName": "Rizvi",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. A. Rizvi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3313513"
                        ],
                        "name": "Patrick J. Rauss",
                        "slug": "Patrick-J.-Rauss",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Rauss",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Patrick J. Rauss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 497801,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "791e530f6a4098bb39696d1476032821a7a1c569",
            "isKey": false,
            "numCitedBy": 2334,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Two of the most critical requirements in support of producing reliable face-recognition systems are a large database of facial images and a testing procedure to evaluate systems. The Face Recognition Technology (FERET) program has addressed both issues through the FERET database of facial images and the establishment of the FERET tests. To date, 14,126 images from 1199 individuals are included in the FERET database, which is divided into development and sequestered portions. In September 1996, the FERET program administered the third in a series of FERET face-recognition tests. The primary objectives of the third test were to (1) assess the state of the art, (2) identify future areas of research, and (3) measure algorithm performance on large databases."
            },
            "slug": "The-FERET-evaluation-methodology-for-algorithms-Phillips-Moon",
            "title": {
                "fragments": [],
                "text": "The FERET evaluation methodology for face-recognition algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Two of the most critical requirements in support of producing reliable face-recognition systems are a large database of facial images and a testing procedure to evaluate systems."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691986"
                        ],
                        "name": "P. Phillips",
                        "slug": "P.-Phillips",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Phillips",
                            "middleNames": [
                                "Jonathon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3313513"
                        ],
                        "name": "Patrick J. Rauss",
                        "slug": "Patrick-J.-Rauss",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Rauss",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Patrick J. Rauss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3231915"
                        ],
                        "name": "S. Der",
                        "slug": "S.-Der",
                        "structuredName": {
                            "firstName": "Sandor",
                            "lastName": "Der",
                            "middleNames": [
                                "Z."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Der"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14238832,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "39577ba5d7020bc1750b3a417b7d6432ebb7f00c",
            "isKey": false,
            "numCitedBy": 158,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : As part of the Face Recognition Technology (FERET) program, the U.S. Army Research Laboratory (ARL) conducted supervised government tests and evaluations of automatic face recognition algorithms. The goal of the tests was to provide an independent method of evaluating algorithms and assessing the state of the art in automatic face recognition. This report describes the design and presents the results of the August 1994 and March 1995 FERET tests. Results for FERET tests administered by ARL between August 1994 and August 1996 are reported."
            },
            "slug": "FERET-(Face-Recognition-Technology)-Recognition-and-Phillips-Rauss",
            "title": {
                "fragments": [],
                "text": "FERET (Face Recognition Technology) Recognition Algorithm Development and Test Results."
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The design and results of the August 1994 and March 1995 FERET tests are described and the goal was to provide an independent method of evaluating algorithms and assessing the state of the art in automatic face recognition."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145699982"
                        ],
                        "name": "S. Gutta",
                        "slug": "S.-Gutta",
                        "structuredName": {
                            "firstName": "Srinivas",
                            "lastName": "Gutta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gutta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152292143"
                        ],
                        "name": "Jeffrey R. Huang",
                        "slug": "Jeffrey-R.-Huang",
                        "structuredName": {
                            "firstName": "Jeffrey R.",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeffrey R. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47204595"
                        ],
                        "name": "D. Singh",
                        "slug": "D.-Singh",
                        "structuredName": {
                            "firstName": "Dig",
                            "lastName": "Singh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Singh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50608273"
                        ],
                        "name": "Imran Shah",
                        "slug": "Imran-Shah",
                        "structuredName": {
                            "firstName": "Imran",
                            "lastName": "Shah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Imran Shah"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34948290"
                        ],
                        "name": "B. Tak\u00e1cs",
                        "slug": "B.-Tak\u00e1cs",
                        "structuredName": {
                            "firstName": "Barnab\u00e1s",
                            "lastName": "Tak\u00e1cs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Tak\u00e1cs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143979395"
                        ],
                        "name": "H. Wechsler",
                        "slug": "H.-Wechsler",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Wechsler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wechsler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 12553705,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "51a55cdc165952d0dc99b4fe71f0e88ec977d5aa",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe herein benchmark studies aimed at advancing the state-of-the-art in automated face recognition. We address three complementary problems: (A) development of a representative data base set of facial images to train, test, and evaluate alternative face recognition schemes; (B) bench marking of both simple but well known algorithms, and of novel automated and integrated face recognition schemes; and (C) training and testing of human subjects to evaluate human performance using the same data base developed to test the automated face recognition component. The major results of our R&D program indicate that (i) future advances in automated face recognition are predicated on the development of hybrid recognition systems, (ii) that holistic (connectionist) methods outperform discrete (and direct) feature and correlation methods, (iii) that if the test beds are random and contextual cues are lacking human performance is quite poor, not consistent, and degrades rapidly when compared with machine performance, and (iv) that extensive and proper testing is crucial for bench marking."
            },
            "slug": "Benchmark-Studies-on-Face-Recognition-Gutta-Huang",
            "title": {
                "fragments": [],
                "text": "Benchmark Studies on Face Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "The major results of the R&D program indicate that future advances in automated face recognition are predicated on the development of hybrid recognition systems, and that holistic (connectionist) methods outperform discrete (and direct) feature and correlation methods."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40302807"
                        ],
                        "name": "G. Gordon",
                        "slug": "G.-Gordon",
                        "structuredName": {
                            "firstName": "Gaile",
                            "lastName": "Gordon",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Gordon"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1610286,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de997e1c284584eb799b672e19108d84528d546e",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a unique face recognition sys tem which considers information from both frontal and pro le view images This system represents the rst step toward the development of a face recogni tion solution for the intensity image domain based on a D context In the current system we construct a D face centered model from the two independent images Geometric information is used for view nor malization and at the lowest level the comparison is based on general pattern matching techniques We also discuss the use of geometric information to index the reference database to quickly eliminate impossi ble matches from further consideration The system has been tested using subjects from the FERET program database and has shown excellent results For example we consider the problem of identifying the of the database which is most similar to the target The correct match is included in this list of the time in the system s fully automated mode and of the time in the manually assisted mode The International Workshop on Automatic Face and Gesture Recognition Zurich June"
            },
            "slug": "Face-recognition-from-frontal-and-profile-views-Gordon",
            "title": {
                "fragments": [],
                "text": "Face recognition from frontal and profile views"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A unique face recognition system which considers information from both frontal and pro le view images is presented and the problem of identifying the of the database which is most similar to the target is considered."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2841459,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6bcdca49ed64ec6b15d975adaea49508e9e941d2",
            "isKey": false,
            "numCitedBy": 224,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe experiments using eigenfaces for recognition and interactive search in the FERET face database. A recognition accuracy of 99.35% is obtained using frontal views of 155 individuals. This figure is consistent with the 95% recognition rate obtained previously on a much larger database of 7,562 `mugshots' of approximately 3,000 individuals, consisting of a mix of all age and ethnic groups. We also demonstrate that we can automatically determine head pose without significantly lowering recognition accuracy; this is accomplished by use of a view-based multiple-observer eigenspace technique. In addition, a modular eigenspace description is used which incorporates salient facial features such as the eyes, nose and mouth, in an eigenfeature layer. This modular representation yields slightly higher recognition rates as well as a more robust framework for face recognition. In addition, a robust and automatic feature detection technique using eigentemplates is demonstrated."
            },
            "slug": "Face-recognition-using-view-based-and-modular-Moghaddam-Pentland",
            "title": {
                "fragments": [],
                "text": "Face recognition using view-based and modular eigenspaces"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A modular eigenspace description is used which incorporates salient facial features such as the eyes, nose and mouth, in an eigenfeature layer, which yields slightly higher recognition rates as well as a more robust framework for face recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Optics & Photonics"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691986"
                        ],
                        "name": "P. Phillips",
                        "slug": "P.-Phillips",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Phillips",
                            "middleNames": [
                                "Jonathon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144928357"
                        ],
                        "name": "Y. Vardi",
                        "slug": "Y.-Vardi",
                        "structuredName": {
                            "firstName": "Yehuda",
                            "lastName": "Vardi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Vardi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59638118,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0e615167186c4ebbff64304ec36d208e56d2a091",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This dissertation presents solutions to four problems from face recognition and medical imaging. The first problem identifies an unknown face from a large database of facial images. The algorithm is based on matching pursuit filters, a small set of facial features, and simple geometric model. The set of features consists of the nose and eye regions of the face, and the interior of the face at a reduced scale. The algorithm uses coarse to fine processing to estimate the location of the facial features. Based on the hypothesized locations of the facial features the identification module searches the database for the identity of the unknown face. The identification is made by matching pursuit filters--a self-organizing technique for creating efficient and compact models from data. This technique is based on an adapted wavelet expansion, which is adapted to both the data and the goals of the algorithm. Thus, the filters can automatically find the subtle differences between facial features needed to identify unknown individuals. The algorithm is demonstrated on a database of photographs of 311 individuals and on a database of infrared facial images. The second problem adjusts for illumination differences between two facial images. The algorithm transforms the histogram of pixel values on one face to the histogram of another face. The algorithm, which is computationally efficient, nonlinear, and data-driven, corrects for variations between two different facial images or changes within an image of a face. The third problem uses a sieve algorithm to find the correspondence between pairs of images taken with an electron microscope. A sieve algorithm uses a sequence of approximations to generate increasingly accurate estimates of the correspondence. Initially, the approximations are computationally inexpensive, and at later stages both accuracy and complexity increase. The fourth problem presents an automatic registration algorithm for MR and PET slices of the brain that does not require manual intervention. The algorithm takes an integrated approach and simultaneous segments the brain in both modalities and registers the slices. A sequence of templates from the PET slice is constructed and registered in the MR slice using an energy function. The template with minimum energy gives the final registration."
            },
            "slug": "Representation-and-registration-in-face-recognition-Phillips-Vardi",
            "title": {
                "fragments": [],
                "text": "Representation and registration in face recognition and medical imaging"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "This dissertation presents solutions to four problems from face recognition and medical imaging, which identifies an unknown face from a large database of facial images, a small set of facial features, and simple geometric model based on matching pursuit filters."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738894"
                        ],
                        "name": "T. Starner",
                        "slug": "T.-Starner",
                        "structuredName": {
                            "firstName": "Thad",
                            "lastName": "Starner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Starner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 136280,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b0bf5d558220d39698ce96d59ee5772e8e1a0663",
            "isKey": false,
            "numCitedBy": 2234,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe experiments with eigenfaces for recognition and interactive search in a large-scale face database. Accurate visual recognition is demonstrated using a database of O(10/sup 3/) faces. The problem of recognition under general viewing orientation is also examined. A view-based multiple-observer eigenspace technique is proposed for use in face recognition under variable pose. In addition, a modular eigenspace description technique is used which incorporates salient features such as the eyes, nose and mouth, in an eigenfeature layer. This modular representation yields higher recognition rates as well as a more robust framework for face recognition. An automatic feature extraction technique using feature eigentemplates is also demonstrated.<<ETX>>"
            },
            "slug": "View-based-and-modular-eigenspaces-for-face-Pentland-Moghaddam",
            "title": {
                "fragments": [],
                "text": "View-based and modular eigenspaces for face recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A modular eigenspace description technique is used which incorporates salient features such as the eyes, nose and mouth, in an eigenfeature layer, which yields higher recognition rates as well as a more robust framework for face recognition."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736245"
                        ],
                        "name": "Laurenz Wiskott",
                        "slug": "Laurenz-Wiskott",
                        "structuredName": {
                            "firstName": "Laurenz",
                            "lastName": "Wiskott",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laurenz Wiskott"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145893752"
                        ],
                        "name": "J. Fellous",
                        "slug": "J.-Fellous",
                        "structuredName": {
                            "firstName": "Jean-Marc",
                            "lastName": "Fellous",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Fellous"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721722"
                        ],
                        "name": "N. Kr\u00fcger",
                        "slug": "N.-Kr\u00fcger",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Kr\u00fcger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Kr\u00fcger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7299252,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7dd0b40a28f49ac51fdcb7dd07fd054e5564dec1",
            "isKey": false,
            "numCitedBy": 220,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "The system presented here is a specialized version of a general object recognition system. Images of faces are represented as graphs, labeled with topographical information and local templates. Different poses are represented by different graphs. New graphs of faces are generated by an elastic graph matching procedure comparing the new face with a set of precomputed graphs: the \"general face knowledge\". The final phase of the matching process can be used to generate composite images of faces and to determine certain features represented in the general face knowledge, such as gender or the presence of glasses or a beard. The graphs can be compared by a similarity function which makes the system efficient in recognizing faces."
            },
            "slug": "Face-Recognition-and-Gender-determination-Wiskott-Fellous",
            "title": {
                "fragments": [],
                "text": "Face Recognition and Gender determination"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "The system presented here is a specialized version of a general object recognition system that can be used to generate composite images of faces and to determine certain features represented in the general face knowledge, such as gender or the presence of glasses or a beard."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144412460"
                        ],
                        "name": "Graham Robertson",
                        "slug": "Graham-Robertson",
                        "structuredName": {
                            "firstName": "Graham",
                            "lastName": "Robertson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Graham Robertson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144986880"
                        ],
                        "name": "I. Craw",
                        "slug": "I.-Craw",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Craw",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Craw"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8070444,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9e89c149a5660f9276db70832bac6c17f505e739",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Testing-face-recognition-systems-Robertson-Craw",
            "title": {
                "fragments": [],
                "text": "Testing face recognition systems"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145508996"
                        ],
                        "name": "J. Wilder",
                        "slug": "J.-Wilder",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Wilder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wilder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691986"
                        ],
                        "name": "P. Phillips",
                        "slug": "P.-Phillips",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Phillips",
                            "middleNames": [
                                "Jonathon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1980956"
                        ],
                        "name": "Cunhong Jiang",
                        "slug": "Cunhong-Jiang",
                        "structuredName": {
                            "firstName": "Cunhong",
                            "lastName": "Jiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cunhong Jiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067135310"
                        ],
                        "name": "S. Wiener",
                        "slug": "S.-Wiener",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Wiener",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Wiener"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1208659,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d30bccb82c115317d5f60a889b36603570cad012",
            "isKey": false,
            "numCitedBy": 185,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents initial results in a study comparing the effectiveness of visible and infra-red (IR) imagery for detecting and recognizing faces in areas where personnel identification is critical, (e.g. airports and secure buildings). We compare the effectiveness of visible versus IR imagery by running three face recognition algorithms on a database of images collected for this study. There are both IR and visible images for each person in the database collected using the same scenarios. We used three very different feature-extraction and decision-making algorithms for our study to insure that the comparisons would not depend on a particular processing technique. We also present recognition results when visible and infra-red decision metrics are fused. The recognition results show that both visible and IR imagery perform similarly across algorithms and that fusion of IR and visible imagery as a viable means of enhancing performance beyond that of either acting alone. We examine the relative importance of different regions of the face for recognition. We also discuss practical issues of implementation, along with plans for the next phase of the study, face detection in an uncontrolled environment. Preliminary face detection results are presented."
            },
            "slug": "Comparison-of-visible-and-infra-red-imagery-for-Wilder-Phillips",
            "title": {
                "fragments": [],
                "text": "Comparison of visible and infra-red imagery for face recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The recognition results show that both visible and IR imagery perform similarly across algorithms and that fusion of IR and visible imagery as a viable means of enhancing performance beyond that of either acting alone."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Second International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1983127"
                        ],
                        "name": "C. Nastar",
                        "slug": "C.-Nastar",
                        "structuredName": {
                            "firstName": "Chahab",
                            "lastName": "Nastar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Nastar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15090755,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b33dae4f6ba299189b8911d8814fe34fdd05d9e0",
            "isKey": false,
            "numCitedBy": 94,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a novel technique for face recognition based on deformable intensity surfaces which incorporates both the shape and texture components of the 2D image. The intensity surface of the facial image is modeled as a deformable 3D mesh in (z, y, I(x, y)) space. Using an efficient technique for matching two surfaces (in terms of the analytic modes of vibration), we obtain a dense correspondence field (or 3D warp) between two images. The probability distributions of two classes of warps are then estimated from training data: interpersonal and extrapersonal variations. These densities are then used in a Bayesian framework for image matching and recognition. Experimental results with facial data from the US Army FERET database demonstrate an increased recognition rate over the previous best methods."
            },
            "slug": "Bayesian-face-recognition-using-deformable-surfaces-Moghaddam-Nastar",
            "title": {
                "fragments": [],
                "text": "Bayesian face recognition using deformable intensity surfaces"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "A novel technique for face recognition based on deformable intensity surfaces which incorporates both the shape and texture components of the 2D image and an increased recognition rate over the previous best methods are described."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716933"
                        ],
                        "name": "I. Cox",
                        "slug": "I.-Cox",
                        "structuredName": {
                            "firstName": "Ingemar",
                            "lastName": "Cox",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Cox"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2864754"
                        ],
                        "name": "J. Ghosn",
                        "slug": "J.-Ghosn",
                        "structuredName": {
                            "firstName": "Joumana",
                            "lastName": "Ghosn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ghosn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3203897"
                        ],
                        "name": "P. Yianilos",
                        "slug": "P.-Yianilos",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Yianilos",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Yianilos"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15344386,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb55f2c02ada7b3e79d54baffccb38a71290b844",
            "isKey": false,
            "numCitedBy": 298,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of feature-based face recognition in the setting where only a single example of each face is available for training. The mixture-distance technique we introduce achieves a recognition rate of 95% on a database of 685 people in which each face is represented by 30 measured distances. This is currently the best recorded recognition rate for a feature-based system applied to a database of this size. By comparison, nearest neighbor search using Euclidean distance yields 84%. In our work a novel distance function is constructed based on local second order statistics as estimated by modeling the training data as a mixture of normal densities. We report on the results from mixtures of several sizes. We demonstrate that a flat mixture of mixtures performs as well as the best model and therefore represents an effective solution to the model selection problem. A mixture perspective is also taken for individual Gaussians to choose between first order (variance) and second order (covariance) models. Here an approximation to flat combination is proposed and seen to perform well in practice. Our results demonstrate that even in the absence of multiple training examples for each class, it is sometimes possible to infer from a statistical model of training data, a significantly improved distance function for use in pattern recognition."
            },
            "slug": "Feature-based-face-recognition-using-Cox-Ghosn",
            "title": {
                "fragments": [],
                "text": "Feature-based face recognition using mixture-distance"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The results demonstrate that even in the absence of multiple training examples for each class, it is sometimes possible to infer from a statistical model of training data, a significantly improved distance function for use in pattern recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144097660"
                        ],
                        "name": "M. Turk",
                        "slug": "M.-Turk",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Turk",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Turk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 28
                            }
                        ],
                        "text": "/lmage and Vision Computing 16 (1998) 295-306 291"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 27
                            }
                        ],
                        "text": "/Imqe and Vision Computing 16 (1998) 295-306 305"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 28
                            }
                        ],
                        "text": "/lmage and Vision Computing 16 (1998) 295-306"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 28
                            }
                        ],
                        "text": "/Image and Vision Computing 16 (1998) 295-306"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 31
                            }
                        ],
                        "text": "P.J. Phillips et al./lmage and Vision Computing 16 (1998) 295-306\n1.00\n303\n0.60\n0.60\n0.70 P\nfd 0.60 c 0 ii 0.60 9 f 0.40 E 3 o.xl\n0.20\n0.10\nGallery: 831 Probes: 1660 ~\n0.00 0 10 20 30 40 50 60 70 60 90 100\nRank\nFig."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 42
                            }
                        ],
                        "text": "Phillips et al/Image and Vision Computing 16 (1998) 295-306"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 28
                            }
                        ],
                        "text": "/lmage and Vision Compufing 16 (1998) 295-306 301"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 28
                            }
                        ],
                        "text": "/Image and Vision Computing 16 (1998) 295-306 299"
                    },
                    "intents": []
                }
            ],
            "corpusId": 26127529,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6f1dfcc44277d4cfd8507284d994c9283dc3a2f",
            "isKey": true,
            "numCitedBy": 14954,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We have developed a near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals. The computational approach taken in this system is motivated by both physiology and information theory, as well as by the practical requirements of near-real-time performance and accuracy. Our approach treats the face recognition problem as an intrinsically two-dimensional (2-D) recognition problem rather than requiring recovery of three-dimensional geometry, taking advantage of the fact that faces are normally upright and thus may be described by a small set of 2-D characteristic views. The system functions by projecting face images onto a feature space that spans the significant variations among known face images. The significant features are known as \"eigenfaces,\" because they are the eigenvectors (principal components) of the set of faces; they do not necessarily correspond to features such as eyes, ears, and noses. The projection operation characterizes an individual face by a weighted sum of the eigenface features, and so to recognize a particular face it is necessary only to compare these weights to those of known individuals. Some particular advantages of our approach are that it provides for the ability to learn and later recognize new faces in an unsupervised manner, and that it is easy to implement using a neural network architecture."
            },
            "slug": "Eigenfaces-for-Recognition-Turk-Pentland",
            "title": {
                "fragments": [],
                "text": "Eigenfaces for Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals, and that is easy to implement using a neural network architecture."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Cognitive Neuroscience"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055501916"
                        ],
                        "name": "Thomas Maurer",
                        "slug": "Thomas-Maurer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Maurer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Maurer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11534904,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "04c306621210fd9dc96b6106e1f5a6bd745ff5dd",
            "isKey": false,
            "numCitedBy": 70,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method for recognizing objects (faces) on the basis of just one stored view, in spite of rotation in depth. The method is not based on the construction of a three-dimensional model for the object. Our recognition results represent a signi cant improvement over a previous system developed in our laboratory. We achieve this with the help of a simple assumption about the transformation of local feature vectors with rotation in depth."
            },
            "slug": "Single-View-Based-Recognition-of-Faces-Rotated-in-Maurer-Malsburg",
            "title": {
                "fragments": [],
                "text": "Single-View Based Recognition of Faces Rotated in Depth"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This work presents a method for recognizing objects (faces) on the basis of just one stored view, in spite of rotation in depth, with the help of a simple assumption about the transformation of local feature vectors with rotation in Depth."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35146156"
                        ],
                        "name": "M. Lades",
                        "slug": "M.-Lades",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Lades",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lades"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3189439"
                        ],
                        "name": "J. Vorbr\u00fcggen",
                        "slug": "J.-Vorbr\u00fcggen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Vorbr\u00fcggen",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Vorbr\u00fcggen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682548"
                        ],
                        "name": "J. Buhmann",
                        "slug": "J.-Buhmann",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Buhmann",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Buhmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075388397"
                        ],
                        "name": "J. Lange",
                        "slug": "J.-Lange",
                        "structuredName": {
                            "firstName": "J\u00f6rg",
                            "lastName": "Lange",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lange"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3038814"
                        ],
                        "name": "R. W\u00fcrtz",
                        "slug": "R.-W\u00fcrtz",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "W\u00fcrtz",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. W\u00fcrtz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34993891"
                        ],
                        "name": "W. Konen",
                        "slug": "W.-Konen",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Konen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Konen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1266405,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4fb52984078d75ec5655962dc94dc7848182286b",
            "isKey": false,
            "numCitedBy": 2069,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "An object recognition system based on the dynamic link architecture, an extension to classical artificial neural networks (ANNs), is presented. The dynamic link architecture exploits correlations in the fine-scale temporal structure of cellular signals to group neurons dynamically into higher-order entities. These entities represent a rich structure and can code for high-level objects. To demonstrate the capabilities of the dynamic link architecture, a program was implemented that can recognize human faces and other objects from video images. Memorized objects are represented by sparse graphs, whose vertices are labeled by a multiresolution description in terms of a local power spectrum, and whose edges are labeled by geometrical distance vectors. Object recognition can be formulated as elastic graph matching, which is performed here by stochastic optimization of a matching cost function. The implementation on a transputer network achieved recognition of human faces and office objects from gray-level camera images. The performance of the program is evaluated by a statistical analysis of recognition results from a portrait gallery comprising images of 87 persons. >"
            },
            "slug": "Distortion-Invariant-Object-Recognition-in-the-Link-Lades-Vorbr\u00fcggen",
            "title": {
                "fragments": [],
                "text": "Distortion Invariant Object Recognition in the Dynamic Link Architecture"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "An object recognition system based on the dynamic link architecture, an extension to classical artificial neural networks (ANNs), is presented and the implementation on a transputer network achieved recognition of human faces and office objects from gray-level camera images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Computers"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064264135"
                        ],
                        "name": "A. Hoover",
                        "slug": "A.-Hoover",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Hoover",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hoover"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403999652"
                        ],
                        "name": "G. Jean-Baptiste",
                        "slug": "G.-Jean-Baptiste",
                        "structuredName": {
                            "firstName": "Gillian",
                            "lastName": "Jean-Baptiste",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Jean-Baptiste"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103801794"
                        ],
                        "name": "Xiao-Yue Jiang",
                        "slug": "Xiao-Yue-Jiang",
                        "structuredName": {
                            "firstName": "Xiao-Yue",
                            "lastName": "Jiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiao-Yue Jiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704876"
                        ],
                        "name": "P. Flynn",
                        "slug": "P.-Flynn",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Flynn",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Flynn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720945"
                        ],
                        "name": "H. Bunke",
                        "slug": "H.-Bunke",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bunke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bunke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698267"
                        ],
                        "name": "D. Goldgof",
                        "slug": "D.-Goldgof",
                        "structuredName": {
                            "firstName": "Dmitry",
                            "lastName": "Goldgof",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Goldgof"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143759604"
                        ],
                        "name": "K. Bowyer",
                        "slug": "K.-Bowyer",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Bowyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Bowyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1996470"
                        ],
                        "name": "D. Eggert",
                        "slug": "D.-Eggert",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Eggert",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Eggert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47139824"
                        ],
                        "name": "A. Fitzgibbon",
                        "slug": "A.-Fitzgibbon",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Fitzgibbon",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Fitzgibbon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1843592"
                        ],
                        "name": "Robert B. Fisher",
                        "slug": "Robert-B.-Fisher",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Fisher",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert B. Fisher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 836587,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "id": "91d31a1e9619749051761341e6ac110962475fdf",
            "isKey": false,
            "numCitedBy": 919,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "A methodology for evaluating range image segmentation algorithms is proposed. This methodology involves (1) a common set of 40 laser range finder images and 40 structured light scanner images that have manually specified ground truth and (2) a set of defined performance metrics for instances of correctly segmented, missed, and noise regions, over- and under-segmentation, and accuracy of the recovered geometry. A tool is used to objectively compare a machine generated segmentation against the specified ground truth. Four research groups have contributed to evaluate their own algorithm for segmenting a range image into planar patches."
            },
            "slug": "An-Experimental-Comparison-of-Range-Image-Hoover-Jean-Baptiste",
            "title": {
                "fragments": [],
                "text": "An Experimental Comparison of Range Image Segmentation Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "A methodology for evaluating range image segmentation algorithms and four research groups have contributed to evaluate their own algorithm for segmenting a range image into planar patches."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7343787"
                        ],
                        "name": "Michael D. Heath",
                        "slug": "Michael-D.-Heath",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Heath",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael D. Heath"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145306925"
                        ],
                        "name": "Sudeep Sarkar",
                        "slug": "Sudeep-Sarkar",
                        "structuredName": {
                            "firstName": "Sudeep",
                            "lastName": "Sarkar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sudeep Sarkar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3164225"
                        ],
                        "name": "T. Sanocki",
                        "slug": "T.-Sanocki",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Sanocki",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sanocki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143759604"
                        ],
                        "name": "K. Bowyer",
                        "slug": "K.-Bowyer",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Bowyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Bowyer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11873854,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e65d77514fdc129b3c8a1a6698b2b76bcc5d5061",
            "isKey": false,
            "numCitedBy": 362,
            "numCiting": 85,
            "paperAbstract": {
                "fragments": [],
                "text": "The purpose of this paper is to describe a new (to computer vision) experimental framework which allows us to make quantitative comparisons using subjective ratings made by people. This approach avoids the issue of pixel-level ground truth. As a result, it does not allow us to make statements about the frequency of false positive and false negative errors at the pixel level. Instead, using experimental design and statistical techniques borrowed from Psychology, we make statements about whether the outputs of one edge detector are rated statistically significantly higher than the outputs of another. This approach offers itself as a nice complement to signal-based quantitative measures. Also, the evaluation paradigm in this paper is goal oriented; in particular, we consider edge detection in the context of object recognition. The human judges rate the edge, detectors based on how well the capture the salient features of real objects. So far, edge detection modules have been designed and evaluated in isolation, except for the recent work by Ramesh and Haralick (1992). The only prior work (that we are aware of) which also uses humans to rate image algorithms is that of Reeves and Higdon (1995). They use human ratings to decide on regularization parameters of image restoration. Fram and Deutch (1975) also used human subjects, however, the focus was on human versus machine performance rather than using human ratings to compare different edge detectors. The use of human judges to rate image outputs mist be approached systematically. Experiments must be designed and conducted carefully, and results interpreted with appropriate statistical tools. The use of statistical analysis in vision system performance characterization has been rare. The only prior work in the area that we are aware of is that of Nair et al. (1995), who used statistical ranking procedures to compare neural network based object recognition systems."
            },
            "slug": "Comparison-of-edge-detectors:-a-methodology-and-Heath-Sarkar",
            "title": {
                "fragments": [],
                "text": "Comparison of edge detectors: a methodology and initial study"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "A new (to computer vision) experimental framework which allows us to make quantitative comparisons using subjective ratings made by people, which avoids the issue of pixel-level ground truth."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743797"
                        ],
                        "name": "I. Guyon",
                        "slug": "I.-Guyon",
                        "structuredName": {
                            "firstName": "Isabelle",
                            "lastName": "Guyon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Guyon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799278"
                        ],
                        "name": "Lambert Schomaker",
                        "slug": "Lambert-Schomaker",
                        "structuredName": {
                            "firstName": "Lambert",
                            "lastName": "Schomaker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lambert Schomaker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144586498"
                        ],
                        "name": "R. Plamondon",
                        "slug": "R.-Plamondon",
                        "structuredName": {
                            "firstName": "R\u00e9jean",
                            "lastName": "Plamondon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Plamondon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144173823"
                        ],
                        "name": "M. Liberman",
                        "slug": "M.-Liberman",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Liberman",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Liberman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2123720"
                        ],
                        "name": "S. Janet",
                        "slug": "S.-Janet",
                        "structuredName": {
                            "firstName": "Stanley",
                            "lastName": "Janet",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Janet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 46942410,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "841c2fd138791b06e4afa01ac2b828618343f1af",
            "isKey": false,
            "numCitedBy": 441,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We report the status of the UNIPEN project of data exchange and recognizer benchmarks started two years ago at the initiative of the International Association of Pattern Recognition (Technical Committee 11). The purpose of the project is to propose and implement solutions to the growing need of handwriting samples for online handwriting recognizers used by pen-based computers. Researchers from several companies and universities have agreed on a data format, a platform of data exchange and a protocol for recognizer benchmarks. The online handwriting data of concern may include handprint and cursive from various alphabets (including Latin and Chinese), signatures and pen gestures. These data will be compiled and distributed by the Linguistic Data Consortium. The benchmarks will be arbitrated the US National Institute of Standards and Technologies. We give a brief introduction to the UNIPEN format. We explain the protocol of data exchange and benchmarks."
            },
            "slug": "UNIPEN-project-of-on-line-data-exchange-and-Guyon-Schomaker",
            "title": {
                "fragments": [],
                "text": "UNIPEN project of on-line data exchange and recognizer benchmarks"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "The status of the UNIPEN project of data exchange and recognizer benchmarks started two years ago is reported, to propose and implement solutions to the growing need of handwriting samples for online handwriting recognizers used by pen-based computers."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 12th IAPR International Conference on Pattern Recognition, Vol. 3 - Conference C: Signal Processing (Cat. No.94CH3440-5)"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 27041556,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c8dde86db9d0c98672c271288c9efe6549925f86",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Computer-vision-theory:-The-lack-thereof-Haralick",
            "title": {
                "fragments": [],
                "text": "Computer vision theory: The lack thereof"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Graph. Image Process."
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144938740"
                        ],
                        "name": "R. Jain",
                        "slug": "R.-Jain",
                        "structuredName": {
                            "firstName": "Ramesh",
                            "lastName": "Jain",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738591"
                        ],
                        "name": "T. Binford",
                        "slug": "T.-Binford",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Binford",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Binford"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 28071215,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b6d32588ec6a0e9be12450a4ae77363c4a566e2",
            "isKey": false,
            "numCitedBy": 113,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Ignorance,-myopia,-and-naivet\u00e9-in-computer-vision-Jain-Binford",
            "title": {
                "fragments": [],
                "text": "Ignorance, myopia, and naivet\u00e9 in computer vision systems"
            },
            "venue": {
                "fragments": [],
                "text": "CVGIP Image Underst."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2281877"
                        ],
                        "name": "J. Atick",
                        "slug": "J.-Atick",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Atick",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Atick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144513847"
                        ],
                        "name": "A. Redlich",
                        "slug": "A.-Redlich",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Redlich",
                            "middleNames": [
                                "Norman"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Redlich"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 207599521,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7e1482c67fc0c96dbd1d190e5040ab113a53e544",
            "isKey": false,
            "numCitedBy": 101,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "An unsupervised developmental algorithm for linear maps is derived which reduces the pixel-entropy (using the measure introduced in previous work) at every update and thus removes pairwise correlations between pixels. Since the measure of pixel-entropy has only a global minimum the algorithm is guaranteed to converge to the minimum entropy map. Such optimal maps have recently been shown to possess cognitively desirable properties and are likely to be used by the nervous system to organize sensory information. The algorithm derived here turns out to be one proposed by Goodall for pairwise decorrelation. It is biologically plausible since in a neural network implementation it requires only data available locally to a neuron. In training over ensembles of two-dimensional input signals with the same spatial power spectrum as natural scenes, networks develop output neurons with center-surround receptive fields similar to those of ganglion cells in the retina. Some technical issues pertinent to developmental algorithms of this sort, such as symmetry fixing, are also discussed."
            },
            "slug": "Convergent-Algorithm-for-Sensory-Receptive-Field-Atick-Redlich",
            "title": {
                "fragments": [],
                "text": "Convergent Algorithm for Sensory Receptive Field Development"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "An unsupervised developmental algorithm for linear maps is derived which reduces the pixel-entropy at every update and thus removes pairwise correlations between pixels, and is biologically plausible since in a neural network implementation it requires only data available locally to a neuron."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144513847"
                        ],
                        "name": "A. Redlich",
                        "slug": "A.-Redlich",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Redlich",
                            "middleNames": [
                                "Norman"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Redlich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5242294,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cceb0fdf30bc69b7af0d0e4f43541c7fafe67cbc",
            "isKey": false,
            "numCitedBy": 127,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "A redundancy reduction strategy, which can be applied in stages, is proposed as a way to learn as efficiently as possible the statistical properties of an ensemble of sensory messages. The method works best for inputs consisting of strongly correlated groups, that is features, with weaker statistical dependence between different features. This is the case for localized objects in an image or for words in a text. A local feature measure determining how much a single feature reduces the total redundancy is derived which turns out to depend only on the probability of the feature and of its components, but not on the statistical properties of any other features. The locality of this measure makes it ideal as the basis for a \"neural\" implementation of redundancy reduction, and an example of a very simple non-Hebbian algorithm is given. The effect of noise on learning redundancy is also discussed."
            },
            "slug": "Redundancy-Reduction-as-a-Strategy-for-Unsupervised-Redlich",
            "title": {
                "fragments": [],
                "text": "Redundancy Reduction as a Strategy for Unsupervised Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A local feature measure determining how much a single feature reduces the total redundancy is derived which turns out to depend only on the probability of the feature and of its components, but not on the statistical properties of any other features."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939761"
                        ],
                        "name": "P. S. Penev",
                        "slug": "P.-S.-Penev",
                        "structuredName": {
                            "firstName": "Penio",
                            "lastName": "Penev",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. S. Penev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2281877"
                        ],
                        "name": "J. Atick",
                        "slug": "J.-Atick",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Atick",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Atick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9885372,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "75c979c57b2319f98d793920c92a5ac51207791b",
            "isKey": false,
            "numCitedBy": 774,
            "numCiting": 108,
            "paperAbstract": {
                "fragments": [],
                "text": "Low-dimensional representations of sensory signals are key to solving many of the computational problems encountered in high-level vision. Principal component analysis (PCA) has been used in the pa..."
            },
            "slug": "Local-feature-analysis:-A-general-statistical-for-Penev-Atick",
            "title": {
                "fragments": [],
                "text": "Local feature analysis: A general statistical theory for object representation"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Low-dimensional representations of sensory signals are key to solving many of the computational problems encountered in high-level vision."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "123067218"
                        ],
                        "name": "K. Price",
                        "slug": "K.-Price",
                        "structuredName": {
                            "firstName": "Keith",
                            "lastName": "Price",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Price"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10311409,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "8247090b7730cff1568e7f86b5182b9427b18e2e",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Anything-you-can-do,-I-can-do-better-(No-you-can't)-Price",
            "title": {
                "fragments": [],
                "text": "Anything you can do, I can do better (No you can't)"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Graph. Image Process."
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2035356983"
                        ],
                        "name": "P. Ranss",
                        "slug": "P.-Ranss",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Ranss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Ranss"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 228304130,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f0f19e05e246bd58911438a0bb1b9674ce94d90c",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Face-recognition-technology-program-overview-and-Ranss",
            "title": {
                "fragments": [],
                "text": "Face recognition technology program overview and results"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145820949"
                        ],
                        "name": "T. Pavlidis",
                        "slug": "T.-Pavlidis",
                        "structuredName": {
                            "firstName": "Theodosios",
                            "lastName": "Pavlidis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pavlidis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 19818609,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "11b782688f8d7d79111bd01147442e8a2a01b7f4",
            "isKey": false,
            "numCitedBy": 53,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Why-progress-in-machine-vision-is-so-slow-Pavlidis",
            "title": {
                "fragments": [],
                "text": "Why progress in machine vision is so slow"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit. Lett."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2995060"
                        ],
                        "name": "D. Swets",
                        "slug": "D.-Swets",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Swets",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Swets"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145926447"
                        ],
                        "name": "J. Weng",
                        "slug": "J.-Weng",
                        "structuredName": {
                            "firstName": "Juyang",
                            "lastName": "Weng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weng"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16456691,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3ca615e39db86897bf2cc628a5362d8d7297ac00",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "The method we have been using is based on our Self-Organizing Hierarchical Optimal Subspace Learning and Inference Framework (SHOSLIF). It uses the theories of linear discriminant projection for automatic optimal feature selection in each of the internal nodes of a Space-Tessellation Tree. In this paper, we present our recent study on the applicability of the approach to variability in position, size, and 3D orientation. In the work presented here, we require \"well-framed\" images os input for recognition. By well-framed images we mean that only a relatively small variation in the size, position, and orientation of the objects in the input images is allowed. We report the experimental results that show the performance difference between the subspaces of linear discriminant analysis and the principle component analysis and the effect of using a tree as opposed to a flat eigenspace."
            },
            "slug": "Discriminant-analysis-and-eigenspace-partition-tree-Swets-Weng",
            "title": {
                "fragments": [],
                "text": "Discriminant analysis and eigenspace partition tree for face and object recognition from views"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper presents the experimental results that show the performance difference between the subspaces of linear discriminant analysis and the principle component analysis, and the effect of using a tree as opposed to a flat eigenspace."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Second International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Testing face recognition systems, Image and Vision Computing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Data driven methods in face recognition, in:"
            },
            "venue": {
                "fragments": [],
                "text": "International Workshop on Automatic Face and Gesture Recognition,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Data driven methods in face recognition"
            },
            "venue": {
                "fragments": [],
                "text": "International Workshop on Automatic Face and Gesture Recognition"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood detection of faces and hands"
            },
            "venue": {
                "fragments": [],
                "text": "International Workshop on Automatic Face and Gesture Recognition"
            },
            "year": 1995
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 31,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/The-FERET-database-and-evaluation-procedure-for-Phillips-Wechsler/dc8b25e35a3acb812beb499844734081722319b4?sort=total-citations"
}