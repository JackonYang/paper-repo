{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2961287"
                        ],
                        "name": "N. Littlestone",
                        "slug": "N.-Littlestone",
                        "structuredName": {
                            "firstName": "Nick",
                            "lastName": "Littlestone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Littlestone"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This problem has been addressed by the recent results of Littlestone [ 23 ]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We now give bounds on the growth function and VC dimension of each of the more general concept classes introduced in Section 1. These results are derived in part from results in [ 23 , 44]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 6334230,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a1dace286582d91916fe470d08f30381cf453f20",
            "isKey": false,
            "numCitedBy": 1612,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Valiant (1984) and others have studied the problem of learning various classes of Boolean functions from examples. Here we discuss incremental learning of these functions. We consider a setting in which the learner responds to each example according to a current hypothesis. Then the learner updates the hypothesis, if necessary, based on the correct classification of the example. One natural measure of the quality of learning in this setting is the number of mistakes the learner makes. For suitable classes of functions, learning algorithms are available that make a bounded number of mistakes, with the bound independent of the number of examples seen by the learner. We present one such algorithm that learns disjunctive Boolean functions, along with variants for learning other classes of Boolean functions. The basic method can be expressed as a linear-threshold algorithm. A primary advantage of this algorithm is that the number of mistakes grows only logarithmically with the number of irrelevant attributes in the examples. At the same time, the algorithm is computationally efficient in both time and space."
            },
            "slug": "Learning-Quickly-When-Irrelevant-Attributes-Abound:-Littlestone",
            "title": {
                "fragments": [],
                "text": "Learning Quickly When Irrelevant Attributes Abound: A New Linear-Threshold Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work presents one such algorithm that learns disjunctive Boolean functions, along with variants for learning other classes of Boolean functions."
            },
            "venue": {
                "fragments": [],
                "text": "28th Annual Symposium on Foundations of Computer Science (sfcs 1987)"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2195972"
                        ],
                        "name": "P. Utgoff",
                        "slug": "P.-Utgoff",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Utgoff",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Utgoff"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61047266,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "f5157391985e1b8b451461f3350e9f91e697b76f",
            "isKey": false,
            "numCitedBy": 375,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We identify and examine the fundamental role that bias plays in inductive concept learning. Bias is the set of all influences, procedural or declarative, that causes a concept learner to prefer one hypothesis to another. Much of the success of concept learning programs to date results from the program's author having provided the learning program with appropriate bias. To date there has been no good mechanical method for shifting from one bias to another that is better. Instead, the author of a learning program has himself had to search for a better bias. The program author manually generates a bias, from scratch or by revising a previous bias, and then tests it in his program. If the author is not satisfied with the induced concepts, then he repeats the manual-generate and program-test cycle. If the author is satisfied, then he deems his program successful. Too often, he does not recognize his own role in the learning process. \nOur thesis is that search for appropriate bias is itself a major part of the learning task, and that we can create mechanical procedures for conducting a well-directed search for an appropriate bias. We would like to understand better how a program author goes about doing his search for appropriate bias. What insights does he have? What does he learn when he observes that a particular bias produces poor performance? What domain knowledge does he apply? \nWe explore the problem of mechanizing the search for appropriate bias. To that end, we develop a framework for a procedure that shifts bias. We then build two instantiations of the procedure in a program called STABB, which we then incorporate in the LEX learning program. One, called \"least disjunction\", uses simple syntactic manipulation, and the other, called \"constraint back propagation\" uses analytic deduction. We report experiments with the implementations that both demonstrate the usefulness of the framework, and uncover important issues for this kind of learning."
            },
            "slug": "Shift-of-bias-for-inductive-concept-learning-Utgoff",
            "title": {
                "fragments": [],
                "text": "Shift of bias for inductive concept learning"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that search for appropriate bias is itself a major part of the learning task, and that mechanical procedures for conducting a well-directed search for an appropriate bias can be created."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145166238"
                        ],
                        "name": "A. Bundy",
                        "slug": "A.-Bundy",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Bundy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bundy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145313014"
                        ],
                        "name": "B. Silver",
                        "slug": "B.-Silver",
                        "structuredName": {
                            "firstName": "Bernard",
                            "lastName": "Silver",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Silver"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41219950"
                        ],
                        "name": "Dave Plummer",
                        "slug": "Dave-Plummer",
                        "structuredName": {
                            "firstName": "Dave",
                            "lastName": "Plummer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dave Plummer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 121
                            }
                        ],
                        "text": "s This algorithm is typically presented as an incremental algorithm, but this causes problems with the negative examples [7, 27]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 66
                            }
                        ],
                        "text": "It also corresponds to the \"lower mark\" in the attribute trees of [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 123
                            }
                        ],
                        "text": "In [14] a few speculations on the issue of simultaneously learning sets of related concepts are given, based on ideas from [3, 7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 34510307,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a40262fc39c2611906d4b69481035a5d4b05fc0e",
            "isKey": false,
            "numCitedBy": 130,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-Analytical-Comparison-of-Some-Rule-Learning-Bundy-Silver",
            "title": {
                "fragments": [],
                "text": "An Analytical Comparison of Some Rule-Learning Programs"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741124"
                        ],
                        "name": "L. Valiant",
                        "slug": "L.-Valiant",
                        "structuredName": {
                            "firstName": "Leslie",
                            "lastName": "Valiant",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Valiant"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "ask questions of the form \"is x an instance of the target concept?,\" where x is an instance constructed by the learning algorithm [1, 36,37] (see also [ 39 ])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "These problems with the version space approach are overcome by incorporating into it the probabilistic ideas of the Valiant framework [ 39 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 59712,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "10ddb646feddc12337b5a755c72e153e37088c02",
            "isKey": false,
            "numCitedBy": 4191,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Humans appear to be able to learn new concepts without needing to be programmed explicitly in any conventional sense. In this paper we regard learning as the phenomenon of knowledge acquisition in the absence of explicit programming. We give a precise methodology for studying this phenomenon from a computational viewpoint. It consists of choosing an appropriate information gathering mechanism, the learning protocol, and exploring the class of concepts that can be learnt using it in a reasonable (polynomial) number of steps. We find that inherent algorithmic complexity appears to set serious limits to the range of concepts that can be so learnt. The methodology and results suggest concrete principles for designing realistic learning systems."
            },
            "slug": "A-theory-of-the-learnable-Valiant",
            "title": {
                "fragments": [],
                "text": "A theory of the learnable"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper regards learning as the phenomenon of knowledge acquisition in the absence of explicit programming, and gives a precise methodology for studying this phenomenon from a computational viewpoint."
            },
            "venue": {
                "fragments": [],
                "text": "STOC '84"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683946"
                        ],
                        "name": "A. Ehrenfeucht",
                        "slug": "A.-Ehrenfeucht",
                        "structuredName": {
                            "firstName": "Andrzej",
                            "lastName": "Ehrenfeucht",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ehrenfeucht"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 5200802,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "9a2a56f0a0d5ca5d1c38f0db35c2937c095d1a9b",
            "isKey": false,
            "numCitedBy": 167,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-decision-trees-from-random-examples-Ehrenfeucht-Haussler",
            "title": {
                "fragments": [],
                "text": "Learning decision trees from random examples"
            },
            "venue": {
                "fragments": [],
                "text": "COLT '88"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3288645"
                        ],
                        "name": "R. Banerji",
                        "slug": "R.-Banerji",
                        "structuredName": {
                            "firstName": "Ranan",
                            "lastName": "Banerji",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Banerji"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In [14] a few speculations on the issue of simultaneously learning sets of related concepts are given, based on ideas from [ 3 , 7]. Much more work remains to be done in all these areas."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 28664393,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "95f08ef99f0f0b16ce4a916f2983451ed722fcbc",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Logic-of-Learning:-A-Basis-for-Pattern-and-for-Banerji",
            "title": {
                "fragments": [],
                "text": "The Logic of Learning: A Basis for Pattern Recognition and for Improvement of Performance"
            },
            "venue": {
                "fragments": [],
                "text": "Adv. Comput."
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144299726"
                        ],
                        "name": "Thomas G. Dietterich",
                        "slug": "Thomas-G.-Dietterich",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Dietterich",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas G. Dietterich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2421006"
                        ],
                        "name": "R. Michalski",
                        "slug": "R.-Michalski",
                        "structuredName": {
                            "firstName": "Ryszard",
                            "lastName": "Michalski",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Michalski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 62605382,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "76ec5daa8207d63150ce950118c1b222dd3b9c33",
            "isKey": false,
            "numCitedBy": 333,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Research in the area of learning structural descriptions from examples is reviewed, giving primary attention to methods of learning characteristic descriptions of single concepts. In particular, we examine methods for finding the maximally-specific conjunctive generalizations (MSC-generalizations) that cover all of the training examples of a given concept. Various important aspects of structural learning in general are examined, and several criteria for evaluating structural learning methods are presented. Briefly, these criteria include (i) adequacy of the representation language, (ii) generalization rules employed, (iii) computational efficiency, and (iv) flexibility and extensibility. Selected learning methods developed by Buchanan, et al., Hayes-Roth, Vere, Winston, and the authors are analyzed according to these criteria. Finally, some goals are suggested for future research."
            },
            "slug": "A-Comparative-Review-of-Selected-Methods-for-from-Dietterich-Michalski",
            "title": {
                "fragments": [],
                "text": "A Comparative Review of Selected Methods for Learning from Examples"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Methods for finding the maximally-specific conjunctive generalizations (MSC-generalizations) that cover all of the training examples of a given concept are examined."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39419622"
                        ],
                        "name": "B. Natarajan",
                        "slug": "B.-Natarajan",
                        "structuredName": {
                            "firstName": "Balas",
                            "lastName": "Natarajan",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Natarajan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729906"
                        ],
                        "name": "Prasad Tadepalli",
                        "slug": "Prasad-Tadepalli",
                        "structuredName": {
                            "firstName": "Prasad",
                            "lastName": "Tadepalli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Prasad Tadepalli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "For this initial result, bias is measured in terms of the size of the hypothesis space (see also [ 28 , 32])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "space framework for learning concepts from examples [ 28 ], here from a probabilistic point of view."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Background knowledge and multi-valued functions are considered in [ 28 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17243777,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6c3e9e9e10a1bf803de2e161bd91c7831ecb1a5",
            "isKey": true,
            "numCitedBy": 34,
            "numCiting": 82,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Two-New-Frameworks-for-Learning-Natarajan-Tadepalli",
            "title": {
                "fragments": [],
                "text": "Two New Frameworks for Learning"
            },
            "venue": {
                "fragments": [],
                "text": "ML"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056642528"
                        ],
                        "name": "M. Kearns",
                        "slug": "M.-Kearns",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kearns",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kearns"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2150652510"
                        ],
                        "name": "Ming Li",
                        "slug": "Ming-Li",
                        "structuredName": {
                            "firstName": "Ming",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47494927"
                        ],
                        "name": "L. Pitt",
                        "slug": "L.-Pitt",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Pitt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Pitt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741124"
                        ],
                        "name": "L. Valiant",
                        "slug": "L.-Valiant",
                        "structuredName": {
                            "firstName": "Leslie",
                            "lastName": "Valiant",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Valiant"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18958417,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ebc3afef7c5455ab8bd0c06755ce926f8fe707fb",
            "isKey": false,
            "numCitedBy": 134,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Recent-Results-on-Boolean-Concept-Learning-Kearns-Li",
            "title": {
                "fragments": [],
                "text": "Recent Results on Boolean Concept Learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2647026"
                        ],
                        "name": "A. Blumer",
                        "slug": "A.-Blumer",
                        "structuredName": {
                            "firstName": "Anselm",
                            "lastName": "Blumer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blumer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683946"
                        ],
                        "name": "A. Ehrenfeucht",
                        "slug": "A.-Ehrenfeucht",
                        "structuredName": {
                            "firstName": "Andrzej",
                            "lastName": "Ehrenfeucht",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ehrenfeucht"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Extending the results of [42], in [ 5 , 12] it is shown that this parameter is strongly correlated with learning performance as defined in the learning framework introduced by Valiant ]21, 39-4l]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 1138467,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0b8fa3496283d4d808fba9ff62d5f024bcf23be",
            "isKey": false,
            "numCitedBy": 1909,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": "Valiant's learnability model is extended to learning classes of concepts defined by regions in Euclidean space En. The methods in this paper lead to a unified treatment of some of Valiant's results, along with previous results on distribution-free convergence of certain pattern recognition algorithms. It is shown that the essential condition for distribution-free learnability is finiteness of the Vapnik-Chervonenkis dimension, a simple combinatorial parameter of the class of concepts to be learned. Using this parameter, the complexity and closure properties of learnable classes are analyzed, and the necessary and sufficient conditions are provided for feasible learnability."
            },
            "slug": "Learnability-and-the-Vapnik-Chervonenkis-dimension-Blumer-Ehrenfeucht",
            "title": {
                "fragments": [],
                "text": "Learnability and the Vapnik-Chervonenkis dimension"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper shows that the essential condition for distribution-free learnability is finiteness of the Vapnik-Chervonenkis dimension, a simple combinatorial parameter of the class of concepts to be learned."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47494927"
                        ],
                        "name": "L. Pitt",
                        "slug": "L.-Pitt",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Pitt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Pitt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741124"
                        ],
                        "name": "L. Valiant",
                        "slug": "L.-Valiant",
                        "structuredName": {
                            "firstName": "Leslie",
                            "lastName": "Valiant",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Valiant"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18940285,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "93849122caf1b10c9611eddb707e0720441c73f6",
            "isKey": false,
            "numCitedBy": 541,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "The computational complexity of learning Boolean concepts from examples is investigated. It is shown for various classes of concept representations that these cannot be learned feasibly in a distribution-free sense unless R = NP. These classes include (a) disjunctions of two monomials, (b) Boolean threshold functions, and (c) Boolean formulas in which each variable occurs at most once. Relationships between learning of heuristics and finding approximate solutions to NP-hard optimization problems are given."
            },
            "slug": "Computational-limitations-on-learning-from-examples-Pitt-Valiant",
            "title": {
                "fragments": [],
                "text": "Computational limitations on learning from examples"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "It is shown for various classes of concept representations that these cannot be learned feasibly in a distribution-free sense unless R = NP, and relationships between learning of heuristics and finding approximate solutions to NP-hard optimization problems are given."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683946"
                        ],
                        "name": "A. Ehrenfeucht",
                        "slug": "A.-Ehrenfeucht",
                        "structuredName": {
                            "firstName": "Andrzej",
                            "lastName": "Ehrenfeucht",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ehrenfeucht"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056642528"
                        ],
                        "name": "M. Kearns",
                        "slug": "M.-Kearns",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kearns",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kearns"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741124"
                        ],
                        "name": "L. Valiant",
                        "slug": "L.-Valiant",
                        "structuredName": {
                            "firstName": "Leslie",
                            "lastName": "Valiant",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Valiant"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1925579,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b83396caf4762c906530c9219a9e4dd0658232b0",
            "isKey": false,
            "numCitedBy": 499,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-general-lower-bound-on-the-number-of-examples-for-Ehrenfeucht-Haussler",
            "title": {
                "fragments": [],
                "text": "A general lower bound on the number of examples needed for learning"
            },
            "venue": {
                "fragments": [],
                "text": "COLT '88"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2421006"
                        ],
                        "name": "R. Michalski",
                        "slug": "R.-Michalski",
                        "structuredName": {
                            "firstName": "Ryszard",
                            "lastName": "Michalski",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Michalski"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 58987397,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "83f65f18394f505315f08269db253818fd166a43",
            "isKey": false,
            "numCitedBy": 1286,
            "numCiting": 129,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Theory-and-Methodology-of-Inductive-Learning-Michalski",
            "title": {
                "fragments": [],
                "text": "A theory and methodology of inductive learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40975594"
                        ],
                        "name": "Tom Michael Mitchell",
                        "slug": "Tom-Michael-Mitchell",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Mitchell",
                            "middleNames": [
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom Michael Mitchell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "H) is defined by Mitchell [ 27 ] as the set of all hypotheses in H that are consistent with all examples in Q."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Mitchell observes that by keeping track of only the maximally specific and the maximally general hypotheses in the version space of Q (the sets S and G respectively of [ 27 ]), we can monitor this version space as more examples are added to Q, and, while we cannot in general determine when it is exhausted, we can detect when it is either empt~ or has been reduced to just one hypothesis.: If it becomes empty, then we know that the target ..."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This is achieved if there is a strategy that always cuts the version space in half with each new query [ 27 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17162574,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "id": "0df1aac45ff562089a3bdbcb34e2481a71478651",
            "isKey": true,
            "numCitedBy": 1775,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Generalization-as-Search-Mitchell",
            "title": {
                "fragments": [],
                "text": "Generalization as Search"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2620923"
                        ],
                        "name": "J. C. Schlimmer",
                        "slug": "J.-C.-Schlimmer",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Schlimmer",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. C. Schlimmer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[ 35 ]). In this task we select a set of mushroom attributes (e.g."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 58502460,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62e7ed52e36d427a9d16befc80639d0850c82ef7",
            "isKey": false,
            "numCitedBy": 73,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Incremental-Adjustment-of-Representations-for-Schlimmer",
            "title": {
                "fragments": [],
                "text": "Incremental Adjustment of Representations for Learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2270210"
                        ],
                        "name": "R. S. Wenocur",
                        "slug": "R.-S.-Wenocur",
                        "structuredName": {
                            "firstName": "Roberta",
                            "lastName": "Wenocur",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. S. Wenocur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1881615"
                        ],
                        "name": "R. Dudley",
                        "slug": "R.-Dudley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Dudley",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dudley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We now give bounds on the growth function and VC dimension of each of the more general concept classes introduced in Section 1. These results are derived in part from results in [23,  44 ]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 204985985,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5e6dfb46ed298ff037e166291c128a465f90bfc0",
            "isKey": false,
            "numCitedBy": 146,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Some-special-vapnik-chervonenkis-classes-Wenocur-Dudley",
            "title": {
                "fragments": [],
                "text": "Some special vapnik-chervonenkis classes"
            },
            "venue": {
                "fragments": [],
                "text": "Discret. Math."
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 61447029,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "80c82e8e212ad03d5456088127b50e480631334c",
            "isKey": false,
            "numCitedBy": 112,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract The connection between the simplicity of scientific theories and the credence attributed to their predictions seems to permeate the practice of scientific discovery. When a scientist succeeds in explaining a set of nobservations using a model Mof complexity c then it is generally believed that the likelihood of finding another explanatory model with similar complexity but leading to opposite predictions decreases with increasing nand decreasing c. This paper derives formal relationships between n, c and the probability of ambiguous predictions by examining three modeling languages under binary classification tasks: perceptrons, Boolean formulae, and Boolean networks. Bounds are also derived for the probability of error associated with the policy of accepting only models of complexity not exceeding c. Human tendency to regard the simpler as the more trustworthy is given a qualified justification."
            },
            "slug": "ON-THE-CONNECTION-BETWEEN-THE-COMPLEXITY-AND-OF-Pearl",
            "title": {
                "fragments": [],
                "text": "ON THE CONNECTION BETWEEN THE COMPLEXITY AND CREDIBILITY OF INFERRED MODELS"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper derives formal relationships between n, c and the probability of ambiguous predictions by examining three modeling languages under binary classification tasks: perceptrons, Boolean formulae, and Boolean networks."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29961301"
                        ],
                        "name": "P. Laird",
                        "slug": "P.-Laird",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Laird",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Laird"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 20448439,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d1e83c9a7386bf4ec2fe9793e3e8aa02975669fb",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "A model is presented for the class of inductive inference problems that are solved by refinement algorithms - that is, algorithms that modify a hypothesis by making it more general or more specific in response to examples. The separate effects of the syntax (rule space) and semantics, and the relevant orderings on these, are precisely specified. Relations called refinement operators are defined, one for generalization and one for specialization. General and particular properties of these relations are considered, and algorithm schemas for top-down and bottom-up inference are given. Finally, difficulties common to refinement algorithms are reviewed."
            },
            "slug": "Inductive-Inference-by-Refinement-Laird",
            "title": {
                "fragments": [],
                "text": "Inductive Inference by Refinement"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A model is presented for the class of inductive inference problems that are solved by refinement algorithms - that is, algorithms that modify a hypothesis by making it more general or more specific in response to examples."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056642528"
                        ],
                        "name": "M. Kearns",
                        "slug": "M.-Kearns",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kearns",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kearns"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2150652510"
                        ],
                        "name": "Ming Li",
                        "slug": "Ming-Li",
                        "structuredName": {
                            "firstName": "Ming",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming Li"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Valiant has introduced a completely different model in which an adversary to the learning algorithm is allowed to maliciously modify the training examples [40]. This model is further developed in [ 20 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1507349,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "25875a29eded2acdad72cf897df11c2df2d92ec1",
            "isKey": false,
            "numCitedBy": 396,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper an extension of the distribution-free model of learning introduced by Valiant [Comm. ACM, 27(1984), pp. 1134\u20131142] that allows the presence of malicious errors in the examples given to a learning algorithm is studied. Such errors are generated by an adversary with unbounded computational power and access to the entire history of the learning algorithm\u2019s computation. Thus, a worst-case model of errors is studied.The results of this research include general methods for bounding the rate of error tolerable by any learning algorithm, efficient algorithms tolerating nontrivial rates of malicious errors, and equivalences between problems of learning with errors and standard combinatorial optimization problems."
            },
            "slug": "Learning-in-the-presence-of-malicious-errors-Kearns-Li",
            "title": {
                "fragments": [],
                "text": "Learning in the presence of malicious errors"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "General methods for bounding the rate of error tolerable by any learning algorithm, efficient algorithms tolerating nontrivial rates of malicious errors, and equivalences between problems of learning with errors and standard combinatorial optimization problems are studied."
            },
            "venue": {
                "fragments": [],
                "text": "STOC '88"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "23167841"
                        ],
                        "name": "D. S. Johnson",
                        "slug": "D.-S.-Johnson",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Johnson",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. S. Johnson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2074730549"
                        ],
                        "name": "K. Niemi",
                        "slug": "K.-Niemi",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Niemi",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Niemi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The dynamic programming technique given in [ 19 ] solves this problem by (essentially) calculating for each possible total cost the predecessor-closed subtree with the maximal total gain that has at most that cost."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This investment problem is a variant of the similar investment problem solved in [ 19 ] by dynamic programming."
                    },
                    "intents": []
                }
            ],
            "corpusId": 193379,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "95c041ba471753753ec016e964a5cfe16ea06f6a",
            "isKey": false,
            "numCitedBy": 162,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Let G be an acyclic directed graph with weights and values assigned to its vertices. In the partially ordered knapsack problem we wish to find a maximum-valued subset of vertices whose total weight does not exceed a given knapsack capacity, and which contains every predecessor of a vertex if it contains the vertex itself. We consider the special case where G is an out-tree. Even though this special case is still NP-complete, we observe how dynamic programming techniques can be used to construct pseudopolynomial time optimization algorithms and fully polynomial time approximation schemes for it. In particular, we show that a nonstandard approach we call \u201cleft-right\u201d dynamic programming is better suited for this problem than the standard \u201cbottom-up\u201d approach, and we show how this \u201cleft-right\u201d approach can also be adapted to the case of in-trees and to a related tree partitioning problem arising in integrated circuit design. We conclude by presenting complexity results which indicate that similar success cannot be expected with either problem when the restriction to trees is lifted."
            },
            "slug": "On-Knapsacks,-Partitions,-and-a-New-Dynamic-for-Johnson-Niemi",
            "title": {
                "fragments": [],
                "text": "On Knapsacks, Partitions, and a New Dynamic Programming Technique for Trees"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown how dynamic programming techniques can be used to construct pseudopolynomial time optimization algorithms and fully polynomial time approximation schemes for the partially ordered knapsack problem and how this approach can be adapted to the case of in-trees and to a related tree partitioning problem arising in integrated circuit design."
            },
            "venue": {
                "fragments": [],
                "text": "Math. Oper. Res."
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2647026"
                        ],
                        "name": "A. Blumer",
                        "slug": "A.-Blumer",
                        "structuredName": {
                            "firstName": "Anselm",
                            "lastName": "Blumer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blumer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683946"
                        ],
                        "name": "A. Ehrenfeucht",
                        "slug": "A.-Ehrenfeucht",
                        "structuredName": {
                            "firstName": "Andrzej",
                            "lastName": "Ehrenfeucht",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ehrenfeucht"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 35454947,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "71448a9b8d35d5f3123405d3d7a66288618daab2",
            "isKey": false,
            "numCitedBy": 637,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Occam's-Razor-Blumer-Ehrenfeucht",
            "title": {
                "fragments": [],
                "text": "Occam's Razor"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Process. Lett."
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752732"
                        ],
                        "name": "T. Cover",
                        "slug": "T.-Cover",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Cover",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Cover"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 53
                            }
                        ],
                        "text": "We use the following notions from [42, 43] (see also [9])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 182
                            }
                        ],
                        "text": "The growth function of a hypothesis space can be used to define its Vapnik-Cherv6nenkis dirnension, a combinatorial parameter closely related to the notion of capacity introduced in [9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18251470,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "445ad69010658097fc317f7b83f1198179eebae8",
            "isKey": false,
            "numCitedBy": 1840,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper develops the separating capacities of families of nonlinear decision surfaces by a direct application of a theorem in classical combinatorial geometry. It is shown that a family of surfaces having d degrees of freedom has a natural separating capacity of 2d pattern vectors, thus extending and unifying results of Winder and others on the pattern-separating capacity of hyperplanes. Applying these ideas to the vertices of a binary n-cube yields bounds on the number of spherically, quadratically, and, in general, nonlinearly separable Boolean functions of n variables. It is shown that the set of all surfaces which separate a dichotomy of an infinite, random, separable set of pattern vectors can be characterized, on the average, by a subset of only 2d extreme pattern vectors. In addition, the problem of generalizing the classifications on a labeled set of pattern points to the classification of a new point is defined, and it is found that the probability of ambiguous generalization is large unless the number of training patterns exceeds the capacity of the set of separating surfaces."
            },
            "slug": "Geometrical-and-Statistical-Properties-of-Systems-Cover",
            "title": {
                "fragments": [],
                "text": "Geometrical and Statistical Properties of Systems of Linear Inequalities with Applications in Pattern Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that a family of surfaces having d degrees of freedom has a natural separating capacity of 2d pattern vectors, thus extending and unifying results of Winder and others on the pattern-separating capacity of hyperplanes."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Electron. Comput."
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144922029"
                        ],
                        "name": "D. Subramanian",
                        "slug": "D.-Subramanian",
                        "structuredName": {
                            "firstName": "Devika",
                            "lastName": "Subramanian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Subramanian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751820"
                        ],
                        "name": "J. Feigenbaum",
                        "slug": "J.-Feigenbaum",
                        "structuredName": {
                            "firstName": "Joan",
                            "lastName": "Feigenbaum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Feigenbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "ask questions of the form \"is x an instance of the target concept?,\" where x is an instance constructed by the learning algorithm [1, 36, 37 ] (see also [39])."
                    },
                    "intents": []
                }
            ],
            "corpusId": 53783,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a86d53ff86cbcfa4825c8a655c9725087685d9ec",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Experiment generation is an important part of incremental concept learning. One basic function of experimentation is to gather data to refine the existing space of hypotheses[DB83]. Here we examine the class of experiments that accomplish this, called discrimination experiments, and propose factoring as a technique for generating them efficiently."
            },
            "slug": "Factorization-in-Experiment-Generation-Subramanian-Feigenbaum",
            "title": {
                "fragments": [],
                "text": "Factorization in Experiment Generation"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The class of experiments that accomplish discrimination experiments are examined, called discrimination experiments, and factoring is proposed as a technique for generating them efficiently."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714765"
                        ],
                        "name": "V. Chv\u00e1tal",
                        "slug": "V.-Chv\u00e1tal",
                        "structuredName": {
                            "firstName": "Vasek",
                            "lastName": "Chv\u00e1tal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Chv\u00e1tal"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 253,
                                "start": 250
                            }
                        ],
                        "text": "As with the basic minimum set cover problem, it can be shown that if the original set T to be covered has m elements and s is the minimum cost of any cover, then the generalized greedy method is guaranteed to find a cover of cost at most s(ln m + 1) [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 43555235,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b4e0ca86d00efc6c548939e3ed614bf64dd9d0ab",
            "isKey": false,
            "numCitedBy": 2505,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Let A be a binary matrix of size m \u00d7 n, let cT be a positive row vector of length n and let e be the column vector, all of whose m components are ones. The set-covering problem is to minimize cTx subject to Ax \u2265 e and x binary. We compare the value of the objective function at a feasible solution found by a simple greedy heuristic to the true optimum. It turns out that the ratio between the two grows at most logarithmically in the largest column sum of A. When all the components of cT are the same, our result reduces to a theorem established previously by Johnson and Lovasz."
            },
            "slug": "A-Greedy-Heuristic-for-the-Set-Covering-Problem-Chv\u00e1tal",
            "title": {
                "fragments": [],
                "text": "A Greedy Heuristic for the Set-Covering Problem"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It turns out that the ratio between the two grows at most logarithmically in the largest column sum of A when all the components of cT are the same, which reduces to a theorem established previously by Johnson and Lovasz."
            },
            "venue": {
                "fragments": [],
                "text": "Math. Oper. Res."
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717081"
                        ],
                        "name": "E. Welzl",
                        "slug": "E.-Welzl",
                        "structuredName": {
                            "firstName": "Emo",
                            "lastName": "Welzl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Welzl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Theorem 3.3 ~ ([5, Theorem A2.4]. See also [ 17 ])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "e-net for a set of regions, introduced in [ 17 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 27638326,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "dbdfc10b6af746580bd48f2f3757e9060326e5ab",
            "isKey": false,
            "numCitedBy": 674,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "AbstractWe demonstrate the existence of data structures for half-space and simplex range queries on finite point sets ind-dimensional space,d\u22652, with linear storage andO(n\u03b1) query time,\n% MathType!MTEF!2!1!+-% feaafiart1ev1aaatCvAUfeBSjuyZL2yd9gzLbvyNv2CaerbuLwBLn% hiov2DGi1BTfMBaeXatLxBI9gBaerbd9wDYLwzYbItLDharqqtubsr% 4rNCHbGeaGqiVC0xe9sqqrpepC0xbbL8F4rqqrFfpeea0xe9Gqpi0x% c9q8qqaqFj0df9pwe9Q8fs0-yqaqpepae9pg0FirpepeKkFr0xfr-x% fr-xb9adbaqaaeGaciGaaiaabeqaamaabaabaaGcbaGaeqySdeMaey% ypa0ZaaSaaaeaacaWGKbGaaiikaiaadsgacqGHsislcaaIXaGaaiyk% aaqaaiaadsgacaGGOaGaamizaiabgkHiTiaaigdacaGGPaGaey4kaS% IaaGymaaaacqGHRaWkcqaHZoWzieaacaWFGaGaa8hiaiaa-bcacaWF% GaGaa8hiaiaa-bcacaWFGaGaa8Nzaiaa-9gacaWFYbGaa8hiaiaa-f% gacaWFSbGaa8hBaiaa-bcacaWFGaGaa8hiaiabeo7aNjaa-5dacaWF% Waaaaa!574F!\n\n$$\\alpha = \\frac{{d(d - 1)}}{{d(d - 1) + 1}} + \\gamma for all \\gamma > 0$$\n.These bounds are better than those previously published for alld\u22652. Based on ideas due to Vapnik and Chervonenkis, we introduce the concept of an \u025b-net of a set of points for an abstract set of ranges and give sufficient conditions that a random sample is an \u025b-net with any desired probability. Using these results, we demonstrate how random samples can be used to build a partition-tree structure that achieves the above query time."
            },
            "slug": "\u025b-nets-and-simplex-range-queries-Haussler-Welzl",
            "title": {
                "fragments": [],
                "text": "\u025b-nets and simplex range queries"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The concept of an \u025b-net of a set of points for an abstract set of ranges is introduced and sufficient conditions that a random sample is an \u00c3\u201a-net with any desired probability are given."
            },
            "venue": {
                "fragments": [],
                "text": "Discret. Comput. Geom."
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We measure bias with a combinatorial parameter defined on classes of concepts known as the growth function [ 43 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We use the following notions from [42,  43 ] (see also [9])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The following result, derived from the pioneering work in [42,  43 ], is a"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 8142232,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a36b028d024bf358c4af1a5e1dc3ca0aed23b553",
            "isKey": true,
            "numCitedBy": 3710,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter reproduces the English translation by B. Seckler of the paper by Vapnik and Chervonenkis in which they gave proofs for the innovative results they had obtained in a draft form in July 1966 and announced in 1968 in their note in Soviet Mathematics Doklady. The paper was first published in Russian as \u0412\u0430\u043f\u043d\u0438\u043a \u0412. \u041d. and \u0427\u0435\u0440\u0432\u043e\u043d\u0435\u043d\u043a\u0438\u0441 \u0410. \u042f. \u041e \u0440\u0430\u0432\u043d\u043e\u043c\u0435\u0440\u043d\u043e\u0419 \u0441\u0445\u043e\u0434\u0438\u043c\u043e\u0441\u0442\u0438 \u0447\u0430\u0441\u0442\u043e\u0442 \u043f\u043e\u044f\u0432\u043b\u0435\u043d\u0438\u044f \u0441\u043e\u0431\u044b\u0442\u0438\u0419 \u043a \u0438\u0445 \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u044f\u043c. \u0422\u0435\u043e\u0440\u0438\u044f \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u0435\u0419 \u0438 \u0435\u0435 \u043f\u0440\u0438\u043c\u0435\u043d\u0435\u043d\u0438\u044f 16(2), 264\u2013279 (1971)."
            },
            "slug": "Chervonenkis:-On-the-uniform-convergence-of-of-to-Vapnik",
            "title": {
                "fragments": [],
                "text": "Chervonenkis: On the uniform convergence of relative frequencies of events to their probabilities"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This chapter reproduces the English translation by B. Seckler of the paper by Vapnik and Chervonenkis in which they gave proofs for the innovative results they had obtained in a draft form in July 1966 and announced in 1968 in their note in Soviet Mathematics Doklady."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2150444582"
                        ],
                        "name": "David S. Johnson",
                        "slug": "David-S.-Johnson",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Johnson",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David S. Johnson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We adapt the greedy heuristic for set cover [ 18 ] to simplify the hypothesis produced by the classical algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 42632644,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "4315baed930e06dac39875eba9e289e95d964309",
            "isKey": false,
            "numCitedBy": 2377,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Simple, polynomial-time, heuristic algorithms for finding approximate solutions to various polynomial complete optimization problems are analyzed with respect to their worst case behavior, measured by the ratio of the worst solution value that can be chosen by the algorithm to the optimal value. For certain problems, such as a simple form of the knapsack problem and an optimization problem based on satisfiability testing, there are algorithms for which this ratio is bounded by a constant, independent of the problem size. For a number of set covering problems, simple algorithms yield worst case ratios which can grow with the log of the problem size. And for the problem of finding the maximum clique in a graph, no algorithm has been found for which the ratio does not grow at least as fast as 0(n\u03b5), where n is the problem size and \u03b5> 0 depends on the algorithm."
            },
            "slug": "Approximation-algorithms-for-combinatorial-problems-Johnson",
            "title": {
                "fragments": [],
                "text": "Approximation Algorithms for Combinatorial Problems"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "For the problem of finding the maximum clique in a graph, no algorithm has been found for which the ratio does not grow at least as fast as 0(n\u03b5), where n is the problem size and \u03b5> 0 depends on the algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "J. Comput. Syst. Sci."
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060896"
                        ],
                        "name": "P. Winston",
                        "slug": "P.-Winston",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Winston",
                            "middleNames": [
                                "Henry"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Winston"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In [15] one extension to structured instance spaces (e.g. the blocks world [ 45 ]) is given."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This work provides one step toward putting the empirical investigations in concept learning since Winston [ 45 ] on a solid theoretical foundation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 106617047,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "a7eb50210a468d0878666e8f82fb55f2b179f802",
            "isKey": false,
            "numCitedBy": 1208,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Massachusetts Institute of Technology. Dept. of Electrical Engineering. Thesis. 1970. Ph.D."
            },
            "slug": "Learning-Structural-Descriptions-From-Examples-Winston",
            "title": {
                "fragments": [],
                "text": "Learning Structural Descriptions From Examples"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2516166"
                        ],
                        "name": "J. Rissanen",
                        "slug": "J.-Rissanen",
                        "structuredName": {
                            "firstName": "Jorma",
                            "lastName": "Rissanen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Rissanen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[24,  33 ]). While many forms of bias have been used, up to this point there has been no generally agreed upon language-independent measure of the strength of a bias, in particular, a measure that relates the strength of a bias to the performance of learning algorithms that use it, so that it will be useful in analyzing and comparing learning algorithms."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 30140639,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d382b9c11e5c6a8e173fbeb442545e3be8d3e3a5",
            "isKey": false,
            "numCitedBy": 6261,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Modeling-By-Shortest-Data-Description*-Rissanen",
            "title": {
                "fragments": [],
                "text": "Modeling By Shortest Data Description*"
            },
            "venue": {
                "fragments": [],
                "text": "Autom."
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2911738"
                        ],
                        "name": "D. Angluin",
                        "slug": "D.-Angluin",
                        "structuredName": {
                            "firstName": "Dana",
                            "lastName": "Angluin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Angluin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 82
                            }
                        ],
                        "text": "Angluin has called this framework \"probably approximately correct\" identification [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 130
                            }
                        ],
                        "text": "ask questions of the form \"is x an instance of the target concept?,\" where x is an instance constructed by the learning algorithm [1, 36,37] (see also [39])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 122024170,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "791414dcd59b84ba3fe60db09d80f5cae9059978",
            "isKey": false,
            "numCitedBy": 540,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of using queries to learn an unknown concept. Several types of queries are described and studied: membership, equivalence, subset, superset, disjointness, and exhaustiveness queries. Examples are given of efficient learning methods using various subsets of these queries for formal domains, including the regular languages, restricted classes of context-free languages, the pattern languages, and restricted types of prepositional formulas. Some general lower bound techniques are given. Equivalence queries are compared with Valiant's criterion of probably approximately correct identification under random sampling."
            },
            "slug": "Queries-and-Concept-Learning-Angluin",
            "title": {
                "fragments": [],
                "text": "Queries and Concept Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "This work considers the problem of using queries to learn an unknown concept, and several types of queries are described and studied: membership, equivalence, subset, superset, disjointness, and exhaustiveness queries."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145634459"
                        ],
                        "name": "M. Garey",
                        "slug": "M.-Garey",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Garey",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Garey"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 232754604,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "08421c787d9a9e2d9f5ba4bda1bfc9866fa4b04f",
            "isKey": false,
            "numCitedBy": 4057,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Johnson:-computers-and-intractability:-a-guide-to-Garey",
            "title": {
                "fragments": [],
                "text": "Johnson: computers and intractability: a guide to the theory of np- completeness (freeman"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 123
                            }
                        ],
                        "text": "In [14] a few speculations on the issue of simultaneously learning sets of related concepts are given, based on ideas from [3, 7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "a basis for pattern recognition and improvement of performance, Adv"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. 24"
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 83
                            }
                        ],
                        "text": "3 given in [5, Appendix] (derived from [42]) is sometimes useful in such cases, in [2] a noisy training data viewpoint is adopted in their development and analysis of a noise resistant learning algorithm for k-CNF concepts in Boolean domains."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning from noisy examples, Machine Learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 69
                            }
                        ],
                        "text": "This learning method can be traced back in various forms at least to [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Study in Thinking (Wiley"
            },
            "venue": {
                "fragments": [],
                "text": "New York,"
            },
            "year": 1956
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 13,
            "methodology": 10,
            "result": 4
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 34,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Quantifying-Inductive-Bias:-AI-Learning-Algorithms-Haussler/3b814ad3055d6bfd7828effdbfbf1372646b7c22?sort=total-citations"
}