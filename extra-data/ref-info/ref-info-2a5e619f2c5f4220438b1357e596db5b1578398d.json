{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 67
                            }
                        ],
                        "text": "This arrangement was chosen because it is exactly what was used in [4] and [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 278,
                                "start": 275
                            }
                        ],
                        "text": "We give results according to seven gures of merit: LR (labeled recall | the number of correct nonterminal labeled constituents divided by the number of such constituents in the tree-bank version) LR2 (LR, but using the slightly idiosyncratic de nition of correctness used in [4]), LP (labeled precision | the number of correct non-terminal labeled constituents divided by the number of such constituents produced by the parser), LP2 (LP, but using the de nition of correctness from [4]), CB (the average number of crossbrackets per sentence), 0CB (percentage of sentences with zero cross-brackets), and 2CB (percentage of sentences with 2 cross-brackets)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12615602,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3764baa7465201f054083d02b58fa75f883c4461",
            "isKey": false,
            "numCitedBy": 736,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a new statistical parser which is based on probabilities of dependencies between head-words in the parse tree. Standard bigram probability estimation techniques are extended to calculate probabilities of dependencies between pairs of words. Tests using Wall Street Journal data show that the method performs at least as well as SPATTER (Magerman 95; Jelinek et al. 94), which has the best published results for a statistical parser on this task. The simplicity of the approach means the model trains on 40,000 sentences in under 15 minutes. With a beam search strategy parsing speed can be improved to over 200 sentences a minute with negligible loss in accuracy."
            },
            "slug": "A-New-Statistical-Parser-Based-on-Bigram-Lexical-Collins",
            "title": {
                "fragments": [],
                "text": "A New Statistical Parser Based on Bigram Lexical Dependencies"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A new statistical parser which is based on probabilities of dependencies between head-words in the parse tree, which trains on 40,000 sentences in under 15 minutes and can be improved to over 200 sentences a minute with negligible loss in accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749837"
                        ],
                        "name": "Eugene Charniak",
                        "slug": "Eugene-Charniak",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Charniak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eugene Charniak"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 12
                            }
                        ],
                        "text": "As noted in [3], this problem is not as bad as people expect, and the tests therein showed that lack of coverage was not a signi cant problem."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 12
                            }
                        ],
                        "text": "However, in [3] parsing is done using only tag sequence information, which, as the PCFG results in Figure 2 show, is a poor system."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 89
                            }
                        ],
                        "text": "First we read a context-free grammar (a tree-bank grammar) o the corpus, as described in [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11171645,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aad8c5ae265e8f645101245afb9d9c9cdf40b4ca",
            "isKey": false,
            "numCitedBy": 387,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "By a \"tree-bank grammar\" we mean a context-free grammar created by reading the production rules directly from hand-parsed sentences in a tree bank. Common wisdom has it that such grammars do not perform we & though we know of no published data on the issue. The primary purpose of this paper is to show that the common wisdom is wrong. In particular, we present results on a tree-bank grammar based on the Penn WaII Street Journal tree bank. To the best of our knowledge, this grammar outperforms ah other non-word-based statistical parsers/grammars on this corpus. That is, it outperforms parsers that consider the input as a string of tags and ignore the actual words of the corpus."
            },
            "slug": "Tree-Bank-Grammars-Charniak",
            "title": {
                "fragments": [],
                "text": "Tree-Bank Grammars"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper presents results on a tree-bank grammar based on the Penn WaII Street Journal tree bank that outperforms other non-word-based statistical parsers/grammars on this corpus and outperforms parsers that consider the input as a string of tags and ignore the actual words of the corpus."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI, Vol. 2"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2580777"
                        ],
                        "name": "David M. Magerman",
                        "slug": "David-M.-Magerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Magerman",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David M. Magerman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 75
                            }
                        ],
                        "text": "This arrangement was chosen because it is exactly what was used in [4] and [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 214
                            }
                        ],
                        "text": "In particular, we designed our experiments to conform exactly to those performed on two previous statistical parsing systems that also used the Penn Wall Street Journal Treebank to train parsers, those of Magerman [5] and"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 608,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f0a14be7e7f5614b91d0f648ae5f2baafc6d7036",
            "isKey": false,
            "numCitedBy": 717,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Syntactic natural language parsers have shown themselves to be inadequate for processing highly-ambiguous large-vocabulary text, as is evidenced by their poor performance on domains like the Wall Street Journal, and by the movement away from parsing-based approaches to text-processing in general. In this paper, I describe SPATTER, a statistical parser based on decision-tree learning techniques which constructs a complete parse for every sentence and achieves accuracy rates far better than any published result. This work is based on the following premises: (1) grammars are too complex and detailed to develop manually for most interesting domains; (2) parsing models must rely heavily on lexical and contextual information to analyze sentences accurately; and (3) existing n-gram modeling techniques are inadequate for parsing models. In experiments comparing SPATTER with IBM's computer manuals parser, SPATTER significantly outperforms the grammar-based parser. Evaluating SPATTER against the Penn Treebank Wall Street Journal corpus using the PARSEVAL measures, SPATTER achieves 86% precision, 86% recall, and 1.3 crossing brackets per sentence for sentences of 40 words or less, and 91% precision, 90% recall, and 0.5 crossing brackets for sentences between 10 and 20 words in length."
            },
            "slug": "Statistical-Decision-Tree-Models-for-Parsing-Magerman",
            "title": {
                "fragments": [],
                "text": "Statistical Decision-Tree Models for Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "SPATTER is described, a statistical parser based on decision-tree learning techniques which constructs a complete parse for every sentence and achieves accuracy rates far better than any published result."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2329862"
                        ],
                        "name": "Sharon A. Caraballo",
                        "slug": "Sharon-A.-Caraballo",
                        "structuredName": {
                            "firstName": "Sharon",
                            "lastName": "Caraballo",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sharon A. Caraballo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749837"
                        ],
                        "name": "Eugene Charniak",
                        "slug": "Eugene-Charniak",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Charniak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eugene Charniak"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 32
                            }
                        ],
                        "text": "Rather, techniques described in [1] are used to select constituents that promise to contribute to the most probable parses, where parse probability is measured according to the simple probabilistic context-free grammar distribution p(r j t)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6243853,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "24e5031c567464b858f86c6ca46331f153399bc6",
            "isKey": false,
            "numCitedBy": 109,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Best-first parsing methods for natural language try to parse efficiently by considering the most likely constituents first. Some figure of merit is needed by which to compare the likelihood of constituents, and the choice of this figure has a substantial impact on the efficiency of the parser. While several parsers described in the literature have used such techniques, there is little published data on their efficacy, much less attempts to judge their relative merits. We propose and evaluate several figures of merit for best-first parsing, and we identify an easily computable figure of merit that provides excellent performance on various measures and two different grammars."
            },
            "slug": "Figures-of-Merit-for-Best-First-Probabilistic-Chart-Caraballo-Charniak",
            "title": {
                "fragments": [],
                "text": "New Figures of Merit for Best-First Probabilistic Chart Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work proposes and evaluates several figures of merit for best-first parsing, and identifies an easily computable figure of merit that provides excellent performance on various measures and two different grammars."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734174"
                        ],
                        "name": "M. Marcus",
                        "slug": "M.-Marcus",
                        "structuredName": {
                            "firstName": "Mitchell",
                            "lastName": "Marcus",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Marcus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2424234"
                        ],
                        "name": "Beatrice Santorini",
                        "slug": "Beatrice-Santorini",
                        "structuredName": {
                            "firstName": "Beatrice",
                            "lastName": "Santorini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Beatrice Santorini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2063206"
                        ],
                        "name": "Mary Ann Marcinkiewicz",
                        "slug": "Mary-Ann-Marcinkiewicz",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Marcinkiewicz",
                            "middleNames": [
                                "Ann"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mary Ann Marcinkiewicz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 26
                            }
                        ],
                        "text": "(In this paper we use the Penn Wall Street Journal Treebank [6].)"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 51
                            }
                        ],
                        "text": "paper we use the Penn Wall Street Journal Treebank [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 144
                            }
                        ],
                        "text": "In particular, we designed our experiments to conform exactly to those performed on two previous statistical parsing systems that also used the Penn Wall Street Journal Treebank to train parsers, those of Magerman [5] and Collins [4]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 73
                            }
                        ],
                        "text": "We trained our parser on sections 02-21 (about one million words) of the Penn Wall Street Journal Treebank and tested the parser on section 23 (50,000 words)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 252796,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0b44fcbeea9415d400c5f5789d6b892b6f98daff",
            "isKey": true,
            "numCitedBy": 8177,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : As a result of this grant, the researchers have now published oil CDROM a corpus of over 4 million words of running text annotated with part-of- speech (POS) tags, with over 3 million words of that material assigned skeletal grammatical structure. This material now includes a fully hand-parsed version of the classic Brown corpus. About one half of the papers at the ACL Workshop on Using Large Text Corpora this past summer were based on the materials generated by this grant."
            },
            "slug": "Building-a-Large-Annotated-Corpus-of-English:-The-Marcus-Santorini",
            "title": {
                "fragments": [],
                "text": "Building a Large Annotated Corpus of English: The Penn Treebank"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "As a result of this grant, the researchers have now published on CDROM a corpus of over 4 million words of running text annotated with part-of- speech (POS) tags, which includes a fully hand-parsed version of the classic Brown corpus."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777660"
                        ],
                        "name": "Naftali Tishby",
                        "slug": "Naftali-Tishby",
                        "structuredName": {
                            "firstName": "Naftali",
                            "lastName": "Tishby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naftali Tishby"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145810617"
                        ],
                        "name": "Lillian Lee",
                        "slug": "Lillian-Lee",
                        "structuredName": {
                            "firstName": "Lillian",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lillian Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 106
                            }
                        ],
                        "text": "We do not describe the clustering method here except to note that it uses a scheme something like that in [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6713452,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5eb328cf7e94995199e4c82a1f4d0696430a80b5",
            "isKey": false,
            "numCitedBy": 1193,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe and evaluate experimentally a method for clustering words according to their distribution in particular syntactic contexts. Words are represented by the relative frequency distributions of contexts in which they appear, and relative entropy between those distributions is used as the similarity measure for clustering. Clusters are represented by average context distributions derived from the given words according to their probabilities of cluster membership. In many cases, the clusters can be thought of as encoding coarse sense distinctions. Deterministic annealing is used to find lowest distortion sets of clusters: as the annealing parameter increases, existing clusters become unstable and subdivide, yielding a hierarchical \"soft\" clustering of the data. Clusters are used as the basis for class models of word coocurrence, and the models evaluated with respect to held-out test data."
            },
            "slug": "Distributional-Clustering-of-English-Words-Pereira-Tishby",
            "title": {
                "fragments": [],
                "text": "Distributional Clustering of English Words"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Deterministic annealing is used to find lowest distortion sets of clusters: as the annealed parameter increases, existing clusters become unstable and subdivide, yielding a hierarchical \"soft\" clustering of the data."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749837"
                        ],
                        "name": "Eugene Charniak",
                        "slug": "Eugene-Charniak",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Charniak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eugene Charniak"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 29
                            }
                        ],
                        "text": "\" Our method is described in [2] and is not discussed further here."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7897168,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e64726f878d4dad99608487d75070e7ae52e7796",
            "isKey": false,
            "numCitedBy": 1,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Expected-frequency interpolation is a technique for improving the performance of deleted interpolation smoothing. It allows a system to make ner-grained estimates of how often one would expect to see a particular combination of events than is possible with traditional frequency interpolation. This allows the system to better weigh the emphasis given to the various probablity distributions being mixed. We show that more traditional frequency interpolation, based solely on the frequency of conditioning events, can lead to some anomalous results. We then show that while the equations for expected-frequency interpolation are not exact, they are close, depending on how well some seemingly reasonable assumptions hold. We then present an experiment in which the introduction of expected-frequence interpolation to a statistical parsing system improved performance by .4% with essentially no extra work, and essentially no change in the workings of the system. We also note that even before the change, the system in question was the top performer at its task, so a .4% improvement was well worth obtaining."
            },
            "slug": "Expected-frequency-Interpolation-Expected-frequency-Charniak",
            "title": {
                "fragments": [],
                "text": "Expected-frequency Interpolation Expected-frequency Interpolation"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work presents an experiment in which the introduction of expected-frequence interpolation to a statistical parsing system improved performance by .4% with essentially no extra work, and essentially no change in the workings of the system."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749837"
                        ],
                        "name": "Eugene Charniak",
                        "slug": "Eugene-Charniak",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Charniak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eugene Charniak"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118358528,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cb7326e0f8b6088cef44b893ef6ffb6598a50a4e",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Expected-frequency interpolation is a technique for improving the performance of deleted interpolation smoothing. It allows a system to make finer-grained estimates of how often one would expect to see a particular combination of events than is possible with traditional frequency interpolation. This allows the system to better weigh the emphasis given to the various probability distributions being mixed. We show that more traditional frequency interpolation, based solely on the frequency of conditioning events, can lead to some anomalous results. We then show that while the equations for expected-frequency interpolation are not exact, they are close, depending on how well some seemingly reasonable assumptions hold. We then present an experiment in which the introduction of expected-frequency interpolation to a statistical parsing system improved performance by .4\\ workings of the system. We also note that even before the change, the system in question was the top performer at its task, so a .4\\ improvement was well worth obtaining."
            },
            "slug": "Expected-Frequency-Interpolation-Charniak",
            "title": {
                "fragments": [],
                "text": "Expected-Frequency Interpolation"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work presents an experiment in which the introduction of expected-frequency interpolation to a statistical parsing system improved performance by .4, and notes that even before the change, the system in question was the top performer at its task, so a .4 improvement was well worth obtaining."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Figures ofmerit for bestrst probabilistic chart parsing"
            },
            "venue": {
                "fragments": [],
                "text": "InProceedings of the Conference on Empirical Methods in Natural Language Processing"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Distributional clustering of English words. I n Proceedings of the Association for Computational Linguistics. ACL"
            },
            "venue": {
                "fragments": [],
                "text": "Distributional clustering of English words. I n Proceedings of the Association for Computational Linguistics. ACL"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical decisiontree models for parsing"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 33 rd AnnualMeeting of the Association for Computational Linguistics"
            },
            "year": 1995
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 1,
            "methodology": 7
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 11,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Statistical-Parsing-with-a-Context-Free-Grammar-and-Charniak/2a5e619f2c5f4220438b1357e596db5b1578398d?sort=total-citations"
}