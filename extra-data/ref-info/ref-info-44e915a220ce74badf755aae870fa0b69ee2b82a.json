{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34938639"
                        ],
                        "name": "W. Gale",
                        "slug": "W.-Gale",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Gale",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Gale"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 82
                            }
                        ],
                        "text": "Indeed, we know of many applications of multinomial models to text categorization [3,14, 15,25, 32, 34] but none to text retrieval."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 915058,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5194b668c67aa83c037e71599a087f63c98eb713",
            "isKey": false,
            "numCitedBy": 2404,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "The ability to cheaply train text classifiers is critical to their use in information retrieval, content analysis, natural language processing, and other tasks involving data which is partly or fully textual. An algorithm for sequential sampling during machine learning of statistical classifiers was developed and tested on a newswire text categorization task. This method, which we call uncertainty sampling, reduced by as much as 500-fold the amount of training data that would have to be manually classified to achieve a given level of effectiveness."
            },
            "slug": "A-sequential-algorithm-for-training-text-Lewis-Gale",
            "title": {
                "fragments": [],
                "text": "A sequential algorithm for training text classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An algorithm for sequential sampling during machine learning of statistical classifiers was developed and tested on a newswire text categorization task and reduced by as much as 500-fold the amount of training data that would have to be manually classified to achieve a given level of effectiveness."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '94"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144864352"
                        ],
                        "name": "M. Maron",
                        "slug": "M.-Maron",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Maron",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Maron"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 217
                            }
                        ],
                        "text": "Machine learning researchers tend to be aware of the large pattern recognition literature on naive Bayes, but may be less aware of an equally large information retrieval (IR) literature dating back almost forty years [37,38]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 212
                            }
                        ],
                        "text": "Its use in the form ofEquation 11 was promoted by Robertson and Sparck Jones in a paper [41] thatdid much to clarify and unify a number of related and partially ad hoc applica-tions of naive Bayes dating back to Maron [37]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 219
                            }
                        ],
                        "text": "Its use in the form of Equation 11 was promoted by Robertson and Sparck Jones in a paper [41] that did much to clarify and unify a number of related and partially ad hoc applications of naive Bayes dating back to Maron [37]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 6
                            }
                        ],
                        "text": "M. E. Maron and J. L. Kuhns."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 6
                            }
                        ],
                        "text": "M. E. Maron."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6692916,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c390dbf06af49d3691bc7b906f5fd9b909c2f89b",
            "isKey": true,
            "numCitedBy": 519,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "This inquiry examines a technique for automatically classifying (indexing) documents according to their subject content. The task, in essence, is to have a computing machine read a document and on the basis of the occurrence of selected clue words decide to which of many subject categories the document in question belongs. This paper describes the design, execution and evaluation of a modest experimental study aimed at testing empirically one statistical technique for automatic indexing."
            },
            "slug": "Automatic-Indexing:-An-Experimental-Inquiry-Maron",
            "title": {
                "fragments": [],
                "text": "Automatic Indexing: An Experimental Inquiry"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "The design, execution and evaluation of a modest experimental study aimed at testing empirically one statistical technique for automatic indexed documents according to their subject content are described."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1961
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726733"
                        ],
                        "name": "Ron Kohavi",
                        "slug": "Ron-Kohavi",
                        "structuredName": {
                            "firstName": "Ron",
                            "lastName": "Kohavi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ron Kohavi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8314975,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "34ae1e95775cfec793441c9f588a68c0020f21e5",
            "isKey": false,
            "numCitedBy": 1511,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Naive-Bayes induction algorithms were previously shown to be surprisingly accurate on many classification tasks even when the conditional independence assumption on which they are based is violated. However, most studies were done on small databases. We show that in some larger databases, the accuracy of Naive-Bayes does not scale up as well as decision trees. We then propose a new algorithm, NBTree, which induces a hybrid of decision-tree classifiers and Naive-Bayes classifiers: the decision-tree nodes contain univariate splits as regular decision-trees, but the leaves contain Naive-Bayesian classifiers. The approach retains the interpretability of Naive-Bayes and decision trees, while resulting in classifiers that frequently outperform both constituents, especially in the larger databases tested."
            },
            "slug": "Scaling-Up-the-Accuracy-of-Naive-Bayes-Classifiers:-Kohavi",
            "title": {
                "fragments": [],
                "text": "Scaling Up the Accuracy of Naive-Bayes Classifiers: A Decision-Tree Hybrid"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A new algorithm, NBTree, is proposed, which induces a hybrid of decision-tree classifiers and Naive-Bayes classifiers: the decision-Tree nodes contain univariate splits as regular decision-trees, but the leaves contain Na\u00efve-Bayesian classifiers."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144430625"
                        ],
                        "name": "S. Robertson",
                        "slug": "S.-Robertson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Robertson",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Robertson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48872185"
                        ],
                        "name": "S. Walker",
                        "slug": "S.-Walker",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Walker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Walker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 178
                            }
                        ],
                        "text": "In contrast, a recently proposed term weighting formula which rescales the BIM weight to in some ways approximate the behavior of a two-Poisson model has proven quite successful [43]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 108
                            }
                        ],
                        "text": "While a case can be made that longer documents are somewhat more likely to be of interest to any given user [43,47], the above e ect is likely to be far stronger than appropriate."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2218552,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c0a48ed7577a7b48288dfb2711cbd86e30636b5f",
            "isKey": false,
            "numCitedBy": 1455,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "The 2-Poisson model for term frequencies is used to suggest ways of incorporating certain variables in probabilistic models for information retrieval. The variables concerned are within-document term frequency, document length, and within-query term frequency. Simple weighting functions are developed, and tested on the TREC test collection. Considerable performance improvements (over simple inverse collection frequency weighting) are demonstrated."
            },
            "slug": "Some-simple-effective-approximations-to-the-model-Robertson-Walker",
            "title": {
                "fragments": [],
                "text": "Some simple effective approximations to the 2-Poisson model for probabilistic weighted retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "The 2-Poisson model for term frequencies is used to suggest ways of incorporating certain variables in probabilistic models for information retrieval, and substantial performance improvements are demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '94"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144850246"
                        ],
                        "name": "Louise Guthrie",
                        "slug": "Louise-Guthrie",
                        "structuredName": {
                            "firstName": "Louise",
                            "lastName": "Guthrie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Louise Guthrie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2967060"
                        ],
                        "name": "E. Walker",
                        "slug": "E.-Walker",
                        "structuredName": {
                            "firstName": "Elbert",
                            "lastName": "Walker",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Walker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9108563,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "171592f09aeb1e8720154e4f0b5d59b81b5f9a10",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "In this note, we present results concerning the theory and practice of determining for a given document which of several categories it best fits. We describe a mathematical model of classification schemes and the one scheme which can be proved optimal among all those based on word frequencies. Finally, we report the results of an experiment which illustrates the efficacy of this classification method."
            },
            "slug": "Document-Classification-by-Machine:Theory-and-Guthrie-Walker",
            "title": {
                "fragments": [],
                "text": "Document Classification by Machine:Theory and Practice"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A mathematical model of classification schemes and the one scheme which can be proved optimal among all those based on word frequencies is described and an experiment illustrates the efficacy of this classification method."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145848824"
                        ],
                        "name": "Karen Sp\u00e4rck Jones",
                        "slug": "Karen-Sp\u00e4rck-Jones",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Sp\u00e4rck Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karen Sp\u00e4rck Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 167
                            }
                        ],
                        "text": "An ongoing surprise and disappointment is that structurally simple representations produced without linguistic or domain knowledge have been as e ective as any others [30, 33]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13774241,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d51ef575fe2317411b1395dc823a7d1625626864",
            "isKey": false,
            "numCitedBy": 170,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper summarizes the essential properties of document retrieval and reviews both conventional practice and research findings, the latter suggesting that simple statistical techniques can be effective. It then considers the new opportunities and challenges presented by the user\u2019s ability to search full text directly (rather than e.g. titles and abstracts), and suggests appropriate approaches to doing this, with a focus on the potential role of natural language processing. The paper also comments on possible connections with data and knowledge retrieval, and concludes by emphasizing the importance of rigorous performance testing."
            },
            "slug": "Natural-language-processing-for-information-Lewis-Jones",
            "title": {
                "fragments": [],
                "text": "Natural language processing for information retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The paper considers the new opportunities and challenges presented by the user\u2019s ability to search full text directly (rather than e.g. titles and abstracts), and suggests appropriate approaches to doing this, with a focus on the potential role of natural language processing."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2997706"
                        ],
                        "name": "B. D. Favero",
                        "slug": "B.-D.-Favero",
                        "structuredName": {
                            "firstName": "Brendan",
                            "lastName": "Favero",
                            "middleNames": [
                                "Del"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. D. Favero"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "25238251"
                        ],
                        "name": "R. Fung",
                        "slug": "R.-Fung",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Fung",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fung"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 33162243,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b84c0819718a783e0d1f0b6d3bb62192c09911ff",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe research that adapts and applies Bayesian networks, a new technology for probabilistic representation and inference, to information retrieval. Our research is directed at developing a probabilistic information retrieval architecture that is oriented towards assisting users that have stable information needs in routing large amounts of time-sensitive material; gives users an intuitive language with which to specify their information needs; requires modest computational resources (memory, CPU need); can integrate relevance feedback and training data with users'judgments to incrementally improve retrieval performance"
            },
            "slug": "Bayesian-Inference-with-Node-Aggregation-for-Favero-Fung",
            "title": {
                "fragments": [],
                "text": "Bayesian Inference with Node Aggregation for Information Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Research is directed at developing a probabilistic information retrieval architecture that is oriented towards assisting users that have stable information needs in routing large amounts of time-sensitive material and requires modest computational resources."
            },
            "venue": {
                "fragments": [],
                "text": "TREC"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2131200"
                        ],
                        "name": "A. Bookstein",
                        "slug": "A.-Bookstein",
                        "structuredName": {
                            "firstName": "Abraham",
                            "lastName": "Bookstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bookstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720134"
                        ],
                        "name": "D. Kraft",
                        "slug": "D.-Kraft",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Kraft",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kraft"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 124
                            }
                        ],
                        "text": "The distributions investigated have mostly been Poisson mixtures [4, 26]:the Poisson itself [40], mixtures of 2, 3, or more Poissons [1, 2, 22, 23, 36], andthe negative binomial (an in nite mixture of Poissons) [40]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 134
                            }
                        ],
                        "text": "The distributions investigated have mostly been Poisson mixtures [4, 26]: the Poisson itself [40], mixtures of 2, 3, or more Poissons [1, 2, 22, 23, 36], and the negative binomial (an in nite mixture of Poissons) [40]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14921313,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "48a51d60453c8cfce7e15e9068edd26145ffc724",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper begins with a review of earher work in which a model of word occurrence formed the basis of a decision-making procedure for indexing or, more generally, retrieving documents in response to a request In the earlier work words were considered individually This paper extends the earher model to include interactions among terms The elaborated model allows one to decide whether to retrieve a document by taking into consideration occurrences of all the words in the text Retrieval in response to Boolean expresstons IS also considered, as are procedures for ranking documents in accordance with their assessed relevance to a request The discussion is within the framework of Bayesian decision theory"
            },
            "slug": "Operations-Research-Applied-to-Document-Indexing-Bookstein-Kraft",
            "title": {
                "fragments": [],
                "text": "Operations Research Applied to Document Indexing and Retrieval Decisions"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The earher model is extended to include interactions among terms, which allows one to decide whether to retrieve a document by taking into consideration occurrences of all the words in the text."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2131200"
                        ],
                        "name": "A. Bookstein",
                        "slug": "A.-Bookstein",
                        "structuredName": {
                            "firstName": "Abraham",
                            "lastName": "Bookstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bookstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2657101"
                        ],
                        "name": "D. R. Swanson",
                        "slug": "D.-R.-Swanson",
                        "structuredName": {
                            "firstName": "Don",
                            "lastName": "Swanson",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. R. Swanson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 124
                            }
                        ],
                        "text": "The distributions investigated have mostly been Poisson mixtures [4, 26]:the Poisson itself [40], mixtures of 2, 3, or more Poissons [1, 2, 22, 23, 36], andthe negative binomial (an in nite mixture of Poissons) [40]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 134
                            }
                        ],
                        "text": "The distributions investigated have mostly been Poisson mixtures [4, 26]: the Poisson itself [40], mixtures of 2, 3, or more Poissons [1, 2, 22, 23, 36], and the negative binomial (an in nite mixture of Poissons) [40]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 35279168,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "401bc9e340bb654f1405dd45edd8c80014702bf5",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "The indexing of a document is among the most crucial steps in preparing that document for retrieval. The adequacy of the indexing determines the ability of the system to respond to patron requests. This paper discusses this process, and document retrieval in general, on the basis of formal decision theory. The basic theoretical approach taken is illustrated by means of a model of word occurrences in documents in the context of a model information system; both models are fully defined in this paper. Though the main purpose of this paper is to provide insights into a very complex process, formulae are developed that may prove to be of value for an automated operating system. The paper concludes with an interpretation of recall and precision curves as seen from the point of view of decision theory."
            },
            "slug": "A-decision-theoretic-foundation-for-indexing-Bookstein-Swanson",
            "title": {
                "fragments": [],
                "text": "A decision theoretic foundation for indexing"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Though the main purpose of this paper is to provide insights into a very complex process, formulae are developed that may prove to be of value for an automated operating system."
            },
            "venue": {
                "fragments": [],
                "text": "J. Am. Soc. Inf. Sci."
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118384802"
                        ],
                        "name": "Hang Li",
                        "slug": "Hang-Li",
                        "structuredName": {
                            "firstName": "Hang",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hang Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34755863"
                        ],
                        "name": "K. Yamanishi",
                        "slug": "K.-Yamanishi",
                        "structuredName": {
                            "firstName": "Kenji",
                            "lastName": "Yamanishi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Yamanishi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 870921,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0b23eebc89f4da28e44fadac779ae334a019db80",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new method of classifying documents into categories. We define for each category a finite mixture model based on soft clustering of words. We treat the problem of classifying documents as that of conducting statistical hypothesis testing over finite mixture models, and employ the EM algorithm to efficiently estimate parameters in a finite mixture model. Experimental results indicate that our method outperforms existing methods."
            },
            "slug": "Document-Classification-Using-a-Finite-Mixture-Li-Yamanishi",
            "title": {
                "fragments": [],
                "text": "Document Classification Using a Finite Mixture Model"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This work treats the problem of classifying documents as that of conducting statistical hypothesis testing over finite mixture models, and employs the EM algorithm to efficiently estimate parameters in a finite mixture model."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 82
                            }
                        ],
                        "text": "Indeed, we know of many applications of multinomial models to text categorization [3,14, 15,25, 32, 34] but none to text retrieval."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2427083,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "40212e9474c3ddf3d8c6ffd13dd3211ec9406c49",
            "isKey": false,
            "numCitedBy": 8601,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper explores the use of Support Vector Machines (SVMs) for learning text classifiers from examples. It analyzes the particular properties of learning with text data and identifies why SVMs are appropriate for this task. Empirical results support the theoretical findings. SVMs achieve substantial improvements over the currently best performing methods and behave robustly over a variety of different learning tasks. Furthermore they are fully automatic, eliminating the need for manual parameter tuning."
            },
            "slug": "Text-Categorization-with-Support-Vector-Machines:-Joachims",
            "title": {
                "fragments": [],
                "text": "Text Categorization with Support Vector Machines: Learning with Many Relevant Features"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "This paper explores the use of Support Vector Machines for learning text classifiers from examples and analyzes the particular properties of learning with text data and identifies why SVMs are appropriate for this task."
            },
            "venue": {
                "fragments": [],
                "text": "ECML"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2126632"
                        ],
                        "name": "W. S. Cooper",
                        "slug": "W.-S.-Cooper",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Cooper",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. S. Cooper"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11966912,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "07ed0db70bd575984a764c45ed52da357d0be884",
            "isKey": false,
            "numCitedBy": 84,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Research in the probabilistic theory of information retrieval involves the construction of mathematical models based on statistical assumptions. One of the hazards inherent in this kind of theory construction is that the assumptions laid down maybe inconsmtent in unanticipated ways with the data to which they are applied. Another hazard is that the stated assumptions may not be those on which the derived modeling equations or resulting experiments are actually based. Both kinds of mistakes have been made m past research on probabihstic reformation retrieval. One consequence of these errors is that the statistical character of certain probabilistic IR models, including the so-called Binary Independence model, has been seriously misapprehended"
            },
            "slug": "Some-inconsistencies-and-misidentified-modeling-in-Cooper",
            "title": {
                "fragments": [],
                "text": "Some inconsistencies and misidentified modeling assumptions in probabilistic information retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "Research in the probabilistic theory of information retrieval involves the construction of mathematical models based on statistical assumptions, including the so-called Binary Independence model, which has been seriously misapprehended."
            },
            "venue": {
                "fragments": [],
                "text": "TOIS"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144456145"
                        ],
                        "name": "W. Bruce Croft",
                        "slug": "W.-Bruce-Croft",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Croft",
                            "middleNames": [
                                "Bruce"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Bruce Croft"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62730381,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "13b2a45d9bbd743433eb231c5a6db0074b04b06f",
            "isKey": false,
            "numCitedBy": 57,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "A method of integrating Boolean queries with probabilistic retrieval models is proposed. Boolean queries are interpreted as specifying term dependencies that can be used to correct the document scores obtained with a basic probabilistic model. Alternative methods of obtaining dependency information, such as user-specified phrases, can also be used in this approach. The experimental results indicate that significant performance benefits can be obtained, particularly when dependencies are derived from term phrases identified in natural language queries. \u00a9 1986 John Wiley & Sons, Inc."
            },
            "slug": "Boolean-Queries-and-Term-Dependencies-in-Retrieval-Croft",
            "title": {
                "fragments": [],
                "text": "Boolean Queries and Term Dependencies in Probabilistic Retrieval Models."
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "A method of integrating Boolean queries with probabilistic retrieval models is proposed and the experimental results indicate that significant performance benefits can be obtained, particularly when dependencies are derived from term phrases identified in natural language queries."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144430625"
                        ],
                        "name": "S. Robertson",
                        "slug": "S.-Robertson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Robertson",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Robertson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145848824"
                        ],
                        "name": "Karen Sp\u00e4rck Jones",
                        "slug": "Karen-Sp\u00e4rck-Jones",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Sp\u00e4rck Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karen Sp\u00e4rck Jones"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 89
                            }
                        ],
                        "text": "Its use in the form of Equation 11 was promoted by Robertson and Sparck Jones in a paper [41] that did much to clarify and unify a number of related and partially ad hoc applications of naive Bayes dating back to Maron [37]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 236,
                                "start": 229
                            }
                        ],
                        "text": "That is, if one sets the initial score of a document to be the constant term in Equation 11, the full score can be computed by adding up values involving only those words present in a document, not those absent from the document [41,48]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 45186038,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6e3e57567e9803718623ec088cd7fea65cfbc9d",
            "isKey": false,
            "numCitedBy": 2372,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper examines statistical techniques for exploiting relevance information to weight search terms. These techniques are presented as a natural extension of weighting methods using information about the distribution of index terms in documents in general. A series of relevance weighting functions is derived and is justified by theoretical considerations. In particular, it is shown that specific weighted search methods are implied by a general probabilistic theory of retrieval. Different applications of relevance weighting are illustrated by experimental results for test collections."
            },
            "slug": "Relevance-weighting-of-search-terms-Robertson-Jones",
            "title": {
                "fragments": [],
                "text": "Relevance weighting of search terms"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "This paper examines statistical techniques for exploiting relevance information to weight search terms using information about the distribution of index terms in documents in general and shows that specific weighted search methods are implied by a general probabilistic theory of retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "J. Am. Soc. Inf. Sci."
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144430625"
                        ],
                        "name": "S. Robertson",
                        "slug": "S.-Robertson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Robertson",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Robertson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "115491216"
                        ],
                        "name": "C. J. V. Rijsbergen",
                        "slug": "C.-J.-V.-Rijsbergen",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Rijsbergen",
                            "middleNames": [
                                "J.",
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. J. V. Rijsbergen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057287718"
                        ],
                        "name": "M. Porter",
                        "slug": "M.-Porter",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Porter",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Porter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 129
                            }
                        ],
                        "text": "Despite considerable study, explicit use of Poisson mixtures for text retrieval have not proven more e ective than using the BIM [35,42]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 312,
                                "start": 309
                            }
                        ],
                        "text": "Indeed, weknow of many applications of multinomial models to text categorization [3,14,15,25, 32, 34] but none to text retrieval.5.3 Non-Distributional ApproachesA variety of ad hoc approaches have been developed that more or less grace-fully integrate term frequency and document length information into the BIM"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 74
                            }
                        ],
                        "text": "In contrast, a recently proposed term weighting formula which rescalesthe BIM weight to in some ways approximate the behavior of a two-Poissonmodel has proven quite successful [43]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 116
                            }
                        ],
                        "text": "As a document gets longer,the number of distinct words used, and thus the number of values of xj thatequal 1 in the BIM, will in general increase."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 169
                            }
                        ],
                        "text": "Such an estimate is di cult to obtain either from users or from thesmall, nonrandom samples available for training in a relevance feedback context.4.1 Weaknesses of the BIMWhile the BIM has been very in uential in information retrieval, it has short-comings that mean it is now rarely used in the pure form given above."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 344,
                                "start": 341
                            }
                        ],
                        "text": "Rather than attemptto survey the variations here, we refer the reader to the above references, withthe suggestion that the book by Mosteller and Wallace [40] is the most cleartreatment from a classi cation standpoint.Despite considerable study, explicit use of Poisson mixtures for text retrievalhave not proven more e ective than using the BIM [35,42]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 329,
                                "start": 326
                            }
                        ],
                        "text": "While a case can be made thatlonger documents are somewhat more likely to be of interest to any given user[43,47], the above e ect is likely to be far stronger than appropriate.5 Other Distributional ModelsIn this section we look at a number of variations on the naive Bayes model thatattempt to address the weaknesses of the BIM.5.1 Distributions for Integer-Valued FeaturesThe most straightforward generalization of the BIM is to let the Xj be integer-valued random variables corresponding to term frequencies, that is counts of thenumber of occurrences of words in a document."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 75
                            }
                        ],
                        "text": "weakness is that by considering only the presence or absence of terms, the BIMignores information inherent in the frequencies of terms."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15525525,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "701db31a4914bb3cbdbeb443a289fe07f535ea7a",
            "isKey": true,
            "numCitedBy": 363,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "for example, Robertson and Sparck Jones, 1976; van Rijsbergen, 1977; Harper and van Rijsbergen, 1978), and the work done in the USA on automatic indexing using within-document frequencies of terms (notably by Bookstein and Swanson, 1974, 1975; Harter, 1975a, b; Bookstein and Kraft, 1977). (There is a considerable body of related work by Salton, Yu and associates"
            },
            "slug": "Probabilistic-models-of-indexing-and-searching-Robertson-Rijsbergen",
            "title": {
                "fragments": [],
                "text": "Probabilistic models of indexing and searching"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "There is a considerable body of related work by Salton, Yu and associates on automatic indexing using within-document frequencies of terms."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '80"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2223928"
                        ],
                        "name": "G. Kowalski",
                        "slug": "G.-Kowalski",
                        "structuredName": {
                            "firstName": "Gerald",
                            "lastName": "Kowalski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Kowalski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 60990482,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e94491617f847ffca10b3e17ecf54c91e09a7883",
            "isKey": false,
            "numCitedBy": 385,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Information-Retrieval-Systems:-Theory-and-Kowalski",
            "title": {
                "fragments": [],
                "text": "Information Retrieval Systems: Theory and Implementation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144864352"
                        ],
                        "name": "M. Maron",
                        "slug": "M.-Maron",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Maron",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Maron"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29579066"
                        ],
                        "name": "J. L. Kuhns",
                        "slug": "J.-L.-Kuhns",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Kuhns",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. L. Kuhns"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 217
                            }
                        ],
                        "text": "Machine learning researchers tend to be aware of the large pattern recognition literature on naive Bayes, but may be less aware of an equally large information retrieval (IR) literature dating back almost forty years [37,38]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11592162,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5e52c6ff85ac6d53cb0dac8581c0a76edc6fade7",
            "isKey": false,
            "numCitedBy": 972,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper reports on a novel technique for literature indexing and searching in a mechanized library system. The notion of relevance is taken as the key concept in the theory of information retrieval and a comparative concept of relevance is explicated in terms of the theory of probability. The resulting technique called \u201cProbabilistic Indexing,\u201d allows a computing machine, given a request for information, to make a statistical inference and derive a number (called the \u201crelevance number\u201d) for each document, which is a measure of the probability that the document will satisfy the given request. The result of a search is an ordered list of those documents which satisfy the request ranked according to their probable relevance.\nThe paper goes on to show that whereas in a conventional library system the cross-referencing (\u201csee\u201d and \u201csee also\u201d) is based solely on the \u201csemantical closeness\u201d between index terms, statistical measures of closeness between index terms can be defined and computed. Thus, given an arbitrary request consisting of one (or many) index term(s), a machine can elaborate on it to increase the probability of selecting relevant documents that would not otherwise have been selected.\nFinally, the paper suggests an interpretation of the whole library problem as one where the request is considered as a clue on the basis of which the library system makes a concatenated statistical inference in order to provide as an output an ordered list of those documents which most probably satisfy the information needs of the user."
            },
            "slug": "On-Relevance,-Probabilistic-Indexing-and-Retrieval-Maron-Kuhns",
            "title": {
                "fragments": [],
                "text": "On Relevance, Probabilistic Indexing and Information Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The paper suggests an interpretation of the whole library problem as one where the request is considered as a clue on the basis of which the library system makes a concatenated statistical inference in order to provide as an output an ordered list of those documents which most probably satisfy the information needs of the user."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1960
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50056360"
                        ],
                        "name": "William W. Cohen",
                        "slug": "William-W.-Cohen",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Cohen",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William W. Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740765"
                        ],
                        "name": "Y. Singer",
                        "slug": "Y.-Singer",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Singer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5327274,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce2d6de9cec4a6d135c32bb8d2d02bba09928b33",
            "isKey": false,
            "numCitedBy": 572,
            "numCiting": 80,
            "paperAbstract": {
                "fragments": [],
                "text": "Two recently implemented machine-learning algorithms, RIPPER and sleeping-experts for phrases, are evaluated on a number of large text categorization problems. These algorithms both construct classifiers that allow the \u201ccontext\u201d of a word w to affect how (or even whether) the presence or absence of w will contribute to a classification. However, RIPPER and sleeping-experts differ radically in many other respects: differences include different notions as to what constitutes a context, different ways of combining contexts to construct a classifier, different methods to search for a combination of contexts, and different criteria as to what contexts should be included in such a combination. In spite of these differences, both RIPPER and sleeping-experts perform extremely well across a wide variety of categorization problems, generally outperforming previously applied learning methods. We view this result as a confirmation of the usefulness of classifiers that represent contextual information."
            },
            "slug": "Context-sensitive-learning-methods-for-text-Cohen-Singer",
            "title": {
                "fragments": [],
                "text": "Context-sensitive learning methods for text categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "RIPPER and sleeping-experts perform extremely well across a wide variety of categorization problems, generally outperforming previously applied learning methods and are viewed as a confirmation of the usefulness of classifiers that represent contextual information."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '96"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804272"
                        ],
                        "name": "R. Losee",
                        "slug": "R.-Losee",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Losee",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Losee"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 129
                            }
                        ],
                        "text": "Despite considerable study, explicit use of Poisson mixtures for text retrieval have not proven more e ective than using the BIM [35,42]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 312,
                                "start": 309
                            }
                        ],
                        "text": "Indeed, weknow of many applications of multinomial models to text categorization [3,14,15,25, 32, 34] but none to text retrieval.5.3 Non-Distributional ApproachesA variety of ad hoc approaches have been developed that more or less grace-fully integrate term frequency and document length information into the BIM"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 74
                            }
                        ],
                        "text": "In contrast, a recently proposed term weighting formula which rescalesthe BIM weight to in some ways approximate the behavior of a two-Poissonmodel has proven quite successful [43]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 116
                            }
                        ],
                        "text": "As a document gets longer,the number of distinct words used, and thus the number of values of xj thatequal 1 in the BIM, will in general increase."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 169
                            }
                        ],
                        "text": "Such an estimate is di cult to obtain either from users or from thesmall, nonrandom samples available for training in a relevance feedback context.4.1 Weaknesses of the BIMWhile the BIM has been very in uential in information retrieval, it has short-comings that mean it is now rarely used in the pure form given above."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 344,
                                "start": 341
                            }
                        ],
                        "text": "Rather than attemptto survey the variations here, we refer the reader to the above references, withthe suggestion that the book by Mosteller and Wallace [40] is the most cleartreatment from a classi cation standpoint.Despite considerable study, explicit use of Poisson mixtures for text retrievalhave not proven more e ective than using the BIM [35,42]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 329,
                                "start": 326
                            }
                        ],
                        "text": "While a case can be made thatlonger documents are somewhat more likely to be of interest to any given user[43,47], the above e ect is likely to be far stronger than appropriate.5 Other Distributional ModelsIn this section we look at a number of variations on the naive Bayes model thatattempt to address the weaknesses of the BIM.5.1 Distributions for Integer-Valued FeaturesThe most straightforward generalization of the BIM is to let the Xj be integer-valued random variables corresponding to term frequencies, that is counts of thenumber of occurrences of words in a document."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 75
                            }
                        ],
                        "text": "weakness is that by considering only the presence or absence of terms, the BIMignores information inherent in the frequencies of terms."
                    },
                    "intents": []
                }
            ],
            "corpusId": 62206260,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "81ec4a01efce7c304f575adbb143f55c8bb3a32a",
            "isKey": true,
            "numCitedBy": 49,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A probabilistic document-retrieval system may be seen as a sequential learning process, in which the system learns the characteristics of relevant documents, or more formally, it learns the parameters of probability distributions describing the frequencies of feature occurrences in relevant and nonrelevant documents. Probability distributions that may be used to describe the distribution of features include binary and Poisson distributions. Techniques for estimating the parameters of distributions are suggested. We have tested a proposal that parameters of distributions describing the distribution of features in nonrelevant documents be estimated from the parameters of the corresponding distributions of the entire database; the confidence parameter of such an estimate resulting in the highest average precision is given. Tests of several methods for estimating the parameters of distributions describing the distribution of features in relevant documents suggest that small values of the confidence parameter be used in our initial estimates of parameters for relevant documents. \u00a9 1988 John Wiley & Sons, Inc."
            },
            "slug": "Parameter-Estimation-for-Probabilistic-Models.-Losee",
            "title": {
                "fragments": [],
                "text": "Parameter Estimation for Probabilistic Document-Retrieval Models."
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A proposal that parameters of distributions describing the distribution of features in nonrelevant documents be estimated from the parameters of the corresponding distributions of the entire database is tested; the confidence parameter of such an estimate resulting in the highest average precision is given."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703148"
                        ],
                        "name": "N. Fuhr",
                        "slug": "N.-Fuhr",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Fuhr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Fuhr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15424327,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "61af1deb7a3016cd0760aca0f0a38a4fecda3d61",
            "isKey": false,
            "numCitedBy": 218,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Models-for-retrieval-with-probabilistic-indexing-Fuhr",
            "title": {
                "fragments": [],
                "text": "Models for retrieval with probabilistic indexing"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Process. Manag."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052827105"
                        ],
                        "name": "L. Rasmussen",
                        "slug": "L.-Rasmussen",
                        "structuredName": {
                            "firstName": "Laurits",
                            "lastName": "Rasmussen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rasmussen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 57109550,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2814075572e601f9d4ee37d551086f6732107f60",
            "isKey": false,
            "numCitedBy": 1137,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Following your need to always fulfil the inspiration to obtain everybody is now simple. Connecting to the internet is one of the short cuts to do. There are so many sources that offer and connect us to other world condition. As one of the products to see in internet, this website becomes a very available place to look for countless information retrieval data structures and algorithms sources. Yeah, sources about the books from countries in the world are provided."
            },
            "slug": "In-information-retrieval:-data-structures-and-Rasmussen",
            "title": {
                "fragments": [],
                "text": "In information retrieval: data structures and algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "As one of the products to see in internet, this website becomes a very available place to look for countless information retrieval data structures and algorithms sources."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34986152"
                        ],
                        "name": "S. P. Harter",
                        "slug": "S.-P.-Harter",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Harter",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. P. Harter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 124
                            }
                        ],
                        "text": "The distributions investigated have mostly been Poisson mixtures [4, 26]:the Poisson itself [40], mixtures of 2, 3, or more Poissons [1, 2, 22, 23, 36], andthe negative binomial (an in nite mixture of Poissons) [40]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 134
                            }
                        ],
                        "text": "The distributions investigated have mostly been Poisson mixtures [4, 26]: the Poisson itself [40], mixtures of 2, 3, or more Poissons [1, 2, 22, 23, 36], and the negative binomial (an in nite mixture of Poissons) [40]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 20821537,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "27c77fe6cfe62204e4134eb7a4c447879d8e3a14",
            "isKey": false,
            "numCitedBy": 123,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "In Part I of this study,* a mixture of two Poisson distributions was examined as a model of specialty word distribution. Formulas expressing the three parameters of the model in terms of empirical frequency statistics were derived, and a statistical measure intended to identify specialty words, consistent with the model, was proposed. \n \n \n \nIn the present paper, Part II of the study, a probabilistic model of keyword indexing is outlined, and some of the consequences of the model are examined. An algorithm defining a measure of indexability is developed-a measure intended to reflect the relative significance of words in documents. The measure is evaluated and is found to consistently produce indexes superior to those produced by another measure which had previously been identified in the literature as producing the best results."
            },
            "slug": "A-probabilistic-approach-to-automatic-keyword-Part-Harter",
            "title": {
                "fragments": [],
                "text": "A probabilistic approach to automatic keyword indexing. Part II. An algorithm for probabilistic indexing"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An algorithm defining a measure of indexability is developed-a measure intended to reflect the relative significance of words in documents that is found to consistently produce indexes superior to those produced by another measure which had previously been identified in the literature as producing the best results."
            },
            "venue": {
                "fragments": [],
                "text": "J. Am. Soc. Inf. Sci."
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40941894"
                        ],
                        "name": "Soumen Chakrabarti",
                        "slug": "Soumen-Chakrabarti",
                        "structuredName": {
                            "firstName": "Soumen",
                            "lastName": "Chakrabarti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Soumen Chakrabarti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786444"
                        ],
                        "name": "B. Dom",
                        "slug": "B.-Dom",
                        "structuredName": {
                            "firstName": "Byron",
                            "lastName": "Dom",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Dom"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144947410"
                        ],
                        "name": "R. Agrawal",
                        "slug": "R.-Agrawal",
                        "structuredName": {
                            "firstName": "Rakesh",
                            "lastName": "Agrawal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Agrawal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145503401"
                        ],
                        "name": "P. Raghavan",
                        "slug": "P.-Raghavan",
                        "structuredName": {
                            "firstName": "Prabhakar",
                            "lastName": "Raghavan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Raghavan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 82
                            }
                        ],
                        "text": "Indeed, we know of many applications of multinomial models to text categorization [3,14, 15,25, 32, 34] but none to text retrieval."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10866845,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0fb028cd0b044c6721e7aea302e8e428ea256f62",
            "isKey": false,
            "numCitedBy": 154,
            "numCiting": 96,
            "paperAbstract": {
                "fragments": [],
                "text": "We explore how to organize a text database hierarchically to aid better searching and browsing. We propose to exploit the natural hierarchy of topics, or taxonomy, that many corpora, such as intemet directories, digital libraries, and patent databases enjoy. In our system, the user navigates through the query response not as a flat unstructured list, but embedded in the familiar taxonomy, and annotated with document signatures computed dynamicallywith respect to where the user is located at any time. We show how to update such databases with new documents with high speed and accuracy. We use techniques from statistical pattern recognition to efficiently separate the feature words or discriminants from the noise words at each node of the taxonomy. Using these, we build a multi-level classifier. At each node, this classifier can ignore the large number of noise words in a document. Thus the classifier has a small model size and is very fast. However, owing to the use of context-sensitive features, it classifier is very accurate. We report on experiences with the Reuters newswire benchmark, the US Patent database, and web document samples from Yahoo!."
            },
            "slug": "Using-Taxonomy,-Discriminants,-and-Signatures-for-Chakrabarti-Dom",
            "title": {
                "fragments": [],
                "text": "Using Taxonomy, Discriminants, and Signatures for Navigating in Text Databases"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work uses techniques from statistical pattern recognition to efficiently separate the feature words or discriminants from the noise words at each node of the taxonomy, and builds a multi-level classifier that has a small model size and is very fast."
            },
            "venue": {
                "fragments": [],
                "text": "VLDB"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797808"
                        ],
                        "name": "G. Salton",
                        "slug": "G.-Salton",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Salton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144009691"
                        ],
                        "name": "C. Buckley",
                        "slug": "C.-Buckley",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Buckley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Buckley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 69
                            }
                        ],
                        "text": "In fact, naive Bayes methods, along with prototype formation methods [44,45, 24], accounted for most applications of supervised learning to information retrieval until quite recently."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 115
                            }
                        ],
                        "text": "Robertson and Sparck Jones' particular interest in the binary independence model was its use in relevance feedback [20, 45]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17637032,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "2ebb3dd597bbd7028d8c68bcf509e5bb09ea1e78",
            "isKey": false,
            "numCitedBy": 1442,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Relevance feedback is an automatic process, introduced over 20 years ago, designed to produce query formulations following an initial retrieval operation. The principal relevance feedback methods described over the years are examined briefly, and evaluation data are included to demonstrate the effectiveness of the various methods. Prescriptions are given for conducting text retrieval operations iteratively using relevance feedback."
            },
            "slug": "Improving-retrieval-performance-by-relevance-Salton-Buckley",
            "title": {
                "fragments": [],
                "text": "Improving retrieval performance by relevance feedback"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Prescriptions are given for conducting text retrieval operations iteratively using relevance feedback, and evaluation data are included to demonstrate the effectiveness of the various methods."
            },
            "venue": {
                "fragments": [],
                "text": "J. Am. Soc. Inf. Sci."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768109"
                        ],
                        "name": "Howard R. Turtle",
                        "slug": "Howard-R.-Turtle",
                        "structuredName": {
                            "firstName": "Howard",
                            "lastName": "Turtle",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Howard R. Turtle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144456145"
                        ],
                        "name": "W. Bruce Croft",
                        "slug": "W.-Bruce-Croft",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Croft",
                            "middleNames": [
                                "Bruce"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Bruce Croft"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11025023,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ebdfcd8f456121cf46b5827b049a54eb3eef5fd1",
            "isKey": false,
            "numCitedBy": 680,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "Network representations have been used in information retrieval since at least the early 1960\u2019s. Networks have been used to support diverse retrieval functions, including browsing [38], document clustering [7], spreading activation search [4], support for multiple search strategies [11], and representation of user knowledge [27] or document content [40]. Recent work suggests that significant improvements in retrieval performance will require techniques that, in some sense \u201cunderstand\u201d the content of documents and queries [9, 43] and can be used to infer probable relationships between documents and queries. In this view, information retrieval is an inference or evidential reasoning process in which we estimate the probability that a user\u2019s information need, expressed as one or more queries, is met given a document as \u201cevidence.\u201d Network representations show promise as mechanisms for inferring these kinds of relationships [4, 12]."
            },
            "slug": "Evaluation-of-an-inference-network-based-retrieval-Turtle-Croft",
            "title": {
                "fragments": [],
                "text": "Evaluation of an inference network-based retrieval model"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "Network representations show promise as mechanisms for inferring probable relationships between documents and queries and have been used in information retrieval since at least the early 1960s."
            },
            "venue": {
                "fragments": [],
                "text": "TOIS"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34986152"
                        ],
                        "name": "S. P. Harter",
                        "slug": "S.-P.-Harter",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Harter",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. P. Harter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 124
                            }
                        ],
                        "text": "The distributions investigated have mostly been Poisson mixtures [4, 26]:the Poisson itself [40], mixtures of 2, 3, or more Poissons [1, 2, 22, 23, 36], andthe negative binomial (an in nite mixture of Poissons) [40]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 134
                            }
                        ],
                        "text": "The distributions investigated have mostly been Poisson mixtures [4, 26]: the Poisson itself [40], mixtures of 2, 3, or more Poissons [1, 2, 22, 23, 36], and the negative binomial (an in nite mixture of Poissons) [40]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 42232741,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "9bb0dcd80292262cf60e33259b91e03930bfd0f2",
            "isKey": false,
            "numCitedBy": 191,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem studied in this research is that of developing a set of formal statistical rules for the purpose of identifying the keywords of a document-words likely to be useful as index terms for that document. The research was prompted by the observation, made by a number of writers, that non-specialty words, words which possess little value for indexing purposes, tend to be distributed at random in a collection of documents. In contrast, specialty words are not so distributed. \n \n \n \nIn Part I of the study, a mixture of two Poisson distributions is examined in detail as a model of specialty word distribution, and formulas expressing the three parameters of the model in terms of empirical frequency statistics are derived. The fit of the model is tested on an experimental document collection and found to be acceptable for the purposes of the study. A measure intended to identify specialty words, consistent with the 2-Poisson model, is proposed and evaluated."
            },
            "slug": "A-probabilistic-approach-to-automatic-keyword-Part-Harter",
            "title": {
                "fragments": [],
                "text": "A probabilistic approach to automatic keyword indexing. Part I. On the Distribution of Specialty Words in a Technical Literature"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A mixture of two Poisson distributions is examined in detail as a model of specialty word distribution and a measure intended to identify specialty words, consistent with the 2-Poisson model, is proposed and evaluated."
            },
            "venue": {
                "fragments": [],
                "text": "J. Am. Soc. Inf. Sci."
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34938639"
                        ],
                        "name": "W. Gale",
                        "slug": "W.-Gale",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Gale",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Gale"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244184"
                        ],
                        "name": "Kenneth Ward Church",
                        "slug": "Kenneth-Ward-Church",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Church",
                            "middleNames": [
                                "Ward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Ward Church"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693517"
                        ],
                        "name": "David Yarowsky",
                        "slug": "David-Yarowsky",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Yarowsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Yarowsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17567112,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bf35ed0864ff6cf524a24f0a65aa6951f9d6f214",
            "isKey": false,
            "numCitedBy": 657,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Word sense disambiguation has been recognized as a major problem in natural language processing research for over forty years. Both quantitive and qualitative methods have been tried, but much of this work has been stymied by difficulties in acquiring appropriate lexical resources. The availability of this testing and training material has enabled us to develop quantitative disambiguation methods that achieve 92% accuracy in discriminating between two very distinct senses of a noun. In the training phase, we collect a number of instances of each sense of the polysemous noun. Then in the testing phase, we are given a new instance of the noun, and are asked to assign the instance to one of the senses. We attempt to answer this question by comparing the context of the unknown instance with contexts of known instances using a Bayesian argument that has been applied successfully in related tasks such as author identification and information retrieval. The proposed method is probably most appropriate for those aspects of sense disambiguation that are closest to the information retrieval task. In particular, the proposed method was designed to disambiguate senses that are usually associated with different topics."
            },
            "slug": "A-method-for-disambiguating-word-senses-in-a-large-Gale-Church",
            "title": {
                "fragments": [],
                "text": "A method for disambiguating word senses in a large corpus"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The proposed method was designed to disambiguate senses that are usually associated with different topics using a Bayesian argument that has been applied successfully in related tasks such as author identification and information retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Humanit."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "121352283"
                        ],
                        "name": "Van Rijsbergen",
                        "slug": "Van-Rijsbergen",
                        "structuredName": {
                            "firstName": "Van",
                            "lastName": "Rijsbergen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Van Rijsbergen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62560433,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9ea50374077a506b86dce4796c683abcd98e18d7",
            "isKey": false,
            "numCitedBy": 540,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper provides a foundation for a practical way of improving the effectiveness of an automatic retrieval system. Its main concern is with the weighting of index terms as a device for increasing retrieval effectiveness. Previously index terms have been assumed to be independent for the good reason that then a very simple weighting scheme can be used. In reality index terms are most unlikely to be independent. This paper explores one way of removing the independence assumption. Instead the extent of the dependence between index terms is measured and used to construct a non\u2010linear weighting function. In a practical situation the values of some of the parameters of such a function must be estimated from small samples of documents. So a number of estimation rules are discussed and one in particular is recommended. Finally the feasibility of the computations required for a non\u2010linear weighting scheme is examined."
            },
            "slug": "A-theoretical-basis-for-the-use-of-co-occurence-in-Rijsbergen",
            "title": {
                "fragments": [],
                "text": "A theoretical basis for the use of co-occurence data in information retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "This paper provides a foundation for a practical way of improving the effectiveness of an automatic retrieval system by measuring the extent of the dependence between index terms and using it to construct a non\u2010linear weighting function."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2642131"
                        ],
                        "name": "Clement T. Yu",
                        "slug": "Clement-T.-Yu",
                        "structuredName": {
                            "firstName": "Clement",
                            "lastName": "Yu",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Clement T. Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2723337"
                        ],
                        "name": "H. Mizuno",
                        "slug": "H.-Mizuno",
                        "structuredName": {
                            "firstName": "Hirotaka",
                            "lastName": "Mizuno",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Mizuno"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1714320,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cbd852ea0caefdbd3cef1bf5217d8e34fab2cca8",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Two methods are given to improve weighting schemes by using relevance information of a set of queries. The first method is to estimate parameter values of two independence models in information retrieval \u2014 the binary independence model and the non-binary independence model. The parameters estimated here are used to calculate optimal weights for terms in a different set of queries. Performance of this estimation is compared to the inverse document frequency method, the cosine measure, and the statistical similarity measure. The second method is to learn optimal weights of the non-binary independence model adaptively by a learning formula. Experiments are performed on three different document collections CISI, MEDLARS, and CRN4NUL for both methods, and results are reported. Both methods show improvements compared to the existing weighting schemes. Experimental results show that the second method gives slightly better performance than the first one, and has simpler implementation."
            },
            "slug": "Two-learning-schemes-in-information-retrieval-Yu-Mizuno",
            "title": {
                "fragments": [],
                "text": "Two learning schemes in information retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "Two methods are given to improve weighting schemes by using relevance information of a set of queries to estimate parameter values of two independence models in information retrieval \u2014 the binary independence model and the non-binary independence model."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '88"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 368,
                                "start": 360
                            }
                        ],
                        "text": "Having made clear that ck and x are values taken on by random variables C and X we simplify notation by omitting those random variables and instead writing Bayes' rule as: P (ckjx) = P (ck) P (xjck) P (x) (3) When we know the P (ckjx) exactly for a classi cation problem, classi cation can be done in an optimal way for a wide variety of e ectiveness measures [10, 31]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 17260485,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "91cbbe24c807473b7b935d39b63df5b15da9bb32",
            "isKey": false,
            "numCitedBy": 392,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Text retrieval systems typically produce a ranking of documents and let a user decide how far down that ranking to go. In contrast, programs that filter text streams, software that categorizes documents, agents which alert users, and many other IR systems must make decisions without human input or supervision. It is important to define what constitutes good effectiveness for these autonomous systems, tune the systems to achieve the highest possible effectiveness, and estimate how the effectiveness changes as new data is processed. We show how to do this for binary text classification systems, emphasizing that different goals for the system le ad to different optimal behaviors. Optimizing and estimating effectiveness is greatly aided if classifiers that explicitly estimate the probability of class membership are used. Ranked retrieval is the information retrieval (IR) researc her\u2019s favorite tool for dealing with information overload. Ranked retrieval systems display documents in order of probability of releva nce or some similar measure. Users see the best documents first, anddecide how far down the ranking to go in examining the available information. The central role played by ranking in this appr oach has led researchers to evaluate IR systems primarily, often exclusively, on the quality of their rankings. (See, for instance , the TREC evaluations [1].) In some IR applications, however, ranking is not enough: A company provides an SDI (selective dissemination of information) service which filters newswire feeds. Relevant articles are faxed each morning to clients. Interaction between customer and system takes place infrequently. The cost of resources (tying up phone lines, fax machine paper, etc.) is a factor to consider in operating the system. A text categorization system assigns controlled vocabulary categories to incoming documents as they are stored in a text database. Cost cutting has eliminated manual checking of category assignments."
            },
            "slug": "Evaluating-and-optimizing-autonomous-text-systems-Lewis",
            "title": {
                "fragments": [],
                "text": "Evaluating and optimizing autonomous text classification systems"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This work shows how to define what constitutes good effectiveness for binary text classification systems, tune the systems to achieve the highest possible effectiveness, and estimate how the effectiveness changes as new data is processed."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '95"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797808"
                        ],
                        "name": "G. Salton",
                        "slug": "G.-Salton",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Salton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144321599"
                        ],
                        "name": "M. McGill",
                        "slug": "M.-McGill",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "McGill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. McGill"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 43685115,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "49af3e80343eb80c61e727ae0c27541628c7c5e2",
            "isKey": false,
            "numCitedBy": 12605,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Some people may be laughing when looking at you reading in your spare time. Some may be admired of you. And some may want be like you who have reading hobby. What about your own feel? Have you felt right? Reading is a need and a hobby at once. This condition is the on that will make you feel that you must read. If you know are looking for the book enPDFd introduction to modern information retrieval as the choice of reading, you can find here."
            },
            "slug": "Introduction-to-Modern-Information-Retrieval-Salton-McGill",
            "title": {
                "fragments": [],
                "text": "Introduction to Modern Information Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "Reading is a need and a hobby at once and this condition is the on that will make you feel that you must read."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1899386"
                        ],
                        "name": "E. Margulis",
                        "slug": "E.-Margulis",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Margulis",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Margulis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 124
                            }
                        ],
                        "text": "The distributions investigated have mostly been Poisson mixtures [4, 26]:the Poisson itself [40], mixtures of 2, 3, or more Poissons [1, 2, 22, 23, 36], andthe negative binomial (an in nite mixture of Poissons) [40]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 134
                            }
                        ],
                        "text": "The distributions investigated have mostly been Poisson mixtures [4, 26]: the Poisson itself [40], mixtures of 2, 3, or more Poissons [1, 2, 22, 23, 36], and the negative binomial (an in nite mixture of Poissons) [40]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 36010885,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "f8a4bf3113cf8f3a33a36c581e82dbd50d6ccb40",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Modelling-Documents-with-Multiple-Poisson-Margulis",
            "title": {
                "fragments": [],
                "text": "Modelling Documents with Multiple Poisson Distributions"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Process. Manag."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145848824"
                        ],
                        "name": "Karen Sp\u00e4rck Jones",
                        "slug": "Karen-Sp\u00e4rck-Jones",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Sp\u00e4rck Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karen Sp\u00e4rck Jones"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 236,
                                "start": 229
                            }
                        ],
                        "text": "That is, if one sets the initial score of a document to be the constant term in Equation 11, the full score can be computed by adding up values involving only those words present in a document, not those absent from the document [41,48]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 26956788,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b258da547bbef94d34b7e694f6bc379fcf9b4e12",
            "isKey": false,
            "numCitedBy": 88,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Previous experiments demonstrated the value of relevance weighting for search terms, but relied on substantial relevance information for the terms. The present experiments were designed to study the effects of weights based on very limited relevance information, for example supplied by one or two relevant documents. The tests simulated iterative searching, as in an on\u2010line system, and show that even very little relevance information can be of considerable value."
            },
            "slug": "Search-Term-Relevance-Weighting-given-Little-Jones",
            "title": {
                "fragments": [],
                "text": "Search Term Relevance Weighting given Little Relevance Information"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The tests simulated iterative searching, as in an on\u2010line system, and show that even very little relevance information can be of considerable value in relation to relevance weighting."
            },
            "venue": {
                "fragments": [],
                "text": "J. Documentation"
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145163573"
                        ],
                        "name": "A. Singhal",
                        "slug": "A.-Singhal",
                        "structuredName": {
                            "firstName": "Amit",
                            "lastName": "Singhal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Singhal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144009691"
                        ],
                        "name": "C. Buckley",
                        "slug": "C.-Buckley",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Buckley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Buckley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51933055"
                        ],
                        "name": "M. Mitra",
                        "slug": "M.-Mitra",
                        "structuredName": {
                            "firstName": "Manclar",
                            "lastName": "Mitra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mitra"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 108
                            }
                        ],
                        "text": "While a case can be made that longer documents are somewhat more likely to be of interest to any given user [43,47], the above e ect is likely to be far stronger than appropriate."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207998619,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74c49a7aa91d1cdb45500e853240746cafb1bcaf",
            "isKey": false,
            "numCitedBy": 554,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatic information retrieval systems have to deal with documents of varying lengths in a text collection. Document length normalization is used to fairly retrieve documents of all lengths. In this study, we ohserve that a normalization scheme that retrieves documents of all lengths with similar chances as their likelihood of relevance will outperform another scheme which retrieves documents with chances very different from their likelihood of relevance. We show that the retrievaf probabilities for a particular normalization method deviate systematically from the relevance probabilities across different collections. We present pivoted normalization, a technique that can be used to modify any normalization function thereby reducing the gap between the relevance and the retrieval probabilities. Training pivoted normalization on one collection, we can successfully use it on other (new) text collections, yielding a robust, collectzorz independent normalization technique. We use the idea of pivoting with the well known cosine normalization function. We point out some shortcomings of the cosine function andpresent two new normalization functions--pivoted unique normalization and piuotert byte size normalization."
            },
            "slug": "Pivoted-Document-Length-Normalization-Singhal-Buckley",
            "title": {
                "fragments": [],
                "text": "Pivoted Document Length Normalization"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Pivoted normalization is presented, a technique that can be used to modify any normalization function thereby reducing the gap between the relevance and the retrieval probabilities, and two new normalization functions--pivoted unique normalization and piuotert byte size normalization are presented."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR 1996"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725719"
                        ],
                        "name": "David J. Harper",
                        "slug": "David-J.-Harper",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Harper",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Harper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "115491216"
                        ],
                        "name": "C. J. V. Rijsbergen",
                        "slug": "C.-J.-V.-Rijsbergen",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Rijsbergen",
                            "middleNames": [
                                "J.",
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. J. V. Rijsbergen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 28953999,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "432c125f8f01bab15ed756b0816cae3d3ddf556c",
            "isKey": false,
            "numCitedBy": 175,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper reports experiments with a term weighting model incorporating relevance information in which it is assumed that index terms are distributed dependently. Initially this model was tested with complete relevance information against a similar model which assumes index terms are distributed independently. The experiments demonstrated conclusively that index terms are not independent for a number of diverse document collections. It was concluded that the use of relevance information together with dependence information could potentially improve retrieval effectiveness. As a result of further experiments the initial strict dependence model was modified and in particular a new relevance\u2010based term weight was developed. This modified dependence model was then used as the basis for relevance feedback, i.e. with partial relevance information only, and significant increases in retrieval effectiveness were achieved. The evaluation method used in the feedback experiments emphasized the effect of the feedback on documents which the potential user would not previously have seen. Finally the incorporation of relevance feedback in an operational system is considered and in particular it is argued that if high recall searches are required, relevance feedback based on the modified dependence model may be superior to the widely used Boolean search."
            },
            "slug": "An-Evaluation-of-feedback-in-Document-Retrieval-Harper-Rijsbergen",
            "title": {
                "fragments": [],
                "text": "An Evaluation of feedback in Document Retrieval using Co\u2010Occurrence Data"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This paper reports experiments with a term weighting model incorporating relevance information in which it is assumed that index terms are distributed dependently and argues that if high recall searches are required, relevance feedback based on the modified dependence model may be superior to the widely used Boolean search."
            },
            "venue": {
                "fragments": [],
                "text": "J. Documentation"
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144169170"
                        ],
                        "name": "D. Harman",
                        "slug": "D.-Harman",
                        "structuredName": {
                            "firstName": "Donna",
                            "lastName": "Harman",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Harman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1208194,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d49df3eb2daf21fc508d82b1d96e3fdb1d29a75",
            "isKey": false,
            "numCitedBy": 305,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "In November of 1992 the first Text REtrieval Conference (TREC-1) was held at NIST [Harman 1993]. The conference, co-sponsored by ARPA and NIST, brought together information retrieval researchers to discuss their system results on a new large test collection (the TIPSTER collection). This conference became the first in a series of ongoing conferences dedicated to encouraging research in retrieval from large-scale test collections, and to encouraging increased interaction among research groups in industry and academia. From the beginning there has been an almost equal number of universities and companies participating, with an emphasis on exploring many different types of approaches to the text retrieval problem."
            },
            "slug": "Overview-of-the-Third-Text-REtrieval-Conference-Harman",
            "title": {
                "fragments": [],
                "text": "Overview of the Third Text REtrieval Conference (TREC-3)"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This conference became the first in a series of ongoing conferences dedicated to encouraging research in retrieval from large-scale test collections, and to encouraging increased interaction among research groups in industry and academia."
            },
            "venue": {
                "fragments": [],
                "text": "TREC"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35229948"
                        ],
                        "name": "S. Katz",
                        "slug": "S.-Katz",
                        "structuredName": {
                            "firstName": "Slava",
                            "lastName": "Katz",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Katz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 65
                            }
                        ],
                        "text": "The distributions investigated have mostly been Poisson mixtures [4, 26]: the Poisson itself [40], mixtures of 2, 3, or more Poissons [1, 2, 22, 23, 36], and the negative binomial (an in nite mixture of Poissons) [40]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7423683,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b72c3fddfb70920c2a3be8adfbb3d505120f3f5",
            "isKey": false,
            "numCitedBy": 283,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of distribution of words and phrases in text, a problem of great general interest and of importance for many practical applications. The existing models for word distribution present observed sequences of words in text documents as an outcome of some stochastic processes; the corresponding distributions of numbers of word occurrences in the documents are modelled as mixtures of Poisson distributions whose parameter values are fitted to the data. We pursue a linguistically motivated approach to statistical language modelling and use observable text characteristics as model parameters. Multi-word technical terms, intrinsically content entities, are chosen for experimentation. Their occurrence and the occurrence dynamics are investigated using a 100-million word data collection consisting of a variety of about 13,000 technical documents. The derivation of models describing word distribution in text is based on a linguistic interpretation of the process of text formation, with the probabilities of word occurrence being functions of observable and linguistically meaningful text characteristics. The adequacy of the proposed models for the description of actually observed distributions of words and phrases in text is confirmed experimentally. The paper has two focuses: one is modelling of the distributions of content words and phrases among different documents; and another is word occurrence dynamics within documents and estimation of corresponding probabilities. Accordingly, among the application areas for the new modelling paradigm are information retrieval and speech recognition."
            },
            "slug": "Distribution-of-content-words-and-phrases-in-text-Katz",
            "title": {
                "fragments": [],
                "text": "Distribution of content words and phrases in text and language modelling"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The derivation of models describing word distribution in text is based on a linguistic interpretation of the process of text formation, with the probabilities of word occurrence being functions of observable and linguistically meaningful text characteristics."
            },
            "venue": {
                "fragments": [],
                "text": "Nat. Lang. Eng."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2784519"
                        ],
                        "name": "Peter Norvig",
                        "slug": "Peter-Norvig",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Norvig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Norvig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770316"
                        ],
                        "name": "P. Jacobs",
                        "slug": "P.-Jacobs",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Jacobs",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Jacobs"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 207508259,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "9d75c58dad0917781343d2ad771fe3a9219a736d",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Text-Based-Intelligent-Systems-Norvig-Jacobs",
            "title": {
                "fragments": [],
                "text": "Text-Based Intelligent Systems"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3014360"
                        ],
                        "name": "R. Korfhage",
                        "slug": "R.-Korfhage",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Korfhage",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Korfhage"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62207369,
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology"
            ],
            "id": "89646c38431ad48b2b5738f4245546728f95eb68",
            "isKey": false,
            "numCitedBy": 188,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "An information retrieval system in which a set of distinct information items map to respective nodes in an array of nodes by mutual similarity of the information items, so that similar information items map to nodes at similar positions in the array of nodes; the system comprising: a user control for defining a search criterion for selecting information items; a detector for detecting those positions within the array of nodes corresponding to the selected information items; a graphical user interface for displaying a two-dimensional display array of display points representing those positions within the array of nodes corresponding to the selected information items; and a processor responsive to the selected information items, for providing a representation which is generally representative of the information content of the selected information items."
            },
            "slug": "Information-Storage-and-Retrieval-Korfhage",
            "title": {
                "fragments": [],
                "text": "Information Storage and Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "An information retrieval system in which a set of distinct information items map to respective nodes in an array of nodes by mutual similarity of the information items, so that similar information itemsmap to nodes at similar positions in thearray of nodes."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1963
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35106875"
                        ],
                        "name": "R. Duda",
                        "slug": "R.-Duda",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Duda",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Duda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108177"
                        ],
                        "name": "P. Hart",
                        "slug": "P.-Hart",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 368,
                                "start": 360
                            }
                        ],
                        "text": "Having made clear that ck and x are values taken on by random variables C and X we simplify notation by omitting those random variables and instead writing Bayes' rule as: P (ckjx) = P (ck) P (xjck) P (x) (3) When we know the P (ckjx) exactly for a classi cation problem, classi cation can be done in an optimal way for a wide variety of e ectiveness measures [10, 31]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 12946615,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b07ce649d6f6eb636872527104b0209d3edc8188",
            "isKey": false,
            "numCitedBy": 16927,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Provides a unified, comprehensive and up-to-date treatment of both statistical and descriptive methods for pattern recognition. The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "slug": "Pattern-classification-and-scene-analysis-Duda-Hart",
            "title": {
                "fragments": [],
                "text": "Pattern classification and scene analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "venue": {
                "fragments": [],
                "text": "A Wiley-Interscience publication"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3055160"
                        ],
                        "name": "David J. Ittner",
                        "slug": "David-J.-Ittner",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Ittner",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Ittner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053105315"
                        ],
                        "name": "David D. Ahn",
                        "slug": "David-D.-Ahn",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Ahn",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David D. Ahn"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 69
                            }
                        ],
                        "text": "In fact, naive Bayes methods, along with prototype formation methods [44,45, 24], accounted for most applications of supervised learning to information retrieval until quite recently."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16611584,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "72fe75228c198854d4c43cc70a381643a28deca6",
            "isKey": false,
            "numCitedBy": 146,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Categorization of text images into content oriented classes would be a useful capability in a variety of document handling systems Many methods can be used to cat egorize texts once their words are known but OCR can garble a large proportion of words particularly when low quality images are used Despite this we show for one data set that fax quality images can be cat egorized with nearly the same accuracy as the original text Further the categoriza tion system can be trained on noisy OCR output without need for the true text of any image or for editing of OCR output The use of a vector space classi er and train ing method robust to large feature sets com bined with discarding of low frequency OCR output strings are the key to our approach"
            },
            "slug": "Text-categorization-of-low-quality-images-Ittner-Lewis",
            "title": {
                "fragments": [],
                "text": "Text categorization of low quality images"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown for one data set that fax quality images can be catgorized with nearly the same accuracy as the original text and the categoriza tion system can be trained on noisy OCR output without need for the true text of any image or for editing of O CR output."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111143448"
                        ],
                        "name": "Samuel B. Williams",
                        "slug": "Samuel-B.-Williams",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Williams",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samuel B. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 204
                            }
                        ],
                        "text": "The corresponding disadvantage is that it assumes independence not just between di erent words, but between multiple occurrences of the same word, an assumption which is strikingly violated for real data [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 65
                            }
                        ],
                        "text": "The distributions investigated have mostly been Poisson mixtures [4, 26]: the Poisson itself [40], mixtures of 2, 3, or more Poissons [1, 2, 22, 23, 36], and the negative binomial (an in nite mixture of Poissons) [40]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 889967,
            "fieldsOfStudy": [
                "History"
            ],
            "id": "95c4ebb6df40abc74c9cf36994c0f914be3b04bd",
            "isKey": false,
            "numCitedBy": 1897,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "As the Association for Computing Machinery enters a new phase of its existence, it seems befitting to review, briefly, the conditions in the computing field just prior to its organization and the events of the past six years of its life. Since its formation, in 1947, the Association has adhered to the originally established policy of informality. That is, meetings and discussions were encouraged and information was generally put out in mimeographed form and more formal publications were discouraged. The function of the organization was to maintain a mailing list of members paying only such dues as were necessary to cover the cost of printing or mimeographing and mailing. Such an organization served its purpose excellently, but times have changed.\nPrior to the formation of the Association, the automatic computing field, as such, hardly existed. Probably the first meeting of those interested in the field was held at the Massachusetts Institute of Technology in 1945. The occasion was to introduce the differential analyzer, designed by Dr. Vannevar Bush and Dr. Samuel H. Caldwell, to the public. This machine is a refinement of the original machine built by Dr. Bush in 1925. The earlier machine served as a pattern for several machines which were in operation in 1945, including those at the Aberdeen Proving Ground, the Moore School of Electrical Engineering, the General Electric Company and in Manchester, England.\nIt is interesting to note that, at the time of this first meeting, other analog type machines were in operation. Network analyzers were employed to simulate power distribution systems and aid in their study. None of these machines employed digital representation but represented the values in analog form, such as voltage, current or angular position. Digital computation was possible only by hand operated calculators or by some business machines.\n Although automatic digital computation by machinery was the goal Charles Babbage strove to reach, it was not until the Hollerith rotary counter was suggested in 1890 and the International Business Machines Corporation began producing machines employing such counters for accounting purposes in the period from 1903 to 1905, that such goal was reached. The automatic multiplying punch machine was not produced until 1931.\nComputation by means of telephone relays was first introduced in the Bell System Complex Computer, known as Model I, in 1939. The method of employing the relays was suggested by Dr. George R. Stibitz and the machine was designed by Samuel B. Williams. This was not a fully automatic machine. The complex quantities for a single"
            },
            "slug": "The-Association-for-Computing-Machinery-Williams",
            "title": {
                "fragments": [],
                "text": "The Association for Computing Machinery"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "As the Association for Computing Machinery enters a new phase of its existence, it seems befitting to review the conditions in the computing field just prior to its organization and the events of the past six years of its life."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1954
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244184"
                        ],
                        "name": "Kenneth Ward Church",
                        "slug": "Kenneth-Ward-Church",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Church",
                            "middleNames": [
                                "Ward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Ward Church"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16505277,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "13d3ada414ce8071efd165e074bdfd1a5e8ad64a",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "How effective is stemming? Text normalization? Stemming experiments test two hypotheses: one term (+stemmer) or two (\u2013stemmer). The truth lies somewhere in between. The correlations, \u03c1, between a word and its variants (e.g., + s, + ly, +uppercase) tend to be small (refuting the one term hypothesis), but non-negligible (refuting the two term hypothesis). Moreover, \u03c1 varies systematically depending on the words involved; it is relatively large for a good keyword, \u03c1(hostage , hostages) \u223c\u223c0. 5, and small for pairs with little content, \u03c1(anytime, Anytime) \u223c\u223c0, or conflicting content, \u03c1(continental , Continental) \u223c\u223c0."
            },
            "slug": "One-term-or-two-Church",
            "title": {
                "fragments": [],
                "text": "One term or two?"
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '95"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "134211067"
                        ],
                        "name": "J. Rocchio",
                        "slug": "J.-Rocchio",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Rocchio",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Rocchio"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 69
                            }
                        ],
                        "text": "In fact, naive Bayes methods, along with prototype formation methods [44,45, 24], accounted for most applications of supervised learning to information retrieval until quite recently."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61859400,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4083ad1066cfa2ff0d65866ef4b011399d6873d1",
            "isKey": false,
            "numCitedBy": 3242,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Relevance-feedback-in-information-retrieval-Rocchio",
            "title": {
                "fragments": [],
                "text": "Relevance feedback in information retrieval"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144169170"
                        ],
                        "name": "D. Harman",
                        "slug": "D.-Harman",
                        "structuredName": {
                            "firstName": "Donna",
                            "lastName": "Harman",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Harman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60186948,
            "fieldsOfStudy": [
                "History"
            ],
            "id": "6bbb7e6e7836af5996722db76ae78c89f7cae337",
            "isKey": false,
            "numCitedBy": 197,
            "numCiting": 164,
            "paperAbstract": {
                "fragments": [],
                "text": "... viii"
            },
            "slug": "The-First-Text-REtrieval-Conference-(TREC-1)-Harman",
            "title": {
                "fragments": [],
                "text": "The First Text REtrieval Conference (TREC-1)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144169170"
                        ],
                        "name": "D. Harman",
                        "slug": "D.-Harman",
                        "structuredName": {
                            "firstName": "Donna",
                            "lastName": "Harman",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Harman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 205102948,
            "fieldsOfStudy": [
                "History"
            ],
            "id": "459cdffdd6fe41135f03755b511bdbcdd54ce09a",
            "isKey": false,
            "numCitedBy": 143,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Second-Text-Retrieval-Conference-(TREC-2)-Harman",
            "title": {
                "fragments": [],
                "text": "The Second Text Retrieval Conference (TREC-2)"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Process. Manag."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47976263"
                        ],
                        "name": "F. Mosteller",
                        "slug": "F.-Mosteller",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Mosteller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Mosteller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144087709"
                        ],
                        "name": "D. L. Wallace",
                        "slug": "D.-L.-Wallace",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Wallace",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. L. Wallace"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 33
                            }
                        ],
                        "text": "Frederick Mosteller and David L. Wallace."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 155
                            }
                        ],
                        "text": "Rather than attempt to survey the variations here, we refer the reader to the above references, with the suggestion that the book by Mosteller and Wallace [40] is the most clear treatment from a classi cation standpoint."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 124
                            }
                        ],
                        "text": "The distributions investigated have mostly been Poisson mixtures [4, 26]:the Poisson itself [40], mixtures of 2, 3, or more Poissons [1, 2, 22, 23, 36], andthe negative binomial (an in nite mixture of Poissons) [40]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 131
                            }
                        ],
                        "text": "Rather than attemptto survey the variations here, we refer the reader to the above references, withthe suggestion that the book by Mosteller and Wallace [40] is the most cleartreatment from a classi cation standpoint.Despite considerable study, explicit use of Poisson mixtures for text retrievalhave not proven more e ective than using the BIM [35,42]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 93
                            }
                        ],
                        "text": "The distributions investigated have mostly been Poisson mixtures [4, 26]: the Poisson itself [40], mixtures of 2, 3, or more Poissons [1, 2, 22, 23, 36], and the negative binomial (an in nite mixture of Poissons) [40]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 67
                            }
                        ],
                        "text": "It should be noted, however, that moststudies of Poisson mixtures (Mosteller and Wallace being an exception) havebeen applications to text retrieval rather than routing or categorization (wheremore training data is available), and/or have focused on unsupervised tting ofPoisson mixtures rather than supervised learning with a naive Bayes model.5.2 Multinomial ModelsAn alternative approach to modeling term frequencies is to treat the bag of wordsfor a length f document as resulting from f draws on a d-valued multinomialvariable X, rather than as a single draw on a vector-valued variable of length d[15]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 60749965,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "af0c05cad7d09a5d7bd296dd24f6172ca8e84cf7",
            "isKey": true,
            "numCitedBy": 388,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Applied-Bayesian-and-classical-inference-:-the-case-Mosteller-Wallace",
            "title": {
                "fragments": [],
                "text": "Applied Bayesian and classical inference : the case of the Federalist papers"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746656"
                        ],
                        "name": "E. Voorhees",
                        "slug": "E.-Voorhees",
                        "structuredName": {
                            "firstName": "Ellen",
                            "lastName": "Voorhees",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Voorhees"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144169170"
                        ],
                        "name": "D. Harman",
                        "slug": "D.-Harman",
                        "structuredName": {
                            "firstName": "Donna",
                            "lastName": "Harman",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Harman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 195963785,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9ad10c66ad9c7e4eb5ba540a448b04d3cddd40fb",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Information-Technology:-The-Fifth-Text-REtrieval-|-Voorhees-Harman",
            "title": {
                "fragments": [],
                "text": "Information Technology: The Fifth Text REtrieval Conference [TREC-5] | NIST"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797808"
                        ],
                        "name": "G. Salton",
                        "slug": "G.-Salton",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Salton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salton"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61113802,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "939d409a615d4b88c0a84e1f9b99ed67a9053208",
            "isKey": false,
            "numCitedBy": 3147,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-SMART-Retrieval-System\u2014Experiments-in-Automatic-Salton",
            "title": {
                "fragments": [],
                "text": "The SMART Retrieval System\u2014Experiments in Automatic Document Processing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 167
                            }
                        ],
                        "text": "An ongoing surprise and disappointment is that structurally simple representations produced without linguistic or domain knowledge have been as e ective as any others [30, 33]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60921418,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aecf9f96f2fa2a480cb82e349ce26b5fe7c57f1f",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Text-representation-for-intelligent-text-retrieval:-Lewis",
            "title": {
                "fragments": [],
                "text": "Text representation for intelligent text retrieval: a classification-oriented view"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1847175"
                        ],
                        "name": "M. Minsky",
                        "slug": "M.-Minsky",
                        "structuredName": {
                            "firstName": "Marvin",
                            "lastName": "Minsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Minsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2434678"
                        ],
                        "name": "S. Papert",
                        "slug": "S.-Papert",
                        "structuredName": {
                            "firstName": "Seymour",
                            "lastName": "Papert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Papert"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60361935,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f674bd704e680f57ec08549492e4444007facf9f",
            "isKey": false,
            "numCitedBy": 326,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Perceptrons:-expanded-edition-Minsky-Papert",
            "title": {
                "fragments": [],
                "text": "Perceptrons: expanded edition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144169170"
                        ],
                        "name": "D. Harman",
                        "slug": "D.-Harman",
                        "structuredName": {
                            "firstName": "Donna",
                            "lastName": "Harman",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Harman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 54164761,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e5d615878bbc68051999515f3b78ce8fe606d39b",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-fourth-text-REtrieval-conference-Harman",
            "title": {
                "fragments": [],
                "text": "The fourth text REtrieval conference"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34986152"
                        ],
                        "name": "S. P. Harter",
                        "slug": "S.-P.-Harter",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Harter",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. P. Harter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60495600,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "932149a3b4e3c63a97db9a95da8e7a12ca178a96",
            "isKey": false,
            "numCitedBy": 200,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-probabilistic-approach-to-automatic-keyword-Harter",
            "title": {
                "fragments": [],
                "text": "A probabilistic approach to automatic keyword indexing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144169170"
                        ],
                        "name": "D. Harman",
                        "slug": "D.-Harman",
                        "structuredName": {
                            "firstName": "Donna",
                            "lastName": "Harman",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Harman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 115
                            }
                        ],
                        "text": "Robertson and Sparck Jones' particular interest in the binary independence model was its use in relevance feedback [20, 45]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 46426807,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5fa83eb09ab77bbfbb9543790c2bc7557bea717a",
            "isKey": false,
            "numCitedBy": 202,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Relevance-Feedback-and-Other-Query-Modification-Harman",
            "title": {
                "fragments": [],
                "text": "Relevance Feedback and Other Query Modification Techniques"
            },
            "venue": {
                "fragments": [],
                "text": "Information Retrieval: Data Structures & Algorithms"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Document classiication using a nite mixture model"
            },
            "venue": {
                "fragments": [],
                "text": "Document classiication using a nite mixture model"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 82
                            }
                        ],
                        "text": "Indeed, we know of many applications of multinomial models to text categorization [3,14, 15,25, 32, 34] but none to text retrieval."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Document classi cation using a nite mixture"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Information Retrieval. Butterworths, London, second edition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 82
                            }
                        ],
                        "text": "Indeed, we know of many applications of multinomial models to text categorization [3,14, 15,25, 32, 34] but none to text retrieval."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A method for disam biguating word senses in a large corpus. Computers and the Humanities"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Information Retrieval. Butterworths"
            },
            "venue": {
                "fragments": [],
                "text": "Information Retrieval. Butterworths"
            },
            "year": 1979
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Losee . Parameter estimation for probabilistic document - retrieval mod"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the American Society for Information Science"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Experiments with representation in a document retrieval system"
            },
            "venue": {
                "fragments": [],
                "text": "Information Technology: Research and Development,"
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Second Text REtrieval Conference"
            },
            "venue": {
                "fragments": [],
                "text": "The Second Text REtrieval Conference"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Document classiication by machine: Theory and practice"
            },
            "venue": {
                "fragments": [],
                "text": "COLING 94: The 15th International Conference on Computational Linguistics. Proceedings, Vol. II., pages 1059{1063"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Relevance feedback in information retrieval In Gerard Salton, editor, The SMART Retrieval System: Experiments in Automatic Document Processing , pages 313{323"
            },
            "venue": {
                "fragments": [],
                "text": "Relevance feedback in information retrieval In Gerard Salton, editor, The SMART Retrieval System: Experiments in Automatic Document Processing , pages 313{323"
            },
            "year": 1971
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 264,
                                "start": 260
                            }
                        ],
                        "text": "2 Multinomial Models An alternative approach to modeling term frequencies is to treat the bag of words for a length f document as resulting from f draws on a d-valued multinomial variable X, rather than as a single draw on a vector-valued variable of length d [15]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 82
                            }
                        ],
                        "text": "Indeed, we know of many applications of multinomial models to text categorization [3,14, 15,25, 32, 34] but none to text retrieval."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Document classi cation by ma chine: Theory and practice"
            },
            "venue": {
                "fragments": [],
                "text": "The 15th International Conference  on Computational Linguistics. Proceedings,"
            },
            "year": 1994
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 24,
            "methodology": 7
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 65,
        "totalPages": 7
    },
    "page_url": "https://www.semanticscholar.org/paper/Naive-(Bayes)-at-Forty:-The-Independence-Assumption-Lewis/44e915a220ce74badf755aae870fa0b69ee2b82a?sort=total-citations"
}