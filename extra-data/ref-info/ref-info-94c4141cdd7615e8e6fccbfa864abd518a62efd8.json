{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13087918"
                        ],
                        "name": "F. Arman",
                        "slug": "F.-Arman",
                        "structuredName": {
                            "firstName": "Farshid",
                            "lastName": "Arman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Arman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2998944"
                        ],
                        "name": "R. Depommier",
                        "slug": "R.-Depommier",
                        "structuredName": {
                            "firstName": "Remi",
                            "lastName": "Depommier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Depommier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46891469"
                        ],
                        "name": "A. Hsu",
                        "slug": "A.-Hsu",
                        "structuredName": {
                            "firstName": "Arding",
                            "lastName": "Hsu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hsu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2957701"
                        ],
                        "name": "M. Chiu",
                        "slug": "M.-Chiu",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Chiu",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Chiu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 110
                            }
                        ],
                        "text": "Recently, techniques have proposed browsing representations based on information within the video [12], [13], [14], [16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1360834,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9895be389b31013b477e3bb48a006ad5c73f3a14",
            "isKey": false,
            "numCitedBy": 240,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "A novel methodology to represent the contents of a video sequence is presented. The representation is used to allow the user to rapidly view a video sequence in order to find a particular point within the sequence and/or to decide whether the contents of the sequence are relevant to his or her needs. This system, referred to as content-based browsing, forms an abstraction to represent each shot of the sequence by using a representative frame, or an Rframe, and it includes management techniques to allow the user to easily navigate the Rframes. This methodology is superior to the current techniques of fast forward and rewind because rather than using every frame to view and judge the contents, only a few abstractions are used. Therefore, the need to retrieve the video from a storage system and to transmit every frame over the network in its entirety no longer exists, saving time, expenses, and bandwidth."
            },
            "slug": "Content-based-browsing-of-video-sequences-Arman-Depommier",
            "title": {
                "fragments": [],
                "text": "Content-based browsing of video sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The need to retrieve the video from a storage system and to transmit every frame over the network in its entirety no longer exists, saving time, expenses, and bandwidth."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '94"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2523644"
                        ],
                        "name": "A. Akutsu",
                        "slug": "A.-Akutsu",
                        "structuredName": {
                            "firstName": "Akihito",
                            "lastName": "Akutsu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Akutsu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34638339"
                        ],
                        "name": "Yoshinobu Tonomura",
                        "slug": "Yoshinobu-Tonomura",
                        "structuredName": {
                            "firstName": "Yoshinobu",
                            "lastName": "Tonomura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshinobu Tonomura"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 113
                            }
                        ],
                        "text": "We can interpret camera motion as a pan or zoom by examining the geometric properties of the optical flow vectors[1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17185163,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb3503e948fcda8e40e2be1191a9e51d63e036bd",
            "isKey": false,
            "numCitedBy": 101,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a new, efficient and practical way to extract lens zoom, camera pan and camera tilt information using modified motion analysis. The proposed method is called the Video Tomography Method (VTM), in which tomographic techniques are introduced into a motion estimation algorithm. By using the VTM, one is able to visualize motion as a spatiotemporal flow for motion analysis. The VTM is an extremely robust [resistant to noise] method for estimating camera operation due to its tomographic nature. The practicality of this type of motion estimation and analysis is confirmed by the results of our simulations and experiments in testing the prototype platform with a low quality video source. Other possible applications that might use extracted motion data are discussed. This method is targeted towards video handling applications that attribute extracted motion data into a video index. It will enhance the process of editing and browsing structured video, and will allow the visualization of scenes spatiotemporally so that video may be accessed intuitively and spatially in relation to its temporal location. This type of access is a new interface for structured video. Scene reconstruction techniques can be extended to apply to the problem of reconstructing occluded images and resolution enhancement."
            },
            "slug": "Video-tomography:-an-efficient-method-for-and-Akutsu-Tonomura",
            "title": {
                "fragments": [],
                "text": "Video tomography: an efficient method for camerawork extraction and motion analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This method is targeted towards video handling applications that attribute extracted motion data into a video index, and will allow the visualization of scenes spatiotemporally so that video may be accessed intuitively and spatially in relation to its temporal location."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '94"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35497738"
                        ],
                        "name": "M. Mauldin",
                        "slug": "M.-Mauldin",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Mauldin",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mauldin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 166
                            }
                        ],
                        "text": "We use the well-known technique of TF-IDF (Term Frequency Inverse Document Frequency) to identify critical words and their relative importance for the video document [6], [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 70
                            }
                        ],
                        "text": "Even with intelligent content-based search algorithms being developed [6], [15], multiple segments will be returned to insure retrieval of pertinent information and the users will often need to view them to obtain final selections."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60835163,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8809dbe0bb06859786dc6426026fd6ab5e10735e",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Most information retrieval systems today use only the presence or absence of keywords to classify and retrieve texts. But simple word searches and frequency distributions do not provide these systems with any understanding of those texts. We call this limit the keyword barrier. To go beyond this barrier, information retrieval systems must at least partially understand the texts they retrieve. Although full natural language parsers are capable today of deep understanding within limited domains, they are still too restrictive and slow for general information retrieval. Text skimming parsers, such as DeJong's F scRUMP, are capable of coarse-level understanding, but they require large amounts of domain-specific knowledge in each application domain. \nThis dissertation describes F scERRET: a full text, conceptual information retrieval system that uses a partial understanding of its texts to provide greater precision and recall performance than keyword search techniques. F scERRET parses its input documents by text skimming and then stores their representations as canonical case frames (called abstracts). User queries are similarly converted to case frames, and are matched to the abstracts using a case frame matcher. F scERRET uses the M sc CF scRUMP parser, a derivative of F scRUMP with two important additions. First, it is able to access an on-line English dictionary (Webster's Seventh) to handle unknown words, using script-based expectations to resolve multiple-meaning ambiguities. Second, a script learning component based on Holland's genetic algorithms updates the script database, augmenting M sc CF scRUMP's episodic world knowledge. \nComparison studies of F scERRET's retrieval performance on 1065 astronomy texts show significant improvement in both recall and precision versus the standard boolean keyword search. Precision increased from 35 to 48 percent, and recall more than doubled, from 19 to 52 percent. The script learning component generated new scripts that significantly improved the recall performance of the basic F scERRET system without significant effects on precision. \nThe robust parsing abilities demonstrated, with the depth and flexibility provided by on-line dictionary access and script learning, make text skimming a useful foundation for many applications. The partial understanding provided by a canonical case frame representation is useful for tasks as diverse as information filtering, routing, categorization and summarization."
            },
            "slug": "Information-retrieval-by-text-skimming-Mauldin",
            "title": {
                "fragments": [],
                "text": "Information retrieval by text skimming"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "F scERRET is described: a full text, conceptual information retrieval system that uses a partial understanding of its texts to provide greater precision and recall performance than keyword search techniques."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1931458"
                        ],
                        "name": "B. Arons",
                        "slug": "B.-Arons",
                        "structuredName": {
                            "firstName": "Barry",
                            "lastName": "Arons",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Arons"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 195
                            }
                        ],
                        "text": "Techniques in speech recognition will also be used to segment video based on transitions between speakers and topics which are usually marked by silence or low energy areas in the acoustic signal[2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14765378,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ab1b25bdb2ebbbdc97bf72772d87c01015b06cc3",
            "isKey": false,
            "numCitedBy": 117,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "Skimming or browsing audio recordings is much more difficult than visually scanning a document because of the temporal nature of audio. By exploiting properties of spontaneous speech it is possible to automatically select and present salient audio segments in a time-efficient manner. Techniques for segmenting recordings and a prototype user interface for skimming speech are described. The system developed incorporates time-compressed speech and pause removal to reduce the time needed to listen to speech recordings. This paper presents a multi-level approach to auditory skimming, along with user interface techniques for interacting with the audio and providing feedback. Several time compression algorithms ami an adaptive speech detection technique are also stuntnarized."
            },
            "slug": "SpeechSkimmer:-interactively-skimming-recorded-Arons",
            "title": {
                "fragments": [],
                "text": "SpeechSkimmer: interactively skimming recorded speech"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper presents a multi-level approach to auditory skimming, along with user interface techniques for interacting with the audio and providing feedback, and a prototype user interface for skimming speech."
            },
            "venue": {
                "fragments": [],
                "text": "UIST '93"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086151"
                        ],
                        "name": "Carlo Tomasi",
                        "slug": "Carlo-Tomasi",
                        "structuredName": {
                            "firstName": "Carlo",
                            "lastName": "Tomasi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carlo Tomasi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 186
                            }
                        ],
                        "text": "Such trackable features can be identified as the regions with large, well conditioned eigenvalues in the 2x2 gradient derivative matrix, G, that appears on the left side of equation (4) [10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15407854,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a6cc5a40d17b2bb915ca086c6c35cd4bb558232",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Inferring the depth and shape of remote objects and the camera motion from a sequence of images is possible in principle, but is an ill-conditioned problem when the objects are distant with respect to their size. This problem is overcome by inferring shape and motion without computing depth as an intermediate step. On a single epipolar plane, an image sequence can be represented by the F*P matrix of the image coordinates of P points tracked through F frames. It is shown that under orthographic projection this matrix is of rank three. Using this result, the authors develop a shape-and-motion algorithm based on singular value decomposition. The algorithm gives accurate results, without relying on any smoothness assumption for either shape or motion.<<ETX>>"
            },
            "slug": "Shape-and-motion-without-depth-Tomasi-Kanade",
            "title": {
                "fragments": [],
                "text": "Shape and motion without depth"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that under orthographic projection this matrix of the image coordinates of P points tracked through F frames is of rank three, and the authors develop a shape-and-motion algorithm based on singular value decomposition."
            },
            "venue": {
                "fragments": [],
                "text": "[1990] Proceedings Third International Conference on Computer Vision"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48232483"
                        ],
                        "name": "Leo Degen",
                        "slug": "Leo-Degen",
                        "structuredName": {
                            "firstName": "Leo",
                            "lastName": "Degen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Leo Degen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "27449564"
                        ],
                        "name": "Richard Mander",
                        "slug": "Richard-Mander",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Mander",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Richard Mander"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1925732"
                        ],
                        "name": "G. Salomon",
                        "slug": "G.-Salomon",
                        "structuredName": {
                            "firstName": "Gitta",
                            "lastName": "Salomon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salomon"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 118
                            }
                        ],
                        "text": "Speeding up the video rate eliminates the majority of the audio information and distorts much of the image information[3], while showing separate video sections at fixed intervals merely gives a random estimate of the overall content."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1193051,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "15a92ae29a97756eba42a571e86cd55bcf6fd8b2",
            "isKey": false,
            "numCitedBy": 78,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Audio data is rarely used on desktop computers today, although audio is otherwise widely used for communication tasks. This paper describes early work aimed at creating computer tools that support the ways users may want to work with audio data. User needs for the system were determined by intervieweing people already working with audio data, using existing devices such as portable tape recorders. A preliminary prototype system \u2013 consisting of a personal tape recorder for recording and simultaneously marking audio and a Macintosh application for browsing these recordings \u2013 was built. Informal field user tests of this prototype system have indicated areas for improvement and directions for future work."
            },
            "slug": "Working-with-audio:-integrating-personal-tape-and-Degen-Mander",
            "title": {
                "fragments": [],
                "text": "Working with audio: integrating personal tape recorders and desktop computers"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Early work aimed at creating computer tools that support the ways users may want to work with audio data are described, using existing devices such as portable tape recorders."
            },
            "venue": {
                "fragments": [],
                "text": "CHI"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34638339"
                        ],
                        "name": "Yoshinobu Tonomura",
                        "slug": "Yoshinobu-Tonomura",
                        "structuredName": {
                            "firstName": "Yoshinobu",
                            "lastName": "Tonomura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshinobu Tonomura"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2523644"
                        ],
                        "name": "A. Akutsu",
                        "slug": "A.-Akutsu",
                        "structuredName": {
                            "firstName": "Akihito",
                            "lastName": "Akutsu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Akutsu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113938"
                        ],
                        "name": "Y. Taniguchi",
                        "slug": "Y.-Taniguchi",
                        "structuredName": {
                            "firstName": "Yukinobu",
                            "lastName": "Taniguchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Taniguchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073397535"
                        ],
                        "name": "Gen Suzuki",
                        "slug": "Gen-Suzuki",
                        "structuredName": {
                            "firstName": "Gen",
                            "lastName": "Suzuki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gen Suzuki"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 116
                            }
                        ],
                        "text": "Recently, techniques have proposed browsing representations based on information within the video [12], [13], [14], [16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 29793324,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "59de2dc425e6bbd7e3e2a4366fd61ced9013d1b5",
            "isKey": false,
            "numCitedBy": 128,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Video is becoming increasingly important for multimedia applications, but computers should let us do more than just watch.We propose a way for computers to structure video and several new interfaces that make it easier to browse and search."
            },
            "slug": "Structured-Video-Computing-Tonomura-Akutsu",
            "title": {
                "fragments": [],
                "text": "Structured Video Computing"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A way for computers to structure video and several new interfaces that make it easier to browse and search are proposed that will let us do more than just watch."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE MultiMedia"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144721996"
                        ],
                        "name": "M. Sanderson",
                        "slug": "M.-Sanderson",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Sanderson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sanderson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 33
                            }
                        ],
                        "text": "The extraction of significant information, such as specific objects, audio keywords and relevant video structure, is made possible through the integration of techniques in image and language understanding."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61918350,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "e0a178908cd0851e357d393dc1e0fc424666894b",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Inevitably, reading is one of the requirements to be undergone. To improve the performance and quality, someone needs to have something new every day. It will suggest you to have more inspirations, then. However, the needs of inspirations will make you searching for some sources. Even from the other people experience, internet, and many books. Books and internet are the recommended media to help you improving your quality and performance."
            },
            "slug": "Conceptual-Information-Retrieval-\u2013-A-Case-Study-in-Sanderson",
            "title": {
                "fragments": [],
                "text": "Conceptual Information Retrieval \u2013 A Case Study in Adaptive Partial Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "Books and internet are the recommended media to help you improving your quality and performance."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797808"
                        ],
                        "name": "G. Salton",
                        "slug": "G.-Salton",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Salton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144321599"
                        ],
                        "name": "M. McGill",
                        "slug": "M.-McGill",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "McGill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. McGill"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 171
                            }
                        ],
                        "text": "We use the well-known technique of TF-IDF (Term Frequency Inverse Document Frequency) to identify critical words and their relative importance for the video document [6], [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 43685115,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "49af3e80343eb80c61e727ae0c27541628c7c5e2",
            "isKey": false,
            "numCitedBy": 12606,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Some people may be laughing when looking at you reading in your spare time. Some may be admired of you. And some may want be like you who have reading hobby. What about your own feel? Have you felt right? Reading is a need and a hobby at once. This condition is the on that will make you feel that you must read. If you know are looking for the book enPDFd introduction to modern information retrieval as the choice of reading, you can find here."
            },
            "slug": "Introduction-to-Modern-Information-Retrieval-Salton-McGill",
            "title": {
                "fragments": [],
                "text": "Introduction to Modern Information Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "Reading is a need and a hobby at once and this condition is the on that will make you feel that you must read."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40588702"
                        ],
                        "name": "B. D. Lucas",
                        "slug": "B.-D.-Lucas",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "Lucas",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. D. Lucas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2121536,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "id": "a06547951c97b2a32f23a6c2b5f79c8c75c9b9bd",
            "isKey": false,
            "numCitedBy": 13327,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Image registration finds a variety of applications in computer vision. Unfortunately, traditional image registration techniques tend to be costly. We present a new image registration technique that makes use of the spatial intensity gradient of the images to find a good match using a type of Newton-Raphson iteration. Our technique is taster because it examines far fewer potential matches between the images than existing techniques Furthermore, this registration technique can be generalized to handle rotation, scaling and shearing. We show how our technique can be adapted tor use in a stereo vision system."
            },
            "slug": "An-Iterative-Image-Registration-Technique-with-an-Lucas-Kanade",
            "title": {
                "fragments": [],
                "text": "An Iterative Image Registration Technique with an Application to Stereo Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work presents a new image registration technique that makes use of the spatial intensity gradient of the images to find a good match using a type of Newton-Raphson iteration, and can be generalized to handle rotation, scaling and shearing."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39682833"
                        ],
                        "name": "H. Rowley",
                        "slug": "H.-Rowley",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Rowley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Rowley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767244"
                        ],
                        "name": "S. Baluja",
                        "slug": "S.-Baluja",
                        "structuredName": {
                            "firstName": "Shumeet",
                            "lastName": "Baluja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baluja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 87
                            }
                        ],
                        "text": "The human-face detection system used for our experiments was developed by Rowley, t al [7], at the Vision and Autonomous Systems Center I J Flow"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 676887,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6af749b2b813af20c2f26962249fafdccdc6a1e",
            "isKey": false,
            "numCitedBy": 477,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a neural network-based face detection system. A retinally connected neural network examines small windows of an image, and decides whether each window contains a face. The system arbitrates between multiple networks to improve performance over a single network. We use a bootstrap algorithm for training, which adds false detections into the training set as training progresses. This eliminates the difficult task of manually selecting non-face training examples, which must be chosen to span the entire space of non-face images. Comparisons with another state-of-the-art face detection system are presented; our system has better performance in terms of detection and false-positive rates."
            },
            "slug": "Human-Face-Detection-in-Visual-Scenes-Rowley-Baluja",
            "title": {
                "fragments": [],
                "text": "Human Face Detection in Visual Scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A neural network-based face detection system that uses a bootstrap algorithm for training, which adds false detections into the training set as training progresses, and has better performance in terms of detection and false-positive rates than other state-of-the-art face detection systems."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48817314"
                        ],
                        "name": "S. Stevens",
                        "slug": "S.-Stevens",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Stevens",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Stevens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065857317"
                        ],
                        "name": "Michael Christen",
                        "slug": "Michael-Christen",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Christen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Christen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679880"
                        ],
                        "name": "H. Wactlar",
                        "slug": "H.-Wactlar",
                        "structuredName": {
                            "firstName": "Howard",
                            "lastName": "Wactlar",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wactlar"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 81
                            }
                        ],
                        "text": "[7] Rowley, H., Baluja, S. and Kanade, K. \u201cHuman Face Detection in Visual Scenes,\u201d Carnegie Mellon University, 1995."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 53
                            }
                        ],
                        "text": "These libraries, such as the InformediaTM project at Carnegie Mellon University [9], will consist of thousands of hours of video made available to a user upon request."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 81
                            }
                        ],
                        "text": "These libraries, such as the Informedia TM project at Carnegie Mellon University [9], will consist of thousands of hours of video made available to a user upon request."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 68
                            }
                        ],
                        "text": "[6] Mauldin, M. \u201cInformation Retrieval by Text Skimming,\u201d PhD Thesis, Carnegie Mellon University."
                    },
                    "intents": []
                }
            ],
            "corpusId": 27777431,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3ecdbb4dc0dc539645483ce625ee76186de5a5f5",
            "isKey": true,
            "numCitedBy": 44,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Informedia:-improving-access-to-digital-video-Stevens-Christen",
            "title": {
                "fragments": [],
                "text": "Informedia: improving access to digital video"
            },
            "venue": {
                "fragments": [],
                "text": "INTR"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u201c An Iterative Technique of Image Registration and Its Application to Stereo"
            },
            "venue": {
                "fragments": [],
                "text": "Proc . 7 th International Joint Conference on Artificial Intelligence"
            },
            "year": 1981
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 98
                            }
                        ],
                        "text": "Recently, techniques have proposed browsing representations based on information within the video [12], [13], [14], [16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 126
                            }
                        ],
                        "text": "It has been shown that some image analysis on encoded data can be more efficient and just as accurate as still image analysis [12], [13]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Video parsing and indexing of compressed data"
            },
            "venue": {
                "fragments": [],
                "text": " Multimedia Tools and Applications  1 March 1995, pp. 89-111."
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proceedings of the Second Text Retrieval Conference, D. Harmon, editor, sponsored by ARPA/SISTO"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Second Text Retrieval Conference, D. Harmon, editor, sponsored by ARPA/SISTO"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 63
                            }
                        ],
                        "text": "Using the Lucas-Kanade gradient descent method for optical flow[5], we can track individual regions from one frame to the next and create a vector representation for all associative camera motion."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An Iterative Technique of Image Registration and Its Application to Stereo,\u201dProc"
            },
            "venue": {
                "fragments": [],
                "text": "7th International Joint Conference on Artificial Intelligence  ,"
            },
            "year": 1981
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Acknowledgment The authors would like to thank Henry Rowley and Shumeet Baluja for providing the routines for face detection; and Michael Mauldin for providing the routines for keyword selection"
            },
            "venue": {
                "fragments": [],
                "text": "This work is partially funded by the National Science Foundation, the National Space and Aeronautics Administration, and the Advanced Research Projects Agency"
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 8,
            "methodology": 5
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 17,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Video-Skimming-for-Quick-Browsing-based-on-Audio-Smith/94c4141cdd7615e8e6fccbfa864abd518a62efd8?sort=total-citations"
}