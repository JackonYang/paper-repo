{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691993"
                        ],
                        "name": "E. Riloff",
                        "slug": "E.-Riloff",
                        "structuredName": {
                            "firstName": "Ellen",
                            "lastName": "Riloff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Riloff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116267850"
                        ],
                        "name": "Jay Shoen",
                        "slug": "Jay-Shoen",
                        "structuredName": {
                            "firstName": "Jay",
                            "lastName": "Shoen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jay Shoen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Fast dictionary construction also opens the door for IE technology to support other tasks, such as text classification ( Riloff & Shoen 1995 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 120
                            }
                        ],
                        "text": "Fast dictionary construction also opens the door for IE technology to support other tasks, such as text classification (Riloff & Shoen 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10779824,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7322e43c38897834e746443f67aeda23f42b8aa9",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Previous work on automated dictionary construction for information extraction has relied on annotated text corpora. However, annotating a corpus is time-consuming and difficult. We propose that conceptual patterns for information extraction can be acquired automatically using only a preclassified training corpus and no text annotations. We describe a system called AutoSlog-TS, which is a variation of our previous AutoSlog system, that runs exhaustively on an untagged text corpus. Text classification experiments in the MUC-4 terrorism domain show that the AutoSlog-TS dictionary performs comparably to a hand-crafted dictionary, and actually achieves higher precision on one test set. For text classification, AutoSlog-TS requires no manual effort beyond the preclassified training corpus. Additional experiments suggest how a dictionary produced by AutoSlog-TS can be filtered automatically for information extraction tasks. Some manual intervention is still required in this case, but AutoSlog-TS significantly reduces the amount of effort required to create an appropriate training corpus. 1 I n t r o d u c t i o n In the last few years, significant progress has been made toward automatically acquiring conceptual patterns for information extraction (e.g., [Riloff, 1993; Kim and Moldovan, 1993]). However, previous approaches require an annotated training corpus or some other type of manually encoded training data. Annota ted training corpora are expensive to build, both in terms of the time and the expertise required to create them. Furthermore, training corpora for information extraction are typically annota ted with domain-specific tags, in contrast to general-purpose annotations such as part-of-speech tags or noun-phrase bracketing (e.g., the Brown Corpus [Francis and Kucera, 1982] and the Penn Treebank [Marcus et al., 1993]). Consequently, a new training corpus must be annotated for each domain. We have begun to explore the possibility of using an untagged corpus to automatically acquire conceptual pat terns for information extraction. Our approach uses a combination of domainindependent linguistic rules and statistics. The linguistic rules are based on our previous system, AutoSlog [Riloff, 1993], which automatically constructs dictionaries for information extraction using an annotated training corpus. We have put a new spin on the original system by applying it exhaustively to an untagged but preclassified training corpus (i.e., a corpus in which the texts have been manually classified as either relevant or irrelevant). Statistics are then used to sift through the myriad of pat terns that it produces. The new system, AutoSlog-TS, can generate a conceptual dictionary of extraction pat terns for a domain from a preclassified text corpus."
            },
            "slug": "Automatically-Acquiring-Conceptual-Patterns-without-Riloff-Shoen",
            "title": {
                "fragments": [],
                "text": "Automatically Acquiring Conceptual Patterns without an Annotated Corpus"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is proposed that conceptual patterns for information extraction can be acquired automatically using only a preclassified training corpus and no text annotations, and a system called AutoSlog-TS is described, which is a variation of the previous AutoS Log system that runs exhaustively on an untagged text corpus."
            },
            "venue": {
                "fragments": [],
                "text": "VLC@ACL"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691993"
                        ],
                        "name": "E. Riloff",
                        "slug": "E.-Riloff",
                        "structuredName": {
                            "firstName": "Ellen",
                            "lastName": "Riloff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Riloff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 19
                            }
                        ],
                        "text": "AutoSlog AutoSlog (Riloff 1996) is a dictionary construction system that creates extraction patterns automatically using heuristic rules."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 102
                            }
                        ],
                        "text": "Previous experiments with AutoSlog suggested that it took a user about 8 hours to annotate 160 texts (Riloff 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 5
                            }
                        ],
                        "text": "3See (Riloff 1996) for a more detailed explanation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 9
                            }
                        ],
                        "text": "AutoSlog (Riloff 1996) is a dictionary construction system that creates extraction patterns automatically using heuristic rules."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 218
                            }
                        ],
                        "text": "We rank the extraction patterns according to the formula: relevance rate * log2(frequency), unless the relevance rate is 5 0.5 in which case the function returns zero because the pattern is negatively correlated\n3See (Riloff 1996) for a more detailed explanation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 363940,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "97a3d56d74575aae5d563ab2a0438a25ffbb69ae",
            "isKey": false,
            "numCitedBy": 168,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-Empirical-Study-of-Automated-Dictionary-for-in-Riloff",
            "title": {
                "fragments": [],
                "text": "An Empirical Study of Automated Dictionary Construction for Information Extraction in Three Domains"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691993"
                        ],
                        "name": "E. Riloff",
                        "slug": "E.-Riloff",
                        "structuredName": {
                            "firstName": "Ellen",
                            "lastName": "Riloff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Riloff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 63
                            }
                        ],
                        "text": "One of the first dictionary construction systems was AutoSlog (Riloff 1993)) which requires tagged noun phrases in the form of annotated text or text with associated answer keys."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 191,
                                "start": 180
                            }
                        ],
                        "text": "I II AutoSlog II AutoSlog-TS 1\nI II II I I J\nTable 3: Comparative Results\nThe AutoSlog precision results are substantially lower than those generated by the MUC-4 scoring program (Riloff 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 112
                            }
                        ],
                        "text": "In experiments with the MUC-4 terrorism domain, it took a user only 5 hours to review 1237 extraction patterns (Riloff 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In experiments with the MUC-4 terrorism domain, it took a user only 5 hours to review 1237 extraction patterns ( Riloff 1993 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Corpus-based approaches to information extraction have demonstrated a significant time savings over conventional hand-coding methods ( Riloff 1993 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The AutoSlog precision results are substantially lower than those generated by the MUC-4 scoring program ( Riloff 1993 )."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "One of the first dictionary construction systems was AutoSlog ( Riloff 1993 )) which requires tagged noun phrases in the form of annotated text or text with associated answer keys."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 156
                            }
                        ],
                        "text": "1044 Natural Language\nCorpus-based approaches to information extraction have demonstrated a significant time savings over conventional hand-coding methods (Riloff 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2257053,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bdc08721414c972ab451f8ef3ef39d63c741b324",
            "isKey": false,
            "numCitedBy": 556,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Knowledge-based natural language processing systems have achieved good success with certain tasks but they are often criticized because they depend on a domain-specific dictionary that requires a great deal of manual knowledge engineering. This knowledge engineering bottleneck makes knowledge-based NLP systems impractical for real-world applications because they cannot be easily scaled up or ported to new domains. In response to this problem, we developed a system called AutoSlog that automatically builds a domain-specific dictionary of concepts for extracting information from text. Using AutoSlog, we constructed a dictionary for the domain of terrorist event descriptions in only 5 person-hours. We then compared the AutoSlog dictionary with a hand-crafted dictionary that was built by two highly skilled graduate students and required approximately 1500 person-hours of effort. We evaluated the two dictionaries using two blind test sets of 100 texts each. Overall, the AutoSlog dictionary achieved 98% of the performance of the hand-crafted dictionary. On the first test set, the AutoSlog dictionary obtained 96.3% of the performance of the hand-crafted dictionary. On the second test set, the overall scores were virtually indistinguishable with the AutoSlog dictionary achieving 99.7% of the performance of the handcrafted dictionary."
            },
            "slug": "Automatically-Constructing-a-Dictionary-for-Tasks-Riloff",
            "title": {
                "fragments": [],
                "text": "Automatically Constructing a Dictionary for Information Extraction Tasks"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Using AutoSlog, a system that automatically builds a domain-specific dictionary of concepts for extracting information from text, a dictionary for the domain of terrorist event descriptions was constructed in only 5 person-hours and the overall scores were virtually indistinguishable."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2605572"
                        ],
                        "name": "S. Huffman",
                        "slug": "S.-Huffman",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Huffman",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Huffman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "LIEP (Huffman 1996) is another system that learns extraction patterns but relies on predefined key-"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 6
                            }
                        ],
                        "text": "LIEP (Huffman 1996) is another system that learns extraction patterns but relies on predefined keywords, object recognizers (e.g., to identify people and companies), and human interaction to annotate each relevant sentence with an event type."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14690792,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8dadbf2dfebe794ad4fc5022f8bb65195c8f0d5a",
            "isKey": false,
            "numCitedBy": 193,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "A growing population of users want to extract a growing variety of information from on-line texts. Unfortunately, current information extraction systems typically require experts to hand-build dictionaries of extraction patterns for each new type of information to be extracted. This paper presents a system that can learn dictionaries of extraction patterns directly from user-provided examples of texts and events to be extracted from them. The system, called LIEP, learns patterns that recognize relationships between key constituents based on local syntax. Sets of patterns learned by LIEP for a sample extraction task perform nearly at the level of a hand-built dictionary of patterns."
            },
            "slug": "Learning-information-extraction-patterns-from-Huffman",
            "title": {
                "fragments": [],
                "text": "Learning information extraction patterns from examples"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A system that can learn dictionaries of extraction patterns directly from user-provided examples of texts and events to be extracted from them, and learns patterns that recognize relationships between key constituents based on local syntax."
            },
            "venue": {
                "fragments": [],
                "text": "Learning for Natural Language Processing"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144295318"
                        ],
                        "name": "S. Soderland",
                        "slug": "S.-Soderland",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Soderland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Soderland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145262164"
                        ],
                        "name": "David Fisher",
                        "slug": "David-Fisher",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Fisher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Fisher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51080653"
                        ],
                        "name": "J. Aseltine",
                        "slug": "J.-Aseltine",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Aseltine",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Aseltine"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1925215"
                        ],
                        "name": "W. Lehnert",
                        "slug": "W.-Lehnert",
                        "structuredName": {
                            "firstName": "Wendy",
                            "lastName": "Lehnert",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Lehnert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 0
                            }
                        ],
                        "text": "CRYSTAL relies on both domain-specific annotations plus a semantic hierarchy and associated lexicon."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 0
                            }
                        ],
                        "text": "CRYSTAL: Inducing a conceptual dictionary."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 9
                            }
                        ],
                        "text": "CRYSTAL (Soderland et al. 1995) also generates extraction patterns using an annotated training corpus."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9168228,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8245f6099f547008522ebbe6fb813d8132085746",
            "isKey": true,
            "numCitedBy": 409,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the central knowledge sources of an information extraction (IE) system IS a dictionary of linguistic patterns that can be used to identify references to relevant information in a text Automatic creation of conceptual dictionaries is important for portability and scalability of an IE system This paper describes CRYSTAL, a system which automatically induces a dictionary of \"concept-node definitions\" sufficient to identify relevant information from a training corpus Each of these concept-node definitions is generalized as far as possible without producing errors, so that a minimum number of dictionary entries cover the positive training instances Because it tests the accuracy of each proposed definition, CRYSTAL can often surpass human intuitions in creating reliable extraction rules."
            },
            "slug": "CRYSTAL:-Inducing-a-Conceptual-Dictionary-Soderland-Fisher",
            "title": {
                "fragments": [],
                "text": "CRYSTAL: Inducing a Conceptual Dictionary"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "CRYSTAL is described, a system which automatically induces a dictionary of \"concept-node definitions\" sufficient to identify relevant information from a training corpus that can often surpass human intuitions in creating reliable extraction rules."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2169401916"
                        ],
                        "name": "J.-T. Kim",
                        "slug": "J.-T.-Kim",
                        "structuredName": {
                            "firstName": "J.-T.",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J.-T. Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40497400"
                        ],
                        "name": "D. Moldovan",
                        "slug": "D.-Moldovan",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Moldovan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Moldovan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "PALKA ( Kim & Moldovan 1993 ) is similar in spirit to AutoSlog, but requires manually defined frames (including keywords), a semantic hierarchy, and an associated lexicon."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 7
                            }
                        ],
                        "text": "PALKA (Kim & Moldovan 1993) is similar in spirit to AutoSlog, but requires manually defined frames (including keywords), a semantic hierarchy, and an associated lexicon."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59002598,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e80b34a55aa56578f9a4f27ea207f8c42c93a378",
            "isKey": false,
            "numCitedBy": 78,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "A knowledge acquisition tool to extract semantic patterns for a memory-based information retrieval system is presented. The major goal of this tool is to facilitate the construction of a large knowledge base of semantic patterns. The system acquires semantic patterns from texts with a small amount of user interaction. It acquires new phrasal patterns from the input text, maps each element of the pattern to a meaning frame, generalizes the acquired pattern, and merges it into the current knowledge base. Interaction with the user is introduced at some decision points, where the ambiguity cannot be resolved automatically without other pieces of predefined knowledge. The acquisition process is described in detail, and a preliminary experimental result is discussed.<<ETX>>"
            },
            "slug": "Acquisition-of-semantic-patterns-for-information-Kim-Moldovan",
            "title": {
                "fragments": [],
                "text": "Acquisition of semantic patterns for information extraction from corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "A knowledge acquisition tool to extract semantic patterns for a memory-based information retrieval system is presented to facilitate the construction of a large knowledge base of semantic patterns."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 9th IEEE Conference on Artificial Intelligence for Applications"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748501"
                        ],
                        "name": "Claire Cardie",
                        "slug": "Claire-Cardie",
                        "structuredName": {
                            "firstName": "Claire",
                            "lastName": "Cardie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Claire Cardie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 774849,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1cf6f1209d29c151b693861e083850f1b385c595",
            "isKey": false,
            "numCitedBy": 99,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a case-based approach to knowledge acquisition for natural language systems that simultaneously learns part of speech, word sense, and concept activation knowledge for all open class words in a corpus. The parser begins with a lexicon of function words and creates a case base of context-sensitive word definitions during a humansupervised training phase. Then, given an unknown word and the context in which it occurs, the parser retrieves definitions from the case base to infer the word's syntactic and semantic features. By encoding context as part of a definition, the meaning of a word can change dynamically in response to surrounding phrases without the need for explicit lexical disambiguation heuristics. Moreover, the approach acquires all three classes of knowledge using the same case representation and requires relatively little training and no hand-coded knowledge acquisition heuristics. We evaluate it in experiments that explore two of many practical applications of the technique and conclude that the case-based method provides a promising approach to automated dictionary construction and knowledge acquisition for sentence analysis in limited domains. In addition, we present a novel case retrieval algorithm that uses decision trees to improve the performance of a k-nearest neighbor similarity metric."
            },
            "slug": "A-Case-Based-Approach-to-Knowledge-Acquisition-for-Cardie",
            "title": {
                "fragments": [],
                "text": "A Case-Based Approach to Knowledge Acquisition for Domain-Specific Sentence Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is concluded that the case-based method provides a promising approach to automated dictionary construction and knowledge acquisition for sentence analysis in limited domains and a novel case retrieval algorithm that uses decision trees to improve the performance of a k-nearest neighbor similarity metric."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734174"
                        ],
                        "name": "M. Marcus",
                        "slug": "M.-Marcus",
                        "structuredName": {
                            "firstName": "Mitchell",
                            "lastName": "Marcus",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Marcus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2424234"
                        ],
                        "name": "Beatrice Santorini",
                        "slug": "Beatrice-Santorini",
                        "structuredName": {
                            "firstName": "Beatrice",
                            "lastName": "Santorini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Beatrice Santorini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2063206"
                        ],
                        "name": "Mary Ann Marcinkiewicz",
                        "slug": "Mary-Ann-Marcinkiewicz",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Marcinkiewicz",
                            "middleNames": [
                                "Ann"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mary Ann Marcinkiewicz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 252796,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0b44fcbeea9415d400c5f5789d6b892b6f98daff",
            "isKey": false,
            "numCitedBy": 8177,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : As a result of this grant, the researchers have now published oil CDROM a corpus of over 4 million words of running text annotated with part-of- speech (POS) tags, with over 3 million words of that material assigned skeletal grammatical structure. This material now includes a fully hand-parsed version of the classic Brown corpus. About one half of the papers at the ACL Workshop on Using Large Text Corpora this past summer were based on the materials generated by this grant."
            },
            "slug": "Building-a-Large-Annotated-Corpus-of-English:-The-Marcus-Santorini",
            "title": {
                "fragments": [],
                "text": "Building a Large Annotated Corpus of English: The Penn Treebank"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "As a result of this grant, the researchers have now published on CDROM a corpus of over 4 million words of running text annotated with part-of- speech (POS) tags, which includes a fully hand-parsed version of the classic Brown corpus."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736513"
                        ],
                        "name": "S. Wermter",
                        "slug": "S.-Wermter",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Wermter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Wermter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691993"
                        ],
                        "name": "E. Riloff",
                        "slug": "E.-Riloff",
                        "structuredName": {
                            "firstName": "Ellen",
                            "lastName": "Riloff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Riloff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2576323"
                        ],
                        "name": "G. Scheler",
                        "slug": "G.-Scheler",
                        "structuredName": {
                            "firstName": "Gabriele",
                            "lastName": "Scheler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Scheler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 21173842,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "319a3a51457b5fcaa179576de11305a045177eaa",
            "isKey": false,
            "numCitedBy": 159,
            "numCiting": 95,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning approaches for natural language processing.- Separating learning and representation.- Natural language grammatical inference: A comparison of recurrent neural networks and machine learning methods.- Extracting rules for grammar recognition from Cascade-2 networks.- Generating English plural determiners from semantic representations: A neural network learning approach.- Knowledge acquisition in concept and document spaces by using self-organizing neural networks.- Using hybrid connectionist learning for speech/language analysis.- SKOPE: A connectionist/symbolic architecture of spoken Korean processing.- Integrating different learning approaches into a multilingual spoken language translation system.- Learning language using genetic algorithms.- A statistical syntactic disambiguation program and what it learns.- Training stochastic grammars on semantical categories.- Learning restricted probabilistic link grammars.- Learning PP attachment from corpus statistics.- A minimum description length approach to grammar inference.- Automatic classification of dialog acts with Semantic Classification Trees and Polygrams.- Sample selection in natural language learning.- Learning information extraction patterns from examples.- Implications of an automatic lexical acquisition system.- Using learned extraction patterns for text classification.- Issues in inductive learning of domain-specific text extraction rules.- Applying machine learning to anaphora resolution.- Embedded machine learning systems for natural language processing: A general framework.- Acquiring and updating hierarchical knowledge for machine translation based on a clustering technique.- Applying an existing machine learning algorithm to text categorization.- Comparative results on using inductive logic programming for corpus-based parser construction.- Learning the past tense of English verbs using inductive logic programming.- A dynamic approach to paradigm-driven analogy.- Can punctuation help learning?.- Using parsed corpora for circumventing parsing.- A symbolic and surgical acquisition of terms through variation.- A revision learner to acquire verb selection rules from human-made rules and examples.- Learning from texts - A terminological metareasoning perspective."
            },
            "slug": "Connectionist,-Statistical-and-Symbolic-Approaches-Wermter-Riloff",
            "title": {
                "fragments": [],
                "text": "Connectionist, Statistical and Symbolic Approaches to Learning for Natural Language Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "Embedded machine learning systems for natural language processing: Acquiring and updating hierarchical knowledge for machine translation based on a clustering technique and applying an existing machine learning algorithm to text categorization."
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1400286782"
                        ],
                        "name": "P. Wiemer-Hastings",
                        "slug": "P.-Wiemer-Hastings",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Wiemer-Hastings",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Wiemer-Hastings"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1779477"
                        ],
                        "name": "S. Lytinen",
                        "slug": "S.-Lytinen",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Lytinen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lytinen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 0
                            }
                        ],
                        "text": "Hastings, P., and Lytinen, S. 1994."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Cardie (Cardie 1993) and Hastings ( Hastings & Lytinen 1994 ) also developed lexical acquisition systems for information extraction, but their systems learned individual word From: AAAI-96 Proceedings."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 35
                            }
                        ],
                        "text": "Cardie (Cardie 1993) and Hastings (Hastings & Lytinen 1994) also developed lexical acquisition systems for information extraction, but their systems learned individual word\nmeanings rather than extraction patterns."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8529717,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "0dbef0679ae6cb5725ae6e1b5b071f36e9514469",
            "isKey": false,
            "numCitedBy": 46,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We have implemented an incremental lexical acquisition mechanism that learns the meanings of previously unknown words from the context in which they appear, as a part of the process of parsing and semantically interpreting sentences. Implementation of this algorithm brought to light a fundamental difference between learning verbs and learning nouns. Specifically, because verbs typically play the predicate role in English sentences, whereas nouns typically function as arguments, we found that different mechanisms were required to learn verbs and nouns. Because of this difference in usage, our learning algorithm formulates the most specific hypotheses possible, consistent with the data, for verb meanings, but the most general hypotheses possible for nouns. Subsequent examples may falsify a current hypothesis, causing verb meanings to be generalized and noun meanings to be made more specific. This paper describes the two approaches used to learn verbs and nouns in the system, and reports on the system's performance in substantial empirical testing."
            },
            "slug": "The-Ups-and-Downs-of-Lexical-Acquisition-Wiemer-Hastings-Lytinen",
            "title": {
                "fragments": [],
                "text": "The Ups and Downs of Lexical Acquisition"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The two approaches used to learn verbs and nouns in the system are described, and the system's performance in substantial empirical testing is reported on."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1925215"
                        ],
                        "name": "W. Lehnert",
                        "slug": "W.-Lehnert",
                        "structuredName": {
                            "firstName": "Wendy",
                            "lastName": "Lehnert",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Lehnert"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60954765,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a29ff9c3d0c5c80716ef1ddb23079c7ca6c1e5c1",
            "isKey": false,
            "numCitedBy": 66,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "A NUMBER OF SEMANTICALLY-ORIENTED TECHNIQUES HAVE BEEN DEVISED OVER THE YEARS TO ADDRESS THE PROBLEMS OF CONCEPTUAL SENTENCE ANALYSIS. WE HAVE IMPLEMENTED A NATURAL LANGUAGE SENTENCE ANALYZER, `CIRCUS'', WHICH INCORPOR- ATES A NUMBER OF WELL-KNOWN TECHNIQUES FROM THE SYMBOLIC INFORMATION PRO- CESSING TRADITION ALONG WITH ORIGINAL TECHNIQUES BASED ON NUMERICAL RELAXA- TION. OUR BASIC SYSTEM ARCHITECTURE SUPPORTS A STACK-CONTROLLED MECHANISM FOR MANAGING SYNTACTIC PREDITIONS, AS WELL AS MODULES FOR HANDLING TWO FUNDAMENTALLY DISTINCT TYPES OF SEMANTIC PREFERENCES: PREDICTIVE SEMANTICS AND DATA-DRIVEN SEMANTICS. A MARKER PASSING ALGORITHM IS USED FOR PREDIC- TIVE SEMANTICS, AND NUMERICAL RELAXATION IS USED FOR DATA-DRIVEN SEMANTICS. THIS PAPER PROVIDES A GENERAL INTRODUCTION TO `CIRCUS'', THE OPPORTUNITIES FOR DIFFERENT KINDS OF MEMORY INTERACTIONS WITH `CIRCUS'', AND DETAILED (BUT NOT TECHNICAL) DESCRIPTIONS OF OUR MARKER PASSING AND NUMERICAL RELAXATION ALGORITHMS. `CIRCUS'' IS CURRENTLY RUNNING UNDER COMMON LISP ON THE TI EXPLORER."
            },
            "slug": "Symbolic/Subsymbolic-Sentence-Analysi:-Exploiting-Lehnert",
            "title": {
                "fragments": [],
                "text": "Symbolic/Subsymbolic Sentence Analysi: Exploiting the Best of Two Worlds"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A general introduction to `CIRCUS' is provided, the OPPORTUNities for DIFFERENT KINDS of MEMORY INTERACTIONS with `cIRCus' are presented, and detailed descriptions of the authors' marker passing and NUMERICAL RELAXATION ALGORITHMS are provided."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 63
                            }
                        ],
                        "text": "One of the first dictionary construction systems was AutoSlog (Riloff 1993)) which requires tagged noun phrases in the form of annotated text or text with associated answer keys."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 155
                            }
                        ],
                        "text": "1044 Natural Language Corpus-based approaches to information extraction have demonstrated a significant time savings over conventional hand-coding methods (Riloff 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 191,
                                "start": 180
                            }
                        ],
                        "text": "I II AutoSlog II AutoSlog-TS 1\nI II II I I J\nTable 3: Comparative Results\nThe AutoSlog precision results are substantially lower than those generated by the MUC-4 scoring program (Riloff 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 112
                            }
                        ],
                        "text": "In experiments with the MUC-4 terrorism domain, it took a user only 5 hours to review 1237 extraction patterns (Riloff 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 105
                            }
                        ],
                        "text": "The AutoSlog precision results are substantially lower than those generated by the MUC-4 scoring program (Riloff 1993)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 156
                            }
                        ],
                        "text": "1044 Natural Language\nCorpus-based approaches to information extraction have demonstrated a significant time savings over conventional hand-coding methods (Riloff 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automatically Constructing a Dictio"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11148235"
                        ],
                        "name": "R. Burchfield",
                        "slug": "R.-Burchfield",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Burchfield",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Burchfield"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 143660780,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "73ca80f87a5509a0f4cc62471b8f088f66facd0b",
            "isKey": false,
            "numCitedBy": 1257,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Frequency-Analysis-of-English-Usage:-Lexicon-and-By-Burchfield",
            "title": {
                "fragments": [],
                "text": "Frequency Analysis of English Usage: Lexicon and Grammar. By W. Nelson Francis and Henry Ku\u010dera with the assistance of Andrew W. Mackie. Boston: Houghton Mifflin. 1982. x + 561"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 7
                            }
                        ],
                        "text": "Cardie (Cardie 1993) and Hastings (Hastings & Lytinen 1994) also developed lexical acquisition systems for information extraction, but their systems learned individual word From: AAAI-96 Proceedings."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 8
                            }
                        ],
                        "text": "Cardie (Cardie 1993) and Hastings (Hastings & Lytinen 1994) also developed lexical acquisition systems for information extraction, but their systems learned individual word\nmeanings rather than extraction patterns."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Case-Based Approach to Knowledge"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "MUC-4 Proceedings. 1992. Proceedings of the Fourth Message Understanding Conference"
            },
            "venue": {
                "fragments": [],
                "text": "MUC-4 Proceedings. 1992. Proceedings of the Fourth Message Understanding Conference"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 31
                            }
                        ],
                        "text": "For example, the Brown corpus (Francis & Kucera 1982) and the Penn Treebank corpus (Marcus, Santorini, & Marcinkiewicz 1993) are widely used because they have been manually annotated with part-of-speech and syntactic bracketing information."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 16
                            }
                        ],
                        "text": "We have developed a system called AutoSlog-TS that creates dictionaries of extraction patterns using only untagged text."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Frequency Analysis of English Usage"
            },
            "venue": {
                "fragments": [],
                "text": "Boston, MA: Houghton Mifflin."
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 6
                            }
                        ],
                        "text": "LIEP (Huffman 1996) is another system that learns extraction patterns but relies on predefined keywords, object recognizers (e.g., to identify people and companies), and human interaction to annotate each relevant sentence with an event type."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 5
                            }
                        ],
                        "text": "LIEP (Huffman 1996) is another system that learns extraction patterns but relies on predefined keywords, object recognizers (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning information extraction"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 7
                            }
                        ],
                        "text": "PALKA (Kim & Moldovan 1993) is similar in spirit to AutoSlog, but requires manually defined frames (including keywords), a semantic hierarchy, and an associated lexicon."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Acquisition of Semantic"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 9,
            "methodology": 6
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 18,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Automatically-Generating-Extraction-Patterns-from-Riloff/acec622ca4fb7e01a56116522d35ded149969d0a?sort=total-citations"
}