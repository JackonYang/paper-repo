{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49967661"
                        ],
                        "name": "B. Rost",
                        "slug": "B.-Rost",
                        "structuredName": {
                            "firstName": "Burkhard",
                            "lastName": "Rost",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Rost"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144882390"
                        ],
                        "name": "C. Sander",
                        "slug": "C.-Sander",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Sander",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sander"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 141
                            }
                        ],
                        "text": "Building upon the work of Qian and Sejnowski (1988), for a long time the best SS prediction performance has been achieved by the PHD scheme (Rost and Sander, 1993, 1994)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1530760,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "4a55757c8f347bb232cf95187a48abe38c4fcbb1",
            "isKey": false,
            "numCitedBy": 521,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The explosive accumulation of protein sequences in the wake of large-scale sequencing projects is in stark contrast to the much slower experimental determination of protein structures. Improved methods of structure prediction from the gene sequence alone are therefore needed. Here, we report a substantial increase in both the accuracy and quality of secondary-structure predictions, using a neural-network algorithm. The main improvements come from the use of multiple sequence alignments (better overall accuracy), from \"balanced training\" (better prediction of beta-strands), and from \"structure context training\" (better prediction of helix and strand lengths). This method, cross-validated on seven different test sets purged of sequence similarity to learning sets, achieves a three-state prediction accuracy of 69.7%, significantly better than previous methods. In addition, the predicted structures have a more realistic distribution of helix and strand segments. The predictions may be suitable for use in practice as a first estimate of the structural type of newly sequenced proteins."
            },
            "slug": "Improved-prediction-of-protein-secondary-structure-Rost-Sander",
            "title": {
                "fragments": [],
                "text": "Improved prediction of protein secondary structure by use of sequence profiles and neural networks."
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A substantial increase in both the accuracy and quality of secondary-structure predictions, using a neural-network algorithm, and the predicted structures have a more realistic distribution of helix and strand segments."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "121168328"
                        ],
                        "name": "S. K. Riis",
                        "slug": "S.-K.-Riis",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Riis",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. K. Riis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144197258"
                        ],
                        "name": "A. Krogh",
                        "slug": "A.-Krogh",
                        "structuredName": {
                            "firstName": "Anders",
                            "lastName": "Krogh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krogh"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 145
                            }
                        ],
                        "text": "Moreover, different predictors can be obtained using profiles, or multiple alignments, in input mode (Rost and Sander, 1994), or in output mode (Riis and Krogh, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1060,
                                "start": 117
                            }
                        ],
                        "text": "Here also larger input windows are possible, especially in combination with the weight sharing approach described in Riis and Krogh (1996), and different inputs could be used for the computation of Ft , Bt and Ot . The forward chain Ft stores contextual information contained at the left of time t and plays the same role as the internal state in standard RNNs. The novel part of the model is the presence of an additional backward chain Bt , in charge of storing contextual information contained at the right of time t , i.e. in the future. The actual form of the bidirectional dynamics is controlled by the connection weights in the subnetworks N\u03c6 and N\u03b2 . As we shall see, these weights can be adjusted using a maximumlikelihood approach. Since equation (2) involves two recurrences, two corresponding boundary conditions must be specified, at the beginning and the end of the sequence. For simplicity, here we use F0 = BT +1 = 0, but it is also possible to adapt the boundaries to the data, extending the technique suggested in Forcada and Carrasco (1995) for standard RNNs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 49
                            }
                        ],
                        "text": "Other assignments used in the literature include Riis and Krogh (1996), where \u03b1 contains DSSP classes H, G and I."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 157
                            }
                        ],
                        "text": "In particular, many different feedforward neural network (NN) architectures have been applied to this task (Qian and Sejnowski, 1988; Rost and Sander, 1994; Riis and Krogh, 1996)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 99
                            }
                        ],
                        "text": "By enriching the feedforward architecture with adaptive input encoding and output filtering, as in Riis and Krogh (1996), 68.5% accuracy was achieved (output filtering actually increases the length of the input window)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 123
                            }
                        ],
                        "text": "This is an improvement over standard NNs with input window sizes ranging from 11 to 17 amino acids (Rost and Sander, 1994; Riis and Krogh, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 117
                            }
                        ],
                        "text": "Here also larger input windows are possible, especially in combination with the weight sharing approach described in Riis and Krogh (1996), and different inputs could be used for the computation of Ft , Bt and Ot ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 3
                            }
                        ],
                        "text": "In Riis and Krogh (1996), further NN architectural and machine learning refinements are used, such as an adaptive encoding of the input amino acids by the NN weight-sharing technique to reduce the number of free parameters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13127724,
            "fieldsOfStudy": [
                "Biology",
                "Computer Science"
            ],
            "id": "96a75947cd7bc189d18157ca17cdfa037a8f5380",
            "isKey": true,
            "numCitedBy": 109,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "The prediction of protein secondary structure by use of carefully structured neural networks and multiple sequence alignments has been investigated. Separate networks are used for predicting the three secondary structures alpha-helix, beta-strand, and coil. The networks are designed using a priori knowledge of amino acid properties with respect to the secondary structure and the characteristic periodicity in alpha-helices. Since these single-structure networks all have less than 600 adjustable weights, overfitting is avoided. To obtain a three-state prediction of alpha-helix, beta-strand, or coil, ensembles of single-structure networks are combined with another neural network. This method gives an overall prediction accuracy of 66.3% when using 7-fold cross-validation on a database of 126 nonhomologous globular proteins. Applying the method to multiple sequence alignments of homologous proteins increases the prediction accuracy significantly to 71.3% with corresponding Matthew's correlation coefficients C alpha = 0.59, C beta = 0.52, and Cc = 0.50. More than 72% of the residues in the database are predicted with an accuracy of 80%. It is shown that the network outputs can be interpreted as estimated probabilities of correct prediction, and, therefore, these numbers indicate which residues are predicted with high confidence."
            },
            "slug": "Improving-prediction-of-protein-secondary-structure-Riis-Krogh",
            "title": {
                "fragments": [],
                "text": "Improving prediction of protein secondary structure using structured neural networks and multiple sequence alignments."
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that the network outputs can be interpreted as estimated probabilities of correct prediction, and, therefore, these numbers indicate which residues are predicted with high confidence."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of computational biology : a journal of computational molecular cell biology"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49967661"
                        ],
                        "name": "B. Rost",
                        "slug": "B.-Rost",
                        "structuredName": {
                            "firstName": "Burkhard",
                            "lastName": "Rost",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Rost"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144882390"
                        ],
                        "name": "C. Sander",
                        "slug": "C.-Sander",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Sander",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sander"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 150
                            }
                        ],
                        "text": "Building upon the work of Qian and Sejnowski (1988), for a long time the best SS prediction performance has been achieved by the PHD scheme (Rost and Sander, 1993, 1994)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 111
                            }
                        ],
                        "text": "Moreover, different predictors can be obtained using profiles, or multiple alignments, in input mode (Rost and Sander, 1994), or in output mode (Riis and Krogh, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 143
                            }
                        ],
                        "text": "In particular, many different feedforward neural network (NN) architectures have been applied to this task (Qian and Sejnowski, 1988; Rost and Sander, 1994; Riis and Krogh, 1996)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 109
                            }
                        ],
                        "text": "This is an improvement over standard NNs with input window sizes ranging from 11 to 17 amino acids (Rost and Sander, 1994; Riis and Krogh, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 143
                            }
                        ],
                        "text": "In spite of a considerable amount of architectural design, the final performance with multiple alignments is practically identical to Rost and Sander (1994), with an overall accuracy of Q3 = 71.3%, and correlations C\u03b1 = 0.59, C\u03b2 = 0.50 and C\u03b3 = 0.41."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15203189,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "3247ca84941424412f98e926398dd36472c53b27",
            "isKey": true,
            "numCitedBy": 1466,
            "numCiting": 149,
            "paperAbstract": {
                "fragments": [],
                "text": "Using evolutionary information contained in multiple sequence alignments as input to neural networks, secondary structure can be predicted at significantly increased accuracy. Here, we extend our previous three\u2010level system of neural networks by using additional input information derived from multiple alignments. Using a position\u2010specific conservation weight as part of the input increases performance. Using the number of insertions and deletions reduces the tendency for overprediction and increases overall accuracy. Addition of the global amino acid content yields a further improvement, mainly in predicting structural class. The final network system has a sustained overall accuracy of 71.6% in a multiple cross\u2010validation test on 126 unique protein chains. A test on a new set of 124 recently solved protein structures that have no significant sequence similarity to the learning set confirms the high level of accuracy. The average cross\u2010validated accuracy for all 250 sequence\u2010unique chains is above 72%. Using various data sets, the method is compared to alternative prediction methods, some of which also use multiple alignments: the performance advantage of the network system is at least 6 percentage points in three\u2010state accuracy. In addition, the network estimates secondary structure content from multiple sequence alignments about as well as circular dichroism spectroscopy on a single protein and classifies 75% of the 250 proteins correctly into one of four protein structural classes. Of particular practical importance is the definition of a position\u2010specific reliability index. For 40% of all residues the method has a sustained three\u2010state accuracy of 88%, as high as the overall average for homology modelling. A further strength of the method is greatly increased accuracy in predicting the placement of secondary structure segments. \u00a9 1994 Wiley\u2010Liss, Inc."
            },
            "slug": "Combining-evolutionary-information-and-neural-to-Rost-Sander",
            "title": {
                "fragments": [],
                "text": "Combining evolutionary information and neural networks to predict protein secondary structure"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work extends the previous three\u2010level system of neural networks by using additional input information derived from multiple alignments using a position\u2010specific conservation weight as part of the input to increase performance and greatly increased accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "Proteins"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144902513"
                        ],
                        "name": "P. Baldi",
                        "slug": "P.-Baldi",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Baldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Baldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8169197"
                        ],
                        "name": "S. Brunak",
                        "slug": "S.-Brunak",
                        "structuredName": {
                            "firstName": "S\u00f8ren",
                            "lastName": "Brunak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Brunak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688235"
                        ],
                        "name": "P. Frasconi",
                        "slug": "P.-Frasconi",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Frasconi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Frasconi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2028880"
                        ],
                        "name": "G. Pollastri",
                        "slug": "G.-Pollastri",
                        "structuredName": {
                            "firstName": "Gianluca",
                            "lastName": "Pollastri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Pollastri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2540925"
                        ],
                        "name": "G. Soda",
                        "slug": "G.-Soda",
                        "structuredName": {
                            "firstName": "Giovanni",
                            "lastName": "Soda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Soda"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14431872,
            "fieldsOfStudy": [
                "Biology",
                "Computer Science"
            ],
            "id": "5a0bc896955dbe1fd2db321a754b2895d47355fc",
            "isKey": false,
            "numCitedBy": 70,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": "In this chapter, we have proposed two novel architectures for dealing with sequence learning problems in which data is not obtained from physical measurements over time. The new architectures remove the causality assumption that characterize current connectionist approaches to learning sequential translations. Using bidirectional recurrent neural networks (BRNNs) on the protein secondary structure prediction task appears to be very promising. Our performance is very close to the best existing systems although our usage of profiles is not as sophisticated. One improvement of our prediction system could be obtained by using profiles from the TrEMBL database."
            },
            "slug": "Bidirectional-Dynamics-for-Protein-Secondary-Baldi-Brunak",
            "title": {
                "fragments": [],
                "text": "Bidirectional Dynamics for Protein Secondary Structure Prediction"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "This chapter proposes two novel architectures for dealing with sequence learning problems in which data is not obtained from physical measurements over time, and using bidirectional recurrent neural networks on the protein secondary structure prediction task appears to be very promising."
            },
            "venue": {
                "fragments": [],
                "text": "Sequence Learning"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50394648"
                        ],
                        "name": "N. Qian",
                        "slug": "N.-Qian",
                        "structuredName": {
                            "firstName": "Ning",
                            "lastName": "Qian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Qian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 26
                            }
                        ],
                        "text": "Building upon the work of Qian and Sejnowski (1988), for a long time the best SS prediction performance has been achieved by the PHD scheme (Rost and Sander, 1993, 1994)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 108
                            }
                        ],
                        "text": "In particular, many different feedforward neural network (NN) architectures have been applied to this task (Qian and Sejnowski, 1988; Rost and Sander, 1994; Riis and Krogh, 1996)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 158
                            }
                        ],
                        "text": "Thus we obtained a data set consisting of 464 distinct protein chains, corresponding to 123 752 amino acids, roughly 10 times more than what was available in Qian and Sejnowski (1988)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 32
                            }
                        ],
                        "text": "The influential early work of Qian and Sejnowski was based on a fully connected NN, with a local input window of typical length 13 amino acids with orthogonal encoding, and a single hidden layer."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15403132,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "c94c156d00e0550a89a4af7bffd1d0c562320c76",
            "isKey": true,
            "numCitedBy": 1260,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Predicting-the-secondary-structure-of-globular-Qian-Sejnowski",
            "title": {
                "fragments": [],
                "text": "Predicting the secondary structure of globular proteins using neural network models."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of molecular biology"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39581622"
                        ],
                        "name": "James A. Cuff",
                        "slug": "James-A.-Cuff",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Cuff",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James A. Cuff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764306"
                        ],
                        "name": "G. Barton",
                        "slug": "G.-Barton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Barton",
                            "middleNames": [
                                "John"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Barton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 91
                            }
                        ],
                        "text": "More recently, Cuff and Barton (1999) have compared and combined the main existing predictors."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 225,
                                "start": 207
                            }
                        ],
                        "text": "The improvements seem to result in part from the use of PSI-BLAST generated profiles, although this is somewhat controversial (Cuff and Barton, 1999) and not directly reproducible since the filters used to process the raw\nprofiles are not described in sufficient detail in Jones (1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The work of S.B. is supported by a grant from the Danish National Research Foundation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6016474,
            "fieldsOfStudy": [
                "Biology",
                "Computer Science"
            ],
            "id": "a8946a1a1b666edb4fc1b1b4d69a59b2c80015c5",
            "isKey": false,
            "numCitedBy": 657,
            "numCiting": 137,
            "paperAbstract": {
                "fragments": [],
                "text": "A new dataset of 396 protein domains is developed and used to evaluate the performance of the protein secondary structure prediction algorithms DSC, PHD, NNSSP, and PREDATOR. The maximum theoretical Q3 accuracy for combination of these methods is shown to be 78%. A simple consensus prediction on the 396 domains, with automatically generated multiple sequence alignments gives an average Q3 prediction accuracy of 72.9%. This is a 1% improvement over PHD, which was the best single method evaluated. Segment Overlap Accuracy (SOV) is 75.4% for the consensus method on the 396\u2010protein set. The secondary structure definition method DSSP defines 8 states, but these are reduced by most authors to 3 for prediction. Application of the different published 8\u2010 to 3\u2010state reduction methods shows variation of over 3% on apparent prediction accuracy. This suggests that care should be taken to compare methods by the same reduction method. Two new sequence datasets (CB513 and CB251) are derived which are suitable for cross\u2010validation of secondary structure prediction methods without artifacts due to internal homology. A fully automatic World Wide Web service that predicts protein secondary structure by a combination of methods is available via http://barton.ebi.ac.uk/. Proteins 1999;34:508\u2013519. \u00a9 1999 Wiley\u2010Liss, Inc."
            },
            "slug": "Evaluation-and-improvement-of-multiple-sequence-for-Cuff-Barton",
            "title": {
                "fragments": [],
                "text": "Evaluation and improvement of multiple sequence methods for protein secondary structure prediction"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "Two new sequence datasets are derived which are suitable for cross\u2010validation of secondary structure prediction methods without artifacts due to internal homology and application of the different published 8\u2010 to 3\u2010state reduction methods shows variation of over 3% on apparent prediction accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "Proteins"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107601323"
                        ],
                        "name": "D. T. Jones",
                        "slug": "D.-T.-Jones",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Jones",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. T. Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The improvements seem to result in part from the use of PSI-BLAST generated profiles, although this is somewhat controversial (Cuff and Barton, 1999) and not directly reproducible since the filters used to process the raw profiles are not described in sufficient detail in  Jones (1999) ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "At the last 1998 CASP3 competition, the best results were obtained by  Jones (1999) , using a relatively simple but large NN architecture."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 70
                            }
                        ],
                        "text": "At the last 1998 CASP3 competition, the best results were obtained by Jones (1999), using a relatively simple but large NN architecture."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 285,
                                "start": 273
                            }
                        ],
                        "text": "The improvements seem to result in part from the use of PSI-BLAST generated profiles, although this is somewhat controversial (Cuff and Barton, 1999) and not directly reproducible since the filters used to process the raw\nprofiles are not described in sufficient detail in Jones (1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15506630,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b8131893d6b2f1cb8f0c60b559c146d1da05d77d",
            "isKey": true,
            "numCitedBy": 5272,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "A two-stage neural network has been used to predict protein secondary structure based on the position specific scoring matrices generated by PSI-BLAST. Despite the simplicity and convenience of the approach used, the results are found to be superior to those produced by other methods, including the popular PHD method according to our own benchmarking results and the results from the recent Critical Assessment of Techniques for Protein Structure Prediction experiment (CASP3), where the method was evaluated by stringent blind testing. Using a new testing set based on a set of 187 unique folds, and three-way cross-validation based on structural similarity criteria rather than sequence similarity criteria used previously (no similar folds were present in both the testing and training sets) the method presented here (PSIPRED) achieved an average Q3 score of between 76.5% to 78.3% depending on the precise definition of observed secondary structure used, which is the highest published score for any method to date. Given the success of the method in CASP3, it is reasonable to be confident that the evaluation presented here gives a fair indication of the performance of the method in general."
            },
            "slug": "Protein-secondary-structure-prediction-based-on-Jones",
            "title": {
                "fragments": [],
                "text": "Protein secondary structure prediction based on position-specific scoring matrices."
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A two-stage neural network has been used to predict protein secondary structure based on the position specific scoring matrices generated by PSI-BLAST and achieved an average Q3 score of between 76.5% to 78.3% depending on the precise definition of observed secondary structure used, which is the highest published score for any method to date."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of molecular biology"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145467231"
                        ],
                        "name": "O. Lund",
                        "slug": "O.-Lund",
                        "structuredName": {
                            "firstName": "Ole",
                            "lastName": "Lund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Lund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4229781"
                        ],
                        "name": "K. Frimand",
                        "slug": "K.-Frimand",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Frimand",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Frimand"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1774524"
                        ],
                        "name": "J. Gorodkin",
                        "slug": "J.-Gorodkin",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Gorodkin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Gorodkin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145819543"
                        ],
                        "name": "H. Bohr",
                        "slug": "H.-Bohr",
                        "structuredName": {
                            "firstName": "Henrik",
                            "lastName": "Bohr",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bohr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144145286"
                        ],
                        "name": "J. Bohr",
                        "slug": "J.-Bohr",
                        "structuredName": {
                            "firstName": "Jakob",
                            "lastName": "Bohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bohr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107831487"
                        ],
                        "name": "J. Hansen",
                        "slug": "J.-Hansen",
                        "structuredName": {
                            "firstName": "John-E.",
                            "lastName": "Hansen",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hansen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8169197"
                        ],
                        "name": "S. Brunak",
                        "slug": "S.-Brunak",
                        "structuredName": {
                            "firstName": "S\u00f8ren",
                            "lastName": "Brunak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Brunak"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 3
                            }
                        ],
                        "text": "In Lund et al. (1997) the similarity threshold, dividing sequences with structural homology from those without, had the form I < 290\u221a\nL , where L is the length of the\nalignment."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 23
                            }
                        ],
                        "text": "The setup developed in Lund et al. (1997) has also been used to build profiles for sequences not present in the HSSP database."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15809496,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6f73b75994e3ce860fe23a6497b764c4f3676aed",
            "isKey": false,
            "numCitedBy": 154,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "We predict interatomic Calpha distances by two independent data driven methods. The first method uses statistically derived probability distributions of the pairwise distance between two amino acids, whilst the latter method consists of a neural network prediction approach equipped with windows taking the context of the two residues into account. These two methods are used to predict whether distances in independent test sets were above or below given thresholds. We investigate which distance thresholds produce the most information-rich constraints and, in turn, the optimal performance of the two methods. The predictions are based on a data set derived using a new threshold which defines when sequence similarity implies structural similarity. We show that distances in proteins are predicted more accurately by neural networks than by probability density functions. We show that the accuracy of the predictions can be further increased by using sequence profiles. A threading method based on the predicted distances is presented. A homepage with software, predictions and data related to this paper is available at http://www.cbs.dtu.dk/services/CPHmodels/."
            },
            "slug": "Protein-distance-constraints-predicted-by-neural-Lund-Frimand",
            "title": {
                "fragments": [],
                "text": "Protein distance constraints predicted by neural networks and probability density functions."
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is shown that distances in proteins are predicted more accurately by neural networks than by probability density functions, and that the accuracy of the predictions can be further increased by using sequence profiles."
            },
            "venue": {
                "fragments": [],
                "text": "Protein engineering"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1899612"
                        ],
                        "name": "F. Richards",
                        "slug": "F.-Richards",
                        "structuredName": {
                            "firstName": "Frederic",
                            "lastName": "Richards",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Richards"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5195057"
                        ],
                        "name": "C. Kundrot",
                        "slug": "C.-Kundrot",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Kundrot",
                            "middleNames": [
                                "E"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Kundrot"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 134
                            }
                        ],
                        "text": "DEFINE uses difference distance matrices for evaluating the match of interatomic distances in the protein to those from idealized SS (Richards and Kundrot, 1988)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 29126855,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "eed43edd4483b6eaa8fac1454d8cafa22241a744",
            "isKey": false,
            "numCitedBy": 393,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "A computer program is described that produces a description of the secondary structure and supersecondary structure of a polypeptide chain using the list of alpha carbon coordinates as input. Restricting the term \u201csecondary structure\u201d to the conformation of contiguous segments of the chain, the program determines the initial and final residues in helices, extended strands, sharp turns, and omega loops. This is accomplished through the use of difference distance matrices. The distances in idealized models of the segments are compared with the actual structure, and the differences are evaluated for agreement within preset limits. The program assigns 90\u201395% of the residues in most proteins to at least one type of secondary element"
            },
            "slug": "Identification-of-structural-motifs-from-protein-*-Richards-Kundrot",
            "title": {
                "fragments": [],
                "text": "Identification of structural motifs from protein coordinate data: Secondary structure and first\u2010level supersecondary structure *"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A computer program is described that produces a description of the secondary structure and supersecondary structure of a polypeptide chain using the list of alpha carbon coordinates as input and assigns 90\u201395% of the residues in most proteins to at least one type of secondary element."
            },
            "venue": {
                "fragments": [],
                "text": "Proteins"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755687"
                        ],
                        "name": "A. Bairoch",
                        "slug": "A.-Bairoch",
                        "structuredName": {
                            "firstName": "Amos",
                            "lastName": "Bairoch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bairoch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722884"
                        ],
                        "name": "R. Apweiler",
                        "slug": "R.-Apweiler",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "Apweiler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Apweiler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The work of S.B. is supported by a grant from the Danish National Research Foundation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 205225875,
            "fieldsOfStudy": [
                "Biology",
                "Computer Science"
            ],
            "id": "58a93e9cd60ce331606d31ebed62599a2b7db805",
            "isKey": false,
            "numCitedBy": 2400,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "SWISS-PROT is a curated protein sequence database which strives to provide a high level of annotation (such as the description of the function of a protein, its domains structure, post-translational modifications, variants, etc.), a minimal level of redundancy and high level of integration with other databases. Recent developments of the database include format and content enhancements, cross-references to additional databases, new documentation files and improvements to TrEMBL, a computer-annotated supplement to SWISS-PROT. TrEMBL consists of entries in SWISS-PROT-like format derived from the translation of all coding sequences (CDSs) in the EMBL Nucleotide Sequence Database, except the CDSs already included in SWISS-PROT. We also describe the Human Proteomics Initiative (HPI), a major project to annotate all known human sequences according to the quality standards of SWISS-PROT. SWISS-PROT is available at: http://www.expasy.ch/sprot/ and http://www.ebi.ac.uk/swissprot/"
            },
            "slug": "The-SWISS-PROT-protein-sequence-database-and-its-in-Bairoch-Apweiler",
            "title": {
                "fragments": [],
                "text": "The SWISS-PROT protein sequence database and its supplement TrEMBL in 2000"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The Human Proteomics Initiative (HPI), a major project to annotate all known human sequences according to the quality standards of SWISS-PROT, is described."
            },
            "venue": {
                "fragments": [],
                "text": "Nucleic Acids Res."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755687"
                        ],
                        "name": "A. Bairoch",
                        "slug": "A.-Bairoch",
                        "structuredName": {
                            "firstName": "Amos",
                            "lastName": "Bairoch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bairoch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722884"
                        ],
                        "name": "R. Apweiler",
                        "slug": "R.-Apweiler",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "Apweiler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Apweiler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 252,
                                "start": 226
                            }
                        ],
                        "text": "Still, we believe that this result confirms the effectiveness of the proposed model, especially in consideration of the fact that Jones\u2019 system builds upon more recent profiles based on iterative search in the TrEMBL database (Bairoch and Apweiler, 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7217750,
            "fieldsOfStudy": [
                "Biology",
                "Computer Science"
            ],
            "id": "0c1948a4b33c51309204e3bc1fde9d9de768ade5",
            "isKey": false,
            "numCitedBy": 1138,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "SWISS-PROT is a curated protein sequence database which strives to provide a high level of annotation (such as the description of the function of a protein, its domain structure, post-translational modifications, variants, etc.), a minimal level of redundancy and high level of integration with other databases. Recent developments of the database include: cross-references to additional databases; a variety of new documentation files and improvements to TrEMBL, a computer annotated supplement to SWISS-PROT. TrEMBL consists of entries in SWISS-PROT-like format derived from the translation of all coding sequences (CDS) in the EMBL nucleotide sequence database, except the CDS already included in SWISS-PROT. The URLs for SWISS-PROT on the WWW are: http://www.expasy.ch/sprot and http://www. ebi.ac.uk/sprot"
            },
            "slug": "The-SWISS-PROT-protein-sequence-data-bank-and-its-Bairoch-Apweiler",
            "title": {
                "fragments": [],
                "text": "The SWISS-PROT protein sequence data bank and its supplement TrEMBL in 1999"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Current developments of the database include: cross-references to additional databases; a variety of new documentation files and improvements to TrEMBL, a computer annotated supplement to SWISS-PROT."
            },
            "venue": {
                "fragments": [],
                "text": "Nucleic Acids Res."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144902513"
                        ],
                        "name": "P. Baldi",
                        "slug": "P.-Baldi",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Baldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Baldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2952703"
                        ],
                        "name": "Y. Chauvin",
                        "slug": "Y.-Chauvin",
                        "structuredName": {
                            "firstName": "Yves",
                            "lastName": "Chauvin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Chauvin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17404701,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0bdedf988d9a1de26d949daee0c0ed768510e3b7",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a hybrid modeling approach where the parameters of a model are calculated and modulated by another model, typically a neural network (NN), to avoid both overfitting and underfitting. We develop the approach for the case of Hidden Markov Models (HMMs), by deriving a class of hybrid HMM/NN architectures. These architectures can be trained with unified algorithms that blend HMM dynamic programming with NN backpropagation. In the case of complex data, mixtures of HMMs or modulated HMMs must be used. NNs can then be applied both to the parameters of each single HMM, and to the switching or modulation of the models, as a function of input or context. Hybrid HMM/NN architectures provide a flexible NN parameterization for the control of model structure and complexity. At the same time, they can capture distributions that, in practice, are inaccessible to single HMMs. The HMM/NN hybrid approach is tested, in its simplest form, by constructing a model of the immunoglobulin protein family. A hybrid model is trained, and a multiple alignment derived, with less than a fourth of the number of parameters used with previous single HMMs."
            },
            "slug": "Hybrid-Modeling,-HMM/NN-Architectures,-and-Protein-Baldi-Chauvin",
            "title": {
                "fragments": [],
                "text": "Hybrid Modeling, HMM/NN Architectures, and Protein Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The HMM/NN hybrid approach is tested, in its simplest form, by constructing a model of the immunoglobulin protein family, with less than a fourth of the number of parameters used with previous single HMMs."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755687"
                        ],
                        "name": "A. Bairoch",
                        "slug": "A.-Bairoch",
                        "structuredName": {
                            "firstName": "Amos",
                            "lastName": "Bairoch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bairoch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722884"
                        ],
                        "name": "R. Apweiler",
                        "slug": "R.-Apweiler",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "Apweiler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Apweiler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 252,
                                "start": 226
                            }
                        ],
                        "text": "Still, we believe that this result confirms the effectiveness of the proposed model, especially in consideration of the fact that Jones\u2019 system builds upon more recent profiles based on iterative search in the TrEMBL database (Bairoch and Apweiler, 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 513,
                                "start": 227
                            }
                        ],
                        "text": "Still, we believe that this result confirms the effectiveness of the proposed model, especially in consideration of the fact that Jones\u2019 system builds upon more recent profiles based on iterative search in the TrEMBL database (Bairoch and Apweiler, 1999). These profiles contain many more sequences than our training profiles which are based on the older HSSP profile approach, leaving room for further improvements of our system. To further compare our system with other predictors, as in Cuff and Barton (1999), we also trained an ensemble of"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 32649061,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "b75c9516971fc73866ab6750215b6b1cf6bf6119",
            "isKey": false,
            "numCitedBy": 1835,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "SWISS-PROT is a curated protein sequence database which strives to provide a high level of annotations (such as the description of the function of a protein, structure of its domains, post-translational modifications, variants, etc.), a minimal level of redundancy and high level of integration with other databases. Recent developments of the database include: an increase in the number and scope of model organisms; cross-references to two additional databases; a variety of new documentation files and the creation of TrEMBL, a computer annotated supplement to SWISS-PROT. This supplement consists of entries in SWISS-PROT-like format derived from the translation of all coding sequences (CDS) in the EMBL nucleotide sequence database, except the CDS already included in SWISS-PROT."
            },
            "slug": "The-SWISS-PROT-protein-sequence-data-bank-and-its-Bairoch-Apweiler",
            "title": {
                "fragments": [],
                "text": "The SWISS-PROT protein sequence data bank and its supplement TrEMBL"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This supplement consists of entries in SWiss-PROT-like format derived from the translation of all coding sequences in the EMBL nucleotide sequence database, except the CDS already included in SWISS- PROT."
            },
            "venue": {
                "fragments": [],
                "text": "Nucleic Acids Res."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2598638"
                        ],
                        "name": "U. Hobohm",
                        "slug": "U.-Hobohm",
                        "structuredName": {
                            "firstName": "Uwe",
                            "lastName": "Hobohm",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Hobohm"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059653099"
                        ],
                        "name": "M. Scharf",
                        "slug": "M.-Scharf",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Scharf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Scharf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069507994"
                        ],
                        "name": "R. Schneider",
                        "slug": "R.-Schneider",
                        "structuredName": {
                            "firstName": "Reinhard",
                            "lastName": "Schneider",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schneider"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144882390"
                        ],
                        "name": "C. Sander",
                        "slug": "C.-Sander",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Sander",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sander"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 138
                            }
                        ],
                        "text": "From the remaining chains, a representative subset with low pairwise sequence similarities was selected by running the algorithm no. 1 of Hobohm et al. (1992), using the local alignment procedure search (rigorous Smith\u2013 Waterman algorithm) (Myers and Miller, 1988; Pearson, 1990) using the pam120\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2558294,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b67b4991dffe2b367cd9ce5087e11fd5ee43abc5",
            "isKey": false,
            "numCitedBy": 778,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "The Protein Data Bank currently contains about 600 data sets of three\u2010dimensional protein coordinates determined by X\u2010ray crystallography or NMR. There is considerable redundancy in the data base, as many protein pairs are identical or very similar in sequence. However, statistical analyses of protein sequence\u2010structure relations require nonredundant data. We have developed two algorithms to extract from the data base representative sets of protein chains with maximum coverage and minimum redundancy. The first algorithm focuses on optimizing a particular property of the selected proteins and works by successive selection of proteins from an ordered list and exclusion of all neighbors of each selected protein. The other algorithm aims at maximizing the size of the selected set and works by successive thinning out of clusters of similar proteins. Both algorithms are generally applicable to other data bases in which criteria of similarity can be defined and relate to problems in graph theory. The largest nonredundant set extracted from the current release of the Protein Data Bank has 155 protein chains. In this set, no two proteins have sequence similarity higher than a certain cutoff (30% identical residues for aligned subsequences longer than 80 residues), yet all structurally unique protein families are represented. Periodically updated lists of representative data sets are available by electronic mail from the file server \u201cnetserv@embl\u2010heidelberg.de.\u201d The selection may be useful in statistical approaches to protein folding as well as in the analysis and documentation of the known spectrum of three\u2010dimensional protein structures."
            },
            "slug": "Selection-of-representative-protein-data-sets-Hobohm-Scharf",
            "title": {
                "fragments": [],
                "text": "Selection of representative protein data sets"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Two algorithms are developed to extract from the data base representative sets of protein chains with maximum coverage and minimum redundancy and are generally applicable to other data bases in which criteria of similarity can be defined and relate to problems in graph theory."
            },
            "venue": {
                "fragments": [],
                "text": "Protein science : a publication of the Protein Society"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6252802"
                        ],
                        "name": "W. Kabsch",
                        "slug": "W.-Kabsch",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Kabsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Kabsch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144766425"
                        ],
                        "name": "C. Sander",
                        "slug": "C.-Sander",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Sander",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sander"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 154
                            }
                        ],
                        "text": "The assignment of the SS categories to the experimentally determined 3D structure is nontrivial and is usually performed by the widely used DSSP program (Kabsch and Sander, 1983)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 122
                            }
                        ],
                        "text": "\u2022 The program DSSP could not produce an output, since we wanted to use the DSSP assignment of protein secondary structure (Kabsch and Sander, 1983)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 29185760,
            "fieldsOfStudy": [
                "Chemistry"
            ],
            "id": "225ba9111ed4b4e0f5bbe12c69e7235e353ff3ff",
            "isKey": false,
            "numCitedBy": 13105,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "For a successful analysis of the relation between amino acid sequence and protein structure, an unambiguous and physically meaningful definition of secondary structure is essential. We have developed a set of simple and physically motivated criteria for secondary structure, programmed as a pattern\u2010recognition process of hydrogen\u2010bonded and geometrical features extracted from x\u2010ray coordinates. Cooperative secondary structure is recognized as repeats of the elementary hydrogen\u2010bonding patterns \u201cturn\u201d and \u201cbridge.\u201d Repeating turns are \u201chelices,\u201d repeating bridges are \u201cladders,\u201d connected ladders are \u201csheets.\u201d Geometric structure is defined in terms of the concepts torsion and curvature of differential geometry. Local chain \u201cchirality\u201d is the torsional handedness of four consecutive C\u03b1 positions and is positive for right\u2010handed helices and negative for ideal twisted \u03b2\u2010sheets. Curved pieces are defined as \u201cbends.\u201d Solvent \u201cexposure\u201d is given as the number of water molecules in possible contact with a residue. The end result is a compilation of the primary structure, including SS bonds, secondary structure, and solvent exposure of 62 different globular proteins. The presentation is in linear form: strip graphs for an overall view and strip tables for the details of each of 10.925 residues. The dictionary is also available in computer\u2010readable form for protein structure prediction work."
            },
            "slug": "Dictionary-of-protein-secondary-structure:-Pattern-Kabsch-Sander",
            "title": {
                "fragments": [],
                "text": "Dictionary of protein secondary structure: Pattern recognition of hydrogen\u2010bonded and geometrical features"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A set of simple and physically motivated criteria for secondary structure, programmed as a pattern\u2010recognition process of hydrogen\u2010bonded and geometrical features extracted from x\u2010ray coordinates is developed."
            },
            "venue": {
                "fragments": [],
                "text": "Biopolymers"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144704594"
                        ],
                        "name": "Reinhard Schneider",
                        "slug": "Reinhard-Schneider",
                        "structuredName": {
                            "firstName": "Reinhard",
                            "lastName": "Schneider",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Reinhard Schneider"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7147197"
                        ],
                        "name": "A. Daruvar",
                        "slug": "A.-Daruvar",
                        "structuredName": {
                            "firstName": "Antoine",
                            "lastName": "Daruvar",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Daruvar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144882390"
                        ],
                        "name": "C. Sander",
                        "slug": "C.-Sander",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Sander",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sander"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 86
                            }
                        ],
                        "text": "In all but two experiments (see below), profiles were obtained from the HSSP database (Schneider et al., 1997) available at http://www."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 87
                            }
                        ],
                        "text": "In all but two experiments (see below), profiles were obtained from the HSSP database (Schneider et al., 1997) available at http://www.sander. embl-heidelberg.de/hssp/."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12823452,
            "fieldsOfStudy": [
                "Biology",
                "Computer Science"
            ],
            "id": "939645dfc3a08e7e352ddb190aefd9cf8fcdb2b0",
            "isKey": false,
            "numCitedBy": 160,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "HSSP is a derived database merging structural three dimensional (3-D) and sequence one dimensional(1-D) information. For each protein of known 3-D structure from the Protein Data Bank (PDB), the database has a multiple sequence alignment of all available homologues and a sequence profile characteristic of the family. The list of homologues is the result of a database search in Swissprot using a position-weighted dynamic programming method for sequence profile alignment (MaxHom). The database is updated frequently. The listed homologues are very likely to have the same 3-D structure as the PDB protein to which they have been aligned. As a result, the database is not only a database of aligned sequence families, but also a database of implied secondary and tertiary structures covering 27% of all Swissprot-stored sequences."
            },
            "slug": "The-HSSP-database-of-protein-structure-sequence-Schneider-Daruvar",
            "title": {
                "fragments": [],
                "text": "The HSSP database of protein structure-sequence alignments"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "The HSSP is a derived database merging structural three dimensional (3-D) and sequence one dimensional (1- D) information and a database of implied secondary and tertiary structures covering 27% of all Swissprot-stored sequences."
            },
            "venue": {
                "fragments": [],
                "text": "Nucleic Acids Res."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50486107"
                        ],
                        "name": "W. Pearson",
                        "slug": "W.-Pearson",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Pearson",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Pearson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 221
                            }
                        ],
                        "text": "\u2026subset with low pairwise sequence similarities was selected by running the algorithm no. 1 of Hobohm et al. (1992), using the local alignment procedure search (rigorous Smith\u2013 Waterman algorithm) (Myers and Miller, 1988; Pearson, 1990) using the pam120 matrix, with gap penalties \u221212, \u22124."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 24505202,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "f36e1b178f4503b4339944d41729e072bdc79460",
            "isKey": false,
            "numCitedBy": 2025,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Rapid-and-sensitive-sequence-comparison-with-FASTP-Pearson",
            "title": {
                "fragments": [],
                "text": "Rapid and sensitive sequence comparison with FASTP and FASTA."
            },
            "venue": {
                "fragments": [],
                "text": "Methods in enzymology"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688235"
                        ],
                        "name": "P. Frasconi",
                        "slug": "P.-Frasconi",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Frasconi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Frasconi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 271
                            }
                        ],
                        "text": "\u2026architectures that have been investigated for grammatical inference are recurrent neural networks (RNN), with both first- (Cleeremans, 1993) and second-order (Giles et al., 1992) connections, as well as input\u2013output hidden Markov models (IOHMM) (Baldi and Chauvin, 1996; Bengio and Frasconi, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14298205,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "25bdc473f8377c1200adbd691fbb3cc77fa7bf70",
            "isKey": false,
            "numCitedBy": 338,
            "numCiting": 96,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider problems of sequence processing and propose a solution based on a discrete-state model in order to represent past context. We introduce a recurrent connectionist architecture having a modular structure that associates a subnetwork to each state. The model has a statistical interpretation we call input-output hidden Markov model (IOHMM). It can be trained by the estimation-maximization (EM) or generalized EM (GEM) algorithms, considering state trajectories as missing data, which decouples temporal credit assignment and actual parameter estimation. The model presents similarities to hidden Markov models (HMMs), but allows us to map input sequences to output sequences, using the same processing style as recurrent neural networks. IOHMMs are trained using a more discriminant learning paradigm than HMMs, while potentially taking advantage of the EM algorithm. We demonstrate that IOHMMs are well suited for solving grammatical inference problems on a benchmark problem. Experimental results are presented for the seven Tomita grammars, showing that these adaptive models can attain excellent generalization."
            },
            "slug": "Input-output-HMMs-for-sequence-processing-Bengio-Frasconi",
            "title": {
                "fragments": [],
                "text": "Input-output HMMs for sequence processing"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is demonstrated that IOHMMs are well suited for solving grammatical inference problems on a benchmark problem and able to map input sequences to output sequences, using the same processing style as recurrent neural networks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115356552"
                        ],
                        "name": "Tsungnan Lin",
                        "slug": "Tsungnan-Lin",
                        "structuredName": {
                            "firstName": "Tsungnan",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tsungnan Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35216199"
                        ],
                        "name": "B. Horne",
                        "slug": "B.-Horne",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Horne",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Horne"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4023505"
                        ],
                        "name": "P. Ti\u0148o",
                        "slug": "P.-Ti\u0148o",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Ti\u0148o",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Ti\u0148o"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157784"
                        ],
                        "name": "C. Lee Giles",
                        "slug": "C.-Lee-Giles",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Giles",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lee Giles"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 47
                            }
                        ],
                        "text": "Hence, the best BRNN outperforms our best feedforward network, even when additional architectural design is included."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 72
                            }
                        ],
                        "text": "To limit this problem, we propose a remedy motivated by recent studies (Lin et al., 1996) suggesting that the vanishing gradients problem can be mitigated by the use of an explicit delay line applied to the output, which provides shorter paths for the effective propagation of error signals."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6638216,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6e91c9e7e8f8a577a98ecfcfa998212a683195a",
            "isKey": false,
            "numCitedBy": 630,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "It has previously been shown that gradient-descent learning algorithms for recurrent neural networks can perform poorly on tasks that involve long-term dependencies, i.e. those problems for which the desired output depends on inputs presented at times far in the past. We show that the long-term dependencies problem is lessened for a class of architectures called nonlinear autoregressive models with exogenous (NARX) recurrent neural networks, which have powerful representational capabilities. We have previously reported that gradient descent learning can be more effective in NARX networks than in recurrent neural network architectures that have \"hidden states\" on problems including grammatical inference and nonlinear system identification. Typically, the network converges much faster and generalizes better than other networks. The results in this paper are consistent with this phenomenon. We present some experimental results which show that NARX networks can often retain information for two to three times as long as conventional recurrent neural networks. We show that although NARX networks do not circumvent the problem of long-term dependencies, they can greatly improve performance on long-term dependency problems. We also describe in detail some of the assumptions regarding what it means to latch information robustly and suggest possible ways to loosen these assumptions."
            },
            "slug": "Learning-long-term-dependencies-in-NARX-recurrent-Lin-Horne",
            "title": {
                "fragments": [],
                "text": "Learning long-term dependencies in NARX recurrent neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that the long-term dependencies problem is lessened for a class of architectures called nonlinear autoregressive models with exogenous (NARX) recurrent neural networks, which have powerful representational capabilities."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29942829"
                        ],
                        "name": "A. Cleeremans",
                        "slug": "A.-Cleeremans",
                        "structuredName": {
                            "firstName": "Axel",
                            "lastName": "Cleeremans",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Cleeremans"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 146
                            }
                        ],
                        "text": "The main connectionist architectures that have been investigated for grammatical inference are recurrent neural networks (RNN), with both first- (Cleeremans, 1993) and second-order (Giles et al., 1992) connections, as well as input\u2013output hidden Markov models (IOHMM) (Baldi and Chauvin, 1996;\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 192
                            }
                        ],
                        "text": "\u2026architectures that have been investigated for grammatical inference are recurrent neural networks (RNN), with both first- (Cleeremans, 1993) and second-order (Giles et al., 1992) connections, as well as input\u2013output hidden Markov models (IOHMM) (Baldi and Chauvin, 1996; Bengio and Frasconi, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60598298,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c6180dcacbd0a54733a37bae648dcc8b2050c6b2",
            "isKey": false,
            "numCitedBy": 341,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This book explores unintentional learning from an information-processing perspective. What do people learn when they do not know that they are learning? Until recently all of the work in the area of implicit learning focused on empirical questions and methods. In this book, Axel Cleeremans explores unintentional learning from an information-processing perspective. He introduces a theoretical framework that unifies existing data and models on implicit learning, along with a detailed computational model of human performance in sequence-learning situations. The model, based on a simple recurrent network (SRN), is able to predict perfectly the successive elements of sequences generated from finite-state, grammars. Human subjects are shown to exhibit a similar sensitivity to the temporal structure in a series of choice reaction time experiments of increasing complexity; yet their explicit knowledge of the sequence remains limited. Simulation experiments indicate that the SRN model is able to account for these data in great detail. Cleeremans' model is also useful in understanding the effects of a wide range of variables on sequence-learning performance such as attention, the availability of explicit information, or the complexity of the material. Other architectures that process sequential material are considered. These are contrasted with the SRN model, which they sometimes outperform. Considered together, the models show how complex knowledge may emerge through the operation of elementary mechanisms-a key aspect of implicit learning performance."
            },
            "slug": "Mechanisms-of-Implicit-Learning:-Connectionist-of-Cleeremans",
            "title": {
                "fragments": [],
                "text": "Mechanisms of Implicit Learning: Connectionist Models of Sequence Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A theoretical framework that unifies existing data and models on implicit learning, along with a detailed computational model of human performance in sequence-learning situations are introduced, showing how complex knowledge may emerge through the operation of elementary mechanisms-a key aspect of implicit learning performance."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144902513"
                        ],
                        "name": "P. Baldi",
                        "slug": "P.-Baldi",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Baldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Baldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8169197"
                        ],
                        "name": "S. Brunak",
                        "slug": "S.-Brunak",
                        "structuredName": {
                            "firstName": "S\u00f8ren",
                            "lastName": "Brunak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Brunak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2952703"
                        ],
                        "name": "Y. Chauvin",
                        "slug": "Y.-Chauvin",
                        "structuredName": {
                            "firstName": "Yves",
                            "lastName": "Chauvin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Chauvin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3175570"
                        ],
                        "name": "C. A. Andersen",
                        "slug": "C.-A.-Andersen",
                        "structuredName": {
                            "firstName": "Claus",
                            "lastName": "Andersen",
                            "middleNames": [
                                "A.",
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. A. Andersen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145416108"
                        ],
                        "name": "H. Nielsen",
                        "slug": "H.-Nielsen",
                        "structuredName": {
                            "firstName": "Henrik",
                            "lastName": "Nielsen",
                            "middleNames": [
                                "Bj\u00f8rn"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Nielsen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 74
                            }
                        ],
                        "text": "Unless we specify otherwise, Q3 percentages are measured on a per residue basis."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6923178,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "78200101cb94b926b376f38571bffcaf0f9cc50e",
            "isKey": false,
            "numCitedBy": 1862,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We provide a unified overview of methods that currently are widely used to assess the accuracy of prediction algorithms, from raw percentages, quadratic error measures and other distances, and correlation coefficients, and to information theoretic measures such as relative entropy and mutual information. We briefly discuss the advantages and disadvantages of each approach. For classification tasks, we derive new learning algorithms for the design of prediction systems by directly optimising the correlation coefficient. We observe and prove several results relating sensitivity and specificity of optimal systems. While the principles are general, we illustrate the applicability on specific problems such as protein secondary structure and signal peptide prediction."
            },
            "slug": "Assessing-the-accuracy-of-prediction-algorithms-for-Baldi-Brunak",
            "title": {
                "fragments": [],
                "text": "Assessing the accuracy of prediction algorithms for classification: an overview"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "A unified overview of methods that currently are widely used to assess the accuracy of prediction algorithms, from raw percentages, quadratic error measures and other distances, and correlation coefficients, and to information theoretic measures such as relative entropy and mutual information are provided."
            },
            "venue": {
                "fragments": [],
                "text": "Bioinform."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39877031"
                        ],
                        "name": "F. C. Bernstein",
                        "slug": "F.-C.-Bernstein",
                        "structuredName": {
                            "firstName": "Frances",
                            "lastName": "Bernstein",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. C. Bernstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4868668"
                        ],
                        "name": "T. Koetzle",
                        "slug": "T.-Koetzle",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Koetzle",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Koetzle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107433006"
                        ],
                        "name": "G. J. Williams",
                        "slug": "G.-J.-Williams",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. J. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46675042"
                        ],
                        "name": "E. Meyer",
                        "slug": "E.-Meyer",
                        "structuredName": {
                            "firstName": "Edgar",
                            "lastName": "Meyer",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Meyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153584520"
                        ],
                        "name": "M. Brice",
                        "slug": "M.-Brice",
                        "structuredName": {
                            "firstName": "Michael.",
                            "lastName": "Brice",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Brice"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2537391"
                        ],
                        "name": "J. Rodgers",
                        "slug": "J.-Rodgers",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Rodgers",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Rodgers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3328446"
                        ],
                        "name": "O. Kennard",
                        "slug": "O.-Kennard",
                        "structuredName": {
                            "firstName": "Olga",
                            "lastName": "Kennard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Kennard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46857546"
                        ],
                        "name": "T. Shimanouchi",
                        "slug": "T.-Shimanouchi",
                        "structuredName": {
                            "firstName": "Takehiko",
                            "lastName": "Shimanouchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Shimanouchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3195387"
                        ],
                        "name": "M. Tasumi",
                        "slug": "M.-Tasumi",
                        "structuredName": {
                            "firstName": "Mitsuo",
                            "lastName": "Tasumi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Tasumi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 68
                            }
                        ],
                        "text": "The threshold was then used to build a profile for all the relevant PDB entries from the matches found in the SWISS-PROT database."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 106
                            }
                        ],
                        "text": "The first high quality data used in this study was extracted from the Brookhaven Protein Data Bank (PDB) (Bernstein et al., 1977) release 77 and subsequently updated."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 89
                            }
                        ],
                        "text": "In both sets, internal homology is reduced again by Hobohm\u2019s no. 1 algorithm, keeping the PDB sequences with the best resolution."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "PDB chains."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 76
                            }
                        ],
                        "text": "Finally, we also constructed two more data sets, containing all proteins in PDB which are at least 30 amino acids long, produce DSSP output without chain breaks, and have a resolution of at least 2.5 A\u030a."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 46
                            }
                        ],
                        "text": "Another set we used is the EMBL non-redundant PDB subsets that can be accessed by ftp at the site ftp.embl-heidelberg.de. Data details are in the file /pub/ databases/pdb select/README."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 101
                            }
                        ],
                        "text": "Thus, although the model has in principle the capability of storing remote information, such information cannot be learnt effectively."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16929534,
            "fieldsOfStudy": [
                "Chemistry"
            ],
            "id": "d616ab5486d9de477600f48ea7c6127357253bf6",
            "isKey": true,
            "numCitedBy": 2900,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Protein-Data-Bank:-a-computer-based-archival-Bernstein-Koetzle",
            "title": {
                "fragments": [],
                "text": "The Protein Data Bank: a computer-based archival file for macromolecular structures."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of molecular biology"
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39877031"
                        ],
                        "name": "F. C. Bernstein",
                        "slug": "F.-C.-Bernstein",
                        "structuredName": {
                            "firstName": "Frances",
                            "lastName": "Bernstein",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. C. Bernstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4868668"
                        ],
                        "name": "T. Koetzle",
                        "slug": "T.-Koetzle",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Koetzle",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Koetzle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107433006"
                        ],
                        "name": "G. J. Williams",
                        "slug": "G.-J.-Williams",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. J. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46675042"
                        ],
                        "name": "E. Meyer",
                        "slug": "E.-Meyer",
                        "structuredName": {
                            "firstName": "Edgar",
                            "lastName": "Meyer",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Meyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153584520"
                        ],
                        "name": "M. Brice",
                        "slug": "M.-Brice",
                        "structuredName": {
                            "firstName": "Michael.",
                            "lastName": "Brice",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Brice"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2537391"
                        ],
                        "name": "J. Rodgers",
                        "slug": "J.-Rodgers",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Rodgers",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Rodgers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3328446"
                        ],
                        "name": "O. Kennard",
                        "slug": "O.-Kennard",
                        "structuredName": {
                            "firstName": "Olga",
                            "lastName": "Kennard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Kennard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46857546"
                        ],
                        "name": "T. Shimanouchi",
                        "slug": "T.-Shimanouchi",
                        "structuredName": {
                            "firstName": "Takehiko",
                            "lastName": "Shimanouchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Shimanouchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3195387"
                        ],
                        "name": "M. Tasumi",
                        "slug": "M.-Tasumi",
                        "structuredName": {
                            "firstName": "Mitsuo",
                            "lastName": "Tasumi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Tasumi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 40076748,
            "fieldsOfStudy": [
                "Chemistry"
            ],
            "id": "ac8673f2a4947767a898075b35b81297a5eb2fec",
            "isKey": false,
            "numCitedBy": 896,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "The Protein Data Bank is a computer-based archival file for macromolecular structures. The Bank stores in a uniform format atomic co-ordinates and partial bond connectivities, as derived from crystallographic studies. Text included in each data entry gives pertinent information for the structure at hand (e.g. species from which the molecule has been obtained, resolution of diffraction data, literature citations and specifications of secondary structure). In addition to atomic co-ordinates and connectivities, the Protein Data Bank stores structure factors and phases, although these latter data are not placed in any uniform format. Input of data to the Bank and general maintenance functions are carried out at Brookhaven National Laboratory. All data stored in the Bank are available on magnetic tape for public distribution, from Brookhaven (to laboratories in the Americas), Tokyo (Japan), and Cambridge (Europe and worldwide). A master file is maintained at Brookhaven and duplicate copies are stored in Cambridge and Tokyo. In the future, it is hoped to expand the scope of the Protein Data Bank to make available co-ordinates for standard structural types (e.g. alpha-helix, RNA double-stranded helix) and representative computer programs of utility in the study and interpretation of macromolecular structures."
            },
            "slug": "The-Protein-Data-Bank:-a-computer-based-archival-Bernstein-Koetzle",
            "title": {
                "fragments": [],
                "text": "The Protein Data Bank: a computer-based archival file for macromolecular structures."
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "The Protein Data Bank is a computer-based archival file for macromolecular structures that stores in a uniform format atomic co-ordinates and partial bond connectivities, as derived from crystallographic studies."
            },
            "venue": {
                "fragments": [],
                "text": "Archives of biochemistry and biophysics"
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688235"
                        ],
                        "name": "P. Frasconi",
                        "slug": "P.-Frasconi",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Frasconi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Frasconi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145467467"
                        ],
                        "name": "M. Gori",
                        "slug": "M.-Gori",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Gori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749815"
                        ],
                        "name": "A. Sperduti",
                        "slug": "A.-Sperduti",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Sperduti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sperduti"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 168
                            }
                        ],
                        "text": "Because the unrolled network is acyclic, the generalized backpropagation algorithm can be derived as a special case of the backpropagation through structure algorithm (Frasconi et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6197973,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a5eb96540ef53b49eac2246d6b13635fe6e54451",
            "isKey": false,
            "numCitedBy": 467,
            "numCiting": 100,
            "paperAbstract": {
                "fragments": [],
                "text": "A structured organization of information is typically required by symbolic processing. On the other hand, most connectionist models assume that data are organized according to relatively poor structures, like arrays or sequences. The framework described in this paper is an attempt to unify adaptive models like artificial neural nets and belief nets for the problem of processing structured information. In particular, relations between data variables are expressed by directed acyclic graphs, where both numerical and categorical values coexist. The general framework proposed in this paper can be regarded as an extension of both recurrent neural networks and hidden Markov models to the case of acyclic graphs. In particular we study the supervised learning problem as the problem of learning transductions from an input structured space to an output structured space, where transductions are assumed to admit a recursive hidden statespace representation. We introduce a graphical formalism for representing this class of adaptive transductions by means of recursive networks, i.e., cyclic graphs where nodes are labeled by variables and edges are labeled by generalized delay elements. This representation makes it possible to incorporate the symbolic and subsymbolic nature of data. Structures are processed by unfolding the recursive network into an acyclic graph called encoding network. In so doing, inference and learning algorithms can be easily inherited from the corresponding algorithms for artificial neural networks or probabilistic graphical model."
            },
            "slug": "A-general-framework-for-adaptive-processing-of-data-Frasconi-Gori",
            "title": {
                "fragments": [],
                "text": "A general framework for adaptive processing of data structures"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The framework described in this paper is an attempt to unify adaptive models like artificial neural nets and belief nets for the problem of processing structured information, where relations between data variables are expressed by directed acyclic graphs, where both numerical and categorical values coexist."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144197258"
                        ],
                        "name": "A. Krogh",
                        "slug": "A.-Krogh",
                        "structuredName": {
                            "firstName": "Anders",
                            "lastName": "Krogh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krogh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145666307"
                        ],
                        "name": "G. Mitchison",
                        "slug": "G.-Mitchison",
                        "structuredName": {
                            "firstName": "Graeme",
                            "lastName": "Mitchison",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Mitchison"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 157
                            }
                        ],
                        "text": "Finally, predictions made from individual sequences are combined at the output level, using both multiple alignments and a maximum entropy weighting scheme (Krogh and Mitchinson, 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15879271,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "394edece35cd52215f6aa1ef83860912a6406dd4",
            "isKey": false,
            "numCitedBy": 64,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "In a family of proteins or other biological sequences like DNA the various subfamilies are often very unevenly represented. For this reason a scheme for assigning weights to each sequence can greatly improve performance at tasks such as database searching with profiles or other consensus models based on multiple alignments. A new weighting scheme for this type of database search is proposed. In a statistical description of the searching problem it is derived from the maximum entropy principle. It can be proved that, in a certain sense, it corrects for uneven representation. It is shown that finding the maximum entropy weights is an easy optimization problem for which standard techniques are applicable."
            },
            "slug": "Maximum-Entropy-Weighting-of-Aligned-Sequences-of-Krogh-Mitchison",
            "title": {
                "fragments": [],
                "text": "Maximum Entropy Weighting of Aligned Sequences of Proteins or DNA"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that finding the maximum entropy weights is an easy optimization problem for which standard techniques are applicable and it can be proved that, in a certain sense, it corrects for uneven representation."
            },
            "venue": {
                "fragments": [],
                "text": "ISMB"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2812486"
                        ],
                        "name": "P. Simard",
                        "slug": "P.-Simard",
                        "structuredName": {
                            "firstName": "Patrice",
                            "lastName": "Simard",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Simard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688235"
                        ],
                        "name": "P. Frasconi",
                        "slug": "P.-Frasconi",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Frasconi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Frasconi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 101
                            }
                        ],
                        "text": "One of the principal difficulties when training standard RNNs is the problem of vanishing gradients (Bengio et al., 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 8
                            }
                        ],
                        "text": "When we do not specify otherwise, the default mapping we use is as follows: \u03b1 is formed by DSSP class H, \u03b2 by E, and \u03b3 by everything else (including DSSP classes G, S, T, B, I and \u2018.\u2019)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206457500,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0be39ee052d246ae99c082a565aba25b811be2d",
            "isKey": false,
            "numCitedBy": 6144,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "Recurrent neural networks can be used to map input sequences to output sequences, such as for recognition, production or prediction problems. However, practical difficulties have been reported in training recurrent neural networks to perform tasks in which the temporal contingencies present in the input/output sequences span long intervals. We show why gradient based learning algorithms face an increasingly difficult problem as the duration of the dependencies to be captured increases. These results expose a trade-off between efficient learning by gradient descent and latching on information for long periods. Based on an understanding of this problem, alternatives to standard gradient descent are considered."
            },
            "slug": "Learning-long-term-dependencies-with-gradient-is-Bengio-Simard",
            "title": {
                "fragments": [],
                "text": "Learning long-term dependencies with gradient descent is difficult"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work shows why gradient based learning algorithms face an increasingly difficult problem as the duration of the dependencies to be captured increases, and exposes a trade-off between efficient learning by gradient descent and latching on information for long periods."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157784"
                        ],
                        "name": "C. Lee Giles",
                        "slug": "C.-Lee-Giles",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Giles",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lee Giles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153170210"
                        ],
                        "name": "Clifford B. Miller",
                        "slug": "Clifford-B.-Miller",
                        "structuredName": {
                            "firstName": "Clifford",
                            "lastName": "Miller",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Clifford B. Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2158193072"
                        ],
                        "name": "Dong Chen",
                        "slug": "Dong-Chen",
                        "structuredName": {
                            "firstName": "Dong",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dong Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115401300"
                        ],
                        "name": "Hsing-Hen Chen",
                        "slug": "Hsing-Hen-Chen",
                        "structuredName": {
                            "firstName": "Hsing-Hen",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hsing-Hen Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34922532"
                        ],
                        "name": "Guo-Zheng Sun",
                        "slug": "Guo-Zheng-Sun",
                        "structuredName": {
                            "firstName": "Guo-Zheng",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guo-Zheng Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2552960"
                        ],
                        "name": "Yee-Chun Lee",
                        "slug": "Yee-Chun-Lee",
                        "structuredName": {
                            "firstName": "Yee-Chun",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yee-Chun Lee"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 160
                            }
                        ],
                        "text": "\u2026architectures that have been investigated for grammatical inference are recurrent neural networks (RNN), with both first- (Cleeremans, 1993) and second-order (Giles et al., 1992) connections, as well as input\u2013output hidden Markov models (IOHMM) (Baldi and Chauvin, 1996; Bengio and Frasconi, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 51
                            }
                        ],
                        "text": "For example, a generalization of second-order RNN (Giles et al., 1992) is an easily conceivable alternative parameterization."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 19666035,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "872cdc269f3cb59f8a227818f35041415091545f",
            "isKey": false,
            "numCitedBy": 489,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We show that a recurrent, second-order neural network using a real-time, forward training algorithm readily learns to infer small regular grammars from positive and negative string training samples. We present simulations that show the effect of initial conditions, training set size and order, and neural network architecture. All simulations were performed with random initial weight strengths and usually converge after approximately a hundred epochs of training. We discuss a quantization algorithm for dynamically extracting finite state automata during and after training. For a well-trained neural net, the extracted automata constitute an equivalence class of state machines that are reducible to the minimal machine of the inferred grammar. We then show through simulations that many of the neural net state machines are dynamically stable, that is, they correctly classify many long unseen strings. In addition, some of these extracted automata actually outperform the trained neural network for classification of unseen strings."
            },
            "slug": "Learning-and-Extracting-Finite-State-Automata-with-Giles-Miller",
            "title": {
                "fragments": [],
                "text": "Learning and Extracting Finite State Automata with Second-Order Recurrent Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "It is shown that a recurrent, second-order neural network using a real-time, forward training algorithm readily learns to infer small regular grammars from positive and negative string training samples, and many of the neural net state machines are dynamically stable, that is, they correctly classify many long unseen strings."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2586725"
                        ],
                        "name": "M. Forcada",
                        "slug": "M.-Forcada",
                        "structuredName": {
                            "firstName": "Mikel",
                            "lastName": "Forcada",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Forcada"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1798578"
                        ],
                        "name": "Rafael C. Carrasco",
                        "slug": "Rafael-C.-Carrasco",
                        "structuredName": {
                            "firstName": "Rafael",
                            "lastName": "Carrasco",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rafael C. Carrasco"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 142
                            }
                        ],
                        "text": "For simplicity, here we use F0 = BT +1 = 0, but it is also possible to adapt the boundaries to the data, extending the technique suggested in Forcada and Carrasco (1995) for standard RNNs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16946201,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6cde498cfaf7b862da3fa358caee9749e65ed3d",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent work has shown that second-order recurrent neural networks (2ORNNs) may be used to infer regular languages. This paper presents a modified version of the real-time recurrent learning (RTRL) algorithm used to train 2ORNNs, that learns the initial state in addition to the weights. The results of this modification, which adds extra flexibility at a negligible cost in time complexity, suggest that it may be used to improve the learning of regular languages when the size of the network is small."
            },
            "slug": "Learning-the-Initial-State-of-a-Second-Order-Neural-Forcada-Carrasco",
            "title": {
                "fragments": [],
                "text": "Learning the Initial State of a Second-Order Recurrent Neural Network during Regular-Language Inference"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "A modified version of the real-time recurrent learning (RTRL) algorithm used to train 2ORNNs is presented, that learns the initial state in addition to the weights, suggesting that it may be used to improve the learning of regular languages when the size of the network is small."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145910"
                        ],
                        "name": "E. Myers",
                        "slug": "E.-Myers",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Myers",
                            "middleNames": [
                                "Wimberly"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Myers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "119333843"
                        ],
                        "name": "W. Miller",
                        "slug": "W.-Miller",
                        "structuredName": {
                            "firstName": "Webb",
                            "lastName": "Miller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Miller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 197
                            }
                        ],
                        "text": "\u2026subset with low pairwise sequence similarities was selected by running the algorithm no. 1 of Hobohm et al. (1992), using the local alignment procedure search (rigorous Smith\u2013 Waterman algorithm) (Myers and Miller, 1988; Pearson, 1990) using the pam120 matrix, with gap penalties \u221212, \u22124."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 88
                            }
                        ],
                        "text": "(1992), using the local alignment procedure search (rigorous Smith\u2013 Waterman algorithm) (Myers and Miller, 1988; Pearson, 1990) using the pam120 matrix, with gap penalties \u221212, \u22124."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8140207,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "21fc6d49ae1a6ac1601ab6be95c7132a5667bd74",
            "isKey": false,
            "numCitedBy": 1230,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Space, not time, is often the limiting factor when computing optimal sequence alignments, and a number of recent papers in the biology literature have proposed space-saving strategies. However, a 1975 computer science paper by Hirschberg presented a method that is superior to the new proposals, both in theory and in practice. The goal of this paper is to give Hirschberg's idea the visibility it deserves by developing a linear-space version of Gotoh's algorithm, which accommodates affine gap penalties. A portable C-software package implementing this algorithm is available on the BIONET free of charge."
            },
            "slug": "Optimal-alignments-in-linear-space-Myers-Miller",
            "title": {
                "fragments": [],
                "text": "Optimal alignments in linear space"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The goal of this paper is to give Hirschberg's idea the visibility it deserves by developing a linear-space version of Gotoh's algorithm, which accommodates affine gap penalties."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Appl. Biosci."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2417557"
                        ],
                        "name": "D. Eisenberg",
                        "slug": "D.-Eisenberg",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Eisenberg",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Eisenberg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 17
                            }
                        ],
                        "text": "While input profiles contain information not present in individual sequences, it is worth noting that they also discard information by losing intra-sequence correlations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 148
                            }
                        ],
                        "text": "In the 1996 Asilomar blind prediction competition CASP2 (Critical Assessment of Protein Structure Prediction), this method outperformed all others (Eisenberg, 1997), reaching a performance level of 74%."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 27720250,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "6408fa1f11133feb0611635d962744272f4fd7d8",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Protein structure of prediction methods, critically assessed at Asilomar, California, are starting to work, combining ideas descended from two lines of thought: from Darwin and from Boltzmann and Schrodinger."
            },
            "slug": "Into-the-black-of-night-Eisenberg",
            "title": {
                "fragments": [],
                "text": "Into the black of night"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Protein structure of prediction methods, critically assessed at Asilomar, California, are starting to work, combining ideas descended from two lines of thought: from Darwin and from Boltzmann and Schrodinger."
            },
            "venue": {
                "fragments": [],
                "text": "Nature Structural Biology"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46486898"
                        ],
                        "name": "A. Krogh",
                        "slug": "A.-Krogh",
                        "structuredName": {
                            "firstName": "Anders",
                            "lastName": "Krogh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krogh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2882099"
                        ],
                        "name": "Jesper Vedelsby",
                        "slug": "Jesper-Vedelsby",
                        "structuredName": {
                            "firstName": "Jesper",
                            "lastName": "Vedelsby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jesper Vedelsby"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 150
                            }
                        ],
                        "text": "In a second set of experiments based on the 824 sequences, we combined several BRNNs, trained with 1/3\u2013 2/3 data splitting, to form an ensemble, as in Krogh and Vedelsby (1995), using a simple averaging scheme."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5846986,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "910688d01c01856dd20715907af44157de8d3d1d",
            "isKey": false,
            "numCitedBy": 1971,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning of continuous valued functions using neural network ensembles (committees) can give improved accuracy, reliable estimation of the generalization error, and active learning. The ambiguity is defined as the variation of the output of ensemble members averaged over unlabeled data, so it quantifies the disagreement among the networks. It is discussed how to use the ambiguity in combination with cross-validation to give a reliable estimate of the ensemble generalization error, and how this type of ensemble cross-validation can sometimes improve performance. It is shown how to estimate the optimal weights of the ensemble members using unlabeled data. By a generalization of query by committee, it is finally shown how the ambiguity can be used to select new training data to be labeled in an active learning scheme."
            },
            "slug": "Neural-Network-Ensembles,-Cross-Validation,-and-Krogh-Vedelsby",
            "title": {
                "fragments": [],
                "text": "Neural Network Ensembles, Cross Validation, and Active Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown how to estimate the optimal weights of the ensemble members using unlabeled data and how the ambiguity can be used to select new training data to be labeled in an active learning scheme."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72869726"
                        ],
                        "name": "D. Araki",
                        "slug": "D.-Araki",
                        "structuredName": {
                            "firstName": "Debugging",
                            "lastName": "Araki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Araki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2074232"
                        ],
                        "name": "Z. Furukawa",
                        "slug": "Z.-Furukawa",
                        "structuredName": {
                            "firstName": "Zengo",
                            "lastName": "Furukawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Furukawa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 61696633,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "f1655d8e58e24e19aef57a71db180bd148797f12",
            "isKey": false,
            "numCitedBy": 299,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This report is preliminary and has not been reviewed for conformity with U.S. Geological Survey editorial standards (or with the North American Stratigraphic Code). Use of trade, product, or firm names is for descriptive purposes only and does not imply endorsement by the U. S. Geological Survey."
            },
            "slug": "A-General-Framework-for-Araki-Furukawa",
            "title": {
                "fragments": [],
                "text": "A General Framework for"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This report is preliminary and has not been reviewed for conformity with U.S. Geological Survey editorial standards (or with the North American Stratigraphic Code)."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 4
                            }
                        ],
                        "text": ", 1997; CASP3, 1998), where \u03b1 contains H and G, while \u03b2 contains E and B. Other assignments used in the literature include Riis and Krogh (1996), where \u03b1 contains DSSP classes H, G and I."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 257,
                                "start": 234
                            }
                        ],
                        "text": "In addition, we also used the original set of 126 sequences of Rost and Sander, corresponding to a total of 23 348 amino acid positions, as well as the complementary set of 396 non-homologue sequences (62 189 amino acids) prepared by Cuff and Barton (1999). Both sets can be downloaded at http://circinus."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 40
                            }
                        ],
                        "text": "We also confirm the observation made by Cuff and Barton (1999) concerning the impact of the class assignment: the same system tested with the default class assignment achieves a performance of Q3 = 77.3%"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 2001,
                                "start": 91
                            }
                        ],
                        "text": "A study of the effect of various assignments on the prediction performance can be found in Cuff and Barton (1999). We carried out many experiments to tune up and evaluate the prediction system. The main results are summarized in Tables 1\u20134. In a first set of experiments, based on the 824 sequences, we reserved two-thirds of the available data for training, and one-third for testing, chosen at random. We trained several BRNNs of different sizes and different architectural details. Training was stopped using a fixed threshold on the reduction in error, rather than other adaptive criteria such as early stopping. In all experiments, we set n = m and tried different values for n and s [see equation (6)]. The number of free parameters varied from about 1400 to 2900. Qualitatively we observed that using s > 0 can improve accuracy, but increasing n beyond 12 does not help because of overfitting. Results for this method, without using profiles, are summarized in the first rows of Table 1. By comparison, we also trained several feedforward NNs on the same data. The best feedforward NN achieved Q3 = 67.2% accuracy using a window of 13 amino acids. By enriching the feedforward architecture with adaptive input encoding and output filtering, as in Riis and Krogh (1996), 68.5% accuracy was achieved (output filtering actually increases the length of the input window). Hence, the best BRNN outperforms our best feedforward network, even when additional architectural design is included. Subsequent experiments included the use of profiles. Table 1 reports the best results obtained by using multiple alignments, both at the input and output levels. Profiles at the input level consistently yielded better results. The best feedforward networks trained in the same conditions achieve Q3 = 73.0 and 72.3%, respectively. In a second set of experiments based on the 824 sequences, we combined several BRNNs, trained with 1/3\u2013 2/3 data splitting, to form an ensemble, as in Krogh and Vedelsby (1995), using a simple averaging scheme."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 15
                            }
                        ],
                        "text": "More recently, Cuff and Barton (1999) have compared and combined the main existing predictors."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 238,
                                "start": 54
                            }
                        ],
                        "text": "The performance on the 396 test sequences prepared by Cuff and Barton is Q3 = 72.0%. This is slightly better than the 71.9% score for the single best predictor (PHD) amongst DSC, PHD, NNSSP and PREDATOR reported in Cuff and Barton (1999). This result is also achieved with the CASP class assignment."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 126
                            }
                        ],
                        "text": "The improvements seem to result in part from the use of PSI-BLAST generated profiles, although this is somewhat controversial (Cuff and Barton, 1999) and not directly reproducible since the filters used to process the raw profiles are not described in sufficient detail in Jones (1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 59
                            }
                        ],
                        "text": "To further compare our system with other predictors, as in Cuff and Barton (1999), we also trained an ensemble of\nBRNNs using the 126 sequences in the Rost and Sander data set."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 127
                            }
                        ],
                        "text": "The improvements seem to result in part from the use of PSI-BLAST generated profiles, although this is somewhat controversial (Cuff and Barton, 1999) and not directly reproducible since the filters used to process the raw\nprofiles are not described in sufficient detail in Jones (1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 130
                            }
                        ],
                        "text": "This is slightly better than the 71.9% score for the single best predictor (PHD) amongst DSC, PHD, NNSSP and PREDATOR reported in Cuff and Barton (1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 91
                            }
                        ],
                        "text": "A study of the effect of various assignments on the prediction performance can be found in Cuff and Barton (1999). We carried out many experiments to tune up and evaluate the prediction system."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1276,
                                "start": 91
                            }
                        ],
                        "text": "A study of the effect of various assignments on the prediction performance can be found in Cuff and Barton (1999). We carried out many experiments to tune up and evaluate the prediction system. The main results are summarized in Tables 1\u20134. In a first set of experiments, based on the 824 sequences, we reserved two-thirds of the available data for training, and one-third for testing, chosen at random. We trained several BRNNs of different sizes and different architectural details. Training was stopped using a fixed threshold on the reduction in error, rather than other adaptive criteria such as early stopping. In all experiments, we set n = m and tried different values for n and s [see equation (6)]. The number of free parameters varied from about 1400 to 2900. Qualitatively we observed that using s > 0 can improve accuracy, but increasing n beyond 12 does not help because of overfitting. Results for this method, without using profiles, are summarized in the first rows of Table 1. By comparison, we also trained several feedforward NNs on the same data. The best feedforward NN achieved Q3 = 67.2% accuracy using a window of 13 amino acids. By enriching the feedforward architecture with adaptive input encoding and output filtering, as in Riis and Krogh (1996), 68."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1358,
                                "start": 54
                            }
                        ],
                        "text": "The performance on the 396 test sequences prepared by Cuff and Barton is Q3 = 72.0%. This is slightly better than the 71.9% score for the single best predictor (PHD) amongst DSC, PHD, NNSSP and PREDATOR reported in Cuff and Barton (1999). This result is also achieved with the CASP class assignment. Finally, we also trained an ensemble of six BRNNs using the set containing 826 sequences with less than 25% identity to the 126 sequences of Rost and Sander. When tested on the 126 sequences, the system achieves Q3 = 74.7% per residue, with correlation coefficients C\u03b1 = 0.692, C\u03b2 = 0.571 and C\u03b3 = 0.544. This is again achieved with the harder CASP assignment. In contrast, the Q3 = 75.1% described above and obtained by 7fold cross-validation on 824 sequences was obtained with the easier class assignment (H\u2192 \u03b1, E\u2192 \u03b2, the rest \u2192 \u03b3 ). The same experiment was performed using the larger training set of 1180 sequences having also less than 25% identity with the 126 sequences of Rost and Sander, but with a less stringent redundancy reduction requirement. In this case, with the same hard assignment and with BLAST-derived profiles, the results are Q3 = 75.9% with correlation coefficients C\u03b1 = 0.717, C\u03b2 = 0.586 and C\u03b3 = 0.556. The corresponding confusion matrices are given in Tables 2 and 3. We also confirm the observation made by Cuff and Barton (1999) concerning the impact of the class assignment: the same system tested with the default class assignment achieves a performance of Q3 = 77."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 91
                            }
                        ],
                        "text": "A study of the effect of various assignments on the prediction performance can be found in Cuff and Barton (1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 256,
                                "start": 234
                            }
                        ],
                        "text": "In addition, we also used the original set of 126 sequences of Rost and Sander, corresponding to a total of 23 348 amino acid positions, as well as the complementary set of 396 non-homologue sequences (62 189 amino acids) prepared by Cuff and Barton (1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 71
                            }
                        ],
                        "text": "While assignment methods impact prediction performance to some extent (Cuff and Barton, 1999), here we concentrate exclusively on the DSSP assignments."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Evaluation and improvement"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 40
                            }
                        ],
                        "text": "We also confirm the observation made by Cuff and Barton (1999) concerning the impact of the class assignment: the same system tested with the default class assignment achieves a performance of Q3 = 77.3%"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 14
                            }
                        ],
                        "text": "More recently,Cuff and Barton(1999) have compared and combined the main existing predictors."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 15
                            }
                        ],
                        "text": "More recently, Cuff and Barton (1999) have compared and combined the main existing predictors."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 283,
                                "start": 14
                            }
                        ],
                        "text": "More recently,Cuff and Barton(1999) have compared and combined the main existing predictors. On the particular data sets used in their study, the best isolated predictor is still PHD with Q3 = 71.9%. At the last 1998 CASP3 competition, the best results were obtained by Jones (1999), using a relatively simple but large NN architecture."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 59
                            }
                        ],
                        "text": "To further compare our system with other predictors, as in Cuff and Barton (1999), we also trained an ensemble of\nBRNNs using the 126 sequences in the Rost and Sander data set."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 127
                            }
                        ],
                        "text": "The improvements seem to result in part from the use of PSI-BLAST generated profiles, although this is somewhat controversial (Cuff and Barton, 1999) and not directly reproducible since the filters used to process the raw\nprofiles are not described in sufficient detail in Jones (1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 130
                            }
                        ],
                        "text": "This is slightly better than the 71.9% score for the single best predictor (PHD) amongst DSC, PHD, NNSSP and PREDATOR reported in Cuff and Barton (1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 96
                            }
                        ],
                        "text": "CLOSE FILE the complementary set of 396 non-homologue sequences (62 189 amino acids) prepared byCuff and Barton(1999). Both sets can be downloaded at ht p: //circinus."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 91
                            }
                        ],
                        "text": "A study of the effect of various assignments on the prediction performance can be found in Cuff and Barton (1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 256,
                                "start": 234
                            }
                        ],
                        "text": "In addition, we also used the original set of 126 sequences of Rost and Sander, corresponding to a total of 23 348 amino acid positions, as well as the complementary set of 396 non-homologue sequences (62 189 amino acids) prepared by Cuff and Barton (1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 71
                            }
                        ],
                        "text": "While assignment methods impact prediction performance to some extent (Cuff and Barton, 1999), here we concentrate exclusively on the DSSP assignments."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "We carried out many experiments to tune up and evaluate the prediction system"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 145
                            }
                        ],
                        "text": "Moreover, different predictors can be obtained using profiles, or multiple alignments, in input mode (Rost and Sander, 1994), or in output mode (Riis and Krogh, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 49
                            }
                        ],
                        "text": "Other assignments used in the literature include Riis and Krogh (1996), where \u03b1 contains DSSP classes H, G and I."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 157
                            }
                        ],
                        "text": "In particular, many different feedforward neural network (NN) architectures have been applied to this task (Qian and Sejnowski, 1988; Rost and Sander, 1994; Riis and Krogh, 1996)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 99
                            }
                        ],
                        "text": "By enriching the feedforward architecture with adaptive input encoding and output filtering, as in Riis and Krogh (1996), 68.5% accuracy was achieved (output filtering actually increases the length of the input window)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 123
                            }
                        ],
                        "text": "This is an improvement over standard NNs with input window sizes ranging from 11 to 17 amino acids (Rost and Sander, 1994; Riis and Krogh, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 117
                            }
                        ],
                        "text": "Here also larger input windows are possible, especially in combination with the weight sharing approach described in Riis and Krogh (1996), and different inputs could be used for the computation of Ft , Bt and Ot ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 3
                            }
                        ],
                        "text": "In Riis and Krogh (1996), further NN architectural and machine learning refinements are used, such as an adaptive encoding of the input amino acids by the NN weight-sharing technique to reduce the number of free parameters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Improving prediction of proteinsecondary structure using structured neural networks and multiplesequence alignments"
            },
            "venue": {
                "fragments": [],
                "text": "J . Comput . Biol ."
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 141
                            }
                        ],
                        "text": "Building upon the work of Qian and Sejnowski (1988), for a long time the best SS prediction performance has been achieved by the PHD scheme (Rost and Sander, 1993, 1994)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 102
                            }
                        ],
                        "text": "Moreover, different predictors can be obtained using profiles, or multiple alignments, in input mode (Rost and Sander, 1994), or in output mode (Riis and Krogh, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 134
                            }
                        ],
                        "text": "In particular, many different feedforward neural network (NN) architectures have been applied to this task (Qian and Sejnowski, 1988; Rost and Sander, 1994; Riis and Krogh, 1996)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 100
                            }
                        ],
                        "text": "This is an improvement over standard NNs with input window sizes ranging from 11 to 17 amino acids (Rost and Sander, 1994; Riis and Krogh, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 134
                            }
                        ],
                        "text": "In spite of a considerable amount of architectural design, the final performance with multiple alignments is practically identical to Rost and Sander (1994), with an overall accuracy of Q3 = 71.3%, and correlations C\u03b1 = 0.59, C\u03b2 = 0.50 and C\u03b3 = 0.41."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Combining evolutionary information"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 265,
                                "start": 260
                            }
                        ],
                        "text": "The main connectionist architectures that have been investigated for grammatical inference are recurrent neural networks (RNN), with both first- (Cleeremans, 1993) and second-order (Giles et al., 1992) connections, as well as input\u2013output hidden Markov models (IOHMM) (Baldi and Chauvin, 1996; Bengio and Frasconi, 1996)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 76
                            }
                        ],
                        "text": "Thus, it would make sense to tackle the SS prediction problem using RNNs or IOHMMs."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 65
                            }
                        ],
                        "text": "Thus, inference in BRNNs is more efficient than in bidirectional IOHMMs, where complexity is O(T n3) (Baldi et al., 1999b)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 66
                            }
                        ],
                        "text": "Unlike RNNs, however, propagation of information in bidirectional IOHMMs is computationally expensive."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 14
                            }
                        ],
                        "text": "Both RNNs and IOHMMs are sensible alternatives to methods based on a fixed-width input window."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 102
                            }
                        ],
                        "text": "In fact, such probabilistic version of the architecture would yield a bidirectional generalization of IOHMMs."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 271
                            }
                        ],
                        "text": "\u2026architectures that have been investigated for grammatical inference are recurrent neural networks (RNN), with both first- (Cleeremans, 1993) and second-order (Giles et al., 1992) connections, as well as input\u2013output hidden Markov models (IOHMM) (Baldi and Chauvin, 1996; Bengio and Frasconi, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 82
                            }
                        ],
                        "text": "A more careful analysis, however, reveals a basic limitation of standard RNNs and IOHMMs in computational biology."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 74
                            }
                        ],
                        "text": ", 1992) connections, as well as input\u2013output hidden Markov models (IOHMM) (Baldi and Chauvin, 1996; Bengio and Frasconi, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Input\u2013output HMMs for sequence"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 9
                            }
                        ],
                        "text": "Out of the 35 blind sequences, the program selected 23 and achieved a performance of Q3 = 77.6% per protein, or Q3 = 75.5% per residue."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 70
                            }
                        ],
                        "text": "At the last 1998 CASP3 competition, the best results were obtained by Jones (1999), using a relatively simple but large NN architecture."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 285,
                                "start": 273
                            }
                        ],
                        "text": "The improvements seem to result in part from the use of PSI-BLAST generated profiles, although this is somewhat controversial (Cuff and Barton, 1999) and not directly reproducible since the filters used to process the raw\nprofiles are not described in sufficient detail in Jones (1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Protein secondary structure prediction based on position-speciic scoring matrices"
            },
            "venue": {
                "fragments": [],
                "text": "J. Mol. Biol"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 146
                            }
                        ],
                        "text": "The main connectionist architectures that have been investigated for grammatical inference are recurrent neural networks (RNN), with both first- (Cleeremans, 1993) and second-order (Giles et al., 1992) connections, as well as input\u2013output hidden Markov models (IOHMM) (Baldi and Chauvin, 1996;\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 35
                            }
                        ],
                        "text": "\u2022 The protein had physical chain breaks (defined as neighboring amino acids in the sequence having C\u03b1distances exceeding 4.0 A\u030a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Mechanisms of implicit learning"
            },
            "venue": {
                "fragments": [],
                "text": "Connectionist Models of Sequence Processing"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2195511"
                        ],
                        "name": "J. Moult",
                        "slug": "J.-Moult",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Moult",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Moult"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8126949"
                        ],
                        "name": "T. Hubbard",
                        "slug": "T.-Hubbard",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Hubbard",
                            "middleNames": [
                                "J.",
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hubbard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1807652"
                        ],
                        "name": "S. Bryant",
                        "slug": "S.-Bryant",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Bryant",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bryant"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1842582"
                        ],
                        "name": "K. Fidelis",
                        "slug": "K.-Fidelis",
                        "structuredName": {
                            "firstName": "Krzysztof",
                            "lastName": "Fidelis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fidelis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48309062"
                        ],
                        "name": "J. Pedersen",
                        "slug": "J.-Pedersen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Pedersen",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pedersen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 64
                            }
                        ],
                        "text": "Otherwise we use the \u2018harder\u2019 assignment of the CASP competition (Moult et al., 1997; CASP3, 1998), where \u03b1 contains H and G, while \u03b2 contains E and B."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 26823924,
            "fieldsOfStudy": [
                "Chemistry",
                "Medicine"
            ],
            "id": "87914ee5258b5ed88d066210e2cc7e2bda4e35c7",
            "isKey": false,
            "numCitedBy": 299,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Critical-assessment-of-methods-of-protein-structure-Moult-Hubbard",
            "title": {
                "fragments": [],
                "text": "Critical assessment of methods of protein structure prediction (CASP): Round II"
            },
            "venue": {
                "fragments": [],
                "text": "Proteins"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Mechanisms of implicit learning"
            },
            "venue": {
                "fragments": [],
                "text": "Connec - tionist Models of Sequence Processing"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Protein secondary structure prediction based on positionspecific scoring matrices"
            },
            "venue": {
                "fragments": [],
                "text": "J . Mol . Biol ."
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 87
                            }
                        ],
                        "text": "In all but two experiments (see below), profiles were obtained from the HSSP database (Schneider et al., 1997) available at http://www.sander. embl-heidelberg.de/hssp/."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The HSSPdatabase of protein structuresequence alignments"
            },
            "venue": {
                "fragments": [],
                "text": "Nucleic AcidsRes ."
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 221
                            }
                        ],
                        "text": "\u2026subset with low pairwise sequence similarities was selected by running the algorithm no. 1 of Hobohm et al. (1992), using the local alignment procedure search (rigorous Smith\u2013 Waterman algorithm) (Myers and Miller, 1988; Pearson, 1990) using the pam120 matrix, with gap penalties \u221212, \u22124."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Rapid and sensitive sequence comparison with FASTP and FASTA.Methods Enzymol"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "the similarity threshold, dividing sequences with structural homology from those without, had the form I"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Selection of representative data sets Bayesian updating in recursive graphical models by local computations"
            },
            "venue": {
                "fragments": [],
                "text": "Protein Sci. Comput. Stat. Quarterly"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "As - sessing the accuracy of prediction algorithms for classi cation : anoverview"
            },
            "venue": {
                "fragments": [],
                "text": "Bioinformatics"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 101
                            }
                        ],
                        "text": "One of the principal difficulties when training standard RNNs is the problem of vanishing gradients (Bengio et al., 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning longtermdependencies with gradient descent is di \u000e cult"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactionson Neural Networks"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Evaluation and improvementof multiple sequence methods for protein secondary structure prediction"
            },
            "venue": {
                "fragments": [],
                "text": "Proteins"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 70
                            }
                        ],
                        "text": "At the last 1998 CASP3 competition, the best results were obtained by Jones (1999), using a relatively simple but large NN architecture."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 285,
                                "start": 273
                            }
                        ],
                        "text": "The improvements seem to result in part from the use of PSI-BLAST generated profiles, although this is somewhat controversial (Cuff and Barton, 1999) and not directly reproducible since the filters used to process the raw\nprofiles are not described in sufficient detail in Jones (1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Protein secondary structure prediction basedon positionspeci c scoring matrices"
            },
            "venue": {
                "fragments": [],
                "text": "J . Mol . Biol ."
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "CASP3"
            },
            "venue": {
                "fragments": [],
                "text": "CASP3"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learninglong - term dependencies in NARX recurrent neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "IEEETransactions on Neural Networks"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 60
                            }
                        ],
                        "text": "In addition to hydrogen bonds, STRIDE uses dihedral angles (Frishman and Argos, 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Knowledge - based secondarystructure assignment"
            },
            "venue": {
                "fragments": [],
                "text": "Proteins"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 42
                            }
                        ],
                        "text": "Both RNNs and IOHMMs are sensible alternatives to methods based on a fixed-width input window."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 271
                            }
                        ],
                        "text": "\u2026architectures that have been investigated for grammatical inference are recurrent neural networks (RNN), with both first- (Cleeremans, 1993) and second-order (Giles et al., 1992) connections, as well as input\u2013output hidden Markov models (IOHMM) (Baldi and Chauvin, 1996; Bengio and Frasconi, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Input-output HMM's for sequence processing"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. on Neural Networks"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 60
                            }
                        ],
                        "text": "In addition to hydrogen bonds, STRIDE uses dihedral angles (Frishman and Argos, 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Knowledge-based secondary structure assignment"
            },
            "venue": {
                "fragments": [],
                "text": "Proteins"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 66
                            }
                        ],
                        "text": "Although several symbolic algorithms exist for learning grammars (Angluin and Smith, 1987), to the best of our knowledge they have not led to successful protein SS predictors, presumably because of their scarce robustness in the presence of noisy data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Inductive inference. Encyclopedia of Artificial Intelligence Wiley"
            },
            "venue": {
                "fragments": [],
                "text": "Inductive inference. Encyclopedia of Artificial Intelligence Wiley"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning long-term Abstract Introduction Methods and . . . Implementation and . . . Discussion Acknowledgements References GO BACK CLOSE FILE dependencies in NARX recurrent neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 111
                            }
                        ],
                        "text": "The underlying Bayesian network contains undirected loops that require the use of the junction tree algorithm (Jensen et al., 1990)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 73
                            }
                        ],
                        "text": "Yet, there is presumably relevant information located at longer distances that our models have not been able to discover so far."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bayesian updating in recursive graphical models by local computations"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Stat. Quarterly"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 26
                            }
                        ],
                        "text": "Building upon the work of Qian and Sejnowski (1988), for a long time the best SS prediction performance has been achieved by the PHD scheme (Rost and Sander, 1993, 1994)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 108
                            }
                        ],
                        "text": "In particular, many different feedforward neural network (NN) architectures have been applied to this task (Qian and Sejnowski, 1988; Rost and Sander, 1994; Riis and Krogh, 1996)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 158
                            }
                        ],
                        "text": "Thus we obtained a data set consisting of 464 distinct protein chains, corresponding to 123 752 amino acids, roughly 10 times more than what was available in Qian and Sejnowski (1988)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Predicting the secondarystructure of glubular proteins using neural network models"
            },
            "venue": {
                "fragments": [],
                "text": "J . Mol . Biol ."
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Selec - tion of representative data sets"
            },
            "venue": {
                "fragments": [],
                "text": "Protein Sci ."
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Selec - tion of representative data sets"
            },
            "venue": {
                "fragments": [],
                "text": "Protein Sci ."
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Third community wide experiment on the critical assessment of techniques for protein structure prediction. Unpublished results available in http"
            },
            "venue": {
                "fragments": [],
                "text": "Third community wide experiment on the critical assessment of techniques for protein structure prediction. Unpublished results available in http"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 134
                            }
                        ],
                        "text": "DEFINE uses difference distance matrices for evaluating the match of interatomic distances in the protein to those from idealized SS (Richards and Kundrot, 1988)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Identi cation of structural motifs from protein coordinate data : secondary structure and rstlevel supersecondary structure"
            },
            "venue": {
                "fragments": [],
                "text": "Proteins"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 141
                            }
                        ],
                        "text": "Building upon the work of Qian and Sejnowski (1988), for a long time the best SS prediction performance has been achieved by the PHD scheme (Rost and Sander, 1993, 1994)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Improved prediction of protein"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 197
                            }
                        ],
                        "text": "\u2026subset with low pairwise sequence similarities was selected by running the algorithm no. 1 of Hobohm et al. (1992), using the local alignment procedure search (rigorous Smith\u2013 Waterman algorithm) (Myers and Miller, 1988; Pearson, 1990) using the pam120 matrix, with gap penalties \u221212, \u22124."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Optimal alignments in linearspace"
            },
            "venue": {
                "fragments": [],
                "text": "Comput . Appl . Biosci ."
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 138
                            }
                        ],
                        "text": "From the remaining chains, a representative subset with low pairwise sequence similarities was selected by running the algorithm no. 1 of Hobohm et al. (1992), using the local alignment procedure search (rigorous Smith\u2013 Waterman algorithm) (Myers and Miller, 1988; Pearson, 1990) using the pam120\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Selection of representative data sets"
            },
            "venue": {
                "fragments": [],
                "text": "Prot. Sci"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 72
                            }
                        ],
                        "text": "To limit this problem, we propose a remedy motivated by recent studies (Lin et al., 1996) suggesting that the vanishing gradients problem can be mitigated by the use of an explicit delay line applied to the output, which provides shorter paths for the effective propagation of error signals."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 23
                            }
                        ],
                        "text": "The setup developed in Lund et al. (1997) has also been used to build profiles for sequences not present in the HSSP database."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning longterm dependencies in NARX recurrent neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 111
                            }
                        ],
                        "text": "The underlying Bayesian network contains undirected loops that require the use of the junction tree algorithm (Jensen et al., 1990)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bayesianupdating in recursive graphical models by local computations"
            },
            "venue": {
                "fragments": [],
                "text": "Comput . Stat . Quarterly"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 138
                            }
                        ],
                        "text": "From the remaining chains, a representative subset with low pairwise sequence similarities was selected by running the algorithm no. 1 of Hobohm et al. (1992), using the local alignment procedure search (rigorous Smith\u2013 Waterman algorithm) (Myers and Miller, 1988; Pearson, 1990) using the pam120\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "lection of representative data sets"
            },
            "venue": {
                "fragments": [],
                "text": "Prot . Sci ."
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Third community wide experiment on the critical assessment of techniques for protein structure prediction, Unpublished results available at http"
            },
            "venue": {
                "fragments": [],
                "text": "CASP3"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 330,
                                "start": 3
                            }
                        ],
                        "text": "(1997) has also been used to build profiles for sequences not present in the HSSP database. The setup contains methods similar to the ones applied earlier by Sander and Schneider (1991), where the key parameter is the similarity threshold (in terms of identical residues in a particular pairwise alignment). In Lund et al. (1997) the similarity threshold, dividing sequences with structural homology from those without, had the form I < 290 \u221a L , where L is the length of the"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 3
                            }
                        ],
                        "text": "(1997) has also been used to build profiles for sequences not present in the HSSP database. The setup contains methods similar to the ones applied earlier by Sander and Schneider (1991), where the key parameter is the similarity threshold (in terms of identical residues in a particular pairwise alignment)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 142
                            }
                        ],
                        "text": "For simplicity, here we use F0 = BT +1 = 0, but it is also possible to adapt the boundaries to the data, extending the technique suggested in Forcada and Carrasco (1995) for standard RNNs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning the initial state"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Knowledge - based secondary structure assignment"
            },
            "venue": {
                "fragments": [],
                "text": "Proteins"
            },
            "year": 1995
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 27,
            "methodology": 38,
            "result": 3
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 72,
        "totalPages": 8
    },
    "page_url": "https://www.semanticscholar.org/paper/Exploiting-the-past-and-the-future-in-protein-Baldi-Brunak/9ac3c0f5c9cb6632447c314082151b6b45112941?sort=total-citations"
}