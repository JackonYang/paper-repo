{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144845491"
                        ],
                        "name": "A. Dawid",
                        "slug": "A.-Dawid",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Dawid",
                            "middleNames": [
                                "Philip"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dawid"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 0
                            }
                        ],
                        "text": "Dawid (1992) has described ways to compute, for example, the most probable instantia-tion of unobserved variables (i.e., the set of instantiations which, in the light of evidence,3\nhas maximal joint probability) and a random joint sample of the unobserved variablesgiven evidence."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 190
                            }
                        ],
                        "text": "The approach applied to simulate a component, Ei, is based on the random prop-agation variant of exact local computations in a junction tree (Ploughman & Boehnke6\n1989, Ott 1989, Kong 1991, Dawid 1992)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 228,
                                "start": 218
                            }
                        ],
                        "text": "\u2026models (Bayesian networks) of complex stochastic systems (Cannings, Thomp-son & Skolnick 1976, Cannings, Thompson & Skolnick 1978, Lauritzen & Spiegelhalter1988, Shenoy & Shafer 1990, Jensen, Lauritzen & Olesen 1990, Dawid 1992, Lauritzen1\n1992, Spiegelhalter, Dawid, Lauritzen & Cowell 1993)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 251,
                                "start": 241
                            }
                        ],
                        "text": "The present paper suggests and evaluates a variant of Gibbs sampling (Geman &Geman 1984) involving simultaneous sampling of sets of variables using the junction treearchitecture for exact local computations (Jensen 1988, Jensen et al. 1990, Dawid 1992)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 61247712,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b9abff70b0acf9c6bb74d85f3141d76bef2039a5",
            "isKey": true,
            "numCitedBy": 288,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "A probabilistic expert system provides a graphical representation of a joint probability distribution which can be used to simplify and localize calculations. Jensenet al. (1990) introduced a \u2018flow-propagation\u2019 algorithm for calculating marginal and conditional distributions in such a system. This paper analyses that algorithm in detail, and shows how it can be modified to perform other tasks, including maximization of the joint density and simultaneous \u2018fast retraction\u2019 of evidence entered on several variables."
            },
            "slug": "Applications-of-a-general-propagation-algorithm-for-Dawid",
            "title": {
                "fragments": [],
                "text": "Applications of a general propagation algorithm for probabilistic expert systems"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper analyses a \u2018flow-propagation\u2019 algorithm for calculating marginal and conditional distributions in a probabilistic expert system in detail, and shows how it can be modified to perform other tasks, including maximization of the joint density and simultaneous 'fast retraction' of evidence entered on several variables."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2454055"
                        ],
                        "name": "A. Gelfand",
                        "slug": "A.-Gelfand",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Gelfand",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gelfand"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109352679"
                        ],
                        "name": "Adrian F. M. Smith",
                        "slug": "Adrian-F.-M.-Smith",
                        "structuredName": {
                            "firstName": "Adrian",
                            "lastName": "Smith",
                            "middleNames": [
                                "F.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adrian F. M. Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 184
                            }
                        ],
                        "text": "\u2026alternatives to exact methods, since they are exible, easy to implement,and their computational complexity tends to scale manageably with the size of thenetworks under consideration (Gelfand & Smith 1990, Thomas, Spiegelhalter & Gilks1992, Gelman & Rubin 1992, Geyer 1992, Smith & Roberts 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 53446269,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8d990deca66c9afefbe042f95e41ada0c7227877",
            "isKey": false,
            "numCitedBy": 7054,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract Stochastic substitution, the Gibbs sampler, and the sampling-importance-resampling algorithm can be viewed as three alternative sampling- (or Monte Carlo-) based approaches to the calculation of numerical estimates of marginal probability distributions. The three approaches will be reviewed, compared, and contrasted in relation to various joint probability structures frequently encountered in applications. In particular, the relevance of the approaches to calculating Bayesian posterior densities for a variety of structured models will be discussed and illustrated."
            },
            "slug": "Sampling-Based-Approaches-to-Calculating-Marginal-Gelfand-Smith",
            "title": {
                "fragments": [],
                "text": "Sampling-Based Approaches to Calculating Marginal Densities"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "Stochastic substitution, the Gibbs sampler, and the sampling-importance-resampling algorithm can be viewed as three alternative sampling- (or Monte Carlo-) based approaches to the calculation of numerical estimates of marginal probability distributions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3009522"
                        ],
                        "name": "M. Henrion",
                        "slug": "M.-Henrion",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Henrion",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Henrion"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 947,
                                "start": 315
                            }
                        ],
                        "text": "1 Exact Local Computations Shachter, Andersen & Szolovits (1991) showed that all exact methods for belief updating in Bayesian networks can be viewed as variations on a single, general algorithm involving clustering of variables, thus in e ect creating a secondary structure, which is often called a junction tree (Jensen 1988). The clusters are the nodes of a junction tree and the cliques of a triangulated graph obtained by adding edges to the moral graph (Lauritzen & Spiegelhalter 1988) of the Bayesian network. A triangulated graph is an undirected graph with no cycles of length greater than 3 without a chord. The moral graph of a Bayesian network is obtained by adding undirected edges between all pairs of disconnected nodes with common children and by subsequent replacement of directed edges by undirected ones. In the present paper, we shall refer to an object-oriented version of the exact method of Lauritzen & Spiegelhalter (1988) which has been described by Jensen et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 996,
                                "start": 315
                            }
                        ],
                        "text": "1 Exact Local Computations Shachter, Andersen & Szolovits (1991) showed that all exact methods for belief updating in Bayesian networks can be viewed as variations on a single, general algorithm involving clustering of variables, thus in e ect creating a secondary structure, which is often called a junction tree (Jensen 1988). The clusters are the nodes of a junction tree and the cliques of a triangulated graph obtained by adding edges to the moral graph (Lauritzen & Spiegelhalter 1988) of the Bayesian network. A triangulated graph is an undirected graph with no cycles of length greater than 3 without a chord. The moral graph of a Bayesian network is obtained by adding undirected edges between all pairs of disconnected nodes with common children and by subsequent replacement of directed edges by undirected ones. In the present paper, we shall refer to an object-oriented version of the exact method of Lauritzen & Spiegelhalter (1988) which has been described by Jensen et al. (1990) and implemented in the expert-system shell HUGIN (Andersen, Olesen, Jensen & Jensen 1989)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 64
                            }
                        ],
                        "text": "This variant of forward sampling, which hasbeen investigated by Henrion (1988) under the name of logic sampling, gets increasinglyine cient as p(xA) decreases."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 20172223,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "262f353855b0e6cbeda26ba3b19fff5df1d7c1a2",
            "isKey": true,
            "numCitedBy": 593,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Propagating-uncertainty-in-bayesian-networks-by-Henrion",
            "title": {
                "fragments": [],
                "text": "Propagating uncertainty in bayesian networks by probabilistic logic sampling"
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144389145"
                        ],
                        "name": "A. Gelman",
                        "slug": "A.-Gelman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Gelman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gelman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235217"
                        ],
                        "name": "D. Rubin",
                        "slug": "D.-Rubin",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Rubin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rubin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 333,
                                "start": 323
                            }
                        ],
                        "text": "Stochastic simulation techniques (Monte-Carlo methods) have thus become increas-ingly popular alternatives to exact methods, since they are exible, easy to implement,and their computational complexity tends to scale manageably with the size of thenetworks under consideration (Gelfand & Smith 1990, Thomas, Spiegelhalter & Gilks1992, Gelman & Rubin 1992, Geyer 1992, Smith & Roberts 1993)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 260,
                                "start": 241
                            }
                        ],
                        "text": "\u2026alternatives to exact methods, since they are exible, easy to implement,and their computational complexity tends to scale manageably with the size of thenetworks under consideration (Gelfand & Smith 1990, Thomas, Spiegelhalter & Gilks1992, Gelman & Rubin 1992, Geyer 1992, Smith & Roberts 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14661921,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9c67f30235a47e305dc57c9f185d5587faca4236",
            "isKey": false,
            "numCitedBy": 12103,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "The Gibbs sampler, the algorithm of Metropolis and similar iterative simulation methods are potentially very helpful for summarizing multivariate distributions. Used naively, however, iterative simulation can give misleading answers. Our methods are simple and generally applicable to the output of any iterative simulation; they are designed for researchers primarily interested in the science underlying the data and models they are analyzing, rather than for researchers interested in the probability theory underlying the iterative simulations themselves. Our recommended strategy is to use several independent sequences, with starting points sampled from an overdispersed distribution. At each step of the iterative simulation, we obtain, for each univariate estimand of interest, a distributional estimate and an estimate of how much sharper the distributional estimate might become if the simulations were contin- ued indefinitely. Because our focus is on applied inference for Bayesian posterior distributions in real problems, which often tend toward normal- ity after transformations and marginalization, we derive our results as normal-theory approximations to exact Bayesian inference, conditional on the observed simulations. The methods are illustrated on a random- effects mixture model applied to experimental measurements of reaction times of normal and schizophrenic patients."
            },
            "slug": "Inference-from-Iterative-Simulation-Using-Multiple-Gelman-Rubin",
            "title": {
                "fragments": [],
                "text": "Inference from Iterative Simulation Using Multiple Sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The focus is on applied inference for Bayesian posterior distributions in real problems, which often tend toward normal- ity after transformations and marginalization, and the results are derived as normal-theory approximations to exact Bayesian inference, conditional on the observed simulations."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726406"
                        ],
                        "name": "G. Cooper",
                        "slug": "G.-Cooper",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Cooper",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cooper"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 129
                            }
                        ],
                        "text": "The success of the exact methodshas become a reality despite the fact that computation in Bayesian networks is generallyNP-hard (Cooper 1990), i.e., there is often an exponential relationship between the num-ber of variables and the complexity of computation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 43363498,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ed5324bb3a19f0dcc2e90e482c06373b934fc28c",
            "isKey": false,
            "numCitedBy": 2047,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Computational-Complexity-of-Probabilistic-Using-Cooper",
            "title": {
                "fragments": [],
                "text": "The Computational Complexity of Probabilistic Inference Using Bayesian Belief Networks"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109352679"
                        ],
                        "name": "Adrian F. M. Smith",
                        "slug": "Adrian-F.-M.-Smith",
                        "structuredName": {
                            "firstName": "Adrian",
                            "lastName": "Smith",
                            "middleNames": [
                                "F.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adrian F. M. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3264000"
                        ],
                        "name": "G. Roberts",
                        "slug": "G.-Roberts",
                        "structuredName": {
                            "firstName": "Gareth",
                            "lastName": "Roberts",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Roberts"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 294,
                                "start": 274
                            }
                        ],
                        "text": "\u2026alternatives to exact methods, since they are exible, easy to implement,and their computational complexity tends to scale manageably with the size of thenetworks under consideration (Gelfand & Smith 1990, Thomas, Spiegelhalter & Gilks1992, Gelman & Rubin 1992, Geyer 1992, Smith & Roberts 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 115772206,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "aed20302f003a751b1af4e40ace379b9fd255cc7",
            "isKey": false,
            "numCitedBy": 1708,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "The use of the Gibbs sampler for Bayesian computation is reviewed and illustrated in the context of some canonical examples. Other Markov chain Monte Carlo simulation methods are also briefly described, and comments are made on the advantages of sample-based approaches for Bayesian inference summaries"
            },
            "slug": "Bayesian-computation-via-the-gibbs-sampler-and-Smith-Roberts",
            "title": {
                "fragments": [],
                "text": "Bayesian computation via the gibbs sampler and related markov chain monte carlo methods (with discus"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707788"
                        ],
                        "name": "P. P. Shenoy",
                        "slug": "P.-P.-Shenoy",
                        "structuredName": {
                            "firstName": "Prakash",
                            "lastName": "Shenoy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. P. Shenoy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145500409"
                        ],
                        "name": "G. Shafer",
                        "slug": "G.-Shafer",
                        "structuredName": {
                            "firstName": "Glenn",
                            "lastName": "Shafer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Shafer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 34413970,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "13976cfe3be7e0873fa9814ac5c08cf27bfa91f1",
            "isKey": false,
            "numCitedBy": 675,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe an abstract framework and axioms under which exact local computation of marginals is possible. The primitive objects of the framework are variables and valuations. The primitive operators of the framework are combination and marginalization. These operate on valuations. We state three axioms for these operators and we derive the possibility of local computation from the axioms. Next, we describe a propagation scheme for computing marginals of a valuation when we have a factorization of the valuation on a hypertree. Finally we show how the problem of computing marginals of joint probability distributions and joint belief functions fits the general framework."
            },
            "slug": "Axioms-for-probability-and-belief-function-Shenoy-Shafer",
            "title": {
                "fragments": [],
                "text": "Axioms for probability and belief-function proagation"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper describes an abstract framework and axioms under which exact local computation of marginals is possible and shows how the problem of computing marginals of joint probability distributions and joint belief functions fits the general framework."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1876131"
                        ],
                        "name": "C. Geyer",
                        "slug": "C.-Geyer",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Geyer",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Geyer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 272,
                                "start": 262
                            }
                        ],
                        "text": "\u2026alternatives to exact methods, since they are exible, easy to implement,and their computational complexity tends to scale manageably with the size of thenetworks under consideration (Gelfand & Smith 1990, Thomas, Spiegelhalter & Gilks1992, Gelman & Rubin 1992, Geyer 1992, Smith & Roberts 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 121738787,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0c6b0171fe26bb84e89c244e1f859ebdf86e6e45",
            "isKey": false,
            "numCitedBy": 1758,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Markov chain Monte Carlo using the Metropolis-Hastings algorithm is a general method for the simulation of stochastic processes having probability densities known up to a constant of proportionality. Despite recent advances in its theory, the practice has remained controversial. This article makes the case for basing all inference on one long run of the Markov chain and estimating the Monte Carlo error by standard nonparametric methods well-known in the time-series and operations research literature. In passing it touches on the Kipnis-Varadhan central limit theorem for reversible Markov chains, on some new variance estimators, on judging the relative efficiency of competing Monte Carlo schemes, on methods for constructing more rapidly mixing Markov chains and on diagnostics for Markov chain Monte Carlo."
            },
            "slug": "Practical-Markov-Chain-Monte-Carlo-Geyer",
            "title": {
                "fragments": [],
                "text": "Practical Markov Chain Monte Carlo"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The case is made for basing all inference on one long run of the Markov chain and estimating the Monte Carlo error by standard nonparametric methods well-known in the time-series and operations research literature."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050895"
                        ],
                        "name": "S. Lauritzen",
                        "slug": "S.-Lauritzen",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Lauritzen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lauritzen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17051088,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a87f270ac2c8420db2669e5e12abb6aff0755115",
            "isKey": false,
            "numCitedBy": 493,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract A scheme is presented for modeling and local computation of exact probabilities, means, and variances for mixed qualitative and quantitative variables. The models assume that the conditional distribution of the quantitative variables, given the qualitative, is multivariate Gaussian. The computational architecture is set up by forming a tree of belief universes, and the calculations are then performed by local message passing between universes. The asymmetry between the quantitative and qualitative variables sets some additional limitations for the specification and propagation structure. Approximate methods when these are not appropriately fulfilled are sketched. It has earlier been shown how to exploit the local structure in the specification of a discrete probability model for fast and efficient computation, thereby paving the way for exploiting probability-based models as parts of realistic systems for planning and decision support. The purpose of this article is to extend this computational s..."
            },
            "slug": "Propagation-of-Probabilities,-Means,-and-Variances-Lauritzen",
            "title": {
                "fragments": [],
                "text": "Propagation of Probabilities, Means, and Variances in Mixed Graphical Association Models"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The purpose of this article is to extend the local structure in the specification of a discrete probability model for fast and efficient computation, thereby paving the way for exploiting probability-based models as parts of realistic systems for planning and decision support."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2207788"
                        ],
                        "name": "N. Sheehan",
                        "slug": "N.-Sheehan",
                        "structuredName": {
                            "firstName": "Nuala",
                            "lastName": "Sheehan",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sheehan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152608414"
                        ],
                        "name": "A. Thomas",
                        "slug": "A.-Thomas",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Thomas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Thomas"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 241,
                                "start": 218
                            }
                        ],
                        "text": "While the above example demonstrates how quickly the performance of plain Gibbscan deteriorate, with only two alleles, it is at least true that the correct answer can beobtained if enough iterations are performed (see Sheehan & Thomas (1993))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 41071652,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0ed2482a14416581a7749f2ad09913246a09a760",
            "isKey": false,
            "numCitedBy": 103,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Techniques from image processing are now being considered for use in pedigree analysis. Although the method that we develop here was motivated by considering it as an analogue to the Gibbs sampler, we justify it independently using the ergodic theorem for aperiodic, irreducible, finite Markov chains. While it is trivial to show that aperiodicity holds, irreducibility is a more interesting condition. Proofs of irreducibility are provided for some special cases and counterexamples are provided for others. Where irreducibility does not hold, an alternative method using relaxed genetic parameters and rejection is recommended and justified."
            },
            "slug": "On-the-irreducibility-of-a-Markov-chain-defined-on-Sheehan-Thomas",
            "title": {
                "fragments": [],
                "text": "On the irreducibility of a Markov chain defined on a space of genotype configurations by a sampling scheme."
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "The method that was motivated by considering it as an analogue to the Gibbs sampler is justified using the ergodic theorem for aperiodic, irreducible, finite Markov chains and an alternative method using relaxed genetic parameters and rejection is recommended."
            },
            "venue": {
                "fragments": [],
                "text": "Biometrics"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729111"
                        ],
                        "name": "C. Cannings",
                        "slug": "C.-Cannings",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Cannings",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Cannings"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145414560"
                        ],
                        "name": "E. Thompson",
                        "slug": "E.-Thompson",
                        "structuredName": {
                            "firstName": "Elizabeth",
                            "lastName": "Thompson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Thompson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "104170765"
                        ],
                        "name": "H. H. Skolnick",
                        "slug": "H.-H.-Skolnick",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Skolnick",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. H. Skolnick"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 124974124,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9d85b152fa46e1d83b31f3afea73993e0ae785a0",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "It is frequently required in human genetics to calculate the likelihood of a model given the phenotypes of the individuals within some pedigree. Lange and Elston (1975) have recently presented a recursive method which enables this calculation to be made for, in their terminology, simple pedigrees; those in which at least one of each married couple is an original. The basic methodology of Lange and Elston is to successively reduce the size of the pedigree by collapsing the phenotypic information available on individuals onto parents, and hence to proceed recursively through the pedigree. We shall call this process 'peeling'. By generalizing the recursion so that information on individuals can be collapsed onto an offspring we allow pedigrees in which there are no loops (zero-loop), by introducing the notion of collapsing information onto a set of individuals jointly, we extend the method to pedigrees of arbitrary complexity. We note in passing that zero-loop pedigrees are a smaller class than non-inbred pedigrees. This and other aspects of the method will be treated more exhaustively elsewhere."
            },
            "slug": "The-recursive-derivation-of-likelihoods-on-complex-Cannings-Thompson",
            "title": {
                "fragments": [],
                "text": "The recursive derivation of likelihoods on complex pedigrees"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "By generalizing the recursion so that information on individuals can be collapsed onto an offspring the authors allow pedigrees in which there are no loops (zero-loop), and by introducing the notion of collapsing information onto a set of individuals jointly, the method is extended to pedigree of arbitrary complexity."
            },
            "venue": {
                "fragments": [],
                "text": "Advances in Applied Probability"
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46558286"
                        ],
                        "name": "S. K. Andersen",
                        "slug": "S.-K.-Andersen",
                        "structuredName": {
                            "firstName": "Stig",
                            "lastName": "Andersen",
                            "middleNames": [
                                "Kj\u00e6r"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. K. Andersen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34760449"
                        ],
                        "name": "K. Olesen",
                        "slug": "K.-Olesen",
                        "structuredName": {
                            "firstName": "Kristian",
                            "lastName": "Olesen",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Olesen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35191477"
                        ],
                        "name": "F. V. Jensen",
                        "slug": "F.-V.-Jensen",
                        "structuredName": {
                            "firstName": "Finn",
                            "lastName": "Jensen",
                            "middleNames": [
                                "Verner"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. V. Jensen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120177012"
                        ],
                        "name": "Frank Jensen",
                        "slug": "Frank-Jensen",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Jensen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frank Jensen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16250237,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "181b3b89260b8859d86bf641b7e2b2a4c2663e98",
            "isKey": false,
            "numCitedBy": 466,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Causal probabilistic networks have proved to be a useful knowledge representation tool for modelling domains where causal relations in a broad sense are a natural way of relating domain objects and where uncertainty is inherited in these relations. This paper outlines an implementation the HUGIN shell - for handling a domain model expressed by a causal probabilistic network. The only topological restriction imposed on the network is that, it must not contain any directed loops. The approach is illustrated step by step by solving a genetic breeding problem. A graph representation of the domain model is interactively created by using instances of the basic network components-- nodes and arcs--as building blocks. This structure, together with the quantitative relations between nodes and their immediate causes expressed as conditional probabilities, are automatically transformed into a tree structure, a junction tree. Here a computationally efficient and conceptually simple algebra of Bayesian belief universes supports incorporation of new evidence, propagation of information, and calculation of revised beliefs in the states of the nodes in the network. Finally, as an exam ple of a real world application, MUNIN an expert system for electromyography is discussed."
            },
            "slug": "HUGIN-A-Shell-for-Building-Bayesian-Belief-for-Andersen-Olesen",
            "title": {
                "fragments": [],
                "text": "HUGIN - A Shell for Building Bayesian Belief Universes for Expert Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper outlines an implementation the HUGIN shell - for handling a domain model expressed by a causal probabilistic network, and a computationally efficient and conceptually simple algebra of Bayesian belief universes supports incorporation of new evidence, propagation of information, and calculation of revised beliefs in the states of the nodes in the network."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2638279"
                        ],
                        "name": "C. Yiannoutsos",
                        "slug": "C.-Yiannoutsos",
                        "structuredName": {
                            "firstName": "Constantin",
                            "lastName": "Yiannoutsos",
                            "middleNames": [
                                "Theodore"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Yiannoutsos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2454055"
                        ],
                        "name": "A. Gelfand",
                        "slug": "A.-Gelfand",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Gelfand",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gelfand"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 67807879,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "19717ea1db4bbfb4a335e16a109f0d744d266c11",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : In formulating models for a complex system graphical representation is an effective tool. When the components of the system are viewed as random variables, directed graphical models detail the nature of the dependence among them. Moreover, if for each variable the conditional distribution is provided according to the graph, the joint distribution is uniquely determined. Natural questions arise about the static behavior of the system under such specification as well as its response to information (observed levels of some of the variables). Answers to these questions require the ability to calculate arbitrary marginal and conditional distributions. In complex cases (high dimensional structures) such calculations require high dimensional integrations and/or summations. Most of the work to date has taken advantage of properties of directed graphs to facilitate exact calculations but is limited with regard to distributional assumptions and feasible system size. Monte Carlo methods for such calculations can accommodate much larger system size with arbitrary dependence structure and distributional forms yielding approximations which can be as accurate as desired. It is the objective of this paper to detail such methodology. An illustration is provided using a diagnostic system for congenital heart disease in neonates."
            },
            "slug": "Simulation-Approaches-for-Calculations-in-Directed-Yiannoutsos-Gelfand",
            "title": {
                "fragments": [],
                "text": "Simulation Approaches for Calculations in Directed Graphical Models"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "The objective of this paper is to detail methodology of Monte Carlo methods for formulating models for complex system graphical representation using a diagnostic system for congenital heart disease in neonates."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729111"
                        ],
                        "name": "C. Cannings",
                        "slug": "C.-Cannings",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Cannings",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Cannings"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057177943"
                        ],
                        "name": "E. Thompson",
                        "slug": "E.-Thompson",
                        "structuredName": {
                            "firstName": "E.",
                            "lastName": "Thompson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Thompson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49933092"
                        ],
                        "name": "M. Skolnick",
                        "slug": "M.-Skolnick",
                        "structuredName": {
                            "firstName": "M",
                            "lastName": "Skolnick",
                            "middleNames": [
                                "H"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Skolnick"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120853189,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0b12ebb3801710ed3d15b5c97a8761640a0a1a0",
            "isKey": false,
            "numCitedBy": 267,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The calculation of probabilities on pedigrees of arbitrary complexity is discussed for a basic model of transmission and penetrance (encompassing Mendelian inheritance, and certain environmental influences). The structure of pedigrees, and the types of loops occurring, is discussed. Some results in graph theory are obtained and, using these, a recurrence relation derived for certain probabilities. The recursive procedure enables the successive peeling off of certain members of the pedigree, and the condensation of the information on those individuals into a function on a subset of those remaining. The underlying theory is set out, and examples given of the utilization of the resulting algorithm. PEDIGREE; PROBABILITY; LOOPS; PEELING; GRAPH; OUSIOTYPE; GENETICS"
            },
            "slug": "Probability-functions-on-complex-pedigrees-Cannings-Thompson",
            "title": {
                "fragments": [],
                "text": "Probability functions on complex pedigrees"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The calculation of probabilities on pedigrees of arbitrary complexity is discussed for a basic model of transmission and penetrance (encompassing Mendelian inheritance, and certain environmental influences)."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050895"
                        ],
                        "name": "S. Lauritzen",
                        "slug": "S.-Lauritzen",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Lauritzen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lauritzen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144845491"
                        ],
                        "name": "A. Dawid",
                        "slug": "A.-Dawid",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Dawid",
                            "middleNames": [
                                "Philip"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dawid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144238498"
                        ],
                        "name": "B. N. Larsen",
                        "slug": "B.-N.-Larsen",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Larsen",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. N. Larsen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "74208271"
                        ],
                        "name": "H.-G. Leimer",
                        "slug": "H.-G.-Leimer",
                        "structuredName": {
                            "firstName": "H.-G.",
                            "lastName": "Leimer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H.-G. Leimer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 20450895,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f78884604e3fb89b1fb24d2a9403191dc9e63bd3",
            "isKey": false,
            "numCitedBy": 572,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate directed Markov fields over finite graphs without positivity assumptions on the densities involved. A criterion for conditional independence of two groups of variables given a third is given and named as the directed, global Markov property. We give a simple proof of the fact that the directed, local Markov property and directed, global Markov property are equivalent and \u2013 in the case of absolute continuity w. r. t. a product measure \u2013 equivalent to the recursive factorization of densities. It is argued that our criterion is easy to use, it is sharper than that given by Kiiveri, Speed, and Carlin and equivalent to that of Pearl. It follows that our criterion cannot be sharpened."
            },
            "slug": "Independence-properties-of-directed-markov-fields-Lauritzen-Dawid",
            "title": {
                "fragments": [],
                "text": "Independence properties of directed markov fields"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "A criterion for conditional independence of two groups of variables given a third is given and named as the directed, global Markov property and it is argued that this criterion is easy to use, it is sharper than that given by Kiiveri, Speed, and Carlin and equivalent to that of Pearl."
            },
            "venue": {
                "fragments": [],
                "text": "Networks"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49504816"
                        ],
                        "name": "A. Kong",
                        "slug": "A.-Kong",
                        "structuredName": {
                            "firstName": "Augustine",
                            "lastName": "Kong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144678493"
                        ],
                        "name": "D. Rao",
                        "slug": "D.-Rao",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Rao",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6525814"
                        ],
                        "name": "G. Vogler",
                        "slug": "G.-Vogler",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Vogler",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Vogler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 25106583,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8c9ad8ef0cae470322bc301d2ab63fee07dd61f0",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Traditional methods for computing linkage likelihoods can be infeasible for data that involve considerable inbreeding and missing information, characteristics of large pedigrees affected by rare recessive diseases. For this type of data, we propose alternative procedures that can efficiently provide good approximates of linkage likelihoods. These approximation procedures are constructed based on a new mathematical representation of the multiloci inheritance model. Instead of representing each person by a single variable, the genotype, the disease gene alleles, and the marker alleles are taken as separate variables. This allows us to break down the computations into manageable pieces. This new representation is also potentially useful for multipoint mapping."
            },
            "slug": "Efficient-methods-for-computing-linkage-likelihoods-Kong-Rao",
            "title": {
                "fragments": [],
                "text": "Efficient methods for computing linkage likelihoods of recessive diseases in inbred pedigrees"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "This work proposes alternative procedures that can efficiently provide good approximates of linkage likelihoods for data that involve considerable inbreeding and missing information, characteristics of large pedigrees affected by rare recessive diseases."
            },
            "venue": {
                "fragments": [],
                "text": "Genetic epidemiology"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "67046059"
                        ],
                        "name": "J. Ott",
                        "slug": "J.-Ott",
                        "structuredName": {
                            "firstName": "Jurg",
                            "lastName": "Ott",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ott"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 169
                            }
                        ],
                        "text": "The approach applied to simulate a component, Ei, is based on the random prop-agation variant of exact local computations in a junction tree (Ploughman & Boehnke6\n1989, Ott 1989, Kong 1991, Dawid 1992)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 25410900,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "daea8da5eb30670fe718f584daf1289c9a9e083b",
            "isKey": false,
            "numCitedBy": 515,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "In human linkage analysis, many statistical problems without analytical solution could be solved by ad hoc Monte Carlo procedures were efficient computer-simulation methods available for members of family pedigrees. In this paper, a general method is described for randomly generating genotypes at one or more marker loci, given observed phenotypes at loci linked among themselves and with the markers. The method is based on a well-known expansion of the multivariate probability of genotypes, given phenotypes, into a product of conditional univariate probabilities that may be viewed as corresponding to conditionally independent univariate random variables. This representation allows a recursive evaluation of the univariate probabilities that can be implemented in a surprisingly simple manner by carrying out successive \"risk calculations\" with respect to marker genotypes, given observed phenotypes and marker genotypes already generated. Potential applications to various unresolved problems are discussed. The method is applied to 28 published families analyzed for genetic linkage between hereditary motor and sensory neuropathy I and the Duffy (FY) blood group locus and confirms heterogeneity of hereditary motor and sensory neuropathy I. An implementation of the simulation methods developed in the LINKAGE program package will be available later in 1989."
            },
            "slug": "Computer-simulation-methods-in-human-linkage-Ott",
            "title": {
                "fragments": [],
                "text": "Computer-simulation methods in human linkage analysis."
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A general method is described for randomly generating genotypes at one or more marker loci, given observed phenotypes at loci linked among themselves and with the markers, based on a well-known expansion of the multivariate probability of genotypes, given phenotypes, into a product of conditional univariate probabilities."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2122942"
                        ],
                        "name": "B. Ripley",
                        "slug": "B.-Ripley",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Ripley",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Ripley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 85
                            }
                        ],
                        "text": "Their relianceon pseudorandomnumber generators may also to some extent be a problem (Ripley 1987)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6151205,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a4180abb06c3e6931474c4a3e0ff079d2d5a0382",
            "isKey": false,
            "numCitedBy": 2209,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "One fifth (4 of 20) of the research articles published in the Journal of Educational Statistics in 1988 include simulation studies that justify or illustrate the authors' conclusions. A similar fraction (6 of 33) of the articles in the 1988 volume of Psychometrika include simulations; comparable proportions could be expected in other journals at the boundary of theoretical statistics and social/psychological applications. Due in part to the complexity of the problems tackled today and in part to the availability of cheap, powerful computing\u2014by no means independent influences\u2014simulation and Monte Carlo methods have become both necessary and practical tools for statisticians and applied workers in quantitative areas of education and psychology. Simulation has become popular\u2014not only in the quantitative social sciences, but in all of the mathematical sciences from physics to operations research to number theory\u2014because it is almost always easy to do. This ease of use makes the simulation experimenter vulnerable to two common pitfalls. Selection of the basic source of \"random numbers\" is often passive: Whatever is available in the computer's standard subroutine library is used. However, the fact that a pseudo-random number generator appears in a popular software package or operating system is hardly reason to trust it, as is shown by the infamous RANDU generator, once popular on IBM mainframes and PDP mini-computers, and by the generators burned into RAM on today's PCs. Simulation design and reporting also deserve special care. Some attempt must be made to assess the accuracy of the simulation estimates: One should accurately estimate and report SE (6) as well as 6. In addition, enough detail should be reported that the interested reader can replicate the study and check the results, just as with other experiments. Yet these considerations are also easy to overlook. Brian D. Ripley's Stochastic Simulation is a short, yet ambitious, survey of modern simulation techniques. Three themes run throughout the book. First, one shoud not take basic simulation subroutines for granted, especially on minior microcomputers where they tend to be poor implementations, implementations of poor algorithms, or both. Second, design of experiments, or variance reduction as it is known in this field, deserves greater consideration. Third, modern methods make it possible to simulate and analyze processes that are dependent over time, and using such processes opens the door to new simulation techniques, such as simulated annealing in optimization. Ripley intends this book to be a \"comprehensive guide,\" and it is indeed most accurately described as a researcher's handbook with examples and"
            },
            "slug": "Stochastic-simulation-Ripley",
            "title": {
                "fragments": [],
                "text": "Stochastic simulation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Brian D. Ripley's Stochastic Simulation is a short, yet ambitious, survey of modern simulation techniques, and three themes run throughout the book."
            },
            "venue": {
                "fragments": [],
                "text": "Wiley series in probability and mathematical statistics : applied probability and statistics"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3194361"
                        ],
                        "name": "S. Geman",
                        "slug": "S.-Geman",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Geman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707642"
                        ],
                        "name": "D. Geman",
                        "slug": "D.-Geman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5837272,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "459b30a9a960080f3b313e41886b1aa0e51e882c",
            "isKey": false,
            "numCitedBy": 18710,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "We make an analogy between images and statistical mechanics systems. Pixel gray levels and the presence and orientation of edges are viewed as states of atoms or molecules in a lattice-like physical system. The assignment of an energy function in the physical system determines its Gibbs distribution. Because of the Gibbs distribution, Markov random field (MRF) equivalence, this assignment also determines an MRF image model. The energy function is a more convenient and natural mechanism for embodying picture attributes than are the local characteristics of the MRF. For a range of degradation mechanisms, including blurring, nonlinear deformations, and multiplicative or additive noise, the posterior distribution is an MRF with a structure akin to the image model. By the analogy, the posterior distribution defines another (imaginary) physical system. Gradual temperature reduction in the physical system isolates low energy states (``annealing''), or what is the same thing, the most probable states under the Gibbs distribution. The analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations. The result is a highly parallel ``relaxation'' algorithm for MAP estimation. We establish convergence properties of the algorithm and we experiment with some simple pictures, for which good restorations are obtained at low signal-to-noise ratios."
            },
            "slug": "Stochastic-Relaxation,-Gibbs-Distributions,-and-the-Geman-Geman",
            "title": {
                "fragments": [],
                "text": "Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "The analogy between images and statistical mechanics systems is made and the analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations, creating a highly parallel ``relaxation'' algorithm for MAP estimation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5078961"
                        ],
                        "name": "L. Ploughman",
                        "slug": "L.-Ploughman",
                        "structuredName": {
                            "firstName": "Lynn",
                            "lastName": "Ploughman",
                            "middleNames": [
                                "Marie"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Ploughman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48619776"
                        ],
                        "name": "M. Boehnke",
                        "slug": "M.-Boehnke",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Boehnke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Boehnke"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 21189031,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "4da2814f27ab21fbb79ee2ffe6835e48f7130690",
            "isKey": false,
            "numCitedBy": 241,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Many genetic traits have complex modes of inheritance; they may exhibit incomplete or age-dependent penetrance or fail to show any clear Mendelian inheritance pattern. As primary linkage maps for the human genome near completion, it is becoming increasingly possible to map these traits. Prior to undertaking a linkage study, it is important to consider whether the pedigrees available for the proposed study are likely to provide sufficient information to demonstrate linkage, assuming a linked marker is tested. In the current paper, we describe a computer simulation method to estimate the power of a proposed study to detect linkage for a complex genetic trait, given a hypothesized genetic model for the trait. Our method simulates trait locus genotypes consistent with observed trait phenotypes, in such a way that the probability to detect linkage can be estimated by sample statistics of the maximum lod score distribution. The method uses terms available when calculating the likelihood of the trait phenotypes for the pedigree and is applicable to any trait determined by one or a few genetic loci; individual-specific environmental effects can also be dealt with. Our method provides an objective answer to the question, Will these pedigrees provide sufficient information to map this complex genetic trait?"
            },
            "slug": "Estimating-the-power-of-a-proposed-linkage-study-a-Ploughman-Boehnke",
            "title": {
                "fragments": [],
                "text": "Estimating the power of a proposed linkage study for a complex genetic trait."
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A computer simulation method is described to estimate the power of a proposed study to detect linkage for a complex genetic trait, given a hypothesized genetic model for the trait."
            },
            "venue": {
                "fragments": [],
                "text": "American journal of human genetics"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050895"
                        ],
                        "name": "S. Lauritzen",
                        "slug": "S.-Lauritzen",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Lauritzen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lauritzen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48616434"
                        ],
                        "name": "D. Spiegelhalter",
                        "slug": "D.-Spiegelhalter",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Spiegelhalter",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Spiegelhalter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 144
                            }
                        ],
                        "text": "\u2026ingraphical models (Bayesian networks) of complex stochastic systems (Cannings, Thomp-son & Skolnick 1976, Cannings, Thompson & Skolnick 1978, Lauritzen & Spiegelhalter1988, Shenoy & Shafer 1990, Jensen, Lauritzen & Olesen 1990, Dawid 1992, Lauritzen1\n1992, Spiegelhalter, Dawid, Lauritzen &\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 89
                            }
                        ],
                        "text": "In the present paper, we shall refer to an object-oriented version of the exact methodof Lauritzen & Spiegelhalter (1988) which has been described by Jensen et al. (1990)and implemented in the expert-system shell HUGIN (Andersen, Olesen, Jensen & Jensen1989)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 58792451,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0a3767909649cf31d32e087693d93171af28ebe0",
            "isKey": false,
            "numCitedBy": 4303,
            "numCiting": 126,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Local-computations-with-probabilities-on-graphical-Lauritzen-Spiegelhalter",
            "title": {
                "fragments": [],
                "text": "Local computations with probabilities on graphical structures and their application to expert systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 145
                            }
                        ],
                        "text": "A more general forward-sampling procedure, which is4\ncapable of handling non-categorical evidence is known under the name of importancesampling (Yiannoutsos & Gelfand 1994).2.2.2 Gibbs SamplingWhen evidence is available, importance sampling (of which logic sampling is a specialcase) is very ine\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Simulation approaches for calculations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145414560"
                        ],
                        "name": "E. Thompson",
                        "slug": "E.-Thompson",
                        "structuredName": {
                            "firstName": "Elizabeth",
                            "lastName": "Thompson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Thompson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145414560"
                        ],
                        "name": "E. Thompson",
                        "slug": "E.-Thompson",
                        "structuredName": {
                            "firstName": "Elizabeth",
                            "lastName": "Thompson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Thompson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 134
                            }
                        ],
                        "text": "If the frequency of N in thepopulation is p, and the frequency of n is q = 1-p, and Hardy-Weinberg proportions are8\nassumed (see e.g. Thompson (1986)), the prior probability distribution of the genotypesof any founder, A, is P(A) = (p2; 2pq;q2)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 0
                            }
                        ],
                        "text": "Thompson (1986)), the prior probability distribution of the genotypes of any founder, A, is P(A) = (p2; 2pq;q2)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 203839767,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "9396c78c9681c4b97c5e9b1d482eb25d382e22cf",
            "isKey": false,
            "numCitedBy": 121,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Pedigree-Analysis-in-Human-Genetics-Thompson-Thompson",
            "title": {
                "fragments": [],
                "text": "Pedigree Analysis in Human Genetics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2932960"
                        ],
                        "name": "Ross D. Shachter",
                        "slug": "Ross-D.-Shachter",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Shachter",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross D. Shachter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46558286"
                        ],
                        "name": "S. K. Andersen",
                        "slug": "S.-K.-Andersen",
                        "structuredName": {
                            "firstName": "Stig",
                            "lastName": "Andersen",
                            "middleNames": [
                                "Kj\u00e6r"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. K. Andersen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679873"
                        ],
                        "name": "Peter Szolovits",
                        "slug": "Peter-Szolovits",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Szolovits",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Szolovits"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120190500,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1dfb7bf15fd662f49f6de261e556b41ab3b3f348",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-equivalence-of-exact-methods-for-probabilistic-Shachter-Andersen",
            "title": {
                "fragments": [],
                "text": "The equivalence of exact methods for probabilistic inference on belief networks"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35191477"
                        ],
                        "name": "F. V. Jensen",
                        "slug": "F.-V.-Jensen",
                        "structuredName": {
                            "firstName": "Finn",
                            "lastName": "Jensen",
                            "middleNames": [
                                "Verner"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. V. Jensen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050895"
                        ],
                        "name": "S. Lauritzen",
                        "slug": "S.-Lauritzen",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Lauritzen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lauritzen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34760449"
                        ],
                        "name": "K. Olesen",
                        "slug": "K.-Olesen",
                        "structuredName": {
                            "firstName": "Kristian",
                            "lastName": "Olesen",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Olesen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 150
                            }
                        ],
                        "text": "In the present paper, we shall refer to an object-oriented version of the exact methodof Lauritzen & Spiegelhalter (1988) which has been described by Jensen et al. (1990)and implemented in the expert-system shell HUGIN (Andersen, Olesen, Jensen & Jensen1989)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 239,
                                "start": 221
                            }
                        ],
                        "text": "The present paper suggests and evaluates a variant of Gibbs sampling (Geman &Geman 1984) involving simultaneous sampling of sets of variables using the junction treearchitecture for exact local computations (Jensen 1988, Jensen et al. 1990, Dawid 1992)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 53880385,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb75e5a3b46ec37a72922c706acd87ebab35b666",
            "isKey": false,
            "numCitedBy": 763,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Bayesian-updating-in-causal-probabilistic-networks-Jensen-Lauritzen",
            "title": {
                "fragments": [],
                "text": "Bayesian updating in causal probabilistic networks by local computations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bayesian computation via the Gibbs samplerand related Markov chain Monte Carlo methods"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Royal StatisticalSociety , Series B"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 184
                            }
                        ],
                        "text": "\u2026alternatives to exact methods, since they are exible, easy to implement,and their computational complexity tends to scale manageably with the size of thenetworks under consideration (Gelfand & Smith 1990, Thomas, Spiegelhalter & Gilks1992, Gelman & Rubin 1992, Geyer 1992, Smith & Roberts 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Sampling-based approaches to calculating"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 208
                            }
                        ],
                        "text": "The present paper suggests and evaluates a variant of Gibbs sampling (Geman &Geman 1984) involving simultaneous sampling of sets of variables using the junction treearchitecture for exact local computations (Jensen 1988, Jensen et al. 1990, Dawid 1992)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 287,
                                "start": 276
                            }
                        ],
                        "text": "\u2026Andersen & Szolovits (1991) showed that all exact methods for belief updatingin Bayesian networks can be viewed as variations on a single, general algorithm involvingclustering of variables, thus in e ect creating a secondary structure, which is often calleda junction tree (Jensen 1988)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 327,
                                "start": 314
                            }
                        ],
                        "text": "1 Exact Local Computations Shachter, Andersen & Szolovits (1991) showed that all exact methods for belief updating in Bayesian networks can be viewed as variations on a single, general algorithm involving clustering of variables, thus in e ect creating a secondary structure, which is often called a junction tree (Jensen 1988)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Junction trees and decomposable hypergraphs"
            },
            "venue": {
                "fragments": [],
                "text": "Research report,"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "BUGS: A program"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Probability functions oncomplex pedigrees"
            },
            "venue": {
                "fragments": [],
                "text": "Advances in Applied Probability"
            },
            "year": 1978
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "BUGS: A program to perform Bayesian inference using Gibbs sampling"
            },
            "venue": {
                "fragments": [],
                "text": "BUGS: A program to perform Bayesian inference using Gibbs sampling"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bayesiananalysis in expert systems ( with discussion )"
            },
            "venue": {
                "fragments": [],
                "text": "Statistical Science"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Computer-simulation methods in linkage analysis, Proceeding of the National Academy of Science"
            },
            "venue": {
                "fragments": [],
                "text": "Computer-simulation methods in linkage analysis, Proceeding of the National Academy of Science"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 333,
                                "start": 323
                            }
                        ],
                        "text": "Stochastic simulation techniques (Monte-Carlo methods) have thus become increas-ingly popular alternatives to exact methods, since they are exible, easy to implement,and their computational complexity tends to scale manageably with the size of thenetworks under consideration (Gelfand & Smith 1990, Thomas, Spiegelhalter & Gilks1992, Gelman & Rubin 1992, Geyer 1992, Smith & Roberts 1993)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 260,
                                "start": 241
                            }
                        ],
                        "text": "\u2026alternatives to exact methods, since they are exible, easy to implement,and their computational complexity tends to scale manageably with the size of thenetworks under consideration (Gelfand & Smith 1990, Thomas, Spiegelhalter & Gilks1992, Gelman & Rubin 1992, Geyer 1992, Smith & Roberts 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Inference from iterative simulation using single andmultiple sequences ( with discussion )"
            },
            "venue": {
                "fragments": [],
                "text": "Statistical Science"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The equivalence of exact meth"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 333,
                                "start": 323
                            }
                        ],
                        "text": "Stochastic simulation techniques (Monte-Carlo methods) have thus become increas-ingly popular alternatives to exact methods, since they are exible, easy to implement,and their computational complexity tends to scale manageably with the size of thenetworks under consideration (Gelfand & Smith 1990, Thomas, Spiegelhalter & Gilks1992, Gelman & Rubin 1992, Geyer 1992, Smith & Roberts 1993)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 260,
                                "start": 241
                            }
                        ],
                        "text": "\u2026alternatives to exact methods, since they are exible, easy to implement,and their computational complexity tends to scale manageably with the size of thenetworks under consideration (Gelfand & Smith 1990, Thomas, Spiegelhalter & Gilks1992, Gelman & Rubin 1992, Geyer 1992, Smith & Roberts 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Inference from iterative simulation using single and multiple sequences (with discussion)"
            },
            "venue": {
                "fragments": [],
                "text": "Statistical Science"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "BUGS : A program to performBayesian inference using Gibbs sampling"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Correlation structure and convergence rate of the gibbs sampler with applications to the comparisons of estimators and augmentation schemes"
            },
            "venue": {
                "fragments": [],
                "text": "Correlation structure and convergence rate of the gibbs sampler with applications to the comparisons of estimators and augmentation schemes"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 144
                            }
                        ],
                        "text": "\u2026ingraphical models (Bayesian networks) of complex stochastic systems (Cannings, Thomp-son & Skolnick 1976, Cannings, Thompson & Skolnick 1978, Lauritzen & Spiegelhalter1988, Shenoy & Shafer 1990, Jensen, Lauritzen & Olesen 1990, Dawid 1992, Lauritzen1\n1992, Spiegelhalter, Dawid, Lauritzen &\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 89
                            }
                        ],
                        "text": "In the present paper, we shall refer to an object-oriented version of the exact methodof Lauritzen & Spiegelhalter (1988) which has been described by Jensen et al. (1990)and implemented in the expert-system shell HUGIN (Andersen, Olesen, Jensen & Jensen1989)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Local computations with probabilities on"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The recursive derivation oflikelihoods on complex pedigrees"
            },
            "venue": {
                "fragments": [],
                "text": "Advances in Applied Probability"
            },
            "year": 1976
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 241,
                                "start": 218
                            }
                        ],
                        "text": "While the above example demonstrates how quickly the performance of plain Gibbscan deteriorate, with only two alleles, it is at least true that the correct answer can beobtained if enough iterations are performed (see Sheehan & Thomas (1993))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On the irreducibility of a Markov chain de ned on"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "HUGIN | a shell"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 179
                            }
                        ],
                        "text": "The approach applied to simulate a component, Ei, is based on the random prop-agation variant of exact local computations in a junction tree (Ploughman & Boehnke6\n1989, Ott 1989, Kong 1991, Dawid 1992)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "E \u000e cient methods for computing linkage likelihoods of recessive diseasesin inbred pedigrees"
            },
            "venue": {
                "fragments": [],
                "text": "Genetic Epidemiology"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Correlation structure and convergence rate"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Probability functions on"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 179
                            }
                        ],
                        "text": "The approach applied to simulate a component, Ei, is based on the random prop-agation variant of exact local computations in a junction tree (Ploughman & Boehnke6\n1989, Ott 1989, Kong 1991, Dawid 1992)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 110
                            }
                        ],
                        "text": "For example, the only theoretical work, as far as we know, which studies the e ect of blocking is Liu, Wong & Kong (1992) and it only considers the case where the blocks (the E-sets) do not overlap."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "E cient methods for computing linkage likelihoods of recessive diseases"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bayesian analysis in expert systems (with discussion)"
            },
            "venue": {
                "fragments": [],
                "text": "Statistical Science"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 169
                            }
                        ],
                        "text": "The approach applied to simulate a component, Ei, is based on the random prop-agation variant of exact local computations in a junction tree (Ploughman & Boehnke6\n1989, Ott 1989, Kong 1991, Dawid 1992)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Computer - simulation methods in linkage analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Proceeding of theNational Academy of Science , USA"
            },
            "year": 1989
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 10,
            "methodology": 17
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 48,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/Blocking-Gibbs-sampling-in-very-large-probabilistic-Jensen-Kj\u00e6rulff/1354660aba6bbcadb569f684d5a309ae57f58a79?sort=total-citations"
}