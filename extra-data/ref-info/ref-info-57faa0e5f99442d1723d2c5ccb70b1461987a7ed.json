{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2849472"
                        ],
                        "name": "M. Kr\u00f6tzsch",
                        "slug": "M.-Kr\u00f6tzsch",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Kr\u00f6tzsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kr\u00f6tzsch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808632"
                        ],
                        "name": "Denny Vrande\u010di\u0107",
                        "slug": "Denny-Vrande\u010di\u0107",
                        "structuredName": {
                            "firstName": "Denny",
                            "lastName": "Vrande\u010di\u0107",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Denny Vrande\u010di\u0107"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1094218,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "54e8820e676fa597718e14a4f39c5040d022a6a7",
            "isKey": false,
            "numCitedBy": 684,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "Wikipedia is the world's largest collaboratively edited source of encyclopaedic knowledge. But its contents are barely machine-interpretable. Structural knowledge, e. g. about how concepts are interrelated, can neither be formally stated nor automatically processed. Also the wealth of numerical data is only available as plain text and thus can not be processed by its actual meaning.We provide an extension to be integrated in Wikipedia, that allows even casual users the typing of links between articles and the specification of typed data inside the articles. Wiki users profit from more specific ways of searching and browsing. Each page has an RDF export, that gives direct access to the formalised knowledge. This allows applications to use Wikipedia as a background knowledge base."
            },
            "slug": "Semantic-Wikipedia-Kr\u00f6tzsch-Vrande\u010di\u0107",
            "title": {
                "fragments": [],
                "text": "Semantic Wikipedia"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work provides an extension to be integrated in Wikipedia, that allows even casual users the typing of links between articles and the specification of typed data inside the articles, and gives direct access to the formalised knowledge."
            },
            "venue": {
                "fragments": [],
                "text": "WWW '06"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49484314"
                        ],
                        "name": "Y. Matsuo",
                        "slug": "Y.-Matsuo",
                        "structuredName": {
                            "firstName": "Yutaka",
                            "lastName": "Matsuo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Matsuo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144666118"
                        ],
                        "name": "M. Ishizuka",
                        "slug": "M.-Ishizuka",
                        "structuredName": {
                            "firstName": "Mitsuru",
                            "lastName": "Ishizuka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ishizuka"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8002825,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f3c53ec128034e170dd895072c1561521a6cf850",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "The exponential growth of Wikipedia recently attracts the attention of a large number of researchers and practitioners. One of the current challenge on Wikipedia is to make the encyclopedia processable for machines. In this paper, we deal with the problem of extracting relations between entities from Wikipedia's En- glish articles, which can straightforwardly be transformed into Semantic Web meta data. We propose a method to exploit syntactic and semantic information for relation extraction. In addition, our method can utilize the nature of Wikipedia to automatically obtain training data. The preliminary results of our experiments strongly support our hyperthesis that using information in higher level of description is better for relation extraction on Wikipedia and show that our method is promising for text understanding."
            },
            "slug": "Exploiting-Syntactic-and-Semantic-Information-for-Matsuo-Ishizuka",
            "title": {
                "fragments": [],
                "text": "Exploiting Syntactic and Semantic Information for Relation Extraction from Wikipedia"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The preliminary results of the experiments strongly support the hyperthesis that using information in higher level of description is better for relation extraction on Wikipedia and show that the proposed method is promising for text understanding."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741101"
                        ],
                        "name": "Oren Etzioni",
                        "slug": "Oren-Etzioni",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Etzioni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Etzioni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725561"
                        ],
                        "name": "Michael J. Cafarella",
                        "slug": "Michael-J.-Cafarella",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Cafarella",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Cafarella"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145612610"
                        ],
                        "name": "Doug Downey",
                        "slug": "Doug-Downey",
                        "structuredName": {
                            "firstName": "Doug",
                            "lastName": "Downey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Doug Downey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36445704"
                        ],
                        "name": "Ana-Maria Popescu",
                        "slug": "Ana-Maria-Popescu",
                        "structuredName": {
                            "firstName": "Ana-Maria",
                            "lastName": "Popescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ana-Maria Popescu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3296031"
                        ],
                        "name": "Tal Shaked",
                        "slug": "Tal-Shaked",
                        "structuredName": {
                            "firstName": "Tal",
                            "lastName": "Shaked",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tal Shaked"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144295318"
                        ],
                        "name": "S. Soderland",
                        "slug": "S.-Soderland",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Soderland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Soderland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780531"
                        ],
                        "name": "Daniel S. Weld",
                        "slug": "Daniel-S.-Weld",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Weld",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel S. Weld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3321874"
                        ],
                        "name": "A. Yates",
                        "slug": "A.-Yates",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Yates",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yates"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7162988,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "421151fa75e40dd86414215abf29d9f2c052a2e1",
            "isKey": false,
            "numCitedBy": 1230,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Unsupervised-named-entity-extraction-from-the-Web:-Etzioni-Cafarella",
            "title": {
                "fragments": [],
                "text": "Unsupervised named-entity extraction from the Web: An experimental study"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679784"
                        ],
                        "name": "Fabian M. Suchanek",
                        "slug": "Fabian-M.-Suchanek",
                        "structuredName": {
                            "firstName": "Fabian",
                            "lastName": "Suchanek",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fabian M. Suchanek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686448"
                        ],
                        "name": "Gjergji Kasneci",
                        "slug": "Gjergji-Kasneci",
                        "structuredName": {
                            "firstName": "Gjergji",
                            "lastName": "Kasneci",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gjergji Kasneci"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751591"
                        ],
                        "name": "G. Weikum",
                        "slug": "G.-Weikum",
                        "structuredName": {
                            "firstName": "Gerhard",
                            "lastName": "Weikum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Weikum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207163173,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "00a3f6924f90fcd77e6e7e6534b957a75d0ced07",
            "isKey": false,
            "numCitedBy": 3480,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "We present YAGO, a light-weight and extensible ontology with high coverage and quality. YAGO builds on entities and relations and currently contains more than 1 million entities and 5 million facts. This includes the Is-A hierarchy as well as non-taxonomic relations between entities (such as HASONEPRIZE). The facts have been automatically extracted from Wikipedia and unified with WordNet, using a carefully designed combination of rule-based and heuristic methods described in this paper. The resulting knowledge base is a major step beyond WordNet: in quality by adding knowledge about individuals like persons, organizations, products, etc. with their semantic relationships - and in quantity by increasing the number of facts by more than an order of magnitude. Our empirical evaluation of fact correctness shows an accuracy of about 95%. YAGO is based on a logically clean model, which is decidable, extensible, and compatible with RDFS. Finally, we show how YAGO can be further extended by state-of-the-art information extraction techniques."
            },
            "slug": "Yago:-a-core-of-semantic-knowledge-Suchanek-Kasneci",
            "title": {
                "fragments": [],
                "text": "Yago: a core of semantic knowledge"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "YAGO builds on entities and relations and currently contains more than 1 million entities and 5 million facts, which includes the Is-A hierarchy as well as non-taxonomic relations between entities (such as HASONEPRIZE)."
            },
            "venue": {
                "fragments": [],
                "text": "WWW '07"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3257930"
                        ],
                        "name": "Bill MacCartney",
                        "slug": "Bill-MacCartney",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "MacCartney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bill MacCartney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9925526,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4639cb3718e4eb698a0285548ed2bf23ad9908a9",
            "isKey": false,
            "numCitedBy": 179,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents the first use of a computational model of natural logic---a system of logical inference which operates over natural language---for textual inference. Most current approaches to the PASCAL RTE textual inference task achieve robustness by sacrificing semantic precision; while broadly effective, they are easily confounded by ubiquitous inferences involving monotonicity. At the other extreme, systems which rely on first-order logic and theorem proving are precise, but excessively brittle. This work aims at a middle way. Our system finds a low-cost edit sequence which transforms the premise into the hypothesis; learns to classify entailment relations across atomic edits; and composes atomic entailments into a top-level entailment judgment. We provide the first reported results for any system on the FraCaS test suite. We also evaluate on RTE3 data, and show that hybridizing an existing RTE system with our natural logic system yields significant performance gains."
            },
            "slug": "Natural-Logic-for-Textual-Inference-MacCartney-Manning",
            "title": {
                "fragments": [],
                "text": "Natural Logic for Textual Inference"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "This paper presents the first use of a computational model of natural logic---a system of logical inference which operates over natural language---for textual inference, and provides the first reported results for any system on the FraCaS test suite."
            },
            "venue": {
                "fragments": [],
                "text": "ACL-PASCAL@ACL"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145044578"
                        ],
                        "name": "S. Auer",
                        "slug": "S.-Auer",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Auer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Auer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144568027"
                        ],
                        "name": "Jens Lehmann",
                        "slug": "Jens-Lehmann",
                        "structuredName": {
                            "firstName": "Jens",
                            "lastName": "Lehmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jens Lehmann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1225534,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bd29c41f42d188e138fb27008df51bb59652b93c",
            "isKey": false,
            "numCitedBy": 261,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Wikis are established means for the collaborative authoring, versioning and publishing of textual articles. The Wikipedia project, for example, succeeded in creating the by far largest encyclopedia just on the basis of a wiki. Recently, several approaches have been proposed on how to extend wikis to allow the creation of structured and semantically enriched content. However, the means for creating semantically enriched structured content are already available and are, although unconsciously, even used by Wikipedia authors. In this article, we present a method for revealing this structured content by extracting information from template instances. We suggest ways to efficiently query the vast amount of extracted information (e.g. more than 8 million RDF statements for the English Wikipedia version alone), leading to astonishing query answering possibilities (such as for the title question). We analyze the quality of the extracted content, and propose strategies for quality improvements with just minor modifications of the wiki systems being currently used."
            },
            "slug": "What-Have-Innsbruck-and-Leipzig-in-Common-Semantics-Auer-Lehmann",
            "title": {
                "fragments": [],
                "text": "What Have Innsbruck and Leipzig in Common? Extracting Semantics from Wiki Content"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This article presents a method for revealing structured content by extracting information from template instances, and suggests ways to efficiently query the vast amount of extracted information, leading to astonishing query answering possibilities."
            },
            "venue": {
                "fragments": [],
                "text": "ESWC"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718798"
                        ],
                        "name": "E. Gabrilovich",
                        "slug": "E.-Gabrilovich",
                        "structuredName": {
                            "firstName": "Evgeniy",
                            "lastName": "Gabrilovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Gabrilovich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2309269"
                        ],
                        "name": "Shaul Markovitch",
                        "slug": "Shaul-Markovitch",
                        "structuredName": {
                            "firstName": "Shaul",
                            "lastName": "Markovitch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaul Markovitch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 991213,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fb8f6c5670755a7d282fb9322bc8439492ea052a",
            "isKey": false,
            "numCitedBy": 497,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "When humans approach the task of text categorization, they interpret the specific wording of the document in the much larger context of their background knowledge and experience. On the other hand, state-of-the-art information retrieval systems are quite brittle--they traditionally represent documents as bags of words, and are restricted to learning from individual word occurrences in the (necessarily limited) training set. For instance, given the sentence \"Wal-Mart supply chain goes real time\", how can a text categorization system know that Wal-Mart manages its stock with RFID technology? And having read that \"Ciprofloxacin belongs to the quinolones group\", how on earth can a machine know that the drug mentioned is an antibiotic produced by Bayer? In this paper we present algorithms that can do just that. We propose to enrich document representation through automatic use of a vast compendium of human knowledge--an encyclopedia. We apply machine learning techniques to Wikipedia, the largest encyclopedia to date, which surpasses in scope many conventional encyclopedias and provides a cornucopia of world knowledge. Each Wikipedia article represents a concept, and documents to be categorized are represented in the rich feature space of words and relevant Wikipedia concepts. Empirical results confirm that this knowledge-intensive representation brings text categorization to a qualitatively new level of performance across a diverse collection of datasets."
            },
            "slug": "Overcoming-the-Brittleness-Bottleneck-using-Text-Gabrilovich-Markovitch",
            "title": {
                "fragments": [],
                "text": "Overcoming the Brittleness Bottleneck using Wikipedia: Enhancing Text Categorization with Encyclopedic Knowledge"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is proposed to enrich document representation through automatic use of a vast compendium of human knowledge--an encyclopedia, and empirical results confirm that this knowledge-intensive representation brings text categorization to a qualitatively new level of performance across a diverse collection of datasets."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679784"
                        ],
                        "name": "Fabian M. Suchanek",
                        "slug": "Fabian-M.-Suchanek",
                        "structuredName": {
                            "firstName": "Fabian",
                            "lastName": "Suchanek",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fabian M. Suchanek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2077166952"
                        ],
                        "name": "de",
                        "slug": "de",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "de",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "de"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751591"
                        ],
                        "name": "G. Weikum",
                        "slug": "G.-Weikum",
                        "structuredName": {
                            "firstName": "Gerhard",
                            "lastName": "Weikum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Weikum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 211482502,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7e97c43a02fd7c8ce2c899ec477dcb7ac6e4c1f1",
            "isKey": false,
            "numCitedBy": 338,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We present YAGO, a light-weight and extensible ontology with high coverage and quality. YAGO builds on entities and relations and currently contains more than 1 million entities and 5 million facts. This includes the Is-A hierarchy as well as non-taxonomic relations between entities (such as hasWonPrize). The facts have been automatically extracted from Wikipedia and unified with WordNet, using a carefully designed combination of rule-based and heuristic methods described in this paper. The resulting knowledge base is a major step beyond WordNet: in quality by adding knowledge about individuals like persons, organizations, products, etc. with their semantic relationships \u2013 and in quantity by increasing the number of facts by more than an order of magnitude. Our empirical evaluation of fact correctness shows an accuracy of about 95%. YAGO is based on a logically clean model, which is decidable, extensible, and compatible with RDFS. Finally, we show how YAGO can be further extended by state-of-the-art information extraction techniques."
            },
            "slug": "Yago:-A-Core-of-Semantic-Knowledge-Unifying-WordNet-Suchanek-de",
            "title": {
                "fragments": [],
                "text": "Yago: A Core of Semantic Knowledge Unifying WordNet and Wikipedia"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "YAGO builds on entities and relations and currently contains more than 1 million entities and 5 million facts, which includes the Is-A hierarchy as well as non-taxonomic relations between entities (such as hasWonPrize)."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2413558"
                        ],
                        "name": "Rodrigo de Salvo Braz",
                        "slug": "Rodrigo-de-Salvo-Braz",
                        "structuredName": {
                            "firstName": "Rodrigo",
                            "lastName": "Braz",
                            "middleNames": [
                                "de",
                                "Salvo"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rodrigo de Salvo Braz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2469966"
                        ],
                        "name": "R. Girju",
                        "slug": "R.-Girju",
                        "structuredName": {
                            "firstName": "Roxana",
                            "lastName": "Girju",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Girju"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474158"
                        ],
                        "name": "Vasin Punyakanok",
                        "slug": "Vasin-Punyakanok",
                        "structuredName": {
                            "firstName": "Vasin",
                            "lastName": "Punyakanok",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vasin Punyakanok"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3149169"
                        ],
                        "name": "M. Sammons",
                        "slug": "M.-Sammons",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Sammons",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sammons"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2843460,
            "fieldsOfStudy": [
                "Philosophy",
                "Computer Science"
            ],
            "id": "41e07d21451df21dacda2fea6f90b53bf4b89b27",
            "isKey": false,
            "numCitedBy": 109,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Semantic entailment is the problem of determining if the meaning of a given sentence entails that of another. This is a fundamental problem in natural language understanding that provides a broad framework for studying language variability and has a large number of applications. This paper presents a principled approach to this problem that builds on inducing representations of text snippets into a hierarchical knowledge representation along with a sound optimization-based inferential mechanism that makes use of it to decide semantic entailment. A preliminary evaluation on the PASCAL text collection is presented."
            },
            "slug": "An-Inference-Model-for-Semantic-Entailment-in-Braz-Girju",
            "title": {
                "fragments": [],
                "text": "An Inference Model for Semantic Entailment in Natural Language"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper presents a principled approach to this problem that builds on inducing representations of text snippets into a hierarchical knowledge representation along with a sound optimization-based inferential mechanism that makes use of it to decide semantic entailment."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35707712"
                        ],
                        "name": "Steve Dill",
                        "slug": "Steve-Dill",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Dill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steve Dill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2098146"
                        ],
                        "name": "Nadav Eiron",
                        "slug": "Nadav-Eiron",
                        "structuredName": {
                            "firstName": "Nadav",
                            "lastName": "Eiron",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nadav Eiron"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060104135"
                        ],
                        "name": "David Gibson",
                        "slug": "David-Gibson",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Gibson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Gibson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2890298"
                        ],
                        "name": "D. Gruhl",
                        "slug": "D.-Gruhl",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Gruhl",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gruhl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145615125"
                        ],
                        "name": "R. Guha",
                        "slug": "R.-Guha",
                        "structuredName": {
                            "firstName": "Ramanathan",
                            "lastName": "Guha",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Guha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1779853"
                        ],
                        "name": "A. Jhingran",
                        "slug": "A.-Jhingran",
                        "structuredName": {
                            "firstName": "Anant",
                            "lastName": "Jhingran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Jhingran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143626870"
                        ],
                        "name": "T. Kanungo",
                        "slug": "T.-Kanungo",
                        "structuredName": {
                            "firstName": "Tapas",
                            "lastName": "Kanungo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanungo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145941159"
                        ],
                        "name": "S. Rajagopalan",
                        "slug": "S.-Rajagopalan",
                        "structuredName": {
                            "firstName": "Sridhar",
                            "lastName": "Rajagopalan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Rajagopalan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49365095"
                        ],
                        "name": "A. Tomkins",
                        "slug": "A.-Tomkins",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Tomkins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Tomkins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717630"
                        ],
                        "name": "J. Tomlin",
                        "slug": "J.-Tomlin",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Tomlin",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tomlin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118829"
                        ],
                        "name": "J. Zien",
                        "slug": "J.-Zien",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Zien",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Zien"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17741338,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f60ff1e240be1b1e74c164d0ef4fb2d67f0cbdc3",
            "isKey": false,
            "numCitedBy": 582,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes Seeker, a platform for large-scale text analytics, and SemTag, an application written on the platform to perform automated semantic tagging of large corpora. We apply SemTag to a collection of approximately 264 million web pages, and generate approximately 434 million automatically disambiguated semantic tags, published to the web as a label bureau providing metadata regarding the 434 million annotations. To our knowledge, this is the largest scale semantic tagging effort to date.We describe the Seeker platform, discuss the architecture of the SemTag application, describe a new disambiguation algorithm specialized to support ontological disambiguation of large-scale data, evaluate the algorithm, and present our final results with information about acquiring and making use of the semantic tags. We argue that automated large scale semantic tagging of ambiguous content can bootstrap and accelerate the creation of the semantic web."
            },
            "slug": "SemTag-and-seeker:-bootstrapping-the-semantic-web-Dill-Eiron",
            "title": {
                "fragments": [],
                "text": "SemTag and seeker: bootstrapping the semantic web via automated semantic annotation"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "It is argued that automated large scale semantic tagging of ambiguous content can bootstrap and accelerate the creation of the semantic web."
            },
            "venue": {
                "fragments": [],
                "text": "WWW '03"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2339397"
                        ],
                        "name": "Michele Banko",
                        "slug": "Michele-Banko",
                        "structuredName": {
                            "firstName": "Michele",
                            "lastName": "Banko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michele Banko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725561"
                        ],
                        "name": "Michael J. Cafarella",
                        "slug": "Michael-J.-Cafarella",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Cafarella",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Cafarella"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144295318"
                        ],
                        "name": "S. Soderland",
                        "slug": "S.-Soderland",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Soderland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Soderland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50452701"
                        ],
                        "name": "M. Broadhead",
                        "slug": "M.-Broadhead",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Broadhead",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Broadhead"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741101"
                        ],
                        "name": "Oren Etzioni",
                        "slug": "Oren-Etzioni",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Etzioni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Etzioni"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207169186,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "498bb0efad6ec15dd09d941fb309aa18d6df9f5f",
            "isKey": false,
            "numCitedBy": 2292,
            "numCiting": 148,
            "paperAbstract": {
                "fragments": [],
                "text": "Traditionally, Information Extraction (IE) has focused on satisfying precise, narrow, pre-specified requests from small homogeneous corpora (e.g., extract the location and time of seminars from a set of announcements). Shifting to a new domain requires the user to name the target relations and to manually create new extraction rules or hand-tag new training examples. This manual labor scales linearly with the number of target relations. This paper introduces Open IE (OIE), a new extraction paradigm where the system makes a single data-driven pass over its corpus and extracts a large set of relational tuples without requiring any human input. The paper also introduces TEXTRUNNER, a fully implemented, highly scalable OIE system where the tuples are assigned a probability and indexed to support efficient extraction and exploration via user queries. We report on experiments over a 9,000,000 Web page corpus that compare TEXTRUNNER with KNOWITALL, a state-of-the-art Web IE system. TEXTRUNNER achieves an error reduction of 33% on a comparable set of extractions. Furthermore, in the amount of time it takes KNOWITALL to perform extraction for a handful of pre-specified relations, TEXTRUNNER extracts a far broader set of facts reflecting orders of magnitude more relations, discovered on the fly. We report statistics on TEXTRUNNER\u2019s 11,000,000 highest probability tuples, and show that they contain over 1,000,000 concrete facts and over 6,500,000more abstract assertions."
            },
            "slug": "Open-Information-Extraction-from-the-Web-Banko-Cafarella",
            "title": {
                "fragments": [],
                "text": "Open Information Extraction from the Web"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Open IE (OIE), a new extraction paradigm where the system makes a single data-driven pass over its corpus and extracts a large set of relational tuples without requiring any human input, is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691993"
                        ],
                        "name": "E. Riloff",
                        "slug": "E.-Riloff",
                        "structuredName": {
                            "firstName": "Ellen",
                            "lastName": "Riloff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Riloff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068932662"
                        ],
                        "name": "J. Shepherd",
                        "slug": "J.-Shepherd",
                        "structuredName": {
                            "firstName": "Jessica",
                            "lastName": "Shepherd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shepherd"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1437,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "b3e9130ecab419f8267fccadf80c1ee2489be793",
            "isKey": false,
            "numCitedBy": 257,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Semantic knowledge can be a great asset to natural language processing systems, but it is usually hand-coded for each application. Although some semantic information is available in general-purpose knowledge bases such as WordNet and Cyc, many applications require domain-specific lexicons that represent words and categories for a particular topic. In this paper, we present a corpus-based method that can be used to build semantic lexicons for specific categories. The input to the system is a small set of seed words for a category and a representative text corpus. The output is a ranked list of words that are associated with the category. A user then reviews the top-ranked words and decides which ones should be entered in the semantic lexicon. In experiments with five categories, users typically found about 60 words per category in 10-15 minutes to build a core semantic lexicon."
            },
            "slug": "A-Corpus-Based-Approach-for-Building-Semantic-Riloff-Shepherd",
            "title": {
                "fragments": [],
                "text": "A Corpus-Based Approach for Building Semantic Lexicons"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper presents a corpus-based method that can be used to build semantic lexicons for specific categories using a small set of seed words for a category and a representative text corpus."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751287"
                        ],
                        "name": "C. Clarke",
                        "slug": "C.-Clarke",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Clarke",
                            "middleNames": [
                                "L.",
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Clarke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3114123"
                        ],
                        "name": "G. Cormack",
                        "slug": "G.-Cormack",
                        "structuredName": {
                            "firstName": "Gordon",
                            "lastName": "Cormack",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cormack"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2750485"
                        ],
                        "name": "T. Lynam",
                        "slug": "T.-Lynam",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Lynam",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lynam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 149
                            }
                        ],
                        "text": "Permission to make digital or hard copies of all or part of this work for personal or \nclassroom use is granted without fee provided that copies are not made or distributed for pro.t or commercial \nadvantage and that copies bear this notice and the full citation on the .rst page."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1579602,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "12fc6f855f58869cf81743b9be0df1380c17f4d0",
            "isKey": false,
            "numCitedBy": 252,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Our goal is to automatically answer brief factual questions of the form ``When was the Battle of Hastings?'' or ``Who wrote The Wind in the Willows?''. Since the answer to nearly any such question can now be found somewhere on the Web, the problem reduces to finding potential answers in large volumes of data and validating their accuracy. We apply a method for arbitrary passage retrieval to the first half of the problem and demonstrate that answer redundancy can be used to address the second half. The success of our approach depends on the idea that the volume of available Web data is large enough to supply the answer to most factual questions multiple times and in multiple contexts. A query is generated from a question and this query is used to select short passages that may contain the answer from a large collection of Web data. These passages are analyzed to identify candidate answers. The frequency of these candidates within the passages is used to ``vote'' for the most likely answer. The approach is experimentally tested on questions taken from the TREC-9 question-answering test collection. As an additional demonstration, the approach is extended to answer multiple choice trivia questions of the form typically asked in trivia quizzes and television game shows."
            },
            "slug": "Exploiting-redundancy-in-question-answering-Clarke-Cormack",
            "title": {
                "fragments": [],
                "text": "Exploiting redundancy in question answering"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A method for arbitrary passage retrieval is applied to answer brief factual questions of the form typically asked in trivia quizzes and television game shows and it is demonstrated that answer redundancy can be used to address the second half."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '01"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770962"
                        ],
                        "name": "A. Halevy",
                        "slug": "A.-Halevy",
                        "structuredName": {
                            "firstName": "Alon",
                            "lastName": "Halevy",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Halevy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741101"
                        ],
                        "name": "Oren Etzioni",
                        "slug": "Oren-Etzioni",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Etzioni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Etzioni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3030274"
                        ],
                        "name": "A. Doan",
                        "slug": "A.-Doan",
                        "structuredName": {
                            "firstName": "AnHai",
                            "lastName": "Doan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Doan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804315"
                        ],
                        "name": "Z. Ives",
                        "slug": "Z.-Ives",
                        "structuredName": {
                            "firstName": "Zachary",
                            "lastName": "Ives",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Ives"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2224716"
                        ],
                        "name": "J. Madhavan",
                        "slug": "J.-Madhavan",
                        "structuredName": {
                            "firstName": "Jayant",
                            "lastName": "Madhavan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Madhavan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2956720"
                        ],
                        "name": "Luke K. McDowell",
                        "slug": "Luke-K.-McDowell",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "McDowell",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke K. McDowell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3182988"
                        ],
                        "name": "I. Tatarinov",
                        "slug": "I.-Tatarinov",
                        "structuredName": {
                            "firstName": "Igor",
                            "lastName": "Tatarinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Tatarinov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 146
                            }
                        ],
                        "text": "\u2026Computer Science &#38; Engineering Department, \nUniversity of Washington, Seattle, WA, USA {wufei,weld}@cs.washington.edu ABSTRACT Berners-Lee s compelling \nvisionofa SemanticWebis hinderedby a chicken-and-egg problem, which can be best solved by a boot\u00adstrapping \nmethod creating enough\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8374016,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8d43a96e12a07b53014997f050005e09a62b7cef",
            "isKey": false,
            "numCitedBy": 104,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": "It has frequently been observed that most of the world\u2019s data lies outside database systems. The reason is that database systems focus on structured data, leaving the unstructured realm to others. The world of unstructured data has several very appealing properties, such as ease of authoring, querying and data sharing. In contrast, authoring, querying and sharing structured data require significant effort, albeit with the benefit of rich query languages and exact answers. We argue that in order to broaden the use of data management tools, we need a concerted effort to cross this structure chasm, by importing the attractive properties of the unstructured world into the structured one. As an initial effort in this direction, we introduce the REVERE System, which offers several mechanisms for crossing the structure chasm, and considers as its first application the chasm on the WWW. REVERE includes three innovations: (1) a data creation environment that entices people to structure data and enables them to do it rapidly; (2) a data sharing environment, based on a peer data management system, in which a web of data is created by establishing local mappings between schemas, and query answering is done over the transitive closure of these mappings; (3) a novel set of tools that are based on computing statistics over corpora of schemata and structured data. In a sense, we are trying to adapt the key techniques of the unstructured world, namely computing statistics over text coropra, into the world of structured data. We sketch how statistics computed over such corpora, which capture common term usage patterns, can be used to create tools for assisting in schema and mapping development. The initial application of REVERE focuses on creating a web of structured data from data that is usually stored in HTML web pages (e.g., personal information, course information,"
            },
            "slug": "Crossing-the-Structure-Chasm-Halevy-Etzioni",
            "title": {
                "fragments": [],
                "text": "Crossing the Structure Chasm"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The REVERE System is introduced, which offers several mechanisms for crossing the structure chasm, and considers as its first application the chasm on the WWW."
            },
            "venue": {
                "fragments": [],
                "text": "CIDR"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145612610"
                        ],
                        "name": "Doug Downey",
                        "slug": "Doug-Downey",
                        "structuredName": {
                            "firstName": "Doug",
                            "lastName": "Downey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Doug Downey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741101"
                        ],
                        "name": "Oren Etzioni",
                        "slug": "Oren-Etzioni",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Etzioni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Etzioni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144295318"
                        ],
                        "name": "S. Soderland",
                        "slug": "S.-Soderland",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Soderland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Soderland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 158
                            }
                        ],
                        "text": "Permission to make digital or hard copies of all or part of this work for personal or \nclassroom use is granted without fee provided that copies are not made or distributed for pro.t or commercial \nadvantage and that copies bear this notice and the full citation on the .rst page."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5311461,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "310cd6a39b0539193561148cd9897b1953fa8b28",
            "isKey": false,
            "numCitedBy": 221,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Unsupervised Information Extraction (UIE) is the task of extracting knowledge from text without using hand-tagged training examples. A fundamental problem for both UIE and supervised IE is assessing the probability that extracted information is correct. In massive corpora such as the Web, the same extraction is found repeatedly in different documents. How does this redundancy impact the probability of correctness? \n \nThis paper introduces a combinatorial \"balls-andurns\" model that computes the impact of sample size, redundancy, and corroboration from multiple distinct extraction rules on the probability that an extraction is correct. We describe methods for estimating the model's parameters in practice and demonstrate experimentally that for UIE the model's log likelihoods are 15 times better, on average, than those obtained by Pointwise Mutual Information (PMI) and the noisy-or model used in previous work. For supervised IE, the model's performance is comparable to that of Support Vector Machines, and Logistic Regression."
            },
            "slug": "A-Probabilistic-Model-of-Redundancy-in-Information-Downey-Etzioni",
            "title": {
                "fragments": [],
                "text": "A Probabilistic Model of Redundancy in Information Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A combinatorial \"balls-andurns\" model is introduced that computes the impact of sample size, redundancy, and corroboration from multiple distinct extraction rules on the probability that an extraction is correct."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718798"
                        ],
                        "name": "E. Gabrilovich",
                        "slug": "E.-Gabrilovich",
                        "structuredName": {
                            "firstName": "Evgeniy",
                            "lastName": "Gabrilovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Gabrilovich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2309269"
                        ],
                        "name": "Shaul Markovitch",
                        "slug": "Shaul-Markovitch",
                        "structuredName": {
                            "firstName": "Shaul",
                            "lastName": "Markovitch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaul Markovitch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5291693,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a9fee459ed211f53bfadef22e3ab774d0e927358",
            "isKey": false,
            "numCitedBy": 2319,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "Computing semantic relatedness of natural language texts requires access to vast amounts of common-sense and domain-specific world knowledge. We propose Explicit Semantic Analysis (ESA), a novel method that represents the meaning of texts in a high-dimensional space of concepts derived from Wikipedia. We use machine learning techniques to explicitly represent the meaning of any text as a weighted vector of Wikipedia-based concepts. Assessing the relatedness of texts in this space amounts to comparing the corresponding vectors using conventional metrics (e.g., cosine). Compared with the previous state of the art, using ESA results in substantial improvements in correlation of computed relatedness scores with human judgments: from r = 0.56 to 0.75 for individual words and from r = 0.60 to 0.72 for texts. Importantly, due to the use of natural concepts, the ESA model is easy to explain to human users."
            },
            "slug": "Computing-Semantic-Relatedness-Using-Explicit-Gabrilovich-Markovitch",
            "title": {
                "fragments": [],
                "text": "Computing Semantic Relatedness Using Wikipedia-based Explicit Semantic Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "This work proposes Explicit Semantic Analysis (ESA), a novel method that represents the meaning of texts in a high-dimensional space of concepts derived from Wikipedia that results in substantial improvements in correlation of computed relatedness scores with human judgments."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3030274"
                        ],
                        "name": "A. Doan",
                        "slug": "A.-Doan",
                        "structuredName": {
                            "firstName": "AnHai",
                            "lastName": "Doan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Doan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770962"
                        ],
                        "name": "A. Halevy",
                        "slug": "A.-Halevy",
                        "structuredName": {
                            "firstName": "Alon",
                            "lastName": "Halevy",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Halevy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7501632,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0d43ce048df0a5349c8c17f839c042aae0871d8f",
            "isKey": false,
            "numCitedBy": 510,
            "numCiting": 104,
            "paperAbstract": {
                "fragments": [],
                "text": "Semantic integration has been a long-standing challenge for the database community. It has received steady attention over the past two decades, and has now become a prominent area of database research. In this article, we first review database applications that require semantic integration and discuss the difficulties underlying the integration process. We then describe recent progress and identify open research issues. We focus in particular on schema matching, a topic that has received much attention in the database community, but also discuss data matching (for example, tuple deduplication) and open issues beyond the match discovery context (for example, reasoning with matches, match verification and repair, and reconciling inconsistent data values). For previous surveys of database research on semantic integration, see Rahm and Bernstein (2001); Ouksel and Seth (1999); and Batini, Lenzerini, and Navathe (1986)."
            },
            "slug": "Semantic-Integration-Research-in-the-Database-A-Doan-Halevy",
            "title": {
                "fragments": [],
                "text": "Semantic Integration Research in the Database Community: A Brief Survey"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This article first reviews database applications that require semantic integration and discusses the difficulties underlying the integration process, then describes recent progress and identifies open research issues."
            },
            "venue": {
                "fragments": [],
                "text": "AI Mag."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1983124"
                        ],
                        "name": "Cody C. T. Kwok",
                        "slug": "Cody-C.-T.-Kwok",
                        "structuredName": {
                            "firstName": "Cody",
                            "lastName": "Kwok",
                            "middleNames": [
                                "C.",
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cody C. T. Kwok"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741101"
                        ],
                        "name": "Oren Etzioni",
                        "slug": "Oren-Etzioni",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Etzioni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Etzioni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780531"
                        ],
                        "name": "Daniel S. Weld",
                        "slug": "Daniel-S.-Weld",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Weld",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel S. Weld"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5456456,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "016e9cc85c658c6a69710b4c617609ad2a5d3a74",
            "isKey": false,
            "numCitedBy": 359,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "The wealth of information on the web makes it an attractive resource for seeking quick answers to simple, factual questions such as &quote;who was the first American in space?&quote; or &quote;what is the second tallest mountain in the world?&quote; Yet today's most advanced web search services (e.g., Google and AskJeeves) make it surprisingly tedious to locate answers to such questions. In this paper, we extend question-answering techniques, first studied in the information retrieval literature, to the web and experimentally evaluate their performance.First we introduce Mulder, which we believe to be the first general-purpose, fully-automated question-answering system available on the web. Second, we describe Mulder's architecture, which relies on multiple search-engine queries, natural-language parsing, and a novel voting procedure to yield reliable answers coupled with high recall. Finally, we compare Mulder's performance to that of Google and AskJeeves on questions drawn from the TREC-8 question answering track. We find that Mulder's recall is more than a factor of three higher than that of AskJeeves. In addition, we find that Google requires 6.6 times as much user effort to achieve the same level of recall as Mulder."
            },
            "slug": "Scaling-question-answering-to-the-web-Kwok-Etzioni",
            "title": {
                "fragments": [],
                "text": "Scaling question answering to the web"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Mulder is introduced, which is believed to be the first general-purpose, fully-automated question-answering system available on the web, and its architecture is described, which relies on multiple search-engine queries, natural-language parsing, and a novel voting procedure to yield reliable answers coupled with high recall."
            },
            "venue": {
                "fragments": [],
                "text": "TOIS"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1801255"
                        ],
                        "name": "Simone Paolo Ponzetto",
                        "slug": "Simone-Paolo-Ponzetto",
                        "structuredName": {
                            "firstName": "Simone",
                            "lastName": "Ponzetto",
                            "middleNames": [
                                "Paolo"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Simone Paolo Ponzetto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31380436"
                        ],
                        "name": "M. Strube",
                        "slug": "M.-Strube",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Strube",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Strube"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6860966,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "22d258fa8f9acadfe513ee8b2842f2bc5db85149",
            "isKey": false,
            "numCitedBy": 520,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "We take the category system in Wikipedia as a conceptual network. We label the semantic relations between categories using methods based on connectivity in the network and lexicosyntactic matching. As a result we are able to derive a large scale taxonomy containing a large amount of subsumption, i.e. isa, relations. We evaluate the quality of the created resource by comparing it with ResearchCyc, one of the largest manually annotated ontologies, as well as computing semantic similarity between words in benchmarking datasets."
            },
            "slug": "Deriving-a-Large-Scale-Taxonomy-from-Wikipedia-Ponzetto-Strube",
            "title": {
                "fragments": [],
                "text": "Deriving a Large-Scale Taxonomy from Wikipedia"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A large scale taxonomy containing a large amount of subsumption is derived using methods based on connectivity in the network and lexicosyntactic matching to label the semantic relations between categories in Wikipedia."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728602"
                        ],
                        "name": "S. Dumais",
                        "slug": "S.-Dumais",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "Dumais",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dumais"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2339397"
                        ],
                        "name": "Michele Banko",
                        "slug": "Michele-Banko",
                        "structuredName": {
                            "firstName": "Michele",
                            "lastName": "Banko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michele Banko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145022783"
                        ],
                        "name": "E. Brill",
                        "slug": "E.-Brill",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Brill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Brill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145580839"
                        ],
                        "name": "Jimmy J. Lin",
                        "slug": "Jimmy-J.-Lin",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Lin",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy J. Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067947449"
                        ],
                        "name": "Andrew Y. Ng",
                        "slug": "Andrew-Y.-Ng",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Ng",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Y. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 153
                            }
                        ],
                        "text": "Permission to make digital or hard copies of all or part of this work for personal or \nclassroom use is granted without fee provided that copies are not made or distributed for pro.t or commercial \nadvantage and that copies bear this notice and the full citation on the .rst page."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9391992,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e8f9537a6cfb1ba2501c1c6ac3b114c274534095",
            "isKey": false,
            "numCitedBy": 338,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a question answering system that is designed to capitalize on the tremendous amount of data that is now available online. Most question answering systems use a wide variety of linguistic resources. We focus instead on the redundancy available in large corpora as an important resource. We use this redundancy to simplify the query rewrites that we need to use, and to support answer mining from returned snippets. Our system performs quite well given the simplicity of the techniques being utilized. Experimental results show that question answering accuracy can be greatly improved by analyzing more and more matching passages. Simple passage ranking and n-gram extraction techniques work well in our system making it efficient to use with many backend retrieval engines."
            },
            "slug": "Web-question-answering:-is-more-always-better-Dumais-Banko",
            "title": {
                "fragments": [],
                "text": "Web question answering: is more always better?"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "This paper describes a question answering system that is designed to capitalize on the tremendous amount of data that is now available online, and uses the redundancy available in large corpora as an important resource to simplify the query rewrites and support answer mining from returned snippets."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '02"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36367542"
                        ],
                        "name": "Wensheng Wu",
                        "slug": "Wensheng-Wu",
                        "structuredName": {
                            "firstName": "Wensheng",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wensheng Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3030274"
                        ],
                        "name": "A. Doan",
                        "slug": "A.-Doan",
                        "structuredName": {
                            "firstName": "AnHai",
                            "lastName": "Doan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Doan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2642131"
                        ],
                        "name": "Clement T. Yu",
                        "slug": "Clement-T.-Yu",
                        "structuredName": {
                            "firstName": "Clement",
                            "lastName": "Yu",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Clement T. Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38699354"
                        ],
                        "name": "W. Meng",
                        "slug": "W.-Meng",
                        "structuredName": {
                            "firstName": "Weiyi",
                            "lastName": "Meng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Meng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11994634,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cb915d465d748e75a9336676a268188b196f6ca6",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "The vision of Semantic Web services promises a network of interoperable Web services over different sources. A major challenge to the realization of this vision is the lack of automated means of acquiring domain ontologies necessary for marking up the Web services. In this paper, we propose the DeepMiner system which learns domain ontologies from the source Web sites. Given a set of sources in a domain of interest, DeepMiner first learns a base ontology from their query interfaces. It then grows the current ontology by probing the sources and discovering additional concepts and instances from the data pages retrieved from the sources. We have evaluated DeepMiner in several real-world domains. Preliminary results indicate that DeepMiner discovers concepts and instances with high accuracy."
            },
            "slug": "Bootstrapping-Domain-Ontology-for-Semantic-Web-from-Wu-Doan",
            "title": {
                "fragments": [],
                "text": "Bootstrapping Domain Ontology for Semantic Web Services from Source Web Sites"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The DeepMiner system, a system which learns domain ontologies from the source Web sites, is proposed which discovers concepts and instances with high accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "TES"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145792"
                        ],
                        "name": "S. F. Adafre",
                        "slug": "S.-F.-Adafre",
                        "structuredName": {
                            "firstName": "Sisay",
                            "lastName": "Adafre",
                            "middleNames": [
                                "Fissaha"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. F. Adafre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696030"
                        ],
                        "name": "M. de Rijke",
                        "slug": "M.-de-Rijke",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "de Rijke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. de Rijke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11897787,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "6d9064ff94c5186e12c39ea2e9f3815004066e51",
            "isKey": false,
            "numCitedBy": 188,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we address the problem of discovering missing hypertext links in Wikipedia. The method we propose consists of two steps: first, we compute a cluster of highly similar pages around a given page, and then we identify candidate links from those similar pages that might be missing on the given page. The main innovation is in the algorithm that we use for identifying similar pages, LTRank, which ranks pages using co-citation and page title information. Both LTRank and the link discovery method are manually evaluated and show acceptable results, especially given the simplicity of the methods and conservativeness of the evaluation criteria."
            },
            "slug": "Discovering-missing-links-in-Wikipedia-Adafre-Rijke",
            "title": {
                "fragments": [],
                "text": "Discovering missing links in Wikipedia"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "The method is proposed consists of two steps: first, a cluster of highly similar pages around a given page is computed, and then candidate links from those similar pages that might be missing on the given page are identified."
            },
            "venue": {
                "fragments": [],
                "text": "LinkKDD '05"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145022783"
                        ],
                        "name": "E. Brill",
                        "slug": "E.-Brill",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Brill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Brill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728602"
                        ],
                        "name": "S. Dumais",
                        "slug": "S.-Dumais",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "Dumais",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dumais"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2339397"
                        ],
                        "name": "Michele Banko",
                        "slug": "Michele-Banko",
                        "structuredName": {
                            "firstName": "Michele",
                            "lastName": "Banko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michele Banko"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5541486,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9c99620d7511c83a402ff3b4b3a2348a669e61e3",
            "isKey": false,
            "numCitedBy": 348,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the architecture of the AskMSR question answering system and systematically evaluate contributions of different system components to accuracy. The system differs from most question answering systems in its dependency on data redundancy rather than sophisticated linguistic analyses of either questions or candidate answers. Because a wrong answer is often worse than no answer, we also explore strategies for predicting when the question answering system is likely to give an incorrect answer."
            },
            "slug": "An-Analysis-of-the-AskMSR-Question-Answering-System-Brill-Dumais",
            "title": {
                "fragments": [],
                "text": "An Analysis of the AskMSR Question-Answering System"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "The architecture of the AskMSR question answering system is described and contributions of different system components to accuracy are evaluated and strategies for predicting when the question Answer system is likely to give an incorrect answer are explored."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1766683"
                        ],
                        "name": "R. Meir",
                        "slug": "R.-Meir",
                        "structuredName": {
                            "firstName": "Ron",
                            "lastName": "Meir",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Meir"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2414086"
                        ],
                        "name": "G. R\u00e4tsch",
                        "slug": "G.-R\u00e4tsch",
                        "structuredName": {
                            "firstName": "Gunnar",
                            "lastName": "R\u00e4tsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. R\u00e4tsch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11436633,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4ac9ef24a4b99f244cd17bf5d390a0c0e712327b",
            "isKey": false,
            "numCitedBy": 504,
            "numCiting": 227,
            "paperAbstract": {
                "fragments": [],
                "text": "We provide an introduction to theoretical and practical aspects of Boosting and Ensemble learning, providing a useful reference for researchers in the field of Boosting as well as for those seeking to enter this fascinating area of research. We begin with a short background concerning the necessary learning theoretical foundations of weak learners and their linear combinations. We then point out the useful connection between Boosting and the Theory of Optimization, which facilitates the understanding of Boosting and later on enables us to move on to new Boosting algorithms, applicable to a broad spectrum of problems. In order to increase the relevance of the paper to practitioners, we have added remarks, pseudo code, \"tricks of the trade\", and algorithmic considerations where appropriate. Finally, we illustrate the usefulness of Boosting algorithms by giving an overview of some existing applications. The main ideas are illustrated on the problem of binary classification, although several extensions are discussed."
            },
            "slug": "An-Introduction-to-Boosting-and-Leveraging-Meir-R\u00e4tsch",
            "title": {
                "fragments": [],
                "text": "An Introduction to Boosting and Leveraging"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "An introduction to theoretical and practical aspects ofboosting and Ensemble learning is provided, providing a useful reference for researchers in the field of Boosting as well as for those seeking to enter this fascinating area of research."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning Summer School"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739581"
                        ],
                        "name": "J. Lafferty",
                        "slug": "J.-Lafferty",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Lafferty",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lafferty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "113414328"
                        ],
                        "name": "Fernando Pereira",
                        "slug": "Fernando-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando Pereira"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 219683473,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4ba954b0412773d047dc41231c733de0c1f4926",
            "isKey": false,
            "numCitedBy": 13413,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "We present conditional random fields , a framework for building probabilistic models to segment and label sequence data. Conditional random fields offer several advantages over hidden Markov models and stochastic grammars for such tasks, including the ability to relax strong independence assumptions made in those models. Conditional random fields also avoid a fundamental limitation of maximum entropy Markov models (MEMMs) and other discriminative Markov models based on directed graphical models, which can be biased towards states with few successor states. We present iterative parameter estimation algorithms for conditional random fields and compare the performance of the resulting models to HMMs and MEMMs on synthetic and natural-language data."
            },
            "slug": "Conditional-Random-Fields:-Probabilistic-Models-for-Lafferty-McCallum",
            "title": {
                "fragments": [],
                "text": "Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work presents iterative parameter estimation algorithms for conditional random fields and compares the performance of the resulting models to HMMs and MEMMs on synthetic and natural-language data."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709927"
                        ],
                        "name": "R. Maclin",
                        "slug": "R.-Maclin",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Maclin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Maclin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752379"
                        ],
                        "name": "D. Opitz",
                        "slug": "D.-Opitz",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Opitz",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Opitz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2594813,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4af31c2819d3f2c7f01942f053750ad1a87253db",
            "isKey": false,
            "numCitedBy": 2439,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "An ensemble consists of a set of individually trained classifiers (such as neural networks or decision trees) whose predictions are combined when classifying novel instances. Previous research has shown that an ensemble is often more accurate than any of the single classifiers in the ensemble. Bagging (Breiman, 1996c) and Boosting (Freund & Schapire, 1996; Schapire, 1990) are two relatively new but popular methods for producing ensembles. In this paper we evaluate these methods on 23 data sets using both neural networks and decision trees as our classification algorithm. Our results clearly indicate a number of conclusions. First, while Bagging is almost always more accurate than a single classifier, it is sometimes much less accurate than Boosting. On the other hand, Boosting can create ensembles that are less accurate than a single classifier - especially when using neural networks. Analysis indicates that the performance of the Boosting methods is dependent on the characteristics of the data set being examined. In fact, further results show that Boosting ensembles may overfit noisy data sets, thus decreasing its performance. Finally, consistent with previous studies, our work suggests that most of the gain in an ensemble's performance comes in the first few classifiers combined; however, relatively large gains can be seen up to 25 classifiers when Boosting decision trees."
            },
            "slug": "Popular-Ensemble-Methods:-An-Empirical-Study-Maclin-Opitz",
            "title": {
                "fragments": [],
                "text": "Popular Ensemble Methods: An Empirical Study"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work suggests that most of the gain in an ensemble's performance comes in the first few classifiers combined; however, relatively large gains can be seen up to 25 classifiers when Boosting decision trees."
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif. Intell. Res."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145172877"
                        ],
                        "name": "K. Nigam",
                        "slug": "K.-Nigam",
                        "structuredName": {
                            "firstName": "Kamal",
                            "lastName": "Nigam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Nigam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739581"
                        ],
                        "name": "J. Lafferty",
                        "slug": "J.-Lafferty",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Lafferty",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lafferty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 574041,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "656859af2ed88cfa23f2bd063c1816a8fc04c47e",
            "isKey": false,
            "numCitedBy": 1012,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes the use of maximum entropy techniques for text classification. Maximum entropy is a probability distribution estimation technique widely used for a variety of natural language tasks, such as language modeling, part-of-speech tagging, and text segmentation. The underlying principle of maximum entropy is that without external knowledge, one should prefer distributions that are uniform. Constraints on the distribution, derived from labeled training data, inform the technique where to be minimally non-uniform. The maximum entropy formulation has a unique solution which can be found by the improved iterative scaling algorithm. In this paper, maximum entropy is used for text classification by estimating the conditional distribution of the class variable given the document. In experiments on several text datasets we compare accuracy to naive Bayes and show that maximum entropy is sometimes significantly better, but also sometimes worse. Much future work remains, but the results indicate that maximum entropy is a promising technique for text classification."
            },
            "slug": "Using-Maximum-Entropy-for-Text-Classification-Nigam-Lafferty",
            "title": {
                "fragments": [],
                "text": "Using Maximum Entropy for Text Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "This paper uses maximum entropy techniques for text classification by estimating the conditional distribution of the class variable given the document by comparing accuracy to naive Bayes and showing that maximum entropy is sometimes significantly better, but also sometimes worse."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2423230"
                        ],
                        "name": "L. Breiman",
                        "slug": "L.-Breiman",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Breiman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Breiman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 47328136,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d1ee87290fa827f1217b8fa2bccb3485da1a300e",
            "isKey": false,
            "numCitedBy": 15184,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Bagging predictors is a method for generating multiple versions of a predictor and using these to get an aggregated predictor. The aggregation averages over the versions when predicting a numerical outcome and does a plurality vote when predicting a class. The multiple versions are formed by making bootstrap replicates of the learning set and using these as new learning sets. Tests on real and simulated data sets using classification and regression trees and subset selection in linear regression show that bagging can give substantial gains in accuracy. The vital element is the instability of the prediction method. If perturbing the learning set can cause significant changes in the predictor constructed, then bagging can improve accuracy."
            },
            "slug": "Bagging-predictors-Breiman",
            "title": {
                "fragments": [],
                "text": "Bagging predictors"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Tests on real and simulated data sets using classification and regression trees and subset selection in linear regression show that bagging can give substantial gains in accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403176300"
                        ],
                        "name": "Tim Berners-Lee",
                        "slug": "Tim-Berners-Lee",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Berners-Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Berners-Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701341"
                        ],
                        "name": "J. Hendler",
                        "slug": "J.-Hendler",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Hendler",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hendler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35003282"
                        ],
                        "name": "O. Lassila",
                        "slug": "O.-Lassila",
                        "structuredName": {
                            "firstName": "Ora",
                            "lastName": "Lassila",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Lassila"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 56818714,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "57820e6f974d198bf4bbdf26ae7e1063bac190c3",
            "isKey": false,
            "numCitedBy": 8576,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Semantic-Web\"-in-Scientific-American-Berners-Lee-Hendler",
            "title": {
                "fragments": [],
                "text": "The Semantic Web\" in Scientific American"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Mallet: A machine learning for language toolkit"
            },
            "venue": {
                "fragments": [],
                "text": "Mallet: A machine learning for language toolkit"
            },
            "year": 2002
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 3,
            "methodology": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 30,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Autonomously-semantifying-wikipedia-Wu-Weld/57faa0e5f99442d1723d2c5ccb70b1461987a7ed?sort=total-citations"
}