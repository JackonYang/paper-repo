{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2995060"
                        ],
                        "name": "D. Swets",
                        "slug": "D.-Swets",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Swets",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Swets"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145926447"
                        ],
                        "name": "J. Weng",
                        "slug": "J.-Weng",
                        "structuredName": {
                            "firstName": "Juyang",
                            "lastName": "Weng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weng"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17139993,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "53c111d3a6705a85902b1fffa25163d9e9b635dd",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a self-organizing framework for the generation of a network useful in content-based retrieval of image databases. The system uses the theories of optimal projection for optimal feature selection and a hierarchical network structure of the image database for rapid retrieval rates. We demonstrate the query technique on a large database of widely varying real-world objects in natural settings, and show the applicability of the approach even for large variability within a particular object class."
            },
            "slug": "Efficient-image-retrieval-using-a-network-with-Swets-Weng",
            "title": {
                "fragments": [],
                "text": "Efficient image retrieval using a network with complex neurons"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The query technique is demonstrated on a large database of widely varying real-world objects in natural settings, and the applicability of the approach even for large variability within a particular object class is shown."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of ICNN'95 - International Conference on Neural Networks"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40434992"
                        ],
                        "name": "J. Bach",
                        "slug": "J.-Bach",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Bach",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114176489"
                        ],
                        "name": "Santanu Paul",
                        "slug": "Santanu-Paul",
                        "structuredName": {
                            "firstName": "Santanu",
                            "lastName": "Paul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Santanu Paul"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144938732"
                        ],
                        "name": "R. Jain",
                        "slug": "R.-Jain",
                        "structuredName": {
                            "firstName": "Ramesh",
                            "lastName": "Jain",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jain"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 165
                            }
                        ],
                        "text": "The complexity in the very nature of two-dimensional image data gives rise to a host of problems that alphanumeric information systems were never designed to handle [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 46658611,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "15b32af1996bc0cf3c2beb23902d5667a1ae4f60",
            "isKey": false,
            "numCitedBy": 148,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "The complex nature of two-dimensional image data has presented problems for traditional information systems designed strictly for alphanumeric data. Systems aimed at effectively managing image data have generally approached the problem from two different views: They either possess a strong database component with little image understanding, or they serve as an image repository for computer vision applications, with little emphasis on the image retrieval process. A general architecture for visual information-management systems (VIMS), which combine the strengths of both approaches, is presented. The system utilizes computer vision routines for both insertion and retrieval and allows easy query-by-example specifications. The vision routines are used to segment and evaluate objects based on domain-knowledge describing the objects and their attributes. The vision system can then assign feature values to be used for similarity-measures and image retrieval. A VIMS developed for face-image retrieval is presented to demonstrate these ideas. >"
            },
            "slug": "A-Visual-Information-Management-System-for-the-of-Bach-Paul",
            "title": {
                "fragments": [],
                "text": "A Visual Information Management System for the Interactive Retrieval of Faces"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A general architecture for visual information-management systems (VIMS), which combine the strengths of both approaches, is presented, and a VIMS developed for face-image retrieval is presented to demonstrate these ideas."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Knowl. Data Eng."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738894"
                        ],
                        "name": "T. Starner",
                        "slug": "T.-Starner",
                        "structuredName": {
                            "firstName": "Thad",
                            "lastName": "Starner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Starner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": "In this work, as in [16] and [14], we require \\well-framed\" images as input for training and query-by-example test probes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 149
                            }
                        ],
                        "text": "This projection, also called the Karhunen-Lo eve projection and principal component analysis [8], has been used to represent [11] and recognize [20] [16] face images, and for planning the illumination of objects for future recognition tasks [14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 136280,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b0bf5d558220d39698ce96d59ee5772e8e1a0663",
            "isKey": false,
            "numCitedBy": 2234,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe experiments with eigenfaces for recognition and interactive search in a large-scale face database. Accurate visual recognition is demonstrated using a database of O(10/sup 3/) faces. The problem of recognition under general viewing orientation is also examined. A view-based multiple-observer eigenspace technique is proposed for use in face recognition under variable pose. In addition, a modular eigenspace description technique is used which incorporates salient features such as the eyes, nose and mouth, in an eigenfeature layer. This modular representation yields higher recognition rates as well as a more robust framework for face recognition. An automatic feature extraction technique using feature eigentemplates is also demonstrated.<<ETX>>"
            },
            "slug": "View-based-and-modular-eigenspaces-for-face-Pentland-Moghaddam",
            "title": {
                "fragments": [],
                "text": "View-based and modular eigenspaces for face recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A modular eigenspace description technique is used which incorporates salient features such as the eyes, nose and mouth, in an eigenfeature layer, which yields higher recognition rates as well as a more robust framework for face recognition."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9242811,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e49ad8354bdd2fd6e8babd348df9e9a5b30bf3a6",
            "isKey": false,
            "numCitedBy": 461,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an unsupervised technique for visual learning which is based on density estimation in high-dimensional spaces using an eigenspace decomposition. Two types of density estimates are derived for modeling the training data: a multivariate Gaussian (for a unimodal distributions) and a multivariate Mixture-of-Gaussians model (for multimodal distributions). These probability densities are then used to formulate a maximum-likelihood estimation framework for visual search and target detection for automatic object recognition. This learning technique is tested in experiments with modeling and subsequent detection of human faces and non-rigid objects such as hands.<<ETX>>"
            },
            "slug": "Probabilistic-visual-learning-for-object-detection-Moghaddam-Pentland",
            "title": {
                "fragments": [],
                "text": "Probabilistic visual learning for object detection"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "An unsupervised technique for visual learning which is based on density estimation in high-dimensional spaces using an eigenspace decomposition and a multivariate Mixture-of-Gaussians model is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144097660"
                        ],
                        "name": "M. Turk",
                        "slug": "M.-Turk",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Turk",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Turk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 106
                            }
                        ],
                        "text": "Techniques have been proposed to produce these types of images, using, for example, pixel-to-pixel search [20], hierarchical coarse-to- ne search [21], or genetic algorithm search [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 144
                            }
                        ],
                        "text": "For example, principal component analysis, also known as the Karhunen-Lo eve projection and \\eigenfeatures,\" has been used for face recognition [20] and lip reading [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 207
                            }
                        ],
                        "text": "So we let m satisfy (Pni=m+1 i)=(Pni=1 i) < P: If P = 5%, a good reduction in the number of features is obtained while retaining a large proportion of the variance present in the original feature vector [8] [20], thereby losing very little of their original population-capturing power."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 144
                            }
                        ],
                        "text": "This projection, also called the Karhunen-Lo eve projection and principal component analysis [8], has been used to represent [11] and recognize [20] [16] face images, and for planning the illumination of objects for future recognition tasks [14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 81
                            }
                        ],
                        "text": "These types of approaches can deal directly with complex, real-world images [14] [20] [21] because the system is general and adaptive."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 26127529,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6f1dfcc44277d4cfd8507284d994c9283dc3a2f",
            "isKey": true,
            "numCitedBy": 14955,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We have developed a near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals. The computational approach taken in this system is motivated by both physiology and information theory, as well as by the practical requirements of near-real-time performance and accuracy. Our approach treats the face recognition problem as an intrinsically two-dimensional (2-D) recognition problem rather than requiring recovery of three-dimensional geometry, taking advantage of the fact that faces are normally upright and thus may be described by a small set of 2-D characteristic views. The system functions by projecting face images onto a feature space that spans the significant variations among known face images. The significant features are known as \"eigenfaces,\" because they are the eigenvectors (principal components) of the set of faces; they do not necessarily correspond to features such as eyes, ears, and noses. The projection operation characterizes an individual face by a weighted sum of the eigenface features, and so to recognize a particular face it is necessary only to compare these weights to those of known individuals. Some particular advantages of our approach are that it provides for the ability to learn and later recognize new faces in an unsupervised manner, and that it is easy to implement using a neural network architecture."
            },
            "slug": "Eigenfaces-for-Recognition-Turk-Pentland",
            "title": {
                "fragments": [],
                "text": "Eigenfaces for Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals, and that is easy to implement using a neural network architecture."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Cognitive Neuroscience"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739452"
                        ],
                        "name": "K. Ikeuchi",
                        "slug": "K.-Ikeuchi",
                        "structuredName": {
                            "firstName": "Katsushi",
                            "lastName": "Ikeuchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Ikeuchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7270383,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bd955c01313fd9285b4d8170840d22c2a1be8bd8",
            "isKey": false,
            "numCitedBy": 207,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "Issues and techniques are discussed to automatically compile object and sensor models into a visual recognition strategy for recognizing and locating an object in three-dimensional space from visual data. Automatic generation of recognition programs by compilation, in an attempt to automate this process, is described. An object model describes geometric and photometric properties of an object to be recognized. A sensor model specifies the sensor characteristics in predicting object appearances and variations of feature values. It is emphasized that the sensors, as well as objects, must be explicitly modeled to achieve the goal of automatic generation of reliable and efficient recognition programs. Actual creation of interpretation trees for two objects and their execution for recognition from a bin of parts are demonstrated. >"
            },
            "slug": "Automatic-generation-of-object-recognition-programs-Ikeuchi-Kanade",
            "title": {
                "fragments": [],
                "text": "Automatic generation of object recognition programs"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Issues and techniques are discussed to automatically compile object and sensor models into a visual recognition strategy for recognizing and locating an object in three-dimensional space from visual data."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2995060"
                        ],
                        "name": "D. Swets",
                        "slug": "D.-Swets",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Swets",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Swets"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1863300"
                        ],
                        "name": "B. Punch",
                        "slug": "B.-Punch",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Punch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Punch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145926447"
                        ],
                        "name": "J. Weng",
                        "slug": "J.-Weng",
                        "structuredName": {
                            "firstName": "Juyang",
                            "lastName": "Weng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weng"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 180
                            }
                        ],
                        "text": "Techniques have been proposed to produce these types of images, using, for example, pixel-to-pixel search [20], hierarchical coarse-to- ne search [21], or genetic algorithm search [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11174221,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cde7a9a56076b7800e87e790ad2153618569843e",
            "isKey": false,
            "numCitedBy": 73,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A realworld computer vision module must deal with a wide variety of environmental parameters. Object recognition, one of the major tasks of this vision module, typically requires a preprocessing step to locate objects in the scenes that ought to be recognized. Genetic algorithms are a search technique for dealing with a very large search space, such as the one encountered in image segmentation or object recognition. The article describes a technique for using genetic algorithms to combine the image segmentation and object recognition steps for a complex scene. The results show that this approach is a viable method for successfully combining the image segmentation and object recognition steps for a computer vision module."
            },
            "slug": "Genetic-algorithms-for-object-recognition-in-a-Swets-Punch",
            "title": {
                "fragments": [],
                "text": "Genetic algorithms for object recognition in a complex scene"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The results show that this approach is a viable method for successfully combining the image segmentation and object recognition steps for a computer vision module."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings., International Conference on Image Processing"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "82910116"
                        ],
                        "name": "H. Murase",
                        "slug": "H.-Murase",
                        "structuredName": {
                            "firstName": "Hiroshi",
                            "lastName": "Murase",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Murase"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750470"
                        ],
                        "name": "S. Nayar",
                        "slug": "S.-Nayar",
                        "structuredName": {
                            "firstName": "Shree",
                            "lastName": "Nayar",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nayar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 76
                            }
                        ],
                        "text": "These types of approaches can deal directly with complex, real-world images [14] [20] [21] because the system is general and adaptive."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 29
                            }
                        ],
                        "text": "In this work, as in [16] and [14], we require \\well-framed\" images as input for training and query-by-example test probes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 241
                            }
                        ],
                        "text": "This projection, also called the Karhunen-Lo eve projection and principal component analysis [8], has been used to represent [11] and recognize [20] [16] face images, and for planning the illumination of objects for future recognition tasks [14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6113796,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5ff14f5eddeaa425ab15504a1bc45f328dc9221e",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of illumination planning for robust object recognition in structured environments. Given a set of objects, the goal is to determine the illumination for which the objects are most distinguishable in appearance from each other. For each object, a large number of images is automatically obtained by varying pose and illumination. Images of all objects, together, constitute the planning image set. The planning set is compressed using the Karhunen-Loeve transform to obtain a low-dimensional subspace. For any given illumination, objects are represented as parametrized manifolds in the subspace. The minimum distance between the manifolds of too objects represents the similarity between the objects in the correlation sense. The optimal illumination is therefore one that maximizes the shortest distance between object manifolds. Results produced by the illumination planner heave been used to enhance the performance of an object recognition system.<<ETX>>"
            },
            "slug": "Illumination-planning-for-object-recognition-in-Murase-Nayar",
            "title": {
                "fragments": [],
                "text": "Illumination planning for object recognition in structured environments"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This paper addresses the problem of illumination planning for robust object recognition in structured environments with results produced by the illumination planner heave used to enhance the performance of an object recognition system."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2428034"
                        ],
                        "name": "C. Bregler",
                        "slug": "C.-Bregler",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Bregler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bregler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808760"
                        ],
                        "name": "S. Omohundro",
                        "slug": "S.-Omohundro",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Omohundro",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Omohundro"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 165
                            }
                        ],
                        "text": "For example, principal component analysis, also known as the Karhunen-Lo eve projection and \\eigenfeatures,\" has been used for face recognition [20] and lip reading [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8668565,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4e0d91ea5cf37e7ff5a1105c6dbf84d2ae44b371",
            "isKey": false,
            "numCitedBy": 172,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "A technique for representing and learning smooth nonlinear manifolds is presented and applied to several lip reading tasks. Given a set of points drawn from a smooth manifold in an abstract feature space, the technique is capable of determining the structure of the surface and of finding the closest manifold point to a given query point. We use this technique to learn the \"space of lips\" in a visual speech recognition task. The learned manifold is used for tracking and extracting the lips, for interpolating between frames in an image sequence and for providing features for recognition. We describe a system based on hidden Markov models and this learned lip manifold that significantly improves the performance of acoustic speech recognizers in degraded environments. We also present preliminary results on a purely visual lip reader.<<ETX>>"
            },
            "slug": "Nonlinear-manifold-learning-for-visual-speech-Bregler-Omohundro",
            "title": {
                "fragments": [],
                "text": "Nonlinear manifold learning for visual speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A system based on hidden Markov models and this learned lip manifold that significantly improves the performance of acoustic speech recognizers in degraded environments is described and preliminary results on a purely visual lip reader are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2995060"
                        ],
                        "name": "D. Swets",
                        "slug": "D.-Swets",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Swets",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Swets"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2443096"
                        ],
                        "name": "Y. Pathak",
                        "slug": "Y.-Pathak",
                        "structuredName": {
                            "firstName": "Yogesh",
                            "lastName": "Pathak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Pathak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40813793"
                        ],
                        "name": "J. Weng",
                        "slug": "J.-Weng",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Weng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weng"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 129
                            }
                        ],
                        "text": "Each stored image can maintain pointers to a relational database to provide retrievals under various other desired organizations [17] such as gender, age group, etc."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18430228,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "11cb27e7991a4c44d98423a00424db846259a942",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Large image databases are commonly employed in applications like criminal records, customs, plant root database, and voters' registration database. EEcient and convenient mechanisms for database organization and retrieval are essential. A quick and easy-to-use interface is needed which should also mesh naturally with the overall image management system. In this paper we describe the design and implementation of an integrated image database system. This system ooers support for both alphanumeric query, based on alphanumeric data attached to the image le, and content-based query utilizing image examples. Content-based retrieval, speciically Query by Image Example, is made possible by the SHOSLIF approach. Alphanumeric query is implemented by a collection of parsing and query modules. All these are accessible from within a user-friendly GUI."
            },
            "slug": "A-System-for-Combining-Traditional-Alphanumeric-by-Swets-Pathak",
            "title": {
                "fragments": [],
                "text": "A System for Combining Traditional Alphanumeric Queries with Content-Based Queries by Example in Ima"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The design and implementation of an integrated image database system with support for both alphanumeric query, based on alphan numeric data attached to the image, and content-based query utilizing image examples, made possible by the SHOSLIF approach."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053520352"
                        ],
                        "name": "M. Kirby",
                        "slug": "M.-Kirby",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kirby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kirby"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49555086"
                        ],
                        "name": "L. Sirovich",
                        "slug": "L.-Sirovich",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Sirovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Sirovich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 570648,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "66d75a5fe9e1b6511c5135d68e9ce8c0da5a7374",
            "isKey": false,
            "numCitedBy": 2853,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "The use of natural symmetries (mirror images) in a well-defined family of patterns (human faces) is discussed within the framework of the Karhunen-Loeve expansion. This results in an extension of the data and imposes even and odd symmetry on the eigenfunctions of the covariance matrix, without increasing the complexity of the calculation. The resulting approximation of faces projected from outside of the data set onto this optimal basis is improved on average. >"
            },
            "slug": "Application-of-the-Karhunen-Loeve-Procedure-for-the-Kirby-Sirovich",
            "title": {
                "fragments": [],
                "text": "Application of the Karhunen-Loeve Procedure for the Characterization of Human Faces"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "The use of natural symmetries (mirror images) in a well-defined family of patterns (human faces) is discussed within the framework of the Karhunen-Loeve expansion, which results in an extension of the data and imposes even and odd symmetry on the eigenfunctions of the covariance matrix."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740300"
                        ],
                        "name": "D. Beymer",
                        "slug": "D.-Beymer",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Beymer",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Beymer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 83
                            }
                        ],
                        "text": "The e cient selection of good features, however, is an important issue to consider [2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14814282,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "66505cb708b098a93331471f079965f6ded4ea7f",
            "isKey": false,
            "numCitedBy": 449,
            "numCiting": 76,
            "paperAbstract": {
                "fragments": [],
                "text": "To create a pose-invariant face recognizer, one strategy is the view-based approach, which uses a set of real example views at different poses. But what if we only have one real view available, such as a scanned passport photo-can we still recognize faces under different poses? Given one real view at a known pose, it is still possible to use the view-based approach by exploiting prior knowledge of faces to generate virtual views, or views of the face as seen from different poses. To represent prior knowledge, we use 2D example views of prototype faces under different rotations. We develop example-based techniques for applying the rotation seen in the prototypes to essentially \"rotate\" the single real view which is available. Next, the combined set of one real and multiple virtual views is used as example views for a view-based, pose-invariant face recognizer. Oar experiments suggest that among the techniques for expressing prior knowledge of faces, 2D example-based approaches should be considered alongside the more standard 3D modeling techniques.<<ETX>>"
            },
            "slug": "Face-recognition-from-one-example-view-Beymer-Poggio",
            "title": {
                "fragments": [],
                "text": "Face recognition from one example view"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Oar experiments suggest that among the techniques for expressing prior knowledge of faces, 2D example-based approaches should be considered alongside the more standard 3D modeling techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752732"
                        ],
                        "name": "T. Cover",
                        "slug": "T.-Cover",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Cover",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Cover"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108177"
                        ],
                        "name": "P. Hart",
                        "slug": "P.-Hart",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 145
                            }
                        ],
                        "text": "It has been shown that the probability of error for this nearest neighbor decision rule is bounded above by twice the Bayes probability of error [4] if we have an in nite number of samples."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5246200,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "0efb841403aa6252b39ae6975c1cc5410554ef7b",
            "isKey": false,
            "numCitedBy": 10768,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The nearest neighbor decision rule assigns to an unclassified sample point the classification of the nearest of a set of previously classified points. This rule is independent of the underlying joint distribution on the sample points and their classifications, and hence the probability of error R of such a rule must be at least as great as the Bayes probability of error R^{\\ast} --the minimum probability of error over all decision rules taking underlying probability structure into account. However, in a large sample analysis, we will show in the M -category case that R^{\\ast} \\leq R \\leq R^{\\ast}(2 --MR^{\\ast}/(M-1)) , where these bounds are the tightest possible, for all suitably smooth underlying distributions. Thus for any number of categories, the probability of error of the nearest neighbor rule is bounded above by twice the Bayes probability of error. In this sense, it may be said that half the classification information in an infinite sample set is contained in the nearest neighbor."
            },
            "slug": "Nearest-neighbor-pattern-classification-Cover-Hart",
            "title": {
                "fragments": [],
                "text": "Nearest neighbor pattern classification"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "The nearest neighbor decision rule assigns to an unclassified sample point the classification of the nearest of a set of previously classified points, so it may be said that half the classification information in an infinite sample set is contained in the nearest neighbor."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144938740"
                        ],
                        "name": "R. Jain",
                        "slug": "R.-Jain",
                        "structuredName": {
                            "firstName": "Ramesh",
                            "lastName": "Jain",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690709"
                        ],
                        "name": "A. Hampapur",
                        "slug": "A.-Hampapur",
                        "structuredName": {
                            "firstName": "Arun",
                            "lastName": "Hampapur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hampapur"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207184153,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4adca039a9a101001b1640d9d70074ed0994c17a",
            "isKey": false,
            "numCitedBy": 125,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Video is composed of audio-visual information. Providing content based access to video data is essential for the sucessful integration of video into computers. Organizing video for content based access requires the use of video metadata. This paper explores the nature video metadata. A data model for video databases is presented based on a study of the applications of video, the nature of video retrieval requests, and the features of video. The data model is used in the architectural framework of a video database. The current state of technology in video databases is summarized and research issues are highlighted."
            },
            "slug": "Metadata-in-video-databases-Jain-Hampapur",
            "title": {
                "fragments": [],
                "text": "Metadata in video databases"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A data model for video databases is presented based on a study of the applications of video, the nature of video retrieval requests, and the features of video that is used in the architectural framework of a video database."
            },
            "venue": {
                "fragments": [],
                "text": "SGMD"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1990451"
                        ],
                        "name": "Eitetsu Oomoto",
                        "slug": "Eitetsu-Oomoto",
                        "structuredName": {
                            "firstName": "Eitetsu",
                            "lastName": "Oomoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eitetsu Oomoto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109387168"
                        ],
                        "name": "Katsumi Tanaka",
                        "slug": "Katsumi-Tanaka",
                        "structuredName": {
                            "firstName": "Katsumi",
                            "lastName": "Tanaka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Katsumi Tanaka"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 107
                            }
                        ],
                        "text": "A central task of these multimedia information systems is the storage, retrieval, and management of images [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 22236580,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4224a268267a64648324db5e2eb6d95d6e0c7f3d",
            "isKey": false,
            "numCitedBy": 397,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "A video-object data model and the design and implementation of a prototype video-object database system named OVID based on the model are described. Notable features of the video-object data model are a mechanism to share common descriptional data among video-objects, called interval-inclusion based inheritance, and operations to composite video-objects. The OVID system offers a browsing/inspection tool called VideoChart, and adhoc query facility called VideoSQL, and a video-object definition tool. >"
            },
            "slug": "OVID:-Design-and-Implementation-of-a-Video-Object-Oomoto-Tanaka",
            "title": {
                "fragments": [],
                "text": "OVID: Design and Implementation of a Video-Object Database System"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The OVID system offers a browsing/inspection tool called VideoChart, and adhoc query facility called VideoSQL, and a video-object definition tool."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Knowl. Data Eng."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "100942540"
                        ],
                        "name": "M. Lo\u00e8ve",
                        "slug": "M.-Lo\u00e8ve",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Lo\u00e8ve",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lo\u00e8ve"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 123533290,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f18307ebabf398bb7fd1b3375b2f09a7f9f6c5be",
            "isKey": false,
            "numCitedBy": 6129,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "These notes cover the basic definitions of discrete probability theory, and then present some results including Bayes' rule, inclusion-exclusion formula, Chebyshev's inequality, and the weak law of large numbers. 1 Sample spaces and events To treat probability rigorously, we define a sample space S whose elements are the possible outcomes of some process or experiment. For example, the sample space might be the outcomes of the roll of a die, or flips of a coin. To each element x of the sample space, we assign a probability, which will be a non-negative number between 0 and 1, which we will denote by p(x). We require that x\u2208S p(x) = 1, so the total probability of the elements of our sample space is 1. What this means intuitively is that when we perform our process, exactly one of the things in our sample space will happen. Example. The sample space could be S = {a, b, c}, and the probabilities could be p(a) = 1/2, p(b) = 1/3, p(c) = 1/6. If all elements of our sample space have equal probabilities, we call this the uniform probability distribution on our sample space. For example, if our sample space was the outcomes of a die roll, the sample space could be denoted S = {x 1 , x 2 ,. .. , x 6 }, where the event x i correspond to rolling i. The uniform distribution, in which every outcome x i has probability 1/6 describes the situation for a fair die. Similarly, if we consider tossing a fair coin, the outcomes would be H (heads) and T (tails), each with probability 1/2. In this situation we have the uniform probability distribution on the sample space S = {H, T }. We define an event A to be a subset of the sample space. For example, in the roll of a die, if the event A was rolling an even number, then A = {x 2 , x 4 , x 6 }. The probability of an event A, denoted by P(A), is the sum of the probabilities of the corresponding elements in the sample space. For rolling an even number, we have P(A) = p(x 2) + p(x 4) + p(x 6) = 1 2 Given an event A of our sample space, there is a complementary event which consists of all points in our sample space that are not \u2026"
            },
            "slug": "Probability-Theory-I-Lo\u00e8ve",
            "title": {
                "fragments": [],
                "text": "Probability Theory I"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "These notes cover the basic definitions of discrete probability theory, and then present some results including Bayes' rule, inclusion-exclusion formula, Chebyshev's inequality, and the weak law of large numbers."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1963
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49353544"
                        ],
                        "name": "R. Fisher",
                        "slug": "R.-Fisher",
                        "structuredName": {
                            "firstName": "Rory",
                            "lastName": "Fisher",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fisher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 19
                            }
                        ],
                        "text": "It has been proven [5] [22] that this ratio is maximized when the column vectors of projection matrix W are the eigenvectors of S 1 w Sb associated with the largest eigenvalues."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 85013676,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "3bbec310cdce1fd06ea198a91c160a594611a87a",
            "isKey": false,
            "numCitedBy": 863,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "THE-STATISTICAL-UTILIZATION-OF-MULTIPLE-Fisher",
            "title": {
                "fragments": [],
                "text": "THE STATISTICAL UTILIZATION OF MULTIPLE MEASUREMENTS"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1938
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2295441"
                        ],
                        "name": "K. Fukunaga",
                        "slug": "K.-Fukunaga",
                        "structuredName": {
                            "firstName": "Keinosuke",
                            "lastName": "Fukunaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fukunaga"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60735762,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "71c0f082a41c7f0b102c3ca9e4cf6b31f361d06a",
            "isKey": false,
            "numCitedBy": 4228,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Introduction-to-statistical-pattern-recognition-Fukunaga",
            "title": {
                "fragments": [],
                "text": "Introduction to statistical pattern recognition (2nd ed.)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3087848"
                        ],
                        "name": "R. Dubes",
                        "slug": "R.-Dubes",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Dubes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dubes"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 29535089,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aa4bddbd10eafd8e1b54338517eedfee408f03ae",
            "isKey": false,
            "numCitedBy": 10559,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Algorithms-for-Clustering-Data-Jain-Dubes",
            "title": {
                "fragments": [],
                "text": "Algorithms for Clustering Data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 301,
                                "start": 297
                            }
                        ],
                        "text": "Then the features y1; y2; ; ym can be easily computed from yi = vt i(X MX) ; i = 1; 2; ;m: Since these yi's give the minimum mean-square error, we call them the Most Expressive Features (MEF) in that they best express the population in the sense of linear transform as evidenced in reconstruction [11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 125
                            }
                        ],
                        "text": "This projection, also called the Karhunen-Lo eve projection and principal component analysis [8], has been used to represent [11] and recognize [20] [16] face images, and for planning the illumination of objects for future recognition tasks [14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Application of the Karhunen-Lo eve procedure for the character-  ization of human faces,"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Machine Intell.,"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Juyang) Weng is with the computer science department at Michigan State University"
            },
            "venue": {
                "fragments": [],
                "text": "Juyang) Weng is with the computer science department at Michigan State University"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "AAliation of Authors Daniel L. Swets is with the computer science department at Augustana College"
            },
            "venue": {
                "fragments": [],
                "text": "AAliation of Authors Daniel L. Swets is with the computer science department at Augustana College"
            },
            "year": 1963
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 221
                            }
                        ],
                        "text": "1 Introduction The ability of computers to rapidly and successfully retrieve information from image databases based on the objects contained in the images has a direct impact on the progress of digital library technology [9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Metadata in video databases,\" in Sigmod Record: Special Issue on  Metadata for"
            },
            "venue": {
                "fragments": [],
                "text": "Digital Media,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 202
                            }
                        ],
                        "text": "So we letm satisfy (Pni=m+1 i)=(Pni=1 i) < P: If P = 5%, a good reduction in the number of features is obtained while retaining a large proportion of the variance present in the original feature vector [8] [20], thereby losing very little of their original population-capturing power."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 50
                            }
                        ],
                        "text": "Then the within-class scatter matrix is de ned as [8] Sw = Pci=1Pni j=1(Yj Mi)(Yj Mi)t for ni samples from class i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 93
                            }
                        ],
                        "text": "This projection, also called the Karhunen-Lo eve projection and principal component analysis [8], has been used to represent [11] and recognize [20] [16] face images, and for planning the illumination of objects for future recognition tasks [14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Algorithms for Clustering Data.Prentice-Hall"
            },
            "venue": {
                "fragments": [],
                "text": "New Jersey,"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 38
                            }
                        ],
                        "text": "Then we can use the proven result [6] [10] [12] that the best vectors v1;v2; vm to use are the unit eigenvectors associated with the m largest eigenvalues of the covariance matrix of X, X = E [(X MX)(X MX)t] ; where MX is the mean (expected) vector of X."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Principal Component Analysis.Springer-Verlag"
            },
            "venue": {
                "fragments": [],
                "text": "New York,"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Weng, \\EEcient image retrieval using a network with complex neurons"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings, International Conference on Neural Networks"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 43
                            }
                        ],
                        "text": "Then we can use the proven result [6] [10] [12] that the best vectors v1;v2; vm to use are the unit eigenvectors associated with the m largest eigenvalues of the covariance matrix of X, X = E [(X MX)(X MX)t] ; whereMX is the mean (expected) vector of X."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "eve, Probability Theory.Princeton"
            },
            "venue": {
                "fragments": [],
                "text": "NJ: Van Nostrand,"
            },
            "year": 1955
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "E cient image retrieval using a network with complex neurons,\" in  Proceedings, International Conference on Neural Networks, (Perth, Western Australia), Novem-  ber 1995.Invited Paper"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 11,
            "methodology": 9
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 28,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Using-Discriminant-Eigenfeatures-for-Image-Swets-Weng/5e28e81e757009d2f76b8674e0da431f5845884a?sort=total-citations"
}