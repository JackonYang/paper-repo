{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144854796"
                        ],
                        "name": "D. Gavrila",
                        "slug": "D.-Gavrila",
                        "structuredName": {
                            "firstName": "Dariu",
                            "lastName": "Gavrila",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gavrila"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2919518"
                        ],
                        "name": "S. Munder",
                        "slug": "S.-Munder",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Munder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Munder"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u00c7"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The main difference between generative and discriminative models is how posterior probabilities are estimated for each class."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 145
                            }
                        ],
                        "text": "While the latter two require models of the pedestrian class, e.g., in terms of geometry, appearance, or dynamics, the initial generation of regions of interest is usually based on more general low-level features or prior scene knowledge."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59459,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "91335d9335e4fd06de48d769d1b79eaded4e431b",
            "isKey": false,
            "numCitedBy": 595,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a multi-cue vision system for the real-time detection and tracking of pedestrians from a moving vehicle. The detection component involves a cascade of modules, each utilizing complementary visual criteria to successively narrow down the image search space, balancing robustness and efficiency considerations. Novel is the tight integration of the consecutive modules: (sparse) stereo-based ROI generation, shape-based detection, texture-based classification and (dense) stereo-based verification. For example, shape-based detection activates a weighted combination of texture-based classifiers, each attuned to a particular body pose.Performance of individual modules and their interaction is analyzed by means of Receiver Operator Characteristics (ROCs). A sequential optimization technique allows the successive combination of individual ROCs, providing optimized system parameter settings in a systematic fashion, avoiding ad-hoc parameter tuning. Application-dependent processing constraints can be incorporated in the optimization procedure.Results from extensive field tests in difficult urban traffic conditions suggest system performance is at the leading edge."
            },
            "slug": "Multi-cue-Pedestrian-Detection-and-Tracking-from-a-Gavrila-Munder",
            "title": {
                "fragments": [],
                "text": "Multi-cue Pedestrian Detection and Tracking from a Moving Vehicle"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper presents a multi-cue vision system for the real-time detection and tracking of pedestrians from a moving vehicle, with results from extensive field tests in difficult urban traffic conditions suggest system performance is at the leading edge."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765022"
                        ],
                        "name": "M. Enzweiler",
                        "slug": "M.-Enzweiler",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Enzweiler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Enzweiler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72398497"
                        ],
                        "name": "P. Kanter",
                        "slug": "P.-Kanter",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Kanter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Kanter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144854796"
                        ],
                        "name": "D. Gavrila",
                        "slug": "D.-Gavrila",
                        "structuredName": {
                            "firstName": "Dariu",
                            "lastName": "Gavrila",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gavrila"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 139
                            }
                        ],
                        "text": "While the latter two require models of the pedestrian class, e.g., in terms of geometry, appearance, or dynamics, the initial generation of regions of interest is usually based on more general low-level features or prior scene knowledge."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10698560,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7c89b9b29699ab96653a6949808142cc0e0dd88b",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel focus-of-attention strategy for monocular pedestrian recognition. It uses Bayespsila rule to estimate the posterior for the presence of a pedestrian in a certain (rectangular) image region, based on motion parallax features. This posterior is used as a parameter to control the amount of regions of interest (ROIs) that is passed to subsequent verification stages. For the latter, we use a state-of-the-art pedestrian recognition scheme which consists of multiple modules in a cascade architecture. We obtain optimized settings for the control parameters of the combined cascade system by a sequential ROC convex hull technique. Experiments are conducted on image data captured from a moving vehicle in an urban environment. We demonstrate that the proposed focus-of-attention strategy reduces the false positives of an otherwise identical monocular pedestrian recognition system by a factor of two, at equal detection rates. The overall system maintains processing rates close to real-time."
            },
            "slug": "Monocular-pedestrian-recognition-using-motion-Enzweiler-Kanter",
            "title": {
                "fragments": [],
                "text": "Monocular pedestrian recognition using motion parallax"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "It is demonstrated that the proposed focus-of-attention strategy reduces the false positives of an otherwise identical monocular pedestrian recognition system by a factor of two, at equal detection rates."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Intelligent Vehicles Symposium"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2919518"
                        ],
                        "name": "S. Munder",
                        "slug": "S.-Munder",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Munder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Munder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144854796"
                        ],
                        "name": "D. Gavrila",
                        "slug": "D.-Gavrila",
                        "structuredName": {
                            "firstName": "Dariu",
                            "lastName": "Gavrila",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gavrila"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u00c7"
                    },
                    "intents": []
                }
            ],
            "corpusId": 10769792,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4ebbf3ec461f9b347937e4a5b993f12940558934",
            "isKey": false,
            "numCitedBy": 636,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Detecting people in images is key for several important application domains in computer vision. This paper presents an in-depth experimental study on pedestrian classification; multiple feature-classifier combinations are examined with respect to their ROC performance and efficiency. We investigate global versus local and adaptive versus nonadaptive features, as exemplified by PCA coefficients, Haar wavelets, and local receptive fields (LRFs). In terms of classifiers, we consider the popular support vector machines (SVMs), feedforward neural networks, and k-nearest neighbor classifier. Experiments are performed on a large data set consisting of 4,000 pedestrian and more than 25,000 nonpedestrian (labeled) images captured in outdoor urban environments. Statistically meaningful results are obtained by analyzing performance variances caused by varying training and test sets. Furthermore, we investigate how classification performance and training sample size are correlated. Sample size is adjusted by increasing the number of manually labeled training data or by employing automatic bootstrapping or cascade techniques. Our experiments show that the novel combination of SVMs with LRF features performs best. A boosted cascade of Haar wavelets can, however, reach quite competitive results, at a fraction of computational cost. The data set used in this paper is made public, establishing a benchmark for this important problem"
            },
            "slug": "An-Experimental-Study-on-Pedestrian-Classification-Munder-Gavrila",
            "title": {
                "fragments": [],
                "text": "An Experimental Study on Pedestrian Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "An in-depth experimental study on pedestrian classification; multiple feature-classifier combinations are examined with respect to their ROC performance and efficiency and show that the novel combination of SVMs with LRF features performs best."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145319478"
                        ],
                        "name": "Michael J. Jones",
                        "slug": "Michael-J.-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144626092"
                        ],
                        "name": "D. Snow",
                        "slug": "D.-Snow",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Snow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Snow"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 158
                            }
                        ],
                        "text": "They cover both passive and active safety techniques, the latter using (possibly) multiple vision and nonvision sensors, together with methods for collision risk assessment."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "\u00c7"
                    },
                    "intents": []
                }
            ],
            "corpusId": 47726,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3702c79b8d118f8f363d685905bd285ab8e33979",
            "isKey": false,
            "numCitedBy": 1524,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a pedestrian detection system that integrates image intensity information with motion information. We use a detection style algorithm that scans a detector over two consecutive frames of a video sequence. The detector is trained (using AdaBoost) to take advantage of both motion and appearance information to detect a walking person. Past approaches have built detectors based on motion information or detectors based on appearance information, but ours is the first to combine both sources of information in a single detector. The implementation described runs at about 4 frames/second, detects pedestrians at very small scales (as small as 20 \u00d7 15 pixels), and has a very low false positive rate.Our approach builds on the detection work of Viola and Jones. Novel contributions of this paper include: (i) development of a representation of image motion which is extremely efficient, and (ii) implementation of a state of the art pedestrian detection system which operates on low resolution images under difficult conditions (such as rain and snow)."
            },
            "slug": "Detecting-Pedestrians-Using-Patterns-of-Motion-and-Viola-Jones",
            "title": {
                "fragments": [],
                "text": "Detecting Pedestrians Using Patterns of Motion and Appearance"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This pedestrian detection system is the first to combine both sources of information in a single detector, and operates on low resolution images under difficult conditions (such as rain and snow)."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144471901"
                        ],
                        "name": "I. Parra",
                        "slug": "I.-Parra",
                        "structuredName": {
                            "firstName": "Ignacio",
                            "lastName": "Parra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Parra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729433"
                        ],
                        "name": "D. F. Llorca",
                        "slug": "D.-F.-Llorca",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Llorca",
                            "middleNames": [
                                "Fern\u00e1ndez"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. F. Llorca"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750559"
                        ],
                        "name": "M. Sotelo",
                        "slug": "M.-Sotelo",
                        "structuredName": {
                            "firstName": "Miguel",
                            "lastName": "Sotelo",
                            "middleNames": [
                                "\u00c1ngel"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sotelo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683950"
                        ],
                        "name": "L. M. Bergasa",
                        "slug": "L.-M.-Bergasa",
                        "structuredName": {
                            "firstName": "Luis",
                            "lastName": "Bergasa",
                            "middleNames": [
                                "Miguel"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. M. Bergasa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685786"
                        ],
                        "name": "P. R. D. Toro",
                        "slug": "P.-R.-D.-Toro",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Toro",
                            "middleNames": [
                                "Revenga",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. R. D. Toro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31418350"
                        ],
                        "name": "J. Nuevo",
                        "slug": "J.-Nuevo",
                        "structuredName": {
                            "firstName": "Jes\u00fas",
                            "lastName": "Nuevo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Nuevo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738823"
                        ],
                        "name": "M. Oca\u00f1a",
                        "slug": "M.-Oca\u00f1a",
                        "structuredName": {
                            "firstName": "Manuel",
                            "lastName": "Oca\u00f1a",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Oca\u00f1a"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2383664"
                        ],
                        "name": "M. A. Garrido",
                        "slug": "M.-A.-Garrido",
                        "structuredName": {
                            "firstName": "Miguel",
                            "lastName": "Garrido",
                            "middleNames": [
                                "\u00c1ngel",
                                "Garc\u00eda"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. A. Garrido"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "While the latter two require models of the pedestrian class, e.g., in terms of geometry, appearance, or dynamics, the initial generation of regions of interest is usually based on more general low-level features or prior scene knowledge."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9148635,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d4953d84b893a8d6784ac4401728c6d13ae8b709",
            "isKey": false,
            "numCitedBy": 191,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a comprehensive combination of feature extraction methods for vision-based pedestrian detection in Intelligent Transportation Systems. The basic components of pedestrians are first located in the image and then combined with a support-vector-machine-based classifier. This poses the problem of pedestrian detection in real cluttered road images. Candidate pedestrians are located using a subtractive clustering attention mechanism based on stereo vision. A components-based learning approach is proposed in order to better deal with pedestrian variability, illumination conditions, partial occlusions, and rotations. Extensive comparisons have been carried out using different feature extraction methods as a key to image understanding in real traffic conditions. A database containing thousands of pedestrian samples extracted from real traffic images has been created for learning purposes at either daytime or nighttime. The results achieved to date show interesting conclusions that suggest a combination of feature extraction methods as an essential clue for enhanced detection performance"
            },
            "slug": "Combination-of-Feature-Extraction-Methods-for-SVM-Parra-Llorca",
            "title": {
                "fragments": [],
                "text": "Combination of Feature Extraction Methods for SVM Pedestrian Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A components-based learning approach is proposed in order to better deal with pedestrian variability, illumination conditions, partial occlusions, and rotations and suggest a combination of feature extraction methods as an essential clue for enhanced detection performance."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Intelligent Transportation Systems"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2919518"
                        ],
                        "name": "S. Munder",
                        "slug": "S.-Munder",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Munder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Munder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679944"
                        ],
                        "name": "C. Schn\u00f6rr",
                        "slug": "C.-Schn\u00f6rr",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Schn\u00f6rr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schn\u00f6rr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144854796"
                        ],
                        "name": "D. Gavrila",
                        "slug": "D.-Gavrila",
                        "structuredName": {
                            "firstName": "Dariu",
                            "lastName": "Gavrila",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gavrila"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The main difference between generative and discriminative models is how posterior probabilities are estimated for each class."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 157
                            }
                        ],
                        "text": "While the latter two require models of the pedestrian class, e.g., in terms of geometry, appearance, or dynamics, the initial generation of regions of interest is usually based on more general low-level features or prior scene knowledge."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12797124,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "896a2ad6b91c74aa78ea0111b4e566f57d2dbb75",
            "isKey": false,
            "numCitedBy": 115,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a robust multicue approach to the integrated detection and tracking of pedestrians in a cluttered urban environment. A novel spatiotemporal object representation is proposed, which combines a generative shape model and a discriminative texture classifier, both of which are composed of a mixture of pose-specific submodels. Shape is represented by a set of linear subspace models, which is an extension of point distribution models, with shape transitions being modeled by a first-order Markov process. Texture, i.e., the shape-normalized intensity pattern, is represented by a manifold that is implicitly delimited by a set of pattern classifiers, whereas texture transition is modeled by a random walk. Direct 3-D measurements that are provided by a stereo system are further incorporated into the observation density function. We employ a Bayesian framework based on particle filtering to achieve integrated object detection and tracking. Large-scale experiments that involve pedestrian detection and tracking from a moving vehicle demonstrate the benefit of the proposed approach."
            },
            "slug": "Pedestrian-Detection-and-Tracking-Using-a-Mixture-Munder-Schn\u00f6rr",
            "title": {
                "fragments": [],
                "text": "Pedestrian Detection and Tracking Using a Mixture of View-Based Shape\u2013Texture Models"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel spatiotemporal object representation is proposed, which combines a generative shape model and a discriminative texture classifier, both of which are composed of a mixture of pose-specific submodels."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Intelligent Transportation Systems"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2570029"
                        ],
                        "name": "P. Sabzmeydani",
                        "slug": "P.-Sabzmeydani",
                        "structuredName": {
                            "firstName": "Payam",
                            "lastName": "Sabzmeydani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sabzmeydani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10771328"
                        ],
                        "name": "Greg Mori",
                        "slug": "Greg-Mori",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Mori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Greg Mori"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 93
                            }
                        ],
                        "text": "Gandhi and Trivedi [20] focus on the pedestrian protection application in the intelligent vehicle domain."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13420116,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b09d132046f3b21f98206eb514ebfcbd73f32513",
            "isKey": false,
            "numCitedBy": 356,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we address the problem of detecting pedestrians in still images. We introduce an algorithm for learning shapelet features, a set of mid-level features. These features are focused on local regions of the image and are built from low-level gradient information that discriminates between pedestrian and non-pedestrian classes. Using Ad-aBoost, these shapelet features are created as a combination of oriented gradient responses. To train the final classifier, we use AdaBoost for a second time to select a subset of our learned shapelets. By first focusing locally on smaller feature sets, our algorithm attempts to harvest more useful information than by examining all the low-level features together. We present quantitative results demonstrating the effectiveness of our algorithm. In particular, we obtain an error rate 14 percentage points lower (at 10-6 FPPW) than the previous state of the art detector of Dalal and Triggs on the INRIA dataset."
            },
            "slug": "Detecting-Pedestrians-by-Learning-Shapelet-Features-Sabzmeydani-Mori",
            "title": {
                "fragments": [],
                "text": "Detecting Pedestrians by Learning Shapelet Features"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "This paper introduces an algorithm for learning shapelet features, a set of mid-level features that are built from low-level gradient information that discriminates between pedestrian and non-pedestrian classes on the INRIA dataset."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684626"
                        ],
                        "name": "B. Heisele",
                        "slug": "B.-Heisele",
                        "structuredName": {
                            "firstName": "Bernd",
                            "lastName": "Heisele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Heisele"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696091"
                        ],
                        "name": "C. W\u00f6hler",
                        "slug": "C.-W\u00f6hler",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "W\u00f6hler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. W\u00f6hler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14600711,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d35b73ecd7c3d0a137be51f92fbe9eb67e254667",
            "isKey": false,
            "numCitedBy": 109,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present an algorithm for recognizing walking pedestrians in sequences of color images taken from a moving camera. The recognition is based on the characteristic motion of the legs of a pedestrian walking parallel to the image plane. Each image is segmented into region-like image parts by clustering pixels in a combined color/position feature space. The proposed clustering technique implies matching of corresponding clusters in consecutive frames and therefore allows clusters to be tracked over a sequence of images. Based on the observation of clusters over time a two-stage classifier extracts those clusters which most likely represent the legs of pedestrians. A fast polynomial classifier performs a rough preselection of clusters by evaluating temporal changes of a shape-dependent clusters feature. The final classification is done by a time delay neural network (TDNN) with spatio-temporal receptive fields."
            },
            "slug": "Motion-based-recognition-of-pedestrians-Heisele-W\u00f6hler",
            "title": {
                "fragments": [],
                "text": "Motion-based recognition of pedestrians"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "An algorithm for recognizing walking pedestrians in sequences of color images taken from a moving camera based on the characteristic motion of the legs of a pedestrian walking parallel to the image plane with time delay neural network with spatio-temporal receptive fields."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. Fourteenth International Conference on Pattern Recognition (Cat. No.98EX170)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143847264"
                        ],
                        "name": "Bo Wu",
                        "slug": "Bo-Wu",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144862593"
                        ],
                        "name": "R. Nevatia",
                        "slug": "R.-Nevatia",
                        "structuredName": {
                            "firstName": "Ramakant",
                            "lastName": "Nevatia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nevatia"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 164
                            }
                        ],
                        "text": "They cover both passive and active safety techniques, the latter using (possibly) multiple vision and nonvision sensors, together with methods for collision risk assessment."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2536395,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "49bdd3fb166e0faf7ad1c917aee32c22ebc0f9db",
            "isKey": false,
            "numCitedBy": 782,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Detection and tracking of humans in video streams is important for many applications. We present an approach to automatically detect and track multiple, possibly partially occluded humans in a walking or standing pose from a single camera, which may be stationary or moving. A human body is represented as an assembly of body parts. Part detectors are learned by boosting a number of weak classifiers which are based on edgelet features. Responses of part detectors are combined to form a joint likelihood model that includes an analysis of possible occlusions. The combined detection responses and the part detection responses provide the observations used for tracking. Trajectory initialization and termination are both automatic and rely on the confidences computed from the detection responses. An object is tracked by data association and meanshift methods. Our system can track humans with both inter-object and scene occlusions with static or non-static backgrounds. Evaluation results on a number of images and videos and comparisons with some previous methods are given."
            },
            "slug": "Detection-and-Tracking-of-Multiple,-Partially-by-of-Wu-Nevatia",
            "title": {
                "fragments": [],
                "text": "Detection and Tracking of Multiple, Partially Occluded Humans by Bayesian Combination of Edgelet based Part Detectors"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "This work presents an approach to automatically detect and track multiple, possibly partially occluded humans in a walking or standing pose from a single camera, which may be stationary or moving."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789756"
                        ],
                        "name": "B. Leibe",
                        "slug": "B.-Leibe",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Leibe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Leibe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2083209039"
                        ],
                        "name": "Edgar Seemann",
                        "slug": "Edgar-Seemann",
                        "structuredName": {
                            "firstName": "Edgar",
                            "lastName": "Seemann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Edgar Seemann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48920094"
                        ],
                        "name": "B. Schiele",
                        "slug": "B.-Schiele",
                        "structuredName": {
                            "firstName": "Bernt",
                            "lastName": "Schiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schiele"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "While the latter two require models of the pedestrian class, e.g., in terms of geometry, appearance, or dynamics, the initial generation of regions of interest is usually based on more general low-level features or prior scene knowledge."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14395688,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1854005a7178b2df6afaacdcf91bc35d90616075",
            "isKey": false,
            "numCitedBy": 932,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we address the problem of detecting pedestrians in crowded real-world scenes with severe overlaps. Our basic premise is that this problem is too difficult for any type of model or feature alone. Instead, we present an algorithm that integrates evidence in multiple iterations and from different sources. The core part of our method is the combination of local and global cues via probabilistic top-down segmentation. Altogether, this approach allows examining and comparing object hypotheses with high precision down to the pixel level. Qualitative and quantitative results on a large data set confirm that our method is able to reliably detect pedestrians in crowded scenes, even when they overlap and partially occlude each other. In addition, the flexible nature of our approach allows it to operate on very small training sets."
            },
            "slug": "Pedestrian-detection-in-crowded-scenes-Leibe-Seemann",
            "title": {
                "fragments": [],
                "text": "Pedestrian detection in crowded scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Qualitative and quantitative results on a large data set confirm that the core part of the method is the combination of local and global cues via probabilistic top-down segmentation that allows examining and comparing object hypotheses with high precision down to the pixel level."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48950628"
                        ],
                        "name": "N. Dalal",
                        "slug": "N.-Dalal",
                        "structuredName": {
                            "firstName": "Navneet",
                            "lastName": "Dalal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Dalal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 37581938,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "47980c6e42f1a3381e6c5f3db7230e6a64c40218",
            "isKey": false,
            "numCitedBy": 369,
            "numCiting": 218,
            "paperAbstract": {
                "fragments": [],
                "text": "This thesis targets the detection of humans and other object classes in images and videos. Our focus is on developing robust feature extraction algorithms that encode image regions as highdimensional feature vectors that support high accuracy object/non-object decisions. To test our feature sets we adopt a relatively simple learning framework that uses linear Support Vector Machines to classify each possible image region as an object or as a non-object. The approach is data-driven and purely bottom-up using low-level appearance and motion vectors to detect objects. As a test case we focus on person detection as people are one of the most challenging object classes with many applications, for example in film and video analysis, pedestrian detection for smart cars and video surveillance. Nevertheless we do not make any strong class specific assumptions and the resulting object detection framework also gives state-of-the-art performance for many other classes including cars, motorbikes, cows and sheep. This thesis makes four main contributions. Firstly, we introduce grids of locally normalised Histograms of Oriented Gradients (HOG) as descriptors for object detection in static images. The HOG descriptors are computed over dense and overlapping grids of spatial blocks, with image gradient orientation features extracted at fixed resolution and gathered into a highdimensional feature vector. They are designed to be robust to small changes in image contour locations and directions, and significant changes in image illumination and colour, while remaining highly discriminative for overall visual form. We show that unsmoothed gradients, fine orientation voting, moderately coarse spatial binning, strong normalisation and overlapping blocks are all needed for good performance. Secondly, to detect moving humans in videos, we propose descriptors based on oriented histograms of differential optical flow. These are similar to static HOG descriptors, but instead of image gradients, they are based on local differentials of dense optical flow. They encode the noisy optical flow estimates into robust feature vectors in a manner that is robust to the overall camera motion. Several variants are proposed, some capturing motion boundaries while others encode the relative motions of adjacent image regions. Thirdly, we propose a general method based on kernel density estimation for fusing multiple overlapping detections, that takes into account the number of detections, their confidence scores and the scales of the detections. Lastly, we present work in progress on a parts based approach to person detection that first detects local body parts like heads, torso, and legs and then fuses them to create a global overall person detector."
            },
            "slug": "Finding-People-in-Images-and-Videos-Dalal",
            "title": {
                "fragments": [],
                "text": "Finding People in Images and Videos"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This thesis introduces grids of locally normalised Histograms of Oriented Gradients (HOG) as descriptors for object detection in static images and proposes descriptors based on oriented histograms of differential optical flow to detect moving humans in videos."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116733876"
                        ],
                        "name": "Liang Zhao",
                        "slug": "Liang-Zhao",
                        "structuredName": {
                            "firstName": "Liang",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liang Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34588530"
                        ],
                        "name": "C. Thorpe",
                        "slug": "C.-Thorpe",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Thorpe",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Thorpe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "While the latter two require models of the pedestrian class, e.g., in terms of geometry, appearance, or dynamics, the initial generation of regions of interest is usually based on more general low-level features or prior scene knowledge."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8206308,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "23427eec9461925103bdb5772643987f16590544",
            "isKey": false,
            "numCitedBy": 309,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a real-time pedestrian detection system that uses a pair of moving cameras to detect both stationary and moving pedestrians in crowded environments. This is achieved through stereo-based segmentation and neural network-based recognition. Stereo-based segmentation allows us to extract objects from a changing background; neural network-based recognition allows us to identify pedestrians in various poses, shapes, sizes, clothing, occlusion status. The experiments on a large number of urban street scenes demonstrate the feasibility of the approach in terms of pedestrian detection rate and frame processing rate."
            },
            "slug": "Stereo-and-neural-network-based-pedestrian-Zhao-Thorpe",
            "title": {
                "fragments": [],
                "text": "Stereo- and neural network-based pedestrian detection"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "A real-time pedestrian detection system that uses a pair of moving cameras to detect both stationary and moving pedestrians in crowded environments through stereo-based segmentation and neural network-based recognition is presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Intell. Transp. Syst."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2124866301"
                        ],
                        "name": "A. Mohan",
                        "slug": "A.-Mohan",
                        "structuredName": {
                            "firstName": "Anuj",
                            "lastName": "Mohan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Mohan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145030811"
                        ],
                        "name": "C. Papageorgiou",
                        "slug": "C.-Papageorgiou",
                        "structuredName": {
                            "firstName": "Constantine",
                            "lastName": "Papageorgiou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Papageorgiou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 81
                            }
                        ],
                        "text": "Gandhi and Trivedi [20] focus on the pedestrian protection application in the intelligent vehicle domain."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2559322,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "448bd4e124175ad358078a7b930ecad994c97812",
            "isKey": false,
            "numCitedBy": 1137,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a general example-based framework for detecting objects in static images by components. The technique is demonstrated by developing a system that locates people in cluttered scenes. The system is structured with four distinct example-based detectors that are trained to separately find the four components of the human body: the head, legs, left arm, and right arm. After ensuring that these components are present in the proper geometric configuration, a second example-based classifier combines the results of the component detectors to classify a pattern as either a \"person\" or a \"nonperson.\" We call this type of hierarchical architecture, in which learning occurs at multiple stages, an adaptive combination of classifiers (ACC). We present results that show that this system performs significantly better than a similar full-body person detector. This suggests that the improvement in performance is due to the component-based approach and the ACC data classification architecture. The algorithm is also more robust than the full-body person detection method in that it is capable of locating partially occluded views of people and people whose body parts have little contrast with the background."
            },
            "slug": "Example-Based-Object-Detection-in-Images-by-Mohan-Papageorgiou",
            "title": {
                "fragments": [],
                "text": "Example-Based Object Detection in Images by Components"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Results suggest that the improvement in performance is due to the component-based approach and the ACC data classification architecture, which is capable of locating partially occluded views of people and people whose body parts have little contrast with the background."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 134
                            }
                        ],
                        "text": "They cover both passive and active safety techniques, the latter using (possibly) multiple vision and nonvision sensors, together with methods for collision risk assessment."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3870070,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9cc6155cd69023a736a7b8f8680bcd6232c840e",
            "isKey": false,
            "numCitedBy": 764,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a novel method for human detection in single images which can detect full bodies as well as close-up views in the presence of clutter and occlusion. Humans are modeled as flexible assemblies of parts, and robust part detection is the key to the approach. The parts are represented by co-occurrences of local features which captures the spatial layout of the partrsquos appearance. Feature selection and the part detectors are learnt from training images using AdaBoost. The detection algorithm is very efficient as (i) all part detectors use the same initial features, (ii) a coarse-to-fine cascade approach is used for part detection, (iii) a part assembly strategy reduces the number of spurious detections and the search space. The results outperform existing human detectors."
            },
            "slug": "Human-Detection-Based-on-a-Probabilistic-Assembly-Mikolajczyk-Schmid",
            "title": {
                "fragments": [],
                "text": "Human Detection Based on a Probabilistic Assembly of Robust Part Detectors"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A novel method for human detection in single images which can detect full bodies as well as close-up views in the presence of clutter and occlusion is described."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9964342"
                        ],
                        "name": "M. Szarvas",
                        "slug": "M.-Szarvas",
                        "structuredName": {
                            "firstName": "M\u00e1t\u00e9",
                            "lastName": "Szarvas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Szarvas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064423882"
                        ],
                        "name": "A. Yoshizawa",
                        "slug": "A.-Yoshizawa",
                        "structuredName": {
                            "firstName": "A",
                            "lastName": "Yoshizawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yoshizawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112503258"
                        ],
                        "name": "M. Yamamoto",
                        "slug": "M.-Yamamoto",
                        "structuredName": {
                            "firstName": "Masahiro",
                            "lastName": "Yamamoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Yamamoto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059185014"
                        ],
                        "name": "J. Ogata",
                        "slug": "J.-Ogata",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Ogata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ogata"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 99
                            }
                        ],
                        "text": "Gandhi and Trivedi [20] focus on the pedestrian protection application in the intelligent vehicle domain."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 33935024,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "47caac4cf1169cd46f38c8ecb30a9906be0efc88",
            "isKey": false,
            "numCitedBy": 173,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel pedestrian detection method based on the use of a convolutional neural network (CNN) classifier. Our method achieves high accuracy by automatically optimizing the feature representation to the detection task and regularizing the neural network. We evaluate the proposed method on a difficult database containing pedestrians in a city environment with no restrictions on pose, action, background and lighting conditions. The false positive rate (FPR) of the proposed CNN classifier is less than 1/5-th of the FPR of a support vector machine (SVM) classifier using Haar-wavelet features when the detection rate is 90%. The accuracy of the SVM classifier using the features learnt by the CNN is equivalent to the accuracy of the CNN, confirming the importance of automatically optimized features. The computational demand of the CNN classifier is, however, more than an order of magnitude lower than that of the SVM, irrespective of the type of features used."
            },
            "slug": "Pedestrian-detection-with-convolutional-neural-Szarvas-Yoshizawa",
            "title": {
                "fragments": [],
                "text": "Pedestrian detection with convolutional neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "A novel pedestrian detection method based on the use of a convolutional neural network (CNN) classifier that achieves high accuracy by automatically optimizing the feature representation to the detection task and regularizing the neural network."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Proceedings. Intelligent Vehicles Symposium, 2005."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50118130"
                        ],
                        "name": "Ying Wu",
                        "slug": "Ying-Wu",
                        "structuredName": {
                            "firstName": "Ying",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ying Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117900326"
                        ],
                        "name": "Ting Yu",
                        "slug": "Ting-Yu",
                        "structuredName": {
                            "firstName": "Ting",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ting Yu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The main difference between generative and discriminative models is how posterior probabilities are estimated for each class."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206764155,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ea90acb03f57c1b226f6084524250002ad56bbb1",
            "isKey": false,
            "numCitedBy": 81,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "The large shape variability and partial occlusions challenge most object detection and tracking methods for nonrigid targets such as pedestrians. This paper presents a new approach based on a two-layer statistical field model that characterizes the prior of the complex shape variations as a Boltzmann distribution and embeds this prior and the complex image likelihood into a Markov field. A probabilistic variational analysis of this model reveals a set of fixed-point equations characterizing the equilibrium of the field. It leads to computationally efficient methods for calculating the image likelihood and for training the model. Based on that, effective algorithms for detecting nonrigid objects are developed. This new approach has several advantages. First, it is intrinsically suitable for capturing local nonrigidity. In addition, due to the distributed likelihood, this approach is robust to partial occlusions. Moreover, the two-layer structure provides large flexibility of modeling the image observations, which makes the new method robust to clutters. Extensive experiments demonstrate its effectiveness."
            },
            "slug": "A-field-model-for-human-detection-and-tracking-Wu-Yu",
            "title": {
                "fragments": [],
                "text": "A field model for human detection and tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new approach based on a two-layer statistical field model that characterizes the prior of the complex shape variations as a Boltzmann distribution and embeds this prior and the complex image likelihood into a Markov field, which makes the new method robust to clutters."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789756"
                        ],
                        "name": "B. Leibe",
                        "slug": "B.-Leibe",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Leibe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Leibe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2590936"
                        ],
                        "name": "Nico Cornelis",
                        "slug": "Nico-Cornelis",
                        "structuredName": {
                            "firstName": "Nico",
                            "lastName": "Cornelis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nico Cornelis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804147"
                        ],
                        "name": "K. Cornelis",
                        "slug": "K.-Cornelis",
                        "structuredName": {
                            "firstName": "Kurt",
                            "lastName": "Cornelis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Cornelis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u00c7"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 151
                            }
                        ],
                        "text": "While the latter two require models of the pedestrian class, e.g., in terms of geometry, appearance, or dynamics, the initial generation of regions of interest is usually based on more general low-level features or prior scene knowledge."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12056046,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "82fa8d73891ce6476d58f11d6e3b563af21d0a3a",
            "isKey": false,
            "numCitedBy": 347,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a system that integrates fully automatic scene geometry estimation, 2D object detection, 3D localization, trajectory estimation, and tracking for dynamic scene interpretation from a moving vehicle. Our sole input are two video streams from a calibrated stereo rig on top of a car. From these streams, we estimate structure-from-motion (SfM) and scene geometry in real-time. In parallel, we perform multi-view/multi-category object recognition to detect cars and pedestrians in both camera images. Using the SfM self-localization, 2D object detections are converted to 3D observations, which are accumulated in a world coordinate frame. A subsequent tracking module analyzes the resulting 3D observations to find physically plausible spacetime trajectories. Finally, a global optimization criterion takes object-object interactions into account to arrive at accurate 3D localization and trajectory estimates for both cars and pedestrians. We demonstrate the performance of our integrated system on challenging real-world data showing car passages through crowded city areas."
            },
            "slug": "Dynamic-3D-Scene-Analysis-from-a-Moving-Vehicle-Leibe-Cornelis",
            "title": {
                "fragments": [],
                "text": "Dynamic 3D Scene Analysis from a Moving Vehicle"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A system that integrates fully automatic scene geometry estimation, 2D object detection, 3D localization, trajectory estimation, and tracking for dynamic scene interpretation from a moving vehicle and demonstrates the performance of this integrated system on challenging real-world data showing car passages through crowded city areas."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152835649"
                        ],
                        "name": "Li Zhang",
                        "slug": "Li-Zhang",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143847264"
                        ],
                        "name": "Bo Wu",
                        "slug": "Bo-Wu",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144862593"
                        ],
                        "name": "R. Nevatia",
                        "slug": "R.-Nevatia",
                        "structuredName": {
                            "firstName": "Ramakant",
                            "lastName": "Nevatia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nevatia"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 170
                            }
                        ],
                        "text": "They cover both passive and active safety techniques, the latter using (possibly) multiple vision and nonvision sensors, together with methods for collision risk assessment."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8496483,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "86f918a351efd6e0c283dd9b526c9da2330f18c3",
            "isKey": false,
            "numCitedBy": 64,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a method for detecting and tracking humans. Different from most of the previous work, we focus on humans with extensive pose articulations, under situations where there is typically only a single camera, multiple humans are present and the image resolution is low. In our method pose clusters are learned from an embedded silhouette manifold. A set of object detectors, each of which corresponds to one pose cluster, are trained based on a novel Object-Weighted Appearance Model. A probabilistic pose-based transition model is used to track multiple objects within a sliding window buffer, making use of the detection responses. The track segments in the sliding windows are connected sequentially into full trajectories. Experiments on a set of challenging surveillance videos are presented; these show good performance of our approach compared to standard pedestrian detectors, under difficult conditions."
            },
            "slug": "Detection-and-Tracking-of-Multiple-Humans-with-Pose-Zhang-Wu",
            "title": {
                "fragments": [],
                "text": "Detection and Tracking of Multiple Humans with Extensive Pose Articulation"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "This work describes a method for detecting and tracking humans with extensive pose articulations, under situations where there is typically only a single camera, multiple humans are present and the image resolution is low."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE 11th International Conference on Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2083209039"
                        ],
                        "name": "Edgar Seemann",
                        "slug": "Edgar-Seemann",
                        "structuredName": {
                            "firstName": "Edgar",
                            "lastName": "Seemann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Edgar Seemann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739548"
                        ],
                        "name": "Mario Fritz",
                        "slug": "Mario-Fritz",
                        "structuredName": {
                            "firstName": "Mario",
                            "lastName": "Fritz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mario Fritz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48920094"
                        ],
                        "name": "B. Schiele",
                        "slug": "B.-Schiele",
                        "structuredName": {
                            "firstName": "Bernt",
                            "lastName": "Schiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schiele"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "While the latter two require models of the pedestrian class, e.g., in terms of geometry, appearance, or dynamics, the initial generation of regions of interest is usually based on more general low-level features or prior scene knowledge."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6240352,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4736c2b507a05aa3848dc049003a6b1bd62da221",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Object class detection in scenes of realistic complexity remains a challenging task in computer vision. Most recent approaches focus on a single and general model for object class detection. However, in particular in the context of image sequences, it may be advantageous to adapt the general model to a more object-instance specific model in order to detect this particular object reliably within the image sequence. In this work we present a generative object model that is capable to scale from a general object class model to a more specific object-instance model. This allows to detect class instances as well as to distinguish between individual object instances reliably. We experimentally evaluate the performance of the proposed system on both still images and image sequences."
            },
            "slug": "Towards-Robust-Pedestrian-Detection-in-Crowded-Seemann-Fritz",
            "title": {
                "fragments": [],
                "text": "Towards Robust Pedestrian Detection in Crowded Image Sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work presents a generative object model that is capable to scale from a general object class model to a more specific object-instance model that allows to detect class instances as well as to distinguish between individual object instances reliably."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48950628"
                        ],
                        "name": "N. Dalal",
                        "slug": "N.-Dalal",
                        "structuredName": {
                            "firstName": "Navneet",
                            "lastName": "Dalal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Dalal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 75
                            }
                        ],
                        "text": "Gandhi and Trivedi [20] focus on the pedestrian protection application in the intelligent vehicle domain."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8729004,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "44f3ac3277c2eb6e5599739eb875888c46e21d4c",
            "isKey": false,
            "numCitedBy": 1776,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Detecting humans in films and videos is a challenging problem owing to the motion of the subjects, the camera and the background and to variations in pose, appearance, clothing, illumination and background clutter. We develop a detector for standing and moving people in videos with possibly moving cameras and backgrounds, testing several different motion coding schemes and showing empirically that orientated histograms of differential optical flow give the best overall performance. These motion-based descriptors are combined with our Histogram of Oriented Gradient appearance descriptors. The resulting detector is tested on several databases including a challenging test set taken from feature films and containing wide ranges of pose, motion and background variations, including moving cameras and backgrounds. We validate our results on two challenging test sets containing more than 4400 human examples. The combined detector reduces the false alarm rate by a factor of 10 relative to the best appearance-based detector, for example giving false alarm rates of 1 per 20,000 windows tested at 8% miss rate on our Test Set 1."
            },
            "slug": "Human-Detection-Using-Oriented-Histograms-of-Flow-Dalal-Triggs",
            "title": {
                "fragments": [],
                "text": "Human Detection Using Oriented Histograms of Flow and Appearance"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A detector for standing and moving people in videos with possibly moving cameras and backgrounds is developed, testing several different motion coding schemes and showing empirically that orientated histograms of differential optical flow give the best overall performance."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765022"
                        ],
                        "name": "M. Enzweiler",
                        "slug": "M.-Enzweiler",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Enzweiler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Enzweiler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144854796"
                        ],
                        "name": "D. Gavrila",
                        "slug": "D.-Gavrila",
                        "structuredName": {
                            "firstName": "Dariu",
                            "lastName": "Gavrila",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gavrila"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The main difference between generative and discriminative models is how posterior probabilities are estimated for each class."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15313311,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92273cd8fc8ef9dcf74455d7fe7ffac7f016820c",
            "isKey": false,
            "numCitedBy": 107,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel approach to pedestrian classification which involves utilizing the synthesized virtual samples of a learned generative model to enhance the classification performance of a discriminative model. Our generative model captures prior knowledge about the pedestrian class in terms of a number of probabilistic shape and texture models, each attuned to a particular pedestrian pose. Active learning provides the link between the generative and discriminative model, in the sense that the former is selectively sampled such that the training process is guided towards the most informative samples of the latter. In large-scale experiments on real-world datasets of tens of thousands of samples, we demonstrate a significant improvement in classification performance of the combined generative-discriminative approach over the discriminative-only approach (the latter exemplified by a neural network with local receptive fields and a support vector machine using Haar wavelet features)."
            },
            "slug": "A-mixed-generative-discriminative-framework-for-Enzweiler-Gavrila",
            "title": {
                "fragments": [],
                "text": "A mixed generative-discriminative framework for pedestrian classification"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A significant improvement in classification performance of the combined generative-discriminative approach over the discriminative-only approach (the latter exemplified by a neural network with local receptive fields and a support vector machine using Haar wavelet features)."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433494"
                        ],
                        "name": "Andreas Ess",
                        "slug": "Andreas-Ess",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Ess",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Ess"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789756"
                        ],
                        "name": "B. Leibe",
                        "slug": "B.-Leibe",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Leibe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Leibe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "While the latter two require models of the pedestrian class, e.g., in terms of geometry, appearance, or dynamics, the initial generation of regions of interest is usually based on more general low-level features or prior scene knowledge."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16824129,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "590941c26d057f917c7f5275824d350e9aac7ba3",
            "isKey": false,
            "numCitedBy": 545,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we address the challenging problem of simultaneous pedestrian detection and ground-plane estimation from video while walking through a busy pedestrian zone. Our proposed system integrates robust stereo depth cues, ground-plane estimation, and appearance-based object detection in a principled fashion using a graphical model. Object-object occlusions lead to complex interactions in this model that make an exact solution computationally intractable. We therefore propose a novel iterative approach that first infers scene geometry using belief propagation and then resolves interactions between objects using a global optimization procedure. This approach leads to a robust solution in few iterations, while allowing object detection to benefit from geometry estimation and vice versa. We quantitatively evaluate the performance of our proposed approach on several challenging test sequences showing strolls through busy shopping streets. Comparisons to various baseline systems show that it outperforms both a system using no scene geometry and one just relying on structure-from-motion without dense stereo."
            },
            "slug": "Depth-and-Appearance-for-Mobile-Scene-Analysis-Ess-Leibe",
            "title": {
                "fragments": [],
                "text": "Depth and Appearance for Mobile Scene Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work proposes a novel iterative approach that first infers scene geometry using belief propagation and then resolves interactions between objects using a global optimization procedure, which leads to a robust solution in few iterations, while allowing object detection to benefit from geometry estimation and vice versa."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE 11th International Conference on Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145030811"
                        ],
                        "name": "C. Papageorgiou",
                        "slug": "C.-Papageorgiou",
                        "structuredName": {
                            "firstName": "Constantine",
                            "lastName": "Papageorgiou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Papageorgiou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 87
                            }
                        ],
                        "text": "Gandhi and Trivedi [20] focus on the pedestrian protection application in the intelligent vehicle domain."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13308232,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e6c20ed0c3f375f403ab5d750a6e9699d5c3af6a",
            "isKey": false,
            "numCitedBy": 1404,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a general, trainable system for object detection in unconstrained, cluttered scenes. The system derives much of its power from a representation that describes an object class in terms of an overcomplete dictionary of local, oriented, multiscale intensity differences between adjacent regions, efficiently computable as a Haar wavelet transform. This example-based learning approach implicitly derives a model of an object class by training a support vector machine classifier using a large set of positive and negative examples. We present results on face, people, and car detection tasks using the same architecture. In addition, we quantify how the representation affects detection performance by considering several alternate representations including pixels and principal components. We also describe a real-time application of our person detection system as part of a driver assistance system."
            },
            "slug": "A-Trainable-System-for-Object-Detection-Papageorgiou-Poggio",
            "title": {
                "fragments": [],
                "text": "A Trainable System for Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A general, trainable system for object detection in unconstrained, cluttered scenes that derives much of its power from a representation that describes an object class in terms of an overcomplete dictionary of local, oriented, multiscale intensity differences between adjacent regions, efficiently computable as a Haar wavelet transform."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2797063"
                        ],
                        "name": "S. Agarwal",
                        "slug": "S.-Agarwal",
                        "structuredName": {
                            "firstName": "Shivani",
                            "lastName": "Agarwal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Agarwal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32177941"
                        ],
                        "name": "A. Awan",
                        "slug": "A.-Awan",
                        "structuredName": {
                            "firstName": "Aatif",
                            "lastName": "Awan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Awan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "While the latter two require models of the pedestrian class, e.g., in terms of geometry, appearance, or dynamics, the initial generation of regions of interest is usually based on more general low-level features or prior scene knowledge."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8855331,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b82d251ed367593366680acebc81fdb070b04a18",
            "isKey": false,
            "numCitedBy": 963,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the problem of detecting objects in still, gray-scale images. Our primary focus is the development of a learning-based approach to the problem that makes use of a sparse, part-based representation. A vocabulary of distinctive object parts is automatically constructed from a set of sample images of the object class of interest; images are then represented using parts from this vocabulary, together with spatial relations observed among the parts. Based on this representation, a learning algorithm is used to automatically learn to detect instances of the object class in new images. The approach can be applied to any object with distinguishable parts in a relatively fixed spatial configuration; it is evaluated here on difficult sets of real-world images containing side views of cars, and is seen to successfully detect objects in varying conditions amidst background clutter and mild occlusion. In evaluating object detection approaches, several important methodological issues arise that have not been satisfactorily addressed in the previous work. A secondary focus of this paper is to highlight these issues, and to develop rigorous evaluation standards for the object detection problem. A critical evaluation of our approach under the proposed standards is presented."
            },
            "slug": "Learning-to-detect-objects-in-images-via-a-sparse,-Agarwal-Awan",
            "title": {
                "fragments": [],
                "text": "Learning to detect objects in images via a sparse, part-based representation"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A learning-based approach to the problem of detecting objects in still, gray-scale images that makes use of a sparse, part-based representation is developed and a critical evaluation of the approach under the proposed standards is presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11338130"
                        ],
                        "name": "K. Okuma",
                        "slug": "K.-Okuma",
                        "structuredName": {
                            "firstName": "Kenji",
                            "lastName": "Okuma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Okuma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3210143"
                        ],
                        "name": "Ali Taleghani",
                        "slug": "Ali-Taleghani",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Taleghani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ali Taleghani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710980"
                        ],
                        "name": "J. Little",
                        "slug": "J.-Little",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Little",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Little"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 140
                            }
                        ],
                        "text": "They cover both passive and active safety techniques, the latter using (possibly) multiple vision and nonvision sensors, together with methods for collision risk assessment."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15296463,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "197c7b40c4f5ceb6b1d862de0bfc27b57e61d19d",
            "isKey": false,
            "numCitedBy": 1199,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of tracking a varying number of non-rigid objects has two major difficulties. First, the observation models and target distributions can be highly non-linear and non-Gaussian. Second, the presence of a large, varying number of objects creates complex interactions with overlap and ambiguities. To surmount these difficulties, we introduce a vision system that is capable of learning, detecting and tracking the objects of interest. The system is demonstrated in the context of tracking hockey players using video sequences. Our approach combines the strengths of two successful algorithms: mixture particle filters and Adaboost. The mixture particle filter [17] is ideally suited to multi-target tracking as it assigns a mixture component to each player. The crucial design issues in mixture particle filters are the choice of the proposal distribution and the treatment of objects leaving and entering the scene. Here, we construct the proposal distribution using a mixture model that incorporates information from the dynamic models of each player and the detection hypotheses generated by Adaboost. The learned Adaboost proposal distribution allows us to quickly detect players entering the scene, while the filtering process enables us to keep track of the individual players. The result of interleaving Adaboost with mixture particle filters is a simple, yet powerful and fully automatic multiple object tracking system."
            },
            "slug": "A-Boosted-Particle-Filter:-Multitarget-Detection-Okuma-Taleghani",
            "title": {
                "fragments": [],
                "text": "A Boosted Particle Filter: Multitarget Detection and Tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work introduces a vision system that is capable of learning, detecting and tracking the objects of interest, and interleaving Adaboost with mixture particle filters, a simple, yet powerful and fully automatic multiple object tracking system."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114102452"
                        ],
                        "name": "H. Shimizu",
                        "slug": "H.-Shimizu",
                        "structuredName": {
                            "firstName": "Hiroaki",
                            "lastName": "Shimizu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Shimizu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1845146,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "27f50aa3f9e4ec8b3428997e20f781e13834c433",
            "isKey": false,
            "numCitedBy": 91,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "The capability of estimating the walking direction of pedestrian would be useful in many applications such as those involving autonomous vehicles. We introduce an approach for estimating the walking direction of pedestrian from images, based on learning the correct classification of a still image by using SVMs. We find that the performance of the system can be improved by classifying each image of a walking sequence and combining the outputs of the classifier. Experiments were performed to evaluate our system and estimate the trade-off between number of images in walking sequences and performance."
            },
            "slug": "Direction-estimation-of-pedestrian-from-multiple-Shimizu-Poggio",
            "title": {
                "fragments": [],
                "text": "Direction estimation of pedestrian from multiple still images"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "An approach for estimating the walking direction of pedestrian from images, based on learning the correct classification of a still image by using SVMs is introduced and the performance of the system can be improved by classifying each image of a walking sequence and combining the outputs of the classifier."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Intelligent Vehicles Symposium, 2004"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2372810"
                        ],
                        "name": "T. Gandhi",
                        "slug": "T.-Gandhi",
                        "structuredName": {
                            "firstName": "Tarak",
                            "lastName": "Gandhi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Gandhi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713989"
                        ],
                        "name": "M. Trivedi",
                        "slug": "M.-Trivedi",
                        "structuredName": {
                            "firstName": "Mohan",
                            "lastName": "Trivedi",
                            "middleNames": [
                                "Manubhai"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Trivedi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 130
                            }
                        ],
                        "text": "In this paper, we are concerned with those applications where the human body to be detected covers a smaller portion of the image, i.e., is visible at lower resolution."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1029120,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "309a9f17ed711663bd6c18cb15fcba9dcd731f49",
            "isKey": false,
            "numCitedBy": 382,
            "numCiting": 112,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the recent research on the enhancement of pedestrian safety to help develop a better understanding of the nature, issues, approaches, and challenges surrounding the problem. It presents a comprehensive review of research efforts underway dealing with pedestrian safety and collision avoidance. The importance of pedestrian protection is emphasized in a global context, discussing the research programs and efforts in various countries. Pedestrian safety measures, including infrastructure enhancements and passive safety features in vehicles, are described, followed by a systematic description of active safety systems based on pedestrian detection using sensors in vehicle and infrastructure. The pedestrian detection approaches are classified according to various criteria such as the type and configuration of sensors, as well as the video cues and classifiers used in detection algorithms. It is noted that collision avoidance not only requires detection of pedestrians but also requires collision prediction using pedestrian dynamics and behavior analysis. Hence, this paper includes research dealing with probabilistic modeling of pedestrian behavior for predicting collisions between pedestrians and vehicles."
            },
            "slug": "Pedestrian-Protection-Systems:-Issues,-Survey,-and-Gandhi-Trivedi",
            "title": {
                "fragments": [],
                "text": "Pedestrian Protection Systems: Issues, Survey, and Challenges"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A comprehensive review of research efforts underway dealing with pedestrian safety and collision avoidance is presented, including research dealing with probabilistic modeling of pedestrian behavior for predicting collisions between pedestrians and vehicles."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Intelligent Transportation Systems"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769685"
                        ],
                        "name": "K. Toyama",
                        "slug": "K.-Toyama",
                        "structuredName": {
                            "firstName": "Kentaro",
                            "lastName": "Toyama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Toyama"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145162067"
                        ],
                        "name": "A. Blake",
                        "slug": "A.-Blake",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Blake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blake"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The main difference between generative and discriminative models is how posterior probabilities are estimated for each class."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 271041,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b1ecdfe517088aee1394eb5637dafc40c10e6e23",
            "isKey": false,
            "numCitedBy": 156,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "A new, exemplar-based, probabilistic paradigm for visual tracking is presented. Probabilistic mechanisms are attractive because they handle fusion of information, especially temporal fusion, in a principled manner. Exemplars are selected representatives of raw training data, used here to represent probabilistic mixture distributions of object configurations. Their use avoids tedious hand-construction of object models, and problems with changes of topology.Using exemplars in place of a parameterized model poses several challenges, addressed here with what we call the \u201cMetric Mixture\u201d (M2) approach, which has a number of attractions. Principally, it provides alternatives to standard learning algorithms by allowing the use of metrics that are not embedded in a vector space. Secondly, it uses a noise model that is learned from training data. Lastly, it eliminates any need for an assumption of probabilistic pixelwise independence.Experiments demonstrate the effectiveness of the M2 model in two domains: tracking walking people using \u201cchamfer\u201d distances on binary edge images, and tracking mouth movements by means of a shuffle distance."
            },
            "slug": "Probabilistic-Tracking-with-Exemplars-in-a-Metric-Toyama-Blake",
            "title": {
                "fragments": [],
                "text": "Probabilistic Tracking with Exemplars in a Metric Space"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "A new, exemplar-based, probabilistic paradigm for visual tracking is presented, which provides alternatives to standard learning algorithms by allowing the use of metrics that are not embedded in a vector space and uses a noise model that is learned from training data."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144854796"
                        ],
                        "name": "D. Gavrila",
                        "slug": "D.-Gavrila",
                        "structuredName": {
                            "firstName": "Dariu",
                            "lastName": "Gavrila",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gavrila"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The main difference between generative and discriminative models is how posterior probabilities are estimated for each class."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1546912,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c1d6d01b2b392d99b1903334023784b60067f840",
            "isKey": false,
            "numCitedBy": 310,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel probabilistic approach to hierarchical, exemplar-based shape matching. No feature correspondence is needed among exemplars, just a suitable pairwise similarity measure. The approach uses a template tree to efficiently represent and match the variety of shape exemplars. The tree is generated offline by a bottom-up clustering approach using stochastic optimization. Online matching involves a simultaneous coarse-to-fine approach over the template tree and over the transformation parameters. The main contribution of this paper is a Bayesian model to estimate the a posteriori probability of the object class, after a certain match at a node of the tree. This model takes into account object scale and saliency and allows for a principled setting of the matching thresholds such that unpromising paths in the tree traversal process are eliminated early on. The proposed approach was tested in a variety of application domains. Here, results are presented on one of the more challenging domains: real-time pedestrian detection from a moving vehicle. A significant speed-up is obtained when comparing the proposed probabilistic matching approach with a manually tuned nonprobabilistic variant, both utilizing the same template tree structure."
            },
            "slug": "A-Bayesian,-Exemplar-Based-Approach-to-Hierarchical-Gavrila",
            "title": {
                "fragments": [],
                "text": "A Bayesian, Exemplar-Based Approach to Hierarchical Shape Matching"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A Bayesian model to estimate the a posteriori probability of the object class, after a certain match at a node of the tree, is presented, takes into account object scale and saliency and allows for a principled setting of the matching thresholds such that unpromising paths in the tree traversal process are eliminated early on."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704879"
                        ],
                        "name": "H. Kjellstr\u00f6m",
                        "slug": "H.-Kjellstr\u00f6m",
                        "structuredName": {
                            "firstName": "Hedvig",
                            "lastName": "Kjellstr\u00f6m",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kjellstr\u00f6m"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "To reduce the complexity of parameter estimation, the relation of the\nfitting error and associated model parameters can be learned from examples [9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1255196,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "c368eb34697350e2d9921a5354ddda76813408c3",
            "isKey": false,
            "numCitedBy": 165,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper address the problems of modeling the appearance of humans and distinguishing human appearance from the appearance of general scenes. We seek a model of appearance and motion that is generic in that it accounts for the ways in which people's appearance varies and, at the same time, is specific enough to be useful for tracking people in natural scenes. Given a 3D model of the person projected into an image we model the likelihood of observing various image cues conditioned on the predicted locations and orientations of the limbs. These cues are taken to be steered filter responses corresponding to edges, ridges, and motion-compensated temporal differences. Motivated by work on the statistics of natural scenes, the statistics of these filter responses for human limbs are learned from training images containing hand-labeled limb regions. Similarly, the statistics of the filter responses in general scenes are learned to define a \u201cbackground\u201d distribution. The likelihood of observing a scene given a predicted pose of a person is computed, for each limb, using the likelihood ratio between the learned foreground (person) and background distributions. Adopting a Bayesian formulation allows cues to be combined in a principled way. Furthermore, the use of learned distributions obviates the need for hand-tuned image noise models and thresholds. The paper provides a detailed analysis of the statistics of how people appear in scenes and provides a connection between work on natural image statistics and the Bayesian tracking of people."
            },
            "slug": "Learning-the-Statistics-of-People-in-Images-and-Kjellstr\u00f6m-Black",
            "title": {
                "fragments": [],
                "text": "Learning the Statistics of People in Images and Video"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The paper provides a detailed analysis of the statistics of how people appear in scenes and provides a connection between work on natural image statistics and the Bayesian tracking of people."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48950628"
                        ],
                        "name": "N. Dalal",
                        "slug": "N.-Dalal",
                        "structuredName": {
                            "firstName": "Navneet",
                            "lastName": "Dalal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Dalal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 69
                            }
                        ],
                        "text": "Gandhi and Trivedi [20] focus on the pedestrian protection application in the intelligent vehicle domain."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "\u00c7"
                    },
                    "intents": []
                }
            ],
            "corpusId": 206590483,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cec734d7097ab6b1e60d95228ffd64248eb89d66",
            "isKey": false,
            "numCitedBy": 29263,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the question of feature sets for robust visual object recognition; adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds."
            },
            "slug": "Histograms-of-oriented-gradients-for-human-Dalal-Triggs",
            "title": {
                "fragments": [],
                "text": "Histograms of oriented gradients for human detection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection, and the influence of each stage of the computation on performance is studied."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144739319"
                        ],
                        "name": "R. Lienhart",
                        "slug": "R.-Lienhart",
                        "structuredName": {
                            "firstName": "Rainer",
                            "lastName": "Lienhart",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Lienhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3189904"
                        ],
                        "name": "Jochen Maydt",
                        "slug": "Jochen-Maydt",
                        "structuredName": {
                            "firstName": "Jochen",
                            "lastName": "Maydt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jochen Maydt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11554984,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9fb7b636edeaf344394fdf37481d7b83eec75358",
            "isKey": false,
            "numCitedBy": 3205,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently Viola et al. [2001] have introduced a rapid object detection. scheme based on a boosted cascade of simple feature classifiers. In this paper we introduce a novel set of rotated Haar-like features. These novel features significantly enrich the simple features of Viola et al. and can also be calculated efficiently. With these new rotated features our sample face detector shows off on average a 10% lower false alarm rate at a given hit rate. We also present a novel post optimization procedure for a given boosted cascade improving on average the false alarm rate further by 12.5%."
            },
            "slug": "An-extended-set-of-Haar-like-features-for-rapid-Lienhart-Maydt",
            "title": {
                "fragments": [],
                "text": "An extended set of Haar-like features for rapid object detection"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "This paper introduces a novel set of rotated Haar-like features that significantly enrich the simple features of Viola et al. scheme based on a boosted cascade of simple feature classifiers."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. International Conference on Image Processing"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144238410"
                        ],
                        "name": "Qiang Zhu",
                        "slug": "Qiang-Zhu",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39369497"
                        ],
                        "name": "Mei-Chen Yeh",
                        "slug": "Mei-Chen-Yeh",
                        "structuredName": {
                            "firstName": "Mei-Chen",
                            "lastName": "Yeh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mei-Chen Yeh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143766349"
                        ],
                        "name": "K. Cheng",
                        "slug": "K.-Cheng",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Cheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Cheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1815078"
                        ],
                        "name": "S. Avidan",
                        "slug": "S.-Avidan",
                        "structuredName": {
                            "firstName": "Shai",
                            "lastName": "Avidan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Avidan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7800101,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "05fe01b57b3ba58dc5029c068a48567b55018ea5",
            "isKey": false,
            "numCitedBy": 1568,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We integrate the cascade-of-rejectors approach with the Histograms of Oriented Gradients (HoG) features to achieve a fast and accurate human detection system. The features used in our system are HoGs of variable-size blocks that capture salient features of humans automatically. Using AdaBoost for feature selection, we identify the appropriate set of blocks, from a large set of possible blocks. In our system, we use the integral image representation and a rejection cascade which significantly speed up the computation. For a 320 \u00d7 280 image, the system can process 5 to 30 frames per second depending on the density in which we scan the image, while maintaining an accuracy level similar to existing methods."
            },
            "slug": "Fast-Human-Detection-Using-a-Cascade-of-Histograms-Zhu-Yeh",
            "title": {
                "fragments": [],
                "text": "Fast Human Detection Using a Cascade of Histograms of Oriented Gradients"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This work integrates the cascade-of-rejectors approach with the Histograms of Oriented Gradients features to achieve a fast and accurate human detection system that can process 5 to 30 frames per second depending on the density in which the image is scanned, while maintaining an accuracy level similar to existing methods."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140335"
                        ],
                        "name": "A. Shashua",
                        "slug": "A.-Shashua",
                        "structuredName": {
                            "firstName": "Amnon",
                            "lastName": "Shashua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shashua"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1915667"
                        ],
                        "name": "Y. Gdalyahu",
                        "slug": "Y.-Gdalyahu",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Gdalyahu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Gdalyahu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2079194"
                        ],
                        "name": "G. Hayun",
                        "slug": "G.-Hayun",
                        "structuredName": {
                            "firstName": "Gaby",
                            "lastName": "Hayun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Hayun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 163
                            }
                        ],
                        "text": "While the latter two require models of the pedestrian class, e.g., in terms of geometry, appearance, or dynamics, the initial generation of regions of interest is usually based on more general low-level features or prior scene knowledge."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14981509,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "37a15ce03c26ec83d95bf4aaf756a41370d50353",
            "isKey": false,
            "numCitedBy": 404,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the functional and architectural breakdown of a monocular pedestrian detection system. We describe in detail our approach for single-frame classification based on a novel scheme of breaking down the class variability by repeatedly training a set of relatively simple classifiers on clusters of the training set. Single-frame classification performance results and system level performance figures for daytime conditions are presented with a discussion about the remaining gap to meet a daytime normal weather condition production system."
            },
            "slug": "Pedestrian-detection-for-driving-assistance-and-Shashua-Gdalyahu",
            "title": {
                "fragments": [],
                "text": "Pedestrian detection for driving assistance systems: single-frame classification and system level performance"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "The functional and architectural breakdown of a monocular pedestrian detection system is described and the approach for single-frame classification based on a novel scheme of breaking down the class variability by repeatedly training a set of relatively simple classifiers on clusters of the training set is described."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Intelligent Vehicles Symposium, 2004"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700569"
                        ],
                        "name": "T. Moeslund",
                        "slug": "T.-Moeslund",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Moeslund",
                            "middleNames": [
                                "Baltzer"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Moeslund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144046599"
                        ],
                        "name": "A. Hilton",
                        "slug": "A.-Hilton",
                        "structuredName": {
                            "firstName": "Adrian",
                            "lastName": "Hilton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hilton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48378203"
                        ],
                        "name": "V. Kr\u00fcger",
                        "slug": "V.-Kr\u00fcger",
                        "structuredName": {
                            "firstName": "Volker",
                            "lastName": "Kr\u00fcger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Kr\u00fcger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "In this paper, we are concerned with those applications where the human body to be detected covers a smaller portion of the image, i.e., is visible at lower resolution."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9815253,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c4e16d64b77d133b7382440a08091d64008dd923",
            "isKey": false,
            "numCitedBy": 2738,
            "numCiting": 520,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-survey-of-advances-in-vision-based-human-motion-Moeslund-Hilton",
            "title": {
                "fragments": [],
                "text": "A survey of advances in vision-based human motion capture and analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688865"
                        ],
                        "name": "A. Broggi",
                        "slug": "A.-Broggi",
                        "structuredName": {
                            "firstName": "Alberto",
                            "lastName": "Broggi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Broggi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758448"
                        ],
                        "name": "A. Fascioli",
                        "slug": "A.-Fascioli",
                        "structuredName": {
                            "firstName": "Alessandra",
                            "lastName": "Fascioli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Fascioli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97946138"
                        ],
                        "name": "I. Fedriga",
                        "slug": "I.-Fedriga",
                        "structuredName": {
                            "firstName": "Isabella",
                            "lastName": "Fedriga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Fedriga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "96145099"
                        ],
                        "name": "A. Tibaldi",
                        "slug": "A.-Tibaldi",
                        "structuredName": {
                            "firstName": "Amos",
                            "lastName": "Tibaldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Tibaldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30407500"
                        ],
                        "name": "M. Rose",
                        "slug": "M.-Rose",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Rose",
                            "middleNames": [
                                "S.",
                                "Del"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Rose"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "While the latter two require models of the pedestrian class, e.g., in terms of geometry, appearance, or dynamics, the initial generation of regions of interest is usually based on more general low-level features or prior scene knowledge."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15623299,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "55045678152bcb5cca7bf10a70c960531a4c4192",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the research activities for the localization of human shapes using visual information carried on at the University of Parma, Italy, in the frame of a common project with the TACOM Department of US Army. The paper proposes the application of a stereoscopic technique as a preprocessing for the localization of humans in generic unstructured environments. Each row of the left image is matched with the epipolar row of the right image. This creates a map of each object in the scene as well as the slope of the road. Preliminary results have proved to be promising."
            },
            "slug": "Stereo-based-preprocessing-for-human-shape-in-Broggi-Fascioli",
            "title": {
                "fragments": [],
                "text": "Stereo-based preprocessing for human shape localization in unstructured environments"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "The application of a stereoscopic technique as a preprocessing for the localization of humans in generic unstructured environments by creating a map of each object in the scene as well as the slope of the road."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE IV2003 Intelligent Vehicles Symposium. Proceedings (Cat. No.03TH8683)"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145140331"
                        ],
                        "name": "Hao Zhang",
                        "slug": "Hao-Zhang",
                        "structuredName": {
                            "firstName": "Hao",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hao Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39668247"
                        ],
                        "name": "A. Berg",
                        "slug": "A.-Berg",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Berg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145854440"
                        ],
                        "name": "M. Maire",
                        "slug": "M.-Maire",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Maire",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Maire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 69
                            }
                        ],
                        "text": "We consider a diverse set of state-of-the-art systems: wavelet-based AdaBoost cascade [74], HOG/linSVM [11], NN/LRF [75], and combined shape-texture detection [23]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 65
                            }
                        ],
                        "text": "Later, automatic feature selection procedures, i.e., variants of AdaBoost [18], were employed to select the most discriminative feature subset [74]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 19
                            }
                        ],
                        "text": "Haar wavelet-based AdaBoost cascade [74]; . histogram of oriented gradient (HOG) features combined with a linear SVM [11];\n."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "AdaBoost [18], which has been applied as automatic feature selection procedure (see above), has also been used to construct strong classifiers as weighted linear combinations of the selected weak classifiers, each involving a threshold on a single feature [60], [62]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 23
                            }
                        ],
                        "text": "In each cascade layer, AdaBoost [18] is used to construct a classifier based on a weighted linear combination of selected features, which yield the lowest error on the training set consisting of pedestrian and nonpedestrian samples."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 19
                            }
                        ],
                        "text": "Again, variants of AdaBoost are frequently used to select the most discriminative subset of features."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 151
                            }
                        ],
                        "text": "Results indicate a clear advantage of HOG/linSVM at higher image resolutions and lower processing speeds, and a superiority of the wavelet-based AdaBoost cascade approach at lower image resolutions and (near) real-time processing speeds."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 41
                            }
                        ],
                        "text": "The total number of features selected by AdaBoost for the whole 15-layer cascade using small (medium) resolution samples is 4,070 (3,751), ranging from 15 (14) features in the first layer to 727 (674) features in the final layer."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "AdaBoost is used in each layer to iteratively construct a strong classifier guided by user-specified performance criteria."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 199
                            }
                        ],
                        "text": "Usually, all experts are run in parallel, where the final decision is obtained as a combination of local expert responses using techniques such as maximum selection [51], [76], majority voting [64], AdaBoost [62], trajectorybased data association [80], and probabilistic shape-based weighting [23]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 91
                            }
                        ],
                        "text": "So-called shapelet features are assembled from low-level oriented gradient responses using AdaBoost, to yield more discriminative local features."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 220,
                                "start": 214
                            }
                        ],
                        "text": "In terms of overall systems, results indicate a clear advantage of the HOG-based linear SVM approach at intermediate pedestrian image resolutions and lower processing speeds, and a superiority of the wavelet-based AdaBoost cascade approach at lower pedestrian image resolutions and (near) real-time processing speeds."
                    },
                    "intents": []
                }
            ],
            "corpusId": 274094,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ceb0e1a86dc35e21ce5f0524c8476f15e1b08988",
            "isKey": true,
            "numCitedBy": 1278,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider visual category recognition in the framework of measuring similarities, or equivalently perceptual distances, to prototype examples of categories. This approach is quite flexible, and permits recognition based on color, texture, and particularly shape, in a homogeneous framework. While nearest neighbor classifiers are natural in this setting, they suffer from the problem of high variance (in bias-variance decomposition) in the case of limited sampling. Alternatively, one could use support vector machines but they involve time-consuming optimization and computation of pairwise distances. We propose a hybrid of these two methods which deals naturally with the multiclass setting, has reasonable computational complexity both in training and at run time, and yields excellent results in practice. The basic idea is to find close neighbors to a query sample and train a local support vector machine that preserves the distance function on the collection of neighbors. Our method can be applied to large, multiclass data sets for which it outperforms nearest neighbor and support vector machines, and remains efficient when the problem becomes intractable for support vector machines. A wide variety of distance functions can be used and our experiments show state-of-the-art performance on a number of benchmark data sets for shape and texture classification (MNIST, USPS, CUReT) and object recognition (Caltech- 101). On Caltech-101 we achieved a correct classification rate of 59.05%(\u00b10.56%) at 15 training images per class, and 66.23%(\u00b10.48%) at 30 training images."
            },
            "slug": "SVM-KNN:-Discriminative-Nearest-Neighbor-for-Visual-Zhang-Berg",
            "title": {
                "fragments": [],
                "text": "SVM-KNN: Discriminative Nearest Neighbor Classification for Visual Category Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "This work considers visual category recognition in the framework of measuring similarities, or equivalently perceptual distances, to prototype examples of categories and proposes a hybrid of these two methods which deals naturally with the multiclass setting, has reasonable computational complexity both in training and at run time, and yields excellent results in practice."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754666"
                        ],
                        "name": "R. Poppe",
                        "slug": "R.-Poppe",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Poppe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Poppe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 21
                            }
                        ],
                        "text": "In this paper, we are concerned with those applications where the human body to be detected covers a smaller portion of the image, i.e., is visible at lower resolution."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9073796,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ea481ceaf3ad8bef871a9efdddb27c345e0c3b4e",
            "isKey": false,
            "numCitedBy": 901,
            "numCiting": 161,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Vision-based-human-motion-analysis:-An-overview-Poppe",
            "title": {
                "fragments": [],
                "text": "Vision-based human motion analysis: An overview"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144746940"
                        ],
                        "name": "B. Stenger",
                        "slug": "B.-Stenger",
                        "structuredName": {
                            "firstName": "Bj\u00f6rn",
                            "lastName": "Stenger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Stenger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707867"
                        ],
                        "name": "A. Thayananthan",
                        "slug": "A.-Thayananthan",
                        "structuredName": {
                            "firstName": "Arasanathan",
                            "lastName": "Thayananthan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Thayananthan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143635539"
                        ],
                        "name": "P. Torr",
                        "slug": "P.-Torr",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Torr",
                            "middleNames": [
                                "H.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Torr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745672"
                        ],
                        "name": "R. Cipolla",
                        "slug": "R.-Cipolla",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Cipolla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cipolla"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5794231,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0132e68e6adf3d087d45f3b1c4803d4140c55e0a",
            "isKey": false,
            "numCitedBy": 500,
            "numCiting": 199,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper sets out a tracking framework, which is applied to the recovery of three-dimensional hand motion from an image sequence. The method handles the issues of initialization, tracking, and recovery in a unified way. In a single input image with no prior information of the hand pose, the algorithm is equivalent to a hierarchical detection scheme, where unlikely pose candidates are rapidly discarded. In image sequences, a dynamic model is used to guide the search and approximate the optimal filtering equations. A dynamic model is given by transition probabilities between regions in parameter space and is learned from training data obtained by capturing articulated motion. The algorithm is evaluated on a number of image sequences, which include hand motion with self-occlusion in front of a cluttered background"
            },
            "slug": "Model-based-hand-tracking-using-a-hierarchical-Stenger-Thayananthan",
            "title": {
                "fragments": [],
                "text": "Model-based hand tracking using a hierarchical Bayesian filter"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "This paper sets out a tracking framework, which is applied to the recovery of three-dimensional hand motion from an image sequence, and handles the issues of initialization, tracking, and recovery in a unified way."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144854796"
                        ],
                        "name": "D. Gavrila",
                        "slug": "D.-Gavrila",
                        "structuredName": {
                            "firstName": "Dariu",
                            "lastName": "Gavrila",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gavrila"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 134
                            }
                        ],
                        "text": "In both the generative and discriminative approaches to pedestrian classification, a given image (or a subregion thereof) is to be assigned to either the pedestrian or nonpedestrian class, depending on the corresponding class posterior probabilities."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 9
                            }
                        ],
                        "text": "In this paper, we are concerned with those applications where the human body to be detected covers a smaller portion of the image, i.e., is visible at lower resolution."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7788290,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b4e4b41b6010ac1e6c90791168f57bcd75b696ab",
            "isKey": false,
            "numCitedBy": 2210,
            "numCiting": 145,
            "paperAbstract": {
                "fragments": [],
                "text": "The ability to recognize humans and their activities by vision is key for a machine to interact intelligently and effortlessly with a human-inhabited environment. Because of many potentially important applications, \u201clooking at people\u201d is currently one of the most active application domains in computer vision. This survey identifies a number of promising applications and provides an overview of recent developments in this domain. The scope of this survey is limited to work on whole-body or hand motion; it does not include work on human faces. The emphasis is on discussing the various methodologies; they are grouped in 2-D approaches with or without explicit shape models and 3-D approaches. Where appropriate, systems are reviewed. We conclude with some thoughts about future directions."
            },
            "slug": "The-Visual-Analysis-of-Human-Movement:-A-Survey-Gavrila",
            "title": {
                "fragments": [],
                "text": "The Visual Analysis of Human Movement: A Survey"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A number of promising applications are identified and an overview of recent developments in this domain is provided, including work on whole-body or hand motion and the various methodologies."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2090818"
                        ],
                        "name": "M. Isard",
                        "slug": "M.-Isard",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Isard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Isard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698422"
                        ],
                        "name": "J. MacCormick",
                        "slug": "J.-MacCormick",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "MacCormick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. MacCormick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5369395,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b46da16dca784e66f600cfa05aa3d9d8bc1dee6d",
            "isKey": false,
            "numCitedBy": 729,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Blob trackers have become increasingly powerful in recent years largely due to the adoption of statistical appearance models which allow effective background subtraction and robust tracking of deforming foreground objects. It has been standard, however, to treat background and foreground modelling as separate processes-background subtraction is followed by blob detection and tracking-which prevents a principled computation of image likelihoods. This paper presents two theoretical advances which address this limitation and lead to a robust multiple-person tracking system suitable for single-camera real-time surveillance applications. The first innovation is a multi-blob likelihood function which assigns directly comparable likelihoods to hypotheses containing different numbers of objects. This likelihood function has a rigorous mathematical basis: it is adapted from the theory of Bayesian correlation, but uses the assumption of a static camera to create a more specific background model while retaining a unified approach to background and foreground modelling. Second we introduce a Bayesian filter for tracking multiple objects when the number of objects present is unknown and varies over time. We show how a particle filter can be used to perform joint inference on both the number of objects present and their configurations. Finally we demonstrate that our system runs comfortably in real time on a modest workstation when the number of blobs in the scene is small."
            },
            "slug": "BraMBLe:-a-Bayesian-multiple-blob-tracker-Isard-MacCormick",
            "title": {
                "fragments": [],
                "text": "BraMBLe: a Bayesian multiple-blob tracker"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A multi-blob likelihood function which assigns directly comparable likelihoods to hypotheses containing different numbers of objects and a Bayesian filter for tracking multiple objects when the number of objects present is unknown and varies over time are introduced."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770537"
                        ],
                        "name": "D. Ramanan",
                        "slug": "D.-Ramanan",
                        "structuredName": {
                            "firstName": "Deva",
                            "lastName": "Ramanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ramanan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5574410,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "14eacd0e48a160bfc935cd4d419772f0110b1a0f",
            "isKey": false,
            "numCitedBy": 364,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop an algorithm for finding and kinematically tracking multiple people in long sequences. Our basic assumption is that people tend to take on certain canonical poses, even when performing unusual activities like throwing a baseball or figure skating. We build a person detector that quite accurately detects and localizes limbs of people in lateral walking poses. We use the estimated limbs from a detection to build a discriminative appearance model; we assume the features that discriminate a figure in one frame will discriminate the figure in other frames. We then use the models as limb detectors in a pictorial structure framework, detecting figures in unrestricted poses in both previous and successive frames. We have run our tracker on hundreds of thousands of frames, and present and apply a methodology for evaluating tracking on such a large scale. We test our tracker on real sequences including a feature-length film, an hour of footage from a public park, and various sports sequences. We find that we can quite accurately automatically find and track multiple people interacting with each other while performing fast and unusual motions."
            },
            "slug": "Strike-a-pose:-tracking-people-by-finding-stylized-Ramanan-Forsyth",
            "title": {
                "fragments": [],
                "text": "Strike a pose: tracking people by finding stylized poses"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A person detector that quite accurately detects and localizes limbs of people in lateral walking poses is built, and an algorithm for finding and kinematically tracking multiple people in long sequences is developed."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762260"
                        ],
                        "name": "V. Philomin",
                        "slug": "V.-Philomin",
                        "structuredName": {
                            "firstName": "Vasanth",
                            "lastName": "Philomin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Philomin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719541"
                        ],
                        "name": "R. Duraiswami",
                        "slug": "R.-Duraiswami",
                        "structuredName": {
                            "firstName": "Ramani",
                            "lastName": "Duraiswami",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Duraiswami"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693428"
                        ],
                        "name": "L. Davis",
                        "slug": "L.-Davis",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Davis",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Davis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11308709,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d251db29c89c95e31efa0eed6390bf18bfb65d22",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of tracking pedestrians from a moving car is a challenging one. The Condensation tracking algorithm is appealing for its generality and potential for real-time implementation. However, the conventional Condensation tracker is known to have difficulty with high-dimensional state spaces and unknown motion models. This paper presents an improved algorithm that addresses these problems by using a simplified motion model, and employing quasi-Monte Carlo techniques to efficiently sample the resulting tracking problem in the high-dimensional state space. For N sample points, these techniques achieve sampling errors of O(N-1), as opposed to O(N-1/2) for conventional Monte Carlo techniques. We illustrate the algorithm by tracking objects in both synthetic and real sequences, and show that it achieves reliable tracking and significant speed-ups over conventional Monte Carlo techniques."
            },
            "slug": "Quasi-Random-Sampling-for-Condensation-Philomin-Duraiswami",
            "title": {
                "fragments": [],
                "text": "Quasi-Random Sampling for Condensation"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "An improved algorithm is presented that achieves reliable tracking and significant speed-ups over conventional Monte Carlo techniques by using a simplified motion model, and employing quasi-Monte Carlo techniques to efficiently sample the resulting tracking problem in the high-dimensional state space."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2588636"
                        ],
                        "name": "L. Taycher",
                        "slug": "L.-Taycher",
                        "structuredName": {
                            "firstName": "Leonid",
                            "lastName": "Taycher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Taycher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2444581"
                        ],
                        "name": "D. Demirdjian",
                        "slug": "D.-Demirdjian",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Demirdjian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Demirdjian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2490189"
                        ],
                        "name": "Gregory Shakhnarovich",
                        "slug": "Gregory-Shakhnarovich",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Shakhnarovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gregory Shakhnarovich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8844105,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "id": "d3ad039b1876745562c5a146e5216beb69babbe7",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a state-space tracking approach based on a Conditional Random Field (CRF) model, where the observation potentials are learned from data. We find functions that embed both state and observation into a space where similarity corresponds to L1 distance, and define an observation potential based on distance in this space. This potential is extremely fast to compute and in conjunction with a grid-filtering framework can be used to reduce a continuous state estimation problem to a discrete one. We show how a state temporal prior in the grid-filter can be computed in a manner similar to a sparse HMM, resulting in real-time system performance. The resulting system is used for human pose tracking in video sequences."
            },
            "slug": "Conditional-Random-People:-Tracking-Humans-with-and-Taycher-Demirdjian",
            "title": {
                "fragments": [],
                "text": "Conditional Random People: Tracking Humans with CRFs and Grid Filters"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown how a state temporal prior in the grid-filter can be computed in a manner similar to a sparse HMM, resulting in real-time system performance and is used for human pose tracking in video sequences."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1961864"
                        ],
                        "name": "V. Shet",
                        "slug": "V.-Shet",
                        "structuredName": {
                            "firstName": "Vinay",
                            "lastName": "Shet",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Shet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144660077"
                        ],
                        "name": "J. Neumann",
                        "slug": "J.-Neumann",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Neumann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Neumann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145320582"
                        ],
                        "name": "Visvanathan Ramesh",
                        "slug": "Visvanathan-Ramesh",
                        "structuredName": {
                            "firstName": "Visvanathan",
                            "lastName": "Ramesh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Visvanathan Ramesh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693428"
                        ],
                        "name": "L. Davis",
                        "slug": "L.-Davis",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Davis",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Davis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 146
                            }
                        ],
                        "text": "They cover both passive and active safety techniques, the latter using (possibly) multiple vision and nonvision sensors, together with methods for collision risk assessment."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1136448,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4a1e78a03822a3ab18fb54d8e751ddacd7f6f691",
            "isKey": false,
            "numCitedBy": 124,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "The capacity to robustly detect humans in video is a critical component of automated visual surveillance systems. This paper describes a bilattice based logical reasoning approach that exploits contextual information and knowledge about interactions between humans, and augments it with the output of different low level detectors for human detection. Detections from low level parts-based detectors are treated as logical facts and used to reason explicitly about the presence or absence of humans in the scene. Positive and negative information from different sources, as well as uncertainties from detections and logical rules, are integrated within the bilattice framework. This approach also generates proofs or justifications for each hypothesis it proposes. These justifications (or lack thereof) are further employed by the system to explain and validate, or reject potential hypotheses. This allows the system to explicitly reason about complex interactions between humans and handle occlusions. These proofs are also available to the end user as an explanation of why the system thinks a particular hypothesis is actually a human. We employ a boosted cascade of gradient histograms based detector to detect individual body parts. We have applied this framework to analyze the presence of humans in static images from different datasets."
            },
            "slug": "Bilattice-based-Logical-Reasoning-for-Human-Shet-Neumann",
            "title": {
                "fragments": [],
                "text": "Bilattice-based Logical Reasoning for Human Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "A bilattice based logical reasoning approach that exploits contextual information and knowledge about interactions between humans, and augments it with the output of different low level detectors for human detection, and has applied this framework to analyze the presence of humans in static images from different datasets."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145150531"
                        ],
                        "name": "ilkay Ulusoy",
                        "slug": "ilkay-Ulusoy",
                        "structuredName": {
                            "firstName": "ilkay",
                            "lastName": "Ulusoy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "ilkay Ulusoy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792884"
                        ],
                        "name": "Charles M. Bishop",
                        "slug": "Charles-M.-Bishop",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Bishop",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charles M. Bishop"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 84
                            }
                        ],
                        "text": "The computational costs are often too high to allow for real-time processing [11], [12], [48], [53], [60], [68]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14271284,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "59be0bc6397f99386dd6a87b5966735e88948b54",
            "isKey": false,
            "numCitedBy": 192,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Many approaches to object recognition are founded on probability theory, and can be broadly characterized as either generative or discriminative according to whether or not the distribution of the image features is modelled. Generative and discriminative methods have very different characteristics, as well as complementary strengths and weaknesses. In this paper we introduce new generative and discriminative models for object detection and classification based on weakly labelled training data. We use these models to illustrate the relative merits of the two approaches in the context of a data set of widely varying images of non-rigid objects (animals). Our results support the assertion that neither approach alone will be sufficient for large scale object recognition, and we discuss techniques for combining them."
            },
            "slug": "Generative-versus-discriminative-methods-for-object-Ulusoy-Bishop",
            "title": {
                "fragments": [],
                "text": "Generative versus discriminative methods for object recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The results support the assertion that neither generative or discriminative approach alone will be sufficient for large scale object recognition, and the techniques for combining them are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46887580"
                        ],
                        "name": "Tao Zhao",
                        "slug": "Tao-Zhao",
                        "structuredName": {
                            "firstName": "Tao",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tao Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144862593"
                        ],
                        "name": "R. Nevatia",
                        "slug": "R.-Nevatia",
                        "structuredName": {
                            "firstName": "Ramakant",
                            "lastName": "Nevatia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nevatia"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 169
                            }
                        ],
                        "text": "While the latter two require models of the pedestrian class, e.g., in terms of geometry, appearance, or dynamics, the initial generation of regions of interest is usually based on more general low-level features or prior scene knowledge."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1522788,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b60ea458dc5d571c7bc028d9fd98fb545c0070d1",
            "isKey": false,
            "numCitedBy": 564,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "Tracking multiple humans in complex situations is challenging. The difficulties are tackled with appropriate knowledge in the form of various models in our approach. Human motion is decomposed into its global motion and limb motion. In the first part, we show how multiple human objects are segmented and their global motions are tracked in 3D using ellipsoid human shape models. Experiments show that it successfully applies to the cases where a small number of people move together, have occlusion, and cast shadow or reflection. In the second part, we estimate the modes (e.g., walking, running, standing) of the locomotion and 3D body postures by making inference in a prior locomotion model. Camera model and ground plane assumptions provide geometric constraints in both parts. Robust results are shown on some difficult sequences."
            },
            "slug": "Tracking-multiple-humans-in-complex-situations-Zhao-Nevatia",
            "title": {
                "fragments": [],
                "text": "Tracking multiple humans in complex situations"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work shows how multiple human objects are segmented and their global motions are tracked in 3D using ellipsoid human shape models and estimates the modes (e.g., walking, running, standing) of the locomotion and 3D body postures by making inference in a prior locomotion model."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2652428"
                        ],
                        "name": "R. Polana",
                        "slug": "R.-Polana",
                        "structuredName": {
                            "firstName": "Ramprasad",
                            "lastName": "Polana",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Polana"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113399896"
                        ],
                        "name": "R. Nelson",
                        "slug": "R.-Nelson",
                        "structuredName": {
                            "firstName": "Randall",
                            "lastName": "Nelson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nelson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "While the latter two require models of the pedestrian class, e.g., in terms of geometry, appearance, or dynamics, the initial generation of regions of interest is usually based on more general low-level features or prior scene knowledge."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6353138,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "1ee01bf96b5dbd441eabda533fa89da3fa4d916a",
            "isKey": false,
            "numCitedBy": 371,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The recognition of human movements such as walking, running or climbing has been approached previously by tracking a number of feature points and either classifying the trajectories directly or matching them with a high-level model of the movement. A major difficulty with these methods is acquiring and trading the requisite feature points, which are generally specific joints such as knees or angles. This requires previous recognition and/or part segmentation of the actor. We show that the recognition of walking or any repetitive motion activity can be accomplished on the basis of bottom up processing, which does not require the prior identification of specific parts, or classification of the actor. In particular, we demonstrate that repetitive motion is such a strong cue, that the moving actor can be segmented, normalized spatially and temporally, and recognized by matching against a spatiotemporal template of motion features. We have implemented a real-time system that can recognize and classify repetitive motion activities in normal gray-scale image sequences.<<ETX>>"
            },
            "slug": "Low-level-recognition-of-human-motion-(or-how-to-Polana-Nelson",
            "title": {
                "fragments": [],
                "text": "Low level recognition of human motion (or how to get your man without finding his body parts)"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is demonstrated that repetitive motion is such a strong cue, that the moving actor can be segmented, normalized spatially and temporally, and recognized by matching against a spatiotemporal template of motion features."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1994 IEEE Workshop on Motion of Non-rigid and Articulated Objects"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731320"
                        ],
                        "name": "S. Maskell",
                        "slug": "S.-Maskell",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Maskell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Maskell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144998829"
                        ],
                        "name": "N. Gordon",
                        "slug": "N.-Gordon",
                        "structuredName": {
                            "firstName": "Neil",
                            "lastName": "Gordon",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Gordon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 55577025,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7f0bbe9dd4aa3bfb8a355a2444f81848b020b7a4",
            "isKey": false,
            "numCitedBy": 1097,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Increasingly, for many application areas, it is becoming important to include elements of nonlinearity and non-Gaussianity in order to model accurately the underlying dynamics of a physical system. Moreover, it is typically crucial to process data on-line as it arrives, both from the point of view of storage costs as well as for rapid adaptation to changing signal characteristics. In this paper, we review both optimal and suboptimal Bayesian algorithms for nonlinear/non-Gaussian tracking problems, with a focus on particle filters. Particle filters are sequential Monte Carlo methods based on point mass (or \u201cparticle\u201d) representations of probability densities, which can be applied to any state-space model and which generalize the traditional Kalman filtering methods. Several variants of the particle filter such as SIR, ASIR, and RPF are introduced within a generic framework of the sequential importance sampling (SIS) algorithm. These are discussed and compared with the standard EKF through an illustrative example."
            },
            "slug": "A-tutorial-on-particle-filters-for-on-line-Bayesian-Maskell-Gordon",
            "title": {
                "fragments": [],
                "text": "A tutorial on particle filters for on-line nonlinear/non-Gaussian Bayesian tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Both optimal and suboptimal Bayesian algorithms for nonlinear/non-Gaussian tracking problems, with a focus on particle filters are reviewed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747298"
                        ],
                        "name": "R. Duin",
                        "slug": "R.-Duin",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Duin",
                            "middleNames": [
                                "P.",
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Duin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4723637"
                        ],
                        "name": "J. Mao",
                        "slug": "J.-Mao",
                        "structuredName": {
                            "firstName": "Jianchang",
                            "lastName": "Mao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "multilayer neural networks [33] implement linear discriminant functions in the feature space in which input patterns have been mapped nonlinearly, e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": ", mean squared error [33]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 192934,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3626f388371b678b2f02f6eefc44fa5abc53ceb3",
            "isKey": false,
            "numCitedBy": 6533,
            "numCiting": 473,
            "paperAbstract": {
                "fragments": [],
                "text": "The primary goal of pattern recognition is supervised or unsupervised classification. Among the various frameworks in which pattern recognition has been traditionally formulated, the statistical approach has been most intensively studied and used in practice. More recently, neural network techniques and methods imported from statistical learning theory have been receiving increasing attention. The design of a recognition system requires careful attention to the following issues: definition of pattern classes, sensing environment, pattern representation, feature extraction and selection, cluster analysis, classifier design and learning, selection of training and test samples, and performance evaluation. In spite of almost 50 years of research and development in this field, the general problem of recognizing complex patterns with arbitrary orientation, location, and scale remains unsolved. New and emerging applications, such as data mining, web searching, retrieval of multimedia data, face recognition, and cursive handwriting recognition, require robust and efficient pattern recognition techniques. The objective of this review paper is to summarize and compare some of the well-known methods used in various stages of a pattern recognition system and identify research topics and applications which are at the forefront of this exciting and challenging field."
            },
            "slug": "Statistical-Pattern-Recognition:-A-Review-Jain-Duin",
            "title": {
                "fragments": [],
                "text": "Statistical Pattern Recognition: A Review"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The objective of this review paper is to summarize and compare some of the well-known methods used in various stages of a pattern recognition system and identify research topics and applications which are at the forefront of this exciting and challenging field."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733319"
                        ],
                        "name": "G. Borgefors",
                        "slug": "G.-Borgefors",
                        "structuredName": {
                            "firstName": "Gunilla",
                            "lastName": "Borgefors",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Borgefors"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[6] between a shape template and an image subwindow as smooth and robust similarity measure."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 36889447,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c566d306cdd00512af5040ad1c4aed61707732a7",
            "isKey": false,
            "numCitedBy": 2010,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Distance-transformations-in-digital-images-Borgefors",
            "title": {
                "fragments": [],
                "text": "Distance transformations in digital images"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Graph. Image Process."
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2577513"
                        ],
                        "name": "Oncel Tuzel",
                        "slug": "Oncel-Tuzel",
                        "structuredName": {
                            "firstName": "Oncel",
                            "lastName": "Tuzel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oncel Tuzel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29905643"
                        ],
                        "name": "F. Porikli",
                        "slug": "F.-Porikli",
                        "structuredName": {
                            "firstName": "Fatih",
                            "lastName": "Porikli",
                            "middleNames": [
                                "Murat"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Porikli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145776090"
                        ],
                        "name": "P. Meer",
                        "slug": "P.-Meer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Meer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Meer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 152
                            }
                        ],
                        "text": "They cover both passive and active safety techniques, the latter using (possibly) multiple vision and nonvision sensors, together with methods for collision risk assessment."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2161048,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "b5702b5726b3dc58d97100061b4f54020631d9e6",
            "isKey": false,
            "numCitedBy": 535,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new algorithm to detect humans in still images utilizing covariance matrices as object descriptors. Since these descriptors do not lie on a vector space, well known machine learning techniques are not adequate to learn the classifiers. The space of d-dimensional nonsingular covariance matrices can be represented as a connected Riemannian manifold. We present a novel approach for classifying points lying on a Riemannian manifold by incorporating the a priori information about the geometry of the space. The algorithm is tested on INRIA human database where superior detection rates are observed over the previous approaches."
            },
            "slug": "Human-Detection-via-Classification-on-Riemannian-Tuzel-Porikli",
            "title": {
                "fragments": [],
                "text": "Human Detection via Classification on Riemannian Manifolds"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A novel approach for classifying points lying on a Riemannian manifold by incorporating the a priori information about the geometry of the space."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3298395"
                        ],
                        "name": "M. Arulampalam",
                        "slug": "M.-Arulampalam",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Arulampalam",
                            "middleNames": [
                                "Sanjeev"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Arulampalam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731320"
                        ],
                        "name": "S. Maskell",
                        "slug": "S.-Maskell",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Maskell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Maskell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144998829"
                        ],
                        "name": "N. Gordon",
                        "slug": "N.-Gordon",
                        "structuredName": {
                            "firstName": "Neil",
                            "lastName": "Gordon",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Gordon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102907269"
                        ],
                        "name": "T. Clapp",
                        "slug": "T.-Clapp",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Clapp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Clapp"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 122803681,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "763493cf694f3a7365c02676c139ee01cbac30b9",
            "isKey": false,
            "numCitedBy": 11118,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Increasingly, for many application areas, it is becoming important to include elements of nonlinearity and non-Gaussianity in order to model accurately the underlying dynamics of a physical system. Moreover, it is typically crucial to process data on-line as it arrives, both from the point of view of storage costs as well as for rapid adaptation to changing signal characteristics. In this paper, we review both optimal and suboptimal Bayesian algorithms for nonlinear/non-Gaussian tracking problems, with a focus on particle filters. Particle filters are sequential Monte Carlo methods based on point mass (or \"particle\") representations of probability densities, which can be applied to any state-space model and which generalize the traditional Kalman filtering methods. Several variants of the particle filter such as SIR, ASIR, and RPF are introduced within a generic framework of the sequential importance sampling (SIS) algorithm. These are discussed and compared with the standard EKF through an illustrative example."
            },
            "slug": "A-tutorial-on-particle-filters-for-online-Bayesian-Arulampalam-Maskell",
            "title": {
                "fragments": [],
                "text": "A tutorial on particle filters for online nonlinear/non-Gaussian Bayesian tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Both optimal and suboptimal Bayesian algorithms for nonlinear/non-Gaussian tracking problems, with a focus on particle filters are reviewed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Signal Process."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694562"
                        ],
                        "name": "Chikahito Nakajima",
                        "slug": "Chikahito-Nakajima",
                        "structuredName": {
                            "firstName": "Chikahito",
                            "lastName": "Nakajima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chikahito Nakajima"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704699"
                        ],
                        "name": "M. Pontil",
                        "slug": "M.-Pontil",
                        "structuredName": {
                            "firstName": "Massimiliano",
                            "lastName": "Pontil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pontil"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684626"
                        ],
                        "name": "B. Heisele",
                        "slug": "B.-Heisele",
                        "structuredName": {
                            "firstName": "Bernd",
                            "lastName": "Heisele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Heisele"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18251590,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7a3f03376d11e857f6b5ed7ae02e0981f68b371c",
            "isKey": false,
            "numCitedBy": 159,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Full-body-person-recognition-system-Nakajima-Pontil",
            "title": {
                "fragments": [],
                "text": "Full-body person recognition system"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2090818"
                        ],
                        "name": "M. Isard",
                        "slug": "M.-Isard",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Isard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Isard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145162067"
                        ],
                        "name": "A. Blake",
                        "slug": "A.-Blake",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Blake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blake"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18939846,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "91a389b99a77895e4b33e4a81af2f0a5fe8fc011",
            "isKey": false,
            "numCitedBy": 676,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Tracking research has diverged into two camps; low-level approaches which are typically fast and robust but provide little fine-scale information, and high-level approaches which track complex deformations in high-dimensional spaces but must trade off speed against robustness. Real-time high-level systems perform poorly in clutter and initialisation for most high-level systems is either performed manually or by a separate module. This paper presents a new technique to combine low- and high-level information in a consistent probabilistic framework, using the statistical technique of importance sampling combined with the Condensation algorithm. The general framework, which we term Icondensation, is described, and a hand tracker is demonstrated which combines colour blob-tracking with a contour model. The resulting tracker is robust to rapid motion, heavy clutter and hand-coloured distractors, and re-initialises automatically. The system runs comfortably in real time on an entry-level desktop workstation."
            },
            "slug": "ICONDENSATION:-Unifying-Low-Level-and-High-Level-in-Isard-Blake",
            "title": {
                "fragments": [],
                "text": "ICONDENSATION: Unifying Low-Level and High-Level Tracking in a Stochastic Framework"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new technique to combine low- and high-level information in a consistent probabilistic framework is presented, using the statistical technique of importance sampling combined with the Condensation algorithm, and a hand tracker is demonstrated which combines colour blob-tracking with a contour model."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32212403"
                        ],
                        "name": "M. Spengler",
                        "slug": "M.-Spengler",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Spengler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Spengler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48920094"
                        ],
                        "name": "B. Schiele",
                        "slug": "B.-Schiele",
                        "structuredName": {
                            "firstName": "Bernt",
                            "lastName": "Schiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schiele"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "While the latter two require models of the pedestrian class, e.g., in terms of geometry, appearance, or dynamics, the initial generation of regions of interest is usually based on more general low-level features or prior scene knowledge."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7555853,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "483d0bcc530b7e767f6f5dd3ad9fb70c348c1f73",
            "isKey": false,
            "numCitedBy": 138,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract. Even though many of today's vision algorithms are very successful, they lack robustness, since they are typically tailored to a particular situation. In this paper, we argue that the principles of sensor and model integration can increase the robustness of today's computer-vision systems substantially. As an example, multi-cue tracking of faces is discussed. The approach is based on the principles of self-organization of the integration mechanism and self-adaptation of the cue models during tracking. Experiments show that the robustness of simple models is leveraged significantly by sensor and model integration."
            },
            "slug": "Towards-robust-multi-cue-integration-for-visual-Spengler-Schiele",
            "title": {
                "fragments": [],
                "text": "Towards robust multi-cue integration for visual tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is argued that the principles of sensor and model integration can increase the robustness of today's computer-vision systems substantially and, as an example, multi-cue tracking of faces is discussed."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Vision and Applications"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108261094"
                        ],
                        "name": "Seungkyu Lee",
                        "slug": "Seungkyu-Lee",
                        "structuredName": {
                            "firstName": "Seungkyu",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Seungkyu Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689241"
                        ],
                        "name": "Yanxi Liu",
                        "slug": "Yanxi-Liu",
                        "structuredName": {
                            "firstName": "Yanxi",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yanxi Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143980462"
                        ],
                        "name": "R. Collins",
                        "slug": "R.-Collins",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Collins",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Collins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12684746,
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "id": "4263630a35c5ee34ccf9dbd81c0541d92d0c7d5b",
            "isKey": false,
            "numCitedBy": 104,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Gait is an attractive biometric for vision-based human identification. Previous work on existing public data sets has shown that shape cues yield improved recognition rates compared to pure motion cues. However, shape cues are fragile to gross appearance variations of an individual, for example, walking while carrying a ball or a backpack. We introduce a novel, spatiotemporal shape variation-based frieze pattern (SVB frieze pattern) representation for gait, which captures motion information over time. The SVB frieze pattern represents normalized frame difference over gait cycles. Rows/columns of the vertical/horizontal SVB frieze pattern contain motion variation information augmented by key frame information with body shape. A temporal symmetry map of gait patterns is also constructed and combined with vertical/horizontal SVB frieze patterns for measuring the dissimilarity between gait sequences. Experimental results show that our algorithm improves gait recognition performance on sequences with and without gross differences in silhouette shape. We demonstrate superior performance of this computational framework over previous algorithms using shape cues alone on both CMU MoBo and UoS HumanID gait databases."
            },
            "slug": "Shape-Variation-Based-Frieze-Pattern-for-Robust-Lee-Liu",
            "title": {
                "fragments": [],
                "text": "Shape Variation-Based Frieze Pattern for Robust Gait Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel, spatiotemporal shape variation-based frieze pattern (SVB friezes pattern) representation for gait, which captures motion information over time, and demonstrates superior performance of this computational framework over previous algorithms using shape cues alone on both CMU MoBo and UoS HumanID gait databases."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1911372"
                        ],
                        "name": "T. Randen",
                        "slug": "T.-Randen",
                        "structuredName": {
                            "firstName": "Trygve",
                            "lastName": "Randen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Randen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31557075"
                        ],
                        "name": "J. H. Hus\u00f8y",
                        "slug": "J.-H.-Hus\u00f8y",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hus\u00f8y",
                            "middleNames": [
                                "H\u00e5kon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. H. Hus\u00f8y"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17026785,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "8c3ae83da4542257971c4033087bcd7eb33465a6",
            "isKey": false,
            "numCitedBy": 1620,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we review most major filtering approaches to texture feature extraction and perform a comparative study. Filtering approaches included are Laws masks (1980), ring/wedge filters, dyadic Gabor filter banks, wavelet transforms, wavelet packets and wavelet frames, quadrature mirror filters, discrete cosine transform, eigenfilters, optimized Gabor filters, linear predictors, and optimized finite impulse response filters. The features are computed as the local energy of the filter responses. The effect of the filtering is highlighted, keeping the local energy function and the classification algorithm identical for most approaches. For reference, comparisons with two classical nonfiltering approaches, co-occurrence (statistical) and autoregressive (model based) features, are given. We present a ranking of the tested approaches based on extensive experiments."
            },
            "slug": "Filtering-for-Texture-Classification:-A-Comparative-Randen-Hus\u00f8y",
            "title": {
                "fragments": [],
                "text": "Filtering for Texture Classification: A Comparative Study"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "Most major filtering approaches to texture feature extraction are reviewed and a ranking of the tested approaches based on extensive experiments is presented, showing the effect of the filtering is highlighted, keeping the local energy function and the classification algorithm identical for most approaches."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2034793"
                        ],
                        "name": "Lixin Fan",
                        "slug": "Lixin-Fan",
                        "structuredName": {
                            "firstName": "Lixin",
                            "lastName": "Fan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lixin Fan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38817267"
                        ],
                        "name": "K. Sung",
                        "slug": "K.-Sung",
                        "structuredName": {
                            "firstName": "Kah",
                            "lastName": "Sung",
                            "middleNames": [
                                "Kay"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Sung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3082766"
                        ],
                        "name": "Teck Khim Ng",
                        "slug": "Teck-Khim-Ng",
                        "structuredName": {
                            "firstName": "Teck",
                            "lastName": "Ng",
                            "middleNames": [
                                "Khim"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Teck Khim Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The main difference between generative and discriminative models is how posterior probabilities are estimated for each class."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16079318,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "8b74e1749ed60395082b0eb50d7bd1ab5f93f031",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Pedestrian-registration-in-static-images-with-Fan-Sung",
            "title": {
                "fragments": [],
                "text": "Pedestrian registration in static images with unconstrained background"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152672574"
                        ],
                        "name": "J. Deutscher",
                        "slug": "J.-Deutscher",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Deutscher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Deutscher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145162067"
                        ],
                        "name": "A. Blake",
                        "slug": "A.-Blake",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Blake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blake"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145950884"
                        ],
                        "name": "I. Reid",
                        "slug": "I.-Reid",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Reid",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Reid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 686395,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6f6613ef17d3d7627adf3108ac4b3be9e0abfb6e",
            "isKey": false,
            "numCitedBy": 1082,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "The main challenge in articulated body motion tracking is the large number of degrees of freedom (around 30) to be recovered. Search algorithms, either deterministic or stochastic, that search such a space without constraint, fall foul of exponential computational complexity. One approach is to introduce constraints: either labelling using markers or colour coding, prior assumptions about motion trajectories or view restrictions. Another is to relax constraints arising from articulation, and track limbs as if their motions were independent. In contrast, we aim for general tracking without special preparation of objects or restrictive assumptions. The principal contribution of the paper is the development of a modified particle filter for search in high dimensional configuration spaces. It uses a continuation principle based on annealing to introduce the influence of narrow peaks in the fitness function, gradually. The new algorithm, termed annealed particle filtering, is shown to be capable of recovering full articulated body motion efficiently."
            },
            "slug": "Articulated-body-motion-capture-by-annealed-Deutscher-Blake",
            "title": {
                "fragments": [],
                "text": "Articulated body motion capture by annealed particle filtering"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The principal contribution of the paper is the development of a modified particle filter for search in high dimensional configuration spaces that uses a continuation principle based on annealing to introduce the influence of narrow peaks in the fitness function, gradually."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698422"
                        ],
                        "name": "J. MacCormick",
                        "slug": "J.-MacCormick",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "MacCormick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. MacCormick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145162067"
                        ],
                        "name": "A. Blake",
                        "slug": "A.-Blake",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Blake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blake"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7644136,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "491a1a5281efb711045e3c220e9907c275c5a460",
            "isKey": false,
            "numCitedBy": 354,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "Tracking multiple targets is a challenging problem, especially when the targets are \u201cidentical\u201d, in the sense that the same model is used to describe each target. In this case, simply instantiating several independent 1-body trackers is not an adequate solution, because the independent trackers tend to coalesce onto the best-fitting target. This paper presents an observation density for tracking which solves this problem by exhibiting a probabilistic exclusion principle. Exclusion arises naturally from a systematic derivation of the observation density, without relying on heuristics. Another important contribution of the paper is the presentation of partitioned sampling, a new sampling method for multiple object tracking. Partitioned sampling avoids the high computational load associated with fully coupled trackers, while retaining the desirable properties of coupling."
            },
            "slug": "A-Probabilistic-Exclusion-Principle-for-Tracking-MacCormick-Blake",
            "title": {
                "fragments": [],
                "text": "A Probabilistic Exclusion Principle for Tracking Multiple Objects"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "An observation density for tracking is presented which solves this problem by exhibiting a probabilistic exclusion principle, and is presented of partitioned sampling, a new sampling method for multiple object tracking."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2232680"
                        ],
                        "name": "Heegu Kang",
                        "slug": "Heegu-Kang",
                        "structuredName": {
                            "firstName": "Heegu",
                            "lastName": "Kang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Heegu Kang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47181644"
                        ],
                        "name": "Daijin Kim",
                        "slug": "Daijin-Kim",
                        "structuredName": {
                            "firstName": "Daijin",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daijin Kim"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 18293861,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "21eff774370204baa68cf65aa1070c230ada4181",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "The CONDENSATION algorithm is attractive as it has robust tracking performance and potential for real-time implementation. However the CONDENSATION tracker has difficulty with real-time implementation for multiple people tracking since it requires complicated shape model and large number of samples for precise tracking performance. This paper presents two improvements for real-time multiple object tracking: the discrete shape model with a small search space and the competition rule which requires a small number of samples to track multiple people. We show that they achieve robust and real-time tracking for image sequences of a crowd of people."
            },
            "slug": "Real-time-multiple-people-tracking-using-Kang-Kim",
            "title": {
                "fragments": [],
                "text": "Real-time multiple people tracking using competitive condensation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Two improvements for real-time multiple object tracking are presented: the discrete shape model with a small search space and the competition rule which requires a small number of samples to track multiple people."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. International Conference on Image Processing"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40178596"
                        ],
                        "name": "T. Heap",
                        "slug": "T.-Heap",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Heap",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Heap"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1967104"
                        ],
                        "name": "David C. Hogg",
                        "slug": "David-C.-Hogg",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hogg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David C. Hogg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The main difference between generative and discriminative models is how posterior probabilities are estimated for each class."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11163366,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f093c71f27cbb3d5003c1956ffb528c780f6d1fb",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "The Point Distribution Model PDM has proved useful for many tasks involving the location and tracking of deformable objects A principal limitation is non speci city in constructing a model to in clude all valid object shapes the inclusion of some invalid shapes is unavoidable due to the linear nature of the approach Bregler and Omohundro describe a piecewise linear method for applying constraints within model shape space whereby principal component analysis is used on training data clusters in shape space to generate lower dimensional overlapping subspaces Object shapes are constrained to lie within the union of these subspaces thus improving the speci city of the model This is an important development in itself but its most useful qual ity is that it lends itself to automated training Manual annotation of training examples has previously been necessary to ensure good speci city in PDMs requiring expertise and time and thus limiting the amount of training data that can feasibly be collected The use of shape space constraints means that such accurate annotation is unnec essary and automated training becomes signi cantly more successful In this paper we expand on Bregler and Omohundro s work sug gesting an alternative representation for the linear pieces and showing how a two level hierarchy in shape space can be used to improve e ciency and reduce noise We perform an evaluation on both synthetic and automatically trained real models"
            },
            "slug": "Improving-Specificity-in-PDMs-using-a-Hierarchical-Heap-Hogg",
            "title": {
                "fragments": [],
                "text": "Improving Specificity in PDMs using a Hierarchical Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A piecewise linear method for applying constraints within model shape space whereby principal component analysis is used on training data clusters in shape space to generate lower dimensional overlapping subspaces thus improving the speci city of the model."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40178596"
                        ],
                        "name": "T. Heap",
                        "slug": "T.-Heap",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Heap",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Heap"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1967104"
                        ],
                        "name": "David C. Hogg",
                        "slug": "David-C.-Hogg",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hogg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David C. Hogg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The main difference between generative and discriminative models is how posterior probabilities are estimated for each class."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2418402,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1c3948ca1d291955c78cbc29e998d83e4ede0ab4",
            "isKey": false,
            "numCitedBy": 154,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Existing object tracking algorithms generally use some form of local optimisation, assuming that an object's position and shape change smoothly over time. In some situations this assumption is not valid: the track able shape of an object may change discontinuously, for example if it is the 2D silhouette of a 3D object. In this paper we propose a novel method for modelling temporal shape discontinuities explicitly. Allowable shapes are represented as a union of (learned) bounded regions within a shape space. Discontinuous shape changes are described in terms of transitions between these regions. Transition probabilities are learned from training sequences and stored in a Markov model. In this way we can create 'wormholes' in shape space. Tracking with such models is via an adaptation, of the CONDENSATION algorithm."
            },
            "slug": "Wormholes-in-shape-space:-tracking-through-changes-Heap-Hogg",
            "title": {
                "fragments": [],
                "text": "Wormholes in shape space: tracking through discontinuous changes in shape"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper proposes a novel method for modelling temporal shape discontinuities explicitly, represented as a union of (learned) bounded regions within a shape space, which can create 'wormholes' in shape space."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145319478"
                        ],
                        "name": "Michael J. Jones",
                        "slug": "Michael-J.-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The main difference between generative and discriminative models is how posterior probabilities are estimated for each class."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10299793,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f96248048d349fa9a24277f266a8b5033bae7b09",
            "isKey": false,
            "numCitedBy": 149,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a flexible model for representing images of objects of a certain class, known a priori, such as faces, and introduce a new algorithm for matching it to a novel image and thereby performing image analysis. We call this model a multidimensional morphable model or just a, morphable model. The morphable model is learned from example images (called prototypes) of objects of a class. In this paper we introduce an effective stochastic gradient descent algorithm that automaticaIly matches a model to a novel image by finding the parameters that minimize the error between the image generated by the model and the novel image. Two examples demonstrate the robustness and the broad range of applicability of the matching algorithm and the underlying morphable model. Our approach can provide novel solutions to several vision tasks, including the computation of image correspondence, object verification, image synthesis and image compression."
            },
            "slug": "Multidimensional-morphable-models-Jones-Poggio",
            "title": {
                "fragments": [],
                "text": "Multidimensional morphable models"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "An effective stochastic gradient descent algorithm is introduced that automaticaIly matches a model to a novel image by finding the parameters that minimize the error between the image generated by the model and the novel image."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698422"
                        ],
                        "name": "J. MacCormick",
                        "slug": "J.-MacCormick",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "MacCormick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. MacCormick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2090818"
                        ],
                        "name": "M. Isard",
                        "slug": "M.-Isard",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Isard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Isard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14382281,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "86efc15754e34254e5991c3a0fdcffbffbc47a3e",
            "isKey": false,
            "numCitedBy": 570,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Partitioned sampling is a technique which was introduced in [I7] for avoiding the high cost of particle filters when tracking more than one object. In fact this technique can reduce the curse of dimensionality in other situations too. This paper describes how to use partitioned sampling on articulated objects, obtaining results that would be impossible with standard sampling methods. Because partitioned sampling is the statistical analogue of a hierarchical search, it makes sense to use it on articulated objects, since links at the base of the object can be localised before moving on to search for subsequent links."
            },
            "slug": "Partitioned-Sampling,-Articulated-Objects,-and-Hand-MacCormick-Isard",
            "title": {
                "fragments": [],
                "text": "Partitioned Sampling, Articulated Objects, and Interface-Quality Hand Tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper describes how to use partitioned sampling on articulated objects, obtaining results that would be impossible with standard sampling methods."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145033585"
                        ],
                        "name": "Z. Khan",
                        "slug": "Z.-Khan",
                        "structuredName": {
                            "firstName": "Zia",
                            "lastName": "Khan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Khan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1826964"
                        ],
                        "name": "T. Balch",
                        "slug": "T.-Balch",
                        "structuredName": {
                            "firstName": "Tucker",
                            "lastName": "Balch",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Balch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2038264"
                        ],
                        "name": "F. Dellaert",
                        "slug": "F.-Dellaert",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Dellaert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Dellaert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 580489,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "4831bafed66417a353530e3cd6d9dbee6516499c",
            "isKey": false,
            "numCitedBy": 906,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a particle filter that effectively deals with interacting targets, targets that are influenced by the proximity and/or behavior of other targets. The particle filter includes a Markov random field (MRF) motion prior that helps maintain the identity of targets throughout an interaction, significantly reducing tracker failures. We show that this MRF prior can be easily implemented by including an additional interaction factor in the importance weights of the particle filter. However, the computational requirements of the resulting multitarget filter render it unusable for large numbers of targets. Consequently, we replace the traditional importance sampling step in the particle filter with a novel Markov chain Monte Carlo (MCMC) sampling step to obtain a more efficient MCMC-based multitarget filter. We also show how to extend this MCMC-based filter to address a variable number of interacting targets. Finally, we present both qualitative and quantitative experimental results, demonstrating that the resulting particle filters deal efficiently and effectively with complicated target interactions."
            },
            "slug": "MCMC-based-particle-filtering-for-tracking-a-number-Khan-Balch",
            "title": {
                "fragments": [],
                "text": "MCMC-based particle filtering for tracking a variable number of interacting targets"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A particle filter that effectively deals with interacting targets, targets that are influenced by the proximity and/or behavior of other targets, is described and a novel Markov chain Monte Carlo (MCMC) sampling step is replaced to obtain a more efficient MCMC-based multitarget filter."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703537"
                        ],
                        "name": "Y. Freund",
                        "slug": "Y.-Freund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Freund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6644398,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ccf5208521cb8c35f50ee8873df89294b8ed7292",
            "isKey": false,
            "numCitedBy": 13126,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "In the first part of the paper we consider the problem of dynamically apportioning resources among a set of options in a worst-case on-line framework. The model we study can be interpreted as a broad, abstract extension of the well-studied on-line prediction model to a general decision-theoretic setting. We show that the multiplicative weight-update Littlestone?Warmuth rule can be adapted to this model, yielding bounds that are slightly weaker in some cases, but applicable to a considerably more general class of learning problems. We show how the resulting learning algorithm can be applied to a variety of problems, including gambling, multiple-outcome prediction, repeated games, and prediction of points in Rn. In the second part of the paper we apply the multiplicative weight-update technique to derive a new boosting algorithm. This boosting algorithm does not require any prior knowledge about the performance of the weak learning algorithm. We also study generalizations of the new boosting algorithm to the problem of learning functions whose range, rather than being binary, is an arbitrary finite set or a bounded segment of the real line."
            },
            "slug": "A-decision-theoretic-generalization-of-on-line-and-Freund-Schapire",
            "title": {
                "fragments": [],
                "text": "A decision-theoretic generalization of on-line learning and an application to boosting"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "The model studied can be interpreted as a broad, abstract extension of the well-studied on-line prediction model to a general decision-theoretic setting, and it is shown that the multiplicative weight-update Littlestone?Warmuth rule can be adapted to this model, yielding bounds that are slightly weaker in some cases, but applicable to a considerably more general class of learning problems."
            },
            "venue": {
                "fragments": [],
                "text": "EuroCOLT"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2679389"
                        ],
                        "name": "A. Baumberg",
                        "slug": "A.-Baumberg",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Baumberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Baumberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The main difference between generative and discriminative models is how posterior probabilities are estimated for each class."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 523052,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "10004bd29d61704f1bef4dcf6f09e0d942f495ac",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Hierarchical-shape-fitting-using-an-iterated-linear-Baumberg",
            "title": {
                "fragments": [],
                "text": "Hierarchical shape fitting using an iterated linear filter"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2882378"
                        ],
                        "name": "Karina Zapien Arreola",
                        "slug": "Karina-Zapien-Arreola",
                        "structuredName": {
                            "firstName": "Karina",
                            "lastName": "Arreola",
                            "middleNames": [
                                "Zapien"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karina Zapien Arreola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1951979"
                        ],
                        "name": "J. Fehr",
                        "slug": "J.-Fehr",
                        "structuredName": {
                            "firstName": "Janis",
                            "lastName": "Fehr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Fehr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36736177"
                        ],
                        "name": "H. Burkhardt",
                        "slug": "H.-Burkhardt",
                        "structuredName": {
                            "firstName": "Hans",
                            "lastName": "Burkhardt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Burkhardt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12838921,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "88fac1ec835681d0fe7e0da5e7f73a4b6017e70c",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a classification method based on a decision tree whose nodes consist of linear support vector machines (SVMs). Each node defines a decision hyperplane that classifies part of the feature space. For large classification problems (with many support vectors (SVs)) it has the advantage that the classification time does not depend on the number of SVs. Here, the classification of a new sample can be calculated by the dot product with the orthogonal vector of each hyperplane. The number of nodes in the tree has shown to be much smaller than the number of SVs in a non-linear SVM, thus, a significant speedup in classification time can be achieved. For non-linear separable problems, the trivial solution (zero vector) of a linear SVM is analyzed and a new formulation of the optimization problem is given to avoid it"
            },
            "slug": "Fast-Support-Vector-Machine-Classification-using-Arreola-Fehr",
            "title": {
                "fragments": [],
                "text": "Fast Support Vector Machine Classification using linear SVMs"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The number of nodes in the tree has shown to be much smaller than the number of SVs in a non-linear SVM, thus, a significant speedup in classification time can be achieved."
            },
            "venue": {
                "fragments": [],
                "text": "18th International Conference on Pattern Recognition (ICPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2090818"
                        ],
                        "name": "M. Isard",
                        "slug": "M.-Isard",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Isard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Isard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145162067"
                        ],
                        "name": "A. Blake",
                        "slug": "A.-Blake",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Blake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blake"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6821810,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "963dddc907f56bd1d6c98dd40f560eb8786e49ea",
            "isKey": false,
            "numCitedBy": 5523,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of tracking curves in dense visual clutter is challenging. Kalman filtering is inadequate because it is based on Gaussian densities which, being unimo dal, cannot represent simultaneous alternative hypotheses. The Condensation algorithm uses \u201cfactored sampling\u201d, previously applied to the interpretation of static images, in which the probability distribution of possible interpretations is represented by a randomly generated set. Condensation uses learned dynamical models, together with visual observations, to propagate the random set over time. The result is highly robust tracking of agile motion. Notwithstanding the use of stochastic methods, the algorithm runs in near real-time."
            },
            "slug": "CONDENSATION\u2014Conditional-Density-Propagation-for-Isard-Blake",
            "title": {
                "fragments": [],
                "text": "CONDENSATION\u2014Conditional Density Propagation for Visual Tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The Condensation algorithm uses \u201cfactored sampling\u201d, previously applied to the interpretation of static images, in which the probability distribution of possible interpretations is represented by a randomly generated set."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112255"
                        ],
                        "name": "S. Marsland",
                        "slug": "S.-Marsland",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Marsland",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Marsland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2822268"
                        ],
                        "name": "C. Twining",
                        "slug": "C.-Twining",
                        "structuredName": {
                            "firstName": "Carole",
                            "lastName": "Twining",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Twining"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118120241"
                        ],
                        "name": "Kate Smith",
                        "slug": "Kate-Smith",
                        "structuredName": {
                            "firstName": "Kate",
                            "lastName": "Smith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kate Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The main difference between generative and discriminative models is how posterior probabilities are estimated for each class."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2982288,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c37792e0cbe4363caff54be87aaf080d21adfc6",
            "isKey": false,
            "numCitedBy": 121,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a framework for registering a group of images together using a set of non-linear diffeomorphic warps. The result of the groupwise registration is an implicit definition of dense correspondences between all of the images in a set, which can be used to construct statistical models of shape change across the set, avoiding the need for manual annotation of training images. We give examples on two datasets (brains and faces) and show the resulting models of shape and appearance variation. We show results of experiments demonstrating that the groupwise approach gives a more reliable correspondence than pairwise matching alone."
            },
            "slug": "Groupwise-Diffeomorphic-Non-rigid-Registration-for-Cootes-Marsland",
            "title": {
                "fragments": [],
                "text": "Groupwise Diffeomorphic Non-rigid Registration for Automatic Model Building"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "The result of the groupwise registration is an implicit definition of dense correspondences between all of the images in a set, which can be used to construct statistical models of shape change across the set, avoiding the need for manual annotation of training images."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644050191"
                        ],
                        "name": "G. LoweDavid",
                        "slug": "G.-LoweDavid",
                        "structuredName": {
                            "firstName": "G",
                            "lastName": "LoweDavid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. LoweDavid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "While the latter two require models of the pedestrian class, e.g., in terms of geometry, appearance, or dynamics, the initial generation of regions of interest is usually based on more general low-level features or prior scene knowledge."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 174065,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4cab9c4b571761203ed4c3a4c5a07dd615f57a91",
            "isKey": false,
            "numCitedBy": 25503,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are ..."
            },
            "slug": "Distinctive-Image-Features-from-Scale-Invariant-LoweDavid",
            "title": {
                "fragments": [],
                "text": "Distinctive Image Features from Scale-Invariant Keypoints"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The main difference between generative and discriminative models is how posterior probabilities are estimated for each class."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61105478,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c56d05649805eb0429aaa8c0f9992247f6fbfbd1",
            "isKey": false,
            "numCitedBy": 995,
            "numCiting": 112,
            "paperAbstract": {
                "fragments": [],
                "text": "1 This is an ongoing draft of a report describing our work on Active Shape Models and Active Appearance Models. Hopefully it will be expanded to become more comprehensive, when I get the time. My apologies for the missing and incomplete sections and the inconsistancies in notation. TFC"
            },
            "slug": "Statistical-models-of-appearance-for-computer-Cootes-Taylor",
            "title": {
                "fragments": [],
                "text": "Statistical models of appearance for computer vision"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "This is an ongoing draft of a report describing the authors' work on Active Shape Models and Active Appearance Models, and hopefully it will be expanded to become more comprehensive, when I get the time."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696091"
                        ],
                        "name": "C. W\u00f6hler",
                        "slug": "C.-W\u00f6hler",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "W\u00f6hler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. W\u00f6hler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1976316"
                        ],
                        "name": "J. Anlauf",
                        "slug": "J.-Anlauf",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Anlauf",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Anlauf"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u00c7"
                    },
                    "intents": []
                }
            ],
            "corpusId": 16813677,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9a0a08e4d9a4cea6fa035555f2ee54bdae673614",
            "isKey": false,
            "numCitedBy": 131,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "In this letter we present an algorithm based on a time-delay neural network with spatio-temporal receptive fields and adaptable time delays for image sequence analysis. Our main result is that tedious manual adaptation of the temporal size of the receptive fields can be avoided by employing a novel method to adapt the corresponding time delay and related network structure parameters during the training process."
            },
            "slug": "An-adaptable-time-delay-neural-network-algorithm-W\u00f6hler-Anlauf",
            "title": {
                "fragments": [],
                "text": "An adaptable time-delay neural-network algorithm for image sequence analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The main result is that tedious manual adaptation of the temporal size of the receptive fields can be avoided by employing a novel method to adapt the corresponding time delay and related network structure parameters during the training process."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1774881"
                        ],
                        "name": "M. Bergtholdt",
                        "slug": "M.-Bergtholdt",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Bergtholdt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bergtholdt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695302"
                        ],
                        "name": "D. Cremers",
                        "slug": "D.-Cremers",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Cremers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cremers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679944"
                        ],
                        "name": "C. Schn\u00f6rr",
                        "slug": "C.-Schn\u00f6rr",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Schn\u00f6rr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schn\u00f6rr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The main difference between generative and discriminative models is how posterior probabilities are estimated for each class."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17167380,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4fcb1aaf6279b4bd2dbfff91930f371ba7c322e2",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We discuss the design of shape priors for variational region-based segmentation. By means of two different approaches, we elucidate the critical design issues involved: representation of shape, use of perceptually plausible dissimilarity measures, Euclidean embedding of shapes, learning of shape appearance from examples, combining shape priors and variational approaches to segmentation. The overall approach enables the appearance-based segmentation of views of 3D objects, without the use of 3D models."
            },
            "slug": "Variational-Segmentation-with-Shape-Priors-Bergtholdt-Cremers",
            "title": {
                "fragments": [],
                "text": "Variational Segmentation with Shape Priors"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The overall approach enables the appearance-based segmentation of views of3D objects, without the use of 3D models, using shape priors and variational approaches to segmentation."
            },
            "venue": {
                "fragments": [],
                "text": "Handbook of Mathematical Models in Computer Vision"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3160228"
                        ],
                        "name": "K. Fukushima",
                        "slug": "K.-Fukushima",
                        "structuredName": {
                            "firstName": "Kunihiko",
                            "lastName": "Fukushima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fukushima"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3126340"
                        ],
                        "name": "S. Miyake",
                        "slug": "S.-Miyake",
                        "structuredName": {
                            "firstName": "Sei",
                            "lastName": "Miyake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Miyake"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145214184"
                        ],
                        "name": "Takayuki Ito",
                        "slug": "Takayuki-Ito",
                        "structuredName": {
                            "firstName": "Takayuki",
                            "lastName": "Ito",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Takayuki Ito"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 8235461,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "71ea46c9266f5104f79ea27fdfb4c5686677695a",
            "isKey": false,
            "numCitedBy": 755,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "A recognition with a large-scale network is simulated on a PDP-11/34 minicomputer and is shown to have a great capability for visual pattern recognition. The model consists of nine layers of cells. The authors demonstrate that the model can be trained to recognize handwritten Arabic numerals even with considerable deformations in shape. A learning-with-a-teacher process is used for the reinforcement of the modifiable synapses in the new large-scale model, instead of the learning-without-a-teacher process applied to a previous model. The authors focus on the mechanism for pattern recognition rather than that for self-organization."
            },
            "slug": "Neocognitron:-A-neural-network-model-for-a-of-Fukushima-Miyake",
            "title": {
                "fragments": [],
                "text": "Neocognitron: A neural network model for a mechanism of visual pattern recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A recognition with a large-scale network is simulated on a PDP-11/34 minicomputer and is shown to have a great capability for visual pattern recognition and can be trained to recognize handwritten Arabic numerals even with considerable deformations in shape."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Systems, Man, and Cybernetics"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2941401"
                        ],
                        "name": "H. Kuhn",
                        "slug": "H.-Kuhn",
                        "structuredName": {
                            "firstName": "Harold",
                            "lastName": "Kuhn",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kuhn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9426884,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "b6a0f30260302a2001da9999096cfdd89bc1f7fb",
            "isKey": false,
            "numCitedBy": 4506,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper has been presented with the Best Paper Award. It will appear in print in Volume 52, No. 1, February 2005."
            },
            "slug": "The-Hungarian-method-for-the-assignment-problem-Kuhn",
            "title": {
                "fragments": [],
                "text": "The Hungarian Method for the Assignment Problem"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper has always been one of my favorite \u201cchildren,\u201d combining as it does elements of the duality of linear programming and combinatorial tools from graph theory."
            },
            "venue": {
                "fragments": [],
                "text": "50 Years of Integer Programming"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3985917"
                        ],
                        "name": "H. Bastian",
                        "slug": "H.-Bastian",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Bastian",
                            "middleNames": [
                                "Charlton"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bastian"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 16
                            }
                        ],
                        "text": "Total processing time for training, testing, and evaluation was several months of CPU time on a 2.66 GHz Intel processor, using implementations in C/C++.\ntraining samples with an actual pedestrian height of 32 pixels (small scale) and 72 pixels (medium scale)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4120647,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "2f1f4a22a906e57c81241c16a7c2fc982d9d44c6",
            "isKey": true,
            "numCitedBy": 1339,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "VERY different meanings have been attached to the words sensation and perception by different writers; and this diversity of meaning is to be met with in physiological as well as in more strictly philosophical works. Yet it is most important that we should come to a definite understanding upon the subject, in order to know whether certain physiologists have been warranted in assigning sensation and perception to different parts of the brain, as functions of separate portions of this principal organ of mind."
            },
            "slug": "Sensation-and-Perception.\u2014I-Bastian",
            "title": {
                "fragments": [],
                "text": "Sensation and Perception.\u2014I"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1869
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7138354,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8213dbed4db44e113af3ed17d6dad57471a0c048",
            "isKey": false,
            "numCitedBy": 38755,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Setting of the learning problem consistency of learning processes bounds on the rate of convergence of learning processes controlling the generalization ability of learning processes constructing learning algorithms what is important in learning theory?."
            },
            "slug": "The-Nature-of-Statistical-Learning-Theory-Vapnik",
            "title": {
                "fragments": [],
                "text": "The Nature of Statistical Learning Theory"
            },
            "venue": {
                "fragments": [],
                "text": "Statistics for Engineering and Information Science"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47139824"
                        ],
                        "name": "A. Fitzgibbon",
                        "slug": "A.-Fitzgibbon",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Fitzgibbon",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Fitzgibbon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742208"
                        ],
                        "name": "M. Pollefeys",
                        "slug": "M.-Pollefeys",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Pollefeys",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pollefeys"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 63374487,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "19d6e925ed9643c28981edd233d074b6e3a793c6",
            "isKey": false,
            "numCitedBy": 319,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "European-conference-on-computer-vision-(ECCV)-Fitzgibbon-Pollefeys",
            "title": {
                "fragments": [],
                "text": "European conference on computer vision (ECCV)"
            },
            "venue": {
                "fragments": [],
                "text": "eccv 2006"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 30
                            }
                        ],
                        "text": "Support Vector Machines (SVM) [73] have evolved as a powerful tool to solve pattern classification problems."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 59752996,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "5451278e1a11cf3f1be28a05f38d36c8641e68f7",
            "isKey": false,
            "numCitedBy": 4580,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Nature-of-Statistical-Learning-Vapnik",
            "title": {
                "fragments": [],
                "text": "The Nature of Statistical Learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 147
                            }
                        ],
                        "text": "Such features are referred to as local receptive fields [19], [23], [49], [68], [75], in reference to neural structures in the human visual cortex [24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Sensation and Perception (6th ed.)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical Pattern Recognition: A Review IEEE Trans. Pattern Analysis and Machine Intelligence"
            },
            "venue": {
                "fragments": [],
                "text": "Statistical Pattern Recognition: A Review IEEE Trans. Pattern Analysis and Machine Intelligence"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Intel OpenCV Library"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 26
                            }
                        ],
                        "text": "We consider a generic evaluation setting and one specific to pedestrian detection onboard a vehicle."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "http://pascal.inrialpes.fr/data/human"
            },
            "venue": {
                "fragments": [],
                "text": "http://pascal.inrialpes.fr/data/human"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Authorized licensed use limited to: SARNOFF CORPORATION"
            },
            "venue": {
                "fragments": [],
                "text": "Authorized licensed use limited to: SARNOFF CORPORATION"
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "For more information on this or any other computing topic, please visit our Digital Library at www.computer.org/publications/dlib"
            },
            "venue": {
                "fragments": [],
                "text": "For more information on this or any other computing topic, please visit our Digital Library at www.computer.org/publications/dlib"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Distance Transformations in Digital Images Computer Vision, Graphics, and Image Processing"
            },
            "venue": {
                "fragments": [],
                "text": "Distance Transformations in Digital Images Computer Vision, Graphics, and Image Processing"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Sensation and Perception, sixth ed"
            },
            "venue": {
                "fragments": [],
                "text": "Sensation and Perception, sixth ed"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "While the latter two require models of the pedestrian class, e.g., in terms of geometry, appearance, or dynamics, the initial generation of regions of interest is usually based on more general low-level features or prior scene knowledge."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Full-Body Recognition System"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognition"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Intel OpenCV Library"
            },
            "venue": {
                "fragments": [],
                "text": "Intel OpenCV Library"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "PETS Data sets"
            },
            "venue": {
                "fragments": [],
                "text": "PETS Data sets"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 177
                            }
                        ],
                        "text": "Likewise, the particular configuration of spatial features has been included in the actual optimization itself, yielding feature sets that adapt to the underlying data set during training."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Variational segmentation with shape priors Mathematical Models in Computer Vision: The Handbook"
            },
            "venue": {
                "fragments": [],
                "text": "Variational segmentation with shape priors Mathematical Models in Computer Vision: The Handbook"
            },
            "year": 2005
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 46,
            "methodology": 9
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 94,
        "totalPages": 10
    },
    "page_url": "https://www.semanticscholar.org/paper/Monocular-Pedestrian-Detection:-Survey-and-Enzweiler-Gavrila/5224b79368dba945a9e90506f23a1cfa91f6f404?sort=total-citations"
}