{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717841"
                        ],
                        "name": "R. Szeliski",
                        "slug": "R.-Szeliski",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Szeliski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Szeliski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2984143"
                        ],
                        "name": "R. Zabih",
                        "slug": "R.-Zabih",
                        "structuredName": {
                            "firstName": "Ramin",
                            "lastName": "Zabih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zabih"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709053"
                        ],
                        "name": "Daniel Scharstein",
                        "slug": "Daniel-Scharstein",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Scharstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Scharstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1922280"
                        ],
                        "name": "O. Veksler",
                        "slug": "O.-Veksler",
                        "structuredName": {
                            "firstName": "Olga",
                            "lastName": "Veksler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Veksler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144653004"
                        ],
                        "name": "V. Kolmogorov",
                        "slug": "V.-Kolmogorov",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Kolmogorov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Kolmogorov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696487"
                        ],
                        "name": "A. Agarwala",
                        "slug": "A.-Agarwala",
                        "structuredName": {
                            "firstName": "Aseem",
                            "lastName": "Agarwala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Agarwala"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802944"
                        ],
                        "name": "M. Tappen",
                        "slug": "M.-Tappen",
                        "structuredName": {
                            "firstName": "Marshall",
                            "lastName": "Tappen",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Tappen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756036"
                        ],
                        "name": "C. Rother",
                        "slug": "C.-Rother",
                        "structuredName": {
                            "firstName": "Carsten",
                            "lastName": "Rother",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rother"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 137
                            }
                        ],
                        "text": "Even the set of per-label costs {hl} slows down \u03b1-expansion by 40\u2013 60%, though this is still relatively fast for such difficult energies [24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1210309,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0f02f771339d3e5524238a9d960b2ef505e2f47",
            "isKey": false,
            "numCitedBy": 1029,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "Among the most exciting advances in early vision has been the development of efficient energy minimization algorithms for pixel-labeling tasks such as depth or texture computation. It has been known for decades that such problems can be elegantly expressed as Markov random fields, yet the resulting energy minimization problems have been widely viewed as intractable. Algorithms such as graph cuts and loopy belief propagation (LBP) have proven to be very powerful: For example, such methods form the basis for almost all the top-performing stereo methods. However, the trade-offs among different energy minimization algorithms are still not well understood. In this paper, we describe a set of energy minimization benchmarks and use them to compare the solution quality and runtime of several common energy minimization algorithms. We investigate three promising methods-graph cuts, LBP, and tree-reweighted message passing-in addition to the well-known older iterated conditional mode (ICM) algorithm. Our benchmark problems are drawn from published energy functions used for stereo, image stitching, interactive segmentation, and denoising. We also provide a general-purpose software interface that allows vision researchers to easily switch between optimization methods. The benchmarks, code, images, and results are available at http://vision.middlebury.edu/MRF/."
            },
            "slug": "A-Comparative-Study-of-Energy-Minimization-Methods-Szeliski-Zabih",
            "title": {
                "fragments": [],
                "text": "A Comparative Study of Energy Minimization Methods for Markov Random Fields with Smoothness-Based Priors"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A set of energy minimization benchmarks are described and used to compare the solution quality and runtime of several common energy minimizations algorithms and a general-purpose software interface is provided that allows vision researchers to easily switch between optimization methods."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698556"
                        ],
                        "name": "Jing Yuan",
                        "slug": "Jing-Yuan",
                        "structuredName": {
                            "firstName": "Jing",
                            "lastName": "Yuan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jing Yuan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692688"
                        ],
                        "name": "Yuri Boykov",
                        "slug": "Yuri-Boykov",
                        "structuredName": {
                            "firstName": "Yuri",
                            "lastName": "Boykov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuri Boykov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our combined energy (\ufffd ) has recently been extended to convex continuous total variation (TV) formulations ( Yuan and Boykov 2010 )."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5644983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c00f19712b8919b4e70434b9941b18a1e70ab1f5",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper studies image segmentation based on the minimum description length (MDL) functional combining spatial regularization with a penality for the number of distinct segments, a.k.a. label cost prior. Continuous MDL-based segmentation functionals were introduced in [39]. We propose a convex relaxation approach for optimizing MDL criterion that leads to a globally optimal solution. As common in recent continuous convex formulations [30, 31], we use the totalvariation functional to encode spatial regularity of segmentation bondaries. To the best of our knowledge, we are the first to demostrate that the label cost prior can be also addressed within a continuous convex framework. The second-order cone programming algorithm is applied to tackle such nonsmooth convex energy functional. The experiments validate the proposed approach and theoretical results."
            },
            "slug": "TV-Based-Multi-Label-Image-Segmentation-with-Label-Yuan-Boykov",
            "title": {
                "fragments": [],
                "text": "TV-Based Multi-Label Image Segmentation with Label Cost Prior"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "This paper studies image segmentation based on the minimum description length functional combining spatial regularization with a penality for the number of distinct segments, a.k.a. label cost prior to propose a convex relaxation approach for optimizing MDL criterion that leads to a globally optimal solution."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144653004"
                        ],
                        "name": "V. Kolmogorov",
                        "slug": "V.-Kolmogorov",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Kolmogorov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Kolmogorov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692688"
                        ],
                        "name": "Yuri Boykov",
                        "slug": "Yuri-Boykov",
                        "structuredName": {
                            "firstName": "Yuri",
                            "lastName": "Boykov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuri Boykov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756036"
                        ],
                        "name": "C. Rother",
                        "slug": "C.-Rother",
                        "structuredName": {
                            "firstName": "Carsten",
                            "lastName": "Rother",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rother"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 62
                            }
                        ],
                        "text": "8 A similar discussion also appears after Proposition 1(b) in [36]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7582545,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce7dc3a992201ee7b6706c6a8f12b41496691ea2",
            "isKey": false,
            "numCitedBy": 149,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "The maximum flow algorithm for minimizing energy functions of binary variables has become a standard tool in computer vision. In many cases, unary costs of the energy depend linearly on parameter lambda. In this paper we study vision applications for which it is important to solve the maxflow problem for different lambda's. An example is a weighting between data and regularization terms in image segmentation or stereo: it is desirable to vary it both during training (to learn lambda from ground truth data) and testing (to select best lambda using high-knowledge constraints, e.g. user input). We review algorithmic aspects of this parametric maximum flow problem previously unknown in vision, such as the ability to compute all breakpoints of lambda and corresponding optimal configurations infinite time. These results allow, in particular, to minimize the ratio of some geometric functional, such as flux of a vector field over length (or area). Previously, such functional were tackled with shortest path techniques applicable only in 2D. We give theoretical improvements for \"PDE cuts\" [5]. We present experimental results for image segmentation, 3D reconstruction, and the cosegmentation problem."
            },
            "slug": "Applications-of-parametric-maxflow-in-computer-Kolmogorov-Boykov",
            "title": {
                "fragments": [],
                "text": "Applications of parametric maxflow in computer vision"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Algorithmic aspects of this parametric maximum flow problem previously unknown in vision, such as the ability to compute all breakpoints of lambda and corresponding optimal configurations infinite time are reviewed."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE 11th International Conference on Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692688"
                        ],
                        "name": "Yuri Boykov",
                        "slug": "Yuri-Boykov",
                        "structuredName": {
                            "firstName": "Yuri",
                            "lastName": "Boykov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuri Boykov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1922280"
                        ],
                        "name": "O. Veksler",
                        "slug": "O.-Veksler",
                        "structuredName": {
                            "firstName": "Olga",
                            "lastName": "Veksler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Veksler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2984143"
                        ],
                        "name": "R. Zabih",
                        "slug": "R.-Zabih",
                        "structuredName": {
                            "firstName": "Ramin",
                            "lastName": "Zabih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zabih"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 26
                            }
                        ],
                        "text": "The \u03b1-expansion algorithm [4] has had a significant impact in computer vision due to its generality, effectiveness, and speed."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 89
                            }
                        ],
                        "text": "For simplicity, assume that the smoothness terms in (?) are Potts interaction potentials [4] and the third term represents simple per-label costs as in (1)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 90
                            }
                        ],
                        "text": "If each Vpq defines a metric, then minimizing (2) is known as the metric labeling problem [4] and can be optimized effectively with the \u03b1-expansion algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 113
                            }
                        ],
                        "text": "Optimality guarantees In what follows we assume that energy (?) is configured(1) so that Dp \u2265 0, Vpq is a metric [4], and thus E(f) \u2265 0."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 79
                            }
                        ],
                        "text": "Since minimizing energy (?) is NP-hard for |L| \u2265 3 , the \u03b1-expansion algorithm [4] iteratively \u2018moves\u2019 from some current labeling f \u2032 to a better one until convergence."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 81
                            }
                        ],
                        "text": "Our main technical contribution is to extend the wellknown \u03b1-expansion algorithm [4] to incorporate label costs at each expansion (Section 2."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 123
                            }
                        ],
                        "text": "Our main contribution is a way to simultaneously optimize both of these criteria inside the powerful \u03b1-expansion algorithm [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2430892,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3120324069ec20eed853d3f9bbbceb32e4173b93",
            "isKey": false,
            "numCitedBy": 3913,
            "numCiting": 116,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we address the problem of minimizing a large class of energy functions that occur in early vision. The major restriction is that the energy function's smoothness term must only involve pairs of pixels. We propose two algorithms that use graph cuts to compute a local minimum even when very large moves are allowed. The first move we consider is an /spl alpha/-/spl beta/-swap: for a pair of labels /spl alpha/,/spl beta/, this move exchanges the labels between an arbitrary set of pixels labeled a and another arbitrary set labeled /spl beta/. Our first algorithm generates a labeling such that there is no swap move that decreases the energy. The second move we consider is an /spl alpha/-expansion: for a label a, this move assigns an arbitrary set of pixels the label /spl alpha/. Our second algorithm, which requires the smoothness term to be a metric, generates a labeling such that there is no expansion move that decreases the energy. Moreover, this solution is within a known factor of the global minimum. We experimentally demonstrate the effectiveness of our approach on image restoration, stereo and motion."
            },
            "slug": "Fast-approximate-energy-minimization-via-graph-cuts-Boykov-Veksler",
            "title": {
                "fragments": [],
                "text": "Fast approximate energy minimization via graph cuts"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper proposes two algorithms that use graph cuts to compute a local minimum even when very large moves are allowed, and generates a labeling such that there is no expansion move that decreases the energy."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692688"
                        ],
                        "name": "Yuri Boykov",
                        "slug": "Yuri-Boykov",
                        "structuredName": {
                            "firstName": "Yuri",
                            "lastName": "Boykov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuri Boykov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144653004"
                        ],
                        "name": "V. Kolmogorov",
                        "slug": "V.-Kolmogorov",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Kolmogorov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Kolmogorov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 68
                            }
                        ],
                        "text": "This slowdown may be because the BoykovKolmogorov maxflow algorithm [3] relies on heuristics that do not work well for large cliques, i."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5324521,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c62fdf1e6a520d9fee8ca9981fb588d07f2c6fa",
            "isKey": false,
            "numCitedBy": 3563,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "Minimum cut/maximum flow algorithms on graphs have emerged as an increasingly useful tool for exactor approximate energy minimization in low-level vision. The combinatorial optimization literature provides many min-cut/max-flow algorithms with different polynomial time complexity. Their practical efficiency, however, has to date been studied mainly outside the scope of computer vision. The goal of this paper is to provide an experimental comparison of the efficiency of min-cut/max flow algorithms for applications in vision. We compare the running times of several standard algorithms, as well as a new algorithm that we have recently developed. The algorithms we study include both Goldberg-Tarjan style \"push -relabel\" methods and algorithms based on Ford-Fulkerson style \"augmenting paths.\" We benchmark these algorithms on a number of typical graphs in the contexts of image restoration, stereo, and segmentation. In many cases, our new algorithm works several times faster than any of the other methods, making near real-time performance possible. An implementation of our max-flow/min-cut algorithm is available upon request for research purposes."
            },
            "slug": "An-experimental-comparison-of-min-cut/max-flow-for-Boykov-Kolmogorov",
            "title": {
                "fragments": [],
                "text": "An experimental comparison of min-cut/max- flow algorithms for energy minimization in vision"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The goal of this paper is to provide an experimental comparison of the efficiency of min-cut/max flow algorithms for applications in vision, comparing the running times of several standard algorithms, as well as a new algorithm that is recently developed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143967473"
                        ],
                        "name": "Pushmeet Kohli",
                        "slug": "Pushmeet-Kohli",
                        "structuredName": {
                            "firstName": "Pushmeet",
                            "lastName": "Kohli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pushmeet Kohli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728641"
                        ],
                        "name": "Lubor Ladicky",
                        "slug": "Lubor-Ladicky",
                        "structuredName": {
                            "firstName": "Lubor",
                            "lastName": "Ladicky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lubor Ladicky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143635540"
                        ],
                        "name": "Philip H. S. Torr",
                        "slug": "Philip-H.-S.-Torr",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Torr",
                            "middleNames": [
                                "H.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philip H. S. Torr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 16
                            }
                        ],
                        "text": "We used uniform Potts model for pairwise terms."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 6
                            }
                        ],
                        "text": "\u2032) are Potts interaction potentials [4] and the third term represents simple per-label costs as in (1)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 58
                            }
                        ],
                        "text": "Furthermore a binary construction based on Robust P Potts [15], within our expansion step, allows us to encode an arbitrary concave penalty on the number of variables taking a specific label, thus generalizing \u03b4l(\u00b7) if needed."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 180
                            }
                        ],
                        "text": "(8)\nwhere x\u0304p = 1 \u2212 xp. Figure 4 shows the subgraph corresponding to (8) after cancelling the constant \u2212hL.\nSubgraphs of this type have been used in vision before, most notably the Pn Potts potentials of Kohli et al. [14]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 139
                            }
                        ],
                        "text": "Our technical report [8] elaborates on this point and Section 5 mentions an extension to our work based on the Robust P Potts construction [15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 53
                            }
                        ],
                        "text": "Furthermore a binary construction based on Robust Pn Potts [15], within our expansion step, allows us to encode an arbitrary concave penalty on the number of variables taking a specific label, thus generalizing \u03b4l(\u00b7) if needed."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 29
                            }
                        ],
                        "text": "It is easy to represent a Pn Potts potential by combination of label subset cost potentials, but not the other way around."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 121
                            }
                        ],
                        "text": "Our technical report [8] elaborates on this point and Section 5 mentions an extension to our work based on the Robust Pn Potts construction [15]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 690715,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "87073fd45685b78cb5a68e5eae331d88f2a2be63",
            "isKey": true,
            "numCitedBy": 1008,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a novel framework for labelling problems which is able to combine multiple segmentations in a principled manner. Our method is based on higher order conditional random fields and uses potentials defined on sets of pixels (image segments) generated using unsupervised segmentation algorithms. These potentials enforce label consistency in image regions and can be seen as a generalization of the commonly used pairwise contrast sensitive smoothness potentials. The higher order potential functions used in our framework take the form of the Robust Pn model and are more general than the Pn Potts model recently proposed by Kohli et al. We prove that the optimal swap and expansion moves for energy functions composed of these potentials can be computed by solving a st-mincut problem. This enables the use of powerful graph cut based move making algorithms for performing inference in the framework. We test our method on the problem of multi-class object segmentation by augmenting the conventional crf used for object segmentation with higher order potentials defined on image regions. Experiments on challenging data sets show that integration of higher order potentials quantitatively and qualitatively improves results leading to much better definition of object boundaries. We believe that this method can be used to yield similar improvements for many other labelling problems."
            },
            "slug": "Robust-Higher-Order-Potentials-for-Enforcing-Label-Kohli-Ladicky",
            "title": {
                "fragments": [],
                "text": "Robust Higher Order Potentials for Enforcing Label Consistency"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "This paper proposes a novel framework for labelling problems which is able to combine multiple segmentations in a principled manner based on higher order conditional random fields and uses potentials defined on sets of pixels generated using unsupervised segmentation algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2021123"
                        ],
                        "name": "Hossam N. Isack",
                        "slug": "Hossam-N.-Isack",
                        "structuredName": {
                            "firstName": "Hossam",
                            "lastName": "Isack",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hossam N. Isack"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692688"
                        ],
                        "name": "Yuri Boykov",
                        "slug": "Yuri-Boykov",
                        "structuredName": {
                            "firstName": "Yuri",
                            "lastName": "Boykov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuri Boykov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 87
                            }
                        ],
                        "text": "For simplicity, we will discuss PEARL in the context of geometric model fitting, as in [31]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 153
                            }
                        ],
                        "text": "Below we review a technique to effectively explore the continuum of model parameters by working with a finite subset of models at any given iteration t.\nPEARL Algorithm [13]\n1 propose initial models L0 by random samples (as in RANSAC) 2 run \u03b1-expansion to compute optimal labeling f w.r.t. Lt 3 re-estimate model parameters to get Lt+1; t := t+1; goto 2\nPEARL was the first to use regularization energies and EM-style optimization for geometric multi-model fitting."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 10
                            }
                        ],
                        "text": "Review of PEARL for (?)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "As was first argued in [31], energies like (?) are powerful criteria for multi-model fitting in general."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "PEARL\u2019s re-segmentation and re-estimation steps 2 and 3 reduce the energy."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 201
                            }
                        ],
                        "text": "In particular, we compare algorithms from section 2 and several algorithms originally designed for spatial regularization functional (2) which can be applied to (?) using some merging heuristics as in [31]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 10
                            }
                        ],
                        "text": "Step 1 of PEARL is to propose an initial set of models L0."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 17
                            }
                        ],
                        "text": "The algorithm in [31] finds lower energy solutions when new \u2019merge\u2019 proposals are added (compare \u03b1-SM and \u03b1-BM curves in our Section 6)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 145
                            }
                        ],
                        "text": "2; \u03b1\u03b2+ is a straightforward modification of the standard \u03b1\u03b2-swap [11]; \u03b1-SM and \u03b1-BM are standard \u03b1-expansions with different merging heuristics [31]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 12
                            }
                        ],
                        "text": "As in PEARL [31], the labels are initialized by randomly sampling 1000 models."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 96
                            }
                        ],
                        "text": "Our paper introduces a more general energy (?) and a better algorithm for the expansion step of PEARL (step 2)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 14
                            }
                        ],
                        "text": "Surprisingly, [31] showed that there are examples where introducing spatial coherence (Vpq > 0) for i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 19
                            }
                        ],
                        "text": "The experiments in [31] show that their energy-based formulation beats many stateof-the-art algorithms in this area."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "Our setup follows [31], so we give only a brief outline."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 26
                            }
                        ],
                        "text": "The general setup follows [31,42] and is essentially the same as for homography estimation, except now each model is a fundamental matrix F = [K \u2032 t]\u00d7K \u2032RK\u22121 corresponding to a rigid body motion (R, t) and intrinsic parametersK [28]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5461268,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1195c6401ec86cec7bc773485d4ac61b3787be09",
            "isKey": false,
            "numCitedBy": 299,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Geometric model fitting is a typical chicken-&-egg problem: data points should be clustered based on geometric proximity to models whose unknown parameters must be estimated at the same time. Most existing methods, including generalizations of RANSAC, greedily search for models with most inliers (within a threshold) ignoring overall classification of points. We formulate geometric multi-model fitting as an optimal labeling problem with a global energy function balancing geometric errors and regularity of inlier clusters. Regularization based on spatial coherence (on some near-neighbor graph) and/or label costs is NP hard. Standard combinatorial algorithms with guaranteed approximation bounds (e.g. \u03b1-expansion) can minimize such regularization energies over a finite set of labels, but they are not directly applicable to a continuum of labels, e.g. ${\\mathcal{R}}^{2}$ in line fitting. Our proposed approach (PEaRL) combines model sampling from data points as in RANSAC with iterative re-estimation of inliers and models\u2019 parameters based on a global regularization functional. This technique efficiently explores the continuum of labels in the context of energy minimization. In practice, PEaRL converges to a good quality local minimum of the energy automatically selecting a small number of models that best explain the whole data set. Our tests demonstrate that our energy-based approach significantly improves the current state of the art in geometric model fitting currently dominated by various greedy generalizations of RANSAC."
            },
            "slug": "Energy-Based-Geometric-Multi-model-Fitting-Isack-Boykov",
            "title": {
                "fragments": [],
                "text": "Energy-Based Geometric Multi-model Fitting"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The proposed PEaRL combines model sampling from data points as in RANSAC with iterative re-estimation of inliers and models\u2019 parameters based on a global regularization functional and converges to a good quality local minimum of the energy automatically selecting a small number of models that best explain the whole data set."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2731900"
                        ],
                        "name": "Oliver J. Woodford",
                        "slug": "Oliver-J.-Woodford",
                        "structuredName": {
                            "firstName": "Oliver",
                            "lastName": "Woodford",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oliver J. Woodford"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756036"
                        ],
                        "name": "C. Rother",
                        "slug": "C.-Rother",
                        "structuredName": {
                            "firstName": "Carsten",
                            "lastName": "Rother",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rother"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144653004"
                        ],
                        "name": "V. Kolmogorov",
                        "slug": "V.-Kolmogorov",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Kolmogorov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Kolmogorov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Label costs can be viewed as a special case of other global interactions recently studied in vision, for example by Werner (2008) and  Woodford et al. (2009) ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14372063,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "39895a507c887280a694f2a137bb0cac58dab6d8",
            "isKey": false,
            "numCitedBy": 70,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "In recent years the Markov Random Field (MRF) has become the de facto probabilistic model for low-level vision applications. However, in a maximum a posteriori (MAP) framework, MRFs inherently encourage delta function marginal statistics. By contrast, many low-level vision problems have heavy tailed marginal statistics, making the MRF model unsuitable. In this paper we introduce a more general Marginal Probability Field (MPF), of which the MRF is a special, linear case, and show that convex energy MPFs can be used to encourage arbitrary marginal statistics. We introduce a flexible, extensible framework for effectively optimizing the resulting NP-hard MAP problem, based around dual-decomposition and a modified min-cost flow algorithm, and which achieves global optimality in some instances. We use a range of applications, including image denoising and texture synthesis, to demonstrate the benefits of this class of MPF over MRFs."
            },
            "slug": "A-global-perspective-on-MAP-inference-for-low-level-Woodford-Rother",
            "title": {
                "fragments": [],
                "text": "A global perspective on MAP inference for low-level vision"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A flexible, extensible framework for effectively optimizing the resulting NP-hard MAP problem is introduced, based around dual-decomposition and a modified min-cost flow algorithm, and which achieves global optimality in some instances."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144653004"
                        ],
                        "name": "V. Kolmogorov",
                        "slug": "V.-Kolmogorov",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Kolmogorov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Kolmogorov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Geman and Geman 1984; Leclerc 1989;  Kolmogorov 2006 ) or their modifications, our empirical evaluation is focused on graph cut methods that we consider more promising due to optimality guarantees associated with them."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8616813,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0bcc580a1e9e32b3329363bab43331ed9c5a7d4",
            "isKey": false,
            "numCitedBy": 1302,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Algorithms for discrete energy minimization are of fundamental importance in computer vision. In this paper, we focus on the recent technique proposed by Wainwright et al. (Nov. 2005)- tree-reweighted max-product message passing (TRW). It was inspired by the problem of maximizing a lower bound on the energy. However, the algorithm is not guaranteed to increase this bound - it may actually go down. In addition, TRW does not always converge. We develop a modification of this algorithm which we call sequential tree-reweighted message passing. Its main property is that the bound is guaranteed not to decrease. We also give a weak tree agreement condition which characterizes local maxima of the bound with respect to TRW algorithms. We prove that our algorithm has a limit point that achieves weak tree agreement. Finally, we show that, our algorithm requires half as much memory as traditional message passing approaches. Experimental results demonstrate that on certain synthetic and real problems, our algorithm outperforms both the ordinary belief propagation and tree-reweighted algorithm in (M. J. Wainwright, et al., Nov. 2005). In addition, on stereo problems with Potts interactions, we obtain a lower energy than graph cuts"
            },
            "slug": "Convergent-Tree-Reweighted-Message-Passing-for-Kolmogorov",
            "title": {
                "fragments": [],
                "text": "Convergent Tree-Reweighted Message Passing for Energy Minimization"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This paper develops a modification of the recent technique proposed by Wainwright et al. (Nov. 2005), called sequential tree-reweighted message passing, which outperforms both the ordinary belief propagation and tree- reweighted algorithm in both synthetic and real problems."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143967473"
                        ],
                        "name": "Pushmeet Kohli",
                        "slug": "Pushmeet-Kohli",
                        "structuredName": {
                            "firstName": "Pushmeet",
                            "lastName": "Kohli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pushmeet Kohli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3717791"
                        ],
                        "name": "M. P. Kumar",
                        "slug": "M.-P.-Kumar",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Kumar",
                            "middleNames": [
                                "Pawan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. P. Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143635540"
                        ],
                        "name": "Philip H. S. Torr",
                        "slug": "Philip-H.-S.-Torr",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Torr",
                            "middleNames": [
                                "H.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philip H. S. Torr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Subgraphs of this type have been used in vision before, most notably the P n Potts potentials of Kohli et al. [ 14 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3084505,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "37f70fdac335148c52b6e29087dcfa838253af70",
            "isKey": false,
            "numCitedBy": 246,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we extend the class of energy functions for which the optimal alpha-expansion and alphabeta-swap moves can be computed in polynomial time. Specifically, we introduce a class of higher order clique potentials and show that the expansion and swap moves for any energy function composed of these potentials can be found by minimizing a submodular function. We also show that for a subset of these potentials, the optimal move can be found by solving an st-mincut problem. We refer to this subset as the P3 Potts model. Our results enable the use of powerful move making algorithms i.e. alpha-expansion and alphabeta-swap for minimization of energy functions involving higher order cliques. Such functions have the capability of modelling the rich statistics of natural scenes and can be used for many applications in computer vision. We demonstrate their use on one such application i.e. the texture based video segmentation problem."
            },
            "slug": "P3-&-Beyond:-Solving-Energies-with-Higher-Order-Kohli-Kumar",
            "title": {
                "fragments": [],
                "text": "P3 & Beyond: Solving Energies with Higher Order Cliques"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A class of higher order clique potentials is introduced and it is shown that the expansion and swap moves for any energy function composed of these potentials can be found by minimizing a submodular function."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143967473"
                        ],
                        "name": "Pushmeet Kohli",
                        "slug": "Pushmeet-Kohli",
                        "structuredName": {
                            "firstName": "Pushmeet",
                            "lastName": "Kohli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pushmeet Kohli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3717791"
                        ],
                        "name": "M. P. Kumar",
                        "slug": "M.-P.-Kumar",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Kumar",
                            "middleNames": [
                                "Pawan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. P. Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143635540"
                        ],
                        "name": "Philip H. S. Torr",
                        "slug": "Philip-H.-S.-Torr",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Torr",
                            "middleNames": [
                                "H.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philip H. S. Torr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18084258,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "28aef2ccbe0a8a24670a21f38e775b8ef91b4370",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we extend the class of energy functions for which the optimal \u03b1-expansion and \u03b1\u03b2-swap moves can be computed in polynomial time. Specifically, we introduce a class of higher order clique potentials and show that the expansion and swap moves for any energy function composed of these potentials can be found by minimizing a submodular function. We also show that for a subset of these potentials, the optimal move can be found by solving an st-mincut problem. We refer to this subset as the Pn Potts model. Our results enable the use of powerful move making algorithms i.e. \u03b1-expansion and \u03b1\u03b2-swap for minimization of energy functions involving higher order cliques. Such functions have the capability of modelling the rich statistics of natural scenes and can be used for many applications in computer vision. We demonstrate their use on one such application i.e. the texture based video segmentation problem."
            },
            "slug": "Solving-Energies-with-Higher-Order-Cliques-Kohli-Kumar",
            "title": {
                "fragments": [],
                "text": "Solving Energies with Higher Order Cliques"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A class of higher order clique potentials is introduced and it is shown that the expansion and swap moves for any energy function composed of these potentials can be found by minimizing a submodular function."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778989"
                        ],
                        "name": "M. Szummer",
                        "slug": "M.-Szummer",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Szummer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Szummer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143967473"
                        ],
                        "name": "Pushmeet Kohli",
                        "slug": "Pushmeet-Kohli",
                        "structuredName": {
                            "firstName": "Pushmeet",
                            "lastName": "Kohli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pushmeet Kohli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433269"
                        ],
                        "name": "Derek Hoiem",
                        "slug": "Derek-Hoiem",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Hoiem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Hoiem"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This approach was recently used for CRF learning, e.g. ( Szummer et al. 2008 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13252941,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb86d3cd5d18477be5164b5c9335bfb79e7124a7",
            "isKey": false,
            "numCitedBy": 309,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Many computer vision problems are naturally formulated as random fields, specifically MRFs or CRFs. The introduction of graph cuts has enabled efficient and optimal inference in associative random fields, greatly advancing applications such as segmentation, stereo reconstruction and many others. However, while fast inference is now widespread, parameter learning in random fields has remained an intractable problem. This paper shows how to apply fast inference algorithms, in particular graph cuts, to learn parameters of random fields with similar efficiency. We find optimal parameter values under standard regularized objective functions that ensure good generalization. Our algorithm enables learning of many parameters in reasonable time, and we explore further speedup techniques. We also discuss extensions to non-associative and multi-class problems. We evaluate the method on image segmentation and geometry recognition."
            },
            "slug": "Learning-CRFs-Using-Graph-Cuts-Szummer-Kohli",
            "title": {
                "fragments": [],
                "text": "Learning CRFs Using Graph Cuts"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper shows how to apply fast inference algorithms, in particular graph cuts, to learn parameters of random fields with similar efficiency, and finds optimal parameter values under standard regularized objective functions that ensure good generalization."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40124570"
                        ],
                        "name": "Hongdong Li",
                        "slug": "Hongdong-Li",
                        "structuredName": {
                            "firstName": "Hongdong",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hongdong Li"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 67
                            }
                        ],
                        "text": "The aim is to select true motions from among the candidates, as in [25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 84
                            }
                        ],
                        "text": "This well-studied problem was recently applied for motion segmentation, first by Li [25] and then by Lazic et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 89
                            }
                        ],
                        "text": "Acknowledgements We would like to thank Fredrik Kahl for referring us to the works of Li [25] and Vidal [35], and for suggesting motion segmentation as an application."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "Li [25] recently posed multi-model fitting in terms of UFL."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 54
                            }
                        ],
                        "text": "This criterion was also discussed by Torr [34] and Li [25] in the context of motion estimation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 124
                            }
                        ],
                        "text": "The first point (\u2022) in each series is taken after exactly one segmentation/re-estimation, and thus suggests the speed of Li [25] using a fast greedy algorithm instead of LP relaxation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 88
                            }
                        ],
                        "text": "Other geometric model fitting works have used separate elements such as random sampling [34, 25] (as in RANSAC) or EM-style iteration [3], but none have combined them in a single optimization framework."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 57
                            }
                        ],
                        "text": "The 1st segmentation and re-estimation corresponds to Li [25], but only the yellow line and gray line were correctly aligned."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "Li [25] uses a number of \u201cguided sampling\u201d heuristics specific to motion estimation, but they are only used for the initial proposals."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "Recall that Li [25] does not re-estimate beyond the first iteration, and thus corresponds to what we are calling brute-force, i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10593669,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e1fabfd1d6a6052acf0e6505f2164e7f1b4fe69",
            "isKey": true,
            "numCitedBy": 64,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper studies the problem of multibody motion segmentation, which is an important, but challenging problem due to its well-known chicken-and-egg-type recursive character. We propose a new mixture-of-fundamental-matrices model to describe the multibody motions from two views. Based on the maximum likelihood estimation, in conjunction with a random sampling scheme, we show that the problem can be naturally formulated as a linear programming (LP) problem. Consequently, the motion segmentation problem can be solved efficiently by linear program relaxation. Experiments demonstrate that: without assuming the actual number of motions our method produces accurate segmentation result. This LP formulation has also other advantages, such as easy to handle outliers and easy to enforce prior knowledge etc."
            },
            "slug": "Two-View-Motion-Segmentation-from-Linear-Relaxation-Li",
            "title": {
                "fragments": [],
                "text": "Two-View Motion Segmentation from Linear Programming Relaxation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A new mixture-of-fundamental-matrices model is proposed to describe the multibody motions from two views that can be naturally formulated as a linear programming (LP) problem and can be solved efficiently by linear program relaxation."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756036"
                        ],
                        "name": "C. Rother",
                        "slug": "C.-Rother",
                        "structuredName": {
                            "firstName": "Carsten",
                            "lastName": "Rother",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rother"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144653004"
                        ],
                        "name": "V. Kolmogorov",
                        "slug": "V.-Kolmogorov",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Kolmogorov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Kolmogorov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145162067"
                        ],
                        "name": "A. Blake",
                        "slug": "A.-Blake",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Blake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blake"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6202829,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f26d35d2e32934150cd27b030d4d769942126184",
            "isKey": false,
            "numCitedBy": 5202,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of efficient, interactive foreground/background segmentation in still images is of great practical importance in image editing. Classical image segmentation tools use either texture (colour) information, e.g. Magic Wand, or edge (contrast) information, e.g. Intelligent Scissors. Recently, an approach based on optimization by graph-cut has been developed which successfully combines both types of information. In this paper we extend the graph-cut approach in three respects. First, we have developed a more powerful, iterative version of the optimisation. Secondly, the power of the iterative algorithm is used to simplify substantially the user interaction needed for a given quality of result. Thirdly, a robust algorithm for \"border matting\" has been developed to estimate simultaneously the alpha-matte around an object boundary and the colours of foreground pixels. We show that for moderately difficult examples the proposed method outperforms competitive tools."
            },
            "slug": "\"GrabCut\":-interactive-foreground-extraction-using-Rother-Kolmogorov",
            "title": {
                "fragments": [],
                "text": "\"GrabCut\": interactive foreground extraction using iterated graph cuts"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A more powerful, iterative version of the optimisation of the graph-cut approach is developed and the power of the iterative algorithm is used to simplify substantially the user interaction needed for a given quality of result."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Trans. Graph."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728641"
                        ],
                        "name": "Lubor Ladicky",
                        "slug": "Lubor-Ladicky",
                        "structuredName": {
                            "firstName": "Lubor",
                            "lastName": "Ladicky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lubor Ladicky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145485799"
                        ],
                        "name": "Chris Russell",
                        "slug": "Chris-Russell",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Russell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Russell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143967473"
                        ],
                        "name": "Pushmeet Kohli",
                        "slug": "Pushmeet-Kohli",
                        "structuredName": {
                            "firstName": "Pushmeet",
                            "lastName": "Kohli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pushmeet Kohli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143635540"
                        ],
                        "name": "Philip H. S. Torr",
                        "slug": "Philip-H.-S.-Torr",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Torr",
                            "middleNames": [
                                "H.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philip H. S. Torr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 19
                            }
                        ],
                        "text": "The application in [39] is object recognition with co-occurrance statistics."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 80
                            }
                        ],
                        "text": "This allows interesting new ideas for segmentation, as recently demonstrated in [39] in the context of object recognition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[39], also within an \u03b1-expansion framework but with a heuristic extension; see Section 7 for discussion."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2794268,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0095ca57665eae51c9dd7a4ed8a3311aeea1b441",
            "isKey": true,
            "numCitedBy": 365,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "Markov and Conditional random fields (CRFs) used in computer vision typically model only local interactions between variables, as this is computationally tractable. In this paper we consider a class of global potentials defined over all variables in the CRF. We show how they can be readily optimised using standard graph cut algorithms at little extra expense compared to a standard pairwise field. \n \nThis result can be directly used for the problem of class based image segmentation which has seen increasing recent interest within computer vision. Here the aim is to assign a label to each pixel of a given image from a set of possible object classes. Typically these methods use random fields to model local interactions between pixels or super-pixels. One of the cues that helps recognition is global object co-occurrence statistics, a measure of which classes (such as chair or motorbike) are likely to occur in the same image together. There have been several approaches proposed to exploit this property, but all of them suffer from different limitations and typically carry a high computational cost, preventing their application on large images. We find that the new model we propose produces an improvement in the labelling compared to just using a pairwise model."
            },
            "slug": "Graph-Cut-Based-Inference-with-Co-occurrence-Ladicky-Russell",
            "title": {
                "fragments": [],
                "text": "Graph Cut Based Inference with Co-occurrence Statistics"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper considers a class of global potentials defined over all variables in the CRF to show how they can be readily optimised using standard graph cut algorithms at little extra expense compared to a standard pairwise field."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144019647"
                        ],
                        "name": "I. B. Ayed",
                        "slug": "I.-B.-Ayed",
                        "structuredName": {
                            "firstName": "Ismail",
                            "lastName": "Ayed",
                            "middleNames": [
                                "Ben"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. B. Ayed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688991"
                        ],
                        "name": "A. Mitiche",
                        "slug": "A.-Mitiche",
                        "structuredName": {
                            "firstName": "Amar",
                            "lastName": "Mitiche",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Mitiche"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 4
                            }
                        ],
                        "text": "Ben-Ayed and Mitiche (2008) use multilevel sets to optimize an MDL-like region merging prior."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16978259,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0a8d6b06f0ea7e1464e8b7b152928a06b758e24d",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "In current level set image segmentation methods, the number of regions is assumed to known beforehand. As a result, it remains constant during the optimization of the objective functional. How to allow it to vary is an important question which has been generally avoided. This study investigates a region merging prior related to regions area to allow the number of regions to vary automatically during curve evolution, thereby optimizing the objective functional implicitly with respect to the number of regions. We give a statistical interpretation to the coefficient of this prior to balance its effect systematically against the other functional terms. We demonstrate the validity and efficiency of the method by testing on real images of intensity, color, and motion."
            },
            "slug": "A-Region-Merging-Prior-for-Variational-Level-Set-Ayed-Mitiche",
            "title": {
                "fragments": [],
                "text": "A Region Merging Prior for Variational Level Set Image Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "This study investigates a region merging prior related to regions area to allow the number of regions to vary automatically during curve evolution, thereby optimizing the objective functional implicitly with respect to thenumber of regions."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Image Processing"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2238841"
                        ],
                        "name": "Stan Birchfield",
                        "slug": "Stan-Birchfield",
                        "structuredName": {
                            "firstName": "Stan",
                            "lastName": "Birchfield",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stan Birchfield"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086151"
                        ],
                        "name": "Carlo Tomasi",
                        "slug": "Carlo-Tomasi",
                        "structuredName": {
                            "firstName": "Carlo",
                            "lastName": "Tomasi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carlo Tomasi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 134
                            }
                        ],
                        "text": "Other geometric model fitting works have used separate elements such as random sampling [25, 19] (as in RANSAC) or EM-style iteration [2], but none have combined them in a single optimization framework."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 112
                            }
                        ],
                        "text": "In other settings (segmentation, stereo) these elements have been combined in various application-specific ways [28, 2, 22, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7574259,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d7c9c05380a6b3dc244bf8c98717824142257e67",
            "isKey": false,
            "numCitedBy": 265,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Slanted surfaces pose a problem for correspondence algorithms utilizing search because of the greatly increased number of possibilities, when compared with fronto-parallel surfaces. In this paper we propose an algorithm to compute correspondence between stereo images or between frames of a motion sequence by minimizing an energy functional that accounts for slanted surfaces. The energy is minimized in a greedy strategy that alternates between segmenting the image into a number of non-overlapping regions (using the multiway-cut algorithm of Boykov, Veksler, and Zabih) and finding the affine parameters describing the displacement function of each region. A follow-up step enables the algorithm to escape local minima due to oversegmentation. Experiments on real images show the algorithm's ability to find an accurate segmentation and displacement map, as well as discontinuities and creases, from a wide variety of stereo and motion imagery."
            },
            "slug": "Multiway-cut-for-stereo-and-motion-with-slanted-Birchfield-Tomasi",
            "title": {
                "fragments": [],
                "text": "Multiway cut for stereo and motion with slanted surfaces"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "An algorithm to compute correspondence between stereo images or between frames of a motion sequence is proposed by minimizing an energy functional that accounts for slanted surfaces by segmenting the image into a number of non-overlapping regions."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145380991"
                        ],
                        "name": "Song-Chun Zhu",
                        "slug": "Song-Chun-Zhu",
                        "structuredName": {
                            "firstName": "Song-Chun",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song-Chun Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081362"
                        ],
                        "name": "A. Yuille",
                        "slug": "A.-Yuille",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Yuille",
                            "middleNames": [
                                "Loddon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yuille"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 112
                            }
                        ],
                        "text": "In other settings (segmentation, stereo) these elements have been combined in various application-specific ways [28, 2, 22, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "For segmentation, our energy is closer to Zhu & Yuille [28] but our algorithm is more powerful than region-competition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 75
                            }
                        ],
                        "text": "Our energy (?) balances these criteria (c) and corresponds to Zhu & Yuille [28] for segmentation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 44
                            }
                        ],
                        "text": "\u2032) can implement a discrete version of Zhu & Yuille\u2019s energy."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 92
                            }
                        ],
                        "text": "Initial proposals were generated by sampling small patches of the input image, just like in [28, 27]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 83
                            }
                        ],
                        "text": "The MDL principle was first proposed for unsupervised segmentation by Zhu & Yuille [28], along with their region competition algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 35561340,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "73bd5c30eb274671c30b8f7222b5e4b03a915a62",
            "isKey": true,
            "numCitedBy": 2286,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel statistical and variational approach to image segmentation based on a new algorithm, named region competition. This algorithm is derived by minimizing a generalized Bayes/minimum description length (MDL) criterion using the variational principle. The algorithm is guaranteed to converge to a local minimum and combines aspects of snakes/balloons and region growing. The classic snakes/balloons and region growing algorithms can be directly derived from our approach. We provide theoretical analysis of region competition including accuracy of boundary location, criteria for initial conditions, and the relationship to edge detection using filters. It is straightforward to generalize the algorithm to multiband segmentation and we demonstrate it on gray level images, color images and texture images. The novel color model allows us to eliminate intensity gradients and shadows, thereby obtaining segmentation based on the albedos of objects. It also helps detect highlight regions."
            },
            "slug": "Region-Competition:-Unifying-Snakes,-Region-and-for-Zhu-Yuille",
            "title": {
                "fragments": [],
                "text": "Region Competition: Unifying Snakes, Region Growing, and Bayes/MDL for Multiband Image Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A novel statistical and variational approach to image segmentation based on a new algorithm, named region competition, derived by minimizing a generalized Bayes/minimum description length (MDL) criterion using the variational principle is presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2465976"
                        ],
                        "name": "M. Fischler",
                        "slug": "M.-Fischler",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Fischler",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fischler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764443"
                        ],
                        "name": "R. Bolles",
                        "slug": "R.-Bolles",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Bolles",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bolles"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 104
                            }
                        ],
                        "text": "Other geometric model fitting works have used separate elements such as random sampling [25, 19] (as in RANSAC) or EM-style iteration [2], but none have combined them in a single optimization framework."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 142
                            }
                        ],
                        "text": "Each proposal is generated by a randomly sampling the smallest subset of data points needed to define a geometric model, exactly as in RANSAC [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 233,
                                "start": 227
                            }
                        ],
                        "text": "Below we review a technique to effectively explore the continuum of model parameters by working with a finite subset of models at any given iteration t.\nPEARL Algorithm [13]\n1 propose initial models L0 by random samples (as in RANSAC) 2 run \u03b1-expansion to compute optimal labeling f w.r.t. Lt 3 re-estimate model parameters to get Lt+1; t := t+1; goto 2\nPEARL was the first to use regularization energies and EM-style optimization for geometric multi-model fitting."
                    },
                    "intents": []
                }
            ],
            "corpusId": 972888,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "278c9a78d4505cfaf6b709df364dbd1206a017c1",
            "isKey": false,
            "numCitedBy": 15959,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A new paradigm, Random Sample Consensus (RANSAC), for fitting a model to experimental data is introduced. RANSAC is capable of interpreting/smoothing data containing a significant percentage of gross errors, and is thus ideally suited for applications in automated image analysis where interpretation is based on the data provided by error-prone feature detectors. A major portion of this paper describes the application of RANSAC to the Location Determination Problem (LDP): Given an image depicting a set of landmarks with known locations, determine that point in space from which the image was obtained. In response to a RANSAC requirement, new results are derived on the minimum number of landmarks needed to obtain a solution, and algorithms are presented for computing these minimum-landmark solutions in closed form. These results provide the basis for an automatic system that can solve the LDP under difficult viewing"
            },
            "slug": "Random-sample-consensus:-a-paradigm-for-model-with-Fischler-Bolles",
            "title": {
                "fragments": [],
                "text": "Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "New results are derived on the minimum number of landmarks needed to obtain a solution, and algorithms are presented for computing these minimum-landmark solutions in closed form that provide the basis for an automatic system that can solve the Location Determination Problem under difficult viewing."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710872"
                        ],
                        "name": "T. Brox",
                        "slug": "T.-Brox",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Brox",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Brox"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7789445"
                        ],
                        "name": "J. Weickert",
                        "slug": "J.-Weickert",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Weickert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weickert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16256470,
            "fieldsOfStudy": [
                "Business",
                "Computer Science"
            ],
            "id": "b46f162d0a2b69ce77fcd80a3ddf2df0ba432314",
            "isKey": false,
            "numCitedBy": 118,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the difficulty of image segmentation methods based on the popular level set framework to handle an arbitrary number of regions. While in the literature some level set techniques are available that can at least deal with a fixed amount of regions greater than two, there is very few work on how to optimise the segmentation also with regard to the number of regions. Based on a variational model, we propose a minimisation strategy that robustly optimises the energy in a level set framework, including the number of regions. Our evaluation shows that very good segmentations are found even in difficult situations."
            },
            "slug": "Level-Set-Based-Image-Segmentation-with-Multiple-Brox-Weickert",
            "title": {
                "fragments": [],
                "text": "Level Set Based Image Segmentation with Multiple Regions"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work proposes a minimisation strategy that robustly optimises the energy in a level set framework, including the number of regions, based on a variational model and shows that very good segmentations are found even in difficult situations."
            },
            "venue": {
                "fragments": [],
                "text": "DAGM-Symposium"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692688"
                        ],
                        "name": "Yuri Boykov",
                        "slug": "Yuri-Boykov",
                        "structuredName": {
                            "firstName": "Yuri",
                            "lastName": "Boykov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuri Boykov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144653004"
                        ],
                        "name": "V. Kolmogorov",
                        "slug": "V.-Kolmogorov",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Kolmogorov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Kolmogorov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3096531,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "4f32d8245ba8ec0e6dd3d14830a26a66c0c9d1d9",
            "isKey": false,
            "numCitedBy": 665,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Geodesic active contours and graph cuts are two standard image segmentation techniques. We introduce a new segmentation method combining some of their benefits. Our main intuition is that any cut on a graph embedded in some continuous space can be interpreted as a contour (in 2D) or a surface (in 3D). We show how to build a grid graph and set its edge weights so that the cost of cuts is arbitrarily close to the length (area) of the corresponding contours (surfaces) for any anisotropic Riemannian metric. There are two interesting consequences of this technical result. First, graph cut algorithms can be used to find globally minimum geodesic contours (minimal surfaces in 3D) under arbitrary Riemannian metric for a given set of boundary conditions. Second, we show how to minimize metrication artifacts in existing graph-cut based methods in vision. Theoretically speaking, our work provides an interesting link between several branches of mathematics -differential geometry, integral geometry, and combinatorial optimization. The main technical problem is solved using Cauchy-Crofton formula from integral geometry."
            },
            "slug": "Computing-geodesics-and-minimal-surfaces-via-graph-Boykov-Kolmogorov",
            "title": {
                "fragments": [],
                "text": "Computing geodesics and minimal surfaces via graph cuts"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work shows how to build a grid graph and set its edge weights so that the cost of cuts is arbitrarily close to the length (area) of the corresponding contours (surfaces) for any anisotropic Riemannian metric."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33652486"
                        ],
                        "name": "J. Winn",
                        "slug": "J.-Winn",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Winn",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Winn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143774737"
                        ],
                        "name": "J. Shotton",
                        "slug": "J.-Shotton",
                        "structuredName": {
                            "firstName": "Jamie",
                            "lastName": "Shotton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shotton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 120
                            }
                        ],
                        "text": "Their paper was about supervised part-based object recognition, an extension of the 2D LayoutCRF work by Winn & Shotton [38]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11200969,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9e6771a0eeaf95a9400e4fc94911d258983ffe9",
            "isKey": false,
            "numCitedBy": 312,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of detecting and segmenting partially occluded objects of a known category. We first define a part labelling which densely covers the object. Our Layout Consistent Random Field (LayoutCRF) model then imposes asymmetric local spatial constraints on these labels to ensure the consistent layout of parts whilst allowing for object deformation. Arbitrary occlusions of the object are handled by avoiding the assumption that the whole object is visible. The resulting system is both efficient to train and to apply to novel images, due to a novel annealed layout-consistent expansion move algorithm paired with a randomised decision tree classifier. We apply our technique to images of cars and faces and demonstrate state-of-the-art detection and segmentation performance even in the presence of partial occlusion."
            },
            "slug": "The-Layout-Consistent-Random-Field-for-Recognizing-Winn-Shotton",
            "title": {
                "fragments": [],
                "text": "The Layout Consistent Random Field for Recognizing and Segmenting Partially Occluded Objects"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "This paper addresses the problem of detecting and segmenting partially occluded objects of a known category by defining a part labelling which densely covers the object and imposing asymmetric local spatial constraints on these labels to ensure the consistent layout of parts whilst allowing for object deformation."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433269"
                        ],
                        "name": "Derek Hoiem",
                        "slug": "Derek-Hoiem",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Hoiem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Hoiem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756036"
                        ],
                        "name": "C. Rother",
                        "slug": "C.-Rother",
                        "structuredName": {
                            "firstName": "Carsten",
                            "lastName": "Rother",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rother"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33652486"
                        ],
                        "name": "J. Winn",
                        "slug": "J.-Winn",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Winn",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Winn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 244,
                                "start": 225
                            }
                        ],
                        "text": "For example, we learned from personal correspondence that John Winn developed an extension of \u03b1-expansion to instance cost potentials in 2004 that only appeared as part of a supervised part-based object recognition framework (Hoiem et al. 2007), though his approach to deriving an algorithm is quite different from ours."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1217,
                                "start": 83
                            }
                        ],
                        "text": "The result in (b) uses only spatial regularization as in energy (2), see Zabih and Kolmogorov (2004). This approach over-smoothes the segments even when the weight of the regularization term is too small to merge all \u201czebra\u201d parts. The label costs term in (37) allows to obtain \u201czebra\u201d (c) without over-smoothing. In this case we do not depend on the spatial regularization to merge all \u201czebra\u201d parts and smoothing weight \u03bb can be significantly reduced. The label costs term in (37) could be used to obtain segments with certain preferred appearance by assigning penalties hl depending on Ml . Also note that a general version of our label costs term in ( ) uses subsets of labels. This allows interesting new ideas for segmentation, as recently demonstrated in Ladick\u00fd et al. (2010) in the context of object recognition. It should be emphasized that we are not first to suggest energies with label costs for segmentation. A large amount of related work on image segmentation is based on minimum description length (MDL) principle (MacKay 2003) which provides information theoretic foundation for regularization energies like (37). The MDL principle was first proposed for unsupervised segmentation by Leclerc (1989). As further detailed in our Sect."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 784,
                                "start": 83
                            }
                        ],
                        "text": "The result in (b) uses only spatial regularization as in energy (2), see Zabih and Kolmogorov (2004). This approach over-smoothes the segments even when the weight of the regularization term is too small to merge all \u201czebra\u201d parts. The label costs term in (37) allows to obtain \u201czebra\u201d (c) without over-smoothing. In this case we do not depend on the spatial regularization to merge all \u201czebra\u201d parts and smoothing weight \u03bb can be significantly reduced. The label costs term in (37) could be used to obtain segments with certain preferred appearance by assigning penalties hl depending on Ml . Also note that a general version of our label costs term in ( ) uses subsets of labels. This allows interesting new ideas for segmentation, as recently demonstrated in Ladick\u00fd et al. (2010) in the context of object recognition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 111
                            }
                        ],
                        "text": "Review of PEARL for ( ) For simplicity, we will discuss PEARL in the context of geometric model fitting, as in Isack and Boykov (2011). Figure 6 illustrates the algorithm\u2019s progression."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 13
                            }
                        ],
                        "text": "For example, Isack and Boykov (2011) uses basic \u03b1expansion (Boykov et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 83
                            }
                        ],
                        "text": "The result in (b) uses only spatial regularization as in energy (2), see Zabih and Kolmogorov (2004). This approach over-smoothes the segments even when the weight of the regularization term is too small to merge all \u201czebra\u201d parts."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1348,
                                "start": 83
                            }
                        ],
                        "text": "The result in (b) uses only spatial regularization as in energy (2), see Zabih and Kolmogorov (2004). This approach over-smoothes the segments even when the weight of the regularization term is too small to merge all \u201czebra\u201d parts. The label costs term in (37) allows to obtain \u201czebra\u201d (c) without over-smoothing. In this case we do not depend on the spatial regularization to merge all \u201czebra\u201d parts and smoothing weight \u03bb can be significantly reduced. The label costs term in (37) could be used to obtain segments with certain preferred appearance by assigning penalties hl depending on Ml . Also note that a general version of our label costs term in ( ) uses subsets of labels. This allows interesting new ideas for segmentation, as recently demonstrated in Ladick\u00fd et al. (2010) in the context of object recognition. It should be emphasized that we are not first to suggest energies with label costs for segmentation. A large amount of related work on image segmentation is based on minimum description length (MDL) principle (MacKay 2003) which provides information theoretic foundation for regularization energies like (37). The MDL principle was first proposed for unsupervised segmentation by Leclerc (1989). As further detailed in our Sect. 5.3.1 on lossless compression, specific technical realization of MDL principle in Leclerc (1989) is distinct from ours."
                    },
                    "intents": []
                }
            ],
            "corpusId": 9759858,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de8342ac47c8989032dd7e906e9cbd51eab12e3c",
            "isKey": true,
            "numCitedBy": 157,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce an approach to accurately detect and segment partially occluded objects in various viewpoints and scales. Our main contribution is a novel framework for combining object-level descriptions (such as position, shape, and color) with pixel-level appearance, boundary, and occlusion reasoning. In training, we exploit a rough 3D object model to learn physically localized part appearances. To find and segment objects in an image, we generate proposals based on the appearance and layout of local parts. The proposals are then refined after incorporating object-level information, and overlapping objects compete for pixels to produce a final description and segmentation of objects in the scene. A further contribution is a novel instance penalty, which is handled very efficiently during inference. We experimentally validate our approach on the challenging PASCAL'06 car database."
            },
            "slug": "3D-LayoutCRF-for-Multi-View-Object-Class-and-Hoiem-Rother",
            "title": {
                "fragments": [],
                "text": "3D LayoutCRF for Multi-View Object Class Recognition and Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "An approach to accurately detect and segment partially occluded objects in various viewpoints and scales is introduced and a novel framework for combining object-level descriptions with pixel-level appearance, boundary, and occlusion reasoning is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685020"
                        ],
                        "name": "D. Comaniciu",
                        "slug": "D.-Comaniciu",
                        "structuredName": {
                            "firstName": "Dorin",
                            "lastName": "Comaniciu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Comaniciu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145776090"
                        ],
                        "name": "P. Meer",
                        "slug": "P.-Meer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Meer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Meer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Clustering of image pixels represented by points (p, Ip) in X \u00d7Y \u00d7Color space was popularized for image segmentation by the meanshift algorithm ( Comaniciu and Meer 2002 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 691081,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74f4ecc3e4e5b91fbb54330b285ed5214afe2001",
            "isKey": false,
            "numCitedBy": 11481,
            "numCiting": 122,
            "paperAbstract": {
                "fragments": [],
                "text": "A general non-parametric technique is proposed for the analysis of a complex multimodal feature space and to delineate arbitrarily shaped clusters in it. The basic computational module of the technique is an old pattern recognition procedure: the mean shift. For discrete data, we prove the convergence of a recursive mean shift procedure to the nearest stationary point of the underlying density function and, thus, its utility in detecting the modes of the density. The relation of the mean shift procedure to the Nadaraya-Watson estimator from kernel regression and the robust M-estimators; of location is also established. Algorithms for two low-level vision tasks discontinuity-preserving smoothing and image segmentation - are described as applications. In these algorithms, the only user-set parameter is the resolution of the analysis, and either gray-level or color images are accepted as input. Extensive experimental results illustrate their excellent performance."
            },
            "slug": "Mean-Shift:-A-Robust-Approach-Toward-Feature-Space-Comaniciu-Meer",
            "title": {
                "fragments": [],
                "text": "Mean Shift: A Robust Approach Toward Feature Space Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is proved the convergence of a recursive mean shift procedure to the nearest stationary point of the underlying density function and, thus, its utility in detecting the modes of the density."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076198688"
                        ],
                        "name": "Y. G. Leclerc",
                        "slug": "Y.-G.-Leclerc",
                        "structuredName": {
                            "firstName": "Yvan",
                            "lastName": "Leclerc",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. G. Leclerc"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Note that separate merging steps for minimizing MDL-based functionals like (\ufffd )w ere also used in  Leclerc (1989) , Zhu and Yuille (1996) in the context of continuation methods and variational approaches."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Regularization combining smoothness and label costs has a long history in vision going back to well known papers by  Leclerc (1989) , Zhu and Yuille (1996), and many others."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Further more, to simplify optimization ( Leclerc 1989 ) makes approximations, e.g."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The MDL principle was first proposed for unsupervised segmentation by  Leclerc (1989) ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Geman and Geman 1984;  Leclerc 1989;  Kolmogorov 2006) or their modifications, our empirical evaluation is focused on graph cut methods that we consider more promising due to optimality guarantees associated with them."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "5.3.1 on lossless compression, specific technical realization of MDL principle in  Leclerc (1989 ) i s distinct from ours."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "On a conceptual level, we follow the same MDL principle as  Leclerc (1989) ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "However, our descriptive language is different and it leads to energies distinct from those in  Leclerc (1989) ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2949354,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "01e5d824826515e5ae0fd69031e0d1c19abe8079",
            "isKey": true,
            "numCitedBy": 345,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "A new formulation of the image partitioning problem is presented: construct a complete and stable description of an image-in terms of a specified descriptive language-that is simplest in the sense of being shortest. We show that a descriptive language limited to a low-order polynomial description of the intensity variation within each region and a chain-code-like description of the region boundaries yields intuitively satisfying partitions for a wide class of images.The advantage of this formulation is that it can be extended to deal with subsequent steps of the image understanding problem (or to deal with other attributes, such as texture) in a natural way by augmenting the descriptive language. Experiments performed on a variety of both real and synthetic images demonstrate the superior performance of this approach over partitioning techniques based on clustering vectors of local image attributes and standard edge-detection techniques."
            },
            "slug": "Constructing-simple-stable-descriptions-for-image-Leclerc",
            "title": {
                "fragments": [],
                "text": "Constructing simple stable descriptions for image partitioning"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "A new formulation of the image partitioning problem is presented: construct a complete and stable description of an image-in terms of a specified descriptive language-that is simplest in the sense of being shortest, which yields intuitively satisfying partitions for a wide class of images."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3371403"
                        ],
                        "name": "J. Kleinberg",
                        "slug": "J.-Kleinberg",
                        "structuredName": {
                            "firstName": "Jon",
                            "lastName": "Kleinberg",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kleinberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746222"
                        ],
                        "name": "\u00c9. Tardos",
                        "slug": "\u00c9.-Tardos",
                        "structuredName": {
                            "firstName": "\u00c9va",
                            "lastName": "Tardos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00c9. Tardos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "If each Vpq defines a metric, then minimizing (2) is known as the metric labeling problem (Boykov et al. 2001;  Kleinberg and Tardos 2002 ) and can be optimized effectively with the \u03b1-expansion algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16241328,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "a3b3aad58ecc6aed599c7567d4fe07ad3480a866",
            "isKey": false,
            "numCitedBy": 378,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "In a traditional classification problem, we wish to assign one of k labels (or classes) to each of n objects, in a way that is consistent with some observed data that we have about the problem. An active line of research in this area is concerned with classification when one has information about pairwise relationships among the objects to be classified; this issue is one of the principal motivations for the framework of Markov random fields, and it arises in areas such as image processing, biometry: and document analysis. In its most basic form, this style of analysis seeks a classification that optimizes a combinatorial function consisting of assignment costs-based on the individual choice of label we make for each object-and separation costs-based on the pair of choices we make for two \"related\" objects. We formulate a general classification problem of this type, the metric labeling problem; we show that it contains as special cases a number of standard classification frameworks, including several arising from the theory of Markov random fields. From the perspective of combinatorial optimization, our problem can be viewed as a substantial generalization of the multiway cut problem, and equivalent to a type of uncapacitated quadratic assignment problem. We provide the first non-trivial polynomial-time approximation algorithms for a general family of classification problems of this type. Our main result is an O(log k log log k)-approximation algorithm for the metric labeling problem, with respect to an arbitrary metric on a set of k labels, and an arbitrary weighted graph of relationships on a set of objects. For the special case in which the labels are endowed with the uniform metric-all distances are the same-our methods provide a 2-approximation."
            },
            "slug": "Approximation-algorithms-for-classification-with-Kleinberg-Tardos",
            "title": {
                "fragments": [],
                "text": "Approximation algorithms for classification problems with pairwise relationships: metric labeling and Markov random fields"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work provides the first non-trivial polynomial-time approximation algorithms for a general family of classification problems of this type, the metric labeling problem, and shows that it contains as special cases a number of standard classification frameworks, including several arising from the theory of Markov random fields."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145091933"
                        ],
                        "name": "D. Freedman",
                        "slug": "D.-Freedman",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Freedman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Freedman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738441"
                        ],
                        "name": "P. Drineas",
                        "slug": "P.-Drineas",
                        "structuredName": {
                            "firstName": "Petros",
                            "lastName": "Drineas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Drineas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 21
                            }
                        ],
                        "text": "Freedman and Drineas [10] generalized the graph construction of [16] to handle terms c \u220f pxp of arbitrary degree when c \u2264 0."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 0
                            }
                        ],
                        "text": "Freedman and Drineas [10] generalized the graph construction of [16] to handle terms c \u220f\npxp of arbitrary degree when c \u2264 0."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7556238,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c5284a9631062378ebdf52b24bb26933cfa65e47",
            "isKey": false,
            "numCitedBy": 171,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "The recent explosion of interest in graph cut methods in computer vision naturally spawns the question: what energy functions can be minimized via graph cuts? This question was first attacked by two papers of Kolmogorov and Zabih, in which they dealt with functions with pair-wise and triplewise pixel interactions. In this work, we extend their results in two directions. First, we examine the case of k-wise pixel interactions; the results are derived from a purely algebraic approach. Second, we discuss the applicability of provably approximate algorithms. Both of these developments should help researchers best understand what can and cannot be achieved when designing graph cut based algorithms."
            },
            "slug": "Energy-minimization-via-graph-cuts:-settling-what-Freedman-Drineas",
            "title": {
                "fragments": [],
                "text": "Energy minimization via graph cuts: settling what is possible"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "First, the case of k-wise pixel interactions is examined; the results are derived from a purely algebraic approach; second, the applicability of provably approximate algorithms are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2091934"
                        ],
                        "name": "Roberto Tron",
                        "slug": "Roberto-Tron",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Tron",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roberto Tron"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144020730"
                        ],
                        "name": "R. Vidal",
                        "slug": "R.-Vidal",
                        "structuredName": {
                            "firstName": "Ren\u00e9",
                            "lastName": "Vidal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Vidal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 54
                            }
                        ],
                        "text": "21 Rigid motion estimation examples (Vidal\u2019s data set [56]) comparing different algorithms minimizing energy (?): \u03b1++, \u03b1+, \u03b1-SM, \u03b1-BM."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 46
                            }
                        ],
                        "text": "1 Motion segmentation on the 1RT2RCR sequence [56]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 186
                            }
                        ],
                        "text": "Our work on these algorithms was inspired by an array of generic modelfitting applications in vision that benefit from label costs: geometric model fitting [55], rigid motion estimation [42,56], MDL-based segmentation [63], finite mixture models [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9381082,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "22effe373836d4feae2ce3e8abec0058438bebb9",
            "isKey": true,
            "numCitedBy": 694,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Over the past few years, several methods for segmenting a scene containing multiple rigidly moving objects have been proposed. However, most existing methods have been tested on a handful of sequences only, and each method has been often tested on a different set of sequences. Therefore, the comparison of different methods has been fairly limited. In this paper, we compare four 3D motion segmentation algorithms for affine cameras on a benchmark of 155 motion sequences of checkerboard, traffic, and articulated scenes."
            },
            "slug": "A-Benchmark-for-the-Comparison-of-3-D-Motion-Tron-Vidal",
            "title": {
                "fragments": [],
                "text": "A Benchmark for the Comparison of 3-D Motion Segmentation Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper compares four 3D motion segmentation algorithms for affine cameras on a benchmark of 155 motion sequences of checkerboard, traffic, and articulated scenes."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3194361"
                        ],
                        "name": "S. Geman",
                        "slug": "S.-Geman",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Geman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707642"
                        ],
                        "name": "D. Geman",
                        "slug": "D.-Geman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Geman and Geman 1984;  Leclerc 1989; Kolmogorov 2006) or their modifications, our empirical evaluation is focused on graph cut methods that we consider more promising due to optimality guarantees associated with them."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5837272,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "459b30a9a960080f3b313e41886b1aa0e51e882c",
            "isKey": false,
            "numCitedBy": 18710,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "We make an analogy between images and statistical mechanics systems. Pixel gray levels and the presence and orientation of edges are viewed as states of atoms or molecules in a lattice-like physical system. The assignment of an energy function in the physical system determines its Gibbs distribution. Because of the Gibbs distribution, Markov random field (MRF) equivalence, this assignment also determines an MRF image model. The energy function is a more convenient and natural mechanism for embodying picture attributes than are the local characteristics of the MRF. For a range of degradation mechanisms, including blurring, nonlinear deformations, and multiplicative or additive noise, the posterior distribution is an MRF with a structure akin to the image model. By the analogy, the posterior distribution defines another (imaginary) physical system. Gradual temperature reduction in the physical system isolates low energy states (``annealing''), or what is the same thing, the most probable states under the Gibbs distribution. The analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations. The result is a highly parallel ``relaxation'' algorithm for MAP estimation. We establish convergence properties of the algorithm and we experiment with some simple pictures, for which good restorations are obtained at low signal-to-noise ratios."
            },
            "slug": "Stochastic-Relaxation,-Gibbs-Distributions,-and-the-Geman-Geman",
            "title": {
                "fragments": [],
                "text": "Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "The analogy between images and statistical mechanics systems is made and the analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations, creating a highly parallel ``relaxation'' algorithm for MAP estimation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765700"
                        ],
                        "name": "Ioannis Tsochantaridis",
                        "slug": "Ioannis-Tsochantaridis",
                        "structuredName": {
                            "firstName": "Ioannis",
                            "lastName": "Tsochantaridis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ioannis Tsochantaridis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143936663"
                        ],
                        "name": "Thomas Hofmann",
                        "slug": "Thomas-Hofmann",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Hofmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Hofmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783941"
                        ],
                        "name": "Y. Altun",
                        "slug": "Y.-Altun",
                        "structuredName": {
                            "firstName": "Yasemin",
                            "lastName": "Altun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Altun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The label cost terms are included in energy (\ufffd ) linearly and can thus be learned by max-margin methods (Taskar et al. 2004;  Tsochantaridis et al. 2006 )."
                    },
                    "intents": []
                }
            ],
            "corpusId": 17671150,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc97e7dbb821a4edfb5151bff4352655eedca9ee",
            "isKey": false,
            "numCitedBy": 2247,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning general functional dependencies between arbitrary input and output spaces is one of the key challenges in computational intelligence. While recent progress in machine learning has mainly focused on designing flexible and powerful input representations, this paper addresses the complementary issue of designing classification algorithms that can deal with more complex outputs, such as trees, sequences, or sets. More generally, we consider problems involving multiple dependent output variables, structured output spaces, and classification problems with class attributes. In order to accomplish this, we propose to appropriately generalize the well-known notion of a separation margin and derive a corresponding maximum-margin formulation. While this leads to a quadratic program with a potentially prohibitive, i.e. exponential, number of constraints, we present a cutting plane algorithm that solves the optimization problem in polynomial time for a large class of problems. The proposed method has important applications in areas such as computational biology, natural language processing, information retrieval/extraction, and optical character recognition. Experiments from various domains involving different types of output spaces emphasize the breadth and generality of our approach."
            },
            "slug": "Large-Margin-Methods-for-Structured-and-Output-Tsochantaridis-Joachims",
            "title": {
                "fragments": [],
                "text": "Large Margin Methods for Structured and Interdependent Output Variables"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper proposes to appropriately generalize the well-known notion of a separation margin and derive a corresponding maximum-margin formulation and presents a cutting plane algorithm that solves the optimization problem in polynomial time for a large class of problems."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145029825"
                        ],
                        "name": "Antonio Ortega",
                        "slug": "Antonio-Ortega",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Ortega",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antonio Ortega"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144161012"
                        ],
                        "name": "K. Ramchandran",
                        "slug": "K.-Ramchandran",
                        "structuredName": {
                            "firstName": "Kannan",
                            "lastName": "Ramchandran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Ramchandran"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We generalize ideas from the previous section to further illustrate applications for label costs functionals like (\ufffd ). This section follows Shannon\u2019s rate-distortion (RD) optimization approach to lossy image compression, see Gersho and Gray (2001),  Ortega and Ramchandran (1998) ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15599745,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce020a1d9b3fa027563a046075da4f9e7c880f18",
            "isKey": false,
            "numCitedBy": 872,
            "numCiting": 148,
            "paperAbstract": {
                "fragments": [],
                "text": "In this article we provide an overview of rate-distortion (R-D) based optimization techniques and their practical application to image and video coding. We begin with a short discussion of classical rate-distortion theory and then we show how in many practical coding scenarios, such as in standards-compliant coding environments, resource allocation can be put in an R-D framework. We then introduce two popular techniques for resource allocation, namely, Lagrangian optimization and dynamic programming. After a discussion of these techniques as well as some of their extensions, we conclude with a quick review of literature in these areas citing a number of applications related to image and video compression and transmission."
            },
            "slug": "Rate-distortion-methods-for-image-and-video-Ortega-Ramchandran",
            "title": {
                "fragments": [],
                "text": "Rate-distortion methods for image and video compression"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "An overview of rate-distortion (R-D) based optimization techniques and their practical application to image and video coding is provided and two popular techniques for resource allocation are introduced, namely, Lagrangian optimization and dynamic programming."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Signal Process. Mag."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145878635"
                        ],
                        "name": "Tom\u00e1\u0161 Werner",
                        "slug": "Tom\u00e1\u0161-Werner",
                        "structuredName": {
                            "firstName": "Tom\u00e1\u0161",
                            "lastName": "Werner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom\u00e1\u0161 Werner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7682719,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "448a9af2fe594494f9e2f8fb12088a1a69ecb36a",
            "isKey": false,
            "numCitedBy": 109,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "LP relaxation approach to soft constraint optimisation (i.e. MAP-MRF) has been mostly considered only for binary problems. We present its generalisation to n-ary problems, including a simple algorithm to optimise the LP bound, n-ary max-sum diffusion. As applications, we show that a hierarchy of gradually tighter polyhedral relaxations of MAP-MRF is obtained by adding zero interactions. We propose a cutting plane algorithm, where cuts correspond to adding zero interactions and the separation problem to finding an unsatisfiable constraint satisfaction subproblem. Next, we show that certain high-arity interactions, e.g. certain global constraints, can be included into the framework in a principled way. Finally, we prove that n-ary max-sum diffusion finds global optimum for n-ary supermodular problems."
            },
            "slug": "High-arity-interactions,-polyhedral-relaxations,-Werner",
            "title": {
                "fragments": [],
                "text": "High-arity interactions, polyhedral relaxations, and cutting plane algorithm for soft constraint optimisation (MAP-MRF)"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that certain high-arity interactions, e.g. certain global constraints, can be included into the framework in a principled way and it is proved that n-ary max-sum diffusion finds global optimum for n-ARY supermodular problems."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1735221"
                        ],
                        "name": "N. Ueda",
                        "slug": "N.-Ueda",
                        "structuredName": {
                            "firstName": "Naonori",
                            "lastName": "Ueda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ueda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763517"
                        ],
                        "name": "R. Nakano",
                        "slug": "R.-Nakano",
                        "structuredName": {
                            "firstName": "Ryohei",
                            "lastName": "Nakano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nakano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744700"
                        ],
                        "name": "Zoubin Ghahramani",
                        "slug": "Zoubin-Ghahramani",
                        "structuredName": {
                            "firstName": "Zoubin",
                            "lastName": "Ghahramani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zoubin Ghahramani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Another general heuristic is to fit a new model to the inliers of two existing models, and then add this new model to the candidate list; this \u2018merge\u2019 heuristic ( Ueda et al. 2000 ) gives energy (\ufffd \ufffd ) an opportunity to jump out of"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8382117,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a88f04ee3dd09c2a753685cb70f7e43d478aab82",
            "isKey": false,
            "numCitedBy": 441,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a split-and-merge expectation-maximization (SMEM) algorithm to overcome the local maxima problem in parameter estimation of finite mixture models. In the case of mixture models, local maxima often involve having too many components of a mixture model in one part of the space and too few in another, widely separated part of the space. To escape from such configurations, we repeatedly perform simultaneous split-and-merge operations using a new criterion for efficiently selecting the split-and-merge candidates. We apply the proposed algorithm to the training of gaussian mixtures and mixtures of factor analyzers using synthetic and real data and show the effectiveness of using the split- and-merge operations to improve the likelihood of both the training data and of held-out test data. We also show the practical usefulness of the proposed algorithm by applying it to image compression and pattern recognition problems."
            },
            "slug": "SMEM-Algorithm-for-Mixture-Models-Ueda-Nakano",
            "title": {
                "fragments": [],
                "text": "SMEM Algorithm for Mixture Models"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A split-and-merge expectation-maximization algorithm to overcome the local maxima problem in parameter estimation of finite mixture models and is applied to the training of gaussian mixtures and mixtures of factor analyzers and shows the practical usefulness by applying it to image compression and pattern recognition problems."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143635539"
                        ],
                        "name": "P. Torr",
                        "slug": "P.-Torr",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Torr",
                            "middleNames": [
                                "H.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Torr"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 88
                            }
                        ],
                        "text": "Other geometric model fitting works have used separate elements such as random sampling [25, 19] (as in RANSAC) or EM-style iteration [2], but none have combined them in a single optimization framework."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 90
                            }
                        ],
                        "text": "See [5] for an intuitive discussion and derivation of BIC in general, and see Torr\u2019s work [25] for insights specific to vision."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 42
                            }
                        ],
                        "text": "This criterion was also discussed by Torr [25] and Li [19] in the context of motion estimation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 91496181,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aa1317300c2c9a02bb400fe01827d95241ccca62",
            "isKey": false,
            "numCitedBy": 320,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Motion segmentation involves clustering features together that belong to independently moving objects. The image features on each of these objects conform to one of several putative motion models, but the number and type of motion is unknown a priori. In order to cluster these features, the problems of model selection, robust estimation and clustering must all be addressed simultaneously. Within this paper we place the three problems into a common statistical framework; investigating the use of information criteria and robust mixture models as a principled way for motion segmentation of images. The final result is a general fully automatic algorithm for clustering that works in the presence of noise and outliers."
            },
            "slug": "Geometric-motion-segmentation-and-model-selection-Torr",
            "title": {
                "fragments": [],
                "text": "Geometric motion segmentation and model selection"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper places the problems of model selection, robust estimation and clustering into a common statistical framework; investigating the use of information criteria and robust mixture models as a principled way for motion segmentation of images."
            },
            "venue": {
                "fragments": [],
                "text": "Philosophical Transactions of the Royal Society of London. Series A: Mathematical, Physical and Engineering Sciences"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34659351"
                        ],
                        "name": "M\u00e1rio A. T. Figueiredo",
                        "slug": "M\u00e1rio-A.-T.-Figueiredo",
                        "structuredName": {
                            "firstName": "M\u00e1rio",
                            "lastName": "Figueiredo",
                            "middleNames": [
                                "A.",
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M\u00e1rio A. T. Figueiredo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "As discussed in  Figueiredo and Jain (2002) , one can use \u03b1 Figueiredo and Jain (2002) , we solve this problem in the following way."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Note that our EM implementation for posterior (20) is similar to the EM algorithm in  Figueiredo and Jain (2002) ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This approach to minimizing (20) is robust to initialization and avoids local minima ( Figueiredo and Jain 2002 )."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "As discussed in  Figueiredo and Jain (2002) , this makes EM robust to initialization and helps to avoid local minima."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Similarly to  Figueiredo and Jain (2002)  and to our EM approach for (20), optimization of (30 )v iaPEARL avoids local minima when initialized with a large set of randomly sampled models."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "According to  Figueiredo and Jain (2002)  and in our own experience (see Fig. 12), negative values of \u03b1 are often necessary in practice to effectively remove redundant models."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4034894,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a67d2d9a318736560977a374c9a23d4dcf395f2b",
            "isKey": true,
            "numCitedBy": 2188,
            "numCiting": 95,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes an unsupervised algorithm for learning a finite mixture model from multivariate data. The adjective \"unsupervised\" is justified by two properties of the algorithm: 1) it is capable of selecting the number of components and 2) unlike the standard expectation-maximization (EM) algorithm, it does not require careful initialization. The proposed method also avoids another drawback of EM for mixture fitting: the possibility of convergence toward a singular estimate at the boundary of the parameter space. The novelty of our approach is that we do not use a model selection criterion to choose one among a set of preestimated candidate models; instead, we seamlessly integrate estimation and model selection in a single algorithm. Our technique can be applied to any type of parametric mixture model for which it is possible to write an EM algorithm; in this paper, we illustrate it with experiments involving Gaussian mixtures. These experiments testify for the good performance of our approach."
            },
            "slug": "Unsupervised-Learning-of-Finite-Mixture-Models-Figueiredo-Jain",
            "title": {
                "fragments": [],
                "text": "Unsupervised Learning of Finite Mixture Models"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The novelty of the approach is that it does not use a model selection criterion to choose one among a set of preestimated candidate models; instead, it seamlessly integrate estimation and model selection in a single algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680297"
                        ],
                        "name": "Marco Zuliani",
                        "slug": "Marco-Zuliani",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Zuliani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marco Zuliani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145319358"
                        ],
                        "name": "C. Kenney",
                        "slug": "C.-Kenney",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Kenney",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Kenney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50591689"
                        ],
                        "name": "B. S. Manjunath",
                        "slug": "B.-S.-Manjunath",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Manjunath",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. S. Manjunath"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2446552,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bef348b975d3f7b7d211d71742d1870edf074597",
            "isKey": false,
            "numCitedBy": 313,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "A RANSAC based procedure is described for detecting inliers corresponding to multiple models in a given set of data points. The algorithm we present in this paper (called multiRANSAC) on average performs better than traditional approaches based on the sequential application of a standard RANSAC algorithm followed by the removal of the detected set of inliers. We illustrate the effectiveness of our approach on a synthetic example and apply it to the problem of identifying multiple world planes in pairs of images containing dominant planar structures."
            },
            "slug": "The-multiRANSAC-algorithm-and-its-application-to-Zuliani-Kenney",
            "title": {
                "fragments": [],
                "text": "The multiRANSAC algorithm and its application to detect planar homographies"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The algorithm presented in this paper, called multiRANSAC, on average performs better than traditional approaches based on the sequential application of a standard RANSAC algorithm followed by the removal of the detected set of inliers."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE International Conference on Image Processing 2005"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705564"
                        ],
                        "name": "G. Nemhauser",
                        "slug": "G.-Nemhauser",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nemhauser",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nemhauser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736128"
                        ],
                        "name": "L. Wolsey",
                        "slug": "L.-Wolsey",
                        "structuredName": {
                            "firstName": "Laurence",
                            "lastName": "Wolsey",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Wolsey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145456487"
                        ],
                        "name": "M. Fisher",
                        "slug": "M.-Fisher",
                        "structuredName": {
                            "firstName": "Marshall",
                            "lastName": "Fisher",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fisher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The greedy bound for UFL by Cornuejols et al. (1977) then follows from a general bound on minimizing supermodular functions by  Nemhauser et al. (1978) ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206800425,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b9e43395663f74c581982e9ca97a0d7057a0008c",
            "isKey": false,
            "numCitedBy": 4009,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "LetN be a finite set andz be a real-valued function defined on the set of subsets ofN that satisfies z(S)+z(T)\u2265z(S\u22c3T)+z(S\u22c2T) for allS, T inN. Such a function is called submodular. We consider the problem maxS\u2282N{a(S):|S|\u2264K,z(S) submodular}.Several hard combinatorial optimization problems can be posed in this framework. For example, the problem of finding a maximum weight independent set in a matroid, when the elements of the matroid are colored and the elements of the independent set can have no more thanK colors, is in this class. The uncapacitated location problem is a special case of this matroid optimization problem.We analyze greedy and local improvement heuristics and a linear programming relaxation for this problem. Our results are worst case bounds on the quality of the approximations. For example, whenz(S) is nondecreasing andz(0) = 0, we show that a \u201cgreedy\u201d heuristic always produces a solution whose value is at least 1 \u2212[(K \u2212 1)/K]K times the optimal value. This bound can be achieved for eachK and has a limiting value of (e \u2212 1)/e, where e is the base of the natural logarithm."
            },
            "slug": "An-analysis-of-approximations-for-maximizing-set-Nemhauser-Wolsey",
            "title": {
                "fragments": [],
                "text": "An analysis of approximations for maximizing submodular set functions\u2014I"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "It is shown that a \u201cgreedy\u201d heuristic always produces a solution whose value is at least 1 \u2212[(K \u2212 1/K]K times the optimal value, which can be achieved for eachK and has a limiting value of (e \u2212 1)/e, where e is the base of the natural logarithm."
            },
            "venue": {
                "fragments": [],
                "text": "Math. Program."
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685978"
                        ],
                        "name": "B. Taskar",
                        "slug": "B.-Taskar",
                        "structuredName": {
                            "firstName": "Ben",
                            "lastName": "Taskar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Taskar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2482074"
                        ],
                        "name": "Vassil Chatalbashev",
                        "slug": "Vassil-Chatalbashev",
                        "structuredName": {
                            "firstName": "Vassil",
                            "lastName": "Chatalbashev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vassil Chatalbashev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736370"
                        ],
                        "name": "D. Koller",
                        "slug": "D.-Koller",
                        "structuredName": {
                            "firstName": "Daphne",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Koller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The label cost terms are included in energy (\ufffd ) linearly and can thus be learned by max-margin methods ( Taskar et al. 2004;  Tsochantaridis et al. 2006)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 11312524,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "702c2fde33ccb4328be06405c11e208a4b3ee347",
            "isKey": false,
            "numCitedBy": 200,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Markov networks are extensively used to model complex sequential, spatial, and relational interactions in fields as diverse as image processing, natural language analysis, and bioinformatics. However, inference and learning in general Markov networks is intractable. In this paper, we focus on learning a large subclass of such models (called associative Markov networks) that are tractable or closely approximable. This subclass contains networks of discrete variables with K labels each and clique potentials that favor the same labels for all variables in the clique. Such networks capture the \"guilt by association\" pattern of reasoning present in many domains, in which connected (\"associated\") variables tend to have the same label. Our approach exploits a linear programming relaxation for the task of finding the best joint assignment in such networks, which provides an approximate quadratic program (QP) for the problem of learning a margin-maximizing Markov network. We show that for associative Markov network over binary-valued variables, this approximate QP is guaranteed to return an optimal parameterization for Markov networks of arbitrary topology. For the nonbinary case, optimality is not guaranteed, but the relaxation produces good solutions in practice. Experimental results with hypertext and newswire classification show significant advantages over standard approaches."
            },
            "slug": "Learning-associative-Markov-networks-Taskar-Chatalbashev",
            "title": {
                "fragments": [],
                "text": "Learning associative Markov networks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper exploits a linear programming relaxation for the task of finding the best joint assignment in associative Markov networks, which provides an approximate quadratic program (QP) for the problem of learning a margin-maximizing Markov network."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144649144"
                        ],
                        "name": "O. Barinova",
                        "slug": "O.-Barinova",
                        "structuredName": {
                            "firstName": "Olga",
                            "lastName": "Barinova",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Barinova"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740145"
                        ],
                        "name": "V. Lempitsky",
                        "slug": "V.-Lempitsky",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Lempitsky",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Lempitsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143967473"
                        ],
                        "name": "Pushmeet Kohli",
                        "slug": "Pushmeet-Kohli",
                        "structuredName": {
                            "firstName": "Pushmeet",
                            "lastName": "Kohli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pushmeet Kohli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 826,
                                "start": 15
                            }
                        ],
                        "text": "More recently, Barinova et al. (2010) used UFL to model a class of objectdetection problems and used the same greedy algorithm as our concurrent work (Delong et al. 2010). The general3 UFL problem is NP-hard by simple reduction from SET-COVER. A hardness result for SET-COVER by Feige (1998) implies that UFL cannot be approximated better than (1 \u2212 \u03b5) ln |P | for \u03b5 > 0 in polynomial time unless the complexity class NP \u2286 DTIME[nO(log logn)]. Kuehn and Hamburger (1963) proposed a natural greedy algorithm where facilities are opened one at a time. Cornuejols et al. (1977) showed that the greedy algorithm provides a constant-factor approximation bound, but only with respect to the gap between best and worst solutions; this bound is not informative when the range of costs involved are prohibitively large. Hochbaum (1982) later proposed a set-greedy algorithm that achieves a ln |P |-approximation regardless of the costs involved, which is optimal in the sense outlined by Feige."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 292,
                                "start": 15
                            }
                        ],
                        "text": "More recently, Barinova et al. (2010) used UFL to model a class of objectdetection problems and used the same greedy algorithm as our concurrent work (Delong et al. 2010). The general3 UFL problem is NP-hard by simple reduction from SET-COVER. A hardness result for SET-COVER by Feige (1998) implies that UFL cannot be approximated better than (1 \u2212 \u03b5) ln |P | for \u03b5 > 0 in polynomial time unless the complexity class NP \u2286 DTIME[nO(log logn)]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 15
                            }
                        ],
                        "text": "More recently, Barinova et al. (2010) used UFL to model a class of objectdetection problems and used the same greedy algorithm as our concurrent work (Delong et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 316,
                                "start": 6
                            }
                        ],
                        "text": "2009; Barinova et al. 2010). Our combined energy ( ) has recently been extended to convex continuous total variation (TV) formulations (Yuan and Boykov 2010). Label costs can be viewed as a special case of other global interactions recently studied in vision, for example by Werner (2008) and Woodford et al. (2009). Werner proposed a cutting plane algorithm to make certain high-order potentials tractable in an LP relaxation framework."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 470,
                                "start": 15
                            }
                        ],
                        "text": "More recently, Barinova et al. (2010) used UFL to model a class of objectdetection problems and used the same greedy algorithm as our concurrent work (Delong et al. 2010). The general3 UFL problem is NP-hard by simple reduction from SET-COVER. A hardness result for SET-COVER by Feige (1998) implies that UFL cannot be approximated better than (1 \u2212 \u03b5) ln |P | for \u03b5 > 0 in polynomial time unless the complexity class NP \u2286 DTIME[nO(log logn)]. Kuehn and Hamburger (1963) proposed a natural greedy algorithm where facilities are opened one at a time."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 574,
                                "start": 15
                            }
                        ],
                        "text": "More recently, Barinova et al. (2010) used UFL to model a class of objectdetection problems and used the same greedy algorithm as our concurrent work (Delong et al. 2010). The general3 UFL problem is NP-hard by simple reduction from SET-COVER. A hardness result for SET-COVER by Feige (1998) implies that UFL cannot be approximated better than (1 \u2212 \u03b5) ln |P | for \u03b5 > 0 in polynomial time unless the complexity class NP \u2286 DTIME[nO(log logn)]. Kuehn and Hamburger (1963) proposed a natural greedy algorithm where facilities are opened one at a time. Cornuejols et al. (1977) showed that the greedy algorithm provides a constant-factor approximation bound, but only with respect to the gap between best and worst solutions; this bound is not informative when the range of costs involved are prohibitively large."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 213,
                                "start": 163
                            }
                        ],
                        "text": "1 Special case energy (1) corresponds to objective functions studied in vision by Torr (1998) and in a number of independent later works for specific applications (Li 2007; Lazic et al. 2009; Barinova et al. 2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7436254,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6dc9908adef2578e3664859be9277cb30f3a484b",
            "isKey": true,
            "numCitedBy": 278,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Hough transform-based methods for detecting multiple objects use nonmaxima suppression or mode seeking to locate and distinguish peaks in Hough images. Such postprocessing requires the tuning of many parameters and is often fragile, especially when objects are located spatially close to each other. In this paper, we develop a new probabilistic framework for object detection which is related to the Hough transform. It shares the simplicity and wide applicability of the Hough transform but, at the same time, bypasses the problem of multiple peak identification in Hough images and permits detection of multiple objects without invoking nonmaximum suppression heuristics. Our experiments demonstrate that this method results in a significant improvement in detection accuracy both for the classical task of straight line detection and for a more modern category-level (pedestrian) detection problem."
            },
            "slug": "On-Detection-of-Multiple-Object-Instances-Using-Barinova-Lempitsky",
            "title": {
                "fragments": [],
                "text": "On Detection of Multiple Object Instances Using Hough Transforms"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new probabilistic framework for object detection which is related to the Hough transform is developed which bypasses the problem of multiple peak identification in Hough images and permits detection of multiple objects without invoking nonmaximum suppression heuristics."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143624539"
                        ],
                        "name": "A. Kulik",
                        "slug": "A.-Kulik",
                        "structuredName": {
                            "firstName": "Ariel",
                            "lastName": "Kulik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kulik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794456"
                        ],
                        "name": "H. Shachnai",
                        "slug": "H.-Shachnai",
                        "structuredName": {
                            "firstName": "Hadas",
                            "lastName": "Shachnai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Shachnai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2031981"
                        ],
                        "name": "Tami Tamir",
                        "slug": "Tami-Tamir",
                        "structuredName": {
                            "firstName": "Tami",
                            "lastName": "Tamir",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tami Tamir"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 192
                            }
                        ],
                        "text": "Babayev [2] and Frieze [15] noted in 1974 that, as a function of open facilities, standard UFL is supermodular (as a minimization problem) and thus yields some form of approximation guarantee [29, 23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2987767,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "b0e4485d39eb2cb734bb48e29425381fad679ce5",
            "isKey": false,
            "numCitedBy": 168,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "The concept of submodularity plays a vital role in combinatorial optimization. In particular, many important optimization problems can be cast as submodular maximization problems, including maximum coverage, maximum facility location and max cut in directed/undirected graphs. \n \nIn this paper we present the first known approximation algorithms for the problem of maximizing a nondecreasing submodular set function subject to multiple linear constraints. Given a d-dimensional budget vector [EQUATION], for some d \u2265 1, and an oracle for a non-decreasing submodular set function f over a universe U, where each element e \u2208 U is associated with a d-dimensional cost vector, we seek a subset of elements S \u2286 U whose total cost is at most [EQUATION], such that f(S) is maximized. \n \nWe develop a framework for maximizing submodular functions subject to d linear constraints that yields a (1 - e)(1 - e\u22121)-approximation to the optimum for any e > 0, where d > 1 is some constant. Our study is motivated by a variant of the classical maximum coverage problem that we call maximum coverage with multiple packing constraints. We use our framework to obtain the same approximation ratio for this problem. To the best of our knowledge, this is the first time the theoretical bound of 1 - e\u22121 is (almost) matched for both of these problems."
            },
            "slug": "Maximizing-submodular-set-functions-subject-to-Kulik-Shachnai",
            "title": {
                "fragments": [],
                "text": "Maximizing submodular set functions subject to multiple linear constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A framework for maximizing submodular functions subject to d linear constraints is developed that yields a (1 - e)(1- e\u22121)-approximation to the optimum for any e > 0, where d > 1 is some constant."
            },
            "venue": {
                "fragments": [],
                "text": "SODA"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2849560"
                        ],
                        "name": "Nevena Lazic",
                        "slug": "Nevena-Lazic",
                        "structuredName": {
                            "firstName": "Nevena",
                            "lastName": "Lazic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nevena Lazic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2256743"
                        ],
                        "name": "Inmar E. Givoni",
                        "slug": "Inmar-E.-Givoni",
                        "structuredName": {
                            "firstName": "Inmar",
                            "lastName": "Givoni",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Inmar E. Givoni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749650"
                        ],
                        "name": "B. Frey",
                        "slug": "B.-Frey",
                        "structuredName": {
                            "firstName": "Brendan",
                            "lastName": "Frey",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Frey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3241876"
                        ],
                        "name": "Parham Aarabi",
                        "slug": "Parham-Aarabi",
                        "structuredName": {
                            "firstName": "Parham",
                            "lastName": "Aarabi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Parham Aarabi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 662989,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "135eeb3eedee71b1836c4b409c3ef30a204927b2",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Subspace segmentation is the task of segmenting data lying on multiple linear subspaces. Its applications in computer vision include motion segmentation in video, structure-from-motion, and image clustering. In this work, we describe a novel approach for subspace segmentation that uses probabilistic inference via a message-passing algorithm."
            },
            "slug": "FLoSS:-Facility-location-for-subspace-segmentation-Lazic-Givoni",
            "title": {
                "fragments": [],
                "text": "FLoSS: Facility location for subspace segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A novel approach for subspace segmentation that uses probabilistic inference via a message-passing algorithm to solve the challenge of segmenting data lying on multiple linear subspaces."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38817267"
                        ],
                        "name": "K. Sung",
                        "slug": "K.-Sung",
                        "structuredName": {
                            "firstName": "Kah",
                            "lastName": "Sung",
                            "middleNames": [
                                "Kay"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Sung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 36
                            }
                        ],
                        "text": "The elliptical(4) K-means algorithm [51] maximizes the following likelihood on the same probability space"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7164794,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "088eb2d102c6bb486f5270d0b2adff76961994cf",
            "isKey": false,
            "numCitedBy": 2061,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an example-based learning approach for locating vertical frontal views of human faces in complex scenes. The technique models the distribution of human face patterns by means of a few view-based \"face\" and \"nonface\" model clusters. At each image location, a difference feature vector is computed between the local image pattern and the distribution-based model. A trained classifier determines, based on the difference feature vector measurements, whether or not a human face exists at the current image location. We show empirically that the distance metric we adopt for computing difference feature vectors, and the \"nonface\" clusters we include in our distribution-based model, are both critical for the success of our system."
            },
            "slug": "Example-Based-Learning-for-View-Based-Human-Face-Sung-Poggio",
            "title": {
                "fragments": [],
                "text": "Example-Based Learning for View-Based Human Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "An example-based learning approach for locating vertical frontal views of human faces in complex scenes and shows empirically that the distance metric adopted for computing difference feature vectors, and the \"nonface\" clusters included in the distribution-based model, are both critical for the success of the system."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747127"
                        ],
                        "name": "D. Shmoys",
                        "slug": "D.-Shmoys",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Shmoys",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Shmoys"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16202436,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "561a3254aafd6abc7b9d5490cf37c98da698b8a2",
            "isKey": false,
            "numCitedBy": 526,
            "numCiting": 119,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the most flourishing areas of research in the design and analysis of approximation algorithms has been for facility location problems. In particular, for the metric case of two simple models, the uncapacitated facility location and the k-median problems, there are now a variety of techniques that yield constant performance guarantees. These methods include LP rounding, primal-dual algorithms, and local search techniques. Furthermore, the salient ideas in these algorithms and their analyzes are simple-to-explain and reflect a surprising degree of commonality. This note is intended as companion to our lecture at CONF 2000, mainly to give pointers to the appropriate references."
            },
            "slug": "Approximation-algorithms-for-facility-location-Shmoys",
            "title": {
                "fragments": [],
                "text": "Approximation algorithms for facility location problems"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This note is intended as companion to the lecture at CONF 2000, mainly to give pointers to the appropriate references."
            },
            "venue": {
                "fragments": [],
                "text": "APPROX"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144890574"
                        ],
                        "name": "James Allan",
                        "slug": "James-Allan",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Allan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Allan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701451"
                        ],
                        "name": "Ramesh Nallapati",
                        "slug": "Ramesh-Nallapati",
                        "structuredName": {
                            "firstName": "Ramesh",
                            "lastName": "Nallapati",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ramesh Nallapati"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60614419,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e892771df0d0708b07a7e65472a1b04d0610015",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "Unigram Language modeling is a successful probabilistic framework for Information Retrieval (IR) that uses the multinomial distribution to model documents and queries. An important feature in this approach is the usage of the empirically successful cross-entropy function between the query model and document models as a document ranking function. However, this function does not follow directly from the underlying models and as such there is no justification available for its usage till date. \nAnother related and interesting observation is that the naive Bayes model for text classification uses the same multinomial distribution to model documents but in contrast, employs document-log-likelihood that follows directly from the model, as a scoring function. Curiously, the document-log-likelihood closely corresponds to cross entropy, but to an asymmetric counterpart of the function used in language modeling. It has been empirically demonstrated that the version of cross entropy used in IR is a better performer than document-log-likelihood, but this interesting phenomenon remains largely unexplained. \nOne of the main objectives of this work is to develop a theoretical understanding of the reasons for the success of the version of cross entropy function used for ranking in IR. We also aim to construct a likelihood based generative model that directly corresponds to this cross-entropy function. Such a model, if successful, would allow us to view IR essentially as a machine learning problem. A secondary objective is to bridge the gap between the generative approaches used in IR and text classification through a unified model. \nIn this work we show that the cross entropy ranking function corresponds to the log-likelihood of documents w.r.t. the approximate Smoothed-Dirichlet (SD) distribution, a novel variant of the Dirichlet distribution. We also empirically demonstrate that this new distribution captures term occurrence patterns in documents much better than the multinomial, thus offering a reason behind the superior performance of the cross entropy ranking function compared to the multinomial document-likelihood. \nOur experiments in text classification show that a classifier based on the Smoothed Dirichlet performs significantly better than the multinomial based naive Bayes model and on par with the Support Vector Machines (SVM), confirming our reasoning. In addition, this classifier is as quick to train as the naive Bayes and several times faster than the SVMs owing to its closed form maximum likelihood solution, making it ideal for many practical IR applications. We also construct a well-motivated generative classifier for IR based on SD distribution that uses the EM algorithm to learn from pseudo-feedback and show that its performance is equivalent to the Relevance model (RM), a state-of-the-art model for IR in the language modeling framework that uses the same cross-entropy as its ranking function. In addition, the SD based classifier provides more flexibility than RM in modeling documents owing to a consistent generative framework. We demonstrate that this flexibility translates into a superior performance compared to RM on the task of topic tracking, an online classification task."
            },
            "slug": "The-smoothed-dirichlet-distribution:-understanding-Allan-Nallapati",
            "title": {
                "fragments": [],
                "text": "The smoothed dirichlet distribution: understanding cross-entropy ranking in information retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work shows that the cross entropy ranking function corresponds to the log-likelihood of documents w.r.t. the approximate Smoothed-Dirichlet (SD) distribution, a novel variant of the Dirichlet distribution, and constructs a likelihood based generative model that directly corresponds to this cross-entropy function."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745182"
                        ],
                        "name": "E. Dahlhaus",
                        "slug": "E.-Dahlhaus",
                        "structuredName": {
                            "firstName": "Elias",
                            "lastName": "Dahlhaus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Dahlhaus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "23167841"
                        ],
                        "name": "D. S. Johnson",
                        "slug": "D.-S.-Johnson",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Johnson",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. S. Johnson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144102674"
                        ],
                        "name": "C. Papadimitriou",
                        "slug": "C.-Papadimitriou",
                        "structuredName": {
                            "firstName": "Christos",
                            "lastName": "Papadimitriou",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Papadimitriou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3696176"
                        ],
                        "name": "P. Seymour",
                        "slug": "P.-Seymour",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Seymour",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Seymour"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748179"
                        ],
                        "name": "M. Yannakakis",
                        "slug": "M.-Yannakakis",
                        "structuredName": {
                            "firstName": "Mihalis",
                            "lastName": "Yannakakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Yannakakis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The \u03b1-expansion algorithm is indifferent to ep, and this property distinguishes it from the isolation heuristic algorithm for multi-terminal cuts ( Dahlhaus et al. 1994 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1123876,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "1cf64c2bdd4f1c384a55910606a64c8d831a96ba",
            "isKey": false,
            "numCitedBy": 623,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "In the multiterminal cut problem one is given an edge-weighted graph and a subset of the vertices called terminals, and is asked for a minimum weight set of edges that separates each terminal from all the others. When the number $k$ of terminals is two, this is simply the mincut, max-flow problem, and can be solved in polynomial time. It is shown that the problem becomes NP-hard as soon as $k=3$, but can be solved in polynomial time for planar graphs for any fixed $k$. The planar problem is NP-hard, however, if $k$ is not fixed. A simple approximation algorithm for arbitrary graphs that is guaranteed to come within a factor of $2-2/k$ of the optimal cut weight is also described."
            },
            "slug": "The-Complexity-of-Multiterminal-Cuts-Dahlhaus-Johnson",
            "title": {
                "fragments": [],
                "text": "The Complexity of Multiterminal Cuts"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that the problem becomes NP-hard as soon as $k=3$, but can be solved in polynomial time for planar graphs for any fixed $k$, if the planar problem is NP- hard, however, if \u00a3k$ is not fixed."
            },
            "venue": {
                "fragments": [],
                "text": "SIAM J. Comput."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "94055099"
                        ],
                        "name": "Harvey J. Everett",
                        "slug": "Harvey-J.-Everett",
                        "structuredName": {
                            "firstName": "Harvey",
                            "lastName": "Everett",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Harvey J. Everett"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Following the discrete version of Lagrange method ( Everett 1963 ), the constrained problem above is closely related to unconstrained optimization of generalized Lagrange function"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "with parameter \u03c3 instead of e. In particular, an optimal solution for (40) for any fixed value of Lagrange multiplier \u03c3 also solves the constrained problem above for some e. Following the discussion after Theorem 1 in  Everett (1963) , the unconstrained minimum solution (f \u2217 ,M \u2217 , \u00af I \u2217 ) for en-"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 122381976,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "2894125ea5f8a3300bd098e7be2331f7789ff91b",
            "isKey": false,
            "numCitedBy": 1284,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "The usefulness of Lagrange multipliers for optimization in the presence of constraints is not limited to differentiable functions. They can be applied to problems of maximizing an arbitrary real valued objective function over any set whatever, subject to bounds on the values of any other finite collection of real valued functions denned on the same set. While the use of the Lagrange multipliers does not guarantee that a solution will necessarily be found for all problems, it is \u201cfail-safe\u201d in the sense that any solution found by their use is a true solution. Since the method is so simple compared to other available methods it is often worth trying first, and succeeds in a surprising fraction of cases. They are particularly well suited to the solution of problems of allocating limited resources among a set of independent activities."
            },
            "slug": "Generalized-Lagrange-Multiplier-Method-for-Solving-Everett",
            "title": {
                "fragments": [],
                "text": "Generalized Lagrange Multiplier Method for Solving Problems of Optimum Allocation of Resources"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1963
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "17173992"
                        ],
                        "name": "B. Wrobel",
                        "slug": "B.-Wrobel",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Wrobel",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Wrobel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 50
                            }
                        ],
                        "text": "Data costs measure the squared Sampson\u2019s distance [11] of a match w."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 48
                            }
                        ],
                        "text": "Data costs measure the symmetric transfer error [11] of a match w."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 44793400,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "339093c7ed71919ce59a7e78979a77abd25bad0c",
            "isKey": false,
            "numCitedBy": 16324,
            "numCiting": 222,
            "paperAbstract": {
                "fragments": [],
                "text": "Downloading the book in this website lists can give you more advantages. It will show you the best book collections and completed collections. So many books can be found in this website. So, this is not only this multiple view geometry in computer vision. However, this book is referred to read because it is an inspiring book to give you more chance to get experiences and also thoughts. This is simple, read the soft file of the book and you get it."
            },
            "slug": "Multiple-View-Geometry-in-Computer-Vision-Wrobel",
            "title": {
                "fragments": [],
                "text": "Multiple View Geometry in Computer Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "This book is referred to read because it is an inspiring book to give you more chance to get experiences and also thoughts and it will show the best book collections and completed collections."
            },
            "venue": {
                "fragments": [],
                "text": "K\u00fcnstliche Intell."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46842850"
                        ],
                        "name": "T. J. Mitchell",
                        "slug": "T.-J.-Mitchell",
                        "structuredName": {
                            "firstName": "Toby",
                            "lastName": "Mitchell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. J. Mitchell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48769747"
                        ],
                        "name": "J. Beauchamp",
                        "slug": "J.-Beauchamp",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Beauchamp",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Beauchamp"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "As an alternative to Dirichlet prior, one can impose a sparsity prior similar to the spike-and-slab distribution ( Mitchell and Beauchamp 1988 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 120106449,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "7f70179b5935583e7062eb7745c010b37b3205a0",
            "isKey": false,
            "numCitedBy": 1202,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract This article is concerned with the selection of subsets of predictor variables in a linear regression model for the prediction of a dependent variable. It is based on a Bayesian approach, intended to be as objective as possible. A probability distribution is first assigned to the dependent variable through the specification of a family of prior distributions for the unknown parameters in the regression model. The method is not fully Bayesian, however, because the ultimate choice of prior distribution from this family is affected by the data. It is assumed that the predictors represent distinct observables; the corresponding regression coefficients are assigned independent prior distributions. For each regression coefficient subject to deletion from the model, the prior distribution is a mixture of a point mass at 0 and a diffuse uniform distribution elsewhere, that is, a \u201cspike and slab\u201d distribution. The random error component is assigned a normal distribution with mean 0 and standard deviation ..."
            },
            "slug": "Bayesian-Variable-Selection-in-Linear-Regression-Mitchell-Beauchamp",
            "title": {
                "fragments": [],
                "text": "Bayesian Variable Selection in Linear Regression"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "71533324"
                        ],
                        "name": "G. Cornuejols",
                        "slug": "G.-Cornuejols",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Cornuejols",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cornuejols"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145456487"
                        ],
                        "name": "M. Fisher",
                        "slug": "M.-Fisher",
                        "structuredName": {
                            "firstName": "Marshall",
                            "lastName": "Fisher",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fisher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705564"
                        ],
                        "name": "G. Nemhauser",
                        "slug": "G.-Nemhauser",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nemhauser",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nemhauser"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Other greedy moves have been proposed for UFL besides \u201copen one facility at a time\u201d (see [ 6 , 7])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61819804,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "3e9d14246a6b6c09942779b52a7f4c7bf58378f9",
            "isKey": false,
            "numCitedBy": 517,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "In the course of the deliberations of the 1977 Lanchester Prize Committee, Alan J. Goldman brought to our attention an error in the proof of Lemma 1 of our paper (Cornuejols, G., M. L. Fisher, G. L. Nemhauser. 1977. Location of bank accounts to optimize float: an analytic study of exact and approximate algorithms. Management Sci. 23 789-810.). The lemma, however, is true and the original correct, but long and intricate, proof was provided to the Committee, see (Cornuejols, G., M. L. Fisher, G. L. Nemhauser. 1977. On the uncapacitated location problem. Ann. Discrete Math. 1 163-178.) for details."
            },
            "slug": "Note--On-\"Location-of-Bank-Accounts-to-Optimize-An-Cornuejols-Fisher",
            "title": {
                "fragments": [],
                "text": "Note--On \"Location of Bank Accounts to Optimize Float: An Analytic Study of Exact and Approximate Algorithms\""
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "In the course of the deliberations of the 1977 Lanchester Prize Committee, Alan J. Goldman brought to the authors' attention an error in the proof of Lemma 1 of their paper, which is true and the original correct, but long and intricate, proof was provided."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2300250"
                        ],
                        "name": "D. Babayev",
                        "slug": "D.-Babayev",
                        "structuredName": {
                            "firstName": "Djangir",
                            "lastName": "Babayev",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Babayev"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Babayev (1974)  and Frieze (1974) noted in 1974 that the set function Z(S) is supermodular (as a minimization problem), i.e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 32215881,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a9773ba9855fa0eb3aa1ddc7c013fbd3c813078d",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "For convenience we change the notation of [1] by replacing (s} by S and thus the condition s q~ J by S n J = ~, where ~ is the empty set. Property P is possessed by the uncapacitated plant location problem: If adding some set of plants S to the set of open plants I improves the solution (decreases the cost function), then this improvement cannot be increased by further augmenting the set of open plants (that is to say, replacing I by J / ) . On the basis of Property P, Frieze defined sets OP1 and OP2 and proved Theorem 3 which may be effective in the search for optimal solutions. Reading Frieze's note [1] provoked the question: Is there any connection between the results of [1] and \"the method of successive calculations\" 1 [2] ? In [21, V.P. Cherenin considered the same problem of finding a subset I c M = { 1, ..., m }, which minimizes a function C(/), which is defined also on an empty subset, and satisfies the following property:"
            },
            "slug": "Comments-on-the-note-of-Frieze-Babayev",
            "title": {
                "fragments": [],
                "text": "Comments on the note of Frieze"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "On the basis of Property P, Frieze defined sets OP1 and OP2 and proved Theorem 3 which may be effective in the search for optimal solutions and changed the notation of [1] by replacing (s} by S and thus the condition s q~ J by S n J = ~, where ~ is the empty set."
            },
            "venue": {
                "fragments": [],
                "text": "Math. Program."
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50324911"
                        ],
                        "name": "S. Creel",
                        "slug": "S.-Creel",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Creel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Creel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 4
                            }
                        ],
                        "text": "See [5] for an intuitive discussion and derivation of BIC in general, and see Torr\u2019s work [25] for insights specific to vision."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 4
                            }
                        ],
                        "text": "The BIC suggests that label costs should be chosen in some proportion to the number of observations (or, in our case, the expected number of observations per model)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 66
                            }
                        ],
                        "text": "Another well-known example is the Bayesian informa-\ntion criterion (BIC) [5, 21]:\nmin \u0398\n\u22122 ln Pr(X |\u0398) + 12 |\u0398|\u00b7ln |P| (12)\nwhere |P| is the number of observations."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 71
                            }
                        ],
                        "text": "Another well-known example is the Bayesian information criterion (BIC) [5, 21]:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 27845119,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "003aa796666b28cbc66f7bebff078e712bff09bd",
            "isKey": true,
            "numCitedBy": 1906,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "chemists. Commenting on the new material in the second edition (2E), which was published in 1991, Blackwood (1994) noted the predominance of citations from the chemometrics literature and commented that \u201creferences from other statistical sources are sparse.\u201d Chemometrics had certainly arrived in a big way by 1991, and there had not been much impact from the statistical community. If the methodology has not developed greatly through the 1990s, then the applications certainly have blossomed. (See the Journal of Chemometrics or Chemometrics and Intelligent Laboratory Systems, which have a lot of papers that would work perfectly well in the pages of Technometrics.) Blackwood (1994) noted in his review of the 2E that \u201cThe mathematical and statistical theory behind factor analysis is generally well presented, but it is in the practice and application areas that the book does best\u201d (p. 115). In the Preface, the author notes that \u201cthe introductory chapters, 1 through 5, remain unchanged\u201d (p. ix). Why mess with a proven product? Blackwood (1994) did comment that \u201cthe book is not an easy read,\u201d and \u201cit requires a good deal of mathematical understanding to get through.\u201d See the review for a complete summary of the 2E. The remainder of the book has been revised considerably. Chapter 6, formerly \u201cSpectral Methods of Factor Analysis,\u201d has been reorganized and retitled as \u201cEvolutionary Methods.\u201d It focuses on self-modeling methods and rank-annihilation factor analysis. This chapter is followed by additional material from the former Chapter 6 that has been expanded into two new chapters, \u201cMultimode Analysis\u201d and \u201cPartial Least-Squares Regression.\u201d All statisticians are quite familiar with the latter methodology, if not with some of the advanced realizations in chemistry, such as multiblock PLS, serial PLS, and multilinear PLS, that are described in this chapter. The chapter on multimode analysis carries the factor analysis tools into the arena of multiway arrays. This chapter deals with three-dimensional rank-annihilation factor analysis, simultaneous analysis, three-mode factor analysis, and PARAFAC (parallel factor analysis). The four application chapters that conclude the book continue to bear the same titles as before, but they have all been updated to incorporate the latest advances in a wide variety of disciplines where various factor analysis methodologies have been applied. Three of the chapters are focused strictly within the realm of chemistry, whereas the \u008e nal chapter broadens the spectrum to incorporate examples from related sciences, speci\u008e cally biomedical, fuels, environmental, and food science applications. Despite the vast computational complexity of many of the methods in the book, the author continues to make no attempt to integrate statistical software into the text. There is an appendix that discusses the Toolbox for Chemical Factor Analysis, a suite of Matlab which the author apparently wrote. However, no CD-ROM is included. These programs need to be purchased. Another appendix provides the actual Matlab code for three of the programs, which are like subroutines in FORTRAN in that they need to be strung together to create a factor analysis program. There is no reference to software packages from Umetrics or other companies whose software can carry out many of the analyses in the book."
            },
            "slug": "Model-Selection-and-Multimodel-Inference-Creel",
            "title": {
                "fragments": [],
                "text": "Model Selection and Multimodel Inference"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747127"
                        ],
                        "name": "D. Shmoys",
                        "slug": "D.-Shmoys",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Shmoys",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Shmoys"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746222"
                        ],
                        "name": "\u00c9. Tardos",
                        "slug": "\u00c9.-Tardos",
                        "structuredName": {
                            "firstName": "\u00c9va",
                            "lastName": "Tardos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00c9. Tardos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2229828"
                        ],
                        "name": "K. Aardal",
                        "slug": "K.-Aardal",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Aardal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Aardal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 141
                            }
                        ],
                        "text": "Hochbaum [12] later showed that greedy yields a O(log |P|)-approximation in general, and better bounds exist for special cost functions (see [23] for review)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1624873,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "42d882522dfc2e35459d0e35f0b284708a48a79c",
            "isKey": false,
            "numCitedBy": 563,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "We present new approximation algorithms for several facility location problems. In each facility location problem that we study, there is a set of locations at which we may build a facility (such as a warehouse), where the cost of building at location i is fi; furthermore, there is a set of client locations (such as stores) that require to be serviced by a facility, and if a client at location j is assigned to a facility at location i, a cost of cij is incurred that is proportional to the distance between i and j. The objective is to determine a set of locations at which to open facilities so as to minimize the total facility and assignment costs. In the uncapacitated case, each facility can service an unlimited number of clients, whereas in the capacitated case, each facility can serve, for example, at most u clients. These models and a number of closely related ones have been studied extensively in the Operations Research literature. We shall consider the case in which the distances between locations are non-negative, symmetric and satisfy the triangle inequality. For the uncapacitated facility location, we give a polynomial-time algorithm that finds a solution of cost within a factor of 3.16 of the optimal. This is the first constant performance guarantee known for this problem. We also present approximation algorithms with constant performance guarantees for a number of capacitated models as well as a generalization in which there is a 2-level hierarchy of facilities. Our results are based on the filtering and rounding technique of Lin & Vitter. We also give a randomized variant of this technique that can then be derandomized to yield improved deterministic performance guarantees. shmoys@cs.cornell.edu. School of Operations Research & Industrial Engineering and Department of Computer Science, Cornell University, Ithaca, NY 14853. Research partially supported by NSF grants CCR-9307391 and DMS-9505155 and ONR grant N00014-96-1-0050O. yeva@cs.cornell.edu. Department of Computer Science and School of Operations Research & Industrial Engineering, Cornell University, Ithaca, NY 14853. Research partially supported by NSF grants DMI-9157199 and DMS-9505155 and ONR grant N00014-96-1-0050O. zaardal@cs.ruu.nl. Department of Computer Science, Utrecht University, Utrecht, The Netherlands. Research partially supported by NSF grant CCR-9307391, and by ESPRIT Long Term Research Project No. 20244 (project ALCOM-IT: Algorithms and Complexity in Information Technology)."
            },
            "slug": "Approximation-algorithms-for-facility-location-Shmoys-Tardos",
            "title": {
                "fragments": [],
                "text": "Approximation algorithms for facility location problems (extended abstract)"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A polynomial-time algorithm is given that finds a solution of cost within a factor of 3.16 of the optimal for the uncapacitated facility location, which is the first constant performance guarantee known for this problem."
            },
            "venue": {
                "fragments": [],
                "text": "STOC '97"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2608771"
                        ],
                        "name": "A. Gersho",
                        "slug": "A.-Gersho",
                        "structuredName": {
                            "firstName": "Allen",
                            "lastName": "Gersho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gersho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We generalize ideas from the previous section to further illustrate applications for label costs functionals like (\ufffd ). This section follows Shannon\u2019s rate-distortion (RD) optimization approach to lossy image compression, see  Gersho and Gray (2001) , Ortega and Ramchandran (1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 118950728,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c564aa7639a08c280423489e52b6e32055c9aa7f",
            "isKey": false,
            "numCitedBy": 7028,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1 Introduction.- 1.1 Signals, Coding, and Compression.- 1.2 Optimality.- 1.3 How to Use this Book.- 1.4 Related Reading.- I Basic Tools.- 2 Random Processes and Linear Systems.- 2.1 Introduction.- 2.2 Probability.- 2.3 Random Variables and Vectors.- 2.4 Random Processes.- 2.5 Expectation.- 2.6 Linear Systems.- 2.7 Stationary and Ergodic Properties.- 2.8 Useful Processes.- 2.9 Problems.- 3 Sampling.- 3.1 Introduction.- 3.2 Periodic Sampling.- 3.3 Noise in Sampling.- 3.4 Practical Sampling Schemes.- 3.5 Sampling Jitter.- 3.6 Multidimensional Sampling.- 3.7 Problems.- 4 Linear Prediction.- 4.1 Introduction.- 4.2 Elementary Estimation Theory.- 4.3 Finite-Memory Linear Prediction.- 4.4 Forward and Backward Prediction.- 4.5 The Levinson-Durbin Algorithm.- 4.6 Linear Predictor Design from Empirical Data.- 4.7 Minimum Delay Property.- 4.8 Predictability and Determinism.- 4.9 Infinite Memory Linear Prediction.- 4.10 Simulation of Random Processes.- 4.11 Problems.- II Scalar Coding.- 5 Scalar Quantization I.- 5.1 Introduction.- 5.2 Structure of a Quantizer.- 5.3 Measuring Quantizer Performance.- 5.4 The Uniform Quantizer.- 5.5 Nonuniform Quantization and Companding.- 5.6 High Resolution: General Case.- 5.7 Problems.- 6 Scalar Quantization II.- 6.1 Introduction.- 6.2 Conditions for Optimality.- 6.3 High Resolution Optimal Companding.- 6.4 Quantizer Design Algorithms.- 6.5 Implementation.- 6.6 Problems.- 7 Predictive Quantization.- 7.1 Introduction.- 7.2 Difference Quantization.- 7.3 Closed-Loop Predictive Quantization.- 7.4 Delta Modulation.- 7.5 Problems.- 8 Bit Allocation and Transform Coding.- 8.1 Introduction.- 8.2 The Problem of Bit Allocation.- 8.3 Optimal Bit Allocation Results.- 8.4 Integer Constrained Allocation Techniques.- 8.5 Transform Coding.- 8.6 Karhunen-Loeve Transform.- 8.7 Performance Gain of Transform Coding.- 8.8 Other Transforms.- 8.9 Sub-band Coding.- 8.10 Problems.- 9 Entropy Coding.- 9.1 Introduction.- 9.2 Variable-Length Scalar Noiseless Coding.- 9.3 Prefix Codes.- 9.4 Huffman Coding.- 9.5 Vector Entropy Coding.- 9.6 Arithmetic Coding.- 9.7 Universal and Adaptive Entropy Coding.- 9.8 Ziv-Lempel Coding.- 9.9 Quantization and Entropy Coding.- 9.10 Problems.- III Vector Coding.- 10 Vector Quantization I.- 10.1 Introduction.- 10.2 Structural Properties and Characterization.- 10.3 Measuring Vector Quantizer Performance.- 10.4 Nearest Neighbor Quantizers.- 10.5 Lattice Vector Quantizers.- 10.6 High Resolution Distortion Approximations.- 10.7 Problems.- 11 Vector Quantization II.- 11.1 Introduction.- 11.2 Optimality Conditions for VQ.- 11.3 Vector Quantizer Design.- 11.4 Design Examples.- 11.5 Problems.- 12 Constrained Vector Quantization.- 12.1 Introduction.- 12.2 Complexity and Storage Limitations.- 12.3 Structurally Constrained VQ.- 12.4 Tree-Structured VQ.- 12.5 Classified VQ.- 12.6 Transform VQ.- 12.7 Product Code Techniques.- 12.8 Partitioned VQ.- 12.9 Mean-Removed VQ.- 12.10 Shape-Gain VQ.- 12.11 Multistage VQ.- 12.12 Constrained Storage VQ.- 12.13 Hierarchical and Multiresolution VQ.- 12.14 Nonlinear Interpolative VQ.- 12.15 Lattice Codebook VQ.- 12.16 Fast Nearest Neighbor Encoding.- 12.17 Problems.- 13 Predictive Vector Quantization.- 13.1 Introduction.- 13.2 Predictive Vector Quantization.- 13.3 Vector Linear Prediction.- 13.4 Predictor Design from Empirical Data.- 13.5 Nonlinear Vector Prediction.- 13.6 Design Examples.- 13.7 Problems.- 14 Finite-State Vector Quantization.- 14.1 Recursive Vector Quantizers.- 14.2 Finite-State Vector Quantizers.- 14.3 Labeled-States and Labeled-Transitions.- 14.4 Encoder/Decoder Design.- 14.5 Next-State Function Design.- 14.6 Design Examples.- 14.7 Problems.- 15 Tree and Trellis Encoding.- 15.1 Delayed Decision Encoder.- 15.2 Tree and Trellis Coding.- 15.3 Decoder Design.- 15.4 Predictive Trellis Encoders.- 15.5 Other Design Techniques.- 15.6 Problems.- 16 Adaptive Vector Quantization.- 16.1 Introduction.- 16.2 Mean Adaptation.- 16.3 Gain-Adaptive Vector Quantization.- 16.4 Switched Codebook Adaptation.- 16.5 Adaptive Bit Allocation.- 16.6 Address VQ.- 16.7 Progressive Code Vector Updating.- 16.8 Adaptive Codebook Generation.- 16.9 Vector Excitation Coding.- 16.10 Problems.- 17 Variable Rate Vector Quantization.- 17.1 Variable Rate Coding.- 17.2 Variable Dimension VQ.- 17.3 Alternative Approaches to Variable Rate VQ.- 17.4 Pruned Tree-Structured VQ.- 17.5 The Generalized BFOS Algorithm.- 17.6 Pruned Tree-Structured VQ.- 17.7 Entropy Coded VQ.- 17.8 Greedy Tree Growing.- 17.9 Design Examples.- 17.10 Bit Allocation Revisited.- 17.11 Design Algorithms.- 17.12 Problems."
            },
            "slug": "Vector-quantization-and-signal-compression-Gersho-Gray",
            "title": {
                "fragments": [],
                "text": "Vector quantization and signal compression"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The author explains the design and implementation of the Levinson-Durbin Algorithm, which automates the very labor-intensive and therefore time-heavy and expensive process of designing and implementing a Quantizer."
            },
            "venue": {
                "fragments": [],
                "text": "The Kluwer international series in engineering and computer science"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35043531"
                        ],
                        "name": "A. Dempster",
                        "slug": "A.-Dempster",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Dempster",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dempster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7890796"
                        ],
                        "name": "N. Laird",
                        "slug": "N.-Laird",
                        "structuredName": {
                            "firstName": "Nan",
                            "lastName": "Laird",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Laird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235217"
                        ],
                        "name": "D. Rubin",
                        "slug": "D.-Rubin",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Rubin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rubin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Objective Functions for EM The classic EM algorithm (Bishop 2006;  Dempster et al. 1977 ) finds maximum likelihood (ML) estimators for GMM."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4193919,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "d36efb9ad91e00faa334b549ce989bfae7e2907a",
            "isKey": false,
            "numCitedBy": 48406,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "Vibratory power unit for vibrating conveyers and screens comprising an asynchronous polyphase motor, at least one pair of associated unbalanced masses disposed on the shaft of said motor, with the first mass of a pair of said unbalanced masses being rigidly fastened to said shaft and with said second mass of said pair being movably arranged relative to said first mass, means for controlling and regulating the conveying rate during conveyer operation by varying the rotational speed of said motor between predetermined minimum and maximum values, said second mass being movably outwardly by centrifugal force against the pressure of spring means, said spring means being prestressed in such a manner that said second mass is, at rotational motor speeds lower than said minimum speed, held in its initial position, and at motor speeds between said lower and upper values in positions which are radially offset with respect to the axis of said motor to an extent depending on the value of said rotational motor speed."
            },
            "slug": "Maximum-likelihood-from-incomplete-data-via-the-EM-Dempster-Laird",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood from incomplete data via the EM - algorithm plus discussions on the paper"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808201"
                        ],
                        "name": "G. Cornu\u00e9jols",
                        "slug": "G.-Cornu\u00e9jols",
                        "structuredName": {
                            "firstName": "G\u00e9rard",
                            "lastName": "Cornu\u00e9jols",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cornu\u00e9jols"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145456487"
                        ],
                        "name": "M. Fisher",
                        "slug": "M.-Fisher",
                        "structuredName": {
                            "firstName": "Marshall",
                            "lastName": "Fisher",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fisher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705564"
                        ],
                        "name": "G. Nemhauser",
                        "slug": "G.-Nemhauser",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nemhauser",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nemhauser"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 120246927,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "7b67c701873f662688152680ff7f9567070d46f0",
            "isKey": false,
            "numCitedBy": 703,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The number of days required to clear a check drawn on a bank in city j depends on the city i in which the check is cashed. Thus, to maximize its available funds, a company that pays bills to numerous clients in various locations may find it advantageous to maintain accounts in several strategically located banks. We will discuss the problem of optimally locating bank accounts to maximize clearing times. The importance of this problem depends in part on its mathematical equivalence to the well-known uncapacitated plant location problem. We present a Lagrangian dual for obtaining an upper bound and heuristics for obtaining a lower bound on the value of an optimal solution. Our main results are analytical worst-case analyses of these bounds. In particular we show that the relative error of the dual bound and a \"greedy\" heuristic never exceeds [(K - 1)/K] k"
            },
            "slug": "Exceptional-Paper\u2014Location-of-Bank-Accounts-to-An-Cornu\u00e9jols-Fisher",
            "title": {
                "fragments": [],
                "text": "Exceptional Paper\u2014Location of Bank Accounts to Optimize Float: An Analytic Study of Exact and Approximate Algorithms"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808201"
                        ],
                        "name": "G. Cornu\u00e9jols",
                        "slug": "G.-Cornu\u00e9jols",
                        "structuredName": {
                            "firstName": "G\u00e9rard",
                            "lastName": "Cornu\u00e9jols",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cornu\u00e9jols"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705564"
                        ],
                        "name": "G. Nemhauser",
                        "slug": "G.-Nemhauser",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nemhauser",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nemhauser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "98650329"
                        ],
                        "name": "L. Wolsey",
                        "slug": "L.-Wolsey",
                        "structuredName": {
                            "firstName": "Lairemce",
                            "lastName": "Wolsey",
                            "middleNames": [
                                "A"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Wolsey"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 89
                            }
                        ],
                        "text": "Other greedy moves have been proposed for UFL besides \u201copen one facility at a time\u201d (see [6, 7])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8880493,
            "fieldsOfStudy": [
                "Economics",
                "Business",
                "Sociology"
            ],
            "id": "1c1697671bc4a9a85e8619bc0c8d3e40c1bd27cb",
            "isKey": false,
            "numCitedBy": 536,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : An economic problem of great practical importance is to choose the location of facilities, such as industrial plants or warehouses, in order to minimize the cost (or maximize the profit) of satisfying the demand for some commodity. In general there are fixed costs for locating the facilities and transportation costs for distributing the commodities between the facilities and the clients. This problem has been extensively studied in the literature and is often referred to as the plant, warehouse or facility location problem. When each potential facility has a capacity, which is the maximum demand that it can supply, the problem is known as the capacitated facility location problem. When the capacity hypothesis is not needed, we have the simple or uncapacitated facility location problem, which the authors abbreviate by UL. The mathematical formulation of these problems as integer programs has proven very fruitful in the derivation of solution methods."
            },
            "slug": "The-uncapacitated-facility-location-problem-Cornu\u00e9jols-Nemhauser",
            "title": {
                "fragments": [],
                "text": "The uncapacitated facility location problem"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709874"
                        ],
                        "name": "A. Frieze",
                        "slug": "A.-Frieze",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Frieze",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Frieze"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Babayev (1974) and  Frieze (1974)  noted in 1974 that the set function Z(S) is supermodular (as a minimization problem), i.e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206799746,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "aaf8b8c3ff0b45ea6a6479ab947b6d5afd03e484",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "Property P is possessed by the simple plant location problem and more general problems as pointed out by Babayev [1 ], where C(/) is the minimum 'delivery cost' plus 'construction cost' when the plants in set I are considered to be open. For simplicity we shall replace I u is) by I + s where no confusion is possible. From Property P we may develop all the results on 'gain' functions used to solve simple plant location problems as well as the existence of a class of sub-optimal subsets. The proofs are straightforward and are omitted."
            },
            "slug": "A-cost-function-property-for-plant-location-Frieze",
            "title": {
                "fragments": [],
                "text": "A cost function property for plant location problems"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "From Property P, all the results on 'gain' functions used to solve simple plant location problems as well as the existence of a class of sub-optimal subsets are developed."
            },
            "venue": {
                "fragments": [],
                "text": "Math. Program."
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2737945"
                        ],
                        "name": "H. Akaike",
                        "slug": "H.-Akaike",
                        "structuredName": {
                            "firstName": "Hirotugu",
                            "lastName": "Akaike",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Akaike"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "For example, consider the well-known Akaike information criterion (AIC) [ 1 ]:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 411526,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "50a42ed2f81b9fe150883a6c89194c88a9647106",
            "isKey": false,
            "numCitedBy": 42034,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "The history of the development of statistical hypothesis testing in time series analysis is reviewed briefly and it is pointed out that the hypothesis testing procedure is not adequately defined as the procedure for statistical model identification. The classical maximum likelihood estimation procedure is reviewed and a new estimate minimum information theoretical criterion (AIC) estimate (MAICE) which is designed for the purpose of statistical identification is introduced. When there are several competing models the MAICE is defined by the model and the maximum likelihood estimates of the parameters which give the minimum of AIC defined by AIC = (-2)log-(maximum likelihood) + 2(number of independently adjusted parameters within the model). MAICE provides a versatile procedure for statistical model identification which is free from the ambiguities inherent in the application of conventional hypothesis testing procedure. The practical utility of MAICE in time series analysis is demonstrated with some numerical examples."
            },
            "slug": "A-new-look-at-the-statistical-model-identification-Akaike",
            "title": {
                "fragments": [],
                "text": "A new look at the statistical model identification"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48447996"
                        ],
                        "name": "A. Kuehn",
                        "slug": "A.-Kuehn",
                        "structuredName": {
                            "firstName": "Alfred",
                            "lastName": "Kuehn",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kuehn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40129467"
                        ],
                        "name": "Michael J. Hamburger",
                        "slug": "Michael-J.-Hamburger",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Hamburger",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Hamburger"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 48
                            }
                        ],
                        "text": "Our C++ library implements the greedy heuristic [17] and, when smooth costs are all zero, it is 15\u201330 times faster than \u03b1-expansion while yielding similar energies."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "Kuehn & Hamburger [17] proposed a natural greedy algorithm for UFL in 1963."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 57740806,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "5d56c70cddc22bb6efb7fb82a826e78d510d6c3b",
            "isKey": false,
            "numCitedBy": 916,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The linear programing algorithms available for optimizing the routing of shipments in multi-plant, multi-destination systems cannot, in the current state of knowledge, be applied directly to the more general problem of determining the number and location of regional warehouses in large-scale distribution networks. This paper outlines a heuristic computer program for locating warehouses and compares it with recently published efforts at solving the problem either by means of simulation or as a variant of linear programing. The heuristic approach outlined in this paper appears to offer significant advantages in the solution of this class of problems in that it (1) provides considerable flexibility in the specification (modeling) of the problem to be solved, (2) can be used to study large-scale problems, that is, complexes with several hundred potential warehouse sites and several thousand shipment destinations, and (3) is economical of computer time. The results obtained in applying the program to small scale problems have been equal to or better than those provided by the alternative methods considered."
            },
            "slug": "A-Heuristic-Program-for-Locating-Warehouses-Kuehn-Hamburger",
            "title": {
                "fragments": [],
                "text": "A Heuristic Program for Locating Warehouses"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The heuristic approach outlined in this paper appears to offer significant advantages in the solution of this class of problems in that it provides considerable flexibility in the specification (modeling) of the problem to be solved and is economical of computer time."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1963
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717379"
                        ],
                        "name": "D. Hochbaum",
                        "slug": "D.-Hochbaum",
                        "structuredName": {
                            "firstName": "Dorit",
                            "lastName": "Hochbaum",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hochbaum"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 9
                            }
                        ],
                        "text": "Hochbaum [12] later showed that greedy yields a O(log |P|)-approximation in general, and better bounds exist for special cost functions (see [23] for review)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3451944,
            "fieldsOfStudy": [
                "Business",
                "Mathematics"
            ],
            "id": "579f46eeaede6dead8318a4051227585079d80c5",
            "isKey": false,
            "numCitedBy": 276,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe in this paper polynomial heuristics for three important hard problems\u2014the discrete fixed cost median problem (the plant location problem), the continuous fixed cost median problem in a Euclidean space, and the network fixed cost median problem with convex costs. The heuristics for all the three problems guarantee error ratios no worse than the logarithm of the number of customer points. The derivation of the heuristics is based on the presentation of all types of median problems discussed as a set covering problem."
            },
            "slug": "Heuristics-for-the-fixed-cost-median-problem-Hochbaum",
            "title": {
                "fragments": [],
                "text": "Heuristics for the fixed cost median problem"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "This paper describes polynomial heuristics for three important hard problems\u2014the discrete fixed cost median problem (the plant location problem), the continuous fixed cost Median problem in a Euclidean space, and the network fixedcost median problem with convex costs."
            },
            "venue": {
                "fragments": [],
                "text": "Math. Program."
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39382965"
                        ],
                        "name": "Minghe Sun",
                        "slug": "Minghe-Sun",
                        "structuredName": {
                            "firstName": "Minghe",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Minghe Sun"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59835917,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "d7b1c0a971d94f80b3a693b7cc5ced7c77101618",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "A tabu search heuristic procedure is developed to solve the uncapacitated facility location problem. The heuristic procedure uses tabu search to guide the solution process when evolving from one solution to another in order to search for an optimal solution. A move is defined to be the closing or opening of a facility. The net change in the total cost resulting from a move is used to measure the attractiveness of a move. Searching only a small subset of the feasible solutions that contains the optimal solution, the procedure is computationally very efficient. A computational experiment is conducted to test the performance of the procedure and computational results are reported. The procedure can easily find optimal solutions for test problems with known optimal solutions from the literature. Solutions obtained with this tabu search procedure completely dominate those obtained with the Lagrangian method for randomly generated test problems."
            },
            "slug": "A-Tabu-Search-Heuristic-for-the-Uncapacitated-Sun",
            "title": {
                "fragments": [],
                "text": "A Tabu Search Heuristic for the Uncapacitated Facility Location Problem"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A tabu search heuristic procedure is developed to solve the uncapacitated facility location problem and solutions obtained completely dominate those obtained with the Lagrangian method for randomly generated test problems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644050191"
                        ],
                        "name": "G. LoweDavid",
                        "slug": "G.-LoweDavid",
                        "structuredName": {
                            "firstName": "G",
                            "lastName": "LoweDavid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. LoweDavid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 30
                            }
                        ],
                        "text": "We first detect SIFT features [20] and do matching as a preprocessing step; these matches are our observations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 174065,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4cab9c4b571761203ed4c3a4c5a07dd615f57a91",
            "isKey": false,
            "numCitedBy": 25505,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are ..."
            },
            "slug": "Distinctive-Image-Features-from-Scale-Invariant-LoweDavid",
            "title": {
                "fragments": [],
                "text": "Distinctive Image Features from Scale-Invariant Keypoints"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708061"
                        ],
                        "name": "E. Boros",
                        "slug": "E.-Boros",
                        "structuredName": {
                            "firstName": "Endre",
                            "lastName": "Boros",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Boros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692448"
                        ],
                        "name": "P. Hammer",
                        "slug": "P.-Hammer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hammer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hammer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "where y L is an auxiliary variable that must be optimized alongside x whenever hL > 0. Since each xpy L term has non-positive coefficient, the overall binary energy can be minimized by a single graph cut ( Boros and Hammer 2002 )."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11157651,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7b57d8ca6b0eadcb2689c4963e698bb4db1f23a7",
            "isKey": false,
            "numCitedBy": 804,
            "numCiting": 214,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Pseudo-Boolean-optimization-Boros-Hammer",
            "title": {
                "fragments": [],
                "text": "Pseudo-Boolean optimization"
            },
            "venue": {
                "fragments": [],
                "text": "Discret. Appl. Math."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113861474"
                        ],
                        "name": "C. Bishop",
                        "slug": "C.-Bishop",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Bishop",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bishop"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60688891,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "932a106c21a1db1e1876459c1521d27fd152caac",
            "isKey": false,
            "numCitedBy": 8461,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Looking for competent reading resources? We have pattern recognition and machine learning information science and statistics to read, not only read, but also download them or even check out online. Locate this fantastic book writtern by by now, simply here, yeah just here. Obtain the reports in the kinds of txt, zip, kindle, word, ppt, pdf, as well as rar. Once again, never ever miss to review online and download this book in our site right here. Click the link."
            },
            "slug": "Pattern-Recognition-and-Machine-Learning-Science-Bishop",
            "title": {
                "fragments": [],
                "text": "Pattern Recognition and Machine Learning (Information Science and Statistics)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113861474"
                        ],
                        "name": "C. Bishop",
                        "slug": "C.-Bishop",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Bishop",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bishop"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8147588"
                        ],
                        "name": "N. Nasrabadi",
                        "slug": "N.-Nasrabadi",
                        "structuredName": {
                            "firstName": "Nasser",
                            "lastName": "Nasrabadi",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Nasrabadi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "It can be shown that data points in X sampled in this manner correspond to the standard mixture model density ( Bishop 2006 )"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "M-step: To re-estimate each Gaussian model\u2019s parameters \u03bcl and \ufffd l in GMM, we use the standard weighted MLE formula, e.g. see  Bishop (2006) ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The EM algorithm can be generalized ( Bishop 2006 ) to compute maximum a posteriori (MAP) estimates of \u03b8 and \u03c9 maximizing the posterior Pr(\u03b8, \u03c9 | X) \u221d Pr(X| \u03b8,\u03c9) Pr(\u03b8 ) Pr(\u03c9)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Objective Functions for EM The classic EM algorithm ( Bishop 2006;  Dempster et al. 1977) finds maximum likelihood (ML) estimators for GMM."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Our work on these algorithms was inspired by an array of generic modelfitting applications in vision that benefit from label costs: geometric model fitting (Torr 1998), rigid motion estimation (Li 2007; Tron and Vidal 2007), MDL-based segmentation (Zhu and Yuille 1996), finite mixture models ( Bishop 2006 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 63317738,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "668b1277fbece28c4841eeab1c97e4ebd0079700",
            "isKey": true,
            "numCitedBy": 10185,
            "numCiting": 389,
            "paperAbstract": {
                "fragments": [],
                "text": "Probability Distributions.- Linear Models for Regression.- Linear Models for Classification.- Neural Networks.- Kernel Methods.- Sparse Kernel Machines.- Graphical Models.- Mixture Models and EM.- Approximate Inference.- Sampling Methods.- Continuous Latent Variables.- Sequential Data.- Combining Models."
            },
            "slug": "Pattern-Recognition-and-Machine-Learning-Bishop-Nasrabadi",
            "title": {
                "fragments": [],
                "text": "Pattern Recognition and Machine Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "Probability Distributions, linear models for Regression, Linear Models for Classification, Neural Networks, Graphical Models, Mixture Models and EM, Sampling Methods, Continuous Latent Variables, Sequential Data are studied."
            },
            "venue": {
                "fragments": [],
                "text": "J. Electronic Imaging"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145852650"
                        ],
                        "name": "D. Mackay",
                        "slug": "D.-Mackay",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mackay",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mackay"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 199
                            }
                        ],
                        "text": "We formulate the problem as one of finding a minimum description length (MDL) representation for the image, meaning a we want to represent the image compactly, in an information-theoretic sense (see [21] for review of MDL)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 126
                            }
                        ],
                        "text": "Information criteria penalize overly-complex models, preferring to explain the data with fewer, simpler models (Occam\u2019s razor [21])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 4
                            }
                        ],
                        "text": "The BIC suggests that label costs should be chosen in some proportion to the number of observations (or, in our case, the expected number of observations per model)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 66
                            }
                        ],
                        "text": "Another well-known example is the Bayesian informa-\ntion criterion (BIC) [5, 21]:\nmin \u0398\n\u22122 ln Pr(X |\u0398) + 12 |\u0398|\u00b7ln |P| (12)\nwhere |P| is the number of observations."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 71
                            }
                        ],
                        "text": "Another well-known example is the Bayesian information criterion (BIC) [5, 21]:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "See [5] for an intuitive discussion and derivation of BIC in general, and see Torr\u2019s work [25] for insights specific to vision."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5436619,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f7f15848cd0fbb3d08f351595da833b1627de9c3",
            "isKey": true,
            "numCitedBy": 8764,
            "numCiting": 249,
            "paperAbstract": {
                "fragments": [],
                "text": "Fun and exciting textbook on the mathematics underpinning the most dynamic areas of modern science and engineering."
            },
            "slug": "Information-Theory,-Inference,-and-Learning-Mackay",
            "title": {
                "fragments": [],
                "text": "Information Theory, Inference, and Learning Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "A fun and exciting textbook on the mathematics underpinning the most dynamic areas of modern science and engineering."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Information Theory"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 112
                            }
                        ],
                        "text": "In other settings (segmentation, stereo) these elements have been combined in various application-specific ways [28, 2, 22, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 39
                            }
                        ],
                        "text": "This slowdown may be because the BoykovKolmogorov maxflow algorithm [3] relies on heuristics that do not work well for large cliques, i.e. subgraphs of the kind in Figure 4."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 92
                            }
                        ],
                        "text": "Initial proposals were generated by sampling small patches of the input image, just like in [28, 27]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 92
                            }
                        ],
                        "text": "Energy (2) clusters over pixels and must either over-segment or over-smooth (b), just as in [27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 70
                            }
                        ],
                        "text": "Notice we find coarser clustering on baseball than Zabih & Kolmogorov [27] without over-smoothing."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Spatially Coherent Clustering with Graph Cuts"
            },
            "venue": {
                "fragments": [],
                "text": "In CVPR,"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 55
                            }
                        ],
                        "text": "a specific local optimum f\u0302 and global optimum f\u2217; see [8] for worst-case local minima."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 62
                            }
                        ],
                        "text": "See Section 5 for discussion and possible extensions, and see [8] for relation to standard expectation maximization (EM) and K-means formulations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 124
                            }
                        ],
                        "text": "The proof contains an alternate bound (26) that does not assume Dp \u2265 0 and is tight under much more general conditions; see [8] for a discussion of tightness and local minima."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 21
                            }
                        ],
                        "text": "Our technical report [8] elaborates on this point and Section 5 mentions an extension to our work based on the Robust P Potts construction [15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 60833109,
            "fieldsOfStudy": [],
            "id": "45e572a90d38c041985a1a71e307da217aba905b",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fast approximate energy minimization with label costs"
            },
            "venue": {
                "fragments": [],
                "text": "CVPR"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710872"
                        ],
                        "name": "T. Brox",
                        "slug": "T.-Brox",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Brox",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Brox"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7789445"
                        ],
                        "name": "J. Weickert",
                        "slug": "J.-Weickert",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Weickert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weickert"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 42
                            }
                        ],
                        "text": "A subsequent algorithm by Brox & Weickert [12] uses level sets to recursively partition the domain until it no longer pays to add regions (labels)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 124636812,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ee4c04cacd899c6d99b8d6b5b7f05a11b4ff40c5",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Level-set-based-segmentation-of-multiple-objects-Brox-Weickert",
            "title": {
                "fragments": [],
                "text": "Level set based segmentation of multiple objects"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152747119"
                        ],
                        "name": "O. Faugeras",
                        "slug": "O.-Faugeras",
                        "structuredName": {
                            "firstName": "O.",
                            "lastName": "Faugeras",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Faugeras"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143635539"
                        ],
                        "name": "P. Torr",
                        "slug": "P.-Torr",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Torr",
                            "middleNames": [
                                "H.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Torr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704936"
                        ],
                        "name": "N. Hollinghurst",
                        "slug": "N.-Hollinghurst",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Hollinghurst",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Hollinghurst"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764249"
                        ],
                        "name": "Joan Lasenby",
                        "slug": "Joan-Lasenby",
                        "structuredName": {
                            "firstName": "Joan",
                            "lastName": "Lasenby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joan Lasenby"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37585740"
                        ],
                        "name": "M. Sabin",
                        "slug": "M.-Sabin",
                        "structuredName": {
                            "firstName": "M",
                            "lastName": "Sabin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sabin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47139824"
                        ],
                        "name": "A. Fitzgibbon",
                        "slug": "A.-Fitzgibbon",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Fitzgibbon",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Fitzgibbon"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61188421,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9024afaa96e9200a2f967e02e061eeb5649ee4f2",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Geometric-motion-segmentation-and-model-selection-Faugeras-Torr",
            "title": {
                "fragments": [],
                "text": "Geometric motion segmentation and model selection - Discussion"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144653004"
                        ],
                        "name": "V. Kolmogorov",
                        "slug": "V.-Kolmogorov",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Kolmogorov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Kolmogorov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "104192849"
                        ],
                        "name": "R. Zabin",
                        "slug": "R.-Zabin",
                        "structuredName": {
                            "firstName": "Rawaa",
                            "lastName": "Zabin",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zabin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "and Drineas [10] generalized the graph construction of [ 16 ] to handle terms c Q p xp of arbitrary degree when c \ufffd 0."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Because this specific term is cubic and h\ufffd \ufffd 0, it can be optimized by a single graph cut using the construction in [ 16 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 53303132,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "6a1876f699838d79c184b7a2349f927c6f5ec99e",
            "isKey": false,
            "numCitedBy": 2088,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "In the last few years, several new algorithms based on graph cuts have been developed to solve energy minimization problems in computer vision. Each of these techniques constructs a graph such that the minimum cut on the graph also minimizes the energy. Yet, because these graph constructions are complex and highly specific to a particular energy function, graph cuts have seen limited application to date. In this paper, we give a characterization of the energy functions that can be minimized by graph cuts. Our results are restricted to functions of binary variables. However, our work generalizes many previous constructions and is easily applicable to vision problems that involve large numbers of labels, such as stereo, motion, image restoration, and scene reconstruction. We give a precise characterization of what energy functions can be minimized using graph cuts, among the energy functions that can be written as a sum of terms containing three or fewer binary variables. We also provide a general-purpose construction to minimize such an energy function. Finally, we give a necessary condition for any energy function of binary variables to be minimized by graph cuts. Researchers who are considering the use of graph cuts to optimize a particular energy function can use our results to determine if this is possible and then follow our construction to create the appropriate graph. A software implementation is freely available."
            },
            "slug": "What-energy-functions-can-be-minimized-via-graph-Kolmogorov-Zabin",
            "title": {
                "fragments": [],
                "text": "What energy functions can be minimized via graph cuts"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work gives a precise characterization of what energy functions can be minimized using graph cuts, among the energy functions that can be written as a sum of terms containing three or fewer binary variables."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 53303772,
            "fieldsOfStudy": [],
            "id": "1f9bd237a3184d4f53711c916be45fdfc5848719",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On Detection of Multiple Object Instances Using Hough Transforms"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684495"
                        ],
                        "name": "U. Feige",
                        "slug": "U.-Feige",
                        "structuredName": {
                            "firstName": "Uriel",
                            "lastName": "Feige",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Feige"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 115
                            }
                        ],
                        "text": "Performing expansions in greedy order (rather than arbitrary order) may help empirically, but a hardness result of Feige (1998) still applies to our problem (discussed in Sect."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 52827488,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "126900d94473a2f06a4b2a265c77fa44df1fd8d1",
            "isKey": false,
            "numCitedBy": 3095,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Given a collection<inline-equation><f> <sc>F</sc></f></inline-equation> of subsets of <?Pub Fmt italic>S<?Pub Fmt /italic> ={1,\u2026,<?Pub Fmt italic>n<?Pub Fmt /italic>}, <?Pub Fmt italic>setcover<?Pub Fmt /italic> is the problem of selecting as few as possiblesubsets from <inline-equation> <f> <sc>F</sc></f></inline-equation> such that their union covers<?Pub Fmt italic>S,<?Pub Fmt /italic>, and <?Pub Fmt italic>maxk-cover<?Pub Fmt /italic> is the problem of selecting<?Pub Fmt italic>k<?Pub Fmt /italic> subsets from<inline-equation> <f> <sc>F</sc></f></inline-equation> such that their union has maximum cardinality. Both these problems areNP-hard.   We prove that (1 - <?Pub Fmt italic>o<?Pub Fmt /italic>(1)) ln<?Pub Fmt italic>n<?Pub Fmt /italic> is a threshold below   which setcover cannot be approximated efficiently, unless NP has slightlysuperpolynomial time algorithms. This closes the gap (up to low-orderterms) between the ratio of approximation achievable by the greedyalogorithm (which is (1 - <?Pub Fmt italic>o<?Pub Fmt /italic>(1)) lnn), and provious results of Lund and Yanakakis, that showed hardness ofapproximation within a ratio of <inline-equation><f><fen lp=\"par\"><lim align=\"r\"><op><rf>log</rf></op><ll>2</ll></lim>n<rp post=\"par\"></fen>/2\u22430.72</f></inline-equation> ln <?Pub Fmt italic>n<?Pub Fmt /italic>. For max<?Pub Fmt italic>k<?Pub Fmt /italic>-cover, we show an approximationthreshold of (1 - 1/<?Pub   Fmt italic>e<?Pub Fmt /italic>)(up tolow-order terms), under assumption that <inline-equation><f>P\u2260NP</f><?Pub   Caret></inline-equation>."
            },
            "slug": "A-threshold-of-ln-n-for-approximating-set-cover-Feige",
            "title": {
                "fragments": [],
                "text": "A threshold of ln n for approximating set cover"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is proved that (1 - <?Pub Fmt italic>o<?Pub FMT /italic>(1) ln n setcover is a threshold below which setcover cannot be approximated efficiently, unless NP has slightlysuperpolynomial time algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145162067"
                        ],
                        "name": "A. Blake",
                        "slug": "A.-Blake",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Blake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blake"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 136
                            }
                        ],
                        "text": "Leclerc derives energies somewhat different from (37) and optimizes them using continuation technique similar to graduated nonconvexity (Blake and Zisserman 1987)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13115760,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "048e3a0904f7d964a0ade5da031a585dadc5a92f",
            "isKey": false,
            "numCitedBy": 1908,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Visual-Reconstruction-Blake-Zisserman",
            "title": {
                "fragments": [],
                "text": "Visual Reconstruction"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Int J Comput Vis"
            },
            "venue": {
                "fragments": [],
                "text": "Int J Comput Vis"
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Kolmogorov . An Experimental Comparison of MinCut / MaxFlow Algorithms for Energy Minimization in Vision"
            },
            "venue": {
                "fragments": [],
                "text": "International Conf . on Computer Vision ( ICCV )"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning associative Markov networks. In International conf. on machine learning (ICML)"
            },
            "venue": {
                "fragments": [],
                "text": "Learning associative Markov networks. In International conf. on machine learning (ICML)"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Vector quantization and signal compression . Norwell: Kluwer Academic"
            },
            "venue": {
                "fragments": [],
                "text": "Vector quantization and signal compression . Norwell: Kluwer Academic"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 108
                            }
                        ],
                        "text": "Finally, the greedy algorithm may be enhanced by applying the tabu search meta-heuristic to the UFL problem (Sun 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A tabu search heuristic for the uncapacitated facility location problem. In Metaheuristic optimization via memory and evolution: Vol"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Kolmogorov . Spatially Coherent Clustering with Graph Cuts"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 42,
            "methodology": 32
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 80,
        "totalPages": 8
    },
    "page_url": "https://www.semanticscholar.org/paper/Fast-Approximate-Energy-Minimization-with-Label-Delong-Osokin/ce51aa425cccb509830f5e5882230ff976344cc5?sort=total-citations"
}