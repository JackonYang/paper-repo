{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144638694"
                        ],
                        "name": "Adam Coates",
                        "slug": "Adam-Coates",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Coates",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adam Coates"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697141"
                        ],
                        "name": "Honglak Lee",
                        "slug": "Honglak-Lee",
                        "structuredName": {
                            "firstName": "Honglak",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Honglak Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 78
                            }
                        ],
                        "text": "As with the full CIFAR dataset, we note that it was not possible to achieve equivalent performance by merely expanding the first layer or by using either of the alternative receptive field structures (which, again, make minimal gains over a single layer)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 14
                            }
                        ],
                        "text": "In this work we propose a way to address the problem of choosing receptive fields that is not only a flexible addition to unsupervised learning and pre-training pipelines, but that can scale up to the extremely large networks used in state-of-the-art systems."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 156
                            }
                        ],
                        "text": "Much of this line of inquiry has sought to identify the best choices of network parameters such as size, activation function, pooling method and so on [12, 5, 3, 16, 19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 308212,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "be9a17321537d9289875fe475b71f4821457b435",
            "isKey": false,
            "numCitedBy": 2600,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "A great deal of research has focused on algorithms for learning features from unlabeled data. Indeed, much progress has been made on benchmark datasets like NORB and CIFAR by employing increasingly complex unsupervised learning algorithms and deep models. In this paper, however, we show that several simple factors, such as the number of hidden nodes in the model, may be more important to achieving high performance than the learning algorithm or the depth of the model. Specifically, we will apply several othe-shelf feature learning algorithms (sparse auto-encoders, sparse RBMs, K-means clustering, and Gaussian mixtures) to CIFAR, NORB, and STL datasets using only singlelayer networks. We then present a detailed analysis of the eect of changes in the model setup: the receptive field size, number of hidden nodes (features), the step-size (\u201cstride\u201d) between extracted features, and the eect of whitening. Our results show that large numbers of hidden nodes and dense feature extraction are critical to achieving high performance\u2014so critical, in fact, that when these parameters are pushed to their limits, we achieve state-of-the-art performance on both CIFAR-10 and NORB using only a single layer of features. More surprisingly, our best performance is based on K-means clustering, which is extremely fast, has no hyperparameters to tune beyond the model structure itself, and is very easy to implement. Despite the simplicity of our system, we achieve accuracy beyond all previously published results on the CIFAR-10 and NORB datasets (79.6% and 97.2% respectively)."
            },
            "slug": "An-Analysis-of-Single-Layer-Networks-in-Feature-Coates-Ng",
            "title": {
                "fragments": [],
                "text": "An Analysis of Single-Layer Networks in Unsupervised Feature Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The results show that large numbers of hidden nodes and dense feature extraction are critical to achieving high performance\u2014so critical, in fact, that when these parameters are pushed to their limits, they achieve state-of-the-art performance on both CIFAR-10 and NORB using only a single layer of features."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144717963"
                        ],
                        "name": "Karol Gregor",
                        "slug": "Karol-Gregor",
                        "structuredName": {
                            "firstName": "Karol",
                            "lastName": "Gregor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karol Gregor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 1
                            }
                        ],
                        "text": "These methods have many advantages but require us to specify a topography first, then solve a large-scale optimization problem in order to organize our features according to the given topographic layout."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15372343,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "31f04f8f83365fabf7ba9c9be1179c0da6815128",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new neural architecture and an unsupervised algorithm for learning invariant representations from temporal sequence of images. The system uses two groups of complex cells whose outputs are combined multiplicatively: one that represents the content of the image, constrained to be constant over several consecutive frames, and one that represents the precise location of features, which is allowed to vary over time but constrained to be sparse. The architecture uses an encoder to extract features, and a decoder to reconstruct the input from the features. The method was applied to patches extracted from consecutive movie frames and produces orientation and frequency selective units analogous to the complex cells in V1. An extension of the method is proposed to train a network composed of units with local receptive field spread over a large image of arbitrary size. A layer of complex cells, subject to sparsity constraints, pool feature units over overlapping local neighborhoods, which causes the feature units to organize themselves into pinwheel patterns of orientation-selective receptive fields, similar to those observed in the mammalian visual cortex. A feed-forward encoder efficiently computes the feature representation of full images."
            },
            "slug": "Emergence-of-Complex-Like-Cells-in-a-Temporal-with-Gregor-LeCun",
            "title": {
                "fragments": [],
                "text": "Emergence of Complex-Like Cells in a Temporal Product Network with Local Receptive Fields"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A new neural architecture and an unsupervised algorithm for learning invariant representations from temporal sequence of images and an extension of the method is proposed to train a network composed of units with local receptive field spread over a large image of arbitrary size."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064160"
                        ],
                        "name": "A. Krizhevsky",
                        "slug": "A.-Krizhevsky",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Krizhevsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krizhevsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15295567,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bea5780d621e669e8069f05d0f2fc0db9df4b50f",
            "isKey": false,
            "numCitedBy": 440,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe how to train a two-layer convolutional Deep Belief Network (DBN) on the 1.6 million tiny images dataset. When training a convolutional DBN, one must decide what to do with the edge pixels of teh images. As the pixels near the edge of an image contribute to the fewest convolutional lter outputs, the model may see it t to tailor its few convolutional lters to better model the edge pixels. This is undesirable becaue it usually comes at the expense of a good model for the interior parts of the image. We investigate several ways of dealing with the edge pixels when training a convolutional DBN. Using a combination of locally-connected convolutional units and globally-connected units, as well as a few tricks to reduce the e ects of over tting, we achieve state-of-the-art performance in the classi cation task of the CIFAR-10 subset of the tiny images dataset."
            },
            "slug": "Convolutional-Deep-Belief-Networks-on-CIFAR-10-Krizhevsky",
            "title": {
                "fragments": [],
                "text": "Convolutional Deep Belief Networks on CIFAR-10"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Using a combination of locally-connected convolutional units and globally-connected units, as well as a few tricks to reduce the e ects of over tting, the DBN achieves state-of-the-art performance in the classi cation task of the CIFAR-10 subset of the tiny images dataset."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697141"
                        ],
                        "name": "Honglak Lee",
                        "slug": "Honglak-Lee",
                        "structuredName": {
                            "firstName": "Honglak",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Honglak Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785346"
                        ],
                        "name": "Roger B. Grosse",
                        "slug": "Roger-B.-Grosse",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Grosse",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roger B. Grosse"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2615814"
                        ],
                        "name": "R. Ranganath",
                        "slug": "R.-Ranganath",
                        "structuredName": {
                            "firstName": "Rajesh",
                            "lastName": "Ranganath",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ranganath"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 236,
                                "start": 235
                            }
                        ],
                        "text": "For instance, in the first layer of a network used for object recognition it is common to connect each feature extractor to a small rectangular area within a larger image instead of connecting every feature to the entire image [14, 15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12008458,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e80f755bcbf10479afd2338cec05211fdbd325c",
            "isKey": false,
            "numCitedBy": 2510,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "There has been much interest in unsupervised learning of hierarchical generative models such as deep belief networks. Scaling such models to full-sized, high-dimensional images remains a difficult problem. To address this problem, we present the convolutional deep belief network, a hierarchical generative model which scales to realistic image sizes. This model is translation-invariant and supports efficient bottom-up and top-down probabilistic inference. Key to our approach is probabilistic max-pooling, a novel technique which shrinks the representations of higher layers in a probabilistically sound way. Our experiments show that the algorithm learns useful high-level visual features, such as object parts, from unlabeled images of objects and natural scenes. We demonstrate excellent performance on several visual recognition tasks and show that our model can perform hierarchical (bottom-up and top-down) inference over full-sized images."
            },
            "slug": "Convolutional-deep-belief-networks-for-scalable-of-Lee-Grosse",
            "title": {
                "fragments": [],
                "text": "Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "The convolutional deep belief network is presented, a hierarchical generative model which scales to realistic image sizes and is translation-invariant and supports efficient bottom-up and top-down probabilistic inference."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '09"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30017846"
                        ],
                        "name": "N. Pinto",
                        "slug": "N.-Pinto",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Pinto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Pinto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3250342"
                        ],
                        "name": "D. Doukhan",
                        "slug": "D.-Doukhan",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doukhan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doukhan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1865831"
                        ],
                        "name": "J. DiCarlo",
                        "slug": "J.-DiCarlo",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "DiCarlo",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. DiCarlo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2042941"
                        ],
                        "name": "D. Cox",
                        "slug": "D.-Cox",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Cox",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cox"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 17
                            }
                        ],
                        "text": "Pinto et al. [17], on the other hand, use a screening procedure to choose from amongst large numbers of randomly composed networks, collecting the best performing networks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 215779860,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "d46fd54609e09bcd135fd28750003185a5ee4125",
            "isKey": false,
            "numCitedBy": 254,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "While many models of biological object recognition share a common set of \u201cbroad-stroke\u201d properties, the performance of any one model depends strongly on the choice of parameters in a particular instantiation of that model\u2014e.g., the number of units per layer, the size of pooling kernels, exponents in normalization operations, etc. Since the number of such parameters (explicit or implicit) is typically large and the computational cost of evaluating one particular parameter set is high, the space of possible model instantiations goes largely unexplored. Thus, when a model fails to approach the abilities of biological visual systems, we are left uncertain whether this failure is because we are missing a fundamental idea or because the correct \u201cparts\u201d have not been tuned correctly, assembled at sufficient scale, or provided with enough training. Here, we present a high-throughput approach to the exploration of such parameter sets, leveraging recent advances in stream processing hardware (high-end NVIDIA graphic cards and the PlayStation 3's IBM Cell Processor). In analogy to high-throughput screening approaches in molecular biology and genetics, we explored thousands of potential network architectures and parameter instantiations, screening those that show promising object recognition performance for further analysis. We show that this approach can yield significant, reproducible gains in performance across an array of basic object recognition tasks, consistently outperforming a variety of state-of-the-art purpose-built vision systems from the literature. As the scale of available computational power continues to expand, we argue that this approach has the potential to greatly accelerate progress in both artificial vision and our understanding of the computational underpinning of biological vision."
            },
            "slug": "A-High-Throughput-Screening-Approach-to-Discovering-Pinto-Doukhan",
            "title": {
                "fragments": [],
                "text": "A High-Throughput Screening Approach to Discovering Good Forms of Biologically Inspired Visual Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This approach can yield significant, reproducible gains in performance across an array of basic object recognition tasks, consistently outperforming a variety of state-of-the-art purpose-built vision systems from the literature."
            },
            "venue": {
                "fragments": [],
                "text": "PLoS Comput. Biol."
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144638694"
                        ],
                        "name": "Adam Coates",
                        "slug": "Adam-Coates",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Coates",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adam Coates"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 29
                            }
                        ],
                        "text": "For this reason we have also performed classification using 400 labeled examples per class.3 Our results for this scenario are in Table 2."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 191,
                                "start": 188
                            }
                        ],
                        "text": "There are now many results in the literature indicating that large networks with thousands of unique feature extractors are top competitors in applications and benchmarks (e.g., [4, 6, 9, 19])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Finally, we will also provide test results using a larger 1st layer representation (K1 = 4800 maps) to verify that the performance gains we achieve are not merely the result of passing more projections of the data to the supervised classification stage."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 29
                            }
                        ],
                        "text": "The architecture proposed by [6] works by constructing a feature representation of a small image patch (say, a 6-by-6 pixel region) and then extracting these features from many overlapping patches within a larger image (much like a convolutional neural net)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 81
                            }
                        ],
                        "text": "Using our method in conjunction with the pipeline proposed by [6], we demonstrate the ability to train multi-layered networks using only vector quantization as our unsupervised learning module."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 36
                            }
                        ],
                        "text": "We have adopted the architecture of [6], which has previously been applied with success to image recognition problems."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 22
                            }
                        ],
                        "text": "Then the system in [6] applies the following procedure to learn a new representation of an image patch:\n1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 1
                            }
                        ],
                        "text": "In this paper, we propose a method to automatically choose such receptive fields in situations where we do not know how to specify them by hand\u2014a situation that, as we will explain, is commonly encountered in deep networks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 200
                            }
                        ],
                        "text": "\u2026of feature responses.1 We will then explain how our method integrates with a typical learning pipeline and, in particular, how to couple our algorithm with the feature learning system proposed in [6], which we adopt since it has been shown previously to perform well on image recognition tasks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12132619,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6f568d757d2c1ab42f2006faa25690b74c3d2d44",
            "isKey": false,
            "numCitedBy": 600,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "While vector quantization (VQ) has been applied widely to generate features for visual recognition problems, much recent work has focused on more powerful methods. In particular, sparse coding has emerged as a strong alternative to traditional VQ approaches and has been shown to achieve consistently higher performance on benchmark datasets. Both approaches can be split into a training phase, where the system learns a dictionary of basis functions, and an encoding phase, where the dictionary is used to extract features from new inputs. In this work, we investigate the reasons for the success of sparse coding over VQ by decoupling these phases, allowing us to separate out the contributions of training and encoding in a controlled way. Through extensive experiments on CIFAR, NORB and Caltech 101 datasets, we compare several training and encoding schemes, including sparse coding and a form of VQ with a soft threshold activation function. Our results show not only that we can use fast VQ algorithms for training, but that we can just as well use randomly chosen exemplars from the training set. Rather than spend resources on training, we find it is more important to choose a good encoder\u2014which can often be a simple feed forward non-linearity. Our results include state-of-the-art performance on both CIFAR and NORB."
            },
            "slug": "The-Importance-of-Encoding-Versus-Training-with-and-Coates-Ng",
            "title": {
                "fragments": [],
                "text": "The Importance of Encoding Versus Training with Sparse Coding and Vector Quantization"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work investigates the reasons for the success of sparse coding over VQ by decoupling these phases, allowing us to separate out the contributions of training and encoding in a controlled way and shows not only that it can use fast VQ algorithms for training, but that they can just as well use randomly chosen exemplars from the training set."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34927843"
                        ],
                        "name": "Andrew M. Saxe",
                        "slug": "Andrew-M.-Saxe",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Saxe",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew M. Saxe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2572525"
                        ],
                        "name": "Pang Wei Koh",
                        "slug": "Pang-Wei-Koh",
                        "structuredName": {
                            "firstName": "Pang Wei",
                            "lastName": "Koh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pang Wei Koh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2122924605"
                        ],
                        "name": "Zhenghao Chen",
                        "slug": "Zhenghao-Chen",
                        "structuredName": {
                            "firstName": "Zhenghao",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhenghao Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1997588"
                        ],
                        "name": "M. Bhand",
                        "slug": "M.-Bhand",
                        "structuredName": {
                            "firstName": "Maneesh",
                            "lastName": "Bhand",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bhand"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39086009"
                        ],
                        "name": "B. Suresh",
                        "slug": "B.-Suresh",
                        "structuredName": {
                            "firstName": "Bipin",
                            "lastName": "Suresh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Suresh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 30
                            }
                        ],
                        "text": "For instance, Saxe et al. [18] propose using randomly initialized networks (forgoing the expense of training) to search for a high-performing structure."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8907667,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "265069b3670930fd884b02062d7e7b79ff2a49d5",
            "isKey": false,
            "numCitedBy": 390,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently two anomalous results in the literature have shown that certain feature learning architectures can yield useful features for object recognition tasks even with untrained, random weights. In this paper we pose the question: why do random weights sometimes do so well? Our answer is that certain convolutional pooling architectures can be inherently frequency selective and translation invariant, even with random weights. Based on this we demonstrate the viability of extremely fast architecture search by using random weights to evaluate candidate architectures, thereby sidestepping the time-consuming learning process. We then show that a surprising fraction of the performance of certain state-of-the-art methods can be attributed to the architecture alone."
            },
            "slug": "On-Random-Weights-and-Unsupervised-Feature-Learning-Saxe-Koh",
            "title": {
                "fragments": [],
                "text": "On Random Weights and Unsupervised Feature Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The answer is that certain convolutional pooling architectures can be inherently frequency selective and translation invariant, even with random weights, and the viability of extremely fast architecture search is demonstrated by using random weights to evaluate candidate architectures, thereby sidestepping the time-consuming learning process."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "90841478"
                        ],
                        "name": "Y-Lan Boureau",
                        "slug": "Y-Lan-Boureau",
                        "structuredName": {
                            "firstName": "Y-Lan",
                            "lastName": "Boureau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y-Lan Boureau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144570279"
                        ],
                        "name": "F. Bach",
                        "slug": "F.-Bach",
                        "structuredName": {
                            "firstName": "Francis",
                            "lastName": "Bach",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Bach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 160
                            }
                        ],
                        "text": "Much of this line of inquiry has sought to identify the best choices of network parameters such as size, activation function, pooling method and so on [12, 5, 3, 16, 19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 80
                            }
                        ],
                        "text": "Finally, we will also provide test results using a larger 1st layer representation (K1 = 4800 maps) to verify that the performance gains we achieve are not merely the result of passing more projections of the data to the supervised classification stage."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 90113,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "498efaa51f5eda731dc6199c3547b9465717fa68",
            "isKey": false,
            "numCitedBy": 1101,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Many successful models for scene or object recognition transform low-level descriptors (such as Gabor filter responses, or SIFT descriptors) into richer representations of intermediate complexity. This process can often be broken down into two steps: (1) a coding step, which performs a pointwise transformation of the descriptors into a representation better adapted to the task, and (2) a pooling step, which summarizes the coded features over larger neighborhoods. Several combinations of coding and pooling schemes have been proposed in the literature. The goal of this paper is threefold. We seek to establish the relative importance of each step of mid-level feature extraction through a comprehensive cross evaluation of several types of coding modules (hard and soft vector quantization, sparse coding) and pooling schemes (by taking the average, or the maximum), which obtains state-of-the-art performance or better on several recognition benchmarks. We show how to improve the best performing coding scheme by learning a supervised discriminative dictionary for sparse coding. We provide theoretical and empirical insight into the remarkable performance of max pooling. By teasing apart components shared by modern mid-level feature extractors, our approach aims to facilitate the design of better recognition architectures."
            },
            "slug": "Learning-mid-level-features-for-recognition-Boureau-Bach",
            "title": {
                "fragments": [],
                "text": "Learning mid-level features for recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work seeks to establish the relative importance of each step of mid-level feature extraction through a comprehensive cross evaluation of several types of coding modules and pooling schemes and shows how to improve the best performing coding scheme by learning a supervised discriminative dictionary for sparse coding."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895356"
                        ],
                        "name": "D. Ciresan",
                        "slug": "D.-Ciresan",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Ciresan",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ciresan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2514691"
                        ],
                        "name": "U. Meier",
                        "slug": "U.-Meier",
                        "structuredName": {
                            "firstName": "Ueli",
                            "lastName": "Meier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Meier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2426718"
                        ],
                        "name": "Jonathan Masci",
                        "slug": "Jonathan-Masci",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Masci",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Masci"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6803671"
                        ],
                        "name": "L. Gambardella",
                        "slug": "L.-Gambardella",
                        "structuredName": {
                            "firstName": "Luca",
                            "lastName": "Gambardella",
                            "middleNames": [
                                "Maria"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gambardella"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 65
                            }
                        ],
                        "text": "This is similar to the structure commonly employed by prior work [4, 12], but here we are able to choose receptive fields that span several feature maps in a deliberate way while also exploiting knowledge of the spatial structure."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 147
                            }
                        ],
                        "text": "Thus when we train a second layer of features we must typically resort to connecting each feature to every input map or to a random subset of maps [12, 4] (though we may still take advantage of the remaining spatial organization within each map)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 135
                            }
                        ],
                        "text": "This problem is exacerbated further when we try to use very large numbers of maps which are often necessary to achieve top performance [4, 5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 135
                            }
                        ],
                        "text": "This trick dramatically reduces the number of parameters that must be trained and is a key element of several state-of-the-art systems [4, 19, 6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 91
                            }
                        ],
                        "text": "Each 2D grid of 28-by28 feature responses for a single filter is frequently called a \u201cmap\u201d [14, 4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8432978,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "82b9099ddf092463f497bd48bb112c46ca52c4d1",
            "isKey": true,
            "numCitedBy": 257,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a fast, fully parameterizable GPU implementation of Convolutional Neural Network variants. Our feature extractors are neither carefully designed nor pre-wired, but rather learned in a supervised way. Our deep hierarchical architectures achieve the best published results on benchmarks for object classification (NORB, CIFAR10) and handwritten digit recognition (MNIST), with error rates of 2.53%, 19.51%, 0.35%, respectively. Deep nets trained by simple back-propagation perform better than more shallow ones. Learning is surprisingly rapid. NORB is completely trained within five epochs. Test error rates on MNIST drop to 2.42%, 0.97% and 0.48% after 1, 3 and 17 epochs, respectively."
            },
            "slug": "High-Performance-Neural-Networks-for-Visual-Object-Ciresan-Meier",
            "title": {
                "fragments": [],
                "text": "High-Performance Neural Networks for Visual Object Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A fast, fully parameterizable GPU implementation of Convolutional Neural Network variants and their feature extractors are neither carefully designed nor pre-wired, but rather learned in a supervised way."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2077257730"
                        ],
                        "name": "Kevin Jarrett",
                        "slug": "Kevin-Jarrett",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Jarrett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Jarrett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2645384"
                        ],
                        "name": "K. Kavukcuoglu",
                        "slug": "K.-Kavukcuoglu",
                        "structuredName": {
                            "firstName": "Koray",
                            "lastName": "Kavukcuoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kavukcuoglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706809"
                        ],
                        "name": "Marc'Aurelio Ranzato",
                        "slug": "Marc'Aurelio-Ranzato",
                        "structuredName": {
                            "firstName": "Marc'Aurelio",
                            "lastName": "Ranzato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc'Aurelio Ranzato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 151
                            }
                        ],
                        "text": "Much of this line of inquiry has sought to identify the best choices of network parameters such as size, activation function, pooling method and so on [12, 5, 3, 16, 19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Finally, we will also provide test results using a larger 1st layer representation (K1 = 4800 maps) to verify that the performance gains we achieve are not merely the result of passing more projections of the data to the supervised classification stage."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 164
                            }
                        ],
                        "text": "Thus when we train a second layer of features we must typically resort to connecting each feature to every input map or to a random subset of maps [12, 4] (though we may still take advantage of the remaining spatial organization within each map)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206769720,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1f88427d7aa8225e47f946ac41a0667d7b69ac52",
            "isKey": false,
            "numCitedBy": 2085,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "In many recent object recognition systems, feature extraction stages are generally composed of a filter bank, a non-linear transformation, and some sort of feature pooling layer. Most systems use only one stage of feature extraction in which the filters are hard-wired, or two stages where the filters in one or both stages are learned in supervised or unsupervised mode. This paper addresses three questions: 1. How does the non-linearities that follow the filter banks influence the recognition accuracy? 2. does learning the filter banks in an unsupervised or supervised manner improve the performance over random filters or hardwired filters? 3. Is there any advantage to using an architecture with two stages of feature extraction, rather than one? We show that using non-linearities that include rectification and local contrast normalization is the single most important ingredient for good accuracy on object recognition benchmarks. We show that two stages of feature extraction yield better accuracy than one. Most surprisingly, we show that a two-stage system with random filters can yield almost 63% recognition rate on Caltech-101, provided that the proper non-linearities and pooling layers are used. Finally, we show that with supervised refinement, the system achieves state-of-the-art performance on NORB dataset (5.6%) and unsupervised pre-training followed by supervised refinement produces good accuracy on Caltech-101 (\u226b 65%), and the lowest known error rate on the undistorted, unprocessed MNIST dataset (0.53%)."
            },
            "slug": "What-is-the-best-multi-stage-architecture-for-Jarrett-Kavukcuoglu",
            "title": {
                "fragments": [],
                "text": "What is the best multi-stage architecture for object recognition?"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is shown that using non-linearities that include rectification and local contrast normalization is the single most important ingredient for good accuracy on object recognition benchmarks and that two stages of feature extraction yield better accuracy than one."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34071791"
                        ],
                        "name": "Pierre Garrigues",
                        "slug": "Pierre-Garrigues",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Garrigues",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pierre Garrigues"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708655"
                        ],
                        "name": "B. Olshausen",
                        "slug": "B.-Olshausen",
                        "structuredName": {
                            "firstName": "Bruno",
                            "lastName": "Olshausen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Olshausen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 146
                            }
                        ],
                        "text": "Similar methods can be obtained by imposing group sparsity constraints so that features within a group tend to be on or off at the same time [7, 8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2118934,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "511fe09bb782b47b64a4a1dc9d0ca899ba0e64a9",
            "isKey": false,
            "numCitedBy": 111,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a class of sparse coding models that utilizes a Laplacian Scale Mixture (LSM) prior to model dependencies among coefficients. Each coefficient is modeled as a Laplacian distribution with a variable scale parameter, with a Gamma distribution prior over the scale parameter. We show that, due to the conjugacy of the Gamma prior, it is possible to derive efficient inference procedures for both the coefficients and the scale parameter. When the scale parameters of a group of coefficients are combined into a single variable, it is possible to describe the dependencies that occur due to common amplitude fluctuations among coefficients, which have been shown to constitute a large fraction of the redundancy in natural images [1]. We show that, as a consequence of this group sparse coding, the resulting inference of the coefficients follows a divisive normalization rule, and that this may be efficiently implemented in a network architecture similar to that which has been proposed to occur in primary visual cortex. We also demonstrate improvements in image coding and compressive sensing recovery using the LSM model."
            },
            "slug": "Group-Sparse-Coding-with-a-Laplacian-Scale-Mixture-Garrigues-Olshausen",
            "title": {
                "fragments": [],
                "text": "Group Sparse Coding with a Laplacian Scale Mixture Prior"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A class of sparse coding models that utilizes a Laplacian Scale Mixture (LSM) prior to model dependencies among coefficients follows a divisive normalization rule, and this may be efficiently implemented in a network architecture similar to that which has been proposed to occur in primary visual cortex."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070963479"
                        ],
                        "name": "Dominik Scherer",
                        "slug": "Dominik-Scherer",
                        "structuredName": {
                            "firstName": "Dominik",
                            "lastName": "Scherer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dominik Scherer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113785713"
                        ],
                        "name": "Andreas C. M\u00fcller",
                        "slug": "Andreas-C.-M\u00fcller",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "M\u00fcller",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas C. M\u00fcller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699019"
                        ],
                        "name": "Sven Behnke",
                        "slug": "Sven-Behnke",
                        "structuredName": {
                            "firstName": "Sven",
                            "lastName": "Behnke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sven Behnke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 143
                            }
                        ],
                        "text": "This trick dramatically reduces the number of parameters that must be trained and is a key element of several state-of-the-art systems [4, 19, 6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 169
                            }
                        ],
                        "text": "Much of this line of inquiry has sought to identify the best choices of network parameters such as size, activation function, pooling method and so on [12, 5, 3, 16, 19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 2
                            }
                        ],
                        "text": "A major obstacle to scaling up these representations further is the blowup in the number of network parameters: for n input features, a complete representation with n features requires a matrix of n2 weights\u2014one weight for every feature and input."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18388506,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5d21006fa32ff69f6b0a646f26ce0db84f2f4d33",
            "isKey": false,
            "numCitedBy": 1285,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "A common practice to gain invariant features in object recognition models is to aggregate multiple low-level features over a small neighborhood. However, the differences between those models makes a comparison of the properties of different aggregation functions hard. Our aim is to gain insight into different functions by directly comparing them on a fixed architecture for several common object recognition tasks. Empirical results show that a maximum pooling operation significantly outperforms subsampling operations. Despite their shift-invariant properties, overlapping pooling windows are no significant improvement over nonoverlapping pooling windows. By applying this knowledge, we achieve state-of-the-art error rates of 4.57% on the NORB normalized-uniform dataset and 5.6% on the NORB jittered-cluttered dataset."
            },
            "slug": "Evaluation-of-Pooling-Operations-in-Convolutional-Scherer-M\u00fcller",
            "title": {
                "fragments": [],
                "text": "Evaluation of Pooling Operations in Convolutional Architectures for Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The aim is to gain insight into different functions by directly comparing them on a fixed architecture for several common object recognition tasks, and empirical results show that a maximum pooling operation significantly outperforms subsampling operations."
            },
            "venue": {
                "fragments": [],
                "text": "ICANN"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13919023"
                        ],
                        "name": "F. Huang",
                        "slug": "F.-Huang",
                        "structuredName": {
                            "firstName": "Fu",
                            "lastName": "Huang",
                            "middleNames": [
                                "Jie"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 192
                            }
                        ],
                        "text": "There are now many results in the literature indicating that large networks with thousands of unique feature extractors are top competitors in applications and benchmarks (e.g., [4, 6, 9, 19])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9123239,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cf03fdf52dd6e4249cbbdbd0bffbbbe5ca389feb",
            "isKey": false,
            "numCitedBy": 349,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "The detection and recognition of generic object categories with invariance to viewpoint, illumination, and clutter requires the combination of a feature extractor and a classifier. We show that architectures such as convolutional networks are good at learning invariant features, but not always optimal for classification, while Support Vector Machines are good at producing decision surfaces from wellbehaved feature vectors, but cannot learn complicated invariances. We present a hybrid system where a convolutional network is trained to detect and recognize generic objects, and a Gaussian-kernel SVM is trained from the features learned by the convolutional network. Results are given on a large generic object recognition task with six categories (human figures, four-legged animals, airplanes, trucks, cars, and \"none of the above\"), with multiple instances of each object category under various poses, illuminations, and backgrounds. On the test set, which contains different object instances than the training set, an SVM alone yields a 43.3% error rate, a convolutional net alone yields 7.2% and an SVM on top of features produced by the convolutional net yields 5.9%."
            },
            "slug": "Large-scale-Learning-with-SVM-and-Convolutional-for-Huang-LeCun",
            "title": {
                "fragments": [],
                "text": "Large-scale Learning with SVM and Convolutional for Generic Object Categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that architectures such as convolutional networks are good at learning invariant features, but not always optimal for classification, while Support Vector Machines are good for producing decision surfaces from wellbehaved feature vectors, but cannot learn complicated invariances."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144187218"
                        ],
                        "name": "A. J. Bell",
                        "slug": "A.-J.-Bell",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Bell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. J. Bell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 228,
                                "start": 225
                            }
                        ],
                        "text": "\u2026throughout, and propose some extensions, it can be replaced by many other choices such as the mutual information between two features.\nbetween features xj and xk as the correlation between the squared responses:\nS[xj , xk] = corr(x2j , x 2 k) = E [ x2jx 2 k \u2212 1 ] / \u221a E [ x4j \u2212 1 ] E [x4k \u2212 1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6219133,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ca1d23be869380ac9e900578c601c2d1febcc0c9",
            "isKey": false,
            "numCitedBy": 2373,
            "numCiting": 90,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-\u201cindependent-components\u201d-of-natural-scenes-are-Bell-Sejnowski",
            "title": {
                "fragments": [],
                "text": "The \u201cindependent components\u201d of natural scenes are edge filters"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13919023"
                        ],
                        "name": "F. Huang",
                        "slug": "F.-Huang",
                        "structuredName": {
                            "firstName": "Fu",
                            "lastName": "Huang",
                            "middleNames": [
                                "Jie"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 7
                            }
                        ],
                        "text": "Though there are still spatial relationships amongst the feature values within each map, it is not clear how two features in different maps are related."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 230
                            }
                        ],
                        "text": "For instance, in the first layer of a network used for object recognition it is common to connect each feature extractor to a small rectangular area within a larger image instead of connecting every feature to the entire image [14, 15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 84
                            }
                        ],
                        "text": "Finally, we will also provide test results using a larger 1st layer representation (K1 = 4800 maps) to verify that the performance gains we achieve are not merely the result of passing more projections of the data to the supervised classification stage."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 712708,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f354310098e09c1e1dc88758fca36767fd9d084d",
            "isKey": false,
            "numCitedBy": 1306,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We assess the applicability of several popular learning methods for the problem of recognizing generic visual categories with invariance to pose, lighting, and surrounding clutter. A large dataset comprising stereo image pairs of 50 uniform-colored toys under 36 azimuths, 9 elevations, and 6 lighting conditions was collected (for a total of 194,400 individual images). The objects were 10 instances of 5 generic categories: four-legged animals, human figures, airplanes, trucks, and cars. Five instances of each category were used for training, and the other five for testing. Low-resolution grayscale images of the objects with various amounts of variability and surrounding clutter were used for training and testing. Nearest neighbor methods, support vector machines, and convolutional networks, operating on raw pixels or on PCA-derived features were tested. Test error rates for unseen object instances placed on uniform backgrounds were around 13% for SVM and 7% for convolutional nets. On a segmentation/recognition task with highly cluttered images, SVM proved impractical, while convolutional nets yielded 16/7% error. A real-time version of the system was implemented that can detect and classify objects in natural scenes at around 10 frames per second."
            },
            "slug": "Learning-methods-for-generic-object-recognition-to-LeCun-Huang",
            "title": {
                "fragments": [],
                "text": "Learning methods for generic object recognition with invariance to pose and lighting"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A real-time version of the system was implemented that can detect and classify objects in natural scenes at around 10 frames per second and proved impractical, while convolutional nets yielded 16/7% error."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689350"
                        ],
                        "name": "Eero P. Simoncelli",
                        "slug": "Eero-P.-Simoncelli",
                        "structuredName": {
                            "firstName": "Eero",
                            "lastName": "Simoncelli",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eero P. Simoncelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47590737"
                        ],
                        "name": "O. Schwartz",
                        "slug": "O.-Schwartz",
                        "structuredName": {
                            "firstName": "Odelia",
                            "lastName": "Schwartz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Schwartz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This statistical measure of similarity is motivated by empirical observations of neurons and has been used in other analytical models [20]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 152931,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "a6da157d4d14fb88fab97486eb75ed71dbc02e13",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We examine the statistics of natural monochromatic images decomposed using a multi-scale wavelet basis. Although the coefficients of this representation are nearly decorrelated, they exhibit important higher-order statistical dependencies that cannot be eliminated with purely linear procssing. In particular, rectified coefficients corresponding to basis functions at neighboring spatial positions, orientations and scales are highly correlated. A method of removing these dependencies is to divide each coefficient by a weighted combination of its rectified neighbors. Several successful models of the steady -state behavior of neurons in primary visual cortex are based on such \"divisive normalization\" computations, and thus our analysis provides a theoretical justification for these models. Perhaps more importantly, the statistical measurements explicitly specify the weights that should be used in computing the normalization signal. We demonstrate that this weighting is qualitatively consistent with recent physiological experiments that characterize the suppressive effect of stimuli presented outside of the classical receptive field. Our observations thus provide evidence for the hypothesis that early visual neural processing is well matched to these statistical properties of images."
            },
            "slug": "Modeling-Surround-Suppression-in-V1-Neurons-with-a-Simoncelli-Schwartz",
            "title": {
                "fragments": [],
                "text": "Modeling Surround Suppression in V1 Neurons with a Statistically Derived Normalization Model"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "The statistics of natural monochromatic images decomposed using a multi-scale wavelet basis are examined to provide evidence for the hypothesis that early visual neural processing is well matched to these statistical properties of images."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722180"
                        ],
                        "name": "Ryan P. Adams",
                        "slug": "Ryan-P.-Adams",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "Adams",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan P. Adams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1831395"
                        ],
                        "name": "H. Wallach",
                        "slug": "H.-Wallach",
                        "structuredName": {
                            "firstName": "Hanna",
                            "lastName": "Wallach",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wallach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744700"
                        ],
                        "name": "Zoubin Ghahramani",
                        "slug": "Zoubin-Ghahramani",
                        "structuredName": {
                            "firstName": "Zoubin",
                            "lastName": "Ghahramani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zoubin Ghahramani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2941742,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "abfc7be42901be89d4508de6c0befe58523c3728",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep belief networks are a powerful way to model complex probability distributions. However, it is difficult to learn the structure of a belief network, particularly one with hidden units. The Indian buffet process has been used as a nonparametric Bayesian prior on the structure of a directed belief network with a single infinitely wide hidden layer. Here, we introduce the cascading Indian buffet process (CIBP), which provides a prior on the structure of a layered, directed belief network that is unbounded in both depth and width, yet allows tractable inference. We use the CIBP prior with the nonlinear Gaussian belief network framework to allow each unit to vary its behavior between discrete and continuous representations. We use Markov chain Monte Carlo for inference in this model and explore the structures learned on image data."
            },
            "slug": "Learning-the-Structure-of-Deep-Sparse-Graphical-Adams-Wallach",
            "title": {
                "fragments": [],
                "text": "Learning the Structure of Deep Sparse Graphical Models"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The cascading Indian buffet process (CIBP) is introduced, which provides a prior on the structure of a layered, directed belief network that is unbounded in both depth and width, yet allows tractable inference."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073603971"
                        ],
                        "name": "Vinod Nair",
                        "slug": "Vinod-Nair",
                        "structuredName": {
                            "firstName": "Vinod",
                            "lastName": "Nair",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vinod Nair"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 164
                            }
                        ],
                        "text": "Much of this line of inquiry has sought to identify the best choices of network parameters such as size, activation function, pooling method and so on [12, 5, 3, 16, 19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15539264,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a538b05ebb01a40323997629e171c91aa28b8e2f",
            "isKey": false,
            "numCitedBy": 12809,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Restricted Boltzmann machines were developed using binary stochastic hidden units. These can be generalized by replacing each binary unit by an infinite number of copies that all have the same weights but have progressively more negative biases. The learning and inference rules for these \"Stepped Sigmoid Units\" are unchanged. They can be approximated efficiently by noisy, rectified linear units. Compared with binary units, these units learn features that are better for object recognition on the NORB dataset and face verification on the Labeled Faces in the Wild dataset. Unlike binary units, rectified linear units preserve information about relative intensities as information travels through multiple layers of feature detectors."
            },
            "slug": "Rectified-Linear-Units-Improve-Restricted-Boltzmann-Nair-Hinton",
            "title": {
                "fragments": [],
                "text": "Rectified Linear Units Improve Restricted Boltzmann Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "Restricted Boltzmann machines were developed using binary stochastic hidden units that learn features that are better for object recognition on the NORB dataset and face verification on the Labeled Faces in the Wild dataset."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143972711"
                        ],
                        "name": "Kun Zhang",
                        "slug": "Kun-Zhang",
                        "structuredName": {
                            "firstName": "Kun",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kun Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144281180"
                        ],
                        "name": "L. Chan",
                        "slug": "L.-Chan",
                        "structuredName": {
                            "firstName": "Lai-Wan",
                            "lastName": "Chan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Chan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Zhang and Chan [21] use an L1 penalization scheme to zero out many of the connections in an otherwise bipartite structure."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1085218,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "48e6ac22a705c44ac9a3161505ff4ca81c96178c",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "When applying independent component analysis (ICA), sometimes that the connections between the observed mixtures and the recovered independent components (or the original sources) to be sparse, to make the interpretation easier or to reduce the model complexity. In this paper we propose natural gradient algorithms for ICA with a sparse separation matrix, as well as ICA with a sparse mixing matrix. The sparsity of the matrix is achieved by applying certain penalty functions to its entries. The properties of the penalty functions are investigated. Experimental results on both artificial data and causality discovery in financial stocks show the usefulness of the proposed methods."
            },
            "slug": "ICA-with-Sparse-Connections-Zhang-Chan",
            "title": {
                "fragments": [],
                "text": "ICA with Sparse Connections"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper proposes natural gradient algorithms for ICA with a sparse separation matrix, as well as a sparse mixing matrix, where the sparsity of the matrix is achieved by applying certain penalty functions to its entries."
            },
            "venue": {
                "fragments": [],
                "text": "IDEAL"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1791548"
                        ],
                        "name": "A. Hyv\u00e4rinen",
                        "slug": "A.-Hyv\u00e4rinen",
                        "structuredName": {
                            "firstName": "Aapo",
                            "lastName": "Hyv\u00e4rinen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hyv\u00e4rinen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726997"
                        ],
                        "name": "E. Oja",
                        "slug": "E.-Oja",
                        "structuredName": {
                            "firstName": "Erkki",
                            "lastName": "Oja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Oja"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 13
                            }
                        ],
                        "text": "Given the learned receptive fields (groups of features) we can subsequently apply an unsupervised learning method independently over each receptive field."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11959218,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "577d19a115f9ef6f002483fcf88adbb3b5479556",
            "isKey": false,
            "numCitedBy": 7619,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Independent-component-analysis:-algorithms-and-Hyv\u00e4rinen-Oja",
            "title": {
                "fragments": [],
                "text": "Independent component analysis: algorithms and applications"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143817739"
                        ],
                        "name": "J. V. Leeuwen",
                        "slug": "J.-V.-Leeuwen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Leeuwen",
                            "middleNames": [
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. V. Leeuwen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": "Zhang and Chan [21] use an L1 penalization scheme to zero out many of the connections in an otherwise bipartite structure."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 40257103,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1bce1b410cbde7851e902291aad14616fbc318f7",
            "isKey": false,
            "numCitedBy": 125,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Conversational agent is a system that provides user with proper information and maintains the context of dialogue based on natural language. When experts design the network for conversational agent of a domain, the network is usually very complicated and is hard to be understood. So the simplification of network by separating variables in the domain is helpful to design the conversational agent more efficiently. Composing Bayesian network as two stages, we aim to design conversational agent easily and analyze user\u2019s query in detail. Also, by using previous information of dialogue, it is possible to maintain the context of conversation. Actually implementing it for a guide of web pages, we can confirm the usefulness of the proposed architecture for conversational agent."
            },
            "slug": "Intelligent-Data-Engineering-and-Automated-Learning-Leeuwen",
            "title": {
                "fragments": [],
                "text": "Intelligent Data Engineering and Automated Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "Conversational agent is a system that provides user with proper information and maintains the context of dialogue based on natural language, so the simplification of network by separating variables in the domain is helpful to design the conversational agent more efficiently."
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1791548"
                        ],
                        "name": "A. Hyv\u00e4rinen",
                        "slug": "A.-Hyv\u00e4rinen",
                        "structuredName": {
                            "firstName": "Aapo",
                            "lastName": "Hyv\u00e4rinen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hyv\u00e4rinen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 110
                            }
                        ],
                        "text": "One popular choice is \u201csquare correlation\u201d of feature responses, which partly underpins the Topographic ICA [10] algorithm."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 35
                            }
                        ],
                        "text": "The Topographic ICA algorithm [10], for instance, uses a probabilistic model that implies that nearby features in the topography have correlated variances (i.e., energies)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1585328,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "9c07182933e7d8f308292300a63c4b95864d8ff5",
            "isKey": false,
            "numCitedBy": 453,
            "numCiting": 114,
            "paperAbstract": {
                "fragments": [],
                "text": "In ordinary independent component analysis, the components are assumed to be completely independent, and they do not necessarily have any meaningful order relationships. In practice, however, the estimated independent components are often not at all independent. We propose that this residual dependence structure could be used to define a topo-graphic order for the components. In particular, a distance between two components could be defined using their higher-order correlations, and this distance could be used to create a topographic representation. Thus, we obtain a linear decomposition into approximately independent components, where the dependence of two components is approximated by the proximity of the components in the topographic representation."
            },
            "slug": "Topographic-Independent-Component-Analysis-Hyv\u00e4rinen",
            "title": {
                "fragments": [],
                "text": "Topographic Independent Component Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A linear decomposition is obtained into approximately independent components, where the dependence of two components is approximated by the proximity of the components in the topographic representation."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 12
                            }
                        ],
                        "text": "Though there are still spatial relationships amongst the feature values within each map, it is not clear how two features in different maps are related."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 184
                            }
                        ],
                        "text": "There are now many results in the literature indicating that large networks with thousands of unique feature extractors are top competitors in applications and benchmarks (e.g., [4, 6, 9, 19])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 139
                            }
                        ],
                        "text": "This trick dramatically reduces the number of parameters that must be trained and is a key element of several state-of-the-art systems [4, 19, 6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Finally, we will also provide test results using a larger 1st layer representation (K1 = 4800 maps) to verify that the performance gains we achieve are not merely the result of passing more projections of the data to the supervised classification stage."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Highperformance neural networks for visual object classification. Pre-print"
            },
            "venue": {
                "fragments": [],
                "text": "Highperformance neural networks for visual object classification. Pre-print"
            },
            "year": 2011
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 13,
            "methodology": 15
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 23,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Selecting-Receptive-Fields-in-Deep-Networks-Coates-Ng/182015c5edff1956cbafbcb3e7bbe294aa54f9fc?sort=total-citations"
}