{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49517463"
                        ],
                        "name": "S. Ravi",
                        "slug": "S.-Ravi",
                        "structuredName": {
                            "firstName": "Sachin",
                            "lastName": "Ravi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ravi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777528"
                        ],
                        "name": "H. Larochelle",
                        "slug": "H.-Larochelle",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Larochelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Larochelle"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 67413369,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29c887794eed2ca9462638ff853e6fe1ab91d5d8",
            "isKey": false,
            "numCitedBy": 2132,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Optimization-as-a-Model-for-Few-Shot-Learning-Ravi-Larochelle",
            "title": {
                "fragments": [],
                "text": "Optimization as a Model for Few-Shot Learning"
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7718952"
                        ],
                        "name": "Zhenguo Li",
                        "slug": "Zhenguo-Li",
                        "structuredName": {
                            "firstName": "Zhenguo",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhenguo Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "22173351"
                        ],
                        "name": "Fengwei Zhou",
                        "slug": "Fengwei-Zhou",
                        "structuredName": {
                            "firstName": "Fengwei",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fengwei Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "117872156"
                        ],
                        "name": "Fei Chen",
                        "slug": "Fei-Chen",
                        "structuredName": {
                            "firstName": "Fei",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fei Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145571830"
                        ],
                        "name": "Hang Li",
                        "slug": "Hang-Li",
                        "structuredName": {
                            "firstName": "Hang",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hang Li"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 25316837,
            "fieldsOfStudy": [
                "Computer Science",
                "Education"
            ],
            "id": "d33ad6a25264ba1747d8c93f6621c7f90a7ec601",
            "isKey": false,
            "numCitedBy": 564,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Few-shot learning is challenging for learning algorithms that learn each task in isolation and from scratch. In contrast, meta-learning learns from many related tasks a meta-learner that can learn a new task more accurately and faster with fewer examples, where the choice of meta-learners is crucial. In this paper, we develop Meta-SGD, an SGD-like, easily trainable meta-learner that can initialize and adapt any differentiable learner in just one step, on both supervised learning and reinforcement learning. Compared to the popular meta-learner LSTM, Meta-SGD is conceptually simpler, easier to implement, and can be learned more efficiently. Compared to the latest meta-learner MAML, Meta-SGD has a much higher capacity by learning to learn not just the learner initialization, but also the learner update direction and learning rate, all in a single meta-learning process. Meta-SGD shows highly competitive performance for few-shot learning on regression, classification, and reinforcement learning."
            },
            "slug": "Meta-SGD:-Learning-to-Learn-Quickly-for-Few-Shot-Li-Zhou",
            "title": {
                "fragments": [],
                "text": "Meta-SGD: Learning to Learn Quickly for Few Shot Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Meta-SGD, an SGD-like, easily trainable meta-learner that can initialize and adapt any differentiable learner in just one step, shows highly competitive performance for few-shot learning on regression, classification, and reinforcement learning."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3166516"
                        ],
                        "name": "Emilio Parisotto",
                        "slug": "Emilio-Parisotto",
                        "structuredName": {
                            "firstName": "Emilio",
                            "lastName": "Parisotto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Emilio Parisotto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2503659"
                        ],
                        "name": "Jimmy Ba",
                        "slug": "Jimmy-Ba",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Ba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy Ba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 106
                            }
                        ],
                        "text": "In fact, pretraining is in some cases worse than random initialization, a fact observed in prior RL work (Parisotto et al., 2016)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8241258,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1def5d3711ebd1d86787b1ed57c91832c5ddc90b",
            "isKey": false,
            "numCitedBy": 440,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "The ability to act in multiple environments and transfer previous knowledge to new situations can be considered a critical aspect of any intelligent agent. Towards this goal, we define a novel method of multitask and transfer learning that enables an autonomous agent to learn how to behave in multiple tasks simultaneously, and then generalize its knowledge to new domains. This method, termed \"Actor-Mimic\", exploits the use of deep reinforcement learning and model compression techniques to train a single policy network that learns how to act in a set of distinct tasks by using the guidance of several expert teachers. We then show that the representations learnt by the deep policy network are capable of generalizing to new tasks with no prior expert guidance, speeding up learning in novel environments. Although our method can in general be applied to a wide range of problems, we use Atari games as a testing environment to demonstrate these methods."
            },
            "slug": "Actor-Mimic:-Deep-Multitask-and-Transfer-Learning-Parisotto-Ba",
            "title": {
                "fragments": [],
                "text": "Actor-Mimic: Deep Multitask and Transfer Reinforcement Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work defines a novel method of multitask and transfer learning that enables an autonomous agent to learn how to behave in multiple tasks simultaneously, and then generalize its knowledge to new domains, and uses Atari games as a testing environment to demonstrate these methods."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116439278"
                        ],
                        "name": "Jane X. Wang",
                        "slug": "Jane-X.-Wang",
                        "structuredName": {
                            "firstName": "Jane",
                            "lastName": "Wang",
                            "middleNames": [
                                "X."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jane X. Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399114225"
                        ],
                        "name": "Z. Kurth-Nelson",
                        "slug": "Z.-Kurth-Nelson",
                        "structuredName": {
                            "firstName": "Zeb",
                            "lastName": "Kurth-Nelson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Kurth-Nelson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2794457"
                        ],
                        "name": "Hubert Soyer",
                        "slug": "Hubert-Soyer",
                        "structuredName": {
                            "firstName": "Hubert",
                            "lastName": "Soyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hubert Soyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700356"
                        ],
                        "name": "Joel Z. Leibo",
                        "slug": "Joel-Z.-Leibo",
                        "structuredName": {
                            "firstName": "Joel",
                            "lastName": "Leibo",
                            "middleNames": [
                                "Z."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joel Z. Leibo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7794353"
                        ],
                        "name": "Dhruva Tirumala",
                        "slug": "Dhruva-Tirumala",
                        "structuredName": {
                            "firstName": "Dhruva",
                            "lastName": "Tirumala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dhruva Tirumala"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708654"
                        ],
                        "name": "R. Munos",
                        "slug": "R.-Munos",
                        "structuredName": {
                            "firstName": "R\u00e9mi",
                            "lastName": "Munos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Munos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723876"
                        ],
                        "name": "C. Blundell",
                        "slug": "C.-Blundell",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Blundell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Blundell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2106164"
                        ],
                        "name": "D. Kumaran",
                        "slug": "D.-Kumaran",
                        "structuredName": {
                            "firstName": "Dharshan",
                            "lastName": "Kumaran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kumaran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46378362"
                        ],
                        "name": "M. Botvinick",
                        "slug": "M.-Botvinick",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Botvinick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Botvinick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 294,
                                "start": 277
                            }
                        ],
                        "text": "\u2026methods, memory-augmented neural networks (Santoro et al., 2016) specifically, and recurrent meta-learning models in general, represent a more broadly applicable class of methods that, like MAML, can be used for other tasks such as reinforcement learning (Duan et al., 2016b; Wang et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 225,
                                "start": 186
                            }
                        ],
                        "text": ", 2016) specifically, and recurrent meta-learning models in general, represent a more broadly applicable class of methods that can be used for other tasks such as reinforcement learning (Duan et al., 2016b; Wang et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 82
                            }
                        ],
                        "text": ", 2016) and learning \u201cfast\u201d reinforcement learning agents with recurrent policies (Duan et al., 2016b; Wang et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 177
                            }
                        ],
                        "text": "Such networks have been applied to few-shot image recognition (Santoro et al., 2016; Munkhdalai & Yu, 2017) and learning \u201cfast\u201d reinforcement learning agents (Duan et al., 2016b; Wang et al., 2016)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 13623631,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "282a380fb5ac26d99667224cef8c630f6882704f",
            "isKey": true,
            "numCitedBy": 631,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "In recent years deep reinforcement learning (RL) systems have attained superhuman performance in a number of challenging task domains. However, a major limitation of such applications is their demand for massive amounts of training data. A critical present objective is thus to develop deep RL methods that can adapt rapidly to new tasks. In the present work we introduce a novel approach to this challenge, which we refer to as deep meta-reinforcement learning. Previous work has shown that recurrent networks can support meta-learning in a fully supervised context. We extend this approach to the RL setting. What emerges is a system that is trained using one RL algorithm, but whose recurrent dynamics implement a second, quite separate RL procedure. This second, learned RL algorithm can differ from the original one in arbitrary ways. Importantly, because it is learned, it is configured to exploit structure in the training domain. We unpack these points in a series of seven proof-of-concept experiments, each of which examines a key aspect of deep meta-RL. We consider prospects for extending and scaling up the approach, and also point out some potentially important implications for neuroscience."
            },
            "slug": "Learning-to-reinforcement-learn-Wang-Kurth-Nelson",
            "title": {
                "fragments": [],
                "text": "Learning to reinforcement learn"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This work introduces a novel approach to deep meta-reinforcement learning, which is a system that is trained using one RL algorithm, but whose recurrent dynamics implement a second, quite separate RL procedure."
            },
            "venue": {
                "fragments": [],
                "text": "CogSci"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38967461"
                        ],
                        "name": "Alex Nichol",
                        "slug": "Alex-Nichol",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Nichol",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Nichol"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3381809"
                        ],
                        "name": "Joshua Achiam",
                        "slug": "Joshua-Achiam",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Achiam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joshua Achiam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47971768"
                        ],
                        "name": "J. Schulman",
                        "slug": "J.-Schulman",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Schulman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schulman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 34
                            }
                        ],
                        "text": "Orcun Cetintas | AutoML \u2022 Reptile [3]: Proposes a new algorithm with only first-order derivatives \u2022 MAML++ [4]: Stabilizes MAML training and proposes improvements such as learning the learning rate \u2022 Meta-SGD [5]: Learns all components of a meta-optimizer (initialization, update direction and learning rate)"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4587331,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "90dc22818bd2d97d8deaff168b0137b75a962767",
            "isKey": false,
            "numCitedBy": 1019,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper considers meta-learning problems, where there is a distribution of tasks, and we would like to obtain an agent that performs well (i.e., learns quickly) when presented with a previously unseen task sampled from this distribution. We analyze a family of algorithms for learning a parameter initialization that can be fine-tuned quickly on a new task, using only first-order derivatives for the meta-learning updates. This family includes and generalizes first-order MAML, an approximation to MAML obtained by ignoring second-order derivatives. It also includes Reptile, a new algorithm that we introduce here, which works by repeatedly sampling a task, training on it, and moving the initialization towards the trained weights on that task. We expand on the results from Finn et al. showing that first-order meta-learning algorithms perform well on some well-established benchmarks for few-shot classification, and we provide theoretical analysis aimed at understanding why these algorithms work."
            },
            "slug": "On-First-Order-Meta-Learning-Algorithms-Nichol-Achiam",
            "title": {
                "fragments": [],
                "text": "On First-Order Meta-Learning Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A family of algorithms for learning a parameter initialization that can be fine-tuned quickly on a new task, using only first-order derivatives for the meta-learning updates, including Reptile, which works by repeatedly sampling a task, training on it, and moving the initialization towards the trained weights on that task."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066516991"
                        ],
                        "name": "J. Kirkpatrick",
                        "slug": "J.-Kirkpatrick",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Kirkpatrick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kirkpatrick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1996134"
                        ],
                        "name": "Razvan Pascanu",
                        "slug": "Razvan-Pascanu",
                        "structuredName": {
                            "firstName": "Razvan",
                            "lastName": "Pascanu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Razvan Pascanu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3422052"
                        ],
                        "name": "Neil C. Rabinowitz",
                        "slug": "Neil-C.-Rabinowitz",
                        "structuredName": {
                            "firstName": "Neil",
                            "lastName": "Rabinowitz",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Neil C. Rabinowitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144056327"
                        ],
                        "name": "J. Veness",
                        "slug": "J.-Veness",
                        "structuredName": {
                            "firstName": "Joel",
                            "lastName": "Veness",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Veness"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2755582"
                        ],
                        "name": "Guillaume Desjardins",
                        "slug": "Guillaume-Desjardins",
                        "structuredName": {
                            "firstName": "Guillaume",
                            "lastName": "Desjardins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guillaume Desjardins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2228824"
                        ],
                        "name": "Andrei A. Rusu",
                        "slug": "Andrei-A.-Rusu",
                        "structuredName": {
                            "firstName": "Andrei",
                            "lastName": "Rusu",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrei A. Rusu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8181864"
                        ],
                        "name": "K. Milan",
                        "slug": "K.-Milan",
                        "structuredName": {
                            "firstName": "Kieran",
                            "lastName": "Milan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Milan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34660073"
                        ],
                        "name": "John Quan",
                        "slug": "John-Quan",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Quan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John Quan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34505275"
                        ],
                        "name": "Tiago Ramalho",
                        "slug": "Tiago-Ramalho",
                        "structuredName": {
                            "firstName": "Tiago",
                            "lastName": "Ramalho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tiago Ramalho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398898827"
                        ],
                        "name": "Agnieszka Grabska-Barwinska",
                        "slug": "Agnieszka-Grabska-Barwinska",
                        "structuredName": {
                            "firstName": "Agnieszka",
                            "lastName": "Grabska-Barwinska",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Agnieszka Grabska-Barwinska"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48987704"
                        ],
                        "name": "D. Hassabis",
                        "slug": "D.-Hassabis",
                        "structuredName": {
                            "firstName": "Demis",
                            "lastName": "Hassabis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hassabis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2388737"
                        ],
                        "name": "C. Clopath",
                        "slug": "C.-Clopath",
                        "structuredName": {
                            "firstName": "Claudia",
                            "lastName": "Clopath",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Clopath"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2106164"
                        ],
                        "name": "D. Kumaran",
                        "slug": "D.-Kumaran",
                        "structuredName": {
                            "firstName": "Dharshan",
                            "lastName": "Kumaran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kumaran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2315504"
                        ],
                        "name": "R. Hadsell",
                        "slug": "R.-Hadsell",
                        "structuredName": {
                            "firstName": "Raia",
                            "lastName": "Hadsell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hadsell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4704285,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5151d6cb3a4eaec14a56944d58338251fca344ab",
            "isKey": false,
            "numCitedBy": 2738,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "Significance Deep neural networks are currently the most successful machine-learning technique for solving a variety of tasks, including language translation, image classification, and image generation. One weakness of such models is that, unlike humans, they are unable to learn multiple tasks sequentially. In this work we propose a practical solution to train such models sequentially by protecting the weights important for previous tasks. This approach, inspired by synaptic consolidation in neuroscience, enables state of the art results on multiple reinforcement learning problems experienced sequentially. The ability to learn tasks in a sequential fashion is crucial to the development of artificial intelligence. Until now neural networks have not been capable of this and it has been widely thought that catastrophic forgetting is an inevitable feature of connectionist models. We show that it is possible to overcome this limitation and train networks that can maintain expertise on tasks that they have not experienced for a long time. Our approach remembers old tasks by selectively slowing down learning on the weights important for those tasks. We demonstrate our approach is scalable and effective by solving a set of classification tasks based on a hand-written digit dataset and by learning several Atari 2600 games sequentially."
            },
            "slug": "Overcoming-catastrophic-forgetting-in-neural-Kirkpatrick-Pascanu",
            "title": {
                "fragments": [],
                "text": "Overcoming catastrophic forgetting in neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is shown that it is possible to overcome the limitation of connectionist models and train networks that can maintain expertise on tasks that they have not experienced for a long time and selectively slowing down learning on the weights important for previous tasks."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2063959275"
                        ],
                        "name": "Antreas Antoniou",
                        "slug": "Antreas-Antoniou",
                        "structuredName": {
                            "firstName": "Antreas",
                            "lastName": "Antoniou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antreas Antoniou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144632352"
                        ],
                        "name": "Harrison Edwards",
                        "slug": "Harrison-Edwards",
                        "structuredName": {
                            "firstName": "Harrison",
                            "lastName": "Edwards",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Harrison Edwards"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728216"
                        ],
                        "name": "A. Storkey",
                        "slug": "A.-Storkey",
                        "structuredName": {
                            "firstName": "Amos",
                            "lastName": "Storkey",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Storkey"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 53036488,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ba5267c42ec429cf9533d6ce07d8d3d03177b9ec",
            "isKey": false,
            "numCitedBy": 357,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "The field of few-shot learning has recently seen substantial advancements. Most of these advancements came from casting few-shot learning as a meta-learning problem. Model Agnostic Meta Learning or MAML is currently one of the best approaches for few-shot learning via meta-learning. MAML is simple, elegant and very powerful, however, it has a variety of issues, such as being very sensitive to neural network architectures, often leading to instability during training, requiring arduous hyperparameter searches to stabilize training and achieve high generalization and being very computationally expensive at both training and inference times. In this paper, we propose various modifications to MAML that not only stabilize the system, but also substantially improve the generalization performance, convergence speed and computational overhead of MAML, which we call MAML++."
            },
            "slug": "How-to-train-your-MAML-Antoniou-Edwards",
            "title": {
                "fragments": [],
                "text": "How to train your MAML"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper proposes various modifications to MAML that not only stabilize the system, but also substantially improve the generalization performance, convergence speed and computational overhead of MAMl, which it is called M AML++."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35030998"
                        ],
                        "name": "Adam Santoro",
                        "slug": "Adam-Santoro",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Santoro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adam Santoro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2258504"
                        ],
                        "name": "Sergey Bartunov",
                        "slug": "Sergey-Bartunov",
                        "structuredName": {
                            "firstName": "Sergey",
                            "lastName": "Bartunov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sergey Bartunov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46378362"
                        ],
                        "name": "M. Botvinick",
                        "slug": "M.-Botvinick",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Botvinick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Botvinick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688276"
                        ],
                        "name": "Daan Wierstra",
                        "slug": "Daan-Wierstra",
                        "structuredName": {
                            "firstName": "Daan",
                            "lastName": "Wierstra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daan Wierstra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2542999"
                        ],
                        "name": "T. Lillicrap",
                        "slug": "T.-Lillicrap",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Lillicrap",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lillicrap"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 92
                            }
                        ],
                        "text": "The Omniglot dataset is augmented with rotations by multiples of 90 degrees, as proposed by Santoro et al. (2016)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 63
                            }
                        ],
                        "text": "Such networks have been applied to few-shot image recognition (Santoro et al., 2016; Munkhdalai & Yu, 2017) and learning \u201cfast\u201d reinforcement learning agents (Duan et al., 2016b; Wang et al., 2016)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 67
                            }
                        ],
                        "text": "Compared to these prior methods, memory-augmented neural networks (Santoro et al., 2016) specifically, and recurrent meta-learning models in general, represent a more broadly applicable class of methods that, like MAML, can be used for other tasks such as reinforcement learning (Duan et al., 2016b;\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 103
                            }
                        ],
                        "text": "5-way Accuracy 20-way Accuracy Omniglot (Lake et al., 2011) 1-shot 5-shot 1-shot 5-shot\nMANN, no conv (Santoro et al., 2016) 82.8% 94.9% \u2013 \u2013 MAML, no conv (ours) 89.7\u00b1 1.1% 97.5\u00b1 0.6% \u2013 \u2013 Siamese nets (Koch, 2015) 97.3% 98.4% 88.2% 97.0% matching nets (Vinyals et al., 2016) 98.1% 98.9% 93.8% 98.5%\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 150
                            }
                        ],
                        "text": "\u2026our algorithm does not expand the number of learned parameters nor place constraints on the model architecture (e.g. by requiring a recurrent model (Santoro et al., 2016) or a Siamese network (Koch, 2015)), and it can be readily combined with fully connected, convolutional, or recurrent neural\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 140
                            }
                        ],
                        "text": "The Omniglot and MiniImagenet image recognition tasks are the most common recently used few-shot learning benchmarks (Vinyals et al., 2016; Santoro et al., 2016; Ravi & Larochelle, 2017)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 108
                            }
                        ],
                        "text": "In contrast to prior work, which has sought to train recurrent neural networks that ingest entire datasets (Santoro et al., 2016; Duan et al., 2016b) or feature embeddings that can be combined with nonparametric methods at test time (Vinyals et al., 2016; Koch, 2015), we propose a method that can\u2026"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 85
                            }
                        ],
                        "text": "Unlike prior meta-learning methods that learn an update function or learning rule (Schmidhuber, 1987; Bengio et al., 1992; Andrychowicz et al., 2016; Ravi & Larochelle, 2017), our algorithm does not expand the number of learned parameters nor place constraints on the model architecture (e.g. by\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 85
                            }
                        ],
                        "text": "In order to also provide a fair comparison against memory-augmented neural networks (Santoro et al., 2016) and to test the flexibility of MAML, we also provide results for a non-convolutional network."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6466088,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3904315e2eca50d0086e4b7273f7fd707c652230",
            "isKey": true,
            "numCitedBy": 918,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Despite recent breakthroughs in the applications of deep neural networks, one setting that presents a persistent challenge is that of \"one-shot learning.\" Traditional gradient-based networks require a lot of data to learn, often through extensive iterative training. When new data is encountered, the models must inefficiently relearn their parameters to adequately incorporate the new information without catastrophic interference. Architectures with augmented memory capacities, such as Neural Turing Machines (NTMs), offer the ability to quickly encode and retrieve new information, and hence can potentially obviate the downsides of conventional models. Here, we demonstrate the ability of a memory-augmented neural network to rapidly assimilate new data, and leverage this data to make accurate predictions after only a few samples. We also introduce a new method for accessing an external memory that focuses on memory content, unlike previous methods that additionally use memory location-based focusing mechanisms."
            },
            "slug": "Meta-Learning-with-Memory-Augmented-Neural-Networks-Santoro-Bartunov",
            "title": {
                "fragments": [],
                "text": "Meta-Learning with Memory-Augmented Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The ability of a memory-augmented neural network to rapidly assimilate new data, and leverage this data to make accurate predictions after only a few samples is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054165706"
                        ],
                        "name": "S. Ioffe",
                        "slug": "S.-Ioffe",
                        "structuredName": {
                            "firstName": "Sergey",
                            "lastName": "Ioffe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ioffe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2574060"
                        ],
                        "name": "Christian Szegedy",
                        "slug": "Christian-Szegedy",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Szegedy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Szegedy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 190
                            }
                        ],
                        "text": "Our model follows the same architecture as the embedding function used by Vinyals et al. (2016), which has 4 modules with a 3 \u00d7 3 convolutions and 64 filters, followed by batch normalization (Ioffe & Szegedy, 2015), a ReLU nonlinearity, and 2 \u00d7 2 max-pooling."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5808102,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4d376d6978dad0374edfa6709c9556b42d3594d3",
            "isKey": false,
            "numCitedBy": 29233,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82% top-5 test error, exceeding the accuracy of human raters."
            },
            "slug": "Batch-Normalization:-Accelerating-Deep-Network-by-Ioffe-Szegedy",
            "title": {
                "fragments": [],
                "text": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689108"
                        ],
                        "name": "Oriol Vinyals",
                        "slug": "Oriol-Vinyals",
                        "structuredName": {
                            "firstName": "Oriol",
                            "lastName": "Vinyals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oriol Vinyals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723876"
                        ],
                        "name": "C. Blundell",
                        "slug": "C.-Blundell",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Blundell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Blundell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2542999"
                        ],
                        "name": "T. Lillicrap",
                        "slug": "T.-Lillicrap",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Lillicrap",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lillicrap"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2645384"
                        ],
                        "name": "K. Kavukcuoglu",
                        "slug": "K.-Kavukcuoglu",
                        "structuredName": {
                            "firstName": "Koray",
                            "lastName": "Kavukcuoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kavukcuoglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688276"
                        ],
                        "name": "Daan Wierstra",
                        "slug": "Daan-Wierstra",
                        "structuredName": {
                            "firstName": "Daan",
                            "lastName": "Wierstra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daan Wierstra"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8909022,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "be1bb4e4aa1fcf70281b4bd24d8cd31c04864bb6",
            "isKey": false,
            "numCitedBy": 3736,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning from a few examples remains a key challenge in machine learning. Despite recent advances in important domains such as vision and language, the standard supervised deep learning paradigm does not offer a satisfactory solution for learning new concepts rapidly from little data. In this work, we employ ideas from metric learning based on deep neural features and from recent advances that augment neural networks with external memories. Our framework learns a network that maps a small labelled support set and an unlabelled example to its label, obviating the need for fine-tuning to adapt to new class types. We then define one-shot learning problems on vision (using Omniglot, ImageNet) and language tasks. Our algorithm improves one-shot accuracy on ImageNet from 87.6% to 93.2% and from 88.0% to 93.8% on Omniglot compared to competing approaches. We also demonstrate the usefulness of the same model on language modeling by introducing a one-shot task on the Penn Treebank."
            },
            "slug": "Matching-Networks-for-One-Shot-Learning-Vinyals-Blundell",
            "title": {
                "fragments": [],
                "text": "Matching Networks for One Shot Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work employs ideas from metric learning based on deep neural features and from recent advances that augment neural networks with external memories to learn a network that maps a small labelled support set and an unlabelled example to its label, obviating the need for fine-tuning to adapt to new class types."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2562966"
                        ],
                        "name": "Philipp Kr\u00e4henb\u00fchl",
                        "slug": "Philipp-Kr\u00e4henb\u00fchl",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Kr\u00e4henb\u00fchl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Kr\u00e4henb\u00fchl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2786693"
                        ],
                        "name": "Carl Doersch",
                        "slug": "Carl-Doersch",
                        "structuredName": {
                            "firstName": "Carl",
                            "lastName": "Doersch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carl Doersch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7408951"
                        ],
                        "name": "Jeff Donahue",
                        "slug": "Jeff-Donahue",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Donahue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeff Donahue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 134
                            }
                        ],
                        "text": "Most of these works have considered good random initializations, though a number of papers have addressed datadependent initializers (Kra\u0308henbu\u0308hl et al., 2016; Salimans & Kingma, 2016), including learned initializations (Husken & Goerick, 2000; Maclaurin et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9665723,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c3af47db3186691270192d5399bb5259e05c87a7",
            "isKey": false,
            "numCitedBy": 174,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Convolutional Neural Networks spread through computer vision like a wildfire, impacting almost all visual tasks imaginable. Despite this, few researchers dare to train their models from scratch. Most work builds on one of a handful of ImageNet pre-trained models, and fine-tunes or adapts these for specific tasks. This is in large part due to the difficulty of properly initializing these networks from scratch. A small miscalibration of the initial weights leads to vanishing or exploding gradients, as well as poor convergence properties. In this work we present a fast and simple data-dependent initialization procedure, that sets the weights of a network such that all units in the network train at roughly the same rate, avoiding vanishing or exploding gradients. Our initialization matches the current state-of-the-art unsupervised or self-supervised pre-training methods on standard computer vision tasks, such as image classification and object detection, while being roughly three orders of magnitude faster. When combined with pre-training methods, our initialization significantly outperforms prior work, narrowing the gap between supervised and unsupervised pre-training."
            },
            "slug": "Data-dependent-Initializations-of-Convolutional-Kr\u00e4henb\u00fchl-Doersch",
            "title": {
                "fragments": [],
                "text": "Data-dependent Initializations of Convolutional Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work presents a fast and simple data-dependent initialization procedure, that sets the weights of a network such that all units in the network train at roughly the same rate, avoiding vanishing or exploding gradients."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144581158"
                        ],
                        "name": "Yan Duan",
                        "slug": "Yan-Duan",
                        "structuredName": {
                            "firstName": "Yan",
                            "lastName": "Duan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yan Duan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41192764"
                        ],
                        "name": "Xi Chen",
                        "slug": "Xi-Chen",
                        "structuredName": {
                            "firstName": "Xi",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xi Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3127100"
                        ],
                        "name": "Rein Houthooft",
                        "slug": "Rein-Houthooft",
                        "structuredName": {
                            "firstName": "Rein",
                            "lastName": "Houthooft",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rein Houthooft"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47971768"
                        ],
                        "name": "J. Schulman",
                        "slug": "J.-Schulman",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Schulman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schulman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689992"
                        ],
                        "name": "P. Abbeel",
                        "slug": "P.-Abbeel",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Abbeel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Abbeel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12296499,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1464776f20e2bccb6182f183b5ff2e15b0ae5e56",
            "isKey": false,
            "numCitedBy": 1241,
            "numCiting": 98,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, researchers have made significant progress combining the advances in deep learning for learning feature representations with reinforcement learning. Some notable examples include training agents to play Atari games based on raw pixel data and to acquire advanced manipulation skills using raw sensory inputs. However, it has been difficult to quantify progress in the domain of continuous control due to the lack of a commonly adopted benchmark. In this work, we present a benchmark suite of continuous control tasks, including classic tasks like cart-pole swing-up, tasks with very high state and action dimensionality such as 3D humanoid locomotion, tasks with partial observations, and tasks with hierarchical structure. We report novel findings based on the systematic evaluation of a range of implemented reinforcement learning algorithms. Both the benchmark and reference implementations are released at this https URL in order to facilitate experimental reproducibility and to encourage adoption by other researchers."
            },
            "slug": "Benchmarking-Deep-Reinforcement-Learning-for-Duan-Chen",
            "title": {
                "fragments": [],
                "text": "Benchmarking Deep Reinforcement Learning for Continuous Control"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work presents a benchmark suite of continuous control tasks, including classic tasks like cart-pole swing-up, tasks with very high state and action dimensionality such as 3D humanoid locomotion, task with partial observations, and tasks with hierarchical structure."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054250597"
                        ],
                        "name": "Gregory R. Koch",
                        "slug": "Gregory-R.-Koch",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Koch",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gregory R. Koch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 59
                            }
                        ],
                        "text": "Some of these existing methods, such as matching networks, Siamese networks, and memory models are designed with few-shot classification in mind, and are not readily applicable to domains such as reinforcement learning."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 178
                            }
                        ],
                        "text": "5-way Accuracy 20-way Accuracy Omniglot (Lake et al., 2011) 1-shot 5-shot 1-shot 5-shot\nMANN, no conv (Santoro et al., 2016) 82.8% 94.9% \u2013 \u2013 MAML, no conv (ours) 89.7\u00b1 1.1% 97.5\u00b1 0.6% \u2013 \u2013 Siamese nets (Koch, 2015) 97.3% 98.4% 88.2% 97.0% matching nets (Vinyals et al., 2016) 98.1% 98.9% 93.8% 98.5% neural statistician (Edwards & Storkey, 2017) 98.1% 99.5% 93.2% 98.1% memory mod."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 147
                            }
                        ],
                        "text": "\u2026et al., 2011) 1-shot 5-shot 1-shot 5-shot\nMANN, no conv (Santoro et al., 2016) 82.8% 94.9% \u2013 \u2013 MAML, no conv (ours) 89.7\u00b1 1.1% 97.5\u00b1 0.6% \u2013 \u2013 Siamese nets (Koch, 2015) 97.3% 98.4% 88.2% 97.0% matching nets (Vinyals et al., 2016) 98.1% 98.9% 93.8% 98.5% neural statistician (Edwards & Storkey,\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 143
                            }
                        ],
                        "text": "One successful approach for few-shot classification is to learn to compare new examples in a learned metric space using e.g. Siamese networks (Koch, 2015) or recurrence with attention mechanisms (Vinyals et al., 2016; Shyam et al., 2017; Snell et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 180
                            }
                        ],
                        "text": "\u2026does not expand the number of learned parameters nor place constraints on the model architecture (e.g. by requiring a recurrent model (Santoro et al., 2016) or a Siamese network (Koch, 2015)), and it can be readily combined with fully connected, convolutional, or recurrent neural networks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 95
                            }
                        ],
                        "text": "This approach has been applied to learning to optimize deep networks (Hochreiter et al., 2001; Andrychowicz et al., 2016; Li & Malik, 2017), as well as for learning dynamically changing recurrent networks (Ha et al., 2017)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 150
                            }
                        ],
                        "text": "\u2026(Santoro et al., 2016; Duan et al., 2016b) or feature embeddings that can be combined with nonparametric methods at test time (Vinyals et al., 2016; Koch, 2015), we propose a method that can learn the parameters of any standard model via meta-learning in such a way as to prepare that model for\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 156
                            }
                        ],
                        "text": "To accomplish this, the model or learner is trained during a meta-learning phase on a set of tasks, such that the trained model can quickly adapt to new tasks using only a small number of examples or trials."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 129
                            }
                        ],
                        "text": "Unlike prior meta-learning methods that learn an update function or learning rule (Schmidhuber, 1987; Bengio et al., 1992; Andrychowicz et al., 2016; Ravi & Larochelle, 2017), our algorithm does not expand the number of learned parameters nor place constraints on the model architecture (e.g. by\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 356,
                                "start": 352
                            }
                        ],
                        "text": "Unlike prior meta-learning methods that learn an update function or learning rule (Schmidhuber, 1987; Bengio et al., 1992; Andrychowicz et al., 2016; Ravi & Larochelle, 2017), our algorithm does not expand the number of learned parameters nor place constraints on the model architecture (e.g. by requiring a recurrent model (Santoro et al., 2016) or a Siamese network (Koch, 2015)), and it can be readily combined with fully connected, convolutional, or recurrent neural networks."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "Siamese nets, matching nets, and the memory module approaches are all specific to classification, and are not directly applicable to regression or RL scenarios."
                    },
                    "intents": []
                }
            ],
            "corpusId": 13874643,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f216444d4f2959b4520c61d20003fa30a199670a",
            "isKey": true,
            "numCitedBy": 2448,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "The process of learning good features for machine learning applications can be very computationally expensive and may prove difficult in cases where little data is available. A prototypical example of this is the one-shot learning setting, in which we must correctly make predictions given only a single example of each new class. In this paper, we explore a method for learning siamese neural networks which employ a unique structure to naturally rank similarity between inputs. Once a network has been tuned, we can then capitalize on powerful discriminative features to generalize the predictive power of the network not just to new data, but to entirely new classes from unknown distributions. Using a convolutional architecture, we are able to achieve strong results which exceed those of other deep learning models with near state-of-the-art performance on one-shot classification tasks."
            },
            "slug": "Siamese-Neural-Networks-for-One-Shot-Image-Koch",
            "title": {
                "fragments": [],
                "text": "Siamese Neural Networks for One-Shot Image Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A method for learning siamese neural networks which employ a unique structure to naturally rank similarity between inputs and is able to achieve strong results which exceed those of other deep learning models with near state-of-the-art performance on one-shot classification tasks."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35030998"
                        ],
                        "name": "Adam Santoro",
                        "slug": "Adam-Santoro",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Santoro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adam Santoro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2258504"
                        ],
                        "name": "Sergey Bartunov",
                        "slug": "Sergey-Bartunov",
                        "structuredName": {
                            "firstName": "Sergey",
                            "lastName": "Bartunov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sergey Bartunov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46378362"
                        ],
                        "name": "M. Botvinick",
                        "slug": "M.-Botvinick",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Botvinick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Botvinick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688276"
                        ],
                        "name": "Daan Wierstra",
                        "slug": "Daan-Wierstra",
                        "structuredName": {
                            "firstName": "Daan",
                            "lastName": "Wierstra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daan Wierstra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2542999"
                        ],
                        "name": "T. Lillicrap",
                        "slug": "T.-Lillicrap",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Lillicrap",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lillicrap"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16660179,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bbd0e204f48a45735e1065c8b90b298077b73192",
            "isKey": false,
            "numCitedBy": 459,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Despite recent breakthroughs in the applications of deep neural networks, one setting that presents a persistent challenge is that of \u201cone-shot learning.\u201d Traditional gradient-based networks require a lot of data to learn, often through extensive iterative training. When new data is encountered, the models must inefficiently relearn their parameters to adequately incorporate the new information without catastrophic interference. Architectures with augmented memory capacities, such as Neural Turing Machines (NTMs), offer the ability to quickly encode and retrieve new information, and hence can potentially obviate the downsides of conventional models. Here, we demonstrate the ability of a memory-augmented neural network to rapidly assimilate new data, and leverage this data to make accurate predictions after only a few samples. We also introduce a new method for accessing an external memory that focuses on memory content, unlike previous methods that additionally use memory locationbased focusing mechanisms."
            },
            "slug": "One-shot-Learning-with-Memory-Augmented-Neural-Santoro-Bartunov",
            "title": {
                "fragments": [],
                "text": "One-shot Learning with Memory-Augmented Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The ability of a memory-augmented neural network to rapidly assimilate new data, and leverage this data to make accurate predictions after only a few samples is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2227827"
                        ],
                        "name": "Tsendsuren Munkhdalai",
                        "slug": "Tsendsuren-Munkhdalai",
                        "structuredName": {
                            "firstName": "Tsendsuren",
                            "lastName": "Munkhdalai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tsendsuren Munkhdalai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2119120474"
                        ],
                        "name": "Hong Yu",
                        "slug": "Hong-Yu",
                        "structuredName": {
                            "firstName": "Hong",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hong Yu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 85
                            }
                        ],
                        "text": "Such networks have been applied to few-shot image recognition (Santoro et al., 2016; Munkhdalai & Yu, 2017) and learning \u201cfast\u201d reinforcement learning agents (Duan et al., 2016b; Wang et al., 2016)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 18702258,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "470d11b8ca4586c930adbbfc3f60bff08f2a0161",
            "isKey": false,
            "numCitedBy": 532,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural networks have been successfully applied in applications with a large amount of labeled data. However, the task of rapid generalization on new concepts with small training data while preserving performances on previously learned ones still presents a significant challenge to neural network models. In this work, we introduce a novel meta learning method, Meta Networks (MetaNet), that learns a meta-level knowledge across tasks and shifts its inductive biases via fast parameterization for rapid generalization. When evaluated on Omniglot and Mini-ImageNet benchmarks, our MetaNet models achieve a near human-level performance and outperform the baseline approaches by up to 6% accuracy. We demonstrate several appealing properties of MetaNet relating to generalization and continual learning."
            },
            "slug": "Meta-Networks-Munkhdalai-Yu",
            "title": {
                "fragments": [],
                "text": "Meta Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A novel meta learning method, Meta Networks (MetaNet), is introduced that learns a meta-level knowledge across tasks and shifts its inductive biases via fast parameterization for rapid generalization."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144581158"
                        ],
                        "name": "Yan Duan",
                        "slug": "Yan-Duan",
                        "structuredName": {
                            "firstName": "Yan",
                            "lastName": "Duan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yan Duan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47971768"
                        ],
                        "name": "J. Schulman",
                        "slug": "J.-Schulman",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Schulman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schulman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41192764"
                        ],
                        "name": "Xi Chen",
                        "slug": "Xi-Chen",
                        "structuredName": {
                            "firstName": "Xi",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xi Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745169"
                        ],
                        "name": "P. Bartlett",
                        "slug": "P.-Bartlett",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Bartlett",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bartlett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689992"
                        ],
                        "name": "P. Abbeel",
                        "slug": "P.-Abbeel",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Abbeel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Abbeel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 179
                            }
                        ],
                        "text": "To evaluate MAML on reinforcement learning problems, we constructed several sets of tasks based off of the simulated continuous control environments in the rllab benchmark suite (Duan et al., 2016a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 101
                            }
                        ],
                        "text": "For both learning and meta-learning updates, we use the standard linear feature baseline proposed by Duan et al. (2016a), which is fitted separately at each iteration for each sampled task in the batch."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 157
                            }
                        ],
                        "text": "Such networks have been applied to few-shot image recognition (Santoro et al., 2016; Munkhdalai & Yu, 2017) and learning \u201cfast\u201d reinforcement learning agents (Duan et al., 2016b; Wang et al., 2016)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 275,
                                "start": 257
                            }
                        ],
                        "text": "\u2026methods, memory-augmented neural networks (Santoro et al., 2016) specifically, and recurrent meta-learning models in general, represent a more broadly applicable class of methods that, like MAML, can be used for other tasks such as reinforcement learning (Duan et al., 2016b; Wang et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 130
                            }
                        ],
                        "text": "In contrast to prior work, which has sought to train recurrent neural networks that ingest entire datasets (Santoro et al., 2016; Duan et al., 2016b) or feature embeddings that can be combined with nonparametric methods at test time (Vinyals et al., 2016; Koch, 2015), we propose a method that can\u2026"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 14763001,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "954b01151ff13aef416d27adc60cd9a076753b1a",
            "isKey": false,
            "numCitedBy": 629,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep reinforcement learning (deep RL) has been successful in learning sophisticated behaviors automatically; however, the learning process requires a huge number of trials. In contrast, animals can learn new tasks in just a few trials, benefiting from their prior knowledge about the world. This paper seeks to bridge this gap. Rather than designing a \"fast\" reinforcement learning algorithm, we propose to represent it as a recurrent neural network (RNN) and learn it from data. In our proposed method, RL$^2$, the algorithm is encoded in the weights of the RNN, which are learned slowly through a general-purpose (\"slow\") RL algorithm. The RNN receives all information a typical RL algorithm would receive, including observations, actions, rewards, and termination flags; and it retains its state across episodes in a given Markov Decision Process (MDP). The activations of the RNN store the state of the \"fast\" RL algorithm on the current (previously unseen) MDP. We evaluate RL$^2$ experimentally on both small-scale and large-scale problems. On the small-scale side, we train it to solve randomly generated multi-arm bandit problems and finite MDPs. After RL$^2$ is trained, its performance on new MDPs is close to human-designed algorithms with optimality guarantees. On the large-scale side, we test RL$^2$ on a vision-based navigation task and show that it scales up to high-dimensional problems."
            },
            "slug": "RL$^2$:-Fast-Reinforcement-Learning-via-Slow-Duan-Schulman",
            "title": {
                "fragments": [],
                "text": "RL$^2$: Fast Reinforcement Learning via Slow Reinforcement Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper proposes to represent a \"fast\" reinforcement learning algorithm as a recurrent neural network (RNN) and learn it from data, encoded in the weights of the RNN, which are learned slowly through a general-purpose (\"slow\") RL algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3308557"
                        ],
                        "name": "S. Hochreiter",
                        "slug": "S.-Hochreiter",
                        "structuredName": {
                            "firstName": "Sepp",
                            "lastName": "Hochreiter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hochreiter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145547836"
                        ],
                        "name": "A. S. Younger",
                        "slug": "A.-S.-Younger",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Younger",
                            "middleNames": [
                                "Steven"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. S. Younger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2927101"
                        ],
                        "name": "P. R. Conwell",
                        "slug": "P.-R.-Conwell",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Conwell",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. R. Conwell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 71
                            }
                        ],
                        "text": "This approach has been applied to learning to optimize neural networks (Hochreiter et al., 2001; Andrychowicz et al., 2016; Li & Malik, 2017), as well as for learning dynamically changing recurrent neural networks (Ha et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 70
                            }
                        ],
                        "text": "This approach has been applied to learning to optimize deep networks (Hochreiter et al., 2001; Andrychowicz et al., 2016; Li & Malik, 2017), as well as for learning dynamically changing recurrent networks (Ha et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 52872549,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "044b2c29e0a54dc689786bd4d029b9ba6e355d58",
            "isKey": false,
            "numCitedBy": 492,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces the application of gradient descent methods to meta-learning. The concept of \"meta-learning\", i.e. of a system that improves or discovers a learning algorithm, has been of interest in machine learning for decades because of its appealing applications. Previous meta-learning approaches have been based on evolutionary methods and, therefore, have been restricted to small models with few free parameters. We make meta-learning in large systems feasible by using recurrent neural networks withth eir attendant learning routines as meta-learning systems. Our system derived complex well performing learning algorithms from scratch. In this paper we also show that our approachp erforms non-stationary time series prediction."
            },
            "slug": "Learning-to-Learn-Using-Gradient-Descent-Hochreiter-Younger",
            "title": {
                "fragments": [],
                "text": "Learning to Learn Using Gradient Descent"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This paper makes meta- learning in large systems feasible by using recurrent neural networks with attendant learning routines as meta-learning systems and shows that the approach to gradient descent methods forms non-stationary time series prediction."
            },
            "venue": {
                "fragments": [],
                "text": "ICANN"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2887364"
                        ],
                        "name": "Tim Salimans",
                        "slug": "Tim-Salimans",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Salimans",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Salimans"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726807"
                        ],
                        "name": "Diederik P. Kingma",
                        "slug": "Diederik-P.-Kingma",
                        "structuredName": {
                            "firstName": "Diederik",
                            "lastName": "Kingma",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diederik P. Kingma"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 151231,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d2c6941a9b4608ba52b328369a3352db2092ae0",
            "isKey": false,
            "numCitedBy": 1290,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "We present weight normalization: a reparameterization of the weight vectors in a neural network that decouples the length of those weight vectors from their direction. By reparameterizing the weights in this way we improve the conditioning of the optimization problem and we speed up convergence of stochastic gradient descent. Our reparameterization is inspired by batch normalization but does not introduce any dependencies between the examples in a minibatch. This means that our method can also be applied successfully to recurrent models such as LSTMs and to noise-sensitive applications such as deep reinforcement learning or generative models, for which batch normalization is less well suited. Although our method is much simpler, it still provides much of the speed-up of full batch normalization. In addition, the computational overhead of our method is lower, permitting more optimization steps to be taken in the same amount of time. We demonstrate the usefulness of our method on applications in supervised image recognition, generative modelling, and deep reinforcement learning."
            },
            "slug": "Weight-Normalization:-A-Simple-Reparameterization-Salimans-Kingma",
            "title": {
                "fragments": [],
                "text": "Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A reparameterization of the weight vectors in a neural network that decouples the length of those weight vectors from their direction is presented, improving the conditioning of the optimization problem and speeding up convergence of stochastic gradient descent."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748523"
                        ],
                        "name": "Danilo Jimenez Rezende",
                        "slug": "Danilo-Jimenez-Rezende",
                        "structuredName": {
                            "firstName": "Danilo",
                            "lastName": "Jimenez Rezende",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Danilo Jimenez Rezende"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14594344"
                        ],
                        "name": "S. Mohamed",
                        "slug": "S.-Mohamed",
                        "structuredName": {
                            "firstName": "Shakir",
                            "lastName": "Mohamed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mohamed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1841008"
                        ],
                        "name": "Ivo Danihelka",
                        "slug": "Ivo-Danihelka",
                        "structuredName": {
                            "firstName": "Ivo",
                            "lastName": "Danihelka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ivo Danihelka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144717963"
                        ],
                        "name": "Karol Gregor",
                        "slug": "Karol-Gregor",
                        "structuredName": {
                            "firstName": "Karol",
                            "lastName": "Gregor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karol Gregor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688276"
                        ],
                        "name": "Daan Wierstra",
                        "slug": "Daan-Wierstra",
                        "structuredName": {
                            "firstName": "Daan",
                            "lastName": "Wierstra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daan Wierstra"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 124
                            }
                        ],
                        "text": "Few-shot learning methods have also been developed for\nspecific tasks such as generative modeling (Edwards & Storkey, 2017; Rezende et al., 2016) and image recognition (Vinyals et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5985692,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0811597b0851b7ebe21aadce7cb4daac4664b44f",
            "isKey": false,
            "numCitedBy": 202,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Humans have an impressive ability to reason about new concepts and experiences from just a single example. In particular, humans have an ability for one-shot generalization: an ability to encounter a new concept, understand its structure, and then be able to generate compelling alternative variations of the concept. We develop machine learning systems with this important capacity by developing new deep generative models, models that combine the representational power of deep learning with the inferential power of Bayesian reasoning. We develop a class of sequential generative models that are built on the principles of feedback and attention. These two characteristics lead to generative models that are among the state-of-the art in density estimation and image generation. We demonstrate the one-shot generalization ability of our models using three tasks: unconditional sampling, generating new exemplars of a given concept, and generating new exemplars of a family of concepts. In all cases our models are able to generate compelling and diverse samples-- having seen new examples just once--providing an important class of general-purpose models for one-shot machine learning."
            },
            "slug": "One-Shot-Generalization-in-Deep-Generative-Models-Rezende-Mohamed",
            "title": {
                "fragments": [],
                "text": "One-Shot Generalization in Deep Generative Models"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "New deep generative models are developed, models that combine the representational power of deep learning with the inferential power of Bayesian reasoning, and are able to generate compelling and diverse samples, providing an important class of general-purpose models for one-shot machine learning."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39770136"
                        ],
                        "name": "Jake Snell",
                        "slug": "Jake-Snell",
                        "structuredName": {
                            "firstName": "Jake",
                            "lastName": "Snell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jake Snell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754860"
                        ],
                        "name": "Kevin Swersky",
                        "slug": "Kevin-Swersky",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Swersky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Swersky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804104"
                        ],
                        "name": "R. Zemel",
                        "slug": "R.-Zemel",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Zemel",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zemel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 70
                            }
                        ],
                        "text": "Siamese networks (Koch, 2015) or recurrence with attention mechanisms (Vinyals et al., 2016; Shyam et al., 2017; Snell et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 256,
                                "start": 238
                            }
                        ],
                        "text": "One successful approach for few-shot classification is to learn to compare new examples in a learned metric space using e.g. Siamese networks (Koch, 2015) or recurrence with attention mechanisms (Vinyals et al., 2016; Shyam et al., 2017; Snell et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 309759,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c269858a7bb34e8350f2442ccf37797856ae9bca",
            "isKey": false,
            "numCitedBy": 3503,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose Prototypical Networks for the problem of few-shot classification, where a classifier must generalize to new classes not seen in the training set, given only a small number of examples of each new class. Prototypical Networks learn a metric space in which classification can be performed by computing distances to prototype representations of each class. Compared to recent approaches for few-shot learning, they reflect a simpler inductive bias that is beneficial in this limited-data regime, and achieve excellent results. We provide an analysis showing that some simple design decisions can yield substantial improvements over recent approaches involving complicated architectural choices and meta-learning. We further extend Prototypical Networks to zero-shot learning and achieve state-of-the-art results on the CU-Birds dataset."
            },
            "slug": "Prototypical-Networks-for-Few-shot-Learning-Snell-Swersky",
            "title": {
                "fragments": [],
                "text": "Prototypical Networks for Few-shot Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This work proposes Prototypical Networks for few-shot classification, and provides an analysis showing that some simple design decisions can yield substantial improvements over recent approaches involving complicated architectural choices and meta-learning."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144632352"
                        ],
                        "name": "Harrison Edwards",
                        "slug": "Harrison-Edwards",
                        "structuredName": {
                            "firstName": "Harrison",
                            "lastName": "Edwards",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Harrison Edwards"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728216"
                        ],
                        "name": "A. Storkey",
                        "slug": "A.-Storkey",
                        "structuredName": {
                            "firstName": "Amos",
                            "lastName": "Storkey",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Storkey"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 253,
                                "start": 230
                            }
                        ],
                        "text": "\u20265-shot\nMANN, no conv (Santoro et al., 2016) 82.8% 94.9% \u2013 \u2013 MAML, no conv (ours) 89.7\u00b1 1.1% 97.5\u00b1 0.6% \u2013 \u2013 Siamese nets (Koch, 2015) 97.3% 98.4% 88.2% 97.0% matching nets (Vinyals et al., 2016) 98.1% 98.9% 93.8% 98.5% neural statistician (Edwards & Storkey, 2017) 98.1% 99.5% 93.2% 98.1% memory mod."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 99
                            }
                        ],
                        "text": "Few-shot learning methods have also been developed for\nspecific tasks such as generative modeling (Edwards & Storkey, 2017; Rezende et al., 2016) and image recognition (Vinyals et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4994434,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "405c31c85a324942811f3c9dc53ce3528f9284df",
            "isKey": true,
            "numCitedBy": 313,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "An efficient learner is one who reuses what they already know to tackle a new problem. For a machine learner, this means understanding the similarities amongst datasets. In order to do this, one must take seriously the idea of working with datasets, rather than datapoints, as the key objects to model. Towards this goal, we demonstrate an extension of a variational autoencoder that can learn a method for computing representations, or statistics, of datasets in an unsupervised fashion. The network is trained to produce statistics that encapsulate a generative model for each dataset. Hence the network enables efficient learning from new datasets for both unsupervised and supervised tasks. We show that we are able to learn statistics that can be used for: clustering datasets, transferring generative models to new datasets, selecting representative samples of datasets and classifying previously unseen classes. We refer to our model as a neural statistician, and by this we mean a neural network that can learn to compute summary statistics of datasets without supervision."
            },
            "slug": "Towards-a-Neural-Statistician-Edwards-Storkey",
            "title": {
                "fragments": [],
                "text": "Towards a Neural Statistician"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "An extension of a variational autoencoder that can learn a method for computing representations, or statistics, of datasets in an unsupervised fashion is demonstrated that is able to learn statistics that can be used for clustering datasets, transferring generative models to new datasets, selecting representative samples of datasets and classifying previously unseen classes."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2071479809"
                        ],
                        "name": "D. K. Naik",
                        "slug": "D.-K.-Naik",
                        "structuredName": {
                            "firstName": "Dattika",
                            "lastName": "Naik",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. K. Naik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1872039"
                        ],
                        "name": "R. Mammone",
                        "slug": "R.-Mammone",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Mammone",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mammone"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61444551,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b64e846fe88acaf302248249696c3b7badde41b5",
            "isKey": false,
            "numCitedBy": 148,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "A novel method for training neural networks is introduced. The method uses an additional observing neural network called a meta-neural network (MNN) to direct the training of the basic neural network. The MNN provides the basic neural network with a step size and a direction vector which is optimal based on successful training strategies learned from problems solved previously. The combination of the MNN with the basic neural network is shown to improve learning rates for several problems when the MNN is trained on a similar problem. The MNN is shown to help solve the problem of sensitivity to initial weight vectors. In addition, computer simulations demonstrate the improvement in the learning rate of the enhanced neural network on a 4-b parity problem, when it has been trained on a different nonlinear Boolean function.<<ETX>>"
            },
            "slug": "Meta-neural-networks-that-learn-by-learning-Naik-Mammone",
            "title": {
                "fragments": [],
                "text": "Meta-neural networks that learn by learning"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "A novel method for training neural networks using an additional observing neural network called a meta-neural network (MNN) to direct the training of the basic neural network and the MNN is shown to help solve the problem of sensitivity to initial weight vectors."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings 1992] IJCNN International Joint Conference on Neural Networks"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2206490"
                        ],
                        "name": "Marcin Andrychowicz",
                        "slug": "Marcin-Andrychowicz",
                        "structuredName": {
                            "firstName": "Marcin",
                            "lastName": "Andrychowicz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marcin Andrychowicz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715051"
                        ],
                        "name": "Misha Denil",
                        "slug": "Misha-Denil",
                        "structuredName": {
                            "firstName": "Misha",
                            "lastName": "Denil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Misha Denil"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2016840"
                        ],
                        "name": "Sergio Gomez Colmenarejo",
                        "slug": "Sergio-Gomez-Colmenarejo",
                        "structuredName": {
                            "firstName": "Sergio",
                            "lastName": "Colmenarejo",
                            "middleNames": [
                                "Gomez"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sergio Gomez Colmenarejo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3243579"
                        ],
                        "name": "Matthew W. Hoffman",
                        "slug": "Matthew-W.-Hoffman",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hoffman",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew W. Hoffman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144846367"
                        ],
                        "name": "D. Pfau",
                        "slug": "D.-Pfau",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Pfau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Pfau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725157"
                        ],
                        "name": "T. Schaul",
                        "slug": "T.-Schaul",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Schaul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Schaul"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 150
                            }
                        ],
                        "text": "The key idea underlying our method is to train the model\u2019s initial parameters such that the model has maximal performance on a new task after the parameters have been updated through one or more gradient steps computed with a small amount of data from that new task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 123
                            }
                        ],
                        "text": "Unlike prior meta-learning methods that learn an update function or learning rule (Schmidhuber, 1987; Bengio et al., 1992; Andrychowicz et al., 2016; Ravi & Larochelle, 2017), our algorithm does not expand the number of learned parameters nor place constraints on the model architecture (e.g. by\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 95
                            }
                        ],
                        "text": "This approach has been applied to learning to optimize deep networks (Hochreiter et al., 2001; Andrychowicz et al., 2016; Li & Malik, 2017), as well as for learning dynamically changing recurrent networks (Ha et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2928017,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "395dd01c0d24777c660cf195c4cfadcdf51fb7e8",
            "isKey": false,
            "numCitedBy": 1329,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "The move from hand-designed features to learned features in machine learning has been wildly successful. In spite of this, optimization algorithms are still designed by hand. In this paper we show how the design of an optimization algorithm can be cast as a learning problem, allowing the algorithm to learn to exploit structure in the problems of interest in an automatic way. Our learned algorithms, implemented by LSTMs, outperform generic, hand-designed competitors on the tasks for which they are trained, and also generalize well to new tasks with similar structure. We demonstrate this on a number of tasks, including simple convex problems, training neural networks, and styling images with neural art."
            },
            "slug": "Learning-to-learn-by-gradient-descent-by-gradient-Andrychowicz-Denil",
            "title": {
                "fragments": [],
                "text": "Learning to learn by gradient descent by gradient descent"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper shows how the design of an optimization algorithm can be cast as a learning problem, allowing the algorithm to learn to exploit structure in the problems of interest in an automatic way."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726807"
                        ],
                        "name": "Diederik P. Kingma",
                        "slug": "Diederik-P.-Kingma",
                        "structuredName": {
                            "firstName": "Diederik",
                            "lastName": "Kingma",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diederik P. Kingma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2503659"
                        ],
                        "name": "Jimmy Ba",
                        "slug": "Jimmy-Ba",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Ba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy Ba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 139
                            }
                        ],
                        "text": "When training with MAML, we use one gradient update with K = 10 examples with a fixed step size \u03b1 = 0.01, and use Adam as the metaoptimizer (Kingma & Ba, 2015)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6628106,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6cb366736791bcccc5c8639de5a8f9636bf87e8",
            "isKey": true,
            "numCitedBy": 90064,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm."
            },
            "slug": "Adam:-A-Method-for-Stochastic-Optimization-Kingma-Ba",
            "title": {
                "fragments": [],
                "text": "Adam: A Method for Stochastic Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This work introduces Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments, and provides a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751569"
                        ],
                        "name": "Samy Bengio",
                        "slug": "Samy-Bengio",
                        "structuredName": {
                            "firstName": "Samy",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samy Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2909364"
                        ],
                        "name": "J. Cloutier",
                        "slug": "J.-Cloutier",
                        "structuredName": {
                            "firstName": "Jocelyn",
                            "lastName": "Cloutier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cloutier"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 167
                            }
                        ],
                        "text": "A popular approach for metalearning is to train a meta-learner that learns how to update the parameters of the learner\u2019s model (Bengio et al., 1992; Schmidhuber, 1992; Bengio et al., 1990)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1734973,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "d130325c41947a41a55a4431e9e8e15be89da8ea",
            "isKey": false,
            "numCitedBy": 246,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Summary form only given, as follows. The authors discuss an original approach to neural modeling based on the idea of searching, with learning methods, for a synaptic learning rule which is biologically plausible and yields networks that are able to learn to perform difficult tasks. The proposed method of automatically finding the learning rule relies on the idea of considering the synaptic modification rule as a parametric function. This function has local inputs and is the same in many neurons. The parameters that define this function can be estimated with known learning methods. For this optimization, particular attention is given to gradient descent and genetic algorithms. In both cases, estimation of this function consists of a joint global optimization of the synaptic modification function and the networks that are learning to perform some tasks. Both network architecture and the learning function can be designed within constraints derived from biological knowledge.<<ETX>>"
            },
            "slug": "Learning-a-synaptic-learning-rule-Bengio-Bengio",
            "title": {
                "fragments": [],
                "text": "Learning a synaptic learning rule"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "An original approach to neural modeling based on the idea of searching, with learning methods, for a synaptic learning rule which is biologically plausible and yields networks that are able to learn to perform difficult tasks is discussed."
            },
            "venue": {
                "fragments": [],
                "text": "IJCNN-91-Seattle International Joint Conference on Neural Networks"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7408951"
                        ],
                        "name": "Jeff Donahue",
                        "slug": "Jeff-Donahue",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Donahue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeff Donahue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39978391"
                        ],
                        "name": "Yangqing Jia",
                        "slug": "Yangqing-Jia",
                        "structuredName": {
                            "firstName": "Yangqing",
                            "lastName": "Jia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yangqing Jia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689108"
                        ],
                        "name": "Oriol Vinyals",
                        "slug": "Oriol-Vinyals",
                        "structuredName": {
                            "firstName": "Oriol",
                            "lastName": "Vinyals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oriol Vinyals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50196944"
                        ],
                        "name": "Judy Hoffman",
                        "slug": "Judy-Hoffman",
                        "structuredName": {
                            "firstName": "Judy",
                            "lastName": "Hoffman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Judy Hoffman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152329702"
                        ],
                        "name": "Ning Zhang",
                        "slug": "Ning-Zhang",
                        "structuredName": {
                            "firstName": "Ning",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ning Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2368132"
                        ],
                        "name": "Eric Tzeng",
                        "slug": "Eric-Tzeng",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Tzeng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eric Tzeng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 160
                            }
                        ],
                        "text": "In computer vision, models pretrained on large-scale image classification tasks have been shown to learn effective features for a wide range of vision problems (Donahue et al., 2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 143
                            }
                        ],
                        "text": "In computer vision, models pretrained on large-scale image classification have been shown to learn effective features for a range of problems (Donahue et al., 2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6161478,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b8de958fead0d8a9619b55c7299df3257c624a96",
            "isKey": false,
            "numCitedBy": 4234,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "We evaluate whether features extracted from the activation of a deep convolutional network trained in a fully supervised fashion on a large, fixed set of object recognition tasks can be repurposed to novel generic tasks. Our generic tasks may differ significantly from the originally trained tasks and there may be insufficient labeled or unlabeled data to conventionally train or adapt a deep architecture to the new tasks. We investigate and visualize the semantic clustering of deep convolutional features with respect to a variety of such tasks, including scene recognition, domain adaptation, and fine-grained recognition challenges. We compare the efficacy of relying on various network levels to define a fixed feature, and report novel results that significantly outperform the state-of-the-art on several important vision challenges. We are releasing DeCAF, an open-source implementation of these deep convolutional activation features, along with all associated network parameters to enable vision researchers to be able to conduct experimentation with deep representations across a range of visual concept learning paradigms."
            },
            "slug": "DeCAF:-A-Deep-Convolutional-Activation-Feature-for-Donahue-Jia",
            "title": {
                "fragments": [],
                "text": "DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "DeCAF, an open-source implementation of deep convolutional activation features, along with all associated network parameters, are released to enable vision researchers to be able to conduct experimentation with deep representations across a range of visual concept learning paradigms."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40527594"
                        ],
                        "name": "Lukasz Kaiser",
                        "slug": "Lukasz-Kaiser",
                        "structuredName": {
                            "firstName": "Lukasz",
                            "lastName": "Kaiser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lukasz Kaiser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7624658"
                        ],
                        "name": "Ofir Nachum",
                        "slug": "Ofir-Nachum",
                        "structuredName": {
                            "firstName": "Ofir",
                            "lastName": "Nachum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ofir Nachum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39788470"
                        ],
                        "name": "Aurko Roy",
                        "slug": "Aurko-Roy",
                        "structuredName": {
                            "firstName": "Aurko",
                            "lastName": "Roy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aurko Roy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751569"
                        ],
                        "name": "Samy Bengio",
                        "slug": "Samy-Bengio",
                        "structuredName": {
                            "firstName": "Samy",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samy Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 1
                            }
                        ],
                        "text": "(Kaiser et al., 2017) 98.4% 99.6% 95.0% 98.6% MAML (ours) 98.7\u00b1 0.4% 99.9\u00b1 0.1% 95.8\u00b1 0.3% 98.9\u00b1 0.2%\n5-way Accuracy MiniImagenet (Ravi & Larochelle, 2017) 1-shot 5-shot fine-tuning baseline 28.86\u00b1 0.54% 49.79\u00b1 0.79% nearest neighbor baseline 41.08\u00b1 0.70% 51.04\u00b1 0.65% matching nets (Vinyals et al.,\u2026"
                    },
                    "intents": []
                }
            ],
            "corpusId": 12122362,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a0d253053ce8646e49904efe0e062bcc30d8257",
            "isKey": true,
            "numCitedBy": 265,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Despite recent advances, memory-augmented deep neural networks are still limited when it comes to life-long and one-shot learning, especially in remembering rare events. We present a large-scale life-long memory module for use in deep learning. The module exploits fast nearest-neighbor algorithms for efficiency and thus scales to large memory sizes. Except for the nearest-neighbor query, the module is fully differentiable and trained end-to-end with no extra supervision. It operates in a life-long manner, i.e., without the need to reset it during training. \nOur memory module can be easily added to any part of a supervised neural network. To show its versatility we add it to a number of networks, from simple convolutional ones tested on image classification to deep sequence-to-sequence and recurrent-convolutional models. In all cases, the enhanced network gains the ability to remember and do life-long one-shot learning. Our module remembers training examples shown many thousands of steps in the past and it can successfully generalize from them. We set new state-of-the-art for one-shot learning on the Omniglot dataset and demonstrate, for the first time, life-long one-shot learning in recurrent neural networks on a large-scale machine translation task."
            },
            "slug": "Learning-to-Remember-Rare-Events-Kaiser-Nachum",
            "title": {
                "fragments": [],
                "text": "Learning to Remember Rare Events"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A large-scale life-long memory module for use in deep learning that remembers training examples shown many thousands of steps in the past and it can successfully generalize from them and demonstrate, for the first time, life- long one-shot learning in recurrent neural networks on a large- scale machine translation task."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722195"
                        ],
                        "name": "Michael H\u00fcsken",
                        "slug": "Michael-H\u00fcsken",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "H\u00fcsken",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael H\u00fcsken"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680943"
                        ],
                        "name": "C. Goerick",
                        "slug": "C.-Goerick",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Goerick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Goerick"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 242,
                                "start": 220
                            }
                        ],
                        "text": "Most of these works have considered good random initializations, though a number of papers have addressed datadependent initializers (Kra\u0308henbu\u0308hl et al., 2016; Salimans & Kingma, 2016), including learned initializations (Husken & Goerick, 2000; Maclaurin et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11171160,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "946ec39029db3ae6f9a1b3ce13fb3f4a7d37bb5e",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The success of learning as well as the learning speed of an artificial neural network (ANN) strongly depends on the initial weights. If problem or domain specific knowledge exists, it can be transferred to the ANN by means of a special choice of the initial weights. In this paper, we focus on the choice of a set of initial weights, well suited to fast and robust learning of all particular problems out of a class of related problems. Our evolutionary approach particularly takes the learning algorithm into consideration in the design of the initial weights. The superior properties of the initial weights resulting from this algorithm are corroborated using a class defined by solving a differential equation with variable boundary conditions."
            },
            "slug": "Fast-learning-for-problem-classes-using-knowledge-H\u00fcsken-Goerick",
            "title": {
                "fragments": [],
                "text": "Fast learning for problem classes using knowledge based network initialization"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper focuses on the choice of a set of initial weights, well suited to fast and robust learning of all particular problems out of a class of related problems, and particularly takes the learning algorithm into consideration in the design of the initial weights."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE-INNS-ENNS International Joint Conference on Neural Networks. IJCNN 2000. Neural Computing: New Challenges and Perspectives for the New Millennium"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34927843"
                        ],
                        "name": "Andrew M. Saxe",
                        "slug": "Andrew-M.-Saxe",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Saxe",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew M. Saxe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701656"
                        ],
                        "name": "James L. McClelland",
                        "slug": "James-L.-McClelland",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "McClelland",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James L. McClelland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "25769960"
                        ],
                        "name": "S. Ganguli",
                        "slug": "S.-Ganguli",
                        "structuredName": {
                            "firstName": "Surya",
                            "lastName": "Ganguli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ganguli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 160
                            }
                        ],
                        "text": "A number of prior works have explored the topic of sensitivity in deep networks, often in the context of studying initialization techniques for weight matrices (Saxe et al., 2014; Kirkpatrick et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 108
                            }
                        ],
                        "text": "A number of prior works have explored sensitivity in deep networks, often in the context of initialization (Saxe et al., 2014; Kirkpatrick et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17272965,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "99c970348b8f70ce23d6641e201904ea49266b6e",
            "isKey": false,
            "numCitedBy": 1264,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Despite the widespread practical success of deep learning methods, our theoretical understanding of the dynamics of learning in deep neural networks remains quite sparse. We attempt to bridge the gap between the theory and practice of deep learning by systematically analyzing learning dynamics for the restricted case of deep linear neural networks. Despite the linearity of their input-output map, such networks have nonlinear gradient descent dynamics on weights that change with the addition of each new hidden layer. We show that deep linear networks exhibit nonlinear learning phenomena similar to those seen in simulations of nonlinear networks, including long plateaus followed by rapid transitions to lower error solutions, and faster convergence from greedy unsupervised pretraining initial conditions than from random initial conditions. We provide an analytical description of these phenomena by finding new exact solutions to the nonlinear dynamics of deep learning. Our theoretical analysis also reveals the surprising finding that as the depth of a network approaches infinity, learning speed can nevertheless remain finite: for a special class of initial conditions on the weights, very deep networks incur only a finite, depth independent, delay in learning speed relative to shallow networks. We show that, under certain conditions on the training data, unsupervised pretraining can find this special class of initial conditions, while scaled random Gaussian initializations cannot. We further exhibit a new class of random orthogonal initial conditions on weights that, like unsupervised pre-training, enjoys depth independent learning times. We further show that these initial conditions also lead to faithful propagation of gradients even in deep nonlinear networks, as long as they operate in a special regime known as the edge of chaos."
            },
            "slug": "Exact-solutions-to-the-nonlinear-dynamics-of-in-Saxe-McClelland",
            "title": {
                "fragments": [],
                "text": "Exact solutions to the nonlinear dynamics of learning in deep linear neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that deep linear networks exhibit nonlinear learning phenomena similar to those seen in simulations of nonlinear networks, including long plateaus followed by rapid transitions to lower error solutions, and faster convergence from greedy unsupervised pretraining initial conditions than from random initial conditions."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751569"
                        ],
                        "name": "Samy Bengio",
                        "slug": "Samy-Bengio",
                        "structuredName": {
                            "firstName": "Samy",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samy Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2909364"
                        ],
                        "name": "J. Cloutier",
                        "slug": "J.-Cloutier",
                        "structuredName": {
                            "firstName": "Jocelyn",
                            "lastName": "Cloutier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cloutier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3349607"
                        ],
                        "name": "J. Gecsei",
                        "slug": "J.-Gecsei",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Gecsei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Gecsei"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 127
                            }
                        ],
                        "text": "A popular approach for metalearning is to train a meta-learner that learns how to update the parameters of the learner\u2019s model (Bengio et al., 1992; Schmidhuber, 1992; Bengio et al., 1990)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 129
                            }
                        ],
                        "text": "The key idea underlying our method is to train the model\u2019s initial parameters such that the model has maximal performance on a new task after the parameters have been updated through one or more gradient steps computed with a small amount of data from that new task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 102
                            }
                        ],
                        "text": "Unlike prior meta-learning methods that learn an update function or learning rule (Schmidhuber, 1987; Bengio et al., 1992; Andrychowicz et al., 2016; Ravi & Larochelle, 2017), our algorithm does not expand the number of learned parameters nor place constraints on the model architecture (e.g. by\u2026"
                    },
                    "intents": []
                }
            ],
            "corpusId": 28783413,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8784f905f4f9fb6fa4a3cc9b0faa5b5479c687ec",
            "isKey": false,
            "numCitedBy": 220,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new approach to neural modeling based on the idea of using an automated method to optimize the parameters of a synaptic learning rule The synaptic modi cation rule is considered as a parametric function This function has local inputs and is the same in many neurons We can use standard optimization methods to select appropriate parameters for a given type of task We also present a theoretical analysis permitting to study the generalization property of such parametric learning rules By generalization we mean the possibility for the learning rule to learn to solve new tasks Experiments were performed on three types of problems a biologically inspired circuit for conditioning in Aplysia Boolean functions linearly separable as well as non linearly separable and classi cation tasks The neural network architecture as well as the form and initial parameter values of the synaptic learning function can be designed using a priori knowledge"
            },
            "slug": "On-the-Optimization-of-a-Synaptic-Learning-Rule-Bengio-Bengio",
            "title": {
                "fragments": [],
                "text": "On the Optimization of a Synaptic Learning Rule"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A new approach to neural modeling based on the idea of using an automated method to optimize the parameters of a synaptic learning rule and a theoretical analysis permitting to study the generalization property of such parametric learning rules is presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683298"
                        ],
                        "name": "D. Maclaurin",
                        "slug": "D.-Maclaurin",
                        "structuredName": {
                            "firstName": "Dougal",
                            "lastName": "Maclaurin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Maclaurin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704657"
                        ],
                        "name": "D. Duvenaud",
                        "slug": "D.-Duvenaud",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Duvenaud",
                            "middleNames": [
                                "Kristjanson"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Duvenaud"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722180"
                        ],
                        "name": "Ryan P. Adams",
                        "slug": "Ryan-P.-Adams",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "Adams",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan P. Adams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 68
                            }
                        ],
                        "text": ", 2016; Salimans & Kingma, 2016), including learned initializations (Husken & Goerick, 2000; Maclaurin et al., 2015)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 266,
                                "start": 244
                            }
                        ],
                        "text": "Most of these works have considered good random initializations, though a number of papers have addressed datadependent initializers (Kra\u0308henbu\u0308hl et al., 2016; Salimans & Kingma, 2016), including learned initializations (Husken & Goerick, 2000; Maclaurin et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8540522,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e2820bffe5b42cb7d88b7f65c12171c62ab4aae2",
            "isKey": false,
            "numCitedBy": 624,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Tuning hyperparameters of learning algorithms is hard because gradients are usually unavailable. We compute exact gradients of cross-validation performance with respect to all hyperparameters by chaining derivatives backwards through the entire training procedure. These gradients allow us to optimize thousands of hyperparameters, including step-size and momentum schedules, weight initialization distributions, richly parameterized regularization schemes, and neural network architectures. We compute hyperparameter gradients by exactly reversing the dynamics of stochastic gradient descent with momentum."
            },
            "slug": "Gradient-based-Hyperparameter-Optimization-through-Maclaurin-Duvenaud",
            "title": {
                "fragments": [],
                "text": "Gradient-based Hyperparameter Optimization through Reversible Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "This work computes exact gradients of cross-validation performance with respect to all hyperparameters by chaining derivatives backwards through the entire training procedure, which allows us to optimize thousands ofhyperparameters, including step-size and momentum schedules, weight initialization distributions, richly parameterized regularization schemes, and neural network architectures."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 77
                            }
                        ],
                        "text": "The gradient updates are computed using vanilla policy gradient (REINFORCE) (Williams, 1992), and we use trust-region policy optimization (TRPO) as the meta-optimizer (Schulman et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2332513,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4c915c1eecb217c123a36dc6d3ce52d12c742614",
            "isKey": false,
            "numCitedBy": 5180,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "This article presents a general class of associative reinforcement learning algorithms for connectionist networks containing stochastic units. These algorithms, called REINFORCE algorithms, are shown to make weight adjustments in a direction that lies along the gradient of expected reinforcement in both immediate-reinforcement tasks and certain limited forms of delayed-reinforcement tasks, and they do this without explicitly computing gradient estimates or even storing information from which such estimates could be computed. Specific examples of such algorithms are presented, some of which bear a close relationship to certain existing algorithms while others are novel but potentially interesting in their own right. Also given are results that show how such algorithms can be naturally integrated with backpropagation. We close with a brief discussion of a number of additional issues surrounding the use of such algorithms, including what is known about their limiting behaviors as well as further considerations that might be used to help develop similar but potentially more powerful reinforcement learning algorithms."
            },
            "slug": "Simple-statistical-gradient-following-algorithms-Williams",
            "title": {
                "fragments": [],
                "text": "Simple statistical gradient-following algorithms for connectionist reinforcement learning"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "This article presents a general class of associative reinforcement learning algorithms for connectionist networks containing stochastic units that are shown to make weight adjustments in a direction that lies along the gradient of expected reinforcement in both immediate-reinforcement tasks and certain limited forms of delayed-reInforcement tasks, and they do this without explicitly computing gradient estimates."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 148
                            }
                        ],
                        "text": "A popular approach for metalearning is to train a meta-learner that learns how to update the parameters of the learner\u2019s model (Bengio et al., 1992; Schmidhuber, 1992; Bengio et al., 1990)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16683347,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bc22e87a26d020215afe91c751e5bdaddd8e4922",
            "isKey": false,
            "numCitedBy": 268,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Previous algorithms for supervised sequence learning are based on dynamic recurrent networks. This paper describes an alternative class of gradient-based systems consisting of two feedforward nets that learn to deal with temporal sequences using fast weights: The first net learns to produce context-dependent weight changes for the second net whose weights may vary very quickly. The method offers the potential for STM storage efficiency: A single weight (instead of a full-fledged unit) may be sufficient for storing temporal information. Various learning methods are derived. Two experiments with unknown time delays illustrate the approach. One experiment shows how the system can be used for adaptive temporary variable binding."
            },
            "slug": "Learning-to-Control-Fast-Weight-Memories:-An-to-Schmidhuber",
            "title": {
                "fragments": [],
                "text": "Learning to Control Fast-Weight Memories: An Alternative to Dynamic Recurrent Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "This paper describes an alternative class of gradient-based systems consisting of two feedforward nets that learn to deal with temporal sequences using fast weights: the first net learns to produce context-dependent weight changes for the second net whose weights may vary very quickly."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153440022"
                        ],
                        "name": "Ian J. Goodfellow",
                        "slug": "Ian-J.-Goodfellow",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Goodfellow",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ian J. Goodfellow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789737"
                        ],
                        "name": "Jonathon Shlens",
                        "slug": "Jonathon-Shlens",
                        "structuredName": {
                            "firstName": "Jonathon",
                            "lastName": "Shlens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathon Shlens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2574060"
                        ],
                        "name": "Christian Szegedy",
                        "slug": "Christian-Szegedy",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Szegedy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Szegedy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 75
                            }
                        ],
                        "text": "Past work has observed that ReLU neural networks are locally almost linear (Goodfellow et al., 2015), which suggests that second derivatives may be close to zero in most cases, partially explaining the good perforFigure 4."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 76
                            }
                        ],
                        "text": "Past work has observed that ReLU neural networks are locally almost linear (Goodfellow et al., 2015), which suggests that second derivatives may be close to zero in most cases, partially explaining the good perfor-\nFigure 4."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6706414,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bee044c8e8903fb67523c1f8c105ab4718600cdb",
            "isKey": false,
            "numCitedBy": 10104,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Several machine learning models, including neural networks, consistently misclassify adversarial examples---inputs formed by applying small but intentionally worst-case perturbations to examples from the dataset, such that the perturbed input results in the model outputting an incorrect answer with high confidence. Early attempts at explaining this phenomenon focused on nonlinearity and overfitting. We argue instead that the primary cause of neural networks' vulnerability to adversarial perturbation is their linear nature. This explanation is supported by new quantitative results while giving the first explanation of the most intriguing fact about them: their generalization across architectures and training sets. Moreover, this view yields a simple and fast method of generating adversarial examples. Using this approach to provide examples for adversarial training, we reduce the test set error of a maxout network on the MNIST dataset."
            },
            "slug": "Explaining-and-Harnessing-Adversarial-Examples-Goodfellow-Shlens",
            "title": {
                "fragments": [],
                "text": "Explaining and Harnessing Adversarial Examples"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is argued that the primary cause of neural networks' vulnerability to adversarial perturbation is their linear nature, supported by new quantitative results while giving the first explanation of the most intriguing fact about them: their generalization across architectures and training sets."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "67311962"
                        ],
                        "name": "Pranav Shyam",
                        "slug": "Pranav-Shyam",
                        "structuredName": {
                            "firstName": "Pranav",
                            "lastName": "Shyam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pranav Shyam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118927417"
                        ],
                        "name": "Shubham Gupta",
                        "slug": "Shubham-Gupta",
                        "structuredName": {
                            "firstName": "Shubham",
                            "lastName": "Gupta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shubham Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2440174"
                        ],
                        "name": "Ambedkar Dukkipati",
                        "slug": "Ambedkar-Dukkipati",
                        "structuredName": {
                            "firstName": "Ambedkar",
                            "lastName": "Dukkipati",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ambedkar Dukkipati"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 70
                            }
                        ],
                        "text": "Siamese networks (Koch, 2015) or recurrence with attention mechanisms (Vinyals et al., 2016; Shyam et al., 2017; Snell et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 236,
                                "start": 218
                            }
                        ],
                        "text": "One successful approach for few-shot classification is to learn to compare new examples in a learned metric space using e.g. Siamese networks (Koch, 2015) or recurrence with attention mechanisms (Vinyals et al., 2016; Shyam et al., 2017; Snell et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10939199,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a3cd82aeecb75ef339889174706d168c40187d7d",
            "isKey": false,
            "numCitedBy": 77,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Rapid learning requires flexible representations to quickly adopt to new evidence. We develop a novel class of models called Attentive Recurrent Comparators (ARCs) that form representations of objects by cycling through them and making observations. Using the representations extracted by ARCs, we develop a way of approximating a \\textit{dynamic representation space} and use it for one-shot learning. In the task of one-shot classification on the Omniglot dataset, we achieve the state of the art performance with an error rate of 1.5\\%. This represents the first super-human result achieved for this task with a generic model that uses only pixel information."
            },
            "slug": "Attentive-Recurrent-Comparators-Shyam-Gupta",
            "title": {
                "fragments": [],
                "text": "Attentive Recurrent Comparators"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This work develops a novel class of models called Attentive Recurrent Comparators (ARCs) that form representations of objects by cycling through them and making observations and develops a way of approximating a dynamic representation space and uses it for one-shot learning."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2373318"
                        ],
                        "name": "B. Lake",
                        "slug": "B.-Lake",
                        "structuredName": {
                            "firstName": "Brenden",
                            "lastName": "Lake",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Lake"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145372150"
                        ],
                        "name": "Jason Gross",
                        "slug": "Jason-Gross",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Gross",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jason Gross"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763295"
                        ],
                        "name": "J. Tenenbaum",
                        "slug": "J.-Tenenbaum",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Tenenbaum",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tenenbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 31
                            }
                        ],
                        "text": "5-way Accuracy 20-way Accuracy Omniglot (Lake et al., 2011) 1-shot 5-shot 1-shot 5-shot\nMANN, no conv (Santoro et al., 2016) 82.8% 94.9% \u2013 \u2013 MAML, no conv (ours) 89.7\u00b1 1.1% 97.5\u00b1 0.6% \u2013 \u2013 Siamese nets (Koch, 2015) 97.3% 98.4% 88.2% 97.0% matching nets (Vinyals et al., 2016) 98.1% 98.9% 93.8% 98.5% neural statistician (Edwards & Storkey, 2017) 98.1% 99.5% 93.2% 98.1% memory mod."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 4
                            }
                        ],
                        "text": "For Omniglot, we used strided convolutions instead of max-pooling."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 22
                            }
                        ],
                        "text": "We ran this method on Omniglot and two RL domains following the same experimental protocol."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 4
                            }
                        ],
                        "text": "The Omniglot dataset is augmented with rotations by multiples of 90 degrees, as proposed by Santoro et al. (2016)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 157
                            }
                        ],
                        "text": "To evaluate MAML in comparison to prior meta-learning and few-shot learning algorithms, we applied our method to few-shot image recognition on the Omniglot (Lake et al., 2011) and MiniImagenet datasets."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 41
                            }
                        ],
                        "text": "5-way Accuracy 20-way Accuracy Omniglot (Lake et al., 2011) 1-shot 5-shot 1-shot 5-shot\nMANN, no conv (Santoro et al., 2016) 82.8% 94.9% \u2013 \u2013 MAML, no conv (ours) 89.7\u00b1 1.1% 97.5\u00b1 0.6% \u2013 \u2013 Siamese nets (Koch, 2015) 97.3% 98.4% 88.2% 97.0% matching nets (Vinyals et al., 2016) 98.1% 98.9% 93.8% 98.5%\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 4
                            }
                        ],
                        "text": "The Omniglot and MiniImagenet image recognition tasks are the most common recently used few-shot learning benchmarks (Vinyals et al., 2016; Santoro et al., 2016; Ravi & Larochelle, 2017)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 4
                            }
                        ],
                        "text": "For Omniglot, the 5-way convolutional and non-convolutional MAML models were each trained with 1 gradient step with step size \u03b1 = 0.4 and a meta batch-size of 32 tasks."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 14
                            }
                        ],
                        "text": "Note that the Omniglot results may not be strictly comparable since the train/test splits used in the prior work were not available."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 36
                            }
                        ],
                        "text": "Few-shot classification on held-out Omniglot characters (top) and the MiniImagenet test set (bottom)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 129
                            }
                        ],
                        "text": "However, as shown in the comparison, MAML significantly outperforms memory-augmented networks and the meta-learner LSTM on 5-way Omniglot and MiniImagenet classification, both in the 1-shot and 5-shot case."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 4
                            }
                        ],
                        "text": "The Omniglot images are downsampled to 28 \u00d7 28, so the dimensionality of the last hidden layer is 64."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 4
                            }
                        ],
                        "text": "For Omniglot, we randomly select 1200 characters for training, irrespective of alphabet, and use the remaining for testing."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 179
                            }
                        ],
                        "text": "To evaluate MAML in comparison to prior meta-learning and few-shot learning algorithms, we evaluate our method on a few-shot character recognition task using the Omniglot dataset (Lake et al., 2011), which consists 20 instances of 1623 characters from 50 different alphabets."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 4
                            }
                        ],
                        "text": "The Omniglot dataset consists of 20 instances of 1623 characters from 50 different alphabets."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15373038,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "100a038fdf29b4b20801887f0ec40e3f10d9a4f9",
            "isKey": true,
            "numCitedBy": 615,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "One shot learning of simple visual concepts Brenden M. Lake, Ruslan Salakhutdinov, Jason Gross, and Joshua B. Tenenbaum Department of Brain and Cognitive Sciences Massachusetts Institute of Technology Abstract People can learn visual concepts from just one example, but it remains a mystery how this is accomplished. Many authors have proposed that transferred knowledge from more familiar concepts is a route to one shot learning, but what is the form of this abstract knowledge? One hypothesis is that the shar- ing of parts is core to one shot learning, and we evaluate this idea in the domain of handwritten characters, using a massive new dataset. These simple visual concepts have a rich inter- nal part structure, yet they are particularly tractable for com- putational models. We introduce a generative model of how characters are composed from strokes, where knowledge from previous characters helps to infer the latent strokes in novel characters. The stroke model outperforms a competing state- of-the-art character model on a challenging one shot learning task, and it provides a good fit to human perceptual data. Keywords: category learning; transfer learning; Bayesian modeling; neural networks Figure 1: Test yourself on one shot learning. From the example boxed in red, can you find the others in the array? On the left is a Segway and on the right is the first character of the Bengali alphabet. Answer for the Bengali character: Row 2, Column 3; Row 4, Column 2. A hallmark of human cognition is learning from just a few examples. For instance, a person only needs to see one Seg- way to acquire the concept and be able to discriminate future Segways from other vehicles like scooters and unicycles (Fig. 1 left). Similarly, children can acquire a new word from one encounter (Carey & Bartlett, 1978). How is one shot learning possible? New concepts are almost never learned in a vacuum. Past experience with other concepts in a domain can support the rapid learning of novel concepts, by showing the learner what matters for generalization. Many authors have suggested this as a route to one shot learning: transfer of abstract knowledge from old to new concepts, often called transfer learning, rep- resentation learning, or learning to learn. But what is the nature of the learned abstract knowledge that lets humans ac- quire new object concepts so quickly? The most straightforward proposals invoke attentional learning (Smith, Jones, Landau, Gershkoff-Stowe, & Samuel- son, 2002) or overhypotheses (Kemp, Perfors, & Tenenbaum, 2007; Dewar & Xu, in press), like the shape bias in word learning. Prior experience with concepts that are clearly orga- nized along one dimension (e.g., shape, as opposed to color or material) draws a learner\u2019s attention to that same dimension (Smith et al., 2002) \u2013 or increases the prior probability of new concepts concentrating on that same dimension (Kemp et al., 2007). But this approach is limited since it requires that the relevant dimensions of similarity be defined in advance. For many real-world concepts, the relevant dimensions of similarity may be constructed in the course of learning to learn. For instance, when we first see a Segway, we may parse it into a structure of familiar parts arranged in a novel configuration: it has two wheels, connected by a platform, supporting a motor and a central post at the top of which are two handlebars. These parts and their relations comprise a Figure 2: Examples from a new 1600 character database. useful representational basis for many different vehicle and artifact concepts \u2013 a representation that is likely learned in the course of learning the concepts that they support. Several papers from the recent machine learning and computer vision literature argue for such an approach: joint learning of many concepts and a high-level part vocabulary that underlies those concepts (e.g., Torralba, Murphy, & Freeman, 2007; Fei-Fei, Fergus, & Perona, 2006). Another recently popular machine learning approach is based on deep learning (Salakhutdinov & Hinton, 2009): unsupervised learning of hierarchies of dis- tributed feature representations in neural-network-style prob- abilistic generative models. These models do not specify ex- plicit parts and structural relations, but they can still construct meaningful representations of what makes two objects deeply similar that go substantially beyond low-level image features. These approaches from machine learning may be com- pelling ways to understand how humans learn so quickly, but there is little experimental evidence that directly supports them. Models that construct parts or features from sensory data (pixels) while learning object concepts have been tested in elegant behavioral experiments with very simple stimuli and a very small number of concepts (Austerweil & Griffiths, 2009; Schyns, Goldstone, & Thibaut, 1998). But there have been few systematic comparisons of multiple state-of-the-art computational approaches to representation learning with hu-"
            },
            "slug": "One-shot-learning-of-simple-visual-concepts-Lake-Salakhutdinov",
            "title": {
                "fragments": [],
                "text": "One shot learning of simple visual concepts"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A generative model of how characters are composed from strokes is introduced, where knowledge from previous characters helps to infer the latent strokes in novel characters, using a massive new dataset of handwritten characters."
            },
            "venue": {
                "fragments": [],
                "text": "CogSci"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2503659"
                        ],
                        "name": "Jimmy Ba",
                        "slug": "Jimmy-Ba",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Ba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy Ba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3255983"
                        ],
                        "name": "Volodymyr Mnih",
                        "slug": "Volodymyr-Mnih",
                        "structuredName": {
                            "firstName": "Volodymyr",
                            "lastName": "Mnih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Volodymyr Mnih"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700356"
                        ],
                        "name": "Joel Z. Leibo",
                        "slug": "Joel-Z.-Leibo",
                        "structuredName": {
                            "firstName": "Joel",
                            "lastName": "Leibo",
                            "middleNames": [
                                "Z."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joel Z. Leibo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2273228"
                        ],
                        "name": "Catalin Ionescu",
                        "slug": "Catalin-Ionescu",
                        "structuredName": {
                            "firstName": "Catalin",
                            "lastName": "Ionescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Catalin Ionescu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 96
                            }
                        ],
                        "text": "Memory augmentation can also take the form of a recurrent network with Hebbian learning updates (Ba et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 568305,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c91ae35dbcb6d479580ecd235eabf98374acdb55",
            "isKey": false,
            "numCitedBy": 162,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Until recently, research on artificial neural networks was largely restricted to systems with only two types of variable: Neural activities that represent the current or recent input and weights that learn to capture regularities among inputs, outputs and payoffs. There is no good reason for this restriction. Synapses have dynamics at many different time-scales and this suggests that artificial neural networks might benefit from variables that change slower than activities but much faster than the standard weights. These ``fast weights'' can be used to store temporary memories of the recent past and they provide a neurally plausible way of implementing the type of attention to the past that has recently proven helpful in sequence-to-sequence models. By using fast weights we can avoid the need to store copies of neural activity patterns."
            },
            "slug": "Using-Fast-Weights-to-Attend-to-the-Recent-Past-Ba-Hinton",
            "title": {
                "fragments": [],
                "text": "Using Fast Weights to Attend to the Recent Past"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "These ``fast weights'' can be used to store temporary memories of the recent past and they provide a neurally plausible way of implementing the type of attention to the past that has recently proven helpful in sequence-to-sequence models."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057642721"
                        ],
                        "name": "Mart\u00edn Abadi",
                        "slug": "Mart\u00edn-Abadi",
                        "structuredName": {
                            "firstName": "Mart\u00edn",
                            "lastName": "Abadi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mart\u00edn Abadi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2078528337"
                        ],
                        "name": "Ashish Agarwal",
                        "slug": "Ashish-Agarwal",
                        "structuredName": {
                            "firstName": "Ashish",
                            "lastName": "Agarwal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ashish Agarwal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144758007"
                        ],
                        "name": "P. Barham",
                        "slug": "P.-Barham",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Barham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Barham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2445241"
                        ],
                        "name": "E. Brevdo",
                        "slug": "E.-Brevdo",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Brevdo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Brevdo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2545358"
                        ],
                        "name": "Z. Chen",
                        "slug": "Z.-Chen",
                        "structuredName": {
                            "firstName": "Z.",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48738717"
                        ],
                        "name": "C. Citro",
                        "slug": "C.-Citro",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Citro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Citro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32131713"
                        ],
                        "name": "G. Corrado",
                        "slug": "G.-Corrado",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Corrado",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Corrado"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36347083"
                        ],
                        "name": "Andy Davis",
                        "slug": "Andy-Davis",
                        "structuredName": {
                            "firstName": "Andy",
                            "lastName": "Davis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andy Davis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49959210"
                        ],
                        "name": "J. Dean",
                        "slug": "J.-Dean",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Dean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dean"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145139947"
                        ],
                        "name": "Matthieu Devin",
                        "slug": "Matthieu-Devin",
                        "structuredName": {
                            "firstName": "Matthieu",
                            "lastName": "Devin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthieu Devin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780892"
                        ],
                        "name": "S. Ghemawat",
                        "slug": "S.-Ghemawat",
                        "structuredName": {
                            "firstName": "Sanjay",
                            "lastName": "Ghemawat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ghemawat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153440022"
                        ],
                        "name": "Ian J. Goodfellow",
                        "slug": "Ian-J.-Goodfellow",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Goodfellow",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ian J. Goodfellow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064102917"
                        ],
                        "name": "A. Harp",
                        "slug": "A.-Harp",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Harp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Harp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060655766"
                        ],
                        "name": "Geoffrey Irving",
                        "slug": "Geoffrey-Irving",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Irving",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey Irving"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2090818"
                        ],
                        "name": "M. Isard",
                        "slug": "M.-Isard",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Isard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Isard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39978391"
                        ],
                        "name": "Yangqing Jia",
                        "slug": "Yangqing-Jia",
                        "structuredName": {
                            "firstName": "Yangqing",
                            "lastName": "Jia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yangqing Jia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1944541"
                        ],
                        "name": "R. J\u00f3zefowicz",
                        "slug": "R.-J\u00f3zefowicz",
                        "structuredName": {
                            "firstName": "Rafal",
                            "lastName": "J\u00f3zefowicz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. J\u00f3zefowicz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40527594"
                        ],
                        "name": "Lukasz Kaiser",
                        "slug": "Lukasz-Kaiser",
                        "structuredName": {
                            "firstName": "Lukasz",
                            "lastName": "Kaiser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lukasz Kaiser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1942300"
                        ],
                        "name": "M. Kudlur",
                        "slug": "M.-Kudlur",
                        "structuredName": {
                            "firstName": "Manjunath",
                            "lastName": "Kudlur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kudlur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3369421"
                        ],
                        "name": "J. Levenberg",
                        "slug": "J.-Levenberg",
                        "structuredName": {
                            "firstName": "Josh",
                            "lastName": "Levenberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Levenberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30415265"
                        ],
                        "name": "Dandelion Man\u00e9",
                        "slug": "Dandelion-Man\u00e9",
                        "structuredName": {
                            "firstName": "Dandelion",
                            "lastName": "Man\u00e9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dandelion Man\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3089272"
                        ],
                        "name": "R. Monga",
                        "slug": "R.-Monga",
                        "structuredName": {
                            "firstName": "Rajat",
                            "lastName": "Monga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Monga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144375552"
                        ],
                        "name": "Sherry Moore",
                        "slug": "Sherry-Moore",
                        "structuredName": {
                            "firstName": "Sherry",
                            "lastName": "Moore",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sherry Moore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20154699"
                        ],
                        "name": "D. Murray",
                        "slug": "D.-Murray",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Murray",
                            "middleNames": [
                                "Gordon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Murray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37232298"
                        ],
                        "name": "C. Olah",
                        "slug": "C.-Olah",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Olah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Olah"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144927151"
                        ],
                        "name": "M. Schuster",
                        "slug": "M.-Schuster",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Schuster",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Schuster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789737"
                        ],
                        "name": "Jonathon Shlens",
                        "slug": "Jonathon-Shlens",
                        "structuredName": {
                            "firstName": "Jonathon",
                            "lastName": "Shlens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathon Shlens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32163737"
                        ],
                        "name": "Benoit Steiner",
                        "slug": "Benoit-Steiner",
                        "structuredName": {
                            "firstName": "Benoit",
                            "lastName": "Steiner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benoit Steiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35210462"
                        ],
                        "name": "Kunal Talwar",
                        "slug": "Kunal-Talwar",
                        "structuredName": {
                            "firstName": "Kunal",
                            "lastName": "Talwar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kunal Talwar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2080690"
                        ],
                        "name": "P. Tucker",
                        "slug": "P.-Tucker",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Tucker",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Tucker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2657155"
                        ],
                        "name": "Vincent Vanhoucke",
                        "slug": "Vincent-Vanhoucke",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Vanhoucke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vincent Vanhoucke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053781980"
                        ],
                        "name": "Vijay Vasudevan",
                        "slug": "Vijay-Vasudevan",
                        "structuredName": {
                            "firstName": "Vijay",
                            "lastName": "Vasudevan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vijay Vasudevan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765169"
                        ],
                        "name": "F. Vi\u00e9gas",
                        "slug": "F.-Vi\u00e9gas",
                        "structuredName": {
                            "firstName": "Fernanda",
                            "lastName": "Vi\u00e9gas",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Vi\u00e9gas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689108"
                        ],
                        "name": "Oriol Vinyals",
                        "slug": "Oriol-Vinyals",
                        "structuredName": {
                            "firstName": "Oriol",
                            "lastName": "Vinyals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oriol Vinyals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47941411"
                        ],
                        "name": "P. Warden",
                        "slug": "P.-Warden",
                        "structuredName": {
                            "firstName": "Pete",
                            "lastName": "Warden",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Warden"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145233583"
                        ],
                        "name": "M. Wattenberg",
                        "slug": "M.-Wattenberg",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Wattenberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wattenberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35078078"
                        ],
                        "name": "M. Wicke",
                        "slug": "M.-Wicke",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Wicke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wicke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117163698"
                        ],
                        "name": "Yuan Yu",
                        "slug": "Yuan-Yu",
                        "structuredName": {
                            "firstName": "Yuan",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuan Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152198093"
                        ],
                        "name": "Xiaoqiang Zheng",
                        "slug": "Xiaoqiang-Zheng",
                        "structuredName": {
                            "firstName": "Xiaoqiang",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaoqiang Zheng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5707386,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9c9d7247f8c51ec5a02b0d911d1d7b9e8160495d",
            "isKey": false,
            "numCitedBy": 9182,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "TensorFlow is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition, computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. This paper describes the TensorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at www.tensorflow.org."
            },
            "slug": "TensorFlow:-Large-Scale-Machine-Learning-on-Systems-Abadi-Agarwal",
            "title": {
                "fragments": [],
                "text": "TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The TensorFlow interface and an implementation of that interface that is built at Google are described, which has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145687301"
                        ],
                        "name": "Marek Rei",
                        "slug": "Marek-Rei",
                        "structuredName": {
                            "firstName": "Marek",
                            "lastName": "Rei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marek Rei"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10915836,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2d1d37b37683b8cc398d170466e6e37220022dbd",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate an extension of continuous online learning in recurrent neural network language models. The model keeps a separate vector representation of the current unit of text being processed and adaptively adjusts it after each prediction. The initial experiments give promising results, indicating that the method is able to increase language modelling accuracy, while also decreasing the parameters needed to store the model along with the computation required at each step."
            },
            "slug": "Online-Representation-Learning-in-Recurrent-Neural-Rei",
            "title": {
                "fragments": [],
                "text": "Online Representation Learning in Recurrent Neural Language Models"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The initial experiments give promising results, indicating that the method is able to increase language modelling accuracy, while also decreasing the parameters needed to store the model along with the computation required at each step."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6833606"
                        ],
                        "name": "W. Yin",
                        "slug": "W.-Yin",
                        "structuredName": {
                            "firstName": "Wotao",
                            "lastName": "Yin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Yin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 122
                            }
                        ],
                        "text": "This approach has been applied to learning to optimize deep networks (Hochreiter et al., 2001; Andrychowicz et al., 2016; Li & Malik, 2017), as well as for learning dynamically changing recurrent networks (Ha et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4940101,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "64e0278a50d0039406b99e6c3826573f5342cfdb",
            "isKey": false,
            "numCitedBy": 300,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider decision-making by boundedly-rational agents in dynamic stochastic environments. The behavioral primitive is anchored to the shadow price of the state vector. Our agent forecasts the value of an additional unit of the state tomorrow using estimated models of shadow prices and transition dynamics, and uses this forecast to choose her control today. The control decision, together with the agent\u2019s forecast of tomorrow\u2019s shadow price, are then used to update the perceived shadow price of today\u2019s states. By following this boundedlyoptimal procedure the agent\u2019s decision rule converges over time to the optimal policy. Specifically, within standard linear-quadratic environments, we obtain general conditions for asymptotically optimal decision-making: agents learn to optimize. Our results carry over to closely related procedures based on valuefunction learning and Euler-equation learning. We provide examples showing that shadow-price learning extends to general dynamic-stochastic decisionmaking environments and embeds naturally in general-equilibrium models. JEL Classifications: E52; E31; D83; D84"
            },
            "slug": "Learning-to-Optimize-Yin",
            "title": {
                "fragments": [],
                "text": "Learning to Optimize \u2217"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47971768"
                        ],
                        "name": "J. Schulman",
                        "slug": "J.-Schulman",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Schulman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schulman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736651"
                        ],
                        "name": "S. Levine",
                        "slug": "S.-Levine",
                        "structuredName": {
                            "firstName": "Sergey",
                            "lastName": "Levine",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Levine"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689992"
                        ],
                        "name": "P. Abbeel",
                        "slug": "P.-Abbeel",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Abbeel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Abbeel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29912342"
                        ],
                        "name": "Philipp Moritz",
                        "slug": "Philipp-Moritz",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Moritz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Moritz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 168
                            }
                        ],
                        "text": "The gradient updates are computed using vanilla policy gradient (REINFORCE) (Williams, 1992), and we use trust-region policy optimization (TRPO) as the meta-optimizer (Schulman et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 195
                            }
                        ],
                        "text": "Practical implementations of this method may also use a variety of improvements recently proposed for policy gradient algorithms, including state or action-dependent baselines and trust regions (Schulman et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16046818,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "66cdc28dc084af6507e979767755e99fe0b46b39",
            "isKey": false,
            "numCitedBy": 3925,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "In this article, we describe a method for optimizing control policies, with guaranteed monotonic improvement. By making several approximations to the theoretically-justified scheme, we develop a practical algorithm, called Trust Region Policy Optimization (TRPO). This algorithm is effective for optimizing large nonlinear policies such as neural networks. Our experiments demonstrate its robust performance on a wide variety of tasks: learning simulated robotic swimming, hopping, and walking gaits; and playing Atari games using images of the screen as input. Despite its approximations that deviate from the theory, TRPO tends to give monotonic improvement, with little tuning of hyperparameters."
            },
            "slug": "Trust-Region-Policy-Optimization-Schulman-Levine",
            "title": {
                "fragments": [],
                "text": "Trust Region Policy Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A method for optimizing control policies, with guaranteed monotonic improvement, by making several approximations to the theoretically-justified scheme, called Trust Region Policy Optimization (TRPO)."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16710884,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7257eacd80458e70c74494eb1b6759b52ff21399",
            "isKey": false,
            "numCitedBy": 214,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Connectionist models usually have a single weight on each connection. Some interesting new properties emerge if each connection has two weights: A slowly changing, plastic weight which stores long-term knowledge and a fast-changing, elastic weight which stores temporary knowledge and spontaneously decays towards zero. If a network learns a set of associations and then these associations are \"blurred\" by subsequent learning, all the original associations can be \"deblurred\" by rehearsing on just a few of them. The rehearsal allows the fast weights to take on values that temporarily cancel out the changes in the slow weights caused by the subsequent learning."
            },
            "slug": "Using-fast-weights-to-deblur-old-memories-Hinton",
            "title": {
                "fragments": [],
                "text": "Using fast weights to deblur old memories"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "All the original associations of a network can be \"deblurred\" by rehearsing on just a few of them by allowing the fast weights to take on values that temporarily cancel out the changes in the slow weights caused by the subsequent learning."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1413064976"
                        ],
                        "name": "S. Caelles",
                        "slug": "S.-Caelles",
                        "structuredName": {
                            "firstName": "Sergi",
                            "lastName": "Caelles",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Caelles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2027105"
                        ],
                        "name": "K. Maninis",
                        "slug": "K.-Maninis",
                        "structuredName": {
                            "firstName": "Kevis-Kokitsi",
                            "lastName": "Maninis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Maninis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403171438"
                        ],
                        "name": "J. Pont-Tuset",
                        "slug": "J.-Pont-Tuset",
                        "structuredName": {
                            "firstName": "Jordi",
                            "lastName": "Pont-Tuset",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pont-Tuset"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388407684"
                        ],
                        "name": "L. Leal-Taix\u00e9",
                        "slug": "L.-Leal-Taix\u00e9",
                        "structuredName": {
                            "firstName": "Laura",
                            "lastName": "Leal-Taix\u00e9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Leal-Taix\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695302"
                        ],
                        "name": "D. Cremers",
                        "slug": "D.-Cremers",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Cremers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cremers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 59
                            }
                        ],
                        "text": "Orcun Cetintas | AutoML One-Shot Video Object Segmentation [1] First frame Ground truth"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5381099,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cb1c0d6be4c22c1f18b0ba20dddd93890f17add6",
            "isKey": false,
            "numCitedBy": 572,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper tackles the task of semi-supervised video object segmentation, i.e., the separation of an object from the background in a video, given the mask of the first frame. We present One-Shot Video Object Segmentation (OSVOS), based on a fully-convolutional neural network architecture that is able to successively transfer generic semantic information, learned on ImageNet, to the task of foreground segmentation, and finally to learning the appearance of a single annotated object of the test sequence (hence one-shot). Although all frames are processed independently, the results are temporally coherent and stable. We perform experiments on two annotated video segmentation databases, which show that OSVOS is fast and improves the state of the art by a significant margin (79.8% vs 68.0%)."
            },
            "slug": "One-Shot-Video-Object-Segmentation-Caelles-Maninis",
            "title": {
                "fragments": [],
                "text": "One-Shot Video Object Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "One-Shot Video Object Segmentation (OSVOS), based on a fully-convolutional neural network architecture that is able to successively transfer generic semantic information, learned on ImageNet, to the task of foreground segmentation, and finally to learning the appearance of a single annotated object of the test sequence (hence one-shot)."
            },
            "venue": {
                "fragments": [],
                "text": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "18424934"
                        ],
                        "name": "C. Nelson",
                        "slug": "C.-Nelson",
                        "structuredName": {
                            "firstName": "C",
                            "lastName": "Nelson",
                            "middleNames": [
                                "A"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Nelson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 89
                            }
                        ],
                        "text": "The method that we propose in this paper addresses the general problem of meta-learning (Thrun & Pratt, 1998; Schmidhuber, 1987; Naik & Mammone, 1992), which includes few-shot learning."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11974053,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "53bb7789be36a58f865f2ec84f6d8f816ddaae6a",
            "isKey": false,
            "numCitedBy": 2270,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "In first year we were taught programming. Those lessons just happened to be in Modular 2. In later years, though, we were only introduced to other languages (most notably C and Java), and were expected to learn the rest ourselves. What I took from this experience was the ability to learn a new programming language myself, and because I had been taught the fundamental principles of programming, instead of any particular programming language, I was able to do that. This became more apparent, though, when I started working on the OCC, as it was developed in Visual Basic; a programming environment that I had never used before. After the few years of programming with Java, it came as quite a shock that Visual Basic did not have inheritance, even though it did have classes. Despite this, I was able to employ my knowledge of programming paradigms to this \u201cnew\u201d language, and produce just as well structured code as I could with any other language I was already familiar with."
            },
            "slug": "Learning-to-Learn-Nelson",
            "title": {
                "fragments": [],
                "text": "Learning to Learn"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Because I had been taught the fundamental principles of programming, instead of any particular programming language, I was able to learn a new programming language myself, and produce just as well structured code as I could with any other language I was already familiar with."
            },
            "venue": {
                "fragments": [],
                "text": "Encyclopedia of Machine Learning and Data Mining"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3203568"
                        ],
                        "name": "H. Mengistu",
                        "slug": "H.-Mengistu",
                        "structuredName": {
                            "firstName": "Henok",
                            "lastName": "Mengistu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Mengistu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39799304"
                        ],
                        "name": "J. Lehman",
                        "slug": "J.-Lehman",
                        "structuredName": {
                            "firstName": "Joel",
                            "lastName": "Lehman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lehman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2552141"
                        ],
                        "name": "J. Clune",
                        "slug": "J.-Clune",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Clune",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Clune"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 73
                            }
                        ],
                        "text": "Similar methods have also been proposed that use evolutionary algorithms (Mengistu et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14987344,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "26ae046d8d8bf5b3721734a3cf441f6d204bb6d7",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "One hallmark of natural organisms is their significant evolvability, i.e.,their increased potential for further evolution. However, reproducing such evolvability in artificial evolution remains a challenge, which both reduces the performance of evolutionary algorithms and inhibits the study of evolvable digital phenotypes. Although some types of selection in evolutionary computation indirectly encourage evolvability, one unexplored possibility is to directly select for evolvability. To do so, we estimate an individual's future potential for diversity by calculating the behavioral diversity of its immediate offspring, and select organisms with increased offspring variation. While the technique is computationally expensive, we hypothesized that direct selection would better encourage evolvability than indirect methods. Experiments in two evolutionary robotics domains confirm this hypothesis: in both domains, such Evolvability Search produces solutions with higher evolvability than those produced with Novelty Search or traditional objective-based search algorithms. Further experiments demonstrate that the higher evolvability produced by Evolvability Search in a training environment also generalizes, producing higher evolvability in a new test environment without further selection. Overall, Evolvability Search enables generating evolvability more easily and directly, facilitating its study and understanding, and may inspire future practical algorithms that increase evolvability without significant computational overhead."
            },
            "slug": "Evolvability-Search:-Directly-Selecting-for-in-to-Mengistu-Lehman",
            "title": {
                "fragments": [],
                "text": "Evolvability Search: Directly Selecting for Evolvability in order to Study and Produce It"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Evolvability Search enables generating evolvability more easily and directly, facilitating its study and understanding, and may inspire future practical algorithms that increase evolVability without significant computational overhead."
            },
            "venue": {
                "fragments": [],
                "text": "GECCO"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144832491"
                        ],
                        "name": "E. Todorov",
                        "slug": "E.-Todorov",
                        "structuredName": {
                            "firstName": "Emanuel",
                            "lastName": "Todorov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Todorov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1968210"
                        ],
                        "name": "T. Erez",
                        "slug": "T.-Erez",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Erez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Erez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109481"
                        ],
                        "name": "Yuval Tassa",
                        "slug": "Yuval-Tassa",
                        "structuredName": {
                            "firstName": "Yuval",
                            "lastName": "Tassa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuval Tassa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 114
                            }
                        ],
                        "text": "complex deep RL problems, we also study adaptation on high-dimensional locomotion tasks with the MuJoCo simulator (Todorov et al., 2012)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 156
                            }
                        ],
                        "text": "To study how well MAML can scale to more complex deep RL problems, we also study adaptation on high-dimensional locomotion tasks with the MuJoCo simulator (Todorov et al., 2012)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5230692,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b354ee518bfc1ac0d8ac447eece9edb69e92eae1",
            "isKey": false,
            "numCitedBy": 2757,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a new physics engine tailored to model-based control. Multi-joint dynamics are represented in generalized coordinates and computed via recursive algorithms. Contact responses are computed via efficient new algorithms we have developed, based on the modern velocity-stepping approach which avoids the difficulties with spring-dampers. Models are specified using either a high-level C++ API or an intuitive XML file format. A built-in compiler transforms the user model into an optimized data structure used for runtime computation. The engine can compute both forward and inverse dynamics. The latter are well-defined even in the presence of contacts and equality constraints. The model can include tendon wrapping as well as actuator activation states (e.g. pneumatic cylinders or muscles). To facilitate optimal control applications and in particular sampling and finite differencing, the dynamics can be evaluated for different states and controls in parallel. Around 400,000 dynamics evaluations per second are possible on a 12-core machine, for a 3D homanoid with 18 dofs and 6 active contacts. We have already used the engine in a number of control applications. It will soon be made publicly available."
            },
            "slug": "MuJoCo:-A-physics-engine-for-model-based-control-Todorov-Erez",
            "title": {
                "fragments": [],
                "text": "MuJoCo: A physics engine for model-based control"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "A new physics engine tailored to model-based control, based on the modern velocity-stepping approach which avoids the difficulties with spring-dampers, which can compute both forward and inverse dynamics."
            },
            "venue": {
                "fragments": [],
                "text": "2012 IEEE/RSJ International Conference on Intelligent Robots and Systems"
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 235,
                                "start": 212
                            }
                        ],
                        "text": "\u2026(Ravi & Larochelle, 2017) 1-shot 5-shot fine-tuning baseline 28.86\u00b1 0.54% 49.79\u00b1 0.79% nearest neighbor baseline 41.08\u00b1 0.70% 51.04\u00b1 0.65% matching nets (Vinyals et al., 2016) 43.56\u00b1 0.84% 55.31\u00b1 0.73% meta-learner LSTM (Ravi & Larochelle, 2017) 43.44\u00b1 0.77% 60.60\u00b1 0.71% MAML, first order approx."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 162
                            }
                        ],
                        "text": "The Omniglot and MiniImagenet image recognition tasks are the most common recently used few-shot learning benchmarks (Vinyals et al., 2016; Santoro et al., 2016; Ravi & Larochelle, 2017)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 82
                            }
                        ],
                        "text": "For MiniImagenet, we used 32 filters per layer to reduce overfitting, as done by (Ravi & Larochelle, 2017)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 41
                            }
                        ],
                        "text": "The MiniImagenet dataset was proposed by Ravi & Larochelle (2017), and involves 64 training classes, 12 validation classes, and 24 test classes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 10
                            }
                        ],
                        "text": "Following Ravi & Larochelle (2017), 15 examples per class were used for evaluating the post-update meta-gradient."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 104
                            }
                        ],
                        "text": "(Kaiser et al., 2017) 98.4% 99.6% 95.0% 98.6% MAML (ours) 98.7\u00b1 0.4% 99.9\u00b1 0.1% 95.8\u00b1 0.3% 98.9\u00b1 0.2%\n5-way Accuracy MiniImagenet (Ravi & Larochelle, 2017) 1-shot 5-shot fine-tuning baseline 28.86\u00b1 0.54% 49.79\u00b1 0.79% nearest neighbor baseline 41.08\u00b1 0.70% 51.04\u00b1 0.65% matching nets (Vinyals et al., 2016) 43.56\u00b1 0.84% 55.31\u00b1 0.73% meta-learner LSTM (Ravi & Larochelle, 2017) 43.44\u00b1 0.77% 60.60\u00b1 0.71% MAML, first order approx."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 78
                            }
                        ],
                        "text": "The MiniImagenet evaluation of baseline methods and matching networks is from Ravi & Larochelle (2017)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 109
                            }
                        ],
                        "text": "One recent approach learns both the weight initialization and the optimizer, for few-shot image recognition (Ravi & Larochelle, 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 150
                            }
                        ],
                        "text": "Unlike prior meta-learning methods that learn an update function or learning rule (Schmidhuber, 1987; Bengio et al., 1992; Andrychowicz et al., 2016; Ravi & Larochelle, 2017), our algorithm does not expand the number of learned parameters nor place constraints on the model architecture (e.g. by\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 127
                            }
                        ],
                        "text": "(Kaiser et al., 2017) 98.4% 99.6% 95.0% 98.6% MAML (ours) 98.7\u00b1 0.4% 99.9\u00b1 0.1% 95.8\u00b1 0.3% 98.9\u00b1 0.2%\n5-way Accuracy MiniImagenet (Ravi & Larochelle, 2017) 1-shot 5-shot fine-tuning baseline 28.86\u00b1 0.54% 49.79\u00b1 0.79% nearest neighbor baseline 41.08\u00b1 0.70% 51.04\u00b1 0.65% matching nets (Vinyals et al.,\u2026"
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Meta-SGD:Optimization as a Model for Few-shot Learning"
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2017
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 1
                            }
                        ],
                        "text": "(Kaiser et al., 2017) 98.4% 99.6% 95.0% 98.6% MAML (ours) 98.7\u00b1 0.4% 99.9\u00b1 0.1% 95.8\u00b1 0.3% 98.9\u00b1 0.2%\n5-way Accuracy MiniImagenet (Ravi & Larochelle, 2017) 1-shot 5-shot fine-tuning baseline 28.86\u00b1 0.54% 49.79\u00b1 0.79% nearest neighbor baseline 41.08\u00b1 0.70% 51.04\u00b1 0.65% matching nets (Vinyals et al.,\u2026"
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning to remember rare"
            },
            "venue": {
                "fragments": [],
                "text": "events. International Conference on Learning Representations (ICLR),"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50990874"
                        ],
                        "name": "Risto Vuorio",
                        "slug": "Risto-Vuorio",
                        "structuredName": {
                            "firstName": "Risto",
                            "lastName": "Vuorio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Risto Vuorio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109374418"
                        ],
                        "name": "Shao-Hua Sun",
                        "slug": "Shao-Hua-Sun",
                        "structuredName": {
                            "firstName": "Shao-Hua",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shao-Hua Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2804000"
                        ],
                        "name": "Hexiang Hu",
                        "slug": "Hexiang-Hu",
                        "structuredName": {
                            "firstName": "Hexiang",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hexiang Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35198686"
                        ],
                        "name": "Joseph J. Lim",
                        "slug": "Joseph-J.-Lim",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Lim",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joseph J. Lim"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 186947580,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a2e6ee708ef5b258415076c4f5484fa1e0f42afa",
            "isKey": false,
            "numCitedBy": 1,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Model-Agnostic-Meta-Learning-for-Multimodal-Task-Vuorio-Sun",
            "title": {
                "fragments": [],
                "text": "Model-Agnostic Meta-Learning for Multimodal Task Distributions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46421372"
                        ],
                        "name": "M. Abbas",
                        "slug": "M.-Abbas",
                        "structuredName": {
                            "firstName": "Mudassar",
                            "lastName": "Abbas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Abbas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6245351"
                        ],
                        "name": "J. Kivinen",
                        "slug": "J.-Kivinen",
                        "structuredName": {
                            "firstName": "Jyri",
                            "lastName": "Kivinen",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kivinen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2785022"
                        ],
                        "name": "T. Raiko",
                        "slug": "T.-Raiko",
                        "structuredName": {
                            "firstName": "Tapani",
                            "lastName": "Raiko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Raiko"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 206
                            }
                        ],
                        "text": "This approach has been applied to learning to optimize deep networks (Hochreiter et al., 2001; Andrychowicz et al., 2016; Li & Malik, 2017), as well as for learning dynamically changing recurrent networks (Ha et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 63450092,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f1aeb751d9cefc9d784d8862562f5a3fe15821ae",
            "isKey": false,
            "numCitedBy": 291,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "International-Conference-on-Learning-(ICLR)-Abbas-Kivinen",
            "title": {
                "fragments": [],
                "text": "International Conference on Learning Representations (ICLR)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2016
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 167
                            }
                        ],
                        "text": "A popular approach for metalearning is to train a meta-learner that learns how to update the parameters of the learner\u2019s model (Bengio et al., 1992; Schmidhuber, 1992; Bengio et al., 1990)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning a synaptic learning"
            },
            "venue": {
                "fragments": [],
                "text": "rule. Universite\u0301 de Montre\u0301al, De\u0301partement d\u2019informatique et de recherche ope\u0301rationnelle,"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 127
                            }
                        ],
                        "text": "A number of prior works have explored sensitivity in deep networks, often in the context of initialization (Saxe et al., 2014; Kirkpatrick et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "et al. Overcoming catastrophic forgetting in neural networks. arXiv preprint arXiv:1612.00796"
            },
            "venue": {
                "fragments": [],
                "text": "et al. Overcoming catastrophic forgetting in neural networks. arXiv preprint arXiv:1612.00796"
            },
            "year": 2016
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Meta-SGD: Parameter Space Noise for Exploration"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2017
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Context vector adaptation Rei (2015) developed a method which learns a context vector that can be adapted online, with an application to recurrent language models. The parameters in this context"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2015
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks"
            },
            "venue": {
                "fragments": [],
                "text": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning to Reinforcement Learn 2016"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2016
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 110
                            }
                        ],
                        "text": "The key idea underlying our method is to train the model\u2019s initial parameters such that the model has maximal performance on a new task after the parameters have been updated through one or more gradient steps computed with a small amount of data from that new task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 110
                            }
                        ],
                        "text": "The method that we propose in this paper addresses the general problem of meta-learning (Thrun & Pratt, 1998; Schmidhuber, 1987; Naik & Mammone, 1992), which includes few-shot learning."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 83
                            }
                        ],
                        "text": "Unlike prior meta-learning methods that learn an update function or learning rule (Schmidhuber, 1987; Bengio et al., 1992; Andrychowicz et al., 2016; Ravi & Larochelle, 2017), our algorithm does not expand the number of learned parameters nor place constraints on the model architecture (e.g. by\u2026"
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Evolutionary principles in selfreferential learning On learning how to learn: The meta-meta-... hook.) Diploma thesis"
            },
            "venue": {
                "fragments": [],
                "text": "Evolutionary principles in selfreferential learning On learning how to learn: The meta-meta-... hook.) Diploma thesis"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 107
                            }
                        ],
                        "text": "Orcun Cetintas | AutoML \u2022 Reptile [3]: Proposes a new algorithm with only first-order derivatives \u2022 MAML++ [4]: Stabilizes MAML training and proposes improvements such as learning the learning rate \u2022 Meta-SGD [5]: Learns all components of a meta-optimizer (initialization, update direction and learning rate)"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "How to train your maml.\" arXiv preprint"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2018
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Evolutionary principles in selfreferential learning. On learning how to learn: The meta-meta-."
            },
            "venue": {
                "fragments": [],
                "text": "hook.) Diploma thesis, Institut f. Informatik, Tech. Univ. Munich,"
            },
            "year": 1987
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 20,
            "methodology": 23,
            "result": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 59,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/Model-Agnostic-Meta-Learning-for-Fast-Adaptation-of-Finn-Abbeel/c889d6f98e6d79b89c3a6adf8a921f88fa6ba518?sort=total-citations"
}