{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40343421"
                        ],
                        "name": "Yanhong Zhai",
                        "slug": "Yanhong-Zhai",
                        "structuredName": {
                            "firstName": "Yanhong",
                            "lastName": "Zhai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yanhong Zhai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145321667"
                        ],
                        "name": "B. Liu",
                        "slug": "B.-Liu",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12750207,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f49e35b6a85b8d81d2c9d9e26e8bf19dd94fad3a",
            "isKey": false,
            "numCitedBy": 600,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper studies the problem of extracting data from a Web page that contains several structured data records. The objective is to segment these data records, extract data items/fields from them and put the data in a database table. This problem has been studied by several researchers. However, existing methods still have some serious limitations. The first class of methods is based on machine learning, which requires human labeling of many examples from each Web site that one is interested in extracting data from. The process is time consuming due to the large number of sites and pages on the Web. The second class of algorithms is based on automatic pattern discovery. These methods are either inaccurate or make many assumptions. This paper proposes a new method to perform the task automatically. It consists of two steps, (1) identifying individual data records in a page, and (2) aligning and extracting data items from the identified data records. For step 1, we propose a method based on visual information to segment data records, which is more accurate than existing methods. For step 2, we propose a novel partial alignment technique based on tree matching. Partial alignment means that we align only those data fields in a pair of data records that can be aligned (or matched) with certainty, and make no commitment on the rest of the data fields. This approach enables very accurate alignment of multiple data records. Experimental results using a large number of Web pages from diverse domains show that the proposed two-step technique is able to segment data records, align and extract data from them very accurately."
            },
            "slug": "Web-data-extraction-based-on-partial-tree-alignment-Zhai-Liu",
            "title": {
                "fragments": [],
                "text": "Web data extraction based on partial tree alignment"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "Experimental results using a large number of Web pages from diverse domains show that the proposed two-step technique is able to segment data records, align and extract data from them very accurately."
            },
            "venue": {
                "fragments": [],
                "text": "WWW '05"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39379522"
                        ],
                        "name": "Gengxin Miao",
                        "slug": "Gengxin-Miao",
                        "structuredName": {
                            "firstName": "Gengxin",
                            "lastName": "Miao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gengxin Miao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2784291"
                        ],
                        "name": "J. Tatemura",
                        "slug": "J.-Tatemura",
                        "structuredName": {
                            "firstName": "Jun'ichi",
                            "lastName": "Tatemura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tatemura"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3183445"
                        ],
                        "name": "Wang-Pin Hsiung",
                        "slug": "Wang-Pin-Hsiung",
                        "structuredName": {
                            "firstName": "Wang-Pin",
                            "lastName": "Hsiung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wang-Pin Hsiung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2389418"
                        ],
                        "name": "A. Sawires",
                        "slug": "A.-Sawires",
                        "structuredName": {
                            "firstName": "Arsany",
                            "lastName": "Sawires",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sawires"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708743"
                        ],
                        "name": "L. Moser",
                        "slug": "L.-Moser",
                        "structuredName": {
                            "firstName": "Louise",
                            "lastName": "Moser",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Moser"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13115982,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "87cfd3ac19dfba177e03fdf1f3cf93a4878dbca1",
            "isKey": false,
            "numCitedBy": 167,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Fully automatic methods that extract lists of objects from the Web have been studied extensively. Record extraction, the first step of this object extraction process, identifies a set of Web page segments, each of which represents an individual object (e.g., a product). State-of-the-art methods suffice for simple search, but they often fail to handle more complicated or noisy Web page structures due to a key limitation -- their greedy manner of identifying a list of records through pairwise comparison (i.e., similarity match) of consecutive segments. This paper introduces a new method for record extraction that captures a list of objects in a more robust way based on a holistic analysis of a Web page. The method focuses on how a distinct tag path appears repeatedly in the DOM tree of the Web document. Instead of comparing a pair of individual segments, it compares a pair of tag path occurrence patterns (called visual signals) to estimate how likely these two tag paths represent the same list of objects. The paper introduces a similarity measure that captures how closely the visual signals appear and interleave. Clustering of tag paths is then performed based on this similarity measure, and sets of tag paths that form the structure of data records are extracted. Experiments show that this method achieves higher accuracy than previous methods."
            },
            "slug": "Extracting-data-records-from-the-web-using-tag-path-Miao-Tatemura",
            "title": {
                "fragments": [],
                "text": "Extracting data records from the web using tag path clustering"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A new method for record extraction that captures a list of objects in a more robust way based on a holistic analysis of a Web page by focusing on how a distinct tag path appears repeatedly in the DOM tree of the Web document."
            },
            "venue": {
                "fragments": [],
                "text": "WWW '09"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3276863"
                        ],
                        "name": "Ion Muslea",
                        "slug": "Ion-Muslea",
                        "structuredName": {
                            "firstName": "Ion",
                            "lastName": "Muslea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ion Muslea"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145293454"
                        ],
                        "name": "Steven Minton",
                        "slug": "Steven-Minton",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Minton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steven Minton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745117"
                        ],
                        "name": "Craig A. Knoblock",
                        "slug": "Craig-A.-Knoblock",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Knoblock",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Craig A. Knoblock"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2801554,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "855eaab4505fea76ab21402839670a483e0ae339",
            "isKey": false,
            "numCitedBy": 406,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "With the tremendous amount of information that becomes available on the Web on a daily basis, the ability to quickly develop information agents has become a crucial problem. A vital component of any Web-based information agent is a set of wrappers that can extract the relevant data from semistructured information sources. Our novel approach to wrapper induction is based on the idea of hierarchical information extraction, which turns the hard problem of extracting data from an arbitrarily complex document into a series of simpler extraction tasks. We introduce an inductive algorithm, STALKER, that generates high accuracy extraction rules based on user-labeled training examples. Labeling the training data represents the major bottleneck in using wrapper induction techniques, and our experimental results show that STALKER requires up to two orders of magnitude fewer examples than other algorithms. Furthermore, STALKER can wrap information sources that could not be wrapped by existing inductive techniques."
            },
            "slug": "Hierarchical-Wrapper-Induction-for-Semistructured-Muslea-Minton",
            "title": {
                "fragments": [],
                "text": "Hierarchical Wrapper Induction for Semistructured Information Sources"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work introduces an inductive algorithm, STALKER, that generates high accuracy extraction rules based on user-labeled training examples that can wrap information sources that could not be wrapped by existing inductive techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Autonomous Agents and Multi-Agent Systems"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3049801"
                        ],
                        "name": "Shuyi Zheng",
                        "slug": "Shuyi-Zheng",
                        "structuredName": {
                            "firstName": "Shuyi",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shuyi Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35119829"
                        ],
                        "name": "Ruihua Song",
                        "slug": "Ruihua-Song",
                        "structuredName": {
                            "firstName": "Ruihua",
                            "lastName": "Song",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ruihua Song"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2259699"
                        ],
                        "name": "Ji-Rong Wen",
                        "slug": "Ji-Rong-Wen",
                        "structuredName": {
                            "firstName": "Ji-Rong",
                            "lastName": "Wen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ji-Rong Wen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157784"
                        ],
                        "name": "C. Lee Giles",
                        "slug": "C.-Lee-Giles",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Giles",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lee Giles"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15079973,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "22eca7b8a3ab6ea577790eefbefa1e0f3da9e2bb",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Web information is often presented in the form of record, e.g., a product record on a shopping website or a personal profile on a social utility website. Given a host webpage and related information needs, how to identify relevant records as well as their internal semantic structures is critical to many online information systems. Wrapper induction is one of the most effective methods for such tasks. However, most traditional wrapper techniques have issues dealing with web records since they are designed to extract information from a page, not a record. We propose a record-level wrapper system. In our system, we use a novel ``broom'' structure to represent both records and generated wrappers. With such representation, our system is able to effectively extract records and identify their internal semantics at the same time. We test our system on 16 real-life websites from four different domains. Experimental results demonstrate 99\\% extraction accuracy in terms of F1-Value."
            },
            "slug": "Efficient-record-level-wrapper-induction-Zheng-Song",
            "title": {
                "fragments": [],
                "text": "Efficient record-level wrapper induction"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work proposes a record-level wrapper system that uses a novel ``broom'' structure to represent both records and generated wrappers and is able to effectively extract records and identify their internal semantics at the same time."
            },
            "venue": {
                "fragments": [],
                "text": "CIKM"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741101"
                        ],
                        "name": "Oren Etzioni",
                        "slug": "Oren-Etzioni",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Etzioni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Etzioni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725561"
                        ],
                        "name": "Michael J. Cafarella",
                        "slug": "Michael-J.-Cafarella",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Cafarella",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Cafarella"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145612610"
                        ],
                        "name": "Doug Downey",
                        "slug": "Doug-Downey",
                        "structuredName": {
                            "firstName": "Doug",
                            "lastName": "Downey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Doug Downey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3447955"
                        ],
                        "name": "Stanley Kok",
                        "slug": "Stanley-Kok",
                        "structuredName": {
                            "firstName": "Stanley",
                            "lastName": "Kok",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stanley Kok"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36445704"
                        ],
                        "name": "Ana-Maria Popescu",
                        "slug": "Ana-Maria-Popescu",
                        "structuredName": {
                            "firstName": "Ana-Maria",
                            "lastName": "Popescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ana-Maria Popescu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3296031"
                        ],
                        "name": "Tal Shaked",
                        "slug": "Tal-Shaked",
                        "structuredName": {
                            "firstName": "Tal",
                            "lastName": "Shaked",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tal Shaked"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144295318"
                        ],
                        "name": "S. Soderland",
                        "slug": "S.-Soderland",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Soderland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Soderland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780531"
                        ],
                        "name": "Daniel S. Weld",
                        "slug": "Daniel-S.-Weld",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Weld",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel S. Weld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3321874"
                        ],
                        "name": "A. Yates",
                        "slug": "A.-Yates",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Yates",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yates"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6755965,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9ef07373873cc0f0b940512dcdde4e7b54b0cfb0",
            "isKey": false,
            "numCitedBy": 892,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Manually querying search engines in order to accumulate a large bodyof factual information is a tedious, error-prone process of piecemealsearch. Search engines retrieve and rank potentially relevantdocuments for human perusal, but do not extract facts, assessconfidence, or fuse information from multiple documents. This paperintroduces KnowItAll, a system that aims to automate the tedious process ofextracting large collections of facts from the web in an autonomous,domain-independent, and scalable manner.The paper describes preliminary experiments in which an instance of KnowItAll, running for four days on a single machine, was able to automatically extract 54,753 facts. KnowItAll associates a probability with each fact enabling it to trade off precision and recall. The paper analyzes KnowItAll's architecture and reports on lessons learned for the design of large-scale information extraction systems."
            },
            "slug": "Web-scale-information-extraction-in-knowitall:-Etzioni-Cafarella",
            "title": {
                "fragments": [],
                "text": "Web-scale information extraction in knowitall: (preliminary results)"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "KnowItAll, a system that aims to automate the tedious process of extracting large collections of facts from the web in an autonomous, domain-independent, and scalable manner, is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "WWW '04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2915438"
                        ],
                        "name": "T. Anton",
                        "slug": "T.-Anton",
                        "structuredName": {
                            "firstName": "Tobias",
                            "lastName": "Anton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Anton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9336145,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "76eb7007bc4aad2f861acbef93ae4c4ce3b1621d",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a wrapper induction algorithm for extracting information from tree-structured documents like HTML or XML. It derives XPath-compatible extraction rules from a set of annotated example documents. The approach builds a minimally generalized tree traversal pattern, and augments it with conditions. Another variant selects a subset of conditions so that (a) the pattern is consistent with the training data, (b) the pat-tern's document coverage is minimized, and (c) conditions that match structures preceding the target nodes are preferred. We discuss the ro-bustness of rules induced by this selection strategy and we illustrate how these rules exhibit knowledge of the target concept."
            },
            "slug": "XPath-Wrapper-Induction-by-generating-tree-patterns-Anton",
            "title": {
                "fragments": [],
                "text": "XPath-Wrapper Induction by generating tree traversal patterns"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A wrapper induction algorithm for extracting information from tree-structured documents like HTML or XML derives XPath-compatible extraction rules from a set of annotated example documents and discusses the ro-bustness of rules induced by this selection strategy."
            },
            "venue": {
                "fragments": [],
                "text": "LWA"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3276863"
                        ],
                        "name": "Ion Muslea",
                        "slug": "Ion-Muslea",
                        "structuredName": {
                            "firstName": "Ion",
                            "lastName": "Muslea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ion Muslea"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145293454"
                        ],
                        "name": "Steven Minton",
                        "slug": "Steven-Minton",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Minton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steven Minton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745117"
                        ],
                        "name": "Craig A. Knoblock",
                        "slug": "Craig-A.-Knoblock",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Knoblock",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Craig A. Knoblock"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 3514097,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1cc263c84b85027164bd39db169f5d5959ef6822",
            "isKey": false,
            "numCitedBy": 464,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "With the tremendous amount of information that becomes available on the Web on a daily basis, the ability to quickly develop information agents has become a crucial problem. A vital component of any Web-based information agent is a set of wrappers that can extract the relevant data from semistructured information sources. Our novel approach to wrapper induction is based on the idea of hierarchical information extraction, which turns the hard problem of extracting data from an arbitrarily complex document into a series of easier extraction tasks. We introduce an inductive algorithm, STALKER, that generates high accuracy extraction rules based on user-labeled training examples. Labeling the training data represents the major bottleneck in using wrapper induction techniques, and our experimental results show that STALKER does significantly better then other approaches; on one hand, STALKER requires up to two orders of magnitude fewer examples than other algorithms, while on the other hand it can handle information sources that could not be wrapped by existing techniques."
            },
            "slug": "A-hierarchical-approach-to-wrapper-induction-Muslea-Minton",
            "title": {
                "fragments": [],
                "text": "A hierarchical approach to wrapper induction"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work introduces an inductive algorithm, STALKER, that generates high accuracy extraction rules based on user-labeled training examples that can handle information sources that could not be wrapped by existing techniques."
            },
            "venue": {
                "fragments": [],
                "text": "AGENTS '99"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1923209"
                        ],
                        "name": "Nilesh N. Dalvi",
                        "slug": "Nilesh-N.-Dalvi",
                        "structuredName": {
                            "firstName": "Nilesh",
                            "lastName": "Dalvi",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nilesh N. Dalvi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730124"
                        ],
                        "name": "P. Bohannon",
                        "slug": "P.-Bohannon",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Bohannon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bohannon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145757665"
                        ],
                        "name": "Fei Sha",
                        "slug": "Fei-Sha",
                        "structuredName": {
                            "firstName": "Fei",
                            "lastName": "Sha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fei Sha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10711472,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b47e5640376b1a3858e1f8119b8588d1e7517f6c",
            "isKey": false,
            "numCitedBy": 78,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "On script-generated web sites, many documents share common HTML tree structure, allowing wrappers to effectively extract information of interest. Of course, the scripts and thus the tree structure evolve over time, causing wrappers to break repeatedly, and resulting in a high cost of maintaining wrappers. In this paper, we explore a novel approach: we use temporal snapshots of web pages to develop a tree-edit model of HTML, and use this model to improve wrapper construction. We view the changes to the tree structure as suppositions of a series of edit operations: deleting nodes, inserting nodes and substituting labels of nodes. The tree structures evolve by choosing these edit operations stochastically. Our model is attractive in that the probability that a source tree has evolved into a target tree can be estimated efficiently--in quadratic time in the size of the trees--making it a potentially useful tool for a variety of tree-evolution problems. We give an algorithm to learn the probabilistic model from training examples consisting of pairs of trees, and apply this algorithm to collections of web-page snapshots to derive HTML-specific tree edit models. Finally, we describe a novel wrapper-construction framework that takes the tree-edit model into account, and compare the quality of resulting wrappers to that of traditional wrappers on synthetic and real HTML document examples."
            },
            "slug": "Robust-web-extraction:-an-approach-based-on-a-model-Dalvi-Bohannon",
            "title": {
                "fragments": [],
                "text": "Robust web extraction: an approach based on a probabilistic tree-edit model"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper uses temporal snapshots of web pages to develop a tree-edit model of HTML, and uses this model to improve wrapper construction, and gives an algorithm to learn the probabilistic model from training examples consisting of pairs of trees."
            },
            "venue": {
                "fragments": [],
                "text": "SIGMOD Conference"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145254043"
                        ],
                        "name": "Jun Zhu",
                        "slug": "Jun-Zhu",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jun Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38301933"
                        ],
                        "name": "Zaiqing Nie",
                        "slug": "Zaiqing-Nie",
                        "structuredName": {
                            "firstName": "Zaiqing",
                            "lastName": "Nie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zaiqing Nie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2259699"
                        ],
                        "name": "Ji-Rong Wen",
                        "slug": "Ji-Rong-Wen",
                        "structuredName": {
                            "firstName": "Ji-Rong",
                            "lastName": "Wen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ji-Rong Wen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49846744"
                        ],
                        "name": "Bo Zhang",
                        "slug": "Bo-Zhang",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712167"
                        ],
                        "name": "Wei-Ying Ma",
                        "slug": "Wei-Ying-Ma",
                        "structuredName": {
                            "firstName": "Wei-Ying",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Ying Ma"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5916894,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d496e3a5edf49a616c53bb80046b132a90934f51",
            "isKey": false,
            "numCitedBy": 200,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent work has shown the feasibility and promise of template-independent Web data extraction. However, existing approaches use decoupled strategies - attempting to do data record detection and attribute labeling in two separate phases. In this paper, we show that separately extracting data records and attributes is highly ineffective and propose a probabilistic model to perform these two tasks simultaneously. In our approach, record detection can benefit from the availability of semantics required in attribute labeling and, at the same time, the accuracy of attribute labeling can be improved when data records are labeled in a collective manner. The proposed model is called Hierarchical Conditional Random Fields. It can efficiently integrate all useful features by learning their importance, and it can also incorporate hierarchical interactions which are very important for Web data extraction. We empirically compare the proposed model with existing decoupled approaches for product information extraction, and the results show significant improvements in both record detection and attribute labeling."
            },
            "slug": "Simultaneous-record-detection-and-attribute-in-web-Zhu-Nie",
            "title": {
                "fragments": [],
                "text": "Simultaneous record detection and attribute labeling in web data extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that separately extracting data records and attributes is highly ineffective and a probabilistic model to perform these two tasks simultaneously is proposed and it can also incorporate hierarchical interactions which are very important for Web data extraction."
            },
            "venue": {
                "fragments": [],
                "text": "KDD '06"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8551365"
                        ],
                        "name": "N. Kushmerick",
                        "slug": "N.-Kushmerick",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Kushmerick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Kushmerick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780531"
                        ],
                        "name": "Daniel S. Weld",
                        "slug": "Daniel-S.-Weld",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Weld",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel S. Weld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2913159"
                        ],
                        "name": "Robert B. Doorenbos",
                        "slug": "Robert-B.-Doorenbos",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Doorenbos",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert B. Doorenbos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5119155,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9e7402ad740b73cc0bb64178f86df3478c3aaf5",
            "isKey": false,
            "numCitedBy": 1283,
            "numCiting": 83,
            "paperAbstract": {
                "fragments": [],
                "text": "Many Internet information resources present relational data|telephone directories, product catalogs, etc. Because these sites are formatted for people, mechanically extracting their content is di cult. Systems using such resources typically use hand-coded wrappers, procedures to extract data from information resources. We introduce wrapper induction, a method for automatically constructing wrappers, and identify hlrt, a wrapper class that is e ciently learnable, yet expressive enough to handle 48% of a recently surveyed sample of Internet resources. We use PAC analysis to bound the problem's sample complexity, and show that the system degrades gracefully with imperfect labeling knowledge."
            },
            "slug": "Wrapper-Induction-for-Information-Extraction-Kushmerick-Weld",
            "title": {
                "fragments": [],
                "text": "Wrapper Induction for Information Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work introduces wrapper induction, a method for automatically constructing wrappers, and identifies hlrt, a wrapper class that is e ciently learnable, yet expressive enough to handle 48% of a recently surveyed sample of Internet resources."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720956"
                        ],
                        "name": "Chia-Hui Chang",
                        "slug": "Chia-Hui-Chang",
                        "structuredName": {
                            "firstName": "Chia-Hui",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chia-Hui Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2484984"
                        ],
                        "name": "Mohammed Kayed",
                        "slug": "Mohammed-Kayed",
                        "structuredName": {
                            "firstName": "Mohammed",
                            "lastName": "Kayed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mohammed Kayed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2570984"
                        ],
                        "name": "M. Girgis",
                        "slug": "M.-Girgis",
                        "structuredName": {
                            "firstName": "Moheb",
                            "lastName": "Girgis",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Girgis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40241708"
                        ],
                        "name": "K. Shaalan",
                        "slug": "K.-Shaalan",
                        "structuredName": {
                            "firstName": "Khaled",
                            "lastName": "Shaalan",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Shaalan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206742377,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3cc310717f422592c3cc9a046943777468c14358",
            "isKey": false,
            "numCitedBy": 877,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "The Internet presents a huge amount of useful information which is usually formatted for its users, which makes it difficult to extract relevant data from various sources. Therefore, the availability of robust, flexible information extraction (IE) systems that transform the Web pages into program-friendly structures such as a relational database will become a great necessity. Although many approaches for data extraction from Web pages have been developed, there has been limited effort to compare such tools. Unfortunately, in only a few cases can the results generated by distinct tools be directly compared since the addressed extraction tasks are different. This paper surveys the major Web data extraction approaches and compares them in three dimensions: the task domain, the automation degree, and the techniques used. The criteria of the first dimension explain why an IE system fails to handle some Web sites of particular structures. The criteria of the second dimension classify IE systems based on the techniques used. The criteria of the third dimension measure the degree of automation for IE systems. We believe these criteria provide qualitatively measures to evaluate various IE approaches"
            },
            "slug": "A-Survey-of-Web-Information-Extraction-Systems-Chang-Kayed",
            "title": {
                "fragments": [],
                "text": "A Survey of Web Information Extraction Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper surveys the major Web data extraction approaches and compares them in three dimensions: the task domain, the automation degree, and the techniques used and believes these criteria provide qualitatively measures to evaluate various IE approaches."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Knowledge and Data Engineering"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2612119"
                        ],
                        "name": "J. Myllymaki",
                        "slug": "J.-Myllymaki",
                        "structuredName": {
                            "firstName": "Jussi",
                            "lastName": "Myllymaki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Myllymaki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2876361"
                        ],
                        "name": "Jared Jackson",
                        "slug": "Jared-Jackson",
                        "structuredName": {
                            "firstName": "Jared",
                            "lastName": "Jackson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jared Jackson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10997495,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a5908690c8b0b86db7812654f828a0c77d917861",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Automated extraction of structured Web data has attracted considerable interest in both the academia and industry. A particularly promising approach is to employ XML technologies to translate semi-structured HTML documents to \u201cpure\u201d XML documents. In this approach, HTML documents are first normalized into XHMTL and then mapped to the desired XML application format by using XML path expressions and regular expressions. In this paper we describe a methodology for creating XML path (XPath) expressions that are capable of extracting data from virtually any HTML page, while placing an emphasis on the persistent integrity of these expressions. This robustness is critical given the vulnerability of extraction technologies to the continually changing content, structure, and formatting of pages on the Web. We define categories of extraction rules in terms of their dependence on content, structural, or formatting features, and provide practical tips on how to create dependable data extraction patterns for the Web."
            },
            "slug": "Robust-Web-Data-Extraction-with-XML-Path-Myllymaki-Jackson",
            "title": {
                "fragments": [],
                "text": "Robust Web Data Extraction with XML Path Expressions"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper describes a methodology for creating XML path (XPath) expressions that are capable of extracting data from virtually any HTML page, while placing an emphasis on the persistent integrity of these expressions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745117"
                        ],
                        "name": "Craig A. Knoblock",
                        "slug": "Craig-A.-Knoblock",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Knoblock",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Craig A. Knoblock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782658"
                        ],
                        "name": "Kristina Lerman",
                        "slug": "Kristina-Lerman",
                        "structuredName": {
                            "firstName": "Kristina",
                            "lastName": "Lerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kristina Lerman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "26602711"
                        ],
                        "name": "Steven N. Minton",
                        "slug": "Steven-N.-Minton",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Minton",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steven N. Minton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9238072,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b33ca9ba9a9790cc308c8a1244316e270c9dbb33",
            "isKey": false,
            "numCitedBy": 176,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "The proliferation of online information sources has led to an increased use of wrappers for extracting data from Web sources. While most of the previous research has focused on quick and efficient generation of wrappers, the development of tools for wrapper maintenance has received less attention. This is an important research problem because Web sources often change in ways that prevent the wrappers from extracting data correctly. We present an efficient algorithm that learns structural information about data from positive examples alone. We describe how this information can be used for two wrapper maintenance applications: wrapper verification and reinduction. The wrapper verification system detects when a wrapper is not extracting correct data, usually because the Web source has changed its format. The reinduction algorithm automatically recovers from changes in the Web source by identifying data on Web pages so that a new wrapper may be generated for this source. To validate our approach, we monitored 27 wrappers over a period of a year. The verification algorithm correctly discovered 35 of the 37 wrapper changes, and made 16 mistakes, resulting in precision of 0.73 and recall of 0.95. We validated the reinduction algorithm on ten Web sources. We were able to successfully reinduce the wrappers, obtaining precision and recall values of 0.90 and 0.80 on the data extraction task."
            },
            "slug": "Wrapper-Maintenance:-A-Machine-Learning-Approach-Knoblock-Lerman",
            "title": {
                "fragments": [],
                "text": "Wrapper Maintenance: A Machine Learning Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An efficient algorithm is presented that learns structural information about data from positive examples alone that can be used for two wrapper maintenance applications: wrapper verification and reinduction."
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif. Intell. Res."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1791339"
                        ],
                        "name": "Valter Crescenzi",
                        "slug": "Valter-Crescenzi",
                        "structuredName": {
                            "firstName": "Valter",
                            "lastName": "Crescenzi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Valter Crescenzi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785690"
                        ],
                        "name": "G. Mecca",
                        "slug": "G.-Mecca",
                        "structuredName": {
                            "firstName": "Giansalvatore",
                            "lastName": "Mecca",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Mecca"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796590"
                        ],
                        "name": "P. Merialdo",
                        "slug": "P.-Merialdo",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Merialdo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Merialdo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15075203,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3dd1f9f7795b31493d98d9f260d37aad07550f6e",
            "isKey": false,
            "numCitedBy": 1157,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper investigates techniques for extracting data from HTML sites through the use of automatically generated wrappers. To automate the wrapper generation and the data extraction process, the paper develops a novel technique to compare HTML pages and generate a wrapper based on their similarities and dierences. Experimental results on real-life data-intensive Web sites confirm the feasibility of the approach."
            },
            "slug": "RoadRunner:-Towards-Automatic-Data-Extraction-from-Crescenzi-Mecca",
            "title": {
                "fragments": [],
                "text": "RoadRunner: Towards Automatic Data Extraction from Large Web Sites"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A novel technique to compare HTML pages and generate a wrapper based on their similarities and dierences is developed, which confirms the feasibility of the approach on real-life data-intensive Web sites."
            },
            "venue": {
                "fragments": [],
                "text": "VLDB"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729294"
                        ],
                        "name": "Boris Chidlovskii",
                        "slug": "Boris-Chidlovskii",
                        "structuredName": {
                            "firstName": "Boris",
                            "lastName": "Chidlovskii",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Boris Chidlovskii"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3314322"
                        ],
                        "name": "Bruno Roustant",
                        "slug": "Bruno-Roustant",
                        "structuredName": {
                            "firstName": "Bruno",
                            "lastName": "Roustant",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bruno Roustant"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15538490"
                        ],
                        "name": "Marc Brette",
                        "slug": "Marc-Brette",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Brette",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc Brette"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8543935,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c135f3eec08b452bf1ca8dc2562ad677a243ec50",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Documentum Enterprise Content Integration (ECI) services is a content integration middleware that provides one-query access to the Intranet and Internet content resources. The ECI Adapter technology offers an interface to any application for data and metadata extraction from unstructured Web pages. It offers a unique frame-work of wrapper production, automatic recovery and maintenance, developed at Xerox Research Centre Europe and based on state-of-art algorithms from machine learning and grammatical inference. In this presentation we analyze the performance of ECI adapters deployed in current commercial installations. We benefit from accessing reports on daily tests for all ECI commercially deployed adapters collected from June 2003 to September 2005. Using the daily reports, we analyze different aspects of the wrapper technology."
            },
            "slug": "Documentum-ECI-self-repairing-wrappers:-performance-Chidlovskii-Roustant",
            "title": {
                "fragments": [],
                "text": "Documentum ECI self-repairing wrappers: performance analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This presentation analyzes the performance of ECI adapters deployed in current commercial installations and uses reports on daily tests for all ECI commercially deployed adapters collected from June 2003 to September 2005 to analyze different aspects of the wrapper technology."
            },
            "venue": {
                "fragments": [],
                "text": "SIGMOD Conference"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1774745"
                        ],
                        "name": "A. Broder",
                        "slug": "A.-Broder",
                        "structuredName": {
                            "firstName": "Andrei",
                            "lastName": "Broder",
                            "middleNames": [
                                "Z."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Broder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3016012"
                        ],
                        "name": "S. Glassman",
                        "slug": "S.-Glassman",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Glassman",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Glassman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2083378"
                        ],
                        "name": "M. Manasse",
                        "slug": "M.-Manasse",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Manasse",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Manasse"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681543"
                        ],
                        "name": "G. Zweig",
                        "slug": "G.-Zweig",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Zweig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Zweig"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9022773,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c3c576ff98424bea3e1e223cd6f68d4971438bf8",
            "isKey": false,
            "numCitedBy": 1501,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Syntactic-Clustering-of-the-Web-Broder-Glassman",
            "title": {
                "fragments": [],
                "text": "Syntactic Clustering of the Web"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Networks"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40355719"
                        ],
                        "name": "R. Agarwal",
                        "slug": "R.-Agarwal",
                        "structuredName": {
                            "firstName": "Rakesh",
                            "lastName": "Agarwal",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Agarwal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7736589,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9e63a730a1474f36eec781e70dd441fab5f5d4fd",
            "isKey": false,
            "numCitedBy": 6583,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of discovering association rules between items in a large database of sales transactions. We present two new algorithms for solving thii problem that are fundamentally different from the known algorithms. Empirical evaluation shows that these algorithms outperform the known algorithms by factors ranging from three for small problems to more than an order of magnitude for large problems. We also show how the best features of the two proposed algorithms can be combined into a hybrid algorithm, called AprioriHybrid. Scale-up experiments show that AprioriHybrid scales linearly with the number of transactions. AprioriHybrid also has excellent scale-up properties with respect to the transaction size and the number of items in the database."
            },
            "slug": "Fast-Algorithms-for-Mining-Association-Rules-Agarwal",
            "title": {
                "fragments": [],
                "text": "Fast Algorithms for Mining Association Rules"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "Two new algorithms for solving thii problem that are fundamentally different from the known algorithms are presented and empirical evaluation shows that these algorithms outperform theknown algorithms by factors ranging from three for small problems to more than an order of magnitude for large problems."
            },
            "venue": {
                "fragments": [],
                "text": "VLDB 1994"
            },
            "year": 1994
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 17,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Web-scale-information-extraction-with-vertex-Gulhane-Madaan/7a12502ba5b9686e37b0ec9d86a2dc7f4b7022ac?sort=total-citations"
}