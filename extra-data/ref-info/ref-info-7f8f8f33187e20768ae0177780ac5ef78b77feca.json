{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2953252"
                        ],
                        "name": "Dick Crouch",
                        "slug": "Dick-Crouch",
                        "structuredName": {
                            "firstName": "Dick",
                            "lastName": "Crouch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dick Crouch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803660"
                        ],
                        "name": "R. Kaplan",
                        "slug": "R.-Kaplan",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Kaplan",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kaplan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2142738"
                        ],
                        "name": "Tracy Holloway King",
                        "slug": "Tracy-Holloway-King",
                        "structuredName": {
                            "firstName": "Tracy",
                            "lastName": "King",
                            "middleNames": [
                                "Holloway"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tracy Holloway King"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3289329"
                        ],
                        "name": "S. Riezler",
                        "slug": "S.-Riezler",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Riezler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Riezler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 150
                            }
                        ],
                        "text": "\u2026down according to classes of parse quality are recorded in the follow-\n4See Carroll et al. (1999) for more detail on the DR annotation scheme, and see Crouch et al. (2002) for more detail on the differences between the DR and the LFG annotation schemes, as well as on the difficulties of the\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10108214,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b361b5941d79d0568efef14145417274240017ad",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper reports on the use of two distinct evaluation metrics for assessing a stochastic parsing model consisting of a broad-coverage Lexical-Functional Grammar (LFG), an efficient constraint-based parser and a stochastic disambiguation model. The first evaluation metric measures matches of predicate-argument relations in LFG f-structures (henceforth the LFG annotation scheme) to a gold standard of manually annotated f-structures for a subset of the UPenn Wall Street Journal treebank. The other metric maps predicate-argument relations in LFG f-structures to dependency relations (henceforth DR annotations) as proposed by Carroll et al. (Carroll et al., 1999). For evaluation, these relations are matched against Carroll et al.\u2019s gold standard which was manually annnotated on a subset of the Brown corpus. The parser plus stochastic disambiguator gives an F-measure of 79% (LFG) or 73% (DR) on the WSJ test set. This shows that the two evaluation schemes are similar in spirit, although accuracy is impaired systematically by mapping one annotation scheme to the other. A systematic loss of accuracy is incurred also by corpus variation: Training the stochastic disambiguation model on WSJ data and testing on Carroll et al.\u2019s Brown corpus data yields an F-score of 74% (DR) for dependency-relation match. A variant of this measure comparable to the measure reported by Carroll et al. yields an F-measure of 76%. We examine divergences between annotation schemes aiming at a future improvement of methods for assessing parser quality."
            },
            "slug": "A-Comparison-of-Evaluation-Metrics-for-a-Stochastic-Crouch-Kaplan",
            "title": {
                "fragments": [],
                "text": "A Comparison of Evaluation Metrics for a Broad-Coverage Stochastic Parser"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Divergences between annotation schemes aiming at a future improvement of methods for assessing parser quality are examined, showing that the two evaluation schemes are similar in spirit, although accuracy is impaired systematically by mapping one annotation scheme to the other."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793218"
                        ],
                        "name": "D. Gildea",
                        "slug": "D.-Gildea",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Gildea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gildea"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 149
                            }
                        ],
                        "text": "\u2026in error rate relative to the\nupper bound for DR evaluation on the Brown corpus can be attributed to a corpus effect that has also been\nobserved by Gildea (2001) for training and testing\nPCFGs on the WSJ and Brown corpora.5\nBreaking down results according to parse quality shows that irrespective\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 196105,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ee7e21dd09949a5a53b39c13fca9cd3d55e2bc50",
            "isKey": false,
            "numCitedBy": 326,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Most work in statistical parsing has focused on a single corpus: the Wall Street Journal portion of the Penn Treebank. While this has allowed for quantitative comparison of parsing techniques, it has left open the question of how other types of text might a ect parser performance, and how portable parsing models are across corpora. We examine these questions by comparing results for the Brown and WSJ corpora, and also consider which parts of the parser's probability model are particularly tuned to the corpus on which it was trained. This leads us to a technique for pruning parameters to reduce the size of the parsing model."
            },
            "slug": "Corpus-Variation-and-Parser-Performance-Gildea",
            "title": {
                "fragments": [],
                "text": "Corpus Variation and Parser Performance"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work examines how other types of text might a ect parser performance, and how portable parsing models are across corpora by comparing results for the Brown and WSJ corpora, and considers which parts of the parser's probability model are particularly tuned to the corpus on which it was trained."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3289329"
                        ],
                        "name": "S. Riezler",
                        "slug": "S.-Riezler",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Riezler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Riezler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2694275"
                        ],
                        "name": "D. Prescher",
                        "slug": "D.-Prescher",
                        "structuredName": {
                            "firstName": "Detlef",
                            "lastName": "Prescher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Prescher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716963"
                        ],
                        "name": "Jonas Kuhn",
                        "slug": "Jonas-Kuhn",
                        "structuredName": {
                            "firstName": "Jonas",
                            "lastName": "Kuhn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonas Kuhn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152465203"
                        ],
                        "name": "Mark Johnson",
                        "slug": "Mark-Johnson",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Johnson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Johnson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 113
                            }
                        ],
                        "text": "Furthermore, properties refering to lexical elements based on an auxiliary distribution approach as presented in Riezler et al. (2000) are included in the model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 112
                            }
                        ],
                        "text": "A stripped down version of the WSJ treebank was created that used only those POS tags and labeled brackets relevant for determining grammatical relations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 107
                            }
                        ],
                        "text": "Rather, parameter estimation for such models had to resort to unsupervised techniques (Bouma et al., 2000; Riezler et al., 2000), or training corpora tailored to the specific grammars had to be created by parsing and manual disambiguation, resulting in relatively small training sets of around 1,000\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 100
                            }
                        ],
                        "text": "Disambiguation performance is evaluated by measuring matches of predicate-argument relations on two distinct test sets."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 63346,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e06e39c0750dab5971f1bdfb132d55b39c715515",
            "isKey": false,
            "numCitedBy": 91,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new approach to stochastic modeling of constraint-based grammars that is based on loglinear models and uses EM for estimation from unannotated data. The techniques are applied to an LFG grammar for German. Evaluation on an exact match task yields 86% precision for an ambiguity rate of 5.4, and 90% precision on a subcat frame match for an ambiguity rate of 25. Experimental comparison to training from a parsebank shows a 10% gain from EM training. Also, a new class-based grammar lexicalization is presented, showing a 10% gain over unlexicalized models."
            },
            "slug": "Lexicalized-Stochastic-Modeling-of-Constraint-Based-Riezler-Prescher",
            "title": {
                "fragments": [],
                "text": "Lexicalized Stochastic Modeling of Constraint-Based Grammars using Log-Linear Measures and EM Training"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A new approach to stochastic modeling of constraint-based grammars that is based on loglinear models and uses EM for estimation from unannotated data and a new class-based grammar lexicalization is presented, showing a 10% gain over unlexicalized models."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144254013"
                        ],
                        "name": "G. Bouma",
                        "slug": "G.-Bouma",
                        "structuredName": {
                            "firstName": "Gosse",
                            "lastName": "Bouma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Bouma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143715131"
                        ],
                        "name": "Gertjan van Noord",
                        "slug": "Gertjan-van-Noord",
                        "structuredName": {
                            "firstName": "Gertjan",
                            "lastName": "Noord",
                            "middleNames": [
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gertjan van Noord"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145804005"
                        ],
                        "name": "Robert Malouf",
                        "slug": "Robert-Malouf",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Malouf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert Malouf"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 87
                            }
                        ],
                        "text": "Rather, parameter estimation for such models had to resort to unsupervised techniques (Bouma et al., 2000; Riezler et al., 2000), or training corpora tailored to the specific grammars had to be created by parsing and manual disambiguation, resulting in relatively small training sets of around 1,000\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 80
                            }
                        ],
                        "text": "Disambiguation performance is evaluated by measuring matches of predicate-argument relations on two distinct test sets."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15025069,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9442a24d6b6d28f35602b504be4336beda365002",
            "isKey": false,
            "numCitedBy": 241,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Alpino is a wide-coverage computational analyzer of Dutch which aims at accurate, full, parsing of unrestricted text. We describe the head-driven lexicalized grammar and the lexical component, which has been derived from existing resources. The grammar produces dependency structures, thus providing a reasonably abstract and theory-neutral level of linguistic representation. An important aspect of wide-coverage parsing is robustness and disambiguation. The dependency relations encoded in the dependency structures have been used to develop and evaluate both hand-coded and statistical disambiguation methods."
            },
            "slug": "Alpino:-Wide-coverage-Computational-Analysis-of-Bouma-Noord",
            "title": {
                "fragments": [],
                "text": "Alpino: Wide-coverage Computational Analysis of Dutch"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "Alpino is a wide-coverage computational analyzer of Dutch which aims at accurate, full, parsing of unrestricted text and describes the head-driven lexicalized grammar and the lexical component, which has been derived from existing resources."
            },
            "venue": {
                "fragments": [],
                "text": "CLIN"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144708726"
                        ],
                        "name": "John A. Carroll",
                        "slug": "John-A.-Carroll",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Carroll",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John A. Carroll"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145702640"
                        ],
                        "name": "Guido Minnen",
                        "slug": "Guido-Minnen",
                        "structuredName": {
                            "firstName": "Guido",
                            "lastName": "Minnen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guido Minnen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145693410"
                        ],
                        "name": "Ted Briscoe",
                        "slug": "Ted-Briscoe",
                        "structuredName": {
                            "firstName": "Ted",
                            "lastName": "Briscoe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ted Briscoe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 10
                            }
                        ],
                        "text": "Following Carroll et al. (1999), we count a dependency relation as correct if the gold standard has a relation with the same governor and dependent but perhaps with a different relation-type."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 78
                            }
                        ],
                        "text": "To our knowledge, so far the only direct point of comparison is the parser of Carroll et al. (1999) which is also evaluated on Carroll et al.\u2019s test corpus."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 6
                            }
                        ],
                        "text": "DO DR\nCarroll et al. (1999) 75.1 -\nupper bound 82.0 80.0 stochastic 76.1 74.0 lower bound 73.3 71.7\nerror reduction 32 33"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 148
                            }
                        ],
                        "text": "\u2026gold-standard f-structure annotations according to our LFG scheme, and (ii) 500 sentences from the Brown corpus given gold standard annotations by Carroll et al. (1999) according to their dependency relations (DR) scheme.3\nAnnotating the WSJ test set was bootstrapped by parsing the test\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 132
                            }
                        ],
                        "text": "In Table 3 we show the DR measure along with an evaluation measure which facilitates a direct comparison of our results to those of Carroll et al. (1999)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 90
                            }
                        ],
                        "text": "F-scores broken down according to classes of parse quality are recorded in the follow-\n4See Carroll et al. (1999) for more detail on the DR annotation scheme, and see Crouch et al. (2002) for more detail on the differences between the DR and the LFG annotation schemes, as well as on the\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "An evaluation on a gold standard of dependency relations for Brown corpus data achieves 76% F-score."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1954,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e43d67b3d053c7e37c3d233f53eca3b7ddd37f5c",
            "isKey": true,
            "numCitedBy": 122,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a recently developed corpus annotation scheme for evaluating parsers that avoids shortcomings of current methods. The scheme encodes grammatical relations between heads and dependents, and has been used to mark up a new public-domain corpus of naturally occurring English text. We show how the corpus can be used to evaluate the accuracy of a robust parser, and relate the corpus to extant resources."
            },
            "slug": "Corpus-Annotation-for-Parser-Evaluation-Carroll-Minnen",
            "title": {
                "fragments": [],
                "text": "Corpus Annotation for Parser Evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A recently developed corpus annotation scheme for evaluating parsers that avoids shortcomings of current methods is described, and it is shown how the corpus can be used to evaluate the accuracy of a robust parser, and relate the corpus to extant resources."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725500"
                        ],
                        "name": "Yves Schabes",
                        "slug": "Yves-Schabes",
                        "structuredName": {
                            "firstName": "Yves",
                            "lastName": "Schabes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yves Schabes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 696805,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0c0eab87d4855c42ae6395bf2e27eefe55003b4a",
            "isKey": false,
            "numCitedBy": 345,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "The inside-outside algorithm for inferring the parameters of a stochastic context-free grammar is extended to take advantage of constituent information in a partially parsed corpus. Experiments on formal and natural language parsed corpora show that the new algorithm can achieve faster convergence and better modelling of hierarchical structure than the original one. In particular, over 90% of the constituents in the most likely analyses of a test set are compatible with test set constituents for a grammar trained on a corpus of 700 hand-parsed part-of-speech strings for ATIS sentences."
            },
            "slug": "Inside-Outside-Reestimation-From-Partially-Corpora-Pereira-Schabes",
            "title": {
                "fragments": [],
                "text": "Inside-Outside Reestimation From Partially Bracketed Corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "The inside-outside algorithm for inferring the parameters of a stochastic context-free grammar is extended to take advantage of constituent information in a partially parsed corpus to achieve faster convergence and better modelling of hierarchical structure than the original one."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2265996"
                        ],
                        "name": "John T. Maxwell",
                        "slug": "John-T.-Maxwell",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Maxwell",
                            "middleNames": [
                                "T."
                            ],
                            "suffix": "III"
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John T. Maxwell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803660"
                        ],
                        "name": "R. Kaplan",
                        "slug": "R.-Kaplan",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Kaplan",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kaplan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 16
                            }
                        ],
                        "text": "The XLE parser (Maxwell and Kaplan, 1993) was used to produce packed represenations, specifying all possible grammar analyses of the input."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6943618,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b3b86bfc97ec254e4ed4ad75a955cdaaec3e42b0",
            "isKey": false,
            "numCitedBy": 190,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Many modern grammatical formalisms divide the task of linguistic specification into a context=free component of phrasal constraints and a separate component of attribute-value or functional constraints. Conventional methods for recognizing the strings of a language also divide into two parts so that they can exploit the different computational properties of these components. This paper focuses on the interface between these components as a source of computational complexity distinct from the complexity internal to each. We first analyze the common hybrid strategy in which a polynomial context-free parser is modified to interleave functional constraint solving with context-free constituent analysis. This strategy depends on the property of monotonicity in order to prune unnecessary computation. We describe a number of other properties that can be exploited for computational advantage, and we analyze some alternative interface strategies based on them. We present the results of preliminary experiments that generally support our intuitive analyses. A surprising outcome is that under certain circumstances an algorithm that does no pruning in the interface may perform significantly better than one that does."
            },
            "slug": "The-Interface-between-Phrasal-and-Functional-Maxwell-Kaplan",
            "title": {
                "fragments": [],
                "text": "The Interface between Phrasal and Functional Constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper analyzes the common hybrid strategy in which a polynomial context-free parser is modified to interleave functional constraint solving with context- free constituent analysis, and describes a number of other properties that can be exploited for computational advantage."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734174"
                        ],
                        "name": "M. Marcus",
                        "slug": "M.-Marcus",
                        "structuredName": {
                            "firstName": "Mitchell",
                            "lastName": "Marcus",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Marcus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116073558"
                        ],
                        "name": "Grace Kim",
                        "slug": "Grace-Kim",
                        "structuredName": {
                            "firstName": "Grace",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Grace Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2063206"
                        ],
                        "name": "Mary Ann Marcinkiewicz",
                        "slug": "Mary-Ann-Marcinkiewicz",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Marcinkiewicz",
                            "middleNames": [
                                "Ann"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mary Ann Marcinkiewicz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33353168"
                        ],
                        "name": "R. MacIntyre",
                        "slug": "R.-MacIntyre",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "MacIntyre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. MacIntyre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3212973"
                        ],
                        "name": "Ann Bies",
                        "slug": "Ann-Bies",
                        "structuredName": {
                            "firstName": "Ann",
                            "lastName": "Bies",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ann Bies"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054785529"
                        ],
                        "name": "Mark Ferguson",
                        "slug": "Mark-Ferguson",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Ferguson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Ferguson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065702818"
                        ],
                        "name": "Karen Katz",
                        "slug": "Karen-Katz",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Katz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karen Katz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2537676"
                        ],
                        "name": "Britta Schasberger",
                        "slug": "Britta-Schasberger",
                        "structuredName": {
                            "firstName": "Britta",
                            "lastName": "Schasberger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Britta Schasberger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 211
                            }
                        ],
                        "text": "The approach presented in this paper is a first attempt to scale up stochastic parsing systems based on linguistically fine-grained handcoded grammars to the UPenn Wall Street Journal (henceforth WSJ) treebank (Marcus et al., 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "An evaluation on a gold standard of dependency relations for Brown corpus data achieves 76% F-score."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5151364,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "59ce9cdbde13affc05a6c1f48a51ee7b0fcb154b",
            "isKey": false,
            "numCitedBy": 897,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "The Penn Treebank has recently implemented a new syntactic annotation scheme, designed to highlight aspects of predicate-argument structure. This paper discusses the implementation of crucial aspects of this new annotation scheme. It incorporates a more consistent treatment of a wide range of grammatical phenomena, provides a set of coindexed null elements in what can be thought of as \"underlying\" position for phenomena such as wh-movement, passive, and the subjects of infinitival constructions, provides some non-context free annotational mechanism to allow the structure of discontinuous constituents to be easily recovered, and allows for a clear, concise tagging system for some semantic roles."
            },
            "slug": "The-Penn-Treebank:-Annotating-Predicate-Argument-Marcus-Kim",
            "title": {
                "fragments": [],
                "text": "The Penn Treebank: Annotating Predicate Argument Structure"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "The implementation of crucial aspects of this new syntactic annotation scheme incorporates a more consistent treatment of a wide range of grammatical phenomena, provides a set of coindexed null elements in what can be thought of as \"underlying\" position for phenomena such as wh-movement, passive, and the subjects of infinitival constructions."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152465203"
                        ],
                        "name": "Mark Johnson",
                        "slug": "Mark-Johnson",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Johnson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Johnson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3194361"
                        ],
                        "name": "S. Geman",
                        "slug": "S.-Geman",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Geman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47428006"
                        ],
                        "name": "S. Canon",
                        "slug": "S.-Canon",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Canon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Canon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140471"
                        ],
                        "name": "Zhiyi Chi",
                        "slug": "Zhiyi-Chi",
                        "structuredName": {
                            "firstName": "Zhiyi",
                            "lastName": "Chi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhiyi Chi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3289329"
                        ],
                        "name": "S. Riezler",
                        "slug": "S.-Riezler",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Riezler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Riezler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 294,
                                "start": 274
                            }
                        ],
                        "text": "\u2026models had to resort to unsupervised techniques (Bouma et al., 2000; Riezler et al., 2000), or training corpora tailored to the specific grammars had to be created by parsing and manual disambiguation, resulting in relatively small training sets of around 1,000 sentences (Johnson et al., 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 119
                            }
                        ],
                        "text": "The grammar has 314 rules with regular expression right-hand sides which compile into a collection of finite-state machines with a total of 8,759 states and 19,695 arcs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 176
                            }
                        ],
                        "text": "Discriminative estimation techniques have recently received great attention in the statistical machine learning community and have already been applied to statistical parsing (Johnson et al., 1999; Collins, 2000; Collins and Duffy, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 88
                            }
                        ],
                        "text": "This grammar parses the sentence as well-formed chunks specified by the grammar, in particular as Ss, NPs, PPs, and VPs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 188
                            }
                        ],
                        "text": "In our experiments, we used around 1000 complex property-functions comprising information about c-structure, f-structure, and lexical elements in parses, similar to the properties used in Johnson et al. (1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 60
                            }
                        ],
                        "text": "An evaluation on a gold standard of dependency relations for Brown corpus data achieves 76% F-score."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17435621,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "463dbd690d912b23d29b7581fb6b253b36f50394",
            "isKey": false,
            "numCitedBy": 233,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Log-linear models provide a statistically sound framework for Stochastic \"Unification-Based\" Grammars (SUBGs) and stochastic versions of other kinds of grammars. We describe two computationally-tractable ways of estimating the parameters of such grammars from a training corpus of syntactic analyses, and apply these to estimate a stochastic version of Lexical-Functional Grammar."
            },
            "slug": "Estimators-for-Stochastic-\"Unification-Based\"-Johnson-Geman",
            "title": {
                "fragments": [],
                "text": "Estimators for Stochastic \"Unification-Based\" Grammars"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "Two computationally-tractable ways of estimating the parameters of Stochastic \"Unification-Based\" Grammars from a training corpus of syntactic analyses are described and applied to estimate a stochastic version of Lexical-Functional Grammar."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143857271"
                        ],
                        "name": "Nigel P. Duffy",
                        "slug": "Nigel-P.-Duffy",
                        "structuredName": {
                            "firstName": "Nigel",
                            "lastName": "Duffy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nigel P. Duffy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 236,
                                "start": 213
                            }
                        ],
                        "text": "Discriminative estimation techniques have recently received great attention in the statistical machine learning community and have already been applied to statistical parsing (Johnson et al., 1999; Collins, 2000; Collins and Duffy, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 396794,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e6c7adc28e20d361d5c35aa9808094b10f6a34d1",
            "isKey": false,
            "numCitedBy": 932,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the application of kernel methods to Natural Language Processing (NLP) problems. In many NLP tasks the objects being modeled are strings, trees, graphs or other discrete structures which require some mechanism to convert them into feature vectors. We describe kernels for various natural language structures, allowing rich, high dimensional representations of these structures. We show how a kernel over trees can be applied to parsing using the voted perceptron algorithm, and we give experimental results on the ATIS corpus of parse trees."
            },
            "slug": "Convolution-Kernels-for-Natural-Language-Collins-Duffy",
            "title": {
                "fragments": [],
                "text": "Convolution Kernels for Natural Language"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown how a kernel over trees can be applied to parsing using the voted perceptron algorithm, and experimental results on the ATIS corpus of parse trees are given."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2160898"
                        ],
                        "name": "Miriam Butt",
                        "slug": "Miriam-Butt",
                        "structuredName": {
                            "firstName": "Miriam",
                            "lastName": "Butt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Miriam Butt"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The grammar used for this project was developed in the ParGram project (Butt et al., 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 60600968,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "aeeeb3ee5a2c683cfd9444c71f11741d5187de94",
            "isKey": false,
            "numCitedBy": 253,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Introduction The grammars: General analyses The clause Verbal elements Nominal elements Determiners Adjectives Prepositional phrases Adverbial elements Coordination Grammar engineering Overview Architecture and user interface Modularity, maintainability and transparency Ambiguity/overgeneration Measuring performance Finite state technology Concluding remarks Appendix."
            },
            "slug": "A-grammar-writer's-cookbook-Butt",
            "title": {
                "fragments": [],
                "text": "A grammar writer's cookbook"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "The grammars: general analyses The clause Verbal elements Nominal elements Determiners Adjectives Prepositional phrases Adverbial elements Coordination Grammar engineering Overview Architecture and user interface Modularity, maintainability and transparency Ambiguity/overgeneration Measuring performance Finite state technology Concluding remarks Appendix."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768120"
                        ],
                        "name": "T. Jebara",
                        "slug": "T.-Jebara",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Jebara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jebara"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 149
                            }
                        ],
                        "text": "Furthermore, only sentences\n2An alternative numerical method would be a combination of iterative scaling techniques with a conditional EM algorithm (Jebara and Pentland, 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1436930,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b791cefc34e24e8d0def67fecad6335afef76b7b",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "We present the CEM (Conditional Expectation Maximization) algorithm as an extension of the EM (Expectation Maximization) algorithm to conditional density estimation under missing data. A bounding and maximization process is given to specifically optimize conditional likelihood instead of the usual joint likelihood. We apply the method to conditioned mixture models and use bounding techniques to derive the model's update rules. Monotonic convergence, computational efficiency and regression results superior to EM are demonstrated."
            },
            "slug": "Maximum-Conditional-Likelihood-via-Bound-and-the-Jebara-Pentland",
            "title": {
                "fragments": [],
                "text": "Maximum Conditional Likelihood via Bound Maximization and the CEM Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "The CEM algorithm is presented as an extension of the EM (Expectation Maximization) algorithm to conditional density estimation under missing data and a bounding and maximization process is given to specifically optimize conditional likelihood instead of the usual joint likelihood."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 176
                            }
                        ],
                        "text": "Discriminative estimation techniques have recently received great attention in the statistical machine learning community and have already been applied to statistical parsing (Johnson et al., 1999; Collins, 2000; Collins and Duffy, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 188
                            }
                        ],
                        "text": "In our experiments, we used around 1000 complex property-functions comprising information about c-structure, f-structure, and lexical elements in parses, similar to the properties used in Johnson et al. (1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 294,
                                "start": 274
                            }
                        ],
                        "text": "\u2026models had to resort to unsupervised techniques (Bouma et al., 2000; Riezler et al., 2000), or training corpora tailored to the specific grammars had to be created by parsing and manual disambiguation, resulting in relatively small training sets of around 1,000 sentences (Johnson et al., 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 189
                            }
                        ],
                        "text": ", 2000), or training corpora tailored to the specific grammars had to be created by parsing and manual disambiguation, resulting in relatively small training sets of around 1,000 sentences (Johnson et al., 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Estimators for stochastic \u201cunification-based"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52626911"
                        ],
                        "name": "T. Minka",
                        "slug": "T.-Minka",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Minka",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Minka"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118158295,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f90e71df8f88a278b22920e2e976947e637efad8",
            "isKey": false,
            "numCitedBy": 107,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Algorithms-for-maximum-likelihood-logistic-Minka",
            "title": {
                "fragments": [],
                "text": "Algorithms for maximum-likelihood logistic regression"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705097"
                        ],
                        "name": "F. Pereira",
                        "slug": "F.-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "Carlos",
                                "Neves"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Pereira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725500"
                        ],
                        "name": "Yves Schabes",
                        "slug": "Yves-Schabes",
                        "structuredName": {
                            "firstName": "Yves",
                            "lastName": "Schabes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yves Schabes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 63967455,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "15e4843e2c55843b5c5b429f89dad3d99e801f02",
            "isKey": false,
            "numCitedBy": 191,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "The inside-outside algorithm for inferring the parameters of a stochastic context-free grammar is extended to take advantage of constituent information (constituent bracketing) in a partially parsed corpus. Experiments on formal and natural language parsed corpora show that the new algorithm can achieve faster convergence and better modeling of hierarchical structure than the original one. In particular, over 90% test set bracketing accuracy was achieved for grammars inferred by our algorithm from a training set of handparsed part-of-speech strings for sentences in the Air Travel Information System spoken language corpus. Finally, the new algorithm has better time complexity than the original one when sufficient bracketing is provided."
            },
            "slug": "Inside-Outside-Reestimation-From-Partially-Corpora-Pereira-Schabes",
            "title": {
                "fragments": [],
                "text": "Inside-Outside Reestimation From Partially Bracketed Corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "The inside-outside algorithm for inferring the parameters of a stochastic context-free grammar is extended to take advantage of constituent information (constituent bracketing) in a partially parsed corpus to achieve faster convergence and better modeling of hierarchical structure than the original one."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 198
                            }
                        ],
                        "text": "Discriminative estimation techniques have recently received great attention in the statistical machine learning community and have already been applied to statistical parsing (Johnson et al., 1999; Collins, 2000; Collins and Duffy, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Discriminative reranking for natural language processing"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventeenth International Conference on Machine Learning (ICML'00)"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 145
                            }
                        ],
                        "text": "However, it has been shown experimentally that conjugate gradient techniques can outperform iterative scaling techniques by far in running time (Minka, 2001).\nwhich received at most 1,000 parses were used."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Algorithms for maximumlikelihood logistic regression"
            },
            "venue": {
                "fragments": [],
                "text": "Algorithms for maximumlikelihood logistic regression"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 145
                            }
                        ],
                        "text": "However, it has been shown experimentally that conjugate gradient techniques can outperform iterative scaling techniques by far in running time (Minka, 2001).\nwhich received at most 1,000 parses were used."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Algorithms for maximumlikelihood logistic regression. Department of Statistics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 72
                            }
                        ],
                        "text": "The grammar used for this project was developed in the ParGram project (Butt et al., 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 72
                            }
                        ],
                        "text": "Statistical parsing using combined systems of handcoded linguistically fine-grained grammars and stochastic disambiguation components has seen considerable progress in recent years."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Grammar Writer's Cookbook . Number 95 in CSLI Lecture Notes"
            },
            "venue": {
                "fragments": [],
                "text": "A Grammar Writer's Cookbook . Number 95 in CSLI Lecture Notes"
            },
            "year": 1999
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 11,
            "methodology": 10,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 19,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Parsing-the-Wall-Street-Journal-using-a-Grammar-and-Riezler-King/7f8f8f33187e20768ae0177780ac5ef78b77feca?sort=total-citations"
}