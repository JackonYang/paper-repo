{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108641"
                        ],
                        "name": "Rohit J. Kate",
                        "slug": "Rohit-J.-Kate",
                        "structuredName": {
                            "firstName": "Rohit",
                            "lastName": "Kate",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rohit J. Kate"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8075439"
                        ],
                        "name": "Y. W. Wong",
                        "slug": "Y.-W.-Wong",
                        "structuredName": {
                            "firstName": "Yuk",
                            "lastName": "Wong",
                            "middleNames": [
                                "Wah"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. W. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 278,
                                "start": 236
                            }
                        ],
                        "text": "We present experimental results on corpora for both geography-database querying and Robocup coaching demonstrating that S CISSORproduces more accurate semantic representations than several previous approaches based on symbolic learning (Tang and Mooney, 2001; Kate et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 121
                            }
                        ],
                        "text": "S ILT is a system that learns symbolic, pattern-based, transformation rules for mapping NL sentences to formal languages (Kate et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 121
                            }
                        ],
                        "text": "SILT is a system that learns symbolic, pattern-based, transformation rules for mapping NL sentences to formal languages (Kate et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 276,
                                "start": 259
                            }
                        ],
                        "text": "We present experimental results on corpora for both geography-database querying and Robocup coaching demonstrating that SCISSORproduces more accurate semantic representations than several previous approaches based on symbolic learning (Tang and Mooney, 2001; Kate et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 79
                            }
                        ],
                        "text": "Each formal instruction was translated into English by one of four annotators (Kate et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7396224,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8dd9fd6a45afd266d48255c398429e01ea4fd6db",
            "isKey": false,
            "numCitedBy": 220,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for inducing transformation rules that map natural-language sentences into a formal query or command language. The approach assumes a formal grammar for the target representation language and learns transformation rules that exploit the non-terminal symbols in this grammar. The learned transformation rules incrementally map a natural-language sentence or its syntactic parse tree into a parse-tree for the target formal language. Experimental results are presented for two corpora. one which maps English instructions into an existing formal coaching language for simulated RoboCup soccer agents, and another which maps English U.S.-geography questions into a database query language. We show that our method performs overall better and faster than previous approaches in both domains."
            },
            "slug": "Learning-to-Transform-Natural-to-Formal-Languages-Kate-Wong",
            "title": {
                "fragments": [],
                "text": "Learning to Transform Natural to Formal Languages"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "This paper presents a method for inducing transformation rules that map natural-language sentences into a formal query or command language and shows that this method performs overall better and faster than previous approaches in both domains."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36445704"
                        ],
                        "name": "Ana-Maria Popescu",
                        "slug": "Ana-Maria-Popescu",
                        "structuredName": {
                            "firstName": "Ana-Maria",
                            "lastName": "Popescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ana-Maria Popescu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2177004"
                        ],
                        "name": "Alex Armanasu",
                        "slug": "Alex-Armanasu",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Armanasu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Armanasu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741101"
                        ],
                        "name": "Oren Etzioni",
                        "slug": "Oren-Etzioni",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Etzioni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Etzioni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2061196271"
                        ],
                        "name": "David Ko",
                        "slug": "David-Ko",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Ko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Ko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3321874"
                        ],
                        "name": "A. Yates",
                        "slug": "A.-Yates",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Yates",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yates"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 235,
                                "start": 213
                            }
                        ],
                        "text": "The queries in this corpus are more complex than those in the ATIS database-query corpus used in the speech community (Zue and Glass, 2000) which makes the G EOQUERYproblem harder, as also shown by the results in (Popescu et al., 2004)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 233,
                                "start": 213
                            }
                        ],
                        "text": "The queries in this corpus are more complex than those in the ATIS database-query corpus used in the speech community (Zue and Glass, 2000) which makes the GEOQUERYproblem harder, as also shown by the results in (Popescu et al., 2004)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 1942340,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "49a8ae5eb474e7f6ce3669f9c55efaee1d43cdec",
            "isKey": false,
            "numCitedBy": 195,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Natural Language Interfaces to Databases (NLIs) can benefit from the advances in statistical parsing over the last fifteen years or so. However, statistical parsers require training on a massive, labeled corpus, and manually creating such a corpus for each database is prohibitively expensive. To address this quandary, this paper reports on the PRECISE NLI, which uses a statistical parser as a \"plug in\". The paper shows how a strong semantic model coupled with \"light re-training\" enables PRECISE to overcome parser errors, and correctly map from parsed questions to the corresponding SQL queries. We discuss the issues in using statistical parsers to build database-independent NLIs, and report on experimental results with the benchmark ATIS data set where PRECISE achieves 94% accuracy."
            },
            "slug": "Modern-Natural-Language-Interfaces-to-Databases:-Popescu-Armanasu",
            "title": {
                "fragments": [],
                "text": "Modern Natural Language Interfaces to Databases: Composing Statistical Parsing with Semantic Tractability"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The paper shows how a strong semantic model coupled with \"light re-training\" enables PRECISE to overcome parser errors, and correctly map from parsed questions to the corresponding SQL queries."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1818123"
                        ],
                        "name": "E. Black",
                        "slug": "E.-Black",
                        "structuredName": {
                            "firstName": "Ezra",
                            "lastName": "Black",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739581"
                        ],
                        "name": "J. Lafferty",
                        "slug": "J.-Lafferty",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Lafferty",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lafferty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2580777"
                        ],
                        "name": "David M. Magerman",
                        "slug": "David-M.-Magerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Magerman",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David M. Magerman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781292"
                        ],
                        "name": "S. Roukos",
                        "slug": "S.-Roukos",
                        "structuredName": {
                            "firstName": "Salim",
                            "lastName": "Roukos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roukos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 58
                            }
                        ],
                        "text": "History-based models of parsing were first introduced in (Black et al., 1993)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5598810,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0ccae6c9f33e41de9c00053aac0bc6c615c7b4a",
            "isKey": false,
            "numCitedBy": 282,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a generative probabilistic model of natural language, which we call HBG, that takes advantage of detailed linguistic information to resolve ambiguity. HBG incorporates lexical, syntactic, semantic, and structural information from the parse tree into the disambiguation process in a novel way. We use a corpus of bracketed sentences, called a Treebank, in combination with decision tree building to tease out the relevant aspects of a parse tree that will determine the correct parse of a sentence. This stands in contrast to the usual approach of further grammar tailoring via the usual linguistic introspection in the hope of generating the correct parse. In head-to-head tests against one of the best existing robust probabilistic parsing models, which we call P-CFG, the HBG model significantly outperforms P-CFG, increasing the parsing accuracy rate from 60% to 75%, a 37% reduction in error."
            },
            "slug": "Towards-History-based-Grammars:-Using-Richer-Models-Black-Jelinek",
            "title": {
                "fragments": [],
                "text": "Towards History-based Grammars: Using Richer Models for Probabilistic Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "HBG incorporates lexical, syntactic, semantic, and structural information from the parse tree into the disambiguation process in a novel way and significantly outperforms P-CFG, increasing the parsing accuracy rate from 60% to 75%, a 37% reduction in error."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793218"
                        ],
                        "name": "D. Gildea",
                        "slug": "D.-Gildea",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Gildea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gildea"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 112
                            }
                        ],
                        "text": "Most recent work in learning for semantic parsing has focused on \u201cshallow\u201d analysis such assemantic role labeling(Gildea and Jurafsky, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207747200,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "fcb7e6cf3b4c349b729fa0444bbb5ac1f99c3f3a",
            "isKey": false,
            "numCitedBy": 882,
            "numCiting": 78,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a system for identifying the semantic relationships, or semantic roles, filled by constituents of a sentence within a semantic frame. Given an input sentence and a target word and frame, the system labels constituents with either abstract semantic roles, such as Agent or Patient, or more domain-specific semantic roles, such as Speaker, Message, and Topic. The system is based on statistical classifiers trained on roughly 50,000 sentences that were hand-annotated with semantic roles by the FrameNet semantic labeling project. We then parsed each training sentence into a syntactic tree and extracted various lexical and syntactic features, including the phrase type of each constituent, its grammatical function, and its position in the sentence. These features were combined with knowledge of the predicate verb, noun, or adjective, as well as information such as the prior probabilities of various combinations of semantic roles. We used various lexical clustering algorithms to generalize across possible fillers of roles. Test sentences were parsed, were annotated with these features, and were then passed through the classifiers. Our system achieves 82 accuracy in identifying the semantic role of presegmented constituents. At the more difficult task of simultaneously segmenting constituents and identifying their semantic role, the system achieved 65 precision and 61 recall. Our study also allowed us to compare the usefulness of different features and feature combination methods in the semantic role labeling task. We also explore the integration of role labeling with statistical syntactic parsing and attempt to generalize to predicates unseen in the training data."
            },
            "slug": "Automatic-Labeling-of-Semantic-Roles-Gildea-Jurafsky",
            "title": {
                "fragments": [],
                "text": "Automatic Labeling of Semantic Roles"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A system for identifying the semantic relationships, or semantic roles, filled by constituents of a sentence within a semantic frame, based on statistical classifiers trained on roughly 50,000 sentences that were hand-annotated with semantic roles by the FrameNet semantic labeling project."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710450"
                        ],
                        "name": "J. Zelle",
                        "slug": "J.-Zelle",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Zelle",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Zelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 59
                            }
                        ],
                        "text": "The only exception is with recall for GEOQUERY, for which CHILL is slightly higher."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 7
                            }
                        ],
                        "text": "C HILL (Zelle and Mooney, 1996) is a system based on Inductive Logic Programming (ILP)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 1
                            }
                        ],
                        "text": "CHILL uses computationally-complex ILP methods, which are slow and memory intensive."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 192
                            }
                        ],
                        "text": "We compare to the version of CHILL presented in (Tang and Mooney, 2001), which uses the improved C OCKTAIL ILP system and produces more accurate parsers than the original version presented in (Zelle and Mooney, 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 89
                            }
                        ],
                        "text": "The G EOQUERY language consists of Prolog queries augmented with several meta-predicates (Zelle and Mooney, 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 201
                            }
                        ],
                        "text": "It comes in two versions, SILT -string, which maps NL strings directly to an MRL, and SILT -tree, which maps syntactic\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\nP re\nci si\non (\n% )\nSCISSOR SILT-string\nSILT-tree CHILL GEOBASE\n0\n10\n20\n30\n40\n50\n60\n70\n80\n0 50 100 150 200 250\nR ec\nal l (\n% )\nTraining sentences\nSCISSOR SILT-string\nSILT-tree CHILL GEOBASE\nFigure 7: Recall learning curves for GEOQUERY.\nparse trees (generated by the Collins parser) to an MRL."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 7
                            }
                        ],
                        "text": "Since CHILL is very memory intensive, it could not be run with larger training sets of the CLANG corpus."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 1
                            }
                        ],
                        "text": "CHILL (Zelle and Mooney, 1996) is a system based on Inductive Logic Programming (ILP)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 30
                            }
                        ],
                        "text": "We compare to the version of CHILL presented in (Tang and Mooney, 2001), which uses the improved COCKTAIL ILP system and produces more accurate parsers than the original version presented in (Zelle and Mooney, 1996)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 263135,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b7c0e47f8b768258b7d536c21b218e6c46ab8791",
            "isKey": false,
            "numCitedBy": 642,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents recent work using the CHILL parser acquisition system to automate the construction of a natural-language interface for database queries. CHILL treats parser acquisition as the learning of search-control rules within a logic program representing a shift-reduce parser and uses techniques from Inductive Logic Programming to learn relational control knowledge. Starting with a general framework for constructing a suitable logical form, CHILL is able to train on a corpus comprising sentences paired with database queries and induce parsers that map subsequent sentences directly into executable queries. Experimental results with a complete database-query application for U.S. geography show that CHILL is able to learn parsers that outperform a preexisting, hand-crafted counterpart. These results demonstrate the ability of a corpus-based system to produce more than purely syntactic representations. They also provide direct evidence of the utility of an empirical approach at the level of a complete natural language application."
            },
            "slug": "Learning-to-Parse-Database-Queries-Using-Inductive-Zelle-Mooney",
            "title": {
                "fragments": [],
                "text": "Learning to Parse Database Queries Using Inductive Logic Programming"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Experimental results with a complete database-query application for U.S. geography show that CHILL is able to learn parsers that outperform a preexisting, hand-crafted counterpart, and provide direct evidence of the utility of an empirical approach at the level of a complete natural language application."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI, Vol. 2"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110271578"
                        ],
                        "name": "Scott Miller",
                        "slug": "Scott-Miller",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Miller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Scott Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145482266"
                        ],
                        "name": "D. Stallard",
                        "slug": "D.-Stallard",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Stallard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Stallard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2189985"
                        ],
                        "name": "R. Bobrow",
                        "slug": "R.-Bobrow",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Bobrow",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bobrow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35442155"
                        ],
                        "name": "R. Schwartz",
                        "slug": "R.-Schwartz",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Schwartz",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schwartz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 27
                            }
                        ],
                        "text": "The systems introduced in (Miller et al., 1996; Miller et al., 2000) also integrate semantic labels into parsing; however, their SAPT\u2019s are used to pro-\nduce a much simpler MR, i.e., a single semantic frame."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10983275,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e9c1f510bcf5933d3cf8ec8108a04a9ba601a843",
            "isKey": false,
            "numCitedBy": 158,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a natural language interface system which is based entirely on trained statistical models. The system consists of three stages of processing: parsing, semantic interpretation, and discourse. Each of these stages is modeled as a statistical process. The models are fully integrated, resulting in an end-to-end system that maps input utterances into meaning representation frames."
            },
            "slug": "A-Fully-Statistical-Approach-to-Natural-Language-Miller-Stallard",
            "title": {
                "fragments": [],
                "text": "A Fully Statistical Approach to Natural Language Interfaces"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "This work presents a natural language interface system which is based entirely on trained statistical models, resulting in an end-to-end system that maps input utterances into meaning representation frames."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2190169"
                        ],
                        "name": "L. Tang",
                        "slug": "L.-Tang",
                        "structuredName": {
                            "firstName": "Lappoon",
                            "lastName": "Tang",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 48
                            }
                        ],
                        "text": "We compare to the version of CHILL presented in (Tang and Mooney, 2001), which uses the improved C OCKTAIL ILP system and produces more accurate parsers than the original version presented in (Zelle and Mooney, 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 278,
                                "start": 236
                            }
                        ],
                        "text": "We present experimental results on corpora for both geography-database querying and Robocup coaching demonstrating that S CISSORproduces more accurate semantic representations than several previous approaches based on symbolic learning (Tang and Mooney, 2001; Kate et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16100071,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f60d8dd8ca3a7dfa7d0a14988af73084ad93619d",
            "isKey": false,
            "numCitedBy": 261,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we explored a learning approach which combines different learning methods in inductive logic programming (ILP) to allow a learner to produce more expressive hypotheses than that of each individual learner. Such a learning approach may be useful when the performance of the task depends on solving a large amount of classification problems and each has its own characteristics which may or may not fit a particular learning method. The task of semantic parser acquisition in two different domains was attempted and preliminary results demonstrated that such an approach is promising."
            },
            "slug": "Using-Multiple-Clause-Constructors-in-Inductive-for-Tang-Mooney",
            "title": {
                "fragments": [],
                "text": "Using Multiple Clause Constructors in Inductive Logic Programming for Semantic Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "Preliminary results demonstrated that an approach which combines different learning methods in inductive logic programming (ILP) to allow a learner to produce more expressive hypotheses than that of each individual learner is promising."
            },
            "venue": {
                "fragments": [],
                "text": "ECML"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40031121"
                        ],
                        "name": "Yuqing Gao",
                        "slug": "Yuqing-Gao",
                        "structuredName": {
                            "firstName": "Yuqing",
                            "lastName": "Gao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuqing Gao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145218984"
                        ],
                        "name": "Bowen Zhou",
                        "slug": "Bowen-Zhou",
                        "structuredName": {
                            "firstName": "Bowen",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bowen Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066371092"
                        ],
                        "name": "Zijian Diao",
                        "slug": "Zijian-Diao",
                        "structuredName": {
                            "firstName": "Zijian",
                            "lastName": "Diao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zijian Diao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144431938"
                        ],
                        "name": "Jeffrey Scott Sorensen",
                        "slug": "Jeffrey-Scott-Sorensen",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Sorensen",
                            "middleNames": [
                                "Scott"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeffrey Scott Sorensen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1774515"
                        ],
                        "name": "M. Picheny",
                        "slug": "M.-Picheny",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Picheny",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Picheny"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 123
                            }
                        ],
                        "text": "Most recent work in learning for semantic parsing has focused on \u201cshallow\u201d analysis such assemantic role labeling(Gildea and Jurafsky, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2553392,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "893ba2a4ead2ba63cee47ab64c15dd31dc493411",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We present MARS (Multilingual Automatic tRanslation System), a research prototype speech-to-speech translation system. MARS is aimed at two-way conversational spoken language translation between English and Mandarin Chinese for limited domains, such as air travel reservations. In MARS, machine translation is embedded within a complex speech processing task, and the translation performance is highly effected by the performance of other components, such as the recognizer and semantic parser, etc. All components in the proposed system are statistically trained using an appropriate training corpus. The speech signal is first recognized by an automatic speech recognizer (ASR). Next, the ASR-transcribed text is analyzed by a semantic parser, which uses a statistical decision-tree model that does not require hand-crafted grammars or rules. Furthermore, the parser provides semantic information that helps further re-scoring of the speech recognition hypotheses. The semantic content extracted by the parser is formatted into a language-independent tree structure, which is used for an interlingua based translation. A Maximum Entropy based sentence-level natural language generation (NLG) approach is used to generate sentences in the target language from the semantic tree representations. Finally, the generated target sentence is synthesized into speech by a speech synthesizer.Many new features and innovations have been incorporated into MARS: the translation is based on understanding the meaning of the sentence; the semantic parser uses a statistical model and is trained from a semantically annotated corpus; the output of the semantic parser is used to select a more specific language model to refine the speech recognition performance; the NLG component uses a statistical model and is also trained from the same annotated corpus. These features give MARS the advantages of robustness to speech disfluencies and recognition errors, tighter integration of semantic information into speech recognition, and portability to new languages and domains. These advantages are verified by our experimental results."
            },
            "slug": "MARS:-A-Statistical-Semantic-Parsing-and-Automatic-Gao-Zhou",
            "title": {
                "fragments": [],
                "text": "MARS: A Statistical Semantic Parsing and Generation-Based Multilingual Automatic tRanslation System"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "MARS (Multilingual Automatic tRanslation System), a research prototype speech-to-speech translation system, is aimed at two-way conversational spoken language translation between English and Mandarin Chinese for limited domains, such as air travel reservations."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Translation"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 68
                            }
                        ],
                        "text": "Only one word is labeled with the concept; the syntactic head word (Collins, 1997) is preferred."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 7
                            }
                        ],
                        "text": "As in (Collins, 1997), the parameterPl(Li(lti; lwi)jP;H;w; t; ; LC) is further smoothed as follows:Pl1(LijP;H;w; t; ; LC) Pl2(ltijP;H;w; t; ; LC;Li) Pl3(lwijP;H;w; t; ; LC;Li(lti)) Note this smoothing is different from the syntactic counterpart."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 80
                            }
                        ],
                        "text": "The syntactic parameters are the same as in Section 5.1 and are smoothed as in (Collins, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 81
                            }
                        ],
                        "text": "Otherwise they are generated along with the words using the same approach as in (Collins, 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 53
                            }
                        ],
                        "text": "In the following section, we follow the notation in (Collins, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 40
                            }
                        ],
                        "text": "We augment Collins\u2019 head-driven model 2 (Collins, 1997) to incorporate a semantic label on each internal node."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 87
                            }
                        ],
                        "text": "The probabilities from these back-off levels are interpolated using the techniques in (Collins, 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 53
                            }
                        ],
                        "text": "Note this threshold is smaller than the one used in (Collins, 1997) since the corpora used in our experiments are smaller."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1345,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0ffa423a5283396c88ff3d4033d541796bd039cc",
            "isKey": true,
            "numCitedBy": 873,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we first propose a new statistical parsing model, which is a generative model of lexicalised context-free grammar. We then extend the model to include a probabilistic treatment of both subcategorisation and wh-movement. Results on Wall Street Journal text show that the parser performs at 88.1/87.5% constituent precision/recall, an average improvement of 2.3% over (Collins 96)."
            },
            "slug": "Three-Generative,-Lexicalised-Models-for-Parsing-Collins",
            "title": {
                "fragments": [],
                "text": "Three Generative, Lexicalised Models for Statistical Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "A new statistical parsing model is proposed, which is a generative model of lexicalised context-free grammar and extended to include a probabilistic treatment of both subcategorisation and wh-movement."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793218"
                        ],
                        "name": "D. Gildea",
                        "slug": "D.-Gildea",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Gildea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gildea"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 62182406,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c274b8aac56e49e65a3827c570b2496b14429166",
            "isKey": false,
            "numCitedBy": 1099,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a system for identifying the semantic relationships, or semantic roles, filled by constituents of a sentence within a semantic frame. Various lexical and syntactic features are derived from parse trees and used to derive statistical classifiers from hand-annotated training data."
            },
            "slug": "Automatic-Labeling-of-Semantic-Roles-Gildea-Jurafsky",
            "title": {
                "fragments": [],
                "text": "Automatic Labeling of Semantic Roles"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "This work presents a system for identifying the semantic relationships, or semantic roles, filled by constituents of a sentence within a semantic frame, derived from parse trees and hand-annotated training data."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "123937952"
                        ],
                        "name": "Scott Miller",
                        "slug": "Scott-Miller",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Miller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Scott Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20866393"
                        ],
                        "name": "Heidi Fox",
                        "slug": "Heidi-Fox",
                        "structuredName": {
                            "firstName": "Heidi",
                            "lastName": "Fox",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Heidi Fox"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744313"
                        ],
                        "name": "L. Ramshaw",
                        "slug": "L.-Ramshaw",
                        "structuredName": {
                            "firstName": "Lance",
                            "lastName": "Ramshaw",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Ramshaw"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732071"
                        ],
                        "name": "R. Weischedel",
                        "slug": "R.-Weischedel",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Weischedel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Weischedel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 48
                            }
                        ],
                        "text": "The systems introduced in (Miller et al., 1996; Miller et al., 2000) also integrate semantic labels into parsing; however, their SAPT\u2019s are used to pro-\nduce a much simpler MR, i.e., a single semantic frame."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 24
                            }
                        ],
                        "text": "The syntactic model in (Miller et al., 2000) is similar to Collins\u2019, but does not use features like subcat frames and distance measures."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 26
                            }
                        ],
                        "text": "The systems introduced in (Miller et al., 1996; Miller et al., 2000) also integrate semantic labels into parsing; however, their SAPT\u2019s are used to pro-"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8945340,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f2124f8995a9cdf4e168baba426472d2d811c0f1",
            "isKey": false,
            "numCitedBy": 225,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Since 1995, a few statistical parsing algorithms have demonstrated a breakthrough in parsing accuracy, as measured against the UPenn TREEBANK as a gold standard. In this paper we report adapting a lexicalized, probabilistic context-free parser to information extraction and evaluate this new technique on MUC-7 template elements and template relations."
            },
            "slug": "A-Novel-Use-of-Statistical-Parsing-to-Extract-from-Miller-Fox",
            "title": {
                "fragments": [],
                "text": "A Novel Use of Statistical Parsing to Extract Information from Text"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A lexicalized, probabilistic context-free parser is adapted to information extraction and this new technique is evaluated on MUC-7 template elements and template relations."
            },
            "venue": {
                "fragments": [],
                "text": "ANLP"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10796472"
                        ],
                        "name": "James H. Martin",
                        "slug": "James-H.-Martin",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Martin",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James H. Martin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60691216,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b54bcfca3fddc26b8889739a247a25e445818149",
            "isKey": false,
            "numCitedBy": 3827,
            "numCiting": 263,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nThis book takes an empirical approach to language processing, based on applying statistical and other machine-learning algorithms to large corpora.Methodology boxes are included in each chapter. Each chapter is built around one or more worked examples to demonstrate the main idea of the chapter. Covers the fundamental algorithms of various fields, whether originally proposed for spoken or written language to demonstrate how the same algorithm can be used for speech recognition and word-sense disambiguation. Emphasis on web and other practical applications. Emphasis on scientific evaluation. Useful as a reference for professionals in any of the areas of speech and language processing."
            },
            "slug": "Speech-and-language-processing-an-introduction-to-Jurafsky-Martin",
            "title": {
                "fragments": [],
                "text": "Speech and language processing - an introduction to natural language processing, computational linguistics, and speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "This book takes an empirical approach to language processing, based on applying statistical and other machine-learning algorithms to large corpora, to demonstrate how the same algorithm can be used for speech recognition and word-sense disambiguation."
            },
            "venue": {
                "fragments": [],
                "text": "Prentice Hall series in artificial intelligence"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36445704"
                        ],
                        "name": "Ana-Maria Popescu",
                        "slug": "Ana-Maria-Popescu",
                        "structuredName": {
                            "firstName": "Ana-Maria",
                            "lastName": "Popescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ana-Maria Popescu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741101"
                        ],
                        "name": "Oren Etzioni",
                        "slug": "Oren-Etzioni",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Etzioni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Etzioni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690271"
                        ],
                        "name": "Henry A. Kautz",
                        "slug": "Henry-A.-Kautz",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Kautz",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Henry A. Kautz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 84
                            }
                        ],
                        "text": "Results on a larger GEOQUERY corpus with 880 queries have been reported for PRECISE(Popescu et al., 2003): 100% precision and 77.5% recall."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 6
                            }
                        ],
                        "text": "Also, PRECISE is not a learning system and can fail to parse a query it considers ambiguous, even though it may not be considered ambiguous by a human and could potentially be resolved by learning regularities in the training data."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 0
                            }
                        ],
                        "text": "PRECISE is designed to work only for the specific task of NL database interfaces."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 85
                            }
                        ],
                        "text": "Results on a larger G EOQUERY corpus with 880 queries have been reported for P RECISE(Popescu et al., 2003): 100% precision and 77."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 0
                            }
                        ],
                        "text": "PRECISE can return multiple distinct SQL queries when it judges a question to be ambiguous and it is considered correct whena y of these SQL queries is correct."
                    },
                    "intents": []
                }
            ],
            "corpusId": 9101619,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b50f78c9534182a09c060580811274928702b38d",
            "isKey": true,
            "numCitedBy": 465,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "The need for Natural Language Interfaces to databases (NLIs) has become increasingly acute as more and more people access information through their web browsers, PDAs, and cell phones. Yet NLIs are only usable if they map natural language questions to SQL queries correctly. As Schneiderman and Norman have argued, people are unwilling to trade reliable and predictable user interfaces for intelligent but unreliable ones. In this paper, we introduce a theoretical framework for reliable NLIs, which is the foundation for the fully implemented Precise NLI. We prove that, for a broad class of semantically tractable natural language questions, Precise is guaranteed to map each question to the corresponding SQL query. We report on experiments testing Precise on several hundred questions drawn from user studies over three benchmark databases. We find that over 80% of the questions are semantically tractable questions, which Precise answers correctly. Precise automatically recognizes the 20% of questions that it cannot handle, and requests a paraphrase. Finally, we show that Precise compares favorably with Mooney's learning NLI and with Microsoft's English Query product"
            },
            "slug": "Towards-a-theory-of-natural-language-interfaces-to-Popescu-Etzioni",
            "title": {
                "fragments": [],
                "text": "Towards a theory of natural language interfaces to databases"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper proves that, for a broad class of semantically tractable natural language questions, Precise is guaranteed to map each question to the corresponding SQL query, and shows that Precise compares favorably with Mooney's learning NLI and with Microsoft's English Query product."
            },
            "venue": {
                "fragments": [],
                "text": "IUI '03"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2023469"
                        ],
                        "name": "D. Bikel",
                        "slug": "D.-Bikel",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Bikel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bikel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 862713,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0606291dae96446e812ea8f09d9fbdc6acc3ec37",
            "isKey": false,
            "numCitedBy": 303,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "This article documents a large set of heretofore unpublished details Collins used in his parser, such that, along with Collins' (1999) thesis, this article contains all information necessary to duplicate Collins' benchmark results. Indeed, these as-yet-unpublished details account for an 11 relative increase in error from an implementation including all details to a clean-room implementation of Collins' model. We also show a cleaner and equally well-performing method for the handling of punctuation and conjunction and reveal certain other probabilistic oddities about Collins' parser. We not only analyze the effect of the unpublished details, but also reanalyze the effect of certain well-known details, revealing that bilexical dependencies are barely used by the model and that head choice is not nearly as important to overall parsing performance as once thought. Finally, we perform experiments that show that the true discriminative power of lexicalization appears to lie in the fact that unlexicalized syntactic structures are generated conditioning on the headword and its part of speech."
            },
            "slug": "Intricacies-of-Collins'-Parsing-Model-Bikel",
            "title": {
                "fragments": [],
                "text": "Intricacies of Collins' Parsing Model"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A large set of heretofore unpublished details Collins used in his parser are documents, such that, along with Collins' (1999) thesis, this article contains all information necessary to duplicate Collins' benchmark results."
            },
            "venue": {
                "fragments": [],
                "text": "Computational Linguistics"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143897219"
                        ],
                        "name": "I. Lev",
                        "slug": "I.-Lev",
                        "structuredName": {
                            "firstName": "Iddo",
                            "lastName": "Lev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Lev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3257930"
                        ],
                        "name": "Bill MacCartney",
                        "slug": "Bill-MacCartney",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "MacCartney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bill MacCartney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143643017"
                        ],
                        "name": "R. Levy",
                        "slug": "R.-Levy",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Levy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Levy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6238509,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "99feb14a76ea4750818d5af0aa9082dfda47a587",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents intial work on a system that bridges from robust, broad-coverage natural language processing to precise semantics and automated reasoning, focusing on solving logic puzzles drawn from sources such as the Law School Admission Test (LSAT) and the analytic section of the Graduate Record Exam (GRE). We highlight key challenges, and discuss the representations and performance of the prototype system."
            },
            "slug": "Solving-logic-puzzles:-From-robust-processing-to-Lev-MacCartney",
            "title": {
                "fragments": [],
                "text": "Solving logic puzzles: From robust processing to precise semantics"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "This paper presents intial work on a system that bridges from robust, broad-coverage natural language processing to precise semantics and automated reasoning, focusing on solving logic puzzles drawn from sources such as the Law School Admission Test and the analytic section of the Graduate Record Exam."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2nd Workshop on Text Meaning and Interpretation - TextMean '04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710543"
                        ],
                        "name": "V. Zue",
                        "slug": "V.-Zue",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Zue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Zue"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 118
                            }
                        ],
                        "text": "The queries in this corpus are more complex than those in the ATIS database-query corpus used in the speech community (Zue and Glass, 2000) which makes the G EOQUERYproblem harder, as also shown by the results in (Popescu et al."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 7344503,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "157f5fc669dfc440492fa01cb7fe46593ed55304",
            "isKey": false,
            "numCitedBy": 310,
            "numCiting": 137,
            "paperAbstract": {
                "fragments": [],
                "text": "The past decade has witnessed the emergence of a new breed of human-computer interfaces that combines several human language technologies to enable humans to converse with computers using spoken dialogue for information access, creation and processing. In this paper, we introduce the nature of these conversational interfaces and describe the underlying human language technologies on which they are based. After summarizing some of the recent progress in this area around the world, we discuss development issues faced by researchers creating these kinds of systems and present some of the ongoing and unmet research challenges in this field."
            },
            "slug": "Conversational-interfaces:-advances-and-challenges-Zue",
            "title": {
                "fragments": [],
                "text": "Conversational interfaces: advances and challenges"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The nature of these conversational interfaces is introduced and the underlying human language technologies on which they are based are described, and development issues faced by researchers creating these kinds of systems are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 68
                            }
                        ],
                        "text": "Only one word is labeled with the concept; the syntactic head word (Collins, 1997) is preferred."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 7
                            }
                        ],
                        "text": "As in (Collins, 1997), the parameterPl(Li(lti; lwi)jP;H;w; t; ; LC) is further smoothed as follows:Pl1(LijP;H;w; t; ; LC) Pl2(ltijP;H;w; t; ; LC;Li) Pl3(lwijP;H;w; t; ; LC;Li(lti)) Note this smoothing is different from the syntactic counterpart."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 80
                            }
                        ],
                        "text": "The syntactic parameters are the same as in Section 5.1 and are smoothed as in (Collins, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 81
                            }
                        ],
                        "text": "Otherwise they are generated along with the words using the same approach as in (Collins, 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 53
                            }
                        ],
                        "text": "In the following section, we follow the notation in (Collins, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 40
                            }
                        ],
                        "text": "We augment Collins\u2019 head-driven model 2 (Collins, 1997) to incorporate a semantic label on each internal node."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 87
                            }
                        ],
                        "text": "The probabilities from these back-off levels are interpolated using the techniques in (Collins, 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 6
                            }
                        ],
                        "text": "As in (Collins, 1997), the parameterPl(Li(lti; lwi)jP;H;w; t; ; LC) is further smoothed as follows: Pl1(LijP;H;w; t; ; LC) Pl2(ltijP;H;w; t; ; LC;Li) Pl3(lwijP;H;w; t; ; LC;Li(lti))"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 53
                            }
                        ],
                        "text": "Note this threshold is smaller than the one used in (Collins, 1997) since the corpora used in our experiments are smaller."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Three generative, lexicalised mo"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 189
                            }
                        ],
                        "text": "This domain was originally chosen to test corpus-based semantic parsing due to the availability of a hand-built natural-language interface, GEOBASE, supplied with Turbo Prolog 2.0 (Borland International, 1988)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 127
                            }
                        ],
                        "text": "First, a statistical parser is used to construct a SAPT that captures the semantic interpretation of individual words and the basic predicate-argument structure of the sentence."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Turbo Prolog 2.0 Reference Guide"
            },
            "venue": {
                "fragments": [],
                "text": "Borland International"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 189
                            }
                        ],
                        "text": "This domain was originally chosen to test corpus-based semantic parsing due to the availability of a hand-built natural-language interface, GEOBASE, supplied with Turbo Prolog 2.0 (Borland International, 1988)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Turbo Prolog 2.0 Reference Guide. Borland International"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Users manual: RoboCup soccer server manual for soccer server version 7.07 and later"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Users manual: RoboCup soccer server manual for soccer server version 7.07 and later. Available at http://sourceforge.net/ projects/sserver"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Users manual: RoboCup soccer server manual for soccer server version 7.07 and later. Available athttp://sourceforge.net/ projects/sserver"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 112
                            }
                        ],
                        "text": "Most recent work in learning for semantic parsing has focused on \u201cshallow\u201d analysis such assemantic role labeling(Gildea and Jurafsky, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automated labelin"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 54
                            }
                        ],
                        "text": "Sentences were parsed by Collins\u2019 head-driven model 2 (Bikel, 2004) (trained on sections 02-21 of the WSJ Penn Treebank) to generate an initial syntactic parse tree."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Intricacies of Collins\u2019 parsing mode"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We evaluate the system in two domains, a natural-language database interface and an interpreter for coaching instructions in robotic soccer."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 55
                            }
                        ],
                        "text": "In the Coach Competition, teams of agents compete on a simulated soccer field and receive advice from a team coach in a formal language called CLANG."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Users manual: RoboCup soccer server manual for soccer server version 7.07 and later. Available at http: //sourceforge"
            },
            "venue": {
                "fragments": [],
                "text": "Users manual: RoboCup soccer server manual for soccer server version 7.07 and later. Available at http: //sourceforge"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Users manual : RoboCup soccer server manual for soccer server version 7 . 07 and later"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 246,
                                "start": 227
                            }
                        ],
                        "text": "The second MRL is a coaching language for robotic soccer developed for the RoboCup Coach Competition, in which AI researchers compete to provide effective instructions to a coachable team of agents in a simulated soccer domain (Chen et al., 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 16
                            }
                        ],
                        "text": "As described in (Chen et al., 2003), its grammar consists of 37 non-terminal symbols and 133 productions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Users manual: RoboCup soccer server manual for soccer"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 9,
            "methodology": 12,
            "result": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 27,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/A-Statistical-Semantic-Parser-that-Integrates-and-Ge-Mooney/7ae207cfaf01dc2b6799da67f454190b34994870?sort=total-citations"
}