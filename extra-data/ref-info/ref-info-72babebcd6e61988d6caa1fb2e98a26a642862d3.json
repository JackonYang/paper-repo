{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1757263"
                        ],
                        "name": "Elvis Koci",
                        "slug": "Elvis-Koci",
                        "structuredName": {
                            "firstName": "Elvis",
                            "lastName": "Koci",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Elvis Koci"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2405035"
                        ],
                        "name": "Maik Thiele",
                        "slug": "Maik-Thiele",
                        "structuredName": {
                            "firstName": "Maik",
                            "lastName": "Thiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Maik Thiele"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144149891"
                        ],
                        "name": "Oscar Romero",
                        "slug": "Oscar-Romero",
                        "structuredName": {
                            "firstName": "Oscar",
                            "lastName": "Romero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oscar Romero"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7337091"
                        ],
                        "name": "Wolfgang Lehner",
                        "slug": "Wolfgang-Lehner",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Lehner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wolfgang Lehner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 111
                            }
                        ],
                        "text": "Recent publications propose approaches involving to some extent machine learning techniques, such as [2], [3], [4], [5], and [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 27
                            }
                        ],
                        "text": "This term was also used at [4], but with a different definition than the one provided below1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 24
                            }
                        ],
                        "text": "In a similar fashion to [4], we then use the inferred roles to create the so-called layout regions (see Figure 1c)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 26604773,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2913fe53f12ad7874215ac67a4e6a5f74ef9a446",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Spreadsheets are one of the most successful content generation tools, used in almost every enterprise to perform data transformation, visualization, and analysis. The high degree of freedom provided by these tools results in very complex sheets, intermingling the actual data with formatting, formulas, layout artifacts, and textual metadata. To unlock the wealth of data contained in spreadsheets, a human analyst will often have to understand and transform the data manually. To overcome this cumbersome process, we propose a framework that is able to automatically infer the structure and extract the data from these documents in a canonical form. In this paper, we describe our heuristics-based method for discovering tables in spreadsheets, given that each cell is classified as either header, attribute, metadata, data, or derived. Experimental results on a real-world dataset of 439 worksheets (858 tables) show that our approach is feasible and effectively identifies tables within partially structured spreadsheets."
            },
            "slug": "Table-Identification-and-Reconstruction-in-Koci-Thiele",
            "title": {
                "fragments": [],
                "text": "Table Identification and Reconstruction in Spreadsheets"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper describes a heuristics-based method for discovering tables in spreadsheets, given that each cell is classified as either header, attribute, metadata, data, or derived, and shows that this approach is feasible and effectively identifies tables within partially structured spreadsheets."
            },
            "venue": {
                "fragments": [],
                "text": "CAiSE"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1757263"
                        ],
                        "name": "Elvis Koci",
                        "slug": "Elvis-Koci",
                        "structuredName": {
                            "firstName": "Elvis",
                            "lastName": "Koci",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Elvis Koci"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2405035"
                        ],
                        "name": "Maik Thiele",
                        "slug": "Maik-Thiele",
                        "structuredName": {
                            "firstName": "Maik",
                            "lastName": "Thiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Maik Thiele"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144149891"
                        ],
                        "name": "Oscar Romero",
                        "slug": "Oscar-Romero",
                        "structuredName": {
                            "firstName": "Oscar",
                            "lastName": "Romero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oscar Romero"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7337091"
                        ],
                        "name": "Wolfgang Lehner",
                        "slug": "Wolfgang-Lehner",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Lehner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wolfgang Lehner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 106
                            }
                        ],
                        "text": "Recent publications propose approaches involving to some extent machine learning techniques, such as [2], [3], [4], [5], and [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 174
                            }
                        ],
                        "text": "For our proposed approach, we use a Random Forest classifier to infer the layout role of individual cells in spreadsheets (see Figure 1b), based on previous work outlined at [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 15
                            }
                        ],
                        "text": "As outlined at [3], the latter is defined as a classification task."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 34088710,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "686426d2d639156d6f4757e9be630f9c0b6b2fab",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Spreadsheet applications are one of the most used tools for content generation and presentation in industry and the Web. In spite of this success, there does not exist a comprehensive approach to automatically extract and reuse the richness of data maintained in this format. The biggest obstacle is the lack of awareness about the structure of the data in spreadsheets, which otherwise could provide the means to automatically understand and extract knowledge from these files. In this paper, we propose a classification approach to discover the layout of tables in spreadsheets. Therefore, we focus on the cell level, considering a wide range of features not covered before by related work. We evaluated the performance of our classifiers on a large dataset covering three different corpora from various domains. Finally, our work includes a novel technique for detecting and repairing incorrectly classified cells in a post-processing step. The experimental results show that our approach delivers very high accuracy bringing us a crucial step closer towards automatic table extraction."
            },
            "slug": "A-Machine-Learning-Approach-for-Layout-Inference-in-Koci-Thiele",
            "title": {
                "fragments": [],
                "text": "A Machine Learning Approach for Layout Inference in Spreadsheets"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work proposes a classification approach to discover the layout of tables in spreadsheets by focusing on the cell level, considering a wide range of features not covered before by related work, and delivers very high accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "KDIR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117036982"
                        ],
                        "name": "Zhe Chen",
                        "slug": "Zhe-Chen",
                        "structuredName": {
                            "firstName": "Zhe",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhe Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725561"
                        ],
                        "name": "Michael J. Cafarella",
                        "slug": "Michael-J.-Cafarella",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Cafarella",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Cafarella"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 116
                            }
                        ],
                        "text": "Recent publications propose approaches involving to some extent machine learning techniques, such as [2], [3], [4], [5], and [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2215843,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "96693c88cdcf0b721e4eff7f4f426bc90f90d601",
            "isKey": false,
            "numCitedBy": 98,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Spreadsheets contain a huge amount of high-value data but do not observe a standard data model and thus are difficult to integrate. A large number of data integration tools exist, but they generally can only work on relational data. Existing systems for extracting relational data from spreadsheets are too labor intensive to support ad-hoc integration tasks, in which the correct extraction target is only learned during the course of user interaction.\n This paper introduces a system that automatically extracts relational data from spreadsheets, thereby enabling relational spreadsheet integration. The resulting integrated relational data can be queried directly or can be translated into RDF triples. When compared to standard techniques for spreadsheet data extraction on a set of 100 random Web spreadsheets, the system reduces the amount of human labor by 72% to 92%. In addition to the system design, we present the results of a general survey of more than 400,000 spreadsheets we downloaded from the Web, giving a novel view of how users organize their data in spreadsheets."
            },
            "slug": "Automatic-web-spreadsheet-data-extraction-Chen-Cafarella",
            "title": {
                "fragments": [],
                "text": "Automatic web spreadsheet data extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A system that automatically extracts relational data from spreadsheets, thereby enabling relational spreadsheet integration and a novel view of how users organize their data in spreadsheets is presented."
            },
            "venue": {
                "fragments": [],
                "text": "SS@ '13"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688711"
                        ],
                        "name": "F. Hermans",
                        "slug": "F.-Hermans",
                        "structuredName": {
                            "firstName": "Felienne",
                            "lastName": "Hermans",
                            "middleNames": [
                                "F.",
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hermans"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775709"
                        ],
                        "name": "M. Pinzger",
                        "slug": "M.-Pinzger",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Pinzger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pinzger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737202"
                        ],
                        "name": "A. Deursen",
                        "slug": "A.-Deursen",
                        "structuredName": {
                            "firstName": "Arie",
                            "lastName": "Deursen",
                            "middleNames": [
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Deursen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 73
                            }
                        ],
                        "text": "Other works make use of domain specific languages, such as [1], [8], and [9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9424441,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d56f469ed5ddf8e56cadb11665414df3b1a130b3",
            "isKey": false,
            "numCitedBy": 92,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "The use of spreadsheets to capture information is widespread in industry. Spreadsheets can thus be a wealthy source of domain information. We propose to automatically extract this information and transform it into class diagrams. The resulting class diagram can be used by software engineers to understand, refine, or re-implement the spreadsheet's functionality. To enable the transformation into class diagrams we create a library of common spreadsheet usage patterns. These patterns are localized in the spreadsheet using a two- dimensional parsing algorithm. The resulting parse tree is transformed and enriched with information from the library. We evaluate our approach on the spreadsheets from the Euses Spreadsheet Corpus by comparing a subset of the generated class diagrams with reference class diagrams created manually."
            },
            "slug": "Automatically-Extracting-Class-Diagrams-from-Hermans-Pinzger",
            "title": {
                "fragments": [],
                "text": "Automatically Extracting Class Diagrams from Spreadsheets"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "This work creates a library of common spreadsheet usage patterns that are localized in the spreadsheet using a two- dimensional parsing algorithm and transformed and enriched with information from the library to automatically extract information and transform it into class diagrams."
            },
            "venue": {
                "fragments": [],
                "text": "ECOOP"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31819608"
                        ],
                        "name": "M. Bendre",
                        "slug": "M.-Bendre",
                        "structuredName": {
                            "firstName": "Mangesh",
                            "lastName": "Bendre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bendre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "17496859"
                        ],
                        "name": "Bofan Sun",
                        "slug": "Bofan-Sun",
                        "structuredName": {
                            "firstName": "Bofan",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bofan Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2141083548"
                        ],
                        "name": "Ding Zhang",
                        "slug": "Ding-Zhang",
                        "structuredName": {
                            "firstName": "Ding",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ding Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2148929637"
                        ],
                        "name": "Xinyan Zhou",
                        "slug": "Xinyan-Zhou",
                        "structuredName": {
                            "firstName": "Xinyan",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xinyan Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143922493"
                        ],
                        "name": "K. Chang",
                        "slug": "K.-Chang",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Chang",
                            "middleNames": [
                                "Chen-Chuan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145592539"
                        ],
                        "name": "Aditya G. Parameswaran",
                        "slug": "Aditya-G.-Parameswaran",
                        "structuredName": {
                            "firstName": "Aditya",
                            "lastName": "Parameswaran",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aditya G. Parameswaran"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 36
                            }
                        ],
                        "text": "Furthermore, it is worth mentioning [10], and [11], which discuss systems having spreadsheets as front-end and a relational databases as back-end."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2837414,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4d11b696bf04f68aaa6c9ce14e7a17c8ec88aa1",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Spreadsheet software is often the tool of choice for ad-hoc tabular data management, processing, and visualization, especially on tiny data sets. On the other hand, relational database systems offer significant power, expressivity, and efficiency over spreadsheet software for data management, while lacking in the ease of use and ad-hoc analysis capabilities. We demonstrate DataSpread, a data exploration tool that holistically unifies databases and spreadsheets. It continues to offer a Microsoft Excel-based spreadsheet front-end, while in parallel managing all the data in a back-end database, specifically, PostgreSQL. DataSpread retains all the advantages of spreadsheets, including ease of use, ad-hoc analysis and visualization capabilities, and a schema-free nature, while also adding the advantages of traditional relational databases, such as scalability and the ability to use arbitrary SQL to import, filter, or join external or internal tables and have the results appear in the spreadsheet. DataSpread needs to reason about and reconcile differences in the notions of schema, addressing of cells and tuples, and the current \u201cpane\u201d (which exists in spreadsheets but not in traditional databases), and support data modifications at both the front-end and the back-end. Our demonstration will center on our first and early prototype of the DataSpread, and will give the attendees a sense for the enormous data exploration capabilities offered by unifying spreadsheets and databases."
            },
            "slug": "DataSpread:-Unifying-Databases-and-Spreadsheets-Bendre-Sun",
            "title": {
                "fragments": [],
                "text": "DataSpread: Unifying Databases and Spreadsheets"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The demonstration will center on the first and early prototype of the DataSpread, a data exploration tool that holistically unifies databases and spreadsheets, and will give the attendees a sense for the enormous data exploration capabilities offered by unifying spreadsheets and databases."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. VLDB Endow."
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3355714"
                        ],
                        "name": "A. Shigarov",
                        "slug": "A.-Shigarov",
                        "structuredName": {
                            "firstName": "Alexey",
                            "lastName": "Shigarov",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shigarov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144116982"
                        ],
                        "name": "A. Mikhailov",
                        "slug": "A.-Mikhailov",
                        "structuredName": {
                            "firstName": "Andrey",
                            "lastName": "Mikhailov",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Mikhailov"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 64
                            }
                        ],
                        "text": "Other works make use of domain specific languages, such as [1], [8], and [9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 205488728,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "19cefa45c8975634b9cf6fa82b745dcc79b4b9ae",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Rule-based-spreadsheet-data-transformation-from-to-Shigarov-Mikhailov",
            "title": {
                "fragments": [],
                "text": "Rule-based spreadsheet data transformation from arbitrary to relational tables"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Syst."
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117036982"
                        ],
                        "name": "Zhe Chen",
                        "slug": "Zhe-Chen",
                        "structuredName": {
                            "firstName": "Zhe",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhe Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "28000187"
                        ],
                        "name": "Sasha Dadiomov",
                        "slug": "Sasha-Dadiomov",
                        "structuredName": {
                            "firstName": "Sasha",
                            "lastName": "Dadiomov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sasha Dadiomov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36620783"
                        ],
                        "name": "R. Wesley",
                        "slug": "R.-Wesley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Wesley",
                            "middleNames": [
                                "Michael",
                                "Grantham"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Wesley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055961603"
                        ],
                        "name": "Gang Xiao",
                        "slug": "Gang-Xiao",
                        "structuredName": {
                            "firstName": "Gang",
                            "lastName": "Xiao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gang Xiao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1505215173"
                        ],
                        "name": "D. Cory",
                        "slug": "D.-Cory",
                        "structuredName": {
                            "firstName": "D",
                            "lastName": "Cory",
                            "middleNames": [
                                "Jensen"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cory"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725561"
                        ],
                        "name": "Michael J. Cafarella",
                        "slug": "Michael-J.-Cafarella",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Cafarella",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Cafarella"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777393"
                        ],
                        "name": "J. Mackinlay",
                        "slug": "J.-Mackinlay",
                        "structuredName": {
                            "firstName": "Jock",
                            "lastName": "Mackinlay",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mackinlay"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 81
                            }
                        ],
                        "text": "While there is some support to perform spreadsheet data extraction, like [1] and [2], it can not be considered a general purpose solution for arbitrary inputs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 101
                            }
                        ],
                        "text": "Recent publications propose approaches involving to some extent machine learning techniques, such as [2], [3], [4], [5], and [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8710783,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b397c8d741796b8a9159e9f118f37c0ea50f0d4a",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Spreadsheets are a critical and widely-used data management tool. Converting spreadsheet data into relational tables would bring benefits to a number of fields, including public policy, public health, and economics. Research to date has focused on designing domain-specific languages to describe transformation processes or automatically converting a specific type of spreadsheets. To handle a larger variety of spreadsheets, we have to identify various spreadsheet properties, which correspond to a series of transformation programs that contribute towards a general framework that converts spreadsheets to relational tables. In this paper, we focus on the problem of spreadsheet property detection. We propose a hybrid approach of building a variety of spreadsheet property detectors to reduce the amount of required human labeling effort. Our approach integrates an active learning framework with crude, easy-to-write, user-provided rules to save human labeling effort by generating additional high-quality labeled data especially in the initial training stage. Using a bagging-like technique, Our approach can also tolerate lower-quality user-provided rules. Our experiments show that when compared to a standard active learning approach, we reduced the training data needed to reach the performance plateau by 34-44% when a human provides relatively high-quality rules, and by a comparable amount with low-quality rules. A study on a large-scale web-crawled spreadsheet dataset demonstrates that it is crucial to detect a variety of spreadsheet properties in order to transform a large portion of the spreadsheets into a relational form."
            },
            "slug": "Spreadsheet-Property-Detection-With-Rule-assisted-Chen-Dadiomov",
            "title": {
                "fragments": [],
                "text": "Spreadsheet Property Detection With Rule-assisted Active Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper proposes a hybrid approach of building a variety of spreadsheet property detectors to reduce the amount of required human labeling effort and integrates an active learning framework with crude, easy-to-write, user-provided rules to save human labeled effort."
            },
            "venue": {
                "fragments": [],
                "text": "CIKM"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 31
                            }
                        ],
                        "text": "The following surveys [15] and [16] provide a comprehensive summary of such works."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 30699745,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5cd207fa19e51db1d6eadb0e5e70f1c5b8d1ecd0",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Tables are the only acceptable means of communicating certain types of structured data. A precise definition of \"tabularity\" remains elusive because some bureaucratic forms, multicolumn text layouts, and schematic drawings share many characteristics of tables. There are significant differences between typeset tables, electronic files designed for display of tables, and tables in symbolic form intended for information retrieval. Although most research to date has addressed the extraction of low-level geometric information from scanned raster images of paper tables, the recent trend toward the analysis of tables in electronic form may pave the way to a higherl evel of table understanding. \n \nRecent research on table composition and table analysis has improved ourunde rstanding of the distinction between the logical and physical structures of tables, and has led to improved formalisms for modeling tables. The present study indicates that progress on half-a-dozen specific research issues would open the door to using existing paper and electronic tables for database update, tabular browsing, structured information retrieval through graphical and audio interfaces, multimedia table editing, and platform-independent display. \n \nAlthough tables are not a conventional format for conveying the primary content of technical papers, here we attempt to subdue our natural garrulity by adopting this genre to communicate what we have to say about tables entirely in tabular form."
            },
            "slug": "A-Tabular-Survey-of-Automated-Table-Processing-Lopresti-Nagy",
            "title": {
                "fragments": [],
                "text": "A Tabular Survey of Automated Table Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The present study indicates that progress on half-a-dozen specific research issues would open the door to using existing paper and electronic tables for database update, tabular browsing, structured information retrieval through graphical and audio interfaces, multimedia table editing, and platform-independent display."
            },
            "venue": {
                "fragments": [],
                "text": "GREC"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689398"
                        ],
                        "name": "J\u00e1come Cunha",
                        "slug": "J\u00e1come-Cunha",
                        "structuredName": {
                            "firstName": "J\u00e1come",
                            "lastName": "Cunha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J\u00e1come Cunha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144562120"
                        ],
                        "name": "J. Saraiva",
                        "slug": "J.-Saraiva",
                        "structuredName": {
                            "firstName": "Jo\u00e3o",
                            "lastName": "Saraiva",
                            "middleNames": [
                                "de",
                                "Sousa"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Saraiva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145039625"
                        ],
                        "name": "Joost Visser",
                        "slug": "Joost-Visser",
                        "structuredName": {
                            "firstName": "Joost",
                            "lastName": "Visser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joost Visser"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 46
                            }
                        ],
                        "text": "Furthermore, it is worth mentioning [10], and [11], which discuss systems having spreadsheets as front-end and a relational databases as back-end."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6395655,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8fae8067960c25da07fbd986ab0d6024103f6b3d",
            "isKey": false,
            "numCitedBy": 84,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents techniques and tools to transform spreadsheets into relational databases and back. A set of data refinement rules is introduced to map a tabular datatype into a relational database schema. Having expressed the transformation of the two data models as data refinements, we obtain for free the functions that migrate the data. We use well-known relational database techniques to optimize and query the data. Because data refinements define bi-directional transformations we can map such database back to an optimized spreadsheet. We have implemented the data refinement rules and we constructed Haskell-based tools to manipulate, optimize and refactor Excel-like spreadsheets."
            },
            "slug": "From-spreadsheets-to-relational-databases-and-back-Cunha-Saraiva",
            "title": {
                "fragments": [],
                "text": "From spreadsheets to relational databases and back"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "This paper presents techniques and tools to transform spreadsheets into relational databases and back, and implemented the data refinement rules and constructed Haskell-based tools to manipulate, optimize and refactor Excel-like spreadsheets."
            },
            "venue": {
                "fragments": [],
                "text": "PEPM '09"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1816014"
                        ],
                        "name": "M. Adelfio",
                        "slug": "M.-Adelfio",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Adelfio",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Adelfio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719385"
                        ],
                        "name": "H. Samet",
                        "slug": "H.-Samet",
                        "structuredName": {
                            "firstName": "Hanan",
                            "lastName": "Samet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Samet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 125
                            }
                        ],
                        "text": "Recent publications propose approaches involving to some extent machine learning techniques, such as [2], [3], [4], [5], and [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3241857,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cbf752d3fe7e3a1cac5c9f62b88ba9a6aa07ba54",
            "isKey": false,
            "numCitedBy": 94,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Tabular data is an abundant source of information on the Web, but remains mostly isolated from the latter's interconnections since tables lack links and computer-accessible descriptions of their structure. In other words, the schemas of these tables -- attribute names, values, data types, etc. -- are not explicitly stored as table metadata. Consequently, the structure that these tables contain is not accessible to the crawlers that power search engines and thus not accessible to user search queries. We address this lack of structure with a new method for leveraging the principles of table construction in order to extract table schemas. Discovering the schema by which a table is constructed is achieved by harnessing the similarities and differences of nearby table rows through the use of a novel set of features and a feature processing scheme. The schemas of these data tables are determined using a classification technique based on conditional random fields in combination with a novel feature encoding method called logarithmic binning, which is specifically designed for the data table extraction task. Our method provides considerable improvement over the well-known WebTables schema extraction method. In contrast with previous work that focuses on extracting individual relations, our method excels at correctly interpreting full tables, thereby being capable of handling general tables such as those found in spreadsheets, instead of being restricted to HTML tables as is the case with the WebTables method. We also extract additional schema characteristics, such as row groupings, which are important for supporting information retrieval tasks on tabular data."
            },
            "slug": "Schema-Extraction-for-Tabular-Data-on-the-Web-Adelfio-Samet",
            "title": {
                "fragments": [],
                "text": "Schema Extraction for Tabular Data on the Web"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This method provides considerable improvement over the well-known WebTables schema extraction method and excels at correctly interpreting full tables, thereby being capable of handling general tables such as those found in spreadsheets, instead of being restricted to HTML tables as is the case with the WebT tables method."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. VLDB Endow."
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688711"
                        ],
                        "name": "F. Hermans",
                        "slug": "F.-Hermans",
                        "structuredName": {
                            "firstName": "Felienne",
                            "lastName": "Hermans",
                            "middleNames": [
                                "F.",
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hermans"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398156124"
                        ],
                        "name": "E. Murphy-Hill",
                        "slug": "E.-Murphy-Hill",
                        "structuredName": {
                            "firstName": "Emerson",
                            "lastName": "Murphy-Hill",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Murphy-Hill"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 89
                            }
                        ],
                        "text": "We drew a representative sample of 208 worksheets2, from three corpora; FUSE [20], ENRON [21], and EUSES [22] respectively contribute 128, 56, and 28 worksheets."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1389852,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7165f695943c203be31ab69a3d75a8b9b813c5c5",
            "isKey": false,
            "numCitedBy": 87,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Spreadsheets are used extensively in business processes around the world and as such, are a topic of research interest. Over the past few years, many spreadsheet studies have been performed on the EUSES spreadsheet corpus. While this corpus has served the spreadsheet community well, the spreadsheets it contains are mainly gathered with search engines and might therefore not represent spreadsheets used in companies. This paper presents an analysis of a new dataset, extracted from the Enron email archive, containing over 15,000 spreadsheets used within the Enron Corporation. In addition to the spreadsheets, we also present an analysis of the associated emails, where we look into spreadsheet-specific email behavior. Our analysis shows that 1) 24% of Enron spreadsheets with at least one formula contain an Excel error, 2) there is little diversity in the functions used in spreadsheets: 76% of spreadsheets in the presented corpus use the same 15 functions and, 3) the spreadsheets are substantially more smelly than the EUSES corpus, especially in terms of long calculation chains. Regarding the emails, we observe that spreadsheets 1) are a frequent topic of email conversation with 10% of emails either referring to or sending spreadsheets and 2) the emails are frequently discussing errors in and updates to spreadsheets."
            },
            "slug": "Enron's-Spreadsheets-and-Related-Emails:-A-Dataset-Hermans-Murphy-Hill",
            "title": {
                "fragments": [],
                "text": "Enron's Spreadsheets and Related Emails: A Dataset and Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An analysis of a new dataset, extracted from the Enron email archive, containing over 15,000 spreadsheets used within the Enrock Corporation, shows that the spreadsheets are substantially more smelly than the EUSES corpus, especially in terms of long calculation chains."
            },
            "venue": {
                "fragments": [],
                "text": "2015 IEEE/ACM 37th IEEE International Conference on Software Engineering"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686613"
                        ],
                        "name": "Titus Barik",
                        "slug": "Titus-Barik",
                        "structuredName": {
                            "firstName": "Titus",
                            "lastName": "Barik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Titus Barik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166534"
                        ],
                        "name": "Kevin Lubick",
                        "slug": "Kevin-Lubick",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Lubick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Lubick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109795311"
                        ],
                        "name": "Justin Smith",
                        "slug": "Justin-Smith",
                        "structuredName": {
                            "firstName": "Justin",
                            "lastName": "Smith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Justin Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2002661"
                        ],
                        "name": "John Slankas",
                        "slug": "John-Slankas",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Slankas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John Slankas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398156124"
                        ],
                        "name": "E. Murphy-Hill",
                        "slug": "E.-Murphy-Hill",
                        "structuredName": {
                            "firstName": "Emerson",
                            "lastName": "Murphy-Hill",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Murphy-Hill"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 77
                            }
                        ],
                        "text": "We drew a representative sample of 208 worksheets2, from three corpora; FUSE [20], ENRON [21], and EUSES [22] respectively contribute 128, 56, and 28 worksheets."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 470351,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b60b5b57ef57b0b49a54c4f3471cf04929ad887d",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Spreadsheets are perhaps the most ubiquitous form of end-user programming software. This paper describes a corpus, called Fuse, containing 2,127,284 URLs that return spreadsheets (and their HTTP server responses), and 249,376 unique spreadsheets, contained within a public web archive of over 26.83 billion pages. Obtained using nearly 60,000 hours of computation, the resulting corpus exhibits several useful properties over prior spreadsheet corpora, including reproducibility and extendability. Our corpus is unencumbered by any license agreements, available to all, and intended for wide usage by end-user software engineering researchers. In this paper, we detail the data and the spreadsheet extraction process, describe the data schema, and discuss the trade-offs of Fuse with other corpora."
            },
            "slug": "Fuse:-A-Reproducible,-Extendable,-Internet-Scale-of-Barik-Lubick",
            "title": {
                "fragments": [],
                "text": "Fuse: A Reproducible, Extendable, Internet-Scale Corpus of Spreadsheets"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A corpus, called Fuse, containing 2,127,284 URLs that return spreadsheets (and their HTTP server responses), and 249,376 unique spreadsheets, contained within a public web archive of over 26.83 billion pages is described."
            },
            "venue": {
                "fragments": [],
                "text": "2015 IEEE/ACM 12th Working Conference on Mining Software Repositories"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2590616"
                        ],
                        "name": "Julian Eberius",
                        "slug": "Julian-Eberius",
                        "structuredName": {
                            "firstName": "Julian",
                            "lastName": "Eberius",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Julian Eberius"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39113490"
                        ],
                        "name": "Christoper Werner",
                        "slug": "Christoper-Werner",
                        "structuredName": {
                            "firstName": "Christoper",
                            "lastName": "Werner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christoper Werner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2405035"
                        ],
                        "name": "Maik Thiele",
                        "slug": "Maik-Thiele",
                        "structuredName": {
                            "firstName": "Maik",
                            "lastName": "Thiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Maik Thiele"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3176379"
                        ],
                        "name": "Katrin Braunschweig",
                        "slug": "Katrin-Braunschweig",
                        "structuredName": {
                            "firstName": "Katrin",
                            "lastName": "Braunschweig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Katrin Braunschweig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2715207"
                        ],
                        "name": "Lars Dannecker",
                        "slug": "Lars-Dannecker",
                        "structuredName": {
                            "firstName": "Lars",
                            "lastName": "Dannecker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lars Dannecker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7337091"
                        ],
                        "name": "Wolfgang Lehner",
                        "slug": "Wolfgang-Lehner",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Lehner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wolfgang Lehner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 42
                            }
                        ],
                        "text": "Also, we find rule-based approaches, like [7]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 16073308,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4e447253d8c04facc9756fed8b1b0e29408b3d4",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Of the structured data published on the web, for instance as datasets on Open Data Platforms such as data.gov, but also in the form of HTML tables on the general web, only a small part is in a relational form. Instead the data is intermingled with formatting, layout and textual metadata, i.e., it is contained in partially structured documents. This makes transformation into a true relational form necessary, which is a precondition for most forms of data analysis and data integration. Studying data.gov as an example source for partially structured documents, we present a classification of typical normalization problems. We then present the DeExcelerator, which is a framework for extracting relations from partially structured documents such as spreadsheets and HTML tables."
            },
            "slug": "DeExcelerator:-a-framework-for-extracting-data-from-Eberius-Werner",
            "title": {
                "fragments": [],
                "text": "DeExcelerator: a framework for extracting relational data from partially structured documents"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The DeExcelerator is presented, which is a framework for extracting relations from partially structured documents such as spreadsheets and HTML tables, and a classification of typical normalization problems."
            },
            "venue": {
                "fragments": [],
                "text": "CIKM"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50589755"
                        ],
                        "name": "M. Fisher",
                        "slug": "M.-Fisher",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Fisher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fisher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722304"
                        ],
                        "name": "G. Rothermel",
                        "slug": "G.-Rothermel",
                        "structuredName": {
                            "firstName": "Gregg",
                            "lastName": "Rothermel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Rothermel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 105
                            }
                        ],
                        "text": "We drew a representative sample of 208 worksheets2, from three corpora; FUSE [20], ENRON [21], and EUSES [22] respectively contribute 128, 56, and 28 worksheets."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 21365062,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a766fb24a7d5f647b05a6077428d372292e6f25d",
            "isKey": false,
            "numCitedBy": 124,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "In recent years several tools and methodologies have been developed to improve the dependability of spreadsheets. However, there has been little evaluation of these dependability devices on spreadsheets in actual use by end users. To assist in the process of evaluating these methodologies, we have assembled a corpus of spreadsheets from a variety of sources. We have ensured that these spreadsheets are suitable for evaluating dependability devices in Microsoft Excel (the most commonly used commercial spreadsheet environment) and have measured a variety of feature of these spreadsheets to aid researchers in selecting subsets of the corpus appropriate to their needs."
            },
            "slug": "The-EUSES-spreadsheet-corpus:-a-shared-resource-for-Fisher-Rothermel",
            "title": {
                "fragments": [],
                "text": "The EUSES spreadsheet corpus: a shared resource for supporting experimentation with spreadsheet dependability mechanisms"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A corpus of spreadsheets is assembled that is suitable for evaluating dependability devices in Microsoft Excel and a variety of feature of these spreadsheets are measured to aid researchers in selecting subsets of the corpus appropriate to their needs."
            },
            "venue": {
                "fragments": [],
                "text": "WEUSE@ICSE"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35873150"
                        ],
                        "name": "Sean Kandel",
                        "slug": "Sean-Kandel",
                        "structuredName": {
                            "firstName": "Sean",
                            "lastName": "Kandel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sean Kandel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750481"
                        ],
                        "name": "A. Paepcke",
                        "slug": "A.-Paepcke",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Paepcke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Paepcke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695576"
                        ],
                        "name": "J. Hellerstein",
                        "slug": "J.-Hellerstein",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Hellerstein",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hellerstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803140"
                        ],
                        "name": "Jeffrey Heer",
                        "slug": "Jeffrey-Heer",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Heer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeffrey Heer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 73
                            }
                        ],
                        "text": "While there is some support to perform spreadsheet data extraction, like [1] and [2], it can not be considered a general purpose solution for arbitrary inputs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 59
                            }
                        ],
                        "text": "Other works make use of domain specific languages, such as [1], [8], and [9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11133756,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4c67851b77766ba4ad9f1ac0bd4c9491c327574e",
            "isKey": false,
            "numCitedBy": 557,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Though data analysis tools continue to improve, analysts still expend an inordinate amount of time and effort manipulating data and assessing data quality issues. Such \"data wrangling\" regularly involves reformatting data values or layout, correcting erroneous or missing values, and integrating multiple data sources. These transforms are often difficult to specify and difficult to reuse across analysis tasks, teams, and tools. In response, we introduce Wrangler, an interactive system for creating data transformations. Wrangler combines direct manipulation of visualized data with automatic inference of relevant transforms, enabling analysts to iteratively explore the space of applicable operations and preview their effects. Wrangler leverages semantic data types (e.g., geographic locations, dates, classification codes) to aid validation and type conversion. Interactive histories support review, refinement, and annotation of transformation scripts. User study results show that Wrangler significantly reduces specification time and promotes the use of robust, auditable transforms instead of manual editing."
            },
            "slug": "Wrangler:-interactive-visual-specification-of-data-Kandel-Paepcke",
            "title": {
                "fragments": [],
                "text": "Wrangler: interactive visual specification of data transformation scripts"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "Wrangler combines direct manipulation of visualized data with automatic inference of relevant transforms, enabling analysts to iteratively explore the space of applicable operations and preview their effects."
            },
            "venue": {
                "fragments": [],
                "text": "CHI"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695936"
                        ],
                        "name": "M. Rahgozar",
                        "slug": "M.-Rahgozar",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Rahgozar",
                            "middleNames": [
                                "Armon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Rahgozar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "75168337"
                        ],
                        "name": "R. Cooperman",
                        "slug": "R.-Cooperman",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Cooperman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cooperman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5695794,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cac606274759fa664bce3d98f53d24ccdf23e46b",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a bottom-up method for recognizing tables within a document. This method is based on the paradigm of graph-rewriting. First, the document image is transformed into a layout graph whose nodes and edges represent document entities and their interrelations respectively. This graph is subsequently rewritten using a set of rules designed based on a priori document knowledge and general formatting conventions. The resulting graph provides a logical view of the document content. It can be parsed to provide general format analysis information."
            },
            "slug": "Graph-based-table-recognition-system-Rahgozar-Cooperman",
            "title": {
                "fragments": [],
                "text": "Graph-based table recognition system"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This paper proposes a bottom-up method for recognizing tables within a document based on the paradigm of graph-rewriting whose nodes and edges represent document entities and their interrelations respectively."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108023096"
                        ],
                        "name": "Xinxin Wang",
                        "slug": "Xinxin-Wang",
                        "structuredName": {
                            "firstName": "Xinxin",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xinxin Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 31
                            }
                        ],
                        "text": "With respect to the Wang model [19], Headers correspond to the Boxhead and Stub Head."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16895319,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb8327c5b091ea26e42ed924e25a02c564998f19",
            "isKey": false,
            "numCitedBy": 151,
            "numCiting": 88,
            "paperAbstract": {
                "fragments": [],
                "text": "This dissertation investigates the composition of high-quality tables with the use of electronic tools. A generic model is designed to support the different stages of tabular composition, including the editing of logical structure, the specification of layout structure, and the formatting of concrete tables. The model separates table's logical structure from its layout structure, which consists of tabular topology and typographic style. The notion of an abstract table, which describes the logical relationships among tabular items, is formally defined and a set of logical operations is proposed to manipulate tables based on these logical relationships. An abstract table can be visualized through a layout structure specified by a set of topological rules, which determine the relative placement of tabular items in two dimensions, and a set of style rules, which determine the final appearance of different items. The absolute placement of a concrete table can be automatically generated by applying a layout specification to an abstract line. An NP-complete problem arises in the formatting process that uses automatic line breaking and determines the physical dimension of a table to satisfy user-specified size constraints. An algorithm has been designed to solve the formatting problem in polynomial time for typical tables. Based on the tabular model, a prototype tabular composition system has been implemented in a UNIX, X Windows environment. This prototype provides an interactive interface to edit the logical structure, the topology and the styles of tables. It allows us to manipulate tables based on the logical relationships tabular items, regardless of where the items are placed in the layout structure, and capable of presenting a table in different topologies and styles so that we can select a high-quality layout structure."
            },
            "slug": "Tabular-Abstraction,-Editing,-and-Formatting-Wang",
            "title": {
                "fragments": [],
                "text": "Tabular Abstraction, Editing, and Formatting"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "This dissertation investigates the composition of high-quality tables with the use of electronic tools using a generic model designed to support the different stages of tabular composition, including the editing of logical structure, the specification of layout structure, and the formatting of concrete tables."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055652863"
                        ],
                        "name": "T. Schmitz",
                        "slug": "T.-Schmitz",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Schmitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Schmitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705282"
                        ],
                        "name": "D. Jannach",
                        "slug": "D.-Jannach",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Jannach",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Jannach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3334382"
                        ],
                        "name": "Birgit Hofer",
                        "slug": "Birgit-Hofer",
                        "structuredName": {
                            "firstName": "Birgit",
                            "lastName": "Hofer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Birgit Hofer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50736844"
                        ],
                        "name": "Patrick W. Koch",
                        "slug": "Patrick-W.-Koch",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Koch",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Patrick W. Koch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7286090"
                        ],
                        "name": "Konstantin Schekotihin",
                        "slug": "Konstantin-Schekotihin",
                        "structuredName": {
                            "firstName": "Konstantin",
                            "lastName": "Schekotihin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Konstantin Schekotihin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743138"
                        ],
                        "name": "F. Wotawa",
                        "slug": "F.-Wotawa",
                        "structuredName": {
                            "firstName": "Franz",
                            "lastName": "Wotawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Wotawa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "At [12] worksheet contents are decomposed into fragments to assist better debugging of formula cells."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 43202125,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0f0f224f92f2205c43e9d687c2033f34551cc53f",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Spreadsheets serve as a basis for decision-making processes in many companies and bugs in spreadsheets can therefore represent a considerable risk to businesses. Systematic tests can help to locate such bugs, but providing test cases can be cumbersome and complex for large real-world spreadsheets. To make the specification of test cases easier, we propose to split spreadsheets into smaller logically connected parts (called fragments) which can be individually tested for correctness. We present an algorithmic approach to compute such fragments, which we validated with a laboratory study in the form of a spreadsheet debugging exercise involving 57 subjects. The results show that the fragmentation approach can help to significantly reduce the required efforts to test a spreadsheet.1"
            },
            "slug": "A-decomposition-based-approach-to-spreadsheet-and-Schmitz-Jannach",
            "title": {
                "fragments": [],
                "text": "A decomposition-based approach to spreadsheet testing and debugging"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work proposes to split spreadsheets into smaller logically connected parts (called fragments) which can be individually tested for correctness, and presents an algorithmic approach to compute such fragments."
            },
            "venue": {
                "fragments": [],
                "text": "2017 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2394344"
                        ],
                        "name": "R. Abraham",
                        "slug": "R.-Abraham",
                        "structuredName": {
                            "firstName": "Robin",
                            "lastName": "Abraham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Abraham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796494"
                        ],
                        "name": "Martin Erwig",
                        "slug": "Martin-Erwig",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Erwig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin Erwig"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 6
                            }
                        ],
                        "text": "Also, [14] outlines a rule-based approach to infer unit errors."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9807808,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c9639a24b8420a6313066fa631bb322d1f51d1e3",
            "isKey": false,
            "numCitedBy": 147,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the design and implementation of a unit and header inference system for spreadsheets. The system is based on a formal model of units that we have described in previous work. Since the unit inference depends on information about headers in a spreadsheet, a realistic unit inference system requires a method for automatically determining headers. The present paper describes (1) several spatial-analysis algorithms for header inference, (2) a framework that facilitates the integration of different algorithms, and (3) the implementation of the system. The combined header and unit inference system is fully integrated into Microsoft Excel and can be used to automatically identify various kinds of errors in spreadsheets. Test results show that the system works accurately and reliably"
            },
            "slug": "Header-and-Unit-Inference-for-Spreadsheets-Through-Abraham-Erwig",
            "title": {
                "fragments": [],
                "text": "Header and Unit Inference for Spreadsheets Through Spatial Analyses"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The present paper describes several spatial-analysis algorithms for header inference, a framework that facilitates the integration of different algorithms, and the implementation of the combined header and unit inference system that is fully integrated into Microsoft Excel."
            },
            "venue": {
                "fragments": [],
                "text": "2004 IEEE Symposium on Visual Languages - Human Centric Computing"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50631599"
                        ],
                        "name": "Rishabh Singh",
                        "slug": "Rishabh-Singh",
                        "structuredName": {
                            "firstName": "Rishabh",
                            "lastName": "Singh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rishabh Singh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145269784"
                        ],
                        "name": "B. Livshits",
                        "slug": "B.-Livshits",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Livshits",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Livshits"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145874411"
                        ],
                        "name": "B. Zorn",
                        "slug": "B.-Zorn",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Zorn",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Zorn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "A recent work, [13], detects formula errors using neural networks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16170348,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "07578f12f0e8601d4bc302173b647e2e3530e5d4",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Spreadsheets are widely used for financial and other types of important numerical computations. Spreadsheet errors have accounted for hundreds of millions of dollars of financial losses, but tools for finding errors in spreadsheets are still quite primitive. At the same time, deep learning techniques have led to great advances in complex tasks such as speech and image recognition. In this paper, we show that applying neural networks to spreadsheets allows us to find an important class of error with high precision. The specific errors we detect are cases where an author has placed a number where there should be a formula, such as in the row totaling the numbers in a column. We use a spatial abstraction of the cells around a particular cell to build a classifier that predicts whether a cell should contain a formula whenever it contains a number. Our approach requires no labeled data and allows us to rapidly explore potential new classifiers to improve the effectiveness of the technique. Our classifier has a low false positive rate and finds more than 150 real errors in a collection of 70 benchmark workbooks. We also applied Melford to almost all of the financial spreadsheets in the EUSES corpus and within hours confirmed real errors that were previously unknown to us in 26 of the 696 workbooks. We believe that applying neural networks to helping individuals reason about the structure and content of spreadsheets has great potential."
            },
            "slug": "Melford:-Using-Neural-Networks-to-Find-Spreadsheet-Singh-Livshits",
            "title": {
                "fragments": [],
                "text": "Melford: Using Neural Networks to Find Spreadsheet Errors"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper shows that applying neural networks to spreadsheets allows us to find an important class of error with high precision, and uses a spatial abstraction of the cells around a particular cell to build a classifier that predicts whether a cell should contain a formula whenever it contains a number."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060810463"
                        ],
                        "name": "Akira Amano",
                        "slug": "Akira-Amano",
                        "structuredName": {
                            "firstName": "Akira",
                            "lastName": "Amano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Akira Amano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2406896"
                        ],
                        "name": "Naoki Asada",
                        "slug": "Naoki-Asada",
                        "structuredName": {
                            "firstName": "Naoki",
                            "lastName": "Asada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naoki Asada"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 33
                            }
                        ],
                        "text": "Also, we can draw parallels with [18], which proposes an approach for analysis of complex table forms."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 32999860,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8485aca1ae78dc821e9ad7eb198ce103b4bfb89c",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Various kinds of complex table forms are used for many purposes, e.g. application forms. This paper presents a graph grammar based approach to the complex table form structure analysis. In our study, field types are classified into four, i.e. blank, insertion, indication, explanation, and four kinds of indication patterns are defined between indication and blank or insertion. Then, two dimensional relations between horizontally and vertically adjacent fields are described by graph representation and those reduction procedures are defined as production rules. We have designed 56 meta rules from which 6745 rules are generated for a complex table form analysis. Experimental results have shown that 31 kinds of different table forms are successfully analyzed using two types of meta grammar."
            },
            "slug": "Complex-Table-Form-Analysis-Using-Graph-Grammar-Amano-Asada",
            "title": {
                "fragments": [],
                "text": "Complex Table Form Analysis Using Graph Grammar"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A graph grammar based approach to the complex table form structure analysis with Experimental results have shown that 31 kinds of different table forms are successfully analyzed using two types of meta grammar."
            },
            "venue": {
                "fragments": [],
                "text": "Document Analysis Systems"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793699"
                        ],
                        "name": "R. Zanibbi",
                        "slug": "R.-Zanibbi",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Zanibbi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zanibbi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703931"
                        ],
                        "name": "D. Blostein",
                        "slug": "D.-Blostein",
                        "structuredName": {
                            "firstName": "Dorothea",
                            "lastName": "Blostein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blostein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683822"
                        ],
                        "name": "J. Cordy",
                        "slug": "J.-Cordy",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Cordy",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cordy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "The following surveys [15] and [16] provide a comprehensive summary of such works."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 42236309,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4c92be1e0a4ecb0c0ee28aa7da9ec0a39611e5bc",
            "isKey": false,
            "numCitedBy": 151,
            "numCiting": 117,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract.Table characteristics vary widely. Consequently, a great variety of computational approaches have been applied to table recognition. In this survey, the table recognition literature is presented as an interaction of table models, observations, transformations, and inferences. A table model defines the physical and logical structure of tables; the model is used to detect tables and to analyze and decompose the detected tables. Observations perform feature measurements and data lookup, transformations alter or restructure data, and inferences generate and test hypotheses. This presentation clarifies both the decisions made by a table recognizer and the assumptions and inferencing techniques that underlie these decisions."
            },
            "slug": "A-survey-of-table-recognition-Zanibbi-Blostein",
            "title": {
                "fragments": [],
                "text": "A survey of table recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This presentation clarifies both the decisions made by a table recognizer and the assumptions and inferencing techniques that underlie these decisions."
            },
            "venue": {
                "fragments": [],
                "text": "Document Analysis and Recognition"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2960836"
                        ],
                        "name": "M. Stoer",
                        "slug": "M.-Stoer",
                        "structuredName": {
                            "firstName": "Mechthild",
                            "lastName": "Stoer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Stoer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143854501"
                        ],
                        "name": "Frank Wagner",
                        "slug": "Frank-Wagner",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Wagner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frank Wagner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 65
                            }
                        ],
                        "text": "Then, we make use of the minimum cut algorithm from Stoer-Wagner [23], to iteratively cut weak edges."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15220291,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fec86cab0f490e94f62bfed00f6895db7296a9a1",
            "isKey": false,
            "numCitedBy": 726,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an algorithm for finding the minimum cut of an undirected edge-weighted graph. It is simple in every respect. It has a short and compact description, is easy to implement, and has a surprisingly simple proof of correctness. Its runtime matches that of the fastest algorithm known. The runtime analysis is straightforward. In contrast to nearly all approaches so far, the algorithm uses no flow techniques. Roughly speaking, the algorithm consists of about |V| nearly identical phases each of which is a maximum adjacency search."
            },
            "slug": "A-simple-min-cut-algorithm-Stoer-Wagner",
            "title": {
                "fragments": [],
                "text": "A simple min-cut algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "An algorithm for finding the minimum cut of an undirected edge-weighted graph that has a short and compact description, is easy to implement, and has a surprisingly simple proof of correctness."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1997
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 15,
            "methodology": 8
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 23,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Table-Recognition-in-Spreadsheets-via-a-Graph-Koci-Thiele/72babebcd6e61988d6caa1fb2e98a26a642862d3?sort=total-citations"
}