{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143875964"
                        ],
                        "name": "M. Levit",
                        "slug": "M.-Levit",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Levit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Levit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145364504"
                        ],
                        "name": "D. Roy",
                        "slug": "D.-Roy",
                        "structuredName": {
                            "firstName": "Deb",
                            "lastName": "Roy",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9428338,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c8b9fdf0491ccc48aef948dabd7fe9e69a486ca6",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "We have developed components of an automated system that understands and follows navigational instructions. The system has prior knowledge of the geometry and landmarks of specific maps. This knowledge is exploited to infer complex paths through maps based on natural language descriptions. The approach is based on an analysis of verbal commands in terms of elementary semantic units that are composed to generate a probability distribution over possible spatial paths in a map. An integration mechanism based on dynamic programming guides this language-to-path translation process, ensuring that resulting paths satisfy continuity and smoothness criteria. In the current implementation, parsing of text into semantic units is performed manually. Composition and interpretation of semantic units into spatial paths is performed automatically. In the evaluations, we show that the system accurately predicts the speakers' intended meanings for a range of instructions. This paper provides building blocks for a complete system that, when combined with robust parsing technologies, could lead to a fully automatic spatial language interpretation system"
            },
            "slug": "Interpretation-of-Spatial-Language-in-a-Map-Task-Levit-Roy",
            "title": {
                "fragments": [],
                "text": "Interpretation of Spatial Language in a Map Navigation Task"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper provides building blocks for a complete system that, when combined with robust parsing technologies, could lead to a fully automatic spatial language interpretation system."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067160148"
                        ],
                        "name": "T. Regier",
                        "slug": "T.-Regier",
                        "structuredName": {
                            "firstName": "Terry",
                            "lastName": "Regier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Regier"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 53881542,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "da10722657dfa1bbaba853ec1d61a463f342a1ea",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 172,
            "paperAbstract": {
                "fragments": [],
                "text": "This thesis describes a connectionist model which learns to perceive spatial events and relations in simple movies of 2-dimensional objects, so as to name the events and relations as a speaker of a particular natural language would. Thus, the model learns perceptually grounded semantics for natural language spatial terms. \nNatural languages differ--sometimes dramatically--in the ways in which they structure space. The aim here has been to have the model be able to perform this learning task for terms from any natural language, and to have learning take place in the absence of explicit negative evidence, in order to rule out ad hoc solutions and to approximate the conditions under which children learn. \nThe central focus of this thesis is a connectionist system which has succeeded in learning spatial terms from a number of different languages. The design and construction of this system have resulted in several technical contributions. The first is a very simple but effective means of learning without explicit negative evidence, taking positive instances of other concepts as implicit negative instances of the concept being learned, and deliberately weakening the evidence from these implicit negatives so as to reduce the effect of false implicit negatives in cases where concepts overlap. This method is shown to be effective even in situations involving a high degree of overlap among concepts. In addition, this thesis presents the notion of partially-structured connectionism, a marriage of structured and unstructured network design techniques capturing the flexibility afforded by unstructured networks, and the tractability in learning and improved generalization ability that result from highly structured network design. Finally, the idea of learning within highly specialized structural devices is introduced, with the purpose of restricting the search during learning to a set of options known in advance to be of possible relevance. \nScientifically, the primary result of the work described here is a computational model of the acquisition of visually grounded semantics. This model is shown to successfully learn terms for spatial events and relations from a range of languages with widely differing spatial systems, including English, Mixtec (a Mexican Indian language), German, Bengali, and Russian. The model exhibits prototype effects which roughly match human intuitions, and extensions to the core system model the linguistic phenomena of polysemy and deixis. While no claims are made regarding structure-to-structure correspondences between architectural elements of the model and structures in the brain, the model is informed by a number of neuroscientific results. And perhaps most importantly, the model does more than just recapitulate the data; it also generates a number of falsifiable linguistic predictions regarding the sorts of semantic features, and combinations of features, one might expect to find in lexemes for spatial events and relations in the world's natural languages."
            },
            "slug": "The-acquisition-of-lexical-semantics-for-spatial-a-Regier",
            "title": {
                "fragments": [],
                "text": "The acquisition of lexical semantics for spatial terms: a connectionist model of perceptual categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "This thesis describes a connectionist model which learns to perceive spatial events and relations in simple movies of 2-dimensional objects, so as to name the events and Relations as a speaker of a particular natural language would, and learns perceptually grounded semantics for natural language spatial terms."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2156253272"
                        ],
                        "name": "Yuan Wei",
                        "slug": "Yuan-Wei",
                        "structuredName": {
                            "firstName": "Yuan",
                            "lastName": "Wei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuan Wei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2563117"
                        ],
                        "name": "Emma Brunskill",
                        "slug": "Emma-Brunskill",
                        "structuredName": {
                            "firstName": "Emma",
                            "lastName": "Brunskill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Emma Brunskill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2836353"
                        ],
                        "name": "T. Kollar",
                        "slug": "T.-Kollar",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kollar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kollar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143724999"
                        ],
                        "name": "N. Roy",
                        "slug": "N.-Roy",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Roy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Roy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 638927,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fe489d863969f2a5bf66aa75deec3110e43bf442",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "An important component of human-robot interaction is that people need to be able to instruct robots to move to other locations using naturally given directions. When giving directions, people often make mistakes such as labelling errors (e.g., left vs. right) and errors of omission (skipping important decision points in a sequence). Furthermore, people often use multiple levels of granularity in specifying directions, referring to locations using single object landmarks, multiple landmarks in a given location, or identifying large regions as a single location. The challenge is to identify the correct path to a destination from a sequence of noisy, possibly erroneous directions. In our work we cast this problem as probabilistic inference: given a set of directions, an agent should automatically find the path with the geometry and physical appearance to maximize the likelihood of those directions. We use a specific variant of a Markov Random Field (MRF) to represent our model, and gather multi-granularity representation information using existing large tagged datasets. On a dataset of route directions collected in a large third floor university building, we found that our algorithm correctly inferred the true final destination in 47 out of the 55 cases successfully followed by humans volunteers. These results suggest that our algorithm is performing well relative to human users. In the future this work will be included in a broader system for autonomously constructing environmental representations that support natural human-robot interaction for direction giving."
            },
            "slug": "Where-to-go:-Interpreting-natural-directions-using-Wei-Brunskill",
            "title": {
                "fragments": [],
                "text": "Where to go: Interpreting natural directions using global inference"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "On a dataset of route directions collected in a large third floor university building, the algorithm correctly inferred the true final destination in 47 out of the 55 cases successfully followed by humans volunteers, suggesting that the algorithm is performing well relative to human users."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE International Conference on Robotics and Automation"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144987760"
                        ],
                        "name": "M. Skubic",
                        "slug": "M.-Skubic",
                        "structuredName": {
                            "firstName": "Marjorie",
                            "lastName": "Skubic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Skubic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3254427"
                        ],
                        "name": "D. Perzanowski",
                        "slug": "D.-Perzanowski",
                        "structuredName": {
                            "firstName": "Dennis",
                            "lastName": "Perzanowski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Perzanowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1928974"
                        ],
                        "name": "Samuel Blisard",
                        "slug": "Samuel-Blisard",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Blisard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samuel Blisard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803820"
                        ],
                        "name": "A. Schultz",
                        "slug": "A.-Schultz",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Schultz",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Schultz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144444996"
                        ],
                        "name": "W. Adams",
                        "slug": "W.-Adams",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Adams",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Adams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2799250"
                        ],
                        "name": "M. Bugajska",
                        "slug": "M.-Bugajska",
                        "structuredName": {
                            "firstName": "Magdalena",
                            "lastName": "Bugajska",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bugajska"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7976026"
                        ],
                        "name": "Derek P. Brock",
                        "slug": "Derek-P.-Brock",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Brock",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek P. Brock"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 35465055,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d298cd32afa6cba6592054856ce589ce8dda0ff9",
            "isKey": false,
            "numCitedBy": 254,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "In conversation, people often use spatial relationships to describe their environment, e.g., \"There is a desk in front of me and a doorway behind it,\" and to issue directives, e.g., \"go around the desk and through the doorway.\" In our research, we have been investigating the use of spatial relationships to establish a natural communication mechanism between people and robots, in particular, for novice users. In this paper, the work on robot spatial relationships is combined with a multimodal robot interface. We show how linguistic spatial descriptions and other spatial information can be extracted from an evidence grid map and how this information can be used in a natural, human-robot dialog. Examples using spatial language are included for both robot-to-human feedback and also human-to-robot commands. We also discuss some linguistic consequences in the semantic representations of spatial and locative information based on this work."
            },
            "slug": "Spatial-language-for-human-robot-dialogs-Skubic-Perzanowski",
            "title": {
                "fragments": [],
                "text": "Spatial language for human-robot dialogs"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown how linguistic spatial descriptions and other spatial information can be extracted from an evidence grid map and how this information can been used in a natural, human-robot dialog."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2913681"
                        ],
                        "name": "Stefanie Tellex",
                        "slug": "Stefanie-Tellex",
                        "structuredName": {
                            "firstName": "Stefanie",
                            "lastName": "Tellex",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stefanie Tellex"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145364504"
                        ],
                        "name": "D. Roy",
                        "slug": "D.-Roy",
                        "structuredName": {
                            "firstName": "Deb",
                            "lastName": "Roy",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8510615,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1d2e4f7081204e7471993fbf1f52b27e88800dec",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Spatial language video retrieval is an important real-world problem that forms a test bed for evaluating semantic structures for natural language descriptions of motion on naturalistic data. Video search by natural language query requires that linguistic input be converted into structures that operate on video in order to find clips that match a query. This paper describes a framework for grounding the meaning of spatial prepositions in video. We present a library of features that can be used to automatically classify a video clip based on whether it matches a natural language query. To evaluate these features, we collected a corpus of natural language descriptions about the motion of people in video clips. We characterize the language used in the corpus, and use it to train and test models for the meanings of the spatial prepositions \"to,\" \"across,\" \"through,\" \"out,\" \"along,\" \"towards,\" and \"around.\" The classifiers can be used to build a spatial language video retrieval system that finds clips matching queries such as \"across the kitchen.\""
            },
            "slug": "Grounding-spatial-prepositions-for-video-search-Tellex-Roy",
            "title": {
                "fragments": [],
                "text": "Grounding spatial prepositions for video search"
            },
            "venue": {
                "fragments": [],
                "text": "ICMI-MLMI '09"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145741913"
                        ],
                        "name": "M. MacMahon",
                        "slug": "M.-MacMahon",
                        "structuredName": {
                            "firstName": "Matt",
                            "lastName": "MacMahon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. MacMahon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2322577"
                        ],
                        "name": "B. Stankiewicz",
                        "slug": "B.-Stankiewicz",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Stankiewicz",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Stankiewicz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145585296"
                        ],
                        "name": "B. Kuipers",
                        "slug": "B.-Kuipers",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Kuipers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Kuipers"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1863523,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "851f27df3a1ec8daa693f6642194562e3fe9769a",
            "isKey": false,
            "numCitedBy": 356,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Following verbal route instructions requires knowledge of language, space, action and perception. We present MARCO, an agent that follows free-form, natural language route instructions by representing and executing a sequence of compound action specifications that model which actions to take under which conditions. MARCO infers implicit actions from knowledge of both linguistic conditional phrases and from spatial action and local configurations. Thus, MARCO performs explicit actions, implicit actions necessary to achieve the stated conditions, and exploratory actions to learn about the world. \n \nWe gathered a corpus of 786 route instructions from six people in three large-scale virtual indoor environments. Thirtysix other people followed these instructions and rated them for quality. These human participants finished at the intended destination on 69% of the trials. MARCO followed the same instructions in the same environments, with a success rate of 61%. We measured the efficacy of action inference with MARCO variants lacking action inference: executing only explicit actions, MARCO succeeded on just 28% of the trials. For this task, inferring implicit actions is essential to follow poor instructions, but is also crucial for many highly-rated route instructions."
            },
            "slug": "Walk-the-Talk:-Connecting-Language,-Knowledge,-and-MacMahon-Stankiewicz",
            "title": {
                "fragments": [],
                "text": "Walk the Talk: Connecting Language, Knowledge, and Action in Route Instructions"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "MARCO, an agent that follows free-form, natural language route instructions by representing and executing a sequence of compound action specifications that model which actions to take under which conditions, is presented."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145559335"
                        ],
                        "name": "B. Landau",
                        "slug": "B.-Landau",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Landau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Landau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1766112"
                        ],
                        "name": "R. Jackendoff",
                        "slug": "R.-Jackendoff",
                        "structuredName": {
                            "firstName": "Ray",
                            "lastName": "Jackendoff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jackendoff"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 144503525,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "e806ea966a1c8c27eef25adb64541390d90c6413",
            "isKey": false,
            "numCitedBy": 921,
            "numCiting": 162,
            "paperAbstract": {
                "fragments": [],
                "text": "Fundamental to spatial knowledge in all species are the representations underlying object recognition, object search, and navigation through space. But what sets humans apart from other species is our ability to express spatial experience through language. This target article explores the language of objects and places , asking what geometric properties are preserved in the representations underlying object nouns and spatial prepositions in English. Evidence from these two aspects of language suggests there are significant differences in the geometric richness with which objects and places are encoded. When an object is named (i.e., with count nouns), detailed geometric properties \u2013 principally the object's shape (axes, solid and hollow volumes, surfaces, and parts) \u2013 are represented. In contrast, when an object plays the role of either \u201cfigure\u201d (located object) or \u201cground\u201d (reference object) in a locational expression, only very coarse geometric object properties are represented, primarily the main axes. In addition, the spatial functions encoded by spatial prepositions tend to be nonmetric and relatively coarse, for example, \u201ccontainment,\u201d \u201ccontact,\u201d \u201crelative distance,\u201d and \u201crelative direction.\u201d These properties are representative of other languages as well. The striking differences in the way language encodes objects versus places lead us to suggest two explanations: First, there is a tendency for languages to level out geometric detail from both object and place representations. Second, a nonlinguistic disparity between the representations of \u201cwhat\u201d and \u201cwhere\u201d underlies how language represents objects and places. The language of objects and places converges with and enriches our understanding of corresponding spatial representations."
            },
            "slug": "\u201cWhat\u201d-and-\u201cwhere\u201d-in-spatial-language-and-spatial-Landau-Jackendoff",
            "title": {
                "fragments": [],
                "text": "\u201cWhat\u201d and \u201cwhere\u201d in spatial language and spatial cognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2637318"
                        ],
                        "name": "Juraj Dzifcak",
                        "slug": "Juraj-Dzifcak",
                        "structuredName": {
                            "firstName": "Juraj",
                            "lastName": "Dzifcak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Juraj Dzifcak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793014"
                        ],
                        "name": "Matthias Scheutz",
                        "slug": "Matthias-Scheutz",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Scheutz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthias Scheutz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760291"
                        ],
                        "name": "Chitta Baral",
                        "slug": "Chitta-Baral",
                        "structuredName": {
                            "firstName": "Chitta",
                            "lastName": "Baral",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chitta Baral"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2510893"
                        ],
                        "name": "P. Schermerhorn",
                        "slug": "P.-Schermerhorn",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Schermerhorn",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Schermerhorn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16366080,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "21e4e58e4e32b0149714653590db6998abd2811d",
            "isKey": false,
            "numCitedBy": 200,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Robots that can be given instructions in spoken language need to be able to parse a natural language utterance quickly, determine its meaning, generate a goal representation from it, check whether the new goal conflicts with existing goals, and if acceptable, produce an action sequence to achieve the new goal (ideally being sensitive to the existing goals). In this paper, we describe an integrated robotic architecture that can achieve the above steps by translating natural language instructions incrementally and simultaneously into formal logical goal description and action languages, which can be used both to reason about the achievability of a goal as well as to generate new action scripts to pursue the goal. We demonstrate the implementation of our approach on a robot taking spoken natural language instructions in an office environment."
            },
            "slug": "What-to-do-and-how-to-do-it:-Translating-natural-Dzifcak-Scheutz",
            "title": {
                "fragments": [],
                "text": "What to do and how to do it: Translating natural language directives into temporal and dynamic logic representation for goal management and action execution"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An integrated robotic architecture is described that can achieve the above steps by translating natural language instructions incrementally and simultaneously into formal logical goal description and action languages, which can be used both to reason about the achievability of a goal as well as to generate new action scripts to pursue the goal."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE International Conference on Robotics and Automation"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1839967"
                        ],
                        "name": "G. Bugmann",
                        "slug": "G.-Bugmann",
                        "structuredName": {
                            "firstName": "Guido",
                            "lastName": "Bugmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Bugmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145606490"
                        ],
                        "name": "Ewan Klein",
                        "slug": "Ewan-Klein",
                        "structuredName": {
                            "firstName": "Ewan",
                            "lastName": "Klein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ewan Klein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33731948"
                        ],
                        "name": "S. Lauria",
                        "slug": "S.-Lauria",
                        "structuredName": {
                            "firstName": "Stanislao",
                            "lastName": "Lauria",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lauria"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2584299"
                        ],
                        "name": "T. Kyriacou",
                        "slug": "T.-Kyriacou",
                        "structuredName": {
                            "firstName": "Theocharis",
                            "lastName": "Kyriacou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kyriacou"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16627690,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1b3942196a5b4e737e618fda91bc925c465faead",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "In corpus-based robotics, the primitive functions built into a robot are determined by the functional content of human utterances spoken to the robot. In the example of route instructions treated in this paper, the 15 primitives found include functions such as turn(), cross(), landmark_is_located(), etc. These are natural primitives of human behaviour but complex robot functions, some of which are not normally thought of by roboticists. Primitives must cope robustly with a variety of environmental conditions and require autonomous navigation capabilities based for instance on visual landmark recognition and localisation, navigable space mapping and path planning. Thus, the requirement of human-robot interaction creates specific and demanding functional targets for robot designers. A major obstacle to human-robot communication lies probably in current robots\u2019 perception capabilities. Furthermore, for human-robot communication to match the performance of human-human communication, the robot must also be provided with capabilities of re-interpreting and correcting instructions at execution time. Such a large autonomy raises wider issues of safety and control."
            },
            "slug": "Corpus-Based-Robotics:-A-Route-Instruction-Example-Bugmann-Klein",
            "title": {
                "fragments": [],
                "text": "Corpus-Based Robotics: A Route Instruction Example"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "For human-robot communication to match the performance of human-human communication, the robot must also be provided with capabilities of re-interpreting and correcting instructions at execution time, which raises wider issues of safety and control."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34967075"
                        ],
                        "name": "John D. Kelleher",
                        "slug": "John-D.-Kelleher",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Kelleher",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John D. Kelleher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767977"
                        ],
                        "name": "F. Costello",
                        "slug": "F.-Costello",
                        "structuredName": {
                            "firstName": "Fintan",
                            "lastName": "Costello",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Costello"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 235717,
            "fieldsOfStudy": [
                "Psychology",
                "Computer Science"
            ],
            "id": "af3167497ab8d75c5f89d162a901eac700302236",
            "isKey": false,
            "numCitedBy": 90,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "This article describes the application of computational models of spatial prepositions to visually situated dialog systems. In these dialogs, spatial prepositions are important because people often use them to refer to entities in the visual context of a dialog. We first describe a generic architecture for a visually situated dialog system and highlight the interactions between the spatial cognition module, which provides the interface to the models of prepositional semantics, and the other components in the architecture. Following this, we present two new computational models of topological and projective spatial prepositions. The main novelty within these models is the fact that they account for the contextual effect which other distractor objects in a visual scene can have on the region described by a given preposition. We next present psycholinguistic tests evaluating our approach to distractor interference on prepositional semantics, and illustrate how these models are used for both interpretation and generation of prepositional expressions."
            },
            "slug": "Applying-Computational-Models-of-Spatial-to-Dialog-Kelleher-Costello",
            "title": {
                "fragments": [],
                "text": "Applying Computational Models of Spatial Prepositions to Visually Situated Dialog"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A generic architecture for a visually situated dialog system is described and the interactions between the spatial cognition module, which provides the interface to the models of prepositional semantics, and the other components in the architecture are highlighted."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145091160"
                        ],
                        "name": "B. Levin",
                        "slug": "B.-Levin",
                        "structuredName": {
                            "firstName": "Beth",
                            "lastName": "Levin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Levin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 62585813,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "6cbc1eb25f4ab29a613418b3b0740e74141a0f17",
            "isKey": false,
            "numCitedBy": 3246,
            "numCiting": 246,
            "paperAbstract": {
                "fragments": [],
                "text": "In this rich reference work, Beth Levin classifies over 3,000 English verbs according to shared meaning and behavior. Levin starts with the hypothesis that a verb's meaning influences its syntactic behavior and develops it into a powerful tool for studying the English verb lexicon. She shows how identifying verbs with similar syntactic behavior provides an effective means of distinguishing semantically coherent verb classes, and isolates these classes by examining verb behavior with respect to a wide range of syntactic alternations that reflect verb meaning. The first part of the book sets out alternate ways in which verbs can express their arguments. The second presents classes of verbs that share a kernel of meaning and explores in detail the behavior of each class, drawing on the alternations in the first part. Levin's discussion of each class and alternation includes lists of relevant verbs, illustrative examples, comments on noteworthy properties, and bibliographic references. The result is an original, systematic picture of the organization of the verb inventory. Easy to use, \"English Verb Classes and Alternations\" sets the stage for further explorations of the interface between lexical semantics and syntax. It will prove indispensable for theoretical and computational linguists, psycholinguists, cognitive scientists, lexicographers, and teachers of English as a second language. Beth Levin is associate professor of linguistics at Northwestern University."
            },
            "slug": "English-Verb-Classes-and-Alternations:-A-Levin",
            "title": {
                "fragments": [],
                "text": "English Verb Classes and Alternations: A Preliminary Investigation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Beth Levin shows how identifying verbs with similar syntactic behavior provides an effective means of distinguishing semantically coherent verb classes, and isolates these classes by examining verb behavior with respect to a wide range of syntactic alternations that reflect verb meaning."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2080232070"
                        ],
                        "name": "Beate Hamp",
                        "slug": "Beate-Hamp",
                        "structuredName": {
                            "firstName": "Beate",
                            "lastName": "Hamp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Beate Hamp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2033027"
                        ],
                        "name": "M. D. Gruyter",
                        "slug": "M.-D.-Gruyter",
                        "structuredName": {
                            "firstName": "Mouton",
                            "lastName": "Gruyter",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. D. Gruyter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 48870580,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "f656808d4685bf0b324bf65fe26ebc96a8a8c85d",
            "isKey": false,
            "numCitedBy": 79,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Linguistic research to date has determined many of the principles that govern the structure of the spatial schemas represented by closed-class forms across the world\u2019s languages. contributing to this cumulative understanding have, for example, been Gruber 1965, Fillmore 1968, Leech 1969, Clark 1973, Bennett 1975, Herskovits 1982, Jackendoff 1983, Zubin and Svorou 1984, as well as myself, Talmy 1983, 2000a, 2000b). It is now feasible to integrate these principles and to determine the comprehensive system they belong to for spatial structuring in spoken language. The finding here is that this system has three main parts: the componential, the compositional, and the augmentive."
            },
            "slug": "The-Fundamental-System-of-Spatial-Schemas-in-Hamp-Gruyter",
            "title": {
                "fragments": [],
                "text": "The Fundamental System of Spatial Schemas in Language"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2836353"
                        ],
                        "name": "T. Kollar",
                        "slug": "T.-Kollar",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kollar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kollar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143724999"
                        ],
                        "name": "N. Roy",
                        "slug": "N.-Roy",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Roy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Roy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12414470,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f06334b2127b5494ac710167b53c17d984046556",
            "isKey": false,
            "numCitedBy": 110,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, our goal is to search for a novel object, where we have a prior map of the environment and knowledge of some of the objects in it, but no information about the location of the specific novel object. We develop a probabilistic model over possible object locations that utilizes object-object and object-scene context. This model can be queried for any of over 25,000 naturally occurring objects in the world and is trained from labeled data acquired from the captions of photos on the Flickr website. We show that these simple models based on object co-occurrences perform surprisingly well at localizing arbitrary objects in an office setting. In addition, we show how to compute paths that minimize the expected distance to the query object and show that this approach performs better than a greedy approach. Finally, we give preliminary results for grounding our approach in object classifiers."
            },
            "slug": "Utilizing-object-object-and-object-scene-context-to-Kollar-Roy",
            "title": {
                "fragments": [],
                "text": "Utilizing object-object and object-scene context when planning to find things"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A probabilistic model over possible object locations that utilizes object-object and object-scene context is developed and it is shown that these simple models based on object co-occurrences perform surprisingly well at localizing arbitrary objects in an office setting."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE International Conference on Robotics and Automation"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35159257"
                        ],
                        "name": "A. Bauer",
                        "slug": "A.-Bauer",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Bauer",
                            "middleNames": [
                                "Maria"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "27371799"
                        ],
                        "name": "Klaas Klasing",
                        "slug": "Klaas-Klasing",
                        "structuredName": {
                            "firstName": "Klaas",
                            "lastName": "Klasing",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Klaas Klasing"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2297123"
                        ],
                        "name": "Georgios Lidoris",
                        "slug": "Georgios-Lidoris",
                        "structuredName": {
                            "firstName": "Georgios",
                            "lastName": "Lidoris",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Georgios Lidoris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3054965"
                        ],
                        "name": "Q. M\u00fchlbauer",
                        "slug": "Q.-M\u00fchlbauer",
                        "structuredName": {
                            "firstName": "Quirin",
                            "lastName": "M\u00fchlbauer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. M\u00fchlbauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1918106"
                        ],
                        "name": "Florian Rohrm\u00fcller",
                        "slug": "Florian-Rohrm\u00fcller",
                        "structuredName": {
                            "firstName": "Florian",
                            "lastName": "Rohrm\u00fcller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Florian Rohrm\u00fcller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2185308"
                        ],
                        "name": "Stefan Sosnowski",
                        "slug": "Stefan-Sosnowski",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Sosnowski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stefan Sosnowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50383691"
                        ],
                        "name": "T. Xu",
                        "slug": "T.-Xu",
                        "structuredName": {
                            "firstName": "Tingting",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708675"
                        ],
                        "name": "K. K\u00fchnlenz",
                        "slug": "K.-K\u00fchnlenz",
                        "structuredName": {
                            "firstName": "Kolja",
                            "lastName": "K\u00fchnlenz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. K\u00fchnlenz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749896"
                        ],
                        "name": "D. Wollherr",
                        "slug": "D.-Wollherr",
                        "structuredName": {
                            "firstName": "Dirk",
                            "lastName": "Wollherr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Wollherr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20631844"
                        ],
                        "name": "M. Buss",
                        "slug": "M.-Buss",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Buss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Buss"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 8079048,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ac02a50306a267afd6449759b647aabe5f456cf6",
            "isKey": false,
            "numCitedBy": 127,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "The Autonomous City Explorer (ACE) project combines research from autonomous outdoor navigation and human-robot interaction. The ACE robot is capable of navigating unknown urban environments without the use of GPS data or prior map knowledge. It finds its way by interacting with pedestrians in a natural and intuitive way and building a topological representation of its surroundings. In a recent experiment the robot managed to successfully travel a 1.5\u2009km distance from the campus of the Technische Universit\u00e4t M\u00fcnchen to Marienplatz, the central square of Munich. This article describes the principles and system components for navigation in urban environments, information retrieval through natural human-robot interaction, the construction of a suitable semantic representation as well as results from the field experiment."
            },
            "slug": "The-Autonomous-City-Explorer:-Towards-Natural-in-Bauer-Klasing",
            "title": {
                "fragments": [],
                "text": "The Autonomous City Explorer: Towards Natural Human-Robot Interaction in Urban Environments"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The principles and system components for navigation in urban environments, information retrieval through natural human-robot interaction, the construction of a suitable semantic representation as well as results from the field experiment are described."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Soc. Robotics"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2077329605"
                        ],
                        "name": "G. Look",
                        "slug": "G.-Look",
                        "structuredName": {
                            "firstName": "Gary",
                            "lastName": "Look",
                            "middleNames": [
                                "Wai",
                                "Keung"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Look"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2862225"
                        ],
                        "name": "Buddhika Kottahachchi",
                        "slug": "Buddhika-Kottahachchi",
                        "structuredName": {
                            "firstName": "Buddhika",
                            "lastName": "Kottahachchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Buddhika Kottahachchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685676"
                        ],
                        "name": "R. Laddaga",
                        "slug": "R.-Laddaga",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Laddaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Laddaga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716356"
                        ],
                        "name": "H. Shrobe",
                        "slug": "H.-Shrobe",
                        "structuredName": {
                            "firstName": "Howard",
                            "lastName": "Shrobe",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Shrobe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18745517,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9491999ed1835a7d0f8a3b1f24b5e4539cb3d2c3",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "An expressive representation for location is an important component in many applications. However, while many location-aware applications can reason about space at the level of coordinates and containment relationships, they have no way to express the semantics that define how a particular space is used. We present Lair, an ontology that addresses this problem by modeling both the geographical relationships between spaces as well as the functional purpose of a given space. We describe how Lair was used to create an application that produces walking directions comparable to those given by a person, and a pilot study that evaluated the quality of these directions. We also describe how Lair can be used to evaluate other intelligent user interfaces."
            },
            "slug": "A-location-representation-for-generating-walking-Look-Kottahachchi",
            "title": {
                "fragments": [],
                "text": "A location representation for generating descriptive walking directions"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work describes how Lair was used to create an application that produces walking directions comparable to those given by a person, and a pilot study that evaluated the quality of these directions."
            },
            "venue": {
                "fragments": [],
                "text": "IUI"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737531"
                        ],
                        "name": "G. Grisetti",
                        "slug": "G.-Grisetti",
                        "structuredName": {
                            "firstName": "Giorgio",
                            "lastName": "Grisetti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Grisetti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722062"
                        ],
                        "name": "C. Stachniss",
                        "slug": "C.-Stachniss",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Stachniss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Stachniss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725973"
                        ],
                        "name": "W. Burgard",
                        "slug": "W.-Burgard",
                        "structuredName": {
                            "firstName": "Wolfram",
                            "lastName": "Burgard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Burgard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 321256,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eac11872f8a29a18058bf61dd04929e1ac29d258",
            "isKey": false,
            "numCitedBy": 1890,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, Rao-Blackwellized particle filters (RBPF) have been introduced as an effective means to solve the simultaneous localization and mapping problem. This approach uses a particle filter in which each particle carries an individual map of the environment. Accordingly, a key question is how to reduce the number of particles. In this paper, we present adaptive techniques for reducing this number in a RBPF for learning grid maps. We propose an approach to compute an accurate proposal distribution, taking into account not only the movement of the robot, but also the most recent observation. This drastically decreases the uncertainty about the robot's pose in the prediction step of the filter. Furthermore, we present an approach to selectively carry out resampling operations, which seriously reduces the problem of particle depletion. Experimental results carried out with real mobile robots in large-scale indoor, as well as outdoor, environments illustrate the advantages of our methods over previous approaches"
            },
            "slug": "Improved-Techniques-for-Grid-Mapping-With-Particle-Grisetti-Stachniss",
            "title": {
                "fragments": [],
                "text": "Improved Techniques for Grid Mapping With Rao-Blackwellized Particle Filters"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Robotics"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2563117"
                        ],
                        "name": "Emma Brunskill",
                        "slug": "Emma-Brunskill",
                        "structuredName": {
                            "firstName": "Emma",
                            "lastName": "Brunskill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Emma Brunskill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2836353"
                        ],
                        "name": "T. Kollar",
                        "slug": "T.-Kollar",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kollar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kollar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143724999"
                        ],
                        "name": "N. Roy",
                        "slug": "N.-Roy",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Roy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Roy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10930644,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e262d03cb5dc072177917176a55c52d6a0411458",
            "isKey": false,
            "numCitedBy": 112,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work we present an online method for generating topological maps from raw sensor information. We first describe an algorithm to automatically decompose a map into submap segments using a graph partitioning technique known as spectral clustering. We then describe how to train a classifier to recognize graph submaps from laser signatures using the AdaBoost machine learning algorithm. We demonstrate that the we can perform topological mapping by incrementally segmenting the world as the robot moves through its environment, and we can close the loop when the learned classifier recognizes that the robot has returned to a previously visited location."
            },
            "slug": "Topological-mapping-using-spectral-clustering-and-Brunskill-Kollar",
            "title": {
                "fragments": [],
                "text": "Topological mapping using spectral clustering and classification"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "An algorithm to automatically decompose a map into submap segments using a graph partitioning technique known as spectral clustering is described and how to train a classifier to recognize graph submaps from laser signatures using the AdaBoost machine learning algorithm is described."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE/RSJ International Conference on Intelligent Robots and Systems"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145500689"
                        ],
                        "name": "A. Viterbi",
                        "slug": "A.-Viterbi",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Viterbi",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Viterbi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15843983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "145c0b53514b02bdc3dadfb2e1cea124f2abd99b",
            "isKey": false,
            "numCitedBy": 5209,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The probability of error in decoding an optimal convolutional code transmitted over a memoryless channel is bounded from above and below as a function of the constraint length of the code. For all but pathological channels the bounds are asymptotically (exponentially) tight for rates above R_{0} , the computational cutoff rate of sequential decoding. As a function of constraint length the performance of optimal convolutional codes is shown to be superior to that of block codes of the same length, the relative improvement increasing with rate. The upper bound is obtained for a specific probabilistic nonsequential decoding algorithm which is shown to be asymptotically optimum for rates above R_{0} and whose performance bears certain similarities to that of sequential decoding algorithms."
            },
            "slug": "Error-bounds-for-convolutional-codes-and-an-optimum-Viterbi",
            "title": {
                "fragments": [],
                "text": "Error bounds for convolutional codes and an asymptotically optimum decoding algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The upper bound is obtained for a specific probabilistic nonsequential decoding algorithm which is shown to be asymptotically optimum for rates above R_{0} and whose performance bears certain similarities to that of sequential decoding algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1967
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "CRF++: Yet another CRF toolkit"
            },
            "venue": {
                "fragments": [],
                "text": "CRF++: Yet another CRF toolkit"
            },
            "year": 2009
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 19,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Toward-understanding-natural-language-directions-Kollar-Tellex/a5b1bf6584f24fe3ccc8d67e5bba369783f817f0?sort=total-citations"
}