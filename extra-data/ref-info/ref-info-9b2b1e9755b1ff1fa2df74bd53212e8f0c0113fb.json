{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2452419"
                        ],
                        "name": "H. Yoshimura",
                        "slug": "H.-Yoshimura",
                        "structuredName": {
                            "firstName": "Hiroshi",
                            "lastName": "Yoshimura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Yoshimura"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8268643"
                        ],
                        "name": "M. Etoh",
                        "slug": "M.-Etoh",
                        "structuredName": {
                            "firstName": "Minoru",
                            "lastName": "Etoh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Etoh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "71290316"
                        ],
                        "name": "K. Kondo",
                        "slug": "K.-Kondo",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Kondo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kondo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771769"
                        ],
                        "name": "N. Yokoya",
                        "slug": "N.-Yokoya",
                        "structuredName": {
                            "firstName": "Naokazu",
                            "lastName": "Yokoya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Yokoya"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 195
                            }
                        ],
                        "text": "Yoshimura and his colleagues ever reported to extract features using Gabor from intensity of video images for character recognition and use LVQ (Linear Vector Quantization) for feature selection [14]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 34363569,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "630effc5ef9b289e90e624cbfe658dabf77d3ef5",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a gray-scale character recognition method for video indexing. It is robust against the problems of binarization against a complex background and low resolution. Unlike a traditional character recognition scheme through image binarization, we directly extract Gabor features (called Gabor jets) from video contents. The use of the Gabor filters contributes to freeing a tricky binarization process for cluttered images, and furthermore provides localized directional edge features, which have phase-shift invariance to edge positions. To form a feature vector to be classified, we accumulate the extracted Gabor features along projection lines in local regions, and then categorize them with a standard LVQ classifier. The projective accumulation provides robustness under character deformation caused by variation of font types or imprecise segmentation. We compare the proposed method by experiments with a typical OCR method, for which correct binarization is advantageously given. The proposed method shows similar or superior performance to the other method in understanding video captions."
            },
            "slug": "Gray-scale-character-recognition-by-Gabor-jets-Yoshimura-Etoh",
            "title": {
                "fragments": [],
                "text": "Gray-scale character recognition by Gabor jets projection"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "A gray-scale character recognition method for video indexing that directly extracts Gabor features (called Gabor jets) from video contents and provides robustness under character deformation caused by variation of font types or imprecise segmentation."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 15th International Conference on Pattern Recognition. ICPR-2000"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2316043"
                        ],
                        "name": "Qiang Huo",
                        "slug": "Qiang-Huo",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Huo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Huo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068908988"
                        ],
                        "name": "Yong Ge",
                        "slug": "Yong-Ge",
                        "structuredName": {
                            "firstName": "Yong",
                            "lastName": "Ge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yong Ge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2418275"
                        ],
                        "name": "Zhi-Dan Feng",
                        "slug": "Zhi-Dan-Feng",
                        "structuredName": {
                            "firstName": "Zhi-Dan",
                            "lastName": "Feng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhi-Dan Feng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 79
                            }
                        ],
                        "text": "Early applications of Gabor wavelet to OCR tasks were based on binary features [1, 3-5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14399071,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd356b57ecee905f476796e46570f321639301b9",
            "isKey": false,
            "numCitedBy": 70,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "We have developed a Chinese OCR engine for machine printed documents. Currently, our OCR engine can support a vocabulary of 6921 characters which include 6707 simplified Chinese characters in GB2312-80, 12 frequently used GBK Chinese characters, 62 alphanumeric characters, 140 punctuation marks and symbols. The supported font styles include Song, Fang Song, Kat, He, Yuan, LiShu, WeiBei, XingKai, etc. The averaged character recognition accuracy is above 99% for newspaper quality documents with a recognition speed of about 250 characters per second on a Pentium III-450 MHz PC yet only consuming less than 2 MB memory. We describe the key technologies we used to construct the above recognizer. Among them, we highlight three key techniques contributing to the high recognition accuracy, namely the use of Gabor features, the use of discriminative feature extraction, and the use of minimum classification error as a criterion for model training."
            },
            "slug": "High-performance-Chinese-OCR-based-on-Gabor-feature-Huo-Ge",
            "title": {
                "fragments": [],
                "text": "High performance Chinese OCR based on Gabor features, discriminative feature extraction and model training"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Three key techniques contributing to the high recognition accuracy are highlighted, namely theuse of Gabor features, the use of discriminative feature extraction, and theUse of minimum classification error as a criterion for model training."
            },
            "venue": {
                "fragments": [],
                "text": "2001 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings (Cat. No.01CH37221)"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144117646"
                        ],
                        "name": "Jiang Gao",
                        "slug": "Jiang-Gao",
                        "structuredName": {
                            "firstName": "Jiang",
                            "lastName": "Gao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiang Gao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118579343"
                        ],
                        "name": "Jie Yang",
                        "slug": "Jie-Yang",
                        "structuredName": {
                            "firstName": "Jie",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jie Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153391519"
                        ],
                        "name": "Ying Zhang",
                        "slug": "Ying-Zhang",
                        "structuredName": {
                            "firstName": "Ying",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ying Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The method of character segmentation has been introduced before [2], and we will only focus on the recognition of the character in this paper."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10228582,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c5c6eaa32e741fcc5e401b2ef3b06077b0fa98ac",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : The authors present a system for automatic extraction and interpretation of signs from a natural scene. The system is capable of capturing images, detecting and recognizing signs, and translating them into a target language. The translation can be displayed on a hand-held wearable display or a head-mounted display. It can also be synthesized as a voice output message over the earphones. The paper addresses challenges in automatic sign extraction and translation, describes methods for automatic sign extraction, and extends example-based machine translation technology for sign translation. The authors use a user-centered approach in system development that takes advantage of human intelligence and leverages human capabilities. They are currently working on Chinese sign translation. So far, they have developed a prototype system that can recognize Chinese signs from a video camera and then translate them either into English text or a voice stream. They have built a database containing about 800 Chinese signs for development and evaluation. The authors hope that the sign translation, in conjunction with spoken language translation, will help international tourists overcome language barriers. The technology could also help a visually handicapped person increase his or her environmental awareness."
            },
            "slug": "Text-Detection-and-Translation-from-Natural-Scenes-Gao-Yang",
            "title": {
                "fragments": [],
                "text": "Text Detection and Translation from Natural Scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A system for automatic extraction and interpretation of signs from a natural scene capable of capturing images, detecting and recognizing signs, and translating them into a target language, which will help international tourists overcome language barriers."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110062608"
                        ],
                        "name": "Toshio Sato",
                        "slug": "Toshio-Sato",
                        "structuredName": {
                            "firstName": "Toshio",
                            "lastName": "Sato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Toshio Sato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2816639"
                        ],
                        "name": "Ellen K. Hughes",
                        "slug": "Ellen-K.-Hughes",
                        "structuredName": {
                            "firstName": "Ellen",
                            "lastName": "Hughes",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ellen K. Hughes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116645471"
                        ],
                        "name": "Michael A. Smith",
                        "slug": "Michael-A.-Smith",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Smith",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael A. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700567"
                        ],
                        "name": "S. Satoh",
                        "slug": "S.-Satoh",
                        "structuredName": {
                            "firstName": "Shin\u2019ichi",
                            "lastName": "Satoh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Satoh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9520237,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "14ce174bddee5b6b2750cf14574773b537ac4d42",
            "isKey": false,
            "numCitedBy": 206,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract. The automatic extraction and recognition of news captions and annotations can be of great help locating topics of interest in digital news video libraries. To achieve this goal, we present a technique, called Video OCR (Optical Character Reader), which detects, extracts, and reads text areas in digital video data. In this paper, we address problems, describe the method by which Video OCR operates, and suggest applications for its use in digital news archives. To solve two problems of character recognition for videos, low-resolution characters and extremely complex backgrounds, we apply an interpolation filter, multi-frame integration and character extraction filters. Character segmentation is performed by a recognition-based segmentation method, and intermediate character recognition results are used to improve the segmentation. We also include a method for locating text areas using text-like properties and the use of a language-based postprocessing technique to increase word recognition rates. The overall recognition results are satisfactory for use in news indexing. Performing Video OCR on news video and combining its results with other video understanding techniques will improve the overall understanding of the news video content."
            },
            "slug": "Video-OCR:-indexing-digital-news-libraries-by-of-Sato-Kanade",
            "title": {
                "fragments": [],
                "text": "Video OCR: indexing digital news libraries by recognition of superimposed captions"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "To solve two problems of character recognition for videos, low-resolution characters and extremely complex backgrounds, an interpolation filter, multi-frame integration and character extraction filters are applied and the overall recognition results are satisfactory for use in news indexing."
            },
            "venue": {
                "fragments": [],
                "text": "Multimedia Systems"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145820949"
                        ],
                        "name": "T. Pavlidis",
                        "slug": "T.-Pavlidis",
                        "structuredName": {
                            "firstName": "Theodosios",
                            "lastName": "Pavlidis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pavlidis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Instead of using only binary information as most other OCR systems, we extract features for recognition from intensity of an image directly [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 27068580,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bd36aa1fcfb2fc07d34adddab03a5872bf5519b4",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Recognition-of-printed-text-under-realistic-Pavlidis",
            "title": {
                "fragments": [],
                "text": "Recognition of printed text under realistic conditions"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit. Lett."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720965"
                        ],
                        "name": "Jeremiah D. Deng",
                        "slug": "Jeremiah-D.-Deng",
                        "structuredName": {
                            "firstName": "Jeremiah",
                            "lastName": "Deng",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeremiah D. Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40392393"
                        ],
                        "name": "Kwok-Ping Chan",
                        "slug": "Kwok-Ping-Chan",
                        "structuredName": {
                            "firstName": "Kwok-Ping",
                            "lastName": "Chan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kwok-Ping Chan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2119041337"
                        ],
                        "name": "Yinglin Yu",
                        "slug": "Yinglin-Yu",
                        "structuredName": {
                            "firstName": "Yinglin",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yinglin Yu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Early applications of Gabor wavelet to OCR tasks were based on binary features [1, 3-5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17025221,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d672f180ce923a3331a15a5b52b4bf06133a3ac2",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "So far the bottleneck of Chinese recognition, especially handwritten recognition, still lies in the effectiveness of feature-extraction to cater for various distortions and position shifting. In the paper, a novel method is proposed by applying a set of Gabor spatial filters with different directions and spatial frequencies to character images, in an effort to reach the optimum trade-off between feature stability and feature localization. While a classic self-organizing map is used for unsupervised clustering feature codes, a multi-staged LVQ with a fuzzy judgement unit is applied for the final recognition on the feature mapping result.<<ETX>>"
            },
            "slug": "Handwritten-Chinese-character-recognition-using-and-Deng-Chan",
            "title": {
                "fragments": [],
                "text": "Handwritten Chinese character recognition using spatial Gabor filters and self-organizing feature maps"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A novel method is proposed by applying a set of Gabor spatial filters with different directions and spatial frequencies to character images, in an effort to reach the optimum trade-off between feature stability and feature localization."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1st International Conference on Image Processing"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144739319"
                        ],
                        "name": "R. Lienhart",
                        "slug": "R.-Lienhart",
                        "structuredName": {
                            "firstName": "Rainer",
                            "lastName": "Lienhart",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Lienhart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8416045,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0dd1def5778f24c2c5a5f1c114846326e8f86123",
            "isKey": false,
            "numCitedBy": 143,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Efficient indexing and retrieval of digital video is an important aspect of video databases. One powerful index for retrieval is the text appearing in them. It enables content- based browsing. We present our methods for automatic segmentation and recognition of text in digital videos. The algorithms we propose make use of typical characteristics of text in videos in order to enable and enhance segmentation and recognition performance. Especially the inter-frame dependencies of the characters provide new possibilities for their refinement. Then, a straightforward indexing and retrieval scheme is introduced. It is used in the experiments to demonstrate that the proposed text segmentation and text recognition algorithms are suitable for indexing and retrieval of relevant video scenes in and from a video data base. Our experimental results are very encouraging and suggest that these algorithms can be used in video retrieval applications as well as to recognize higher semantics in video."
            },
            "slug": "Automatic-text-recognition-for-video-indexing-Lienhart",
            "title": {
                "fragments": [],
                "text": "Automatic text recognition for video indexing"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The proposed text segmentation and text recognition algorithms are suitable for indexing and retrieval of relevant video scenes in and from a video data base and suggest that they can be used in video retrieval applications as well as to recognize higher semantics in video."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '96"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780236"
                        ],
                        "name": "Y. Hamamoto",
                        "slug": "Y.-Hamamoto",
                        "structuredName": {
                            "firstName": "Yoshihiko",
                            "lastName": "Hamamoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Hamamoto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1798048"
                        ],
                        "name": "S. Uchimura",
                        "slug": "S.-Uchimura",
                        "structuredName": {
                            "firstName": "Shunji",
                            "lastName": "Uchimura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Uchimura"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3215317"
                        ],
                        "name": "K. Masamizu",
                        "slug": "K.-Masamizu",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Masamizu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Masamizu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758524"
                        ],
                        "name": "S. Tomita",
                        "slug": "S.-Tomita",
                        "structuredName": {
                            "firstName": "Shingo",
                            "lastName": "Tomita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Tomita"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Early applications of Gabor wavelet to OCR tasks were based on binary features [1, 3-5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 41069560,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a220c9b4fd1d04633f70f6dd7526f54e1b137302",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for handprinted Chinese character recognition based on Gabor filters is proposed. The Gabor approach to character recognition is intuitively appealing because it is inspired by a multi-channel filtering theory for processing visual information in the early stages of the human visual system. The performance of a character recognition system using Gabor features is demonstrated on the ETL-8 character set. Mental results show that the Gabor features yielded an error rate of 2.4% versus the error rate of 4.4% obtained by using a popular feature extraction method."
            },
            "slug": "Recognition-of-handprinted-Chinese-characters-using-Hamamoto-Uchimura",
            "title": {
                "fragments": [],
                "text": "Recognition of handprinted Chinese characters using Gabor features"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A method for handprinted Chinese character recognition based on Gabor filters is proposed, inspired by a multi-channel filtering theory for processing visual information in the early stages of the human visual system."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115196978"
                        ],
                        "name": "Huiping Li",
                        "slug": "Huiping-Li",
                        "structuredName": {
                            "firstName": "Huiping",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huiping Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3272081"
                        ],
                        "name": "O. Kia",
                        "slug": "O.-Kia",
                        "structuredName": {
                            "firstName": "Omid",
                            "lastName": "Kia",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Kia"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In a video OCR task, text in the foreground is usually uniformly distributed and its resolution can be enhanced by inter-frame information [7, 8, 11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15485643,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f8f5c282dc11937d29183b955dc3e4fbb677571b",
            "isKey": false,
            "numCitedBy": 652,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": "Text that appears in a scene or is graphically added to video can provide an important supplemental source of index information as well as clues for decoding the video's structure and for classification. In this work, we present algorithms for detecting and tracking text in digital video. Our system implements a scale-space feature extractor that feeds an artificial neural processor to detect text blocks. Our text tracking scheme consists of two modules: a sum of squared difference (SSD)-based module to find the initial position and a contour-based module to refine the position. Experiments conducted with a variety of video sources show that our scheme can detect and track text robustly."
            },
            "slug": "Automatic-text-detection-and-tracking-in-digital-Li-Doermann",
            "title": {
                "fragments": [],
                "text": "Automatic text detection and tracking in digital video"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work presents algorithms for detecting and tracking text in digital video that implements a scale-space feature extractor that feeds an artificial neural processor to detect text blocks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145573734"
                        ],
                        "name": "F. Lebourgeois",
                        "slug": "F.-Lebourgeois",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Lebourgeois",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Lebourgeois"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 29939979,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0a8754ab68589b8e893d6962eb92c56300ecb764",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper presents a general robust OCR system designed for practical use and suited to unconstrained gray-level images grabbed from a CCD camera. The system works with minimum assumptions on font, text location, size, color and the background scene. The text blocks localization in complex scenes using a specific filter which enhances any text from the background without binarization. A special stage is designed to separate characters, even touched by using gray-level information. The authors also extract gray-level features which make the algorithm more reliable, in particular under poor printing conditions or bad contrast digitization."
            },
            "slug": "Robust-multifont-OCR-system-from-gray-level-images-Lebourgeois",
            "title": {
                "fragments": [],
                "text": "Robust multifont OCR system from gray level images"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "The paper presents a general robust OCR system designed for practical use and suited to unconstrained gray-level images grabbed from a CCD camera, with minimum assumptions on font, text location, size, color and the background scene."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth International Conference on Document Analysis and Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34340513"
                        ],
                        "name": "H. Szu",
                        "slug": "H.-Szu",
                        "structuredName": {
                            "firstName": "Harold",
                            "lastName": "Szu",
                            "middleNames": [],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Szu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2341494"
                        ],
                        "name": "B. Telfer",
                        "slug": "B.-Telfer",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Telfer",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Telfer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116497553"
                        ],
                        "name": "Joseph Garcia",
                        "slug": "Joseph-Garcia",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Garcia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joseph Garcia"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Gabor wavelet has been widely used in many applications, such as data compression [12], face recognition [13], and texture analysis [9], because of its good mathematic properties."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 37124862,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8dea180f96d3076f00b8178ed91a0373babc7ea2",
            "isKey": false,
            "numCitedBy": 90,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Wavelet-transforms-and-neural-networks-for-and-Szu-Telfer",
            "title": {
                "fragments": [],
                "text": "Wavelet transforms and neural networks for compression and recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780236"
                        ],
                        "name": "Y. Hamamoto",
                        "slug": "Y.-Hamamoto",
                        "structuredName": {
                            "firstName": "Yoshihiko",
                            "lastName": "Hamamoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Hamamoto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1798048"
                        ],
                        "name": "S. Uchimura",
                        "slug": "S.-Uchimura",
                        "structuredName": {
                            "firstName": "Shunji",
                            "lastName": "Uchimura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Uchimura"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49887935"
                        ],
                        "name": "M. Watanabe",
                        "slug": "M.-Watanabe",
                        "structuredName": {
                            "firstName": "Masanori",
                            "lastName": "Watanabe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Watanabe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069468028"
                        ],
                        "name": "Tetsuya Yasuda",
                        "slug": "Tetsuya-Yasuda",
                        "structuredName": {
                            "firstName": "Tetsuya",
                            "lastName": "Yasuda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tetsuya Yasuda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758524"
                        ],
                        "name": "S. Tomita",
                        "slug": "S.-Tomita",
                        "structuredName": {
                            "firstName": "Shingo",
                            "lastName": "Tomita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Tomita"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 46502466,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "95182732fe2556e3b1b841134830747b5846e07a",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We study a Gabor filter-based feature extraction method for handwritten numeral character recognition. The performance of the Gabor filter-based method is demonstrated on the ETL-1 database. Experimental results suggest that the Gabor filter-based method should be considered in recognition of handwritten numeric characters."
            },
            "slug": "Recognition-of-handwritten-numerals-using-Gabor-Hamamoto-Uchimura",
            "title": {
                "fragments": [],
                "text": "Recognition of handwritten numerals using Gabor features"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "Experimental results suggest that the Gabor filter-based method should be considered in recognition of handwritten numeric characters."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 13th International Conference on Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764131"
                        ],
                        "name": "R. Mehrotra",
                        "slug": "R.-Mehrotra",
                        "structuredName": {
                            "firstName": "Rajiv",
                            "lastName": "Mehrotra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mehrotra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697423"
                        ],
                        "name": "K. Namuduri",
                        "slug": "K.-Namuduri",
                        "structuredName": {
                            "firstName": "Kamesh",
                            "lastName": "Namuduri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Namuduri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144735955"
                        ],
                        "name": "N. Ranganathan",
                        "slug": "N.-Ranganathan",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Ranganathan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ranganathan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 33886049,
            "fieldsOfStudy": [
                "Engineering",
                "Computer Science"
            ],
            "id": "5ac53aba05c24af6d00e4eed7c54b5f7ad9eb760",
            "isKey": false,
            "numCitedBy": 344,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Gabor-filter-based-edge-detection-Mehrotra-Namuduri",
            "title": {
                "fragments": [],
                "text": "Gabor filter-based edge detection"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 105
                            }
                        ],
                        "text": "Gabor wavelet has been widely used in many applications, such as data compression [12], face recognition [13], and texture analysis [9], because of its good mathematic properties."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 30523165,
            "fieldsOfStudy": [],
            "id": "6f01963039d0a921b1930b4563d1601ff36b971f",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face Recognition by Elastic Bunch Graph Matching"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Multifont OCR System from Gray Level Image"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of 4 ICDAR,"
            },
            "year": 1997
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 1,
            "methodology": 7
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 15,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/A-robust-approach-for-recognition-of-text-embedded-Zhang-Chen/9b2b1e9755b1ff1fa2df74bd53212e8f0c0113fb?sort=total-citations"
}