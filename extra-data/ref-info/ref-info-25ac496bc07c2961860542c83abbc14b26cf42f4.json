{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11941549"
                        ],
                        "name": "J. Ruppert",
                        "slug": "J.-Ruppert",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Ruppert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ruppert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 64
                            }
                        ],
                        "text": "Ruppert\u2019s algorithm for two-dimensional quality mesh generation [15] is perhaps the first theoretically guaranteed meshing algorithm to be truly satisfactory in practice."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 220
                            }
                        ],
                        "text": ") If some PSLGs do not have quality triangulations, what are the implications for shielding? Triangle implements a variant of shielding known as \u201cmodified segment splitting using concentric circular shells\u201d (see Ruppert [15] for details), which is generally effective in practice for PSLGs that have small angles greater than 5 , and often for smaller angles."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 62
                            }
                        ],
                        "text": "The third stage of the algorithm, which diverges from Ruppert [15], is to remove triangles from concavities and holes (Figure 8)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 8
                            }
                        ],
                        "text": "Ruppert [15] proves that this procedure halts for an angle constraint of up to 20:7 ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10264176,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "70b8e80936ab6c393d12cc2d9c6026f19d420a2a",
            "isKey": true,
            "numCitedBy": 788,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a simple new algorithm for triangulating polygons and planar straightline graphs, It provides \"shape\" and \"size\" guarantees: ?All triangles have a bounded aspect ratio.?The number of triangles is within a constant factor of optimal. Such \"quality\" triangulations are desirable as meshes for the finite element method, in which the running time generally increases with the number of triangles, and where the convergence and stability may be hurt by very skinny triangles. The technique we use-successive refinement of a Delaunay triangulation-extends a mesh generation technique of Chew by allowing triangles of varying sizes. Compared with previous quadtree-based algorithms for quality mesh generation, the Delaunay refinement approach is much simpler and generally produces meshes with fewer triangles. We also discuss an implementation of the algorithm and evaluate its performance on a variety of inputs."
            },
            "slug": "A-Delaunay-Refinement-Algorithm-for-Quality-Mesh-Ruppert",
            "title": {
                "fragments": [],
                "text": "A Delaunay Refinement Algorithm for Quality 2-Dimensional Mesh Generation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Compared with previous quadtree-based algorithms for quality mesh generation, the Delaunay refinement approach is much simpler and generally produces meshes with fewer triangles."
            },
            "venue": {
                "fragments": [],
                "text": "J. Algorithms"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693008"
                        ],
                        "name": "M. Bern",
                        "slug": "M.-Bern",
                        "structuredName": {
                            "firstName": "Marshall",
                            "lastName": "Bern",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bern"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719358"
                        ],
                        "name": "D. Eppstein",
                        "slug": "D.-Eppstein",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Eppstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Eppstein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14829229,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "323dc0453e5de1c904fb238162d22809d9275327",
            "isKey": false,
            "numCitedBy": 295,
            "numCiting": 211,
            "paperAbstract": {
                "fragments": [],
                "text": "We survey the computational geometry relevant to nite element mesh generation. We especially focus on optimal triangulations of geometric domains in two-and three-dimensions. An optimal triangulation is a partition of the domain into triangles or tetrahedra, that is best according to some criterion that measures the size, shape, or number of triangles. We discuss algorithms both for the optimization of triangulations on a xed set of vertices and for the placement of new vertices (Steiner points). We brieey survey the heuristic algorithms used in some practical mesh generators."
            },
            "slug": "MESH-GENERATION-AND-OPTIMAL-TRIANGULATION-Bern-Eppstein",
            "title": {
                "fragments": [],
                "text": "MESH GENERATION AND OPTIMAL TRIANGULATION"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This work surveys the computational geometry relevant to night element mesh generation and discusses algorithms both for the optimization of triangulations on a xed set of vertices and for the placement of new vertices (Steiner points)."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144543680"
                        ],
                        "name": "L. Chew",
                        "slug": "L.-Chew",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Chew",
                            "middleNames": [
                                "Paul"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Chew"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 6
                            }
                        ],
                        "text": "(Chew [3] independently developed a similar algo-"
                    },
                    "intents": []
                }
            ],
            "corpusId": 13153569,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c79ae0af0d1cc663e50d3f443639569c02afba1b",
            "isKey": false,
            "numCitedBy": 491,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "For several commonly-used solution techniques for partial differential equations, the first step is to divide the problem region into simply-shaped elements, creating a mesh. We present a technique for creating high-quality triangular meshes for regions on curved surfaces. This technique is an extension of previous methods we developed for regions in the plane. For both flat and curved surfaces, the resulting meshes are guaranteed to exhibit the following properties: (1) internal and external boundaries are respected, (2) element shapes are guaranteed\u2014all elements are triangles with angles between 30 and 120 degrees (with the exception of badly shaped elements that may be required by the specified boundary), and (3) element density can be controlled, producing small elements in \u201cinteresting\u201d areas and large elements elsewhere. An additional contribution of this paper is the development of a practical generalization of Delaunay triangulation to curved surfaces."
            },
            "slug": "Guaranteed-quality-mesh-generation-for-curved-Chew",
            "title": {
                "fragments": [],
                "text": "Guaranteed-quality mesh generation for curved surfaces"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper presents a technique for creating high-quality triangular meshes for regions on curved surfaces, an extension of previous methods developed for regions in the plane."
            },
            "venue": {
                "fragments": [],
                "text": "SCG '93"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50549451"
                        ],
                        "name": "Peter Su",
                        "slug": "Peter-Su",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Su",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Su"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2483279"
                        ],
                        "name": "R. Drysdale",
                        "slug": "R.-Drysdale",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Drysdale",
                            "middleNames": [
                                "L.",
                                "Scot"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Drysdale"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 97
                            }
                        ],
                        "text": "The sweepline and incremental Delaunay triangulation implementations compared by Su and Drysdale [18] each use some variant of uniform bucketing to locate points."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 21
                            }
                        ],
                        "text": ") As Su and Drysdale [18] also found, the divide-and-conquer algorithm is fastest, with the sweepline algorithm second."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 126
                            }
                        ],
                        "text": "There are many Delaunay triangulation algorithms, some of which are surveyed and evaluated by Fortune [7] and Su and Drysdale [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 173
                            }
                        ],
                        "text": "Fortune\u2019s own implementation, available from Netlib, uses bucketing to perform both these functions; hence, an O(n logn) running time is not guaranteed, and Su and Drysdale [18] found that the original implementation exhibitsO(n3=2) performance on uniform random point sets."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2417287,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "48f2ac220c4f1e097e51493989b52d2a8027cfac",
            "isKey": true,
            "numCitedBy": 169,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an experimental comparison of a number of different algorithms for computing the Deluanay triangulation. The algorithms examined are: Dwyer\u2019s divide and conquer algorithm, Fortune\u2019s sweepline algorithm, several versions of the incremental algorithm (including one by Ohya, Iri, and Murota, a new bucketing-based algorithm described in this paper, and Devillers\u2019s version of a Delaunay-tree based algorithm that appears in LEDA), an algorithm that incrementally adds a correct Delaunay triangle adjacent to a current triangle in a manner similar to gift wrapping algorithms for convex hulls, and Barber\u2019s convex hull based algorithm. Most of the algorithms examined are designed for good performance on uniformly distributed sites. However, we also test implementations of these algorithms on a number of non-uniform distibutions. The experiments go beyond measuring total running time, which tends to be machine-dependent. We also analyze the major high-level primitives that algorithms use and do an experimental analysis of how often implementations of these algorithms perform each operation."
            },
            "slug": "A-comparison-of-sequential-Delaunay-triangulation-Su-Drysdale",
            "title": {
                "fragments": [],
                "text": "A comparison of sequential Delaunay triangulation algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "An experimental comparison of a number of different algorithms for computing the Deluanay triangulation and analyzes the major high-level primitives that algorithms use and does an experimental analysis of how often implementations of these algorithms perform each operation."
            },
            "venue": {
                "fragments": [],
                "text": "SCG '95"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145902418"
                        ],
                        "name": "D. Du",
                        "slug": "D.-Du",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Du",
                            "middleNames": [
                                "Z."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Du"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145175212"
                        ],
                        "name": "F. Hwang",
                        "slug": "F.-Hwang",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Hwang",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hwang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 117939627,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c8ae4803b86a8bbd44e5d7a7ddd73510dbf41841",
            "isKey": false,
            "numCitedBy": 209,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Geometric constraint solving, C.M. Hoffmann computational geometry, B. Chazelle the Exact Computation Paradigm, C. Yap mesh generation and optimal triangulation, M. Bern and D. Eppstein machine proofs of geometry theorems, S.-C. Chou and M. Rathi randomized geometric algorithms, K.L. Clarkson Voronoi diagrams and Delauney triangulations, S. Fortune the state of art on Steiner ratio problems, D.-Z. Du and F. Hwang on the development of quantitative geometry from Pythagoras to Grassmann, W.-Y. Hsiang computational geometry and topological network design, J.M. Smith and P. Winter polar forms and triangular B-spline surfaces, H.P Seidel."
            },
            "slug": "Computing-in-Euclidean-Geometry-Du-Hwang",
            "title": {
                "fragments": [],
                "text": "Computing in Euclidean Geometry"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145064923"
                        ],
                        "name": "C. Lawson",
                        "slug": "C.-Lawson",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Lawson",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lawson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 99
                            }
                        ],
                        "text": "Their results indicate a rough parity in speed among the incremental insertion algorithm of Lawson [11], the divide-and-conquer algorithm of Lee and Schachter [12], and the plane-sweep algorithm of Fortune [6]; however, the"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 92
                            }
                        ],
                        "text": "Their results indicate a rough parity in speed among the incremental insertion algorithm of Lawson [11], the divide-and-conquer algorithm of Lee and Schachter [12], and the plane-sweep algorithm of Fortune [6]; however, the\nSupported in part by the Natural Sciences and Engineering Research Council of Canada under a 1967 Science and Engineering Scholarship and by the National Science Foundation under Grant ASC-9318163.\nimplementations they study were written by different people."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 123
                            }
                        ],
                        "text": "The first is to insert a new vertex corresponding to the midpoint of any segment that does not appear in the mesh, and use Lawson\u2019s incremental insertion algorithm to maintain the Delaunay property."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 121
                            }
                        ],
                        "text": "The fourth stage, and the heart of the algorithm, refines the mesh by inserting additional vertices into the mesh (using Lawson\u2019s algorithm to maintain the Delaunay property) until all constraints on minimum angle and maximum triangle area are met (Figure 9)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 118951457,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "769e6dbad6bb38b60e2c6141c26bc16cf4bd5666",
            "isKey": true,
            "numCitedBy": 720,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Software-for-C1-Surface-Interpolation-Lawson",
            "title": {
                "fragments": [],
                "text": "Software for C1 Surface Interpolation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2204648"
                        ],
                        "name": "Ernst P. M\u00fccke",
                        "slug": "Ernst-P.-M\u00fccke",
                        "structuredName": {
                            "firstName": "Ernst",
                            "lastName": "M\u00fccke",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ernst P. M\u00fccke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939207"
                        ],
                        "name": "Isaac Saias",
                        "slug": "Isaac-Saias",
                        "structuredName": {
                            "firstName": "Isaac",
                            "lastName": "Saias",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Isaac Saias"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144192099"
                        ],
                        "name": "B. Zhu",
                        "slug": "B.-Zhu",
                        "structuredName": {
                            "firstName": "Binhai",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Zhu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 135
                            }
                        ],
                        "text": "Triangle\u2019s incremental insertion algorithm for Delaunay triangulation uses the point location method proposed by M\u00fccke, Saias, and Zhu [14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 112
                            }
                        ],
                        "text": "Triangle\u2019s incremental insertion algorithm for Delaunay triangulation uses the point location method proposed by Mu\u0308cke, Saias, and Zhu [14]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 10002371,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "99910cb99d7df87d0883c07836b66590795a5884",
            "isKey": false,
            "numCitedBy": 184,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper studies the point location problem in Delaunay triangulations without preprocessing and additional storage. The proposed procedure finds the query point by simply \u201cwalking through\u201d the triangulation, after selecting a \u201cgood starting point\u201d by random sampling. The analysis generalizes and extends a recent result for dD 2 dimensions by proving this procedure takes expected time close to O.n 1=.dC1/ / for point location in Delaunay triangulations of n random points indD 3 dimensions. Empirical results in both two and three dimensions show that this procedure is efficient in practice. \u00a9 1999 Elsevier Science B.V. All rights reserved."
            },
            "slug": "Fast-randomized-point-location-without-in-two-and-M\u00fccke-Saias",
            "title": {
                "fragments": [],
                "text": "Fast randomized point location without preprocessing in two- and three-dimensional Delaunay triangulations"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "The proposed procedure finds the query point by simply \u201cwalking through\u201d the triangulation, after selecting a \u201cgood starting point\u201d by random sampling, and generalizes and extends a recent result for dD 2 dimensions by proving this procedure takes expected time close to O."
            },
            "venue": {
                "fragments": [],
                "text": "SCG '96"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2096070"
                        ],
                        "name": "J. Shewchuk",
                        "slug": "J.-Shewchuk",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Shewchuk",
                            "middleNames": [
                                "Richard"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shewchuk"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 9
                            }
                        ],
                        "text": "Shewchuk [16] presents details of the arbitrary precision arithmetic algorithms and the adaptivity scheme, and provides empirical evidence that multiple-stage adaptivity can significantly improve on two-stage adaptivity when difficult point sets are triangulated."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14228241,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7852497d8137c945ccbde22f555d679d526cfd84",
            "isKey": false,
            "numCitedBy": 180,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Fast C implementations of four geometric predicates, the 2D and 3D orientation and incircle tests, are publicly available. Their inputs are ordinary single or double precision floating-point numbers. They owe their speed to two features. First, they employ new fast algorithms for arbitrary precision arithmetic that have a strong advantage over other software techniques in computations that manipulate values of extended but small precision. Second, they are adaptive; their running time depends on the degree of uncertainty of the result, and is usually small. These algorithms work on computers whose floating-point arithmetic uses radix two and exact rounding, including machines that comply with the IEEE 754 floating-point standard. Timings of the predicates, in isolation and embedded in 2D and 3D Delaunay triangulation programs, verify their effectiveness."
            },
            "slug": "Robust-adaptive-floating-point-geometric-predicates-Shewchuk",
            "title": {
                "fragments": [],
                "text": "Robust adaptive floating-point geometric predicates"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "Fast C implementations of four geometric predicates, the 2D and 3D orientation and incircle tests, are publicly available and are used to verify the effectiveness of these algorithms for arbitrary precision arithmetic in computations that manipulate values of extended but small precision."
            },
            "venue": {
                "fragments": [],
                "text": "SCG '96"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430592"
                        ],
                        "name": "S. Mitchell",
                        "slug": "S.-Mitchell",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Mitchell",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mitchell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 9
                            }
                        ],
                        "text": "Mitchell [13] proves that if the triangulation has no angles smaller than , then the ratio b=a has an upper bound of (2 cos )180 = ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13101594,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "eaa088e2759d21728d1c31b9c576a89c477ec90a",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider bounding the cardinality of an arbitrary triangulation with smallest angle {alpha}. We show that if the local feature size (i.e. distance between disjoint vertices or edges) of the triangulation is within a constant factor of the local feature size of the input, then N < O(1/{alpha})M, where N is the cardinality of the triangulation and M is the cardinality of any other triangulation with smallest angle at least {alpha}. Previous results had an O(1/{alpha}{sup 1/{alpha}}) dependence. Our O(1/{alpha}) dependence is tight for input with a large length to height ratio, in which triangles may be oriented along the long dimension."
            },
            "slug": "Cardinality-Bounds-for-Triangulations-with-Bounded-Mitchell",
            "title": {
                "fragments": [],
                "text": "Cardinality Bounds for Triangulations with Bounded Minimum Angle"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The authors' O(1/{alpha}) dependence is tight for input with a large length to height ratio, in which triangles may be oriented along the long dimension."
            },
            "venue": {
                "fragments": [],
                "text": "CCCG"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1798254"
                        ],
                        "name": "S. Fortune",
                        "slug": "S.-Fortune",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Fortune",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Fortune"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Their results indicate a rough parity in speed among the incremental insertion algorithm of Lawson [11], the divide-and-conquer algorithm of Lee and Schachter [12], and the plane-sweep algorithm of Fortune [6]; however, the"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18492940,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "id": "904ffb5d672612af20b5a9dd3ce6d198e46d8ffd",
            "isKey": false,
            "numCitedBy": 749,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a geometric transformation that allows Voronoi diagrams to be computed using a sweepline technique. The transformation is used to obtain simple algorithms for computing the Voronoi diagram of point sites, of line segment sites, and of weighted point sites. All algorithms haveO(n logn) worst-case running time and useO(n) space."
            },
            "slug": "A-sweepline-algorithm-for-Voronoi-diagrams-Fortune",
            "title": {
                "fragments": [],
                "text": "A sweepline algorithm for Voronoi diagrams"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "A geometric transformation is introduced that allows Voronoi diagrams to be computed using a sweepline technique and is used to obtain simple algorithms for computing the Vor onoi diagram of point sites, of line segment sites, and of weighted point sites."
            },
            "venue": {
                "fragments": [],
                "text": "SCG '86"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055593"
                        ],
                        "name": "K. Clarkson",
                        "slug": "K.-Clarkson",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Clarkson",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Clarkson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 101
                            }
                        ],
                        "text": "The goal of improving the speed of correct geometric calculations has received much recent attention [4, 8, 1], but the most promising proposals take integer or rational inputs, often of limited precision."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6881816,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a3520a7d12496abf3f7db4406b05acacc87a0283",
            "isKey": false,
            "numCitedBy": 125,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of evaluating the sign of the determinant of a small matrix aries in many geometric algorithms. Given an n*n matrix A with integer entries, whose columns are all smaller than M in Euclidean norm, the algorithm given evaluates the sign of the determinant det A exactly. The algorithm requires an arithmetic precision of less than 1.5n+2lgM bits. The number of arithmetic operations needed is O(n/sup 3/)+O(n/sup 2/) log OD(A)/ beta , where OD(A) mod det A mod is the product of the lengths of the columns of A, and beta is the number of 'extra' bits of precision, min(lg(1/u)-1.1n-2lgn-2,lgN-lgM-1.5n-1), where u is the roundoff error in approximate arithmetic, and N is the largest representable integer. Since OD(A)<or=M/sup n/, the algorithm requires O(n/sup 3/lgM) time, and O(n/sup 3/) time when beta = Omega (logM).<<ETX>>"
            },
            "slug": "Safe-and-effective-determinant-evaluation-Clarkson",
            "title": {
                "fragments": [],
                "text": "Safe and effective determinant evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The problem of evaluating the sign of the determinant of a small matrix aries in many geometric algorithms, given an n*n matrix A with integer entries, whose columns are all smaller than M in Euclidean norm."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings., 33rd Annual Symposium on Foundations of Computer Science"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721040"
                        ],
                        "name": "D. Sleator",
                        "slug": "D.-Sleator",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Sleator",
                            "middleNames": [
                                "Dominic"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Sleator"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721050"
                        ],
                        "name": "R. Tarjan",
                        "slug": "R.-Tarjan",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Tarjan",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Tarjan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 74
                            }
                        ],
                        "text": "Triangle\u2019s implementation uses a heap as well, and also uses a splay tree [17] to store mesh boundary edges, so that an O(n logn) running time is attained, regardless of the distribution of points."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1165848,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb3c073053d93d6abfef9a9c76ec2c5d7f09c313",
            "isKey": false,
            "numCitedBy": 1299,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "The splay tree, a self-adjusting form of binary search tree, is developed and analyzed. The binary search tree is a data structure for representing tables and lists so that accessing, inserting, and deleting items is easy. On an n-node splay tree, all the standard search tree operations have an amortized time bound of O(log n) per operation, where by \u201camortized time\u201d is meant the time per operation averaged over a worst-case sequence of operations. Thus splay trees are as efficient as balanced trees when total running time is the measure of interest. In addition, for sufficiently long access sequences, splay trees are as efficient, to within a constant factor, as static optimum search trees. The efficiency of splay trees comes not from an explicit structural constraint, as with balanced trees, but from applying a simple restructuring heuristic, called splaying, whenever the tree is accessed. Extensions of splaying give simplified forms of two other data structures: lexicographic or multidimensional search trees and link/cut trees."
            },
            "slug": "Self-adjusting-binary-search-trees-Sleator-Tarjan",
            "title": {
                "fragments": [],
                "text": "Self-adjusting binary search trees"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The splay tree, a self-adjusting form of binary search tree, is developed and analyzed and is found to be as efficient as balanced trees when total running time is the measure of interest."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1798254"
                        ],
                        "name": "S. Fortune",
                        "slug": "S.-Fortune",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Fortune",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Fortune"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690180"
                        ],
                        "name": "C. V. Wyk",
                        "slug": "C.-V.-Wyk",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Wyk",
                            "middleNames": [
                                "J.",
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. V. Wyk"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 101
                            }
                        ],
                        "text": "The goal of improving the speed of correct geometric calculations has received much recent attention [4, 8, 1], but the most promising proposals take integer or rational inputs, often of limited precision."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 20
                            }
                        ],
                        "text": "Fortune and Van Wyk [8] take advantage of the fact that only the sign is needed by using a floating-point filter: the determinant is first evaluated approximately, and only if forward error analysis indicates that the sign of the approximate result cannot be trusted does one use an exact test."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16005197,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6dc3d93316314abdb4c56b9f6ff40238c3cf052",
            "isKey": false,
            "numCitedBy": 176,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We experiment with exact integer arithmetic to implement primitives for geometric algorithms. Naive use of exact arithmetic\u2014either modular or multiprecision integer\u2014increases execution time dramatically over the use of floating-point arithmetic. By combining tuned multiprecision integer arithmetic and a floating-point filter based on interval analysis, we can obtain the effect of exact integer arithmetic at a cost close to that of floating-point arithmetic. We describe an experimental expression compiler that conveniently packages our techniques."
            },
            "slug": "Efficient-exact-arithmetic-for-computational-Fortune-Wyk",
            "title": {
                "fragments": [],
                "text": "Efficient exact arithmetic for computational geometry"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "An experimental expression compiler is described that conveniently packages the effect of exact integer arithmetic at a cost close to that of floating-point arithmetic by combining tuned multiprecision integer arithmetic and a floating- point filter based on interval analysis."
            },
            "venue": {
                "fragments": [],
                "text": "SCG '93"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744254"
                        ],
                        "name": "L. Guibas",
                        "slug": "L.-Guibas",
                        "structuredName": {
                            "firstName": "Leonidas",
                            "lastName": "Guibas",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Guibas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719901"
                        ],
                        "name": "J. Stolfi",
                        "slug": "J.-Stolfi",
                        "structuredName": {
                            "firstName": "Jorge",
                            "lastName": "Stolfi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Stolfi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 28
                            }
                        ],
                        "text": "To preserve the elegance of Guibas and Stolfi\u2019s presentation of the divide-and-conquer algorithm, each triangulation is surrounded with a layer of \u201cghost\u201d triangles, one triangle per convex hull edge."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 38
                            }
                        ],
                        "text": "Triangle was originally written using Guibas and Stolfi\u2019s quad-edge data structure [10] (without the Flip operator), then rewritten using a triangle-based data structure."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 215
                            }
                        ],
                        "text": "Should one choose a data structure that uses a record to represent each edge, or one that uses a record to represent each triangle? Triangle was originally written using Guibas and Stolfi\u2019s quad-edge data structure [10] (without the Flip operator), then rewritten using a triangle-based data structure."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 233,
                                "start": 216
                            }
                        ],
                        "text": "The quad-edge data structure is popular because it is elegant, because it simultaneously represents a graph and its geometric dual (such as a Delaunay triangulation and the corresponding Vorono\u0131\u0308 diagram), and because Guibas and Stolfi give detailed pseudocode for implementing the divide-and-conquer and incremental Delaunay algorithms using quad-edges."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 226,
                                "start": 222
                            }
                        ],
                        "text": "Despite the fundamental differences between the data structures, the quad-edge-based and triangle-based implementations of Triangle are both faithful to the Delaunay triangulation algorithms presented by Guibas and Stolfi [10] (I did not implement a quad-edge sweepline algorithm), and hence offer a fair comparison of the data structures."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 52852815,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "88a4714bbbc59b51709b82843f8d79a8bef6bb4a",
            "isKey": true,
            "numCitedBy": 1164,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "The following problem is discussed: given n points in the plane (the sites) and an arbitrary query point q, find the site that is closest to q. This problem can be solved by constructing the Voronoi diagram of the griven sites and then locating the query point inone of its regions. Two algorithms are given, one that constructs the Voronoi diagram in O(n log n) time, and another that inserts a new sit on O(n) time. Both are based on the use of the Voronoi dual, or Delaunay triangulation, and are simple enough to be of practical value. the simplicity of both algorithms can be attributed to the separation of the geometrical and topological aspects of the problem and to the use of two simple but powerful primitives, a geometric predicate and an operator for manipulating the topology of the diagram. The topology is represented by a new data structure for generalized diagrams, that is, embeddings of graphs in two-dimensional manifolds. This structure represents simultaneously an embedding, its dual, and its mirror image. Furthermore, just two operators are sufficients for building and modifying arbitrary diagrams."
            },
            "slug": "Primitives-for-the-manipulation-of-general-and-the-Guibas-Stolfi",
            "title": {
                "fragments": [],
                "text": "Primitives for the manipulation of general subdivisions and the computation of Voronoi"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "The following problem is discussed: given n points in the plane (the sites) and an arbitrary query point q, find the site that is closest to q, which can be solved by constructing the Voronoi diagram of the griven sites and then locating the query point in one of its regions."
            },
            "venue": {
                "fragments": [],
                "text": "TOGS"
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 0
                            }
                        ],
                        "text": "Fortune\u2019s own implementation, available from Netlib, uses bucketing to perform both these functions; hence, an O(n logn) running time is not guaranteed, and Su and Drysdale [18] found that the original implementation exhibitsO(n3=2) performance on uniform random point sets."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 94
                            }
                        ],
                        "text": "There are many Delaunay triangulation algorithms, some of which are surveyed and evaluated by Fortune [7] and Su and Drysdale [18]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 13
                            }
                        ],
                        "text": "By modifying Fortune\u2019s code to use a heap to store events, they obtained O(n logn) running time and better performance on large point sets (having more than 50,000 points)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 0
                            }
                        ],
                        "text": "Fortune\u2019s sweepline algorithm uses two nontrivial data structures in addition to the triangulation: a priority queue to store events, and a balanced tree data structure to store the sequence of edges on the boundary of the mesh."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 0
                            }
                        ],
                        "text": "Fortune and Van Wyk [8] take advantage of the fact that only the sign is needed by using a floating-point filter: the determinant is first evaluated approximately, and only if forward error analysis indicates that the sign of the approximate result cannot be trusted does one use an exact test."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 198
                            }
                        ],
                        "text": "Their results indicate a rough parity in speed among the incremental insertion algorithm of Lawson [11], the divide-and-conquer algorithm of Lee and Schachter [12], and the plane-sweep algorithm of Fortune [6]; however, the\nSupported in part by the Natural Sciences and Engineering Research Council of Canada under a 1967 Science and Engineering Scholarship and by the National Science Foundation under Grant ASC-9318163.\nimplementations they study were written by different people."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 206
                            }
                        ],
                        "text": "Their results indicate a rough parity in speed among the incremental insertion algorithm of Lawson [11], the divide-and-conquer algorithm of Lee and Schachter [12], and the plane-sweep algorithm of Fortune [6]; however, the"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Sweepline Algorithm for Vorono\u0131\u0308 Diagrams"
            },
            "venue": {
                "fragments": [],
                "text": "Algorithmica 2(2):153\u2013174,"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 40
                            }
                        ],
                        "text": "Consult the survey by Bern and Eppstein [2] for an introduction."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 208920664,
            "fieldsOfStudy": [],
            "id": "ef16146a9089856c04eb81825c808447b6e9789a",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "MESH GENERATION AND OPTIMAL TRIANGULATION"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 74
                            }
                        ],
                        "text": "Triangle\u2019s implementation uses a heap as well, and also uses a splay tree [17] to store mesh boundary edges, so that anO(n logn) running time is attained, regardless of the distribution of points."
                    },
                    "intents": []
                }
            ],
            "corpusId": 4148010,
            "fieldsOfStudy": [],
            "id": "993de2892811b5dc507bbb618a7233cbf7a7f6a8",
            "isKey": false,
            "numCitedBy": 1456,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Journal-of-the-Association-for-Computing-Machinery",
            "title": {
                "fragments": [],
                "text": "Journal of the Association for Computing Machinery"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1961
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 91
                            }
                        ],
                        "text": "A more elaborate point location scheme such as that suggested by Guibas, Knuth, and Sharir [9] could be used (along with randomization of the insertion order) to obtain an expectedO(n logn) triangulation algorithm, but the data structure used for location is likely to take up as much memory as the triangulation itself, and unlikely to surpass the performance of the divide-and-conquer algorithm; hence, I do not intend to pursue it."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 33210077,
            "fieldsOfStudy": [],
            "id": "3b46c9e501d664fbf76c977bb77779cfdce9369d",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Randomized Incremental Construction of Delaunay and Voronoi Diagrams"
            },
            "venue": {
                "fragments": [],
                "text": "ICALP"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fast Randomized Point Location Without Preprocessing in Twoand Three - dimensional Delaunay Triangulations . Proceedings of the Twelfth Annual Symposium on Computational Geometry"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 40
                            }
                        ],
                        "text": "Consult the survey by Bern and Eppstein [2] for an introduction."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Mesh Generation and Optimal Triangulation. Computing in Euclidean Geometry (Ding-Zhu Du and Frank Hwang, editors)"
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes Series on Computing,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "Triangle is freely available on the Web at \u201chttp://www.cs.cmu.edu/ quake/triangle.html\u201d and from Netlib."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Software for C 1 Surface Interpolation"
            },
            "venue": {
                "fragments": [],
                "text": "Software for C 1 Surface Interpolation"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "Triangle is freely available on the Web at \u201chttp://www.cs.cmu.edu/ quake/triangle.html\u201d and from Netlib."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Software for 1 Surface Interpolation"
            },
            "venue": {
                "fragments": [],
                "text": "Software for 1 Surface Interpolation"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 52
                            }
                        ],
                        "text": "Features include user-specified constraints on angles and triangle areas, user-specified holes and concavities, and the economical use of exact arithmetic to improve robustness."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Computing in Euclidean Geometry (Ding-Zhu Du and Frank Hwang"
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes Series on Computing"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 37
                            }
                        ],
                        "text": "Guaranteed-quality meshes (having no small angles) are generated using Ruppert\u2019s Delaunay refinement algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Mesh Generation and Optimal Triangulation Computing in Euclidean Geometry (Ding-Zhu Du and Frank Hwang"
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes Series on Computing World Scientific"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 101
                            }
                        ],
                        "text": "The goal of improving the speed of correct geometric calculations has received much recent attention [4, 8, 1], but the most promising proposals take integer or rational inputs, often of limited precision."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Clarkson.Safe and Effective Determinant Evaluation"
            },
            "venue": {
                "fragments": [],
                "text": "Annual Symposium on Foundations of Computer Science,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": ", Donald E . Knuth , and Micha Sharir . Randomized Incremental Construction of Delaunay and Vorono\u0131\u0308 Diagrams"
            },
            "venue": {
                "fragments": [],
                "text": "Algorithmica"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 5
                            }
                        ],
                        "text": "This paper discusses many of the key implementation decisions, including the choice of triangulation algorithms and data structures, the steps taken to create and refine a mesh, a number of issues that arise in Ruppert\u2019s algorithm, and the use of exact arithmetic."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Sweepline Algorithm for Vorono\u00a8Vorono\u00a8\u0131 Diagrams"
            },
            "venue": {
                "fragments": [],
                "text": "Algorithmica"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Randomized Incremental Construction of Delaunay and Vorono\u00a8Vorono\u00a8\u0131 Diagrams"
            },
            "venue": {
                "fragments": [],
                "text": "Algorithmica"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Guibas and Jorge Stolfi . Primitives for the Manipulation of General Subdivisions and the Computation of Vorono\u0131\u0308 Diagrams"
            },
            "venue": {
                "fragments": [],
                "text": "ACM Transactions on Graphics"
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 13,
            "methodology": 10
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 29,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Triangle:-Engineering-a-2D-Quality-Mesh-Generator-Shewchuk/25ac496bc07c2961860542c83abbc14b26cf42f4?sort=total-citations"
}