{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733733"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This was effectively used in acoustic modeling in hybrid MLP-HMM systems [10] , where the scaled likelihood of a frame given a phone state in an HMM is computed by the posterior probability, P(c|o), scaled by the phone prior probability, P(c)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61370836,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8f613e5481d8d567573b0ffa7b8e1c5b07d33a04",
            "isKey": false,
            "numCitedBy": 194,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors focus on a tutorial description of the hybrid HMM/ANN method. The approach has been applied to large vocabulary continuous speech recognition, and variants are in use by many researchers, The method provides a mechanism for incorporating a range of sources of evidence without strong assumptions about their joint statistics, and may have applicability to much more complex systems that can incorporate deep acoustic and linguistic context. The method is inherently discriminant and conservative of parameters. Despite these potential advantages, the hybrid method has focused on implementing fairly simple systems, which do surprisingly well on large continuous speech recognition tasks, Researchers are only beginning to explore the use of more complex structures with this paradigm. In particular, they are just beginning to look at the connectionist inference of language models (including phonology) from data, which may be required in order to take advantage of locally discriminant probabilities rather than simply translating to likelihoods. Finally, the authors' current intuition is that more advanced versions of the hybrid method can greatly benefit from a perceptual perspective. >"
            },
            "slug": "Continuous-speech-recognition-Morgan-Bourlard",
            "title": {
                "fragments": [],
                "text": "Continuous speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "The authors focus on a tutorial description of the hybrid HMM/ANN method, which provides a mechanism for incorporating a range of sources of evidence without strong assumptions about their joint statistics, and may have applicability to much more complex systems that can incorporate deep acoustic and linguistic context."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Signal Process. Mag."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738798"
                        ],
                        "name": "H. Hermansky",
                        "slug": "H.-Hermansky",
                        "structuredName": {
                            "firstName": "Hynek",
                            "lastName": "Hermansky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hermansky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745455"
                        ],
                        "name": "D. Ellis",
                        "slug": "D.-Ellis",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Ellis",
                            "middleNames": [
                                "P.",
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ellis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109947002"
                        ],
                        "name": "Sangita Sharma",
                        "slug": "Sangita-Sharma",
                        "structuredName": {
                            "firstName": "Sangita",
                            "lastName": "Sharma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sangita Sharma"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "A particular application of this tool over the last few years has been the Tandem approach, as described in [7] and other more recent publications."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "To benefit from the strengths of both MLP-HMM and Gaussian-HMM techniques, the Tandem solution was proposed in 2001, using modified MLP outputs as observations for a Gaussian-HMM [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5807992,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5e9082caea65c76bfd23b8763872804473ee7872",
            "isKey": false,
            "numCitedBy": 805,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Hidden Markov model speech recognition systems typically use Gaussian mixture models to estimate the distributions of decorrelated acoustic feature vectors that correspond to individual subword units. By contrast, hybrid connectionist-HMM systems use discriminatively-trained neural networks to estimate the probability distribution among subword units given the acoustic observations. In this work we show a large improvement in word recognition performance by combining neural-net discriminative feature processing with Gaussian-mixture distribution modeling. By training the network to generate the subword probability posteriors, then using transformations of these estimates as the base features for a conventionally-trained Gaussian-mixture based system, we achieve relative error rate reductions of 35% or more on the multicondition Aurora noisy continuous digits task."
            },
            "slug": "Tandem-connectionist-feature-extraction-for-HMM-Hermansky-Ellis",
            "title": {
                "fragments": [],
                "text": "Tandem connectionist feature extraction for conventional HMM systems"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A large improvement in word recognition performance is shown by combining neural-net discriminative feature processing with Gaussian-mixture distribution modeling."
            },
            "venue": {
                "fragments": [],
                "text": "2000 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings (Cat. No.00CH37100)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108424673"
                        ],
                        "name": "Barry Y. Chen",
                        "slug": "Barry-Y.-Chen",
                        "structuredName": {
                            "firstName": "Barry",
                            "lastName": "Chen",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Barry Y. Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9024683"
                        ],
                        "name": "Q. Zhu",
                        "slug": "Q.-Zhu",
                        "structuredName": {
                            "firstName": "Qifeng",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762744"
                        ],
                        "name": "A. Stolcke",
                        "slug": "A.-Stolcke",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Stolcke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Stolcke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This was applied to the Aurora distributed speech recognition task [2], and later to the EARS conversational telephone recognition task [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15905207,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b941804fca1846b8ce91bd205164806897ee01e",
            "isKey": false,
            "numCitedBy": 53,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Temporal patterns (TRAP) and tandem MLP/HMM approaches incorporate feature streams computed from longer time intervals than the conventional short-time analysis. These methods have been used for challenging small- and medium-vocabulary recognition tasks, such as Aurora and SPINE. Conversational telephone speech recognition is a difficult large-vocabulary task, with current systems giving incorrect output for 20-40% of the words, depending on the system complexity and test set. Training and test times for this problem also tend to be relatively long, making rapid development quite difficult. In this paper we report experiments with a reduced conversational speech task that led to the adoption of a number of engineering decisions for the design of an acoustic front end. We then describe our results with this front end on a full-vocabulary conversational telephone speech task. In both cases the front end yielded significant improvements over the baseline."
            },
            "slug": "Trapping-conversational-speech:-extending-to-speech-Morgan-Chen",
            "title": {
                "fragments": [],
                "text": "Trapping conversational speech: extending TRAP/tandem approaches to conversational telephone speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper reports experiments with a reduced conversational speech task that led to the adoption of a number of engineering decisions for the design of an acoustic front end, and describes the results with this front end on a full-vocabulary conversational telephone speech task."
            },
            "venue": {
                "fragments": [],
                "text": "2004 IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108424673"
                        ],
                        "name": "Barry Y. Chen",
                        "slug": "Barry-Y.-Chen",
                        "structuredName": {
                            "firstName": "Barry",
                            "lastName": "Chen",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Barry Y. Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9024683"
                        ],
                        "name": "Q. Zhu",
                        "slug": "Q.-Zhu",
                        "structuredName": {
                            "firstName": "Qifeng",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The two types of MLP-based features are PLP-MLP and the TRAPs (or HATs) [4], which offer complementary information on the phone class."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15123425,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "22b496b7c63e89b51ca2f905195339e03c9deb46",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Incorporating long-term (500-1000 ms) temporal information using multi-layered perceptrons (MLPs) has improved performance on ASR tasks, especially when used to complement traditional short-term (25-100 ms) features. This paper further studies techniques for incorporating long-term temporal information in the acoustic model by presenting experiments showing: 1) that simply widening acoustic context by using more frames of full band speech energies as input to the MLP is suboptimal compared to a more constrained two-stage approach that first focuses on long-term temporal patterns in each critical band separately and then combines them, 2) that the best two-stage approach studied utilizes hidden activation values of MLPs trained on the log critical band energies (LCBEs) of 51 consecutive frames, and 3) that combining the best two-stage approach with conventional short-term features significantly reduces word error rates on the 2001 NIST Hub-5 conversational telephone speech (CTS) evaluation set with models trained using the Switchboard Corpus."
            },
            "slug": "Learning-long-term-temporal-features-in-LVCSR-using-Chen-Zhu",
            "title": {
                "fragments": [],
                "text": "Learning long-term temporal features in LVCSR using neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Experiments show that combining the best two-stage approach with conventional short-term features significantly reduces word error rates on the 2001 NIST Hub-5 conversational telephone speech (CTS) evaluation set with models trained using the Switchboard Corpus."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065228513"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2213649"
                        ],
                        "name": "C. Wellekens",
                        "slug": "C.-Wellekens",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Wellekens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Wellekens"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "As described in [3] and many other sources, with large enough training data and a large enough MLP, and using 1-of-c binary coded class targets, an MLP can learn the posterior probability of a class given an observation, P(c|o)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14700006,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ee50abb5aff3e5c43a38f24396b9552d593a9ae0",
            "isKey": false,
            "numCitedBy": 420,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "The statistical use of a particular classic form of a connectionist system, the multilayer perceptron (MLP), is described in the context of the recognition of continuous speech. A discriminant hidden Markov model (HMM) is defined, and it is shown how a particular MLP with contextual and extra feedback input units can be considered as a general form of such a Markov model. A link between these discriminant HMMs, trained along the Viterbi algorithm, and any other approach based on least mean square minimization of an error function (LMSE) is established. It is shown theoretically and experimentally that the outputs of the MLP (when trained along the LMSE or the entropy criterion) approximate the probability distribution over output classes conditioned on the input, i.e. the maximum a posteriori probabilities. Results of a series of speech recognition experiments are reported. The possibility of embedding MLP into HMM is described. Relations with other recurrent networks are also explained. >"
            },
            "slug": "Links-Between-Markov-Models-and-Multilayer-Bourlard-Wellekens",
            "title": {
                "fragments": [],
                "text": "Links Between Markov Models and Multilayer Perceptrons"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown theoretically and experimentally that the outputs of the MLP approximate the probability distribution over output classes conditioned on the input, i.e. the maximum a posteriori probabilities."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403992137"
                        ],
                        "name": "M. Reyes-Gomez",
                        "slug": "M.-Reyes-Gomez",
                        "structuredName": {
                            "firstName": "Manuel",
                            "lastName": "Reyes-Gomez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Reyes-Gomez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745455"
                        ],
                        "name": "D. Ellis",
                        "slug": "D.-Ellis",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Ellis",
                            "middleNames": [
                                "P.",
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ellis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "An error analysis of Tandem MLP-based features [ 12 ] showed significant differences from the errors of a system using cepstral features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 52867670,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dcf7469458717e1f31ec4167d00a95e757947390",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "Tandem acoustic modeling consists of taking the outputs of a neural network discriminantly trained to estimate the phone-class posterior probabilities of speech, and using them as the input features of a conventional distribution-modeling Gaussian mixture model (GMM) speech recognizer, thereby employing two acoustic models in tandem. This structure reduces the error rate on the Aurora 2 noisy English digits task in more than 50% compared to the HTK baseline. Even though there are some reasonable hypothesis to explain this improvement, the origins are still unclear. This paper introduces the use of visualization tools for error analysis of some variations of the tandem system. The error behavior is first analyzed using word-level confusion matrices. Posteriorgrams (displays of the variation in time of per-phone posterior probabilities) provide for further analysis. The results of corroborate our previous hypothesis that the gains from tandem modeling arise from the very different training and modeling schemes of the two acoustic models."
            },
            "slug": "Error-visualization-for-tandem-acoustic-modeling-on-Reyes-Gomez-Ellis",
            "title": {
                "fragments": [],
                "text": "Error visualization for tandem acoustic modeling on the Aurora task"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The use of visualization tools for error analysis of some variations of the tandem system are introduced and the results corroborate the previous hypothesis that the gains from tandem modeling arise from the very different training and modeling schemes of the two acoustic models."
            },
            "venue": {
                "fragments": [],
                "text": "2002 IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145895185"
                        ],
                        "name": "M. C. Ben\u00edtez",
                        "slug": "M.-C.-Ben\u00edtez",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Ben\u00edtez",
                            "middleNames": [
                                "Carmen"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. C. Ben\u00edtez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1816892"
                        ],
                        "name": "L. Burget",
                        "slug": "L.-Burget",
                        "structuredName": {
                            "firstName": "Luk\u00e1\u0161",
                            "lastName": "Burget",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Burget"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108424673"
                        ],
                        "name": "Barry Y. Chen",
                        "slug": "Barry-Y.-Chen",
                        "structuredName": {
                            "firstName": "Barry",
                            "lastName": "Chen",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Barry Y. Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144436412"
                        ],
                        "name": "S. Dupont",
                        "slug": "S.-Dupont",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Dupont",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dupont"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2911156"
                        ],
                        "name": "H. Garudadri",
                        "slug": "H.-Garudadri",
                        "structuredName": {
                            "firstName": "Harinath",
                            "lastName": "Garudadri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Garudadri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738798"
                        ],
                        "name": "H. Hermansky",
                        "slug": "H.-Hermansky",
                        "structuredName": {
                            "firstName": "Hynek",
                            "lastName": "Hermansky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hermansky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066975404"
                        ],
                        "name": "P. Jain",
                        "slug": "P.-Jain",
                        "structuredName": {
                            "firstName": "Pratibha",
                            "lastName": "Jain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687763"
                        ],
                        "name": "S. Kajarekar",
                        "slug": "S.-Kajarekar",
                        "structuredName": {
                            "firstName": "Sachin",
                            "lastName": "Kajarekar",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kajarekar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739225"
                        ],
                        "name": "S. Sivadas",
                        "slug": "S.-Sivadas",
                        "structuredName": {
                            "firstName": "Sunil",
                            "lastName": "Sivadas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sivadas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This was applied to the Aurora distributed speech recognition task [ 2 ], and later to the EARS conversational telephone recognition task [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 107404,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "17c2d82c4f40ff8155710d71aa3e8dc86214d586",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes an automatic speech recognition frontend that combines low-level robust ASR feature extraction techniques, and higher-level linear and non-linear feature transformations. The low-level algorithms use data-derived filters, mean and variance normalization of the feature vectors, and dropping of noise frames. The feature vectors are then linearly transformed using Principal Components Analysis (PCA). An Artificial Neural Network (ANN) is also used to compute features that are useful for classification of speech sounds. It is trained for phoneme probability estimation on a large corpus of noisy speech. These transformations lead to two feature streams whose vectors are concatenated and then used for speech recognition. This method was tested on the set of speech corpora used for the \u201cAurora\u201d evaluation. Using the feature stream generated without the ANN yields an overall 41% reduction of the error rate over Mel-Frequency Cepstral Coefficients (MFCC) reference features. Adding the ANN stream further reduces the error rate yielding a 46% reduction over the reference features."
            },
            "slug": "Robust-ASR-front-end-using-spectral-based-and-on-Ben\u00edtez-Burget",
            "title": {
                "fragments": [],
                "text": "Robust ASR front-end using spectral-based and discriminant features: experiments on the Aurora tasks"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "An automatic speech recognition frontend that combines low-level robust ASR feature extraction techniques, and higher-level linear and non-linear feature transformations is described."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40268570"
                        ],
                        "name": "A. J. Robinson",
                        "slug": "A.-J.-Robinson",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Robinson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. J. Robinson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144787400"
                        ],
                        "name": "G. Cook",
                        "slug": "G.-Cook",
                        "structuredName": {
                            "firstName": "Gary",
                            "lastName": "Cook",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cook"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745455"
                        ],
                        "name": "D. Ellis",
                        "slug": "D.-Ellis",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Ellis",
                            "middleNames": [
                                "P.",
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ellis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398481836"
                        ],
                        "name": "E. Fosler-Lussier",
                        "slug": "E.-Fosler-Lussier",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Fosler-Lussier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Fosler-Lussier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086187"
                        ],
                        "name": "S. Renals",
                        "slug": "S.-Renals",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Renals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Renals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116802190"
                        ],
                        "name": "D. A. G. Williams",
                        "slug": "D.-A.-G.-Williams",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Williams",
                            "middleNames": [
                                "A.",
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. A. G. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This inherently discriminant approach worked well for many tasks, and was particularly useful for combinations of features with different statistical properties (e.g., continuous and binary features) [ 13 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1233541,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4eb4c82eb0dfc4f1fb5ebbf76cfad0549dde3d11",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 95,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Connectionist-speech-recognition-of-Broadcast-News-Robinson-Cook",
            "title": {
                "fragments": [],
                "text": "Connectionist speech recognition of Broadcast News"
            },
            "venue": {
                "fragments": [],
                "text": "Speech Commun."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144134771"
                        ],
                        "name": "Hemant Misra",
                        "slug": "Hemant-Misra",
                        "structuredName": {
                            "firstName": "Hemant",
                            "lastName": "Misra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hemant Misra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733733"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38311198"
                        ],
                        "name": "V. Tyagi",
                        "slug": "V.-Tyagi",
                        "structuredName": {
                            "firstName": "Vivek",
                            "lastName": "Tyagi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Tyagi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In practice, we use two types of MLPs and combine MLP outputs using a weighted sum (of probabilities), where the weights are a normalized version of the inverse entropy [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11418185,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "67d255f822c92967fe425e6328a40773626a3f84",
            "isKey": false,
            "numCitedBy": 136,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Classifier performance is often enhanced through combining multiple streams of information. In the context of multi-stream HMM/ANN systems in ASR, a confidence measure widely used in classifier combination is the entropy of the posteriors distribution output from each ANN, which generally increases as classification becomes less reliable. The rule most commonly used is to select the ANN with the minimum entropy. However, this is not necessarily the best way to use entropy in classifier combination. In this article, we test three new entropy based combination rules in a full-combination multi-stream HMM/ANN system for noise robust speech recognition. Best results were obtained by combining all the classifiers having entropy below average using a weighting proportional to their inverse entropy."
            },
            "slug": "New-entropy-based-combination-rules-in-HMM/ANN-ASR-Misra-Bourlard",
            "title": {
                "fragments": [],
                "text": "New entropy based combination rules in HMM/ANN multi-stream ASR"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "Three new entropy based combination rules are tested in a full-combination multi-stream HMM/ANN system for noise robust speech recognition by combining all the classifiers having entropy below average using a weighting proportional to their inverse entropy."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE International Conference on Acoustics, Speech, and Signal Processing, 2003. Proceedings. (ICASSP '03)."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740397"
                        ],
                        "name": "M. Gales",
                        "slug": "M.-Gales",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Gales",
                            "middleNames": [
                                "John",
                                "Francis"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gales"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Another approach was to apply a more complicated linear feature transform, HLDA, to search for the best non-trivial feature mapping direction and discard the nuisance dimensions [5][14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "There have been many kinds of linear feature transforms, such as LDA or HLDA [5], that make the transformed feature better for modeling by Gaussian mixtures for an HMM."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8255228,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2b899462b71be626c475c5a372a353de7ec07832",
            "isKey": false,
            "numCitedBy": 633,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "There is normally a simple choice made in the form of the covariance matrix to be used with continuous-density HMMs. Either a diagonal covariance matrix is used, with the underlying assumption that elements of the feature vector are independent, or a full or block-diagonal matrix is used, where all or some of the correlations are explicitly modeled. Unfortunately when using full or block-diagonal covariance matrices there tends to be a dramatic increase in the number of parameters per Gaussian component, limiting the number of components which may be robustly estimated. This paper introduces a new form of covariance matrix which allows a few \"full\" covariance matrices to be shared over many distributions, whilst each distribution maintains its own \"diagonal\" covariance matrix. In contrast to other schemes which have hypothesized a similar form, this technique fits within the standard maximum-likelihood criterion used for training HMMs. The new form of covariance matrix is evaluated on a large-vocabulary speech-recognition task. In initial experiments the performance of the standard system was achieved using approximately half the number of parameters. Moreover, a 10% reduction in word error rate compared to a standard system can be achieved with less than a 1% increase in the number of parameters and little increase in recognition time."
            },
            "slug": "Semi-tied-covariance-matrices-for-hidden-Markov-Gales",
            "title": {
                "fragments": [],
                "text": "Semi-tied covariance matrices for hidden Markov models"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A new form of covariance matrix which allows a few \"full\" covariance matrices to be shared over many distributions, whilst each distribution maintains its own \"diagonal\" covariancy matrix is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Speech Audio Process."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738798"
                        ],
                        "name": "H. Hermansky",
                        "slug": "H.-Hermansky",
                        "structuredName": {
                            "firstName": "Hynek",
                            "lastName": "Hermansky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hermansky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109947002"
                        ],
                        "name": "Sangita Sharma",
                        "slug": "Sangita-Sharma",
                        "structuredName": {
                            "firstName": "Sangita",
                            "lastName": "Sharma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sangita Sharma"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15276102,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "72f3f68664e27745e8f63fdc6cfd0eb5c37dc844",
            "isKey": false,
            "numCitedBy": 197,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The work proposes a radically di erent set of features for ASR where TempoRAl Patterns of spectral energies are used in place of the conventional spectral patterns. The approach has several inherent advantages, among them robustness to stationary or slowly varying disturbances."
            },
            "slug": "TRAPS-classifiers-of-temporal-patterns-Hermansky-Sharma",
            "title": {
                "fragments": [],
                "text": "TRAPS - classifiers of temporal patterns"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "The work proposes a radically different set of features for ASR where TempoRAl Patterns of spectral energies are used in place of the conventional spectral patterns."
            },
            "venue": {
                "fragments": [],
                "text": "ICSLP"
            },
            "year": 1998
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 1,
            "methodology": 8
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 11,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Tandem-Connectionist-Feature-Extraction-for-Speech-Zhu-Chen/dfae87ca0cf2cc3f3ebd60b0d8a94222eab18812?sort=total-citations"
}