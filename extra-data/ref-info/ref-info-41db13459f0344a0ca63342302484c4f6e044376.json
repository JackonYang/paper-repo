{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724421"
                        ],
                        "name": "Deng Cai",
                        "slug": "Deng-Cai",
                        "structuredName": {
                            "firstName": "Deng",
                            "lastName": "Cai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Deng Cai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1911562"
                        ],
                        "name": "Shipeng Yu",
                        "slug": "Shipeng-Yu",
                        "structuredName": {
                            "firstName": "Shipeng",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shipeng Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2259699"
                        ],
                        "name": "Ji-Rong Wen",
                        "slug": "Ji-Rong-Wen",
                        "structuredName": {
                            "firstName": "Ji-Rong",
                            "lastName": "Wen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ji-Rong Wen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712167"
                        ],
                        "name": "Wei-Ying Ma",
                        "slug": "Wei-Ying-Ma",
                        "structuredName": {
                            "firstName": "Wei-Ying",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Ying Ma"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13007604,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "84372852886ddcb49e9adf9c5facf53e1bde9696",
            "isKey": false,
            "numCitedBy": 408,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "A new web content structure based on visual representation is proposed in this paper. Many web applications such as information retrieval, information extraction and automatic page adaptation can benefit from this structure. This paper presents an automatic top-down, tag-tree independent approach to detect web content structure. It simulates how a user understands web layout structure based on his visual perception. Comparing to other existing techniques, our approach is independent to underlying documentation representation such as HTML and works well even when the HTML structure is far different from layout structure. Experiments show satisfactory results."
            },
            "slug": "Extracting-Content-Structure-for-Web-Pages-Based-on-Cai-Yu",
            "title": {
                "fragments": [],
                "text": "Extracting Content Structure for Web Pages Based on Visual Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper presents an automatic top-down, tag-tree independent approach to detect web content structure that simulates how a user understands web layout structure based on his visual perception."
            },
            "venue": {
                "fragments": [],
                "text": "APWeb"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075930761"
                        ],
                        "name": "Fatima Ashraf",
                        "slug": "Fatima-Ashraf",
                        "structuredName": {
                            "firstName": "Fatima",
                            "lastName": "Ashraf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fatima Ashraf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732445"
                        ],
                        "name": "Tansel \u00d6zyer",
                        "slug": "Tansel-\u00d6zyer",
                        "structuredName": {
                            "firstName": "Tansel",
                            "lastName": "\u00d6zyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tansel \u00d6zyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144451975"
                        ],
                        "name": "R. Alhajj",
                        "slug": "R.-Alhajj",
                        "structuredName": {
                            "firstName": "Reda",
                            "lastName": "Alhajj",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Alhajj"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15800539,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "70177e710305c7b996b0872b857132bfa65b9737",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "In the past few years, there has been an exponential increase in the amount of information available on the World Wide Web. This plethora of information can be extremely beneficial for users. However, the amount of human intervention that is currently required for this is inconvenient. Information extraction (IE) systems try to solve this problem by making the task as automatic as possible. Most of the existing approaches, however, require user feedback in one form or another during the extraction. This paper proposes a system that employs clustering techniques for automatic IE from HTML documents containing semistructured data. Using domain-specific information provided by the user, the proposed system parses and tokenizes the data from an HTML document, partitions it into clusters containing similar elements, and estimates an extraction rule based on the pattern of occurrence of data tokens. The extraction rule is then used to refine clusters, and finally, the output is reported. We employed a multiobjective genetic-algorithm-based clustering approach in the process; it is capable of finding the number of clusters and the most natural clustering. The proposed approach is tested by conducting experiments on a number of Web sites from different domains. To demonstrate the effectiveness of this approach, the results of the experiments are tested against those reported in the literature, and prove comparable."
            },
            "slug": "Employing-Clustering-Techniques-for-Automatic-From-Ashraf-\u00d6zyer",
            "title": {
                "fragments": [],
                "text": "Employing Clustering Techniques for Automatic Information Extraction From HTML Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A system that employs clustering techniques for automatic IE from HTML documents containing semistructured data using a multiobjective genetic-algorithm-based clustering approach, capable of finding the number of clusters and the most natural clustering."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2545727"
                        ],
                        "name": "T. S. Jayram",
                        "slug": "T.-S.-Jayram",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Jayram",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. S. Jayram"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3252167"
                        ],
                        "name": "R. Krishnamurthy",
                        "slug": "R.-Krishnamurthy",
                        "structuredName": {
                            "firstName": "Rajasekar",
                            "lastName": "Krishnamurthy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Krishnamurthy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49317498"
                        ],
                        "name": "S. Raghavan",
                        "slug": "S.-Raghavan",
                        "structuredName": {
                            "firstName": "Sriram",
                            "lastName": "Raghavan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Raghavan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066721"
                        ],
                        "name": "Shivakumar Vaithyanathan",
                        "slug": "Shivakumar-Vaithyanathan",
                        "structuredName": {
                            "firstName": "Shivakumar",
                            "lastName": "Vaithyanathan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shivakumar Vaithyanathan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2692987"
                        ],
                        "name": "Huaiyu Zhu",
                        "slug": "Huaiyu-Zhu",
                        "structuredName": {
                            "firstName": "Huaiyu",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huaiyu Zhu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18293364,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aa1688f979263e984ff007d5415d0759b424f75a",
            "isKey": false,
            "numCitedBy": 118,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "TheAVATAR Information Extraction System ( IES) at the IBM Almaden Research Center enables highprecision, rule-based, information extraction from text-documents. Draw ing from our experience we propose the use of probabilistic database techniques as the formal under pi nings of information extraction systems so as to maintain high precision while increasing recall. This involve s building a framework where rule-based annotators can be mapped to queries in a databas e system. We use examples from AVATAR IES to describe the challenges in achieving this goal. Finally, we show that derivin g precision estimates in such a database system presents a significant challe nge for probabilistic database systems."
            },
            "slug": "Avatar-Information-Extraction-System-Jayram-Krishnamurthy",
            "title": {
                "fragments": [],
                "text": "Avatar Information Extraction System"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work proposes the use of probabilistic database techniques as the formal under pi nings of information extraction systems so as to maintain high precision while increasing recall, and shows that derivin g precision estimates in such a database system presents a significant challenge for probabilism database systems."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Data Eng. Bull."
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152180024"
                        ],
                        "name": "Jianying Hu",
                        "slug": "Jianying-Hu",
                        "structuredName": {
                            "firstName": "Jianying",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianying Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32225756"
                        ],
                        "name": "R. Kashi",
                        "slug": "R.-Kashi",
                        "structuredName": {
                            "firstName": "Ramanujan",
                            "lastName": "Kashi",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kashi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2859740"
                        ],
                        "name": "G. Wilfong",
                        "slug": "G.-Wilfong",
                        "structuredName": {
                            "firstName": "Gordon",
                            "lastName": "Wilfong",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wilfong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 85
                            }
                        ],
                        "text": "This does not require OCR and is largely similar to the methods proposed by Hu et al.(12) For a better understanding, Figure 4 demonstrates the \u2217http://lucene."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 89
                            }
                        ],
                        "text": "Applying layout-based methods to production document images has been studied by Hu et al.(12) They present a template detection method based on page segmentation in text blocks and white space blocks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14535685,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8efc295011e191d4830d0f066e0c8d06a9631b15",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes features and methods for document image comparison and classification at the spatial layout level. The methods are useful for visual similarity based document retrieval as well as fast algorithms for initial document type classification without OCR. A novel feature set called interval encoding is introduced to capture elements of spatial layout. This feature set encodes region layout information in fixed-length vectors by capturing structural characteristics of the image. These fixed-length vectors are then compared to each other through a Manhattan distance computation for fast page layout comparison. The paper describes experiments and results to rank-order a set of document pages in terms of their layout similarity to a test document. We also demonstrate the usefulness of the features derived from interval coding in a hidden Markov model based page layout classification system that is trainable and extendible. The methods described in the paper can be used in various document retrieval tasks including visual similarity based retrieval, categorization and information extraction."
            },
            "slug": "Comparison-and-Classification-of-Documents-Based-on-Hu-Kashi",
            "title": {
                "fragments": [],
                "text": "Comparison and Classification of Documents Based on Layout Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The usefulness of the features derived from interval coding in a hidden Markov model based page layout classification system that is trainable and extendible are demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "Information Retrieval"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2317049"
                        ],
                        "name": "D. Narayanan",
                        "slug": "D.-Narayanan",
                        "structuredName": {
                            "firstName": "Dushyanth",
                            "lastName": "Narayanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Narayanan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2305719"
                        ],
                        "name": "Eno Thereska",
                        "slug": "Eno-Thereska",
                        "structuredName": {
                            "firstName": "Eno",
                            "lastName": "Thereska",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eno Thereska"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728318"
                        ],
                        "name": "A. Ailamaki",
                        "slug": "A.-Ailamaki",
                        "structuredName": {
                            "firstName": "Anastasia",
                            "lastName": "Ailamaki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ailamaki"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17980616,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fc1d99feacb6ce19faf06e9790ee0fe14231b02d",
            "isKey": false,
            "numCitedBy": 103,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The AVATAR Information Extraction System (IES) at the IBM Almaden Research Center enables highprecision, rule-based, information extraction from text-documents. Drawing from our experience we propose the use of probabilistic database techniques as the formal underpinnings of information extraction systems so as to maintain high precision while increasing recall. This involves building a framework where rule-based annotators can be mapped to queries in a database system. We use examples from AVATAR IES to describe the challenges in achieving this goal. Finally, we show that deriving precision estimates in such a database system presents a significant challenge for probabilistic database systems."
            },
            "slug": "Challenges-inbuilding-a-DBMS-Resource-Advisor-Narayanan-Thereska",
            "title": {
                "fragments": [],
                "text": "Challenges inbuilding a DBMS Resource Advisor"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work proposes the use of probabilistic database techniques as the formal underpinnings of information extraction systems so as to maintain high precision while increasing recall, and builds a framework where rule-based annotators can be mapped to queries in a database system."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Data Eng. Bull."
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1791339"
                        ],
                        "name": "Valter Crescenzi",
                        "slug": "Valter-Crescenzi",
                        "structuredName": {
                            "firstName": "Valter",
                            "lastName": "Crescenzi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Valter Crescenzi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785690"
                        ],
                        "name": "G. Mecca",
                        "slug": "G.-Mecca",
                        "structuredName": {
                            "firstName": "Giansalvatore",
                            "lastName": "Mecca",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Mecca"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796590"
                        ],
                        "name": "P. Merialdo",
                        "slug": "P.-Merialdo",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Merialdo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Merialdo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 80
                            }
                        ],
                        "text": "Examples for document group based methods are InfoDiscoverer(10) and RoadRunner.(11) Both research activities process web pages by comparing their HTML structure against each other."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 46
                            }
                        ],
                        "text": "Examples for document group based methods are InfoDiscoverer10 and RoadRunner.11 Both research activities process web pages by comparing their HTML structure against each other."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15075203,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3dd1f9f7795b31493d98d9f260d37aad07550f6e",
            "isKey": false,
            "numCitedBy": 1157,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper investigates techniques for extracting data from HTML sites through the use of automatically generated wrappers. To automate the wrapper generation and the data extraction process, the paper develops a novel technique to compare HTML pages and generate a wrapper based on their similarities and dierences. Experimental results on real-life data-intensive Web sites confirm the feasibility of the approach."
            },
            "slug": "RoadRunner:-Towards-Automatic-Data-Extraction-from-Crescenzi-Mecca",
            "title": {
                "fragments": [],
                "text": "RoadRunner: Towards Automatic Data Extraction from Large Web Sites"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A novel technique to compare HTML pages and generate a wrapper based on their similarities and dierences is developed, which confirms the feasibility of the approach on real-life data-intensive Web sites."
            },
            "venue": {
                "fragments": [],
                "text": "VLDB"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1923461"
                        ],
                        "name": "Shian-Hua Lin",
                        "slug": "Shian-Hua-Lin",
                        "structuredName": {
                            "firstName": "Shian-Hua",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shian-Hua Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143608739"
                        ],
                        "name": "Jan-Ming Ho",
                        "slug": "Jan-Ming-Ho",
                        "structuredName": {
                            "firstName": "Jan-Ming",
                            "lastName": "Ho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jan-Ming Ho"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10504461,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1a6834f7c86a80a70d21c5e8094c3ade36b7c908",
            "isKey": false,
            "numCitedBy": 409,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a new approach to discover informative contents from a set of tabular documents (or Web pages) of a Web site. Our system, InfoDiscoverer, first partitions a page into several content blocks according to HTML tag  in a Web page. Based on the occurrence of the features (terms) in the set of pages, it calculates entropy value of each feature. According to the entropy value of each feature in a content block, the entropy value of the block is defined. By analyzing the information measure, we propose a method to dynamically select the entropy-threshold that partitions blocks into either informative or redundant. Informative content blocks are distinguished parts of the page, whereas redundant content blocks are common parts. Based on the answer set generated from 13 manually tagged news Web sites with a total of 26,518 Web pages, experiments show that both recall and precision rates are greater than 0.956. That is, using the approach, informative blocks (news articles) of these sites can be automatically separated from semantically redundant contents such as advertisements, banners, navigation panels, news categories, etc. By adopting InfoDiscoverer as the preprocessor of information retrieval and extraction applications, the retrieval and extracting precision will be increased, and the indexing size and extracting complexity will also be reduced."
            },
            "slug": "Discovering-informative-content-blocks-from-Web-Lin-Ho",
            "title": {
                "fragments": [],
                "text": "Discovering informative content blocks from Web documents"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "By adopting InfoDiscoverer as the preprocessor of information retrieval and extraction applications, the retrieval and extracting precision will be increased, and the indexing size and extracting complexity will also be reduced."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763321"
                        ],
                        "name": "E. Saund",
                        "slug": "E.-Saund",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Saund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Saund"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7736275,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e7323009ab2cf70fc6e809489825d427faa90e60",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "The Field of Document Recognition is bipolar. On one end lies the excellent work of academic institutions engaging in original research on scientifically interesting topics. On the other end lies the document recognition industry which services needs for high-volume data capture for transaction and back-office applications. These realms seldom meet, yet the need is great to address technical hurdles for practical problems using modern approaches from the Document Recognition, Computer Vision, and Machine Learning disciplines. We reflect on three categories of problems we have encountered which are both scientifically challenging and of high practical value. These are Doctype Classification, Functional Role Labeling, and Document Sets. Doctype Classification asks, \"What is the type of page I am looking at?\" Functional Role Labeling asks, \"What is the status of text and graphical elements in a model of document structure?\" Document Sets asks, \"How are pages and their contents related to one another?\" Each of these has ad hoc engineering approaches that provide 40-80% solutions, and each of them begs for a deeply grounded formulation both to provide understanding and to attain the remaining 20-60% of practical value. The practical need is not purely technical but also depends on the user experience in application setup and configuration, and in collection and groundtruthing of sample documents. The challenge therefore extends beyond the science behind document image recognition and into user interface and user experience design."
            },
            "slug": "Scientific-challenges-underlying-production-Saund",
            "title": {
                "fragments": [],
                "text": "Scientific challenges underlying production document processing"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The challenge therefore extends beyond the science behind document image recognition and into user interface and user experience design."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145077269"
                        ],
                        "name": "F. Sebastiani",
                        "slug": "F.-Sebastiani",
                        "structuredName": {
                            "firstName": "Fabrizio",
                            "lastName": "Sebastiani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Sebastiani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3091,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b20af22b0734757d9ead382b201a65f9dd637cc",
            "isKey": false,
            "numCitedBy": 8449,
            "numCiting": 224,
            "paperAbstract": {
                "fragments": [],
                "text": "The automated categorization (or classification) of texts into predefined categories has witnessed a booming interest in the last 10 years, due to the increased availability of documents in digital form and the ensuing need to organize them. In the research community the dominant approach to this problem is based on machine learning techniques: a general inductive process automatically builds a classifier by learning, from a set of preclassified documents, the characteristics of the categories. The advantages of this approach over the knowledge engineering approach (consisting in the manual definition of a classifier by domain experts) are a very good effectiveness, considerable savings in terms of expert labor power, and straightforward portability to different domains. This survey discusses the main approaches to text categorization that fall within the machine learning paradigm. We will discuss in detail issues pertaining to three different problems, namely, document representation, classifier construction, and classifier evaluation."
            },
            "slug": "Machine-learning-in-automated-text-categorization-Sebastiani",
            "title": {
                "fragments": [],
                "text": "Machine learning in automated text categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This survey discusses the main approaches to text categorization that fall within the machine learning paradigm and discusses in detail issues pertaining to three different problems, namely, document representation, classifier construction, and classifier evaluation."
            },
            "venue": {
                "fragments": [],
                "text": "CSUR"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153824195"
                        ],
                        "name": "Li Zhang",
                        "slug": "Li-Zhang",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144455843"
                        ],
                        "name": "Yue Pan",
                        "slug": "Yue-Pan",
                        "structuredName": {
                            "firstName": "Yue",
                            "lastName": "Pan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yue Pan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117881943"
                        ],
                        "name": "Tong Zhang",
                        "slug": "Tong-Zhang",
                        "structuredName": {
                            "firstName": "Tong",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tong Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8491161,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "422c4074b54172ce08e416eaea89fe0bba2bd9bb",
            "isKey": false,
            "numCitedBy": 53,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we study the problem of finding most topical named entities among all entities in a document, which we refer to as focused named entity recognition. We show that these focused named entities are useful for many natural language processing applications, such as document summarization, search result ranking, and entity detection and tracking. We propose a statistical model for focused named entity recognition by converting it into a classification problem. We then study the impact of various linguistic features and compare a number of classification algorithms. From experiments on an annotated Chinese news corpus, we demonstrate that the proposed method can achieve near human-level accuracy."
            },
            "slug": "Focused-named-entity-recognition-using-machine-Zhang-Pan",
            "title": {
                "fragments": [],
                "text": "Focused named entity recognition using machine learning"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A statistical model for focused named entity recognition is proposed by converting it into a classification problem, and the impact of various linguistic features is studied and a number of classification algorithms are compared."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3024630"
                        ],
                        "name": "Hai Leong Chieu",
                        "slug": "Hai-Leong-Chieu",
                        "structuredName": {
                            "firstName": "Hai",
                            "lastName": "Chieu",
                            "middleNames": [
                                "Leong"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hai Leong Chieu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34789794"
                        ],
                        "name": "H. Ng",
                        "slug": "H.-Ng",
                        "structuredName": {
                            "firstName": "Hwee",
                            "lastName": "Ng",
                            "middleNames": [
                                "Tou"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110391587"
                        ],
                        "name": "Yoong Keok Lee",
                        "slug": "Yoong-Keok-Lee",
                        "structuredName": {
                            "firstName": "Yoong",
                            "lastName": "Lee",
                            "middleNames": [
                                "Keok"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoong Keok Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14282973,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "544a0fa1107df1423db05070182f213053003040",
            "isKey": false,
            "numCitedBy": 64,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a learning approach to the scenario template task of information extraction, where information filling one template could come from multiple sentences. When tested on the MUC-4 task, our learning approach achieves accuracy competitive to the best of the MUC-4 systems, which were all built with manually engineered rules. Our analysis reveals that our use of full parsing and state-of-the-art learning algorithms have contributed to the good performance. To our knowledge, this is the first research to have demonstrated that a learning approach to the full-scale information extraction task could achieve performance rivaling that of the knowledge engineering approach."
            },
            "slug": "Closing-the-Gap:-Learning-Based-Information-Methods-Chieu-Ng",
            "title": {
                "fragments": [],
                "text": "Closing the Gap: Learning-Based Information Extraction Rivaling Knowledge-Engineering Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "This is the first research to have demonstrated that a learning approach to the full-scale information extraction task could achieve performance rivaling that of the knowledge engineering approach."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3139133"
                        ],
                        "name": "Razvan C. Bunescu",
                        "slug": "Razvan-C.-Bunescu",
                        "structuredName": {
                            "firstName": "Razvan",
                            "lastName": "Bunescu",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Razvan C. Bunescu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1787006"
                        ],
                        "name": "Ruifang Ge",
                        "slug": "Ruifang-Ge",
                        "structuredName": {
                            "firstName": "Ruifang",
                            "lastName": "Ge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ruifang Ge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108641"
                        ],
                        "name": "Rohit J. Kate",
                        "slug": "Rohit-J.-Kate",
                        "structuredName": {
                            "firstName": "Rohit",
                            "lastName": "Kate",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rohit J. Kate"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1853998"
                        ],
                        "name": "E. Marcotte",
                        "slug": "E.-Marcotte",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Marcotte",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Marcotte"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35679127"
                        ],
                        "name": "A. Ramani",
                        "slug": "A.-Ramani",
                        "structuredName": {
                            "firstName": "Arun",
                            "lastName": "Ramani",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ramani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8075439"
                        ],
                        "name": "Y. W. Wong",
                        "slug": "Y.-W.-Wong",
                        "structuredName": {
                            "firstName": "Yuk",
                            "lastName": "Wong",
                            "middleNames": [
                                "Wah"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. W. Wong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13225477,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "356600aa55214f535f9d43020fe97bbaf6541182",
            "isKey": false,
            "numCitedBy": 428,
            "numCiting": 71,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Comparative-experiments-on-learning-information-for-Bunescu-Ge",
            "title": {
                "fragments": [],
                "text": "Comparative experiments on learning information extractors for proteins and their interactions"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell. Medicine"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145435830"
                        ],
                        "name": "H. Cunningham",
                        "slug": "H.-Cunningham",
                        "structuredName": {
                            "firstName": "Hamish",
                            "lastName": "Cunningham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Cunningham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144272"
                        ],
                        "name": "D. Maynard",
                        "slug": "D.-Maynard",
                        "structuredName": {
                            "firstName": "Diana",
                            "lastName": "Maynard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Maynard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723649"
                        ],
                        "name": "Kalina Bontcheva",
                        "slug": "Kalina-Bontcheva",
                        "structuredName": {
                            "firstName": "Kalina",
                            "lastName": "Bontcheva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kalina Bontcheva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2968188"
                        ],
                        "name": "V. Tablan",
                        "slug": "V.-Tablan",
                        "structuredName": {
                            "firstName": "Valentin",
                            "lastName": "Tablan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Tablan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7237559,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2bd2e082913c5366129622fbee1fe24f2dfa696f",
            "isKey": false,
            "numCitedBy": 1714,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-framework-and-graphical-development-environment-Cunningham-Maynard",
            "title": {
                "fragments": [],
                "text": "A framework and graphical development environment for robust NLP tools and applications"
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Mallet: A machine learning for language toolkit"
            },
            "venue": {
                "fragments": [],
                "text": "http://mallet.cs.umass.edu (2002)."
            },
            "year": 2002
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "methodology": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 14,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Automatic-indexing-of-scanned-documents:-a-approach-Esser-Schuster/41db13459f0344a0ca63342302484c4f6e044376?sort=total-citations"
}