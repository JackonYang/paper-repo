{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144332826"
                        ],
                        "name": "Chen Kong",
                        "slug": "Chen-Kong",
                        "structuredName": {
                            "firstName": "Chen",
                            "lastName": "Kong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chen Kong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1807606"
                        ],
                        "name": "Dahua Lin",
                        "slug": "Dahua-Lin",
                        "structuredName": {
                            "firstName": "Dahua",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dahua Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143977268"
                        ],
                        "name": "Mohit Bansal",
                        "slug": "Mohit-Bansal",
                        "structuredName": {
                            "firstName": "Mohit",
                            "lastName": "Bansal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mohit Bansal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2422559"
                        ],
                        "name": "R. Urtasun",
                        "slug": "R.-Urtasun",
                        "structuredName": {
                            "firstName": "Raquel",
                            "lastName": "Urtasun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Urtasun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37895334"
                        ],
                        "name": "S. Fidler",
                        "slug": "S.-Fidler",
                        "structuredName": {
                            "firstName": "Sanja",
                            "lastName": "Fidler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Fidler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 16
                            }
                        ],
                        "text": "Although others [7, 8] propose interesting alternatives for learning the language binding, it is unclear if such approaches can be used to provide answers on questions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3015754,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "13549b4e6fffbb7932b7a83a8eb6be27e6a60eca",
            "isKey": false,
            "numCitedBy": 164,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we exploit natural sentential descriptions of RGB-D scenes in order to improve 3D semantic parsing. Importantly, in doing so, we reason about which particular object each noun/pronoun is referring to in the image. This allows us to utilize visual information in order to disambiguate the so-called coreference resolution problem that arises in text. Towards this goal, we propose a structure prediction model that exploits potentials computed from text and RGB-D imagery to reason about the class of the 3D objects, the scene type, as well as to align the nouns/pronouns with the referred visual objects. We demonstrate the effectiveness of our approach on the challenging NYU-RGBD v2 dataset, which we enrich with natural lingual descriptions. We show that our approach significantly improves 3D detection and scene classification accuracy, and is able to reliably estimate the text-to-image alignment. Furthermore, by using textual and visual information, we are also able to successfully deal with coreference in text, improving upon the state-of-the-art Stanford coreference system [15]."
            },
            "slug": "What-Are-You-Talking-About-Text-to-Image-Kong-Lin",
            "title": {
                "fragments": [],
                "text": "What Are You Talking About? Text-to-Image Coreference"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This paper proposes a structure prediction model that exploits potentials computed from text and RGB-D imagery to reason about the class of the 3D objects, the scene type, as well as to align the nouns/pronouns with the referred visual objects."
            },
            "venue": {
                "fragments": [],
                "text": "2014 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2674440"
                        ],
                        "name": "Cynthia Matuszek",
                        "slug": "Cynthia-Matuszek",
                        "structuredName": {
                            "firstName": "Cynthia",
                            "lastName": "Matuszek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cynthia Matuszek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143883142"
                        ],
                        "name": "Nicholas FitzGerald",
                        "slug": "Nicholas-FitzGerald",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "FitzGerald",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicholas FitzGerald"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144651486"
                        ],
                        "name": "Liefeng Bo",
                        "slug": "Liefeng-Bo",
                        "structuredName": {
                            "firstName": "Liefeng",
                            "lastName": "Bo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liefeng Bo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145197953"
                        ],
                        "name": "D. Fox",
                        "slug": "D.-Fox",
                        "structuredName": {
                            "firstName": "Dieter",
                            "lastName": "Fox",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Fox"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 39
                            }
                        ],
                        "text": "Language and perception: Previous work [4, 5] has proposed models for the language grounding problem with the goal of connecting the meaning of the natural language sentences to a perceived world."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 86
                            }
                        ],
                        "text": "For instance [5] considers only two mugs, monitor and table in their dataset, whereas [4] examines objects such as blocks, plastic food, and building bricks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 70
                            }
                        ],
                        "text": "Moreover, our paper considers complex questions - beyond the scope of [4] and [5] - and reasoning across different images using only textual question-answer pairs for training."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2408319,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "58bd0afc8a1b98e16a67ebda436e60c6f6410f56",
            "isKey": false,
            "numCitedBy": 287,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "As robots become more ubiquitous and capable, it becomes ever more important for untrained users to easily interact with them. Recently, this has led to study of the language grounding problem, where the goal is to extract representations of the meanings of natural language tied to the physical world. We present an approach for joint learning of language and perception models for grounded attribute induction. The perception model includes classifiers for physical characteristics and a language model based on a probabilistic categorial grammar that enables the construction of compositional meaning representations. We evaluate on the task of interpreting sentences that describe sets of objects in a physical workspace, and demonstrate accurate task performance and effective latent-variable concept induction in physical grounded scenes."
            },
            "slug": "A-Joint-Model-of-Language-and-Perception-for-Matuszek-FitzGerald",
            "title": {
                "fragments": [],
                "text": "A Joint Model of Language and Perception for Grounded Attribute Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work presents an approach for joint learning of language and perception models for grounded attribute induction, which includes a language model based on a probabilistic categorial grammar that enables the construction of compositional meaning representations."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075292388"
                        ],
                        "name": "P. Liang",
                        "slug": "P.-Liang",
                        "structuredName": {
                            "firstName": "Percy",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Liang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38666915"
                        ],
                        "name": "D. Klein",
                        "slug": "D.-Klein",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Klein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Klein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 29
                            }
                        ],
                        "text": "We use the same templates as [1]: string triggers a predicate, string is under a relation, string is under a trace predicate, two predicates are linked via relation and a predicate has a child."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 162
                            }
                        ],
                        "text": "Equally strong progress has been made on the language side, where methods have been proposed that can learn to answer questions solely from question-answer pairs [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 10
                            }
                        ],
                        "text": "Following [1] we use DCS Trees that yield the following recursive evaluation function \u03c3W : \u03c3W(T ) :="
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 105
                            }
                        ],
                        "text": "Question answering on real-world images based on a perceived world Similar to [5], we extend the work of [1] to operate now on what we call perceived world W ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 50
                            }
                        ],
                        "text": "For a detailed exposition, we refer the reader to [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 176
                            }
                        ],
                        "text": "Single-world approach for question answering problem We build on recent progress on end-toend question answering systems that are solely trained on question-answer pairs (Q,A) [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 46
                            }
                        ],
                        "text": "Top part of Figure 1 outlines how we build on [1] by modeling the logical forms associated with a question as latent variable T given a single worldW ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 198
                            }
                        ],
                        "text": "More formally the task of predicting an answer A given a questionQ and a worldW is performed by computing the following posterior which marginalizes over the latent logical forms (semantic trees in [1]) T : P (A|Q,W) := \u2211 T P (A|T ,W)P (T |Q)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 25
                            }
                        ],
                        "text": "In contrast to our work, [1] has never used the semantic parser to connect the natural language to the perceived world."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 64
                            }
                        ],
                        "text": "2 Related work Semantic parsers: Our work is mainly inspired by [1] that learns the semantic representation for the question answering task solely based on questions and answers in natural language."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 340852,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3ecd3e00bbbfd94446c3adc9c6878de27e250f7c",
            "isKey": true,
            "numCitedBy": 568,
            "numCiting": 81,
            "paperAbstract": {
                "fragments": [],
                "text": "Suppose we want to build a system that answers a natural language question by representing its semantics as a logical forxm and computing the answer given a structured database of facts. The core part of such a system is the semantic parser that maps questions to logical forms. Semantic parsers are typically trained from examples of questions annotated with their target logical forms, but this type of annotation is expensive.Our goal is to instead learn a semantic parser from question\u2013answer pairs, where the logical form is modeled as a latent variable. We develop a new semantic formalism, dependency-based compositional semantics (DCS) and define a log-linear distribution over DCS logical forms. The model parameters are estimated using a simple procedure that alternates between beam search and numerical optimization. On two standard semantic parsing benchmarks, we show that our system obtains comparable accuracies to even state-of-the-art systems that do require annotated logical forms."
            },
            "slug": "Learning-Dependency-Based-Compositional-Semantics-Liang-Jordan",
            "title": {
                "fragments": [],
                "text": "Learning Dependency-Based Compositional Semantics"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A new semantic formalism, dependency-based compositional semantics (DCS) is developed and a log-linear distribution over DCS logical forms is defined and it is shown that the system obtains comparable accuracies to even state-of-the-art systems that do require annotated logical forms."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2517825"
                        ],
                        "name": "J. Krishnamurthy",
                        "slug": "J.-Krishnamurthy",
                        "structuredName": {
                            "firstName": "Jayant",
                            "lastName": "Krishnamurthy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Krishnamurthy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2836353"
                        ],
                        "name": "T. Kollar",
                        "slug": "T.-Kollar",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kollar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kollar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 39
                            }
                        ],
                        "text": "Language and perception: Previous work [4, 5] has proposed models for the language grounding problem with the goal of connecting the meaning of the natural language sentences to a perceived world."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 78
                            }
                        ],
                        "text": "Question answering on real-world images based on a perceived world Similar to [5], we extend the work of [1] to operate now on what we call perceived world W ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 13
                            }
                        ],
                        "text": "For instance [5] considers only two mugs, monitor and table in their dataset, whereas [4] examines objects such as blocks, plastic food, and building bricks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 78
                            }
                        ],
                        "text": "Moreover, our paper considers complex questions - beyond the scope of [4] and [5] - and reasoning across different images using only textual question-answer pairs for training."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10250712,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c45fd881bcc20bc1a754ee4b446d99aaff1d3dd5",
            "isKey": true,
            "numCitedBy": 162,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces Logical Semantics with Perception (LSP), a model for grounded language acquisition that learns to map natural language statements to their referents in a physical environment. For example, given an image, LSP can map the statement \u201cblue mug on the table\u201d to the set of image segments showing blue mugs on tables. LSP learns physical representations for both categorical (\u201cblue,\u201d \u201cmug\u201d) and relational (\u201con\u201d) language, and also learns to compose these representations to produce the referents of entire statements. We further introduce a weakly supervised training procedure that estimates LSP\u2019s parameters using annotated referents for entire statements, without annotated referents for individual words or the parse structure of the statement. We perform experiments on two applications: scene understanding and geographical question answering. We find that LSP outperforms existing, less expressive models that cannot represent relational language. We further find that weakly supervised training is competitive with fully supervised training while requiring significantly less annotation effort."
            },
            "slug": "Jointly-Learning-to-Parse-and-Perceive:-Connecting-Krishnamurthy-Kollar",
            "title": {
                "fragments": [],
                "text": "Jointly Learning to Parse and Perceive: Connecting Natural Language to the Physical World"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "This paper introduces Logical Semantics with Perception (LSP), a model for grounded language acquisition that learns to map natural language statements to their referents in a physical environment and finds that LSP outperforms existing, less expressive models that cannot represent relational language."
            },
            "venue": {
                "fragments": [],
                "text": "TACL"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687120"
                        ],
                        "name": "S. Guadarrama",
                        "slug": "S.-Guadarrama",
                        "structuredName": {
                            "firstName": "Sergio",
                            "lastName": "Guadarrama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Guadarrama"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3006928"
                        ],
                        "name": "N. Krishnamoorthy",
                        "slug": "N.-Krishnamoorthy",
                        "structuredName": {
                            "firstName": "Niveda",
                            "lastName": "Krishnamoorthy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Krishnamoorthy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3163967"
                        ],
                        "name": "Girish Malkarnenkar",
                        "slug": "Girish-Malkarnenkar",
                        "structuredName": {
                            "firstName": "Girish",
                            "lastName": "Malkarnenkar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Girish Malkarnenkar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1811430"
                        ],
                        "name": "Subhashini Venugopalan",
                        "slug": "Subhashini-Venugopalan",
                        "structuredName": {
                            "firstName": "Subhashini",
                            "lastName": "Venugopalan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Subhashini Venugopalan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2903226"
                        ],
                        "name": "Kate Saenko",
                        "slug": "Kate-Saenko",
                        "structuredName": {
                            "firstName": "Kate",
                            "lastName": "Saenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kate Saenko"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 47
                            }
                        ],
                        "text": "For \u03bc we use a variant of Wu-Palmer similarity [23, 24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11418612,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d6a7a563640bf53953c4fda0997e4db176488510",
            "isKey": false,
            "numCitedBy": 405,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Despite a recent push towards large-scale object recognition, activity recognition remains limited to narrow domains and small vocabularies of actions. In this paper, we tackle the challenge of recognizing and describing activities ``in-the-wild''. We present a solution that takes a short video clip and outputs a brief sentence that sums up the main activity in the video, such as the actor, the action and its object. Unlike previous work, our approach works on out-of-domain actions: it does not require training videos of the exact activity. If it cannot find an accurate prediction for a pre-trained model, it finds a less specific answer that is also plausible from a pragmatic standpoint. We use semantic hierarchies learned from the data to help to choose an appropriate level of generalization, and priors learned from Web-scale natural language corpora to penalize unlikely combinations of actors/actions/objects, we also use a Web-scale language model to ``fill in'' novel verbs, i.e. when the verb does not appear in the training set. We evaluate our method on a large YouTube corpus and demonstrate it is able to generate short sentence descriptions of video clips better than baseline approaches."
            },
            "slug": "YouTube2Text:-Recognizing-and-Describing-Arbitrary-Guadarrama-Krishnamoorthy",
            "title": {
                "fragments": [],
                "text": "YouTube2Text: Recognizing and Describing Arbitrary Activities Using Semantic Hierarchies and Zero-Shot Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper presents a solution that takes a short video clip and outputs a brief sentence that sums up the main activity in the video, such as the actor, the action and its object, and uses a Web-scale language model to ``fill in'' novel verbs."
            },
            "venue": {
                "fragments": [],
                "text": "2013 IEEE International Conference on Computer Vision"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2354728"
                        ],
                        "name": "A. Karpathy",
                        "slug": "A.-Karpathy",
                        "structuredName": {
                            "firstName": "Andrej",
                            "lastName": "Karpathy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Karpathy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2319608"
                        ],
                        "name": "Armand Joulin",
                        "slug": "Armand-Joulin",
                        "structuredName": {
                            "firstName": "Armand",
                            "lastName": "Joulin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Armand Joulin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 16
                            }
                        ],
                        "text": "Although others [7, 8] propose interesting alternatives for learning the language binding, it is unclear if such approaches can be used to provide answers on questions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2315434,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7f1b111f0bb703b0bd97aba505728a9b0d9b2a54",
            "isKey": false,
            "numCitedBy": 740,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a model for bidirectional retrieval of images and sentences through a deep, multi-modal embedding of visual and natural language data. Unlike previous models that directly map images or sentences into a common embedding space, our model works on a finer level and embeds fragments of images (objects) and fragments of sentences (typed dependency tree relations) into a common space. We then introduce a structured max-margin objective that allows our model to explicitly associate these fragments across modalities. Extensive experimental evaluation shows that reasoning on both the global level of images and sentences and the finer level of their respective fragments improves performance on image-sentence retrieval tasks. Additionally, our model provides interpretable predictions for the image-sentence retrieval task since the inferred inter-modal alignment of fragments is explicit."
            },
            "slug": "Deep-Fragment-Embeddings-for-Bidirectional-Image-Karpathy-Joulin",
            "title": {
                "fragments": [],
                "text": "Deep Fragment Embeddings for Bidirectional Image Sentence Mapping"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This work introduces a model for bidirectional retrieval of images and sentences through a deep, multi-modal embedding of visual and natural language data and introduces a structured max-margin objective that allows this model to explicitly associate fragments across modalities."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687120"
                        ],
                        "name": "S. Guadarrama",
                        "slug": "S.-Guadarrama",
                        "structuredName": {
                            "firstName": "Sergio",
                            "lastName": "Guadarrama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Guadarrama"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145713001"
                        ],
                        "name": "Lorenzo Riano",
                        "slug": "Lorenzo-Riano",
                        "structuredName": {
                            "firstName": "Lorenzo",
                            "lastName": "Riano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lorenzo Riano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72292061"
                        ],
                        "name": "D. Golland",
                        "slug": "D.-Golland",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Golland",
                            "middleNames": [
                                "Hamilton"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Golland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2125436"
                        ],
                        "name": "D. Goehring",
                        "slug": "D.-Goehring",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Goehring",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Goehring"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39978391"
                        ],
                        "name": "Yangqing Jia",
                        "slug": "Yangqing-Jia",
                        "structuredName": {
                            "firstName": "Yangqing",
                            "lastName": "Jia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yangqing Jia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38666915"
                        ],
                        "name": "D. Klein",
                        "slug": "D.-Klein",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Klein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Klein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689992"
                        ],
                        "name": "P. Abbeel",
                        "slug": "P.-Abbeel",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Abbeel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Abbeel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2650170,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e64fd4eb33199fc2cc731aec1c25d4e88a4d4f40",
            "isKey": false,
            "numCitedBy": 125,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a system for human-robot interaction that learns both models for spatial prepositions and for object recognition. Our system grounds the meaning of an input sentence in terms of visual percepts coming from the robot's sensors in order to send an appropriate command to the PR2 or respond to spatial queries. To perform this grounding, the system recognizes the objects in the scene, determines which spatial relations hold between those objects, and semantically parses the input sentence. The proposed system uses the visual and spatial information in conjunction with the semantic parse to interpret statements that refer to objects (nouns), their spatial relationships (prepositions), and to execute commands (actions). The semantic parse is inherently compositional, allowing the robot to understand complex commands that refer to multiple objects and relations such as: \u201cMove the cup close to the robot to the area in front of the plate and behind the tea box\u201d. Our system correctly parses 94% of the 210 online test sentences, correctly interprets 91% of the correctly parsed sentences, and correctly executes 89% of the correctly interpreted sentences."
            },
            "slug": "Grounding-spatial-relations-for-human-robot-Guadarrama-Riano",
            "title": {
                "fragments": [],
                "text": "Grounding spatial relations for human-robot interaction"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "A system for human-robot interaction that learns both models for spatial prepositions and for object recognition, and grounds the meaning of an input sentence in terms of visual percepts coming from the robot's sensors to send an appropriate command to the PR2 or respond to spatial queries."
            },
            "venue": {
                "fragments": [],
                "text": "2013 IEEE/RSJ International Conference on Intelligent Robots and Systems"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30333061"
                        ],
                        "name": "Adam Vogel",
                        "slug": "Adam-Vogel",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Vogel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adam Vogel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 49
                            }
                        ],
                        "text": "Integrated systems that execute commands: Others [9, 10, 11, 12, 13] focus on the task of learning the representation of natural language in the restricted setting of executing commands."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10395192,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "da5289121e139b6810781301a890c94c25a0d3d7",
            "isKey": false,
            "numCitedBy": 193,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a system that learns to follow navigational natural language directions. Where traditional models learn from linguistic annotation or word distributions, our approach is grounded in the world, learning by apprenticeship from routes through a map paired with English descriptions. Lacking an explicit alignment between the text and the reference path makes it difficult to determine what portions of the language describe which aspects of the route. We learn this correspondence with a reinforcement learning algorithm, using the deviation of the route we follow from the intended path as a reward signal. We demonstrate that our system successfully grounds the meaning of spatial terms like above and south into geometric properties of paths."
            },
            "slug": "Learning-to-Follow-Navigational-Directions-Vogel-Jurafsky",
            "title": {
                "fragments": [],
                "text": "Learning to Follow Navigational Directions"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A system that learns to follow navigational natural language directions by learning by apprenticeship from routes through a map paired with English descriptions using a reinforcement learning algorithm, which grounds the meaning of spatial terms like above and south into geometric properties of paths."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2913681"
                        ],
                        "name": "Stefanie Tellex",
                        "slug": "Stefanie-Tellex",
                        "structuredName": {
                            "firstName": "Stefanie",
                            "lastName": "Tellex",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stefanie Tellex"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2836353"
                        ],
                        "name": "T. Kollar",
                        "slug": "T.-Kollar",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kollar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kollar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47315755"
                        ],
                        "name": "Steven Dickerson",
                        "slug": "Steven-Dickerson",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Dickerson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steven Dickerson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733702"
                        ],
                        "name": "Matthew R. Walter",
                        "slug": "Matthew-R.-Walter",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Walter",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew R. Walter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38825120"
                        ],
                        "name": "A. Banerjee",
                        "slug": "A.-Banerjee",
                        "structuredName": {
                            "firstName": "Ashis",
                            "lastName": "Banerjee",
                            "middleNames": [
                                "Gopal"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Banerjee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720894"
                        ],
                        "name": "S. Teller",
                        "slug": "S.-Teller",
                        "structuredName": {
                            "firstName": "Seth",
                            "lastName": "Teller",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Teller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143724999"
                        ],
                        "name": "N. Roy",
                        "slug": "N.-Roy",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Roy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Roy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 220828823,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a389456fdc46e458d0a813a608b71b44b2ff8e62",
            "isKey": false,
            "numCitedBy": 640,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a new model for understanding natural language commands given to autonomous systems that perform navigation and mobile manipulation in semi-structured environments. Previous approaches have used models with fixed structure to infer the likelihood of a sequence of actions given the environment and the command. In contrast, our framework, called Generalized Grounding Graphs (G3), dynamically instantiates a probabilistic graphical model for a particular natural language command according to the command's hierarchical and compositional semantic structure. Our system performs inference in the model to successfully find and execute plans corresponding to natural language commands such as \"Put the tire pallet on the truck.\" The model is trained using a corpus of commands collected using crowdsourcing. We pair each command with robot actions and use the corpus to learn the parameters of the model. We evaluate the robot's performance by inferring plans from natural language commands, executing each plan in a realistic robot simulator, and asking users to evaluate the system's performance. We demonstrate that our system can successfully follow many natural language commands from the corpus."
            },
            "slug": "Understanding-Natural-Language-Commands-for-Robotic-Tellex-Kollar",
            "title": {
                "fragments": [],
                "text": "Understanding Natural Language Commands for Robotic Navigation and Mobile Manipulation"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This paper describes a new model for understanding natural language commands given to autonomous systems that perform navigation and mobile manipulation in semi-structured environments that dynamically instantiates a probabilistic graphical model for a particular natural language command according to the command's hierarchical and compositional semantic structure."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113225771"
                        ],
                        "name": "Tian Lan",
                        "slug": "Tian-Lan",
                        "structuredName": {
                            "firstName": "Tian",
                            "lastName": "Lan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tian Lan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49230687"
                        ],
                        "name": "Weilong Yang",
                        "slug": "Weilong-Yang",
                        "structuredName": {
                            "firstName": "Weilong",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Weilong Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46396571"
                        ],
                        "name": "Yang Wang",
                        "slug": "Yang-Wang",
                        "structuredName": {
                            "firstName": "Yang",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yang Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10771328"
                        ],
                        "name": "Greg Mori",
                        "slug": "Greg-Mori",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Mori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Greg Mori"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1479563,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "10c9e6881eeb27f8b9df7c38de7f914dc1297129",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider image retrieval with structured object queries --- queries that specify the objects that should be present in the scene, and their spatial relations. An example of such queries is \"car on the road\". Existing image retrieval systems typically consider queries consisting of object classes (i.e. keywords). They train a separate classifier for each object class and combine the output heuristically. In contrast, we develop a learning framework to jointly consider object classes and their relations. Our method considers not only the objects in the query (\"car\" and \"road\" in the above example), but also related object categories can be useful for retrieval. Since we do not have ground-truth labeling of object bounding boxes on the test image, we represent them as latent variables in our model. Our learning method is an extension of the ranking SVM with latent variables, which we call latent ranking SVM. We demonstrate image retrieval and ranking results on a dataset with more than a hundred of object classes."
            },
            "slug": "Image-Retrieval-with-Structured-Object-Queries-SVM-Lan-Yang",
            "title": {
                "fragments": [],
                "text": "Image Retrieval with Structured Object Queries Using Latent Ranking SVM"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "This work develops a learning framework to jointly consider object classes and their relations in image retrieval with structured object queries --- queries that specify the objects that should be present in the scene, and their spatial relations."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2517825"
                        ],
                        "name": "J. Krishnamurthy",
                        "slug": "J.-Krishnamurthy",
                        "structuredName": {
                            "firstName": "Jayant",
                            "lastName": "Krishnamurthy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Krishnamurthy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40975594"
                        ],
                        "name": "Tom Michael Mitchell",
                        "slug": "Tom-Michael-Mitchell",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Mitchell",
                            "middleNames": [
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom Michael Mitchell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Single-world approach for question answering problem We build on recent progress on endto-end question answering systems that are solely trained on question-answer pairs (Q,A) [1, 13]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5633240,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2ffc1d8ec7b86a01b047d2c1ce66708a496a3f8a",
            "isKey": false,
            "numCitedBy": 147,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method for training a semantic parser using only a knowledge base and an unlabeled text corpus, without any individually annotated sentences. Our key observation is that multiple forms of weak supervision can be combined to train an accurate semantic parser: semantic supervision from a knowledge base, and syntactic supervision from dependency-parsed sentences. We apply our approach to train a semantic parser that uses 77 relations from Freebase in its knowledge representation. This semantic parser extracts instances of binary relations with state-of-the-art accuracy, while simultaneously recovering much richer semantic structures, such as conjunctions of multiple relations with partially shared arguments. We demonstrate recovery of this richer structure by extracting logical forms from natural language queries against Freebase. On this task, the trained semantic parser achieves 80% precision and 56% recall, despite never having seen an annotated logical form."
            },
            "slug": "Weakly-Supervised-Training-of-Semantic-Parsers-Krishnamurthy-Mitchell",
            "title": {
                "fragments": [],
                "text": "Weakly Supervised Training of Semantic Parsers"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "This work presents a method for training a semantic parser using only a knowledge base and an unlabeled text corpus, without any individually annotated sentences, and demonstrates recovery of this richer structure by extracting logical forms from natural language queries against Freebase."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2674440"
                        ],
                        "name": "Cynthia Matuszek",
                        "slug": "Cynthia-Matuszek",
                        "structuredName": {
                            "firstName": "Cynthia",
                            "lastName": "Matuszek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cynthia Matuszek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6376655"
                        ],
                        "name": "E. Herbst",
                        "slug": "E.-Herbst",
                        "structuredName": {
                            "firstName": "Evan",
                            "lastName": "Herbst",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Herbst"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145197953"
                        ],
                        "name": "D. Fox",
                        "slug": "D.-Fox",
                        "structuredName": {
                            "firstName": "Dieter",
                            "lastName": "Fox",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Fox"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 49
                            }
                        ],
                        "text": "Integrated systems that execute commands: Others [9, 10, 11, 12, 13] focus on the task of learning the representation of natural language in the restricted setting of executing commands."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1658890,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3954a3f80cf1b1f76430d80e924d85f2f1ba6799",
            "isKey": false,
            "numCitedBy": 355,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "As robots become more ubiquitous and capable of performing complex tasks, the importance of enabling untrained users to interact with them has increased. In response, unconstrained natural-language interaction with robots has emerged as a significant research area. We discuss the problem of parsing natural language commands to actions and control structures that can be readily implemented in a robot execution system. Our approach learns a parser based on example pairs of English commands and corresponding control language expressions. We evaluate this approach in the context of following route instructions through an indoor environment, and demonstrate that our system can learn to translate English commands into sequences of desired actions, while correctly capturing the semantic intent of statements involving complex control structures. The procedural nature of our formal representation allows a robot to interpret route instructions online while moving through a previously unknown environment."
            },
            "slug": "Learning-to-Parse-Natural-Language-Commands-to-a-Matuszek-Herbst",
            "title": {
                "fragments": [],
                "text": "Learning to Parse Natural Language Commands to a Robot Control System"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work discusses the problem of parsing natural language commands to actions and control structures that can be readily implemented in a robot execution system, and learns a parser based on example pairs of English commands and corresponding control language expressions."
            },
            "venue": {
                "fragments": [],
                "text": "ISER"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2820687"
                        ],
                        "name": "Joost van de Weijer",
                        "slug": "Joost-van-de-Weijer",
                        "structuredName": {
                            "firstName": "Joost",
                            "lastName": "Weijer",
                            "middleNames": [
                                "van",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joost van de Weijer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721683"
                        ],
                        "name": "J. Verbeek",
                        "slug": "J.-Verbeek",
                        "structuredName": {
                            "firstName": "Jakob",
                            "lastName": "Verbeek",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Verbeek"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 72
                            }
                        ],
                        "text": "They were instructed to give valid answers that are either basic colors [16], numbers or objects (894 categories) or sets of those."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 125
                            }
                        ],
                        "text": "}, instance id is the object\u2019s id, image id is id of the image containing the object, color is estimated color of the object [16], and spatial loc is the object\u2019s position in the image."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 58
                            }
                        ],
                        "text": "They are instructed to answer with a number, basic colors [16], or objects (from 37 or 894 categories) or set of those."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2852002,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2a38768dabcd02539265c065a4d7ac445309ae96",
            "isKey": true,
            "numCitedBy": 192,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Within a computer vision context color naming is the action of assigning linguistic color labels to image pixels. In general, research on color naming applies the following paradigm: a collection of color chips is labelled with color names within a well-defined experimental setup by multiple test subjects. The collected data set is subsequently used to label RGB values in real-world images with a color name. Apart from the fact that this collection process is time consuming, it is unclear to what extent color naming within a controlled setup is representative for color naming in real-world images. Therefore we propose to learn color names from real-world images. Furthermore, we avoid test subjects by using Google Image to collect a data set. Due to limitations of Google Image this data set contains a substantial quantity of wrongly labelled data. The color names are learned using a PLSA model adapted to this task. Experimental results show that color names learned from real-world images significantly outperform color names learned from labelled color chips on retrieval and classification."
            },
            "slug": "Learning-Color-Names-from-Real-World-Images-Weijer-Schmid",
            "title": {
                "fragments": [],
                "text": "Learning Color Names from Real-World Images"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Experimental results show that color names learned from real-world images significantly outperform color names learning from labelled color chips on retrieval and classification."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708708"
                        ],
                        "name": "G. Kruijff",
                        "slug": "G.-Kruijff",
                        "structuredName": {
                            "firstName": "Geert-Jan",
                            "lastName": "Kruijff",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Kruijff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731104"
                        ],
                        "name": "H. Zender",
                        "slug": "H.-Zender",
                        "structuredName": {
                            "firstName": "Hendrik",
                            "lastName": "Zender",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Zender"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770066"
                        ],
                        "name": "P. Jensfelt",
                        "slug": "P.-Jensfelt",
                        "structuredName": {
                            "firstName": "Patric",
                            "lastName": "Jensfelt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Jensfelt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723059"
                        ],
                        "name": "H. Christensen",
                        "slug": "H.-Christensen",
                        "structuredName": {
                            "firstName": "Henrik",
                            "lastName": "Christensen",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Christensen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 58055334,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2533ec0b94e7c6fa4227e629aca3ab083b7f3d51",
            "isKey": false,
            "numCitedBy": 151,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper presents an HRI architecture for human-augmented mapping, which has been implemented and tested on an autonomous mobile robotic platform. Through interaction with a human, the robot can augment its autonomously acquired metric map with qualitative information about locations and objects in the environment. The system implements various interaction strategies observed in independently performed Wizard-of-Oz studies. The paper discusses an ontology-based approach to multi-layered conceptual spatial mapping that provides a common ground for human-robot dialogue. This is achieved by combining acquired knowledge with innate conceptual commonsense knowledge in order to infer new knowledge. The architecture bridges the gap between the rich semantic representations of the meaning expressed by verbal utterances on the one hand and the robot's internal sensor-based world representation on the other. It is thus possible to establish references to spatial areas in a situated dialogue between a human and a robot about their environment. The resulting conceptual descriptions represent qualitative knowledge about locations in the environment that can serve as a basis for achieving a notion of situational awareness."
            },
            "slug": "Situated-Dialogue-and-Spatial-Organization:-What,-Kruijff-Zender",
            "title": {
                "fragments": [],
                "text": "Situated Dialogue and Spatial Organization: What, Where\u2026 and Why?"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "An ontology-based approach to multi-layered conceptual spatial mapping that provides a common ground for human-robot dialogue is discussed, which is achieved by combining acquired knowledge with innate conceptual commonsense knowledge in order to infer new knowledge."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2987641"
                        ],
                        "name": "Michael L. Wick",
                        "slug": "Michael-L.-Wick",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Wick",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael L. Wick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729605"
                        ],
                        "name": "G. Miklau",
                        "slug": "G.-Miklau",
                        "structuredName": {
                            "firstName": "Gerome",
                            "lastName": "Miklau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Miklau"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6160012,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "129e9f5838577eb49881d9165138cf4dcf98fa52",
            "isKey": false,
            "numCitedBy": 92,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Incorporating probabilities into the semantics of incomplete databases has posed many challenges, forcing systems to sacrifice modeling power, scalability, or treatment of relational algebra operators. We propose an alternative approach where the underlying relational database always represents a single world, and an external factor graph encodes a distribution over possible worlds; Markov chain Monte Carlo (MCMC) inference is then used to recover this uncertainty to a desired level of fidelity. Our approach allows the efficient evaluation of arbitrary queries over probabilistic databases with arbitrary dependencies expressed by graphical models with structure that changes during inference. MCMC sampling provides efficiency by hypothesizing modifications to possible worlds rather than generating entire worlds from scratch. Queries are then run over the portions of the world that change, avoiding the onerous cost of running full queries over each sampled world. A significant innovation of this work is the connection between MCMC sampling and materialized view maintenance techniques: we find empirically that using view maintenance techniques is several orders of magnitude faster than naively querying each sampled world. We also demonstrate our system's ability to answer relational queries with aggregation, and demonstrate additional scalability through the use of parallelization on a real-world complex model of information extraction. This framework is sufficiently expressive to support probabilistic inference not only for answering queries, but also for inferring missing database content from raw evidence."
            },
            "slug": "Scalable-probabilistic-databases-with-factor-graphs-Wick-McCallum",
            "title": {
                "fragments": [],
                "text": "Scalable probabilistic databases with factor graphs and MCMC"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An alternative approach where the underlying relational database always represents a single world, and an external factor graph encodes a distribution over possible worlds; Markov chain Monte Carlo (MCMC) inference is then used to recover this uncertainty to a desired level of fidelity."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. VLDB Endow."
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15652489"
                        ],
                        "name": "T. Kwiatkowski",
                        "slug": "T.-Kwiatkowski",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Kwiatkowski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kwiatkowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1991315"
                        ],
                        "name": "S. Goldwater",
                        "slug": "S.-Goldwater",
                        "structuredName": {
                            "firstName": "Sharon",
                            "lastName": "Goldwater",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Goldwater"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145332819"
                        ],
                        "name": "Mark Steedman",
                        "slug": "Mark-Steedman",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Steedman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Steedman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 173
                            }
                        ],
                        "text": "Although the architecture learns the mapping from weak supervision, it achieves comparable results to the semantic parsers that rely on manual annotations of logical forms ([2], [3])."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 6228816,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c7a40c3ef180d847bb3db40fd01990e08a6264f7",
            "isKey": false,
            "numCitedBy": 318,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of learning to map sentences to logical form, given training data consisting of natural language sentences paired with logical representations of their meaning. Previous approaches have been designed for particular natural languages or specific meaning representations; here we present a more general method. The approach induces a probabilistic CCG grammar that represents the meaning of individual words and defines how these meanings can be combined to analyze complete sentences. We use higher-order unification to define a hypothesis space containing all grammars consistent with the training data, and develop an online learning algorithm that efficiently searches this space while simultaneously estimating the parameters of a log-linear parsing model. Experiments demonstrate high accuracy on benchmark data sets in four languages with two different meaning representations."
            },
            "slug": "Inducing-Probabilistic-CCG-Grammars-from-Logical-Kwiatkowski-Zettlemoyer",
            "title": {
                "fragments": [],
                "text": "Inducing Probabilistic CCG Grammars from Logical Form with Higher-Order Unification"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper uses higher-order unification to define a hypothesis space containing all grammars consistent with the training data, and develops an online learning algorithm that efficiently searches this space while simultaneously estimating the parameters of a log-linear parsing model."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143875964"
                        ],
                        "name": "M. Levit",
                        "slug": "M.-Levit",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Levit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Levit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145364504"
                        ],
                        "name": "D. Roy",
                        "slug": "D.-Roy",
                        "structuredName": {
                            "firstName": "Deb",
                            "lastName": "Roy",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9428338,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c8b9fdf0491ccc48aef948dabd7fe9e69a486ca6",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "We have developed components of an automated system that understands and follows navigational instructions. The system has prior knowledge of the geometry and landmarks of specific maps. This knowledge is exploited to infer complex paths through maps based on natural language descriptions. The approach is based on an analysis of verbal commands in terms of elementary semantic units that are composed to generate a probability distribution over possible spatial paths in a map. An integration mechanism based on dynamic programming guides this language-to-path translation process, ensuring that resulting paths satisfy continuity and smoothness criteria. In the current implementation, parsing of text into semantic units is performed manually. Composition and interpretation of semantic units into spatial paths is performed automatically. In the evaluations, we show that the system accurately predicts the speakers' intended meanings for a range of instructions. This paper provides building blocks for a complete system that, when combined with robust parsing technologies, could lead to a fully automatic spatial language interpretation system"
            },
            "slug": "Interpretation-of-Spatial-Language-in-a-Map-Task-Levit-Roy",
            "title": {
                "fragments": [],
                "text": "Interpretation of Spatial Language in a Map Navigation Task"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper provides building blocks for a complete system that, when combined with robust parsing technologies, could lead to a fully automatic spatial language interpretation system."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 178
                            }
                        ],
                        "text": "Although the architecture learns the mapping from weak supervision, it achieves comparable results to the semantic parsers that rely on manual annotations of logical forms ([2], [3])."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 12728987,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "774113732db34ce0b797fc3dcceded811fb6edbc",
            "isKey": false,
            "numCitedBy": 448,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of learning to parse sentences to lambda-calculus representations of their underlying semantics and present an algorithm that learns a weighted combinatory categorial grammar (CCG). A key idea is to introduce non-standard CCG combinators that relax certain parts of the grammar\u2014for example allowing flexible word order, or insertion of lexical items\u2014 with learned costs. We also present a new, online algorithm for inducing a weighted CCG. Results for the approach on ATIS data show 86% F-measure in recovering fully correct semantic analyses and 95.9% F-measure by a partial-match criterion, a more than 5% improvement over the 90.3% partial-match figure reported by He and Young (2006)."
            },
            "slug": "Online-Learning-of-Relaxed-CCG-Grammars-for-Parsing-Zettlemoyer-Collins",
            "title": {
                "fragments": [],
                "text": "Online Learning of Relaxed CCG Grammars for Parsing to Logical Form"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A key idea is to introduce non-standard CCG combinators that relax certain parts of the grammar\u2014for example allowing flexible word order, or insertion of lexical items\u2014 with learned costs."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144157872"
                        ],
                        "name": "Saurabh Gupta",
                        "slug": "Saurabh-Gupta",
                        "structuredName": {
                            "firstName": "Saurabh",
                            "lastName": "Gupta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Saurabh Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778133"
                        ],
                        "name": "Pablo Arbel\u00e1ez",
                        "slug": "Pablo-Arbel\u00e1ez",
                        "structuredName": {
                            "firstName": "Pablo",
                            "lastName": "Arbel\u00e1ez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pablo Arbel\u00e1ez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 178
                            }
                        ],
                        "text": "Based on automatic segmentations (AutoSeg, 37 classes, single) (3rd row in Table 3) tests the architecture based on uncertain facts obtained from automatic semantic segmentation [15] where the"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 235,
                                "start": 231
                            }
                        ],
                        "text": "In particular, we distinguish between experiments on synthetic question-answer pairs (SynthQA) based on templates and those collected by annotators (HumanQA), automatic scene segmentation (AutoSeg) with a computer vision algorithm [15] and human segmentations (HumanSeg) based on the ground-truth annotations in the NYU dataset as well as single world (single) and multi-world (multi) approaches."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 76
                            }
                        ],
                        "text": "Note that the X,Y, Z coordinate system is aligned with direction of gravity [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 99
                            }
                        ],
                        "text": "For this purpose, we build the world by running a state-of-the-art semantic segmentation algorithm [15] over the images and collect the recognized information about objects such as object class, 3D position, and"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 48
                            }
                        ],
                        "text": "We use a state-of-the-art scene analysis method [15] which maps every pixel into 40 classes: 37 informative object classes as well as \u2019other structure\u2019, \u2019other furniture\u2019 and \u2019other prop\u2019."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 30
                            }
                        ],
                        "text": "We use the same data split as [15]: 795 training and 654 test images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 13
                            }
                        ],
                        "text": "According to [15], we preprocess the data to obtain canonical views of the scenes and use X , Y , Z coordinates from the depth sensor to define spatial placement of the objects in 3D."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12061055,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b9d35e88d4dc2156469446270fd67b8e45ca7811",
            "isKey": true,
            "numCitedBy": 529,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problems of contour detection, bottom-up grouping and semantic segmentation using RGB-D data. We focus on the challenging setting of cluttered indoor scenes, and evaluate our approach on the recently introduced NYU-Depth V2 (NYUD2) dataset [27]. We propose algorithms for object boundary detection and hierarchical segmentation that generalize the gPb-ucm approach of [2] by making effective use of depth information. We show that our system can label each contour with its type (depth, normal or albedo). We also propose a generic method for long-range amodal completion of surfaces and show its effectiveness in grouping. We then turn to the problem of semantic segmentation and propose a simple approach that classifies super pixels into the 40 dominant object categories in NYUD2. We use both generic and class-specific features to encode the appearance and geometry of objects. We also show how our approach can be used for scene classification, and how this contextual information in turn improves object recognition. In all of these tasks, we report significant improvements over the state-of-the-art."
            },
            "slug": "Perceptual-Organization-and-Recognition-of-Indoor-Gupta-Arbel\u00e1ez",
            "title": {
                "fragments": [],
                "text": "Perceptual Organization and Recognition of Indoor Scenes from RGB-D Images"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work proposes algorithms for object boundary detection and hierarchical segmentation that generalize the gPb-ucm approach of [2] by making effective use of depth information and shows how this contextual information in turn improves object recognition."
            },
            "venue": {
                "fragments": [],
                "text": "2013 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2286640"
                        ],
                        "name": "N. Silberman",
                        "slug": "N.-Silberman",
                        "structuredName": {
                            "firstName": "Nathan",
                            "lastName": "Silberman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Silberman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433269"
                        ],
                        "name": "Derek Hoiem",
                        "slug": "Derek-Hoiem",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Hoiem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Hoiem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143967473"
                        ],
                        "name": "Pushmeet Kohli",
                        "slug": "Pushmeet-Kohli",
                        "structuredName": {
                            "firstName": "Pushmeet",
                            "lastName": "Kohli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pushmeet Kohli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 179
                            }
                        ],
                        "text": "1 DAtaset for QUestion Answering on Real-world images (DAQUAR) Images and Semantic Segmentation Our new dataset for question answering is built on top of the NYU-Depth V2 dataset [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 87
                            }
                        ],
                        "text": "In contrast, our work focuses on a diverse collection of real-world indoor RGBD images [6] - with many more objects in the scene and more complex spatial relationship between them."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 545361,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c1994ba5946456fc70948c549daf62363f13fa2d",
            "isKey": false,
            "numCitedBy": 3520,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an approach to interpret the major surfaces, objects, and support relations of an indoor scene from an RGBD image. Most existing work ignores physical interactions or is applied only to tidy rooms and hallways. Our goal is to parse typical, often messy, indoor scenes into floor, walls, supporting surfaces, and object regions, and to recover support relationships. One of our main interests is to better understand how 3D cues can best inform a structured 3D interpretation. We also contribute a novel integer programming formulation to infer physical support relations. We offer a new dataset of 1449 RGBD images, capturing 464 diverse indoor scenes, with detailed annotations. Our experiments demonstrate our ability to infer support relations in complex scenes and verify that our 3D scene cues and inferred support lead to better object segmentation."
            },
            "slug": "Indoor-Segmentation-and-Support-Inference-from-RGBD-Silberman-Hoiem",
            "title": {
                "fragments": [],
                "text": "Indoor Segmentation and Support Inference from RGBD Images"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The goal is to parse typical, often messy, indoor scenes into floor, walls, supporting surfaces, and object regions, and to recover support relationships, to better understand how 3D cues can best inform a structured 3D interpretation."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067160148"
                        ],
                        "name": "T. Regier",
                        "slug": "T.-Regier",
                        "structuredName": {
                            "firstName": "Terry",
                            "lastName": "Regier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Regier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35131583"
                        ],
                        "name": "L. Carlson",
                        "slug": "L.-Carlson",
                        "structuredName": {
                            "firstName": "Laura",
                            "lastName": "Carlson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Carlson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14501879,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "b4aeb665438d03a8aab2c255afe7194fb60d4a19",
            "isKey": false,
            "numCitedBy": 303,
            "numCiting": 99,
            "paperAbstract": {
                "fragments": [],
                "text": "The present paper grounds the linguistic cdategorization of space in aspects of visual perception; specifically, the structure of projective spatial terms such as above are grounded in the process of attention and in vector-sum coding of overall direction. This is formalized in the attentional vector-sum (AVS) model. This computational model accurately predicts linguistic acceptability judgments for spatial terms, under a variety of spatial configurations. In 7 experiments, the predictions of the AVS model are tested against those of 3 competing models. The results support the AVS model and disconfirm its competitors. The authors conclude that the structure of linguistic spatial categories can be partially explained in terms of independently motivated perceptual processes."
            },
            "slug": "Grounding-spatial-language-in-perception:-an-and-Regier-Carlson",
            "title": {
                "fragments": [],
                "text": "Grounding spatial language in perception: an empirical and computational investigation."
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The authors conclude that the structure of linguistic spatial categories can be partially explained in terms of independently motivated perceptual processes."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of experimental psychology. General"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2146254443"
                        ],
                        "name": "Zhibiao Wu",
                        "slug": "Zhibiao-Wu",
                        "structuredName": {
                            "firstName": "Zhibiao",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhibiao Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145755155"
                        ],
                        "name": "Martha Palmer",
                        "slug": "Martha-Palmer",
                        "structuredName": {
                            "firstName": "Martha",
                            "lastName": "Palmer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martha Palmer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 127
                            }
                        ],
                        "text": "the ground truth (correct/wrong), we propose, inspired from the work on Fuzzy Sets [22], a soft measure based on the WUP score [23], which we call WUPS (WUP Set) score."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 47
                            }
                        ],
                        "text": "For \u03bc we use a variant of Wu-Palmer similarity [23, 24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12009057,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "0e3e3c3d8ae5cb7c4636870d69967c197484d3bb",
            "isKey": false,
            "numCitedBy": 3703,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper will focus on the semantic representation of verbs in computer systems and its impact on lexical selection problems in machine translation (MT). Two groups of English and Chinese verbs are examined to show that lexical selection must be based on interpretation of the sentences as well as selection restrictions placed on the verb arguments. A novel representation scheme is suggested, and is compared to representations with selection restrictions used in transfer-based MT. We see our approach as closely aligned with knowledge-based MT approaches (KBMT), and as a separate component that could be incorporated into existing systems. Examples and experimental results will show that, using this scheme, inexact matches can achieve correct lexical selection."
            },
            "slug": "Verb-Semantics-and-Lexical-Selection-Wu-Palmer",
            "title": {
                "fragments": [],
                "text": "Verb Semantics and Lexical Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This paper will focus on the semantic representation of verbs in computer systems and its impact on lexical selection problems in machine translation (MT), and sees the approach as closely aligned with knowledge-based MT approaches (KBMT), and as a separate component that could be incorporated into existing systems."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144096985"
                        ],
                        "name": "G. Miller",
                        "slug": "G.-Miller",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Miller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Miller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 87
                            }
                        ],
                        "text": "WUP(a, b) calculates similarity based on the depth of two words a and b in the taxonomy[25, 26], and define the WUPS score: WUPS(A, T ) = 1 N N \u2211"
                    },
                    "intents": []
                }
            ],
            "corpusId": 1671874,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "68c03788224000794d5491ab459be0b2a2c38677",
            "isKey": false,
            "numCitedBy": 13888,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Because meaningful sentences are composed of meaningful words, any system that hopes to process natural languages as people do must have information about words and their meanings. This information is traditionally provided through dictionaries, and machine-readable dictionaries are now widely available. But dictionary entries evolved for the convenience of human readers, not for machines. WordNet1 provides a more effective combination of traditional lexicographic information and modern computing. WordNet is an online lexical database designed for use under program control. English nouns, verbs, adjectives, and adverbs are organized into sets of synonyms, each representing a lexicalized concept. Semantic relations link the synonym sets [4]."
            },
            "slug": "WordNet:-A-Lexical-Database-for-English-Miller",
            "title": {
                "fragments": [],
                "text": "WordNet: A Lexical Database for English"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "WordNet1 provides a more effective combination of traditional lexicographic information and modern computing, and is an online lexical database designed for use under program control."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803434"
                        ],
                        "name": "R. Larson",
                        "slug": "R.-Larson",
                        "structuredName": {
                            "firstName": "Ray",
                            "lastName": "Larson",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Larson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 32493971,
            "fieldsOfStudy": [
                "Computer Science",
                "Environmental Science",
                "Psychology"
            ],
            "id": "5f3b50c6c826ad105163b09d53e1eb498a4b3994",
            "isKey": false,
            "numCitedBy": 7735,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Introduction To Information Retrieval Overdrive Digital. Introduction To Information Retrieval. Introduction To Information Retrieval Putao Ufcg. Introduction To Information Retrieval Arbeitsbereiche. Introduction To Information Retrieval. Introduction To Information Retrieval Stanford Nlp Group. Introduction To Information Retrieval Cs Ucr Edu. Introduction To Information Retrieval By Christopher D. Introduction To Information Retrieval Book. Information Retrieval The Mit Press. Introduction Information Retrieval Uvm. Information Retrieval Lmu Munich. Introduction To Information Retrieval Stanford University. Introduction To Information Retrieval. Introduction To Information Retrieval Amp Models Slideshare. Introduction To Information Retrieval Kangwon Ac Kr. Information Retrieval. Introduction To Information Retrieval Assets. Introduction To Information Retrieval. Introduction To Information Retrieval"
            },
            "slug": "Introduction-to-Information-Retrieval-Larson",
            "title": {
                "fragments": [],
                "text": "Introduction to Information Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "This chapter discusses Information Retrieval, the science and technology behind information retrieval and retrieval, and some of the techniques used in the retrieval of information."
            },
            "venue": {
                "fragments": [],
                "text": "J. Assoc. Inf. Sci. Technol."
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145718274"
                        ],
                        "name": "L. Zadeh",
                        "slug": "L.-Zadeh",
                        "structuredName": {
                            "firstName": "Lotfi",
                            "lastName": "Zadeh",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Zadeh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "mance Measure While the quality of an answer that the system produces can be measured in terms of accuracy w.r.t. the ground truth (correct/wrong), we propose, an inspired from the work on Fuzzy Sets [20], a soft measure based on the WUP score [21], which we call WUPS (WUP Set) score. As the number of classes grows, the semantic boundaries between them are becoming more fuzzy. For example, both concep"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 205883170,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0200705f91e3fc54f29f721b25cc1a52d51d208",
            "isKey": false,
            "numCitedBy": 33345,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Fuzzy-Sets-Zadeh",
            "title": {
                "fragments": [],
                "text": "Fuzzy Sets"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Control."
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "118896288"
                        ],
                        "name": "M. Braga",
                        "slug": "M.-Braga",
                        "structuredName": {
                            "firstName": "Maria",
                            "lastName": "Braga",
                            "middleNames": [
                                "Debora"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Braga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48031598"
                        ],
                        "name": "P. Duca",
                        "slug": "P.-Duca",
                        "structuredName": {
                            "firstName": "P",
                            "lastName": "Duca",
                            "middleNames": [
                                "G"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Duca"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 74
                            }
                        ],
                        "text": "We use Tukey\u2019s trimean 1 4 (Q1+2Q2+Q3), whereQj denotes the j-th quartile [21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2631707,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "3d07e8d62961e6b25869d4d90523157dc94eb484",
            "isKey": false,
            "numCitedBy": 5541,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "[Exploratory-data-analysis].-Braga-Duca",
            "title": {
                "fragments": [],
                "text": "[Exploratory data analysis]."
            },
            "venue": {
                "fragments": [],
                "text": "La Medicina del lavoro"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "How many red chairs are there?! H: ()!"
            },
            "venue": {
                "fragments": [],
                "text": "How many red chairs are there?! H: ()!"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "What is on the right side of cabinet?! H: picture M: bed! C: bed Q: What is on the wall?! H: mirror! M: bed! C: picture Q: What is beh H: lamp M: brown, pink C: picture"
            },
            "venue": {
                "fragments": [],
                "text": "What is on the right side of cabinet?! H: picture M: bed! C: bed Q: What is on the wall?! H: mirror! M: bed! C: picture Q: What is beh H: lamp M: brown, pink C: picture"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "How many chairs are at the table?! H: wall M: 4! C: chair Q: What is the object on the chair?! H: pillow! M: floor"
            },
            "venue": {
                "fragments": [],
                "text": "How many chairs are at the table?! H: wall M: 4! C: chair Q: What is the object on the chair?! H: pillow! M: floor"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 83
                            }
                        ],
                        "text": "the ground truth (correct/wrong), we propose, inspired from the work on Fuzzy Sets [22], a soft measure based on the WUP score [23], which we call WUPS (WUP Set) score."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 192
                            }
                        ],
                        "text": "Performance Measure While the quality of an answer that the system produces can be measured in terms of accuracy w.r.t. the ground truth (correct/wrong), we propose, inspired from the work on Fuzzy Sets [22], a soft measure based on the WUP score [23], which we call WUPS (WUP Set) score."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fuzzy sets. Information and control"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1965
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 11,
            "methodology": 8,
            "result": 3
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 30,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/A-Multi-World-Approach-to-Question-Answering-about-Malinowski-Fritz/ac64fb7e6d2ddf236332ec9f371fe85d308c114d?sort=total-citations"
}