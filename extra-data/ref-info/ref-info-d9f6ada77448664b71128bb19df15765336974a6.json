{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144906624"
                        ],
                        "name": "Alex Wang",
                        "slug": "Alex-Wang",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50286460"
                        ],
                        "name": "Amanpreet Singh",
                        "slug": "Amanpreet-Singh",
                        "structuredName": {
                            "firstName": "Amanpreet",
                            "lastName": "Singh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amanpreet Singh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38614754"
                        ],
                        "name": "Julian Michael",
                        "slug": "Julian-Michael",
                        "structuredName": {
                            "firstName": "Julian",
                            "lastName": "Michael",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Julian Michael"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145783676"
                        ],
                        "name": "Felix Hill",
                        "slug": "Felix-Hill",
                        "structuredName": {
                            "firstName": "Felix",
                            "lastName": "Hill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Felix Hill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39455775"
                        ],
                        "name": "Omer Levy",
                        "slug": "Omer-Levy",
                        "structuredName": {
                            "firstName": "Omer",
                            "lastName": "Levy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Omer Levy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3644767"
                        ],
                        "name": "Samuel R. Bowman",
                        "slug": "Samuel-R.-Bowman",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Bowman",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samuel R. Bowman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 142
                            }
                        ],
                        "text": "In this context, the GLUE benchmark (organized by some of the same authors as this work, short for General Language Understanding Evaluation; Wang et al., 2019) has become a prominent evaluation framework and leaderboard for research towards general-purpose language understanding technologies."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5034059,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "93b8da28d006415866bf48f9a6e06b5242129195",
            "isKey": false,
            "numCitedBy": 2637,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Human ability to understand language is general, flexible, and robust. In contrast, most NLU models above the word level are designed for a specific task and struggle with out-of-domain data. If we aspire to develop models with understanding beyond the detection of superficial correspondences between inputs and outputs, then it is critical to develop a unified model that can execute a range of linguistic tasks across different domains. To facilitate research in this direction, we present the General Language Understanding Evaluation (GLUE, gluebenchmark.com): a benchmark of nine diverse NLU tasks, an auxiliary dataset for probing models for understanding of specific linguistic phenomena, and an online platform for evaluating and comparing models. For some benchmark tasks, training data is plentiful, but for others it is limited or does not match the genre of the test set. GLUE thus favors models that can represent linguistic knowledge in a way that facilitates sample-efficient learning and effective knowledge-transfer across tasks. While none of the datasets in GLUE were created from scratch for the benchmark, four of them feature privately-held test data, which is used to ensure that the benchmark is used fairly. We evaluate baselines that use ELMo (Peters et al., 2018), a powerful transfer learning technique, as well as state-of-the-art sentence representation models. The best models still achieve fairly low absolute scores. Analysis with our diagnostic dataset yields similarly weak performance over all phenomena tested, with some exceptions."
            },
            "slug": "GLUE:-A-Multi-Task-Benchmark-and-Analysis-Platform-Wang-Singh",
            "title": {
                "fragments": [],
                "text": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A benchmark of nine diverse NLU tasks, an auxiliary dataset for probing models for understanding of specific linguistic phenomena, and an online platform for evaluating and comparing models, which favors models that can represent linguistic knowledge in a way that facilitates sample-efficient learning and effective knowledge-transfer across tasks."
            },
            "venue": {
                "fragments": [],
                "text": "BlackboxNLP@EMNLP"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144358401"
                        ],
                        "name": "Kevin Clark",
                        "slug": "Kevin-Clark",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Clark",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Clark"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707242"
                        ],
                        "name": "Minh-Thang Luong",
                        "slug": "Minh-Thang-Luong",
                        "structuredName": {
                            "firstName": "Minh-Thang",
                            "lastName": "Luong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Minh-Thang Luong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3030219"
                        ],
                        "name": "Urvashi Khandelwal",
                        "slug": "Urvashi-Khandelwal",
                        "structuredName": {
                            "firstName": "Urvashi",
                            "lastName": "Khandelwal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Urvashi Khandelwal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827616"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Le",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 85464175,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ef6948edae12eba6f1d486b8600108b9762f36ab",
            "isKey": false,
            "numCitedBy": 139,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "It can be challenging to train multi-task neural networks that outperform or even match their single-task counterparts. To help address this, we propose using knowledge distillation where single-task models teach a multi-task model. We enhance this training with teacher annealing, a novel method that gradually transitions the model from distillation to supervised learning, helping the multi-task model surpass its single-task teachers. We evaluate our approach by multi-task fine-tuning BERT on the GLUE benchmark. Our method consistently improves over standard single-task and multi-task training."
            },
            "slug": "BAM!-Born-Again-Multi-Task-Networks-for-Natural-Clark-Luong",
            "title": {
                "fragments": [],
                "text": "BAM! Born-Again Multi-Task Networks for Natural Language Understanding"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "This work proposes using knowledge distillation where single- task models teach a multi-task model, and enhances this training with teacher annealing, a novel method that gradually transitions the model from distillation to supervised learning, helping the multi- task model surpass its single-task teachers."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10666396"
                        ],
                        "name": "Nikita Nangia",
                        "slug": "Nikita-Nangia",
                        "structuredName": {
                            "firstName": "Nikita",
                            "lastName": "Nangia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nikita Nangia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3644767"
                        ],
                        "name": "Samuel R. Bowman",
                        "slug": "Samuel-R.-Bowman",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Bowman",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samuel R. Bowman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 0
                            }
                        ],
                        "text": "Nangia and Bowman (2019) establish human performance for RTE."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 149
                            }
                        ],
                        "text": "\u2026Score (83.8 with the BERT-based MT-DNN system from Liu et al., 2019c) is only 3.3 points behind our estimate of global human performance (87.1 from Nangia and Bowman, 2019), and in fact exceeds this human performance estimate on three tasks.2\nIn response to this significant (and surprising)\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": ", 2019) have clearly surpassed estimates of non-expert human performance on GLUE (Nangia and Bowman, 2019)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 162
                            }
                        ],
                        "text": "We follow a two step procedure where a crowd worker completes a short training phase before proceeding to the annotations phase, modeled after the method used by Nangia and Bowman (2019) for GLUE."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 156053191,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4888102774ad93140391f3a26af0f54cfba5ec34",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "The GLUE benchmark (Wang et al., 2019b) is a suite of language understanding tasks which has seen dramatic progress in the past year, with average performance moving from 70.0 at launch to 83.9, state of the art at the time of writing (May 24, 2019). Here, we measure human performance on the benchmark, in order to learn whether significant headroom remains for further progress. We provide a conservative estimate of human performance on the benchmark through crowdsourcing: Our annotators are non-experts who must learn each task from a brief set of instructions and 20 examples. In spite of limited training, these annotators robustly outperform the state of the art on six of the nine GLUE tasks and achieve an average score of 87.1. Given the fast pace of progress however, the headroom we observe is quite limited. To reproduce the data-poor setting that our annotators must learn in, we also train the BERT model (Devlin et al., 2019) in limited-data regimes, and conclude that low-resource sentence classification remains a challenge for modern neural network approaches to text understanding."
            },
            "slug": "Human-vs.-Muppet:-A-Conservative-Estimate-of-Human-Nangia-Bowman",
            "title": {
                "fragments": [],
                "text": "Human vs. Muppet: A Conservative Estimate of Human Performance on the GLUE Benchmark"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "It is concluded that low-resource sentence classification remains a challenge for modern neural network approaches to text understanding using the BERT model in limited-data regimes."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40642935"
                        ],
                        "name": "Matt Gardner",
                        "slug": "Matt-Gardner",
                        "structuredName": {
                            "firstName": "Matt",
                            "lastName": "Gardner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matt Gardner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40695489"
                        ],
                        "name": "Joel Grus",
                        "slug": "Joel-Grus",
                        "structuredName": {
                            "firstName": "Joel",
                            "lastName": "Grus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joel Grus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50043859"
                        ],
                        "name": "Mark Neumann",
                        "slug": "Mark-Neumann",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Neumann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Neumann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3385516"
                        ],
                        "name": "Oyvind Tafjord",
                        "slug": "Oyvind-Tafjord",
                        "structuredName": {
                            "firstName": "Oyvind",
                            "lastName": "Tafjord",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oyvind Tafjord"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2697425"
                        ],
                        "name": "Pradeep Dasigi",
                        "slug": "Pradeep-Dasigi",
                        "structuredName": {
                            "firstName": "Pradeep",
                            "lastName": "Dasigi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pradeep Dasigi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "22243769"
                        ],
                        "name": "Nelson F. Liu",
                        "slug": "Nelson-F.-Liu",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Liu",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nelson F. Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39139825"
                        ],
                        "name": "Matthew E. Peters",
                        "slug": "Matthew-E.-Peters",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Peters",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew E. Peters"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144874222"
                        ],
                        "name": "Michael Schmitz",
                        "slug": "Michael-Schmitz",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Schmitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Schmitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 146
                            }
                        ],
                        "text": "Software Tools To facilitate using SuperGLUE, we will release a toolkit, built around PyTorch (Paszke et al., 2017) and components from AllenNLP (Gardner et al., 2017), which implements our baselines and supports the evaluation of custom models and training methods on the benchmark tasks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 295,
                                "start": 275
                            }
                        ],
                        "text": "\u2022 To facilitate the development of unified new methods for this more diverse set of tasks, SuperGLUE is distributed with a modular modeling toolkit for work on pretraining, multitask learning, and transfer learning in NLP, built on PyTorch (Paszke et al., 2017) and AllenNLP (Gardner et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 37
                            }
                        ],
                        "text": ", 2017) and components from AllenNLP (Gardner et al., 2017), which implements our baselines and supports the evaluation of custom models and training methods on the benchmark tasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3994096,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "93b4cc549a1bc4bc112189da36c318193d05d806",
            "isKey": false,
            "numCitedBy": 893,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Modern natural language processing (NLP) research requires writing code. Ideally this code would provide a precise definition of the approach, easy repeatability of results, and a basis for extending the research. However, many research codebases bury high-level parameters under implementation details, are challenging to run and debug, and are difficult enough to extend that they are more likely to be rewritten. This paper describes AllenNLP, a library for applying deep learning methods to NLP research that addresses these issues with easy-to-use command-line tools, declarative configuration-driven experiments, and modular NLP abstractions. AllenNLP has already increased the rate of research experimentation and the sharing of NLP components at the Allen Institute for Artificial Intelligence, and we are working to have the same impact across the field."
            },
            "slug": "AllenNLP:-A-Deep-Semantic-Natural-Language-Platform-Gardner-Grus",
            "title": {
                "fragments": [],
                "text": "AllenNLP: A Deep Semantic Natural Language Processing Platform"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "AllenNLP is described, a library for applying deep learning methods to NLP research that addresses issues with easy-to-use command-line tools, declarative configuration-driven experiments, and modular NLP abstractions."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39172707"
                        ],
                        "name": "Jacob Devlin",
                        "slug": "Jacob-Devlin",
                        "structuredName": {
                            "firstName": "Jacob",
                            "lastName": "Devlin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jacob Devlin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744179"
                        ],
                        "name": "Ming-Wei Chang",
                        "slug": "Ming-Wei-Chang",
                        "structuredName": {
                            "firstName": "Ming-Wei",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming-Wei Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2544107"
                        ],
                        "name": "Kenton Lee",
                        "slug": "Kenton-Lee",
                        "structuredName": {
                            "firstName": "Kenton",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenton Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3259253"
                        ],
                        "name": "Kristina Toutanova",
                        "slug": "Kristina-Toutanova",
                        "structuredName": {
                            "firstName": "Kristina",
                            "lastName": "Toutanova",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kristina Toutanova"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 199
                            }
                        ],
                        "text": "The past year has seen a surge of progress across many natural language processing (NLP) tasks, led by pretrained models like ELMo (Peters et al., 2018), OpenAI GPT (Radford et al., 2018), and BERT (Devlin et al., 2019)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 48
                            }
                        ],
                        "text": "For training, we use the procedure specified in Devlin et al. (2019)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 161
                            }
                        ],
                        "text": "The tasks that have proven amenable to this general approach include question answering, sentiment analysis, textual entailment, and parsing, among many others (Devlin et al., 2019; Kitaev and Klein, 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 5
                            }
                        ],
                        "text": "from Devlin et al. (2019), for each task, we use the simplest possible architecture on top of BERT, described in brief below."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 160
                            }
                        ],
                        "text": "Since its release, GLUE has been used as a testbed and showcase by the developers of several influential models, including GPT (Radford et al., 2018) and BERT (Devlin et al., 2019)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 52967399,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "isKey": true,
            "numCitedBy": 33777,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement)."
            },
            "slug": "BERT:-Pre-training-of-Deep-Bidirectional-for-Devlin-Chang",
            "title": {
                "fragments": [],
                "text": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "A new language representation model, BERT, designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers, which can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "80842917"
                        ],
                        "name": "Jason Phang",
                        "slug": "Jason-Phang",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Phang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jason Phang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "79215748"
                        ],
                        "name": "Thibault F\u00e9vry",
                        "slug": "Thibault-F\u00e9vry",
                        "structuredName": {
                            "firstName": "Thibault",
                            "lastName": "F\u00e9vry",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thibault F\u00e9vry"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3644767"
                        ],
                        "name": "Samuel R. Bowman",
                        "slug": "Samuel-R.-Bowman",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Bowman",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samuel R. Bowman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 10
                            }
                        ],
                        "text": "Recently, Phang et al. (2018) showed that BERT could be improved by extending pretraining with labeled data related to a target task, and Liu et al. (2019c) showed further improvements using a specialized form of multi-task learning with parameter sharing."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 134
                            }
                        ],
                        "text": "Given the productive use of MultiNLI in pretraining and intermediate fine-tuning of pretrained language models (Conneau et al., 2017; Phang et al., 2018, i.a.), for CB and RTE, we use MultiNLI as a transfer task by first using the above procedure on MultiNLI."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 181
                            }
                        ],
                        "text": "We also report results using BERT with additional training on related datasets before fine-tuning on the SuperGLUE tasks, following the STILTs two-stage style of transfer learning (Phang et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 53221289,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b47381e04739ea3f392ba6c8faaf64105493c196",
            "isKey": false,
            "numCitedBy": 264,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Pretraining sentence encoders with language modeling and related unsupervised tasks has recently been shown to be very effective for language understanding tasks. By supplementing language model-style pretraining with further training on data-rich supervised tasks, such as natural language inference, we obtain additional performance improvements on the GLUE benchmark. Applying supplementary training on BERT (Devlin et al., 2018), we attain a GLUE score of 81.8---the state of the art (as of 02/24/2019) and a 1.4 point improvement over BERT. We also observe reduced variance across random restarts in this setting. Our approach yields similar improvements when applied to ELMo (Peters et al., 2018a) and Radford et al. (2018)'s model. In addition, the benefits of supplementary training are particularly pronounced in data-constrained regimes, as we show in experiments with artificially limited training data."
            },
            "slug": "Sentence-Encoders-on-STILTs:-Supplementary-Training-Phang-F\u00e9vry",
            "title": {
                "fragments": [],
                "text": "Sentence Encoders on STILTs: Supplementary Training on Intermediate Labeled-data Tasks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The benefits of supplementary training with further training on data-rich supervised tasks, such as natural language inference, obtain additional performance improvements on the GLUE benchmark, as well as observing reduced variance across random restarts in this setting."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46522098"
                        ],
                        "name": "Xiaodong Liu",
                        "slug": "Xiaodong-Liu",
                        "structuredName": {
                            "firstName": "Xiaodong",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaodong Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50462546"
                        ],
                        "name": "Pengcheng He",
                        "slug": "Pengcheng-He",
                        "structuredName": {
                            "firstName": "Pengcheng",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pengcheng He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109136147"
                        ],
                        "name": "Weizhu Chen",
                        "slug": "Weizhu-Chen",
                        "structuredName": {
                            "firstName": "Weizhu",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Weizhu Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800422"
                        ],
                        "name": "Jianfeng Gao",
                        "slug": "Jianfeng-Gao",
                        "structuredName": {
                            "firstName": "Jianfeng",
                            "lastName": "Gao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianfeng Gao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 102
                            }
                        ],
                        "text": "The outside results for COPA, MultiRC, and RTE are from Sap et al. (2019), Trivedi et al. (2019), and Liu et al. (2019c) respectively."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 48
                            }
                        ],
                        "text": "%) at the time of GLUE\u2019s launch to 85% accuracy (Liu et al., 2019c) at the time of writing."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 138
                            }
                        ],
                        "text": "Recently, Phang et al. (2018) showed that BERT could be improved by extending pretraining with labeled data related to a target task, and Liu et al. (2019c) showed further improvements using a specialized form of multi-task learning with parameter sharing."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 142
                            }
                        ],
                        "text": "\u2026phenomena (Figure 2) measured in GLUE remain difficult, the current state of the art GLUE Score (83.8 with the BERT-based MT-DNN system from Liu et al., 2019c) is only 3.3 points behind our estimate of global human performance (87.1 from Nangia and Bowman, 2019), and in fact exceeds this\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 135
                            }
                        ],
                        "text": "Much recent work has observed this for NLI and QA (Jia and Liang, 2017; Naik et al., 2018; McCoy and Linzen, 2019; McCoy et al., 2019; Liu et al., 2019a,b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59523594,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "658721bc13b0fa97366d38c05a96bf0a9f4bb0ac",
            "isKey": true,
            "numCitedBy": 732,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a Multi-Task Deep Neural Network (MT-DNN) for learning representations across multiple natural language understanding (NLU) tasks. MT-DNN not only leverages large amounts of cross-task data, but also benefits from a regularization effect that leads to more general representations to help adapt to new tasks and domains. MT-DNN extends the model proposed in Liu et al. (2015) by incorporating a pre-trained bidirectional transformer language model, known as BERT (Devlin et al., 2018). MT-DNN obtains new state-of-the-art results on ten NLU tasks, including SNLI, SciTail, and eight out of nine GLUE tasks, pushing the GLUE benchmark to 82.7% (2.2% absolute improvement) as of February 25, 2019 on the latest GLUE test set. We also demonstrate using the SNLI and SciTail datasets that the representations learned by MT-DNN allow domain adaptation with substantially fewer in-domain labels than the pre-trained BERT representations. Our code and pre-trained models will be made publicly available."
            },
            "slug": "Multi-Task-Deep-Neural-Networks-for-Natural-Liu-He",
            "title": {
                "fragments": [],
                "text": "Multi-Task Deep Neural Networks for Natural Language Understanding"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A Multi-Task Deep Neural Network (MT-DNN) for learning representations across multiple natural language understanding (NLU) tasks that allows domain adaptation with substantially fewer in-domain labels than the pre-trained BERT representations."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "22243769"
                        ],
                        "name": "Nelson F. Liu",
                        "slug": "Nelson-F.-Liu",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Liu",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nelson F. Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40642935"
                        ],
                        "name": "Matt Gardner",
                        "slug": "Matt-Gardner",
                        "structuredName": {
                            "firstName": "Matt",
                            "lastName": "Gardner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matt Gardner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2083259"
                        ],
                        "name": "Yonatan Belinkov",
                        "slug": "Yonatan-Belinkov",
                        "structuredName": {
                            "firstName": "Yonatan",
                            "lastName": "Belinkov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yonatan Belinkov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39139825"
                        ],
                        "name": "Matthew E. Peters",
                        "slug": "Matthew-E.-Peters",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Peters",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew E. Peters"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144365875"
                        ],
                        "name": "Noah A. Smith",
                        "slug": "Noah-A.-Smith",
                        "structuredName": {
                            "firstName": "Noah",
                            "lastName": "Smith",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Noah A. Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 102
                            }
                        ],
                        "text": "The outside results for COPA, MultiRC, and RTE are from Sap et al. (2019), Trivedi et al. (2019), and Liu et al. (2019c) respectively."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 48
                            }
                        ],
                        "text": "%) at the time of GLUE\u2019s launch to 85% accuracy (Liu et al., 2019c) at the time of writing."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 138
                            }
                        ],
                        "text": "Recently, Phang et al. (2018) showed that BERT could be improved by extending pretraining with labeled data related to a target task, and Liu et al. (2019c) showed further improvements using a specialized form of multi-task learning with parameter sharing."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 142
                            }
                        ],
                        "text": "\u2026phenomena (Figure 2) measured in GLUE remain difficult, the current state of the art GLUE Score (83.8 with the BERT-based MT-DNN system from Liu et al., 2019c) is only 3.3 points behind our estimate of global human performance (87.1 from Nangia and Bowman, 2019), and in fact exceeds this\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 135
                            }
                        ],
                        "text": "Much recent work has observed this for NLI and QA (Jia and Liang, 2017; Naik et al., 2018; McCoy and Linzen, 2019; McCoy et al., 2019; Liu et al., 2019a,b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 84841767,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6fbb6809374ca57205bd2cf1421d4f4fa04f975",
            "isKey": true,
            "numCitedBy": 443,
            "numCiting": 108,
            "paperAbstract": {
                "fragments": [],
                "text": "Contextual word representations derived from large-scale neural language models are successful across a diverse set of NLP tasks, suggesting that they encode useful and transferable features of language. To shed light on the linguistic knowledge they capture, we study the representations produced by several recent pretrained contextualizers (variants of ELMo, the OpenAI transformer language model, and BERT) with a suite of sixteen diverse probing tasks. We find that linear models trained on top of frozen contextual representations are competitive with state-of-the-art task-specific models in many cases, but fail on tasks requiring fine-grained linguistic knowledge (e.g., conjunct identification). To investigate the transferability of contextual word representations, we quantify differences in the transferability of individual layers within contextualizers, especially between recurrent neural networks (RNNs) and transformers. For instance, higher layers of RNNs are more task-specific, while transformer layers do not exhibit the same monotonic trend. In addition, to better understand what makes contextual word representations transferable, we compare language model pretraining with eleven supervised pretraining tasks. For any given task, pretraining on a closely related task yields better performance than language model pretraining (which is better on average) when the pretraining dataset is fixed. However, language model pretraining on more data gives the best results."
            },
            "slug": "Linguistic-Knowledge-and-Transferability-of-Liu-Gardner",
            "title": {
                "fragments": [],
                "text": "Linguistic Knowledge and Transferability of Contextual Representations"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is found that linear models trained on top of frozen contextual representations are competitive with state-of-the-art task-specific models in many cases, but fail on tasks requiring fine-grained linguistic knowledge."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143808231"
                        ],
                        "name": "Nikita Kitaev",
                        "slug": "Nikita-Kitaev",
                        "structuredName": {
                            "firstName": "Nikita",
                            "lastName": "Kitaev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nikita Kitaev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "65856360"
                        ],
                        "name": "Steven Cao",
                        "slug": "Steven-Cao",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Cao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steven Cao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38666915"
                        ],
                        "name": "D. Klein",
                        "slug": "D.-Klein",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Klein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Klein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 182
                            }
                        ],
                        "text": "The tasks that have proven amenable to this general approach include question answering, sentiment analysis, textual entailment, and parsing, among many others (Devlin et al., 2019; Kitaev and Klein, 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 57189558,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "526cae4863eb15b5bc39112449c2d5fdf1db85b2",
            "isKey": false,
            "numCitedBy": 104,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We show that constituency parsing benefits from unsupervised pre-training across a variety of languages and a range of pre-training conditions. We first compare the benefits of no pre-training, fastText, ELMo, and BERT for English and find that BERT outperforms ELMo, in large part due to increased model capacity, whereas ELMo in turn outperforms the non-contextual fastText embeddings. We also find that pre-training is beneficial across all 11 languages tested; however, large model sizes (more than 100 million parameters) make it computationally expensive to train separate models for each language. To address this shortcoming, we show that joint multilingual pre-training and fine-tuning allows sharing all but a small number of parameters between ten languages in the final model. The 10x reduction in model size compared to fine-tuning one model per language causes only a 3.2% relative error increase in aggregate. We further explore the idea of joint fine-tuning and show that it gives low-resource languages a way to benefit from the larger datasets of other languages. Finally, we demonstrate new state-of-the-art results for 11 languages, including English (95.8 F1) and Chinese (91.8 F1)."
            },
            "slug": "Multilingual-Constituency-Parsing-with-and-Kitaev-Cao",
            "title": {
                "fragments": [],
                "text": "Multilingual Constituency Parsing with Self-Attention and Pre-Training"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "It is shown that constituency parsing benefits from unsupervised pre-training across a variety of languages and a range of pre- training conditions, and the idea of joint fine-tuning is explored and shows that it gives low-resource languages a way to benefit from the larger datasets of other languages."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143997772"
                        ],
                        "name": "Christopher Clark",
                        "slug": "Christopher-Clark",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Clark",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher Clark"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2544107"
                        ],
                        "name": "Kenton Lee",
                        "slug": "Kenton-Lee",
                        "structuredName": {
                            "firstName": "Kenton",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenton Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744179"
                        ],
                        "name": "Ming-Wei Chang",
                        "slug": "Ming-Wei-Chang",
                        "structuredName": {
                            "firstName": "Ming-Wei",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming-Wei Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15652489"
                        ],
                        "name": "T. Kwiatkowski",
                        "slug": "T.-Kwiatkowski",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Kwiatkowski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kwiatkowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "123052390"
                        ],
                        "name": "Michael Collins",
                        "slug": "Michael-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Collins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3259253"
                        ],
                        "name": "Kristina Toutanova",
                        "slug": "Kristina-Toutanova",
                        "structuredName": {
                            "firstName": "Kristina",
                            "lastName": "Toutanova",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kristina Toutanova"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 165163607,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9770fff7379a7ab9006b48939462354dda9a2053",
            "isKey": false,
            "numCitedBy": 229,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we study yes/no questions that are naturally occurring \u2014 meaning that they are generated in unprompted and unconstrained settings. We build a reading comprehension dataset, BoolQ, of such questions, and show that they are unexpectedly challenging. They often query for complex, non-factoid information, and require difficult entailment-like inference to solve. We also explore the effectiveness of a range of transfer learning baselines. We find that transferring from entailment data is more effective than transferring from paraphrase or extractive QA data, and that it, surprisingly, continues to be very beneficial even when starting from massive pre-trained language models such as BERT. Our best method trains BERT on MultiNLI and then re-trains it on our train set. It achieves 80.4% accuracy compared to 90% accuracy of human annotators (and 62% majority-baseline), leaving a significant gap for future work."
            },
            "slug": "BoolQ:-Exploring-the-Surprising-Difficulty-of-Clark-Lee",
            "title": {
                "fragments": [],
                "text": "BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is found that transferring from entailment data is more effective than transferring from paraphrase or extractive QA data, and that it, surprisingly, continues to be very beneficial even when starting from massive pre-trained language models such as BERT."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2544107"
                        ],
                        "name": "Kenton Lee",
                        "slug": "Kenton-Lee",
                        "structuredName": {
                            "firstName": "Kenton",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenton Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2265599"
                        ],
                        "name": "Luheng He",
                        "slug": "Luheng-He",
                        "structuredName": {
                            "firstName": "Luheng",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luheng He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35084211"
                        ],
                        "name": "M. Lewis",
                        "slug": "M.-Lewis",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Lewis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 173
                            }
                        ],
                        "text": "Given the BERT representation for each word in the original sentence, we get span representations of the pronoun and noun phrase via a self-attention span-pooling operator (Lee et al., 2017), before feeding it into a logistic regression classifier."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1222212,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8ae1af4a424f5e464d46903bc3d18fe1cf1434ff",
            "isKey": false,
            "numCitedBy": 602,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce the first end-to-end coreference resolution model and show that it significantly outperforms all previous work without using a syntactic parser or hand-engineered mention detector. The key idea is to directly consider all spans in a document as potential mentions and learn distributions over possible antecedents for each. The model computes span embeddings that combine context-dependent boundary representations with a head-finding attention mechanism. It is trained to maximize the marginal likelihood of gold antecedent spans from coreference clusters and is factored to enable aggressive pruning of potential mentions. Experiments demonstrate state-of-the-art performance, with a gain of 1.5 F1 on the OntoNotes benchmark and by 3.1 F1 using a 5-model ensemble, despite the fact that this is the first approach to be successfully trained with no external resources."
            },
            "slug": "End-to-end-Neural-Coreference-Resolution-Lee-He",
            "title": {
                "fragments": [],
                "text": "End-to-end Neural Coreference Resolution"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "This work introduces the first end-to-end coreference resolution model, trained to maximize the marginal likelihood of gold antecedent spans from coreference clusters and is factored to enable aggressive pruning of potential mentions."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783281"
                        ],
                        "name": "Daniel Khashabi",
                        "slug": "Daniel-Khashabi",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Khashabi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Khashabi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37202877"
                        ],
                        "name": "Snigdha Chaturvedi",
                        "slug": "Snigdha-Chaturvedi",
                        "structuredName": {
                            "firstName": "Snigdha",
                            "lastName": "Chaturvedi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Snigdha Chaturvedi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46617131"
                        ],
                        "name": "Michael Roth",
                        "slug": "Michael-Roth",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Roth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33145619"
                        ],
                        "name": "Shyam Upadhyay",
                        "slug": "Shyam-Upadhyay",
                        "structuredName": {
                            "firstName": "Shyam",
                            "lastName": "Upadhyay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shyam Upadhyay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 11
                            }
                        ],
                        "text": "Similarly, Khashabi et al. (2018) also provide a human performance estimate with the release of\nMultiRC."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 67
                            }
                        ],
                        "text": "MultiRC The Multi-Sentence Reading Comprehension dataset (MultiRC, Khashabi et al., 2018) is a true/false question-answering task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5112038,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "99ad0533f84c110da2d0713d5798e6e14080b159",
            "isKey": false,
            "numCitedBy": 254,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a reading comprehension challenge in which questions can only be answered by taking into account information from multiple sentences. We solicit and verify questions and answers for this challenge through a 4-step crowdsourcing experiment. Our challenge dataset contains 6,500+ questions for 1000+ paragraphs across 7 different domains (elementary school science, news, travel guides, fiction stories, etc) bringing in linguistic diversity to the texts and to the questions wordings. On a subset of our dataset, we found human solvers to achieve an F1-score of 88.1%. We analyze a range of baselines, including a recent state-of-art reading comprehension system, and demonstrate the difficulty of this challenge, despite a high human performance. The dataset is the first to study multi-sentence inference at scale, with an open-ended set of question types that requires reasoning skills."
            },
            "slug": "Looking-Beyond-the-Surface:-A-Challenge-Set-for-Khashabi-Chaturvedi",
            "title": {
                "fragments": [],
                "text": "Looking Beyond the Surface: A Challenge Set for Reading Comprehension over Multiple Sentences"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The dataset is the first to study multi-sentence inference at scale, with an open-ended set of question types that requires reasoning skills, and finds human solvers to achieve an F1-score of 88.1%."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38909097"
                        ],
                        "name": "Alec Radford",
                        "slug": "Alec-Radford",
                        "structuredName": {
                            "firstName": "Alec",
                            "lastName": "Radford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alec Radford"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144958935"
                        ],
                        "name": "Karthik Narasimhan",
                        "slug": "Karthik-Narasimhan",
                        "structuredName": {
                            "firstName": "Karthik",
                            "lastName": "Narasimhan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karthik Narasimhan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 20
                            }
                        ],
                        "text": ", 2018), OpenAI GPT (Radford et al., 2018), and BERT (Devlin et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 127
                            }
                        ],
                        "text": "Since its release, GLUE has been used as a testbed and showcase by the developers of several influential models, including GPT (Radford et al., 2018) and BERT (Devlin et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 128
                            }
                        ],
                        "text": "Since its release, GLUE has been used as a testbed and showcase by the developers of several influential models, including GPT (Radford et al., 2018) and BERT (Devlin et al., 2019)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 166
                            }
                        ],
                        "text": "The past year has seen a surge of progress across many natural language processing (NLP) tasks, led by pretrained models like ELMo (Peters et al., 2018), OpenAI GPT (Radford et al., 2018), and BERT (Devlin et al., 2019)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 49313245,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035",
            "isKey": true,
            "numCitedBy": 3536,
            "numCiting": 76,
            "paperAbstract": {
                "fragments": [],
                "text": "Natural language understanding comprises a wide range of diverse tasks such as textual entailment, question answering, semantic similarity assessment, and document classi\ufb01cation. Although large unlabeled text corpora are abundant, labeled data for learning these speci\ufb01c tasks is scarce, making it challenging for discriminatively trained models to perform adequately. We demonstrate that large gains on these tasks can be realized by generative pre-training of a language model on a diverse corpus of unlabeled text, followed by discriminative \ufb01ne-tuning on each speci\ufb01c task. In contrast to previous approaches, we make use of task-aware input transformations during \ufb01ne-tuning to achieve effective transfer while requiring minimal changes to the model architecture. We demonstrate the effectiveness of our approach on a wide range of benchmarks for natural language understanding. Our general task-agnostic model outperforms discriminatively trained models that use architectures speci\ufb01cally crafted for each task, signi\ufb01cantly improving upon the state of the art in 9 out of the 12 tasks studied. For instance, we achieve absolute improvements of 8.9% on commonsense reasoning (Stories Cloze Test), 5.7% on question answering (RACE), and 1.5% on textual entailment (MultiNLI)."
            },
            "slug": "Improving-Language-Understanding-by-Generative-Radford-Narasimhan",
            "title": {
                "fragments": [],
                "text": "Improving Language Understanding by Generative Pre-Training"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The general task-agnostic model outperforms discriminatively trained models that use architectures speci\ufb01cally crafted for each task, improving upon the state of the art in 9 out of the 12 tasks studied."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46522098"
                        ],
                        "name": "Xiaodong Liu",
                        "slug": "Xiaodong-Liu",
                        "structuredName": {
                            "firstName": "Xiaodong",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaodong Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50462546"
                        ],
                        "name": "Pengcheng He",
                        "slug": "Pengcheng-He",
                        "structuredName": {
                            "firstName": "Pengcheng",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pengcheng He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109136147"
                        ],
                        "name": "Weizhu Chen",
                        "slug": "Weizhu-Chen",
                        "structuredName": {
                            "firstName": "Weizhu",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Weizhu Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800422"
                        ],
                        "name": "Jianfeng Gao",
                        "slug": "Jianfeng-Gao",
                        "structuredName": {
                            "firstName": "Jianfeng",
                            "lastName": "Gao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianfeng Gao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 102
                            }
                        ],
                        "text": "The outside results for COPA, MultiRC, and RTE are from Sap et al. (2019), Trivedi et al. (2019), and Liu et al. (2019c) respectively."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 48
                            }
                        ],
                        "text": "%) at the time of GLUE\u2019s launch to 85% accuracy (Liu et al., 2019c) at the time of writing."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 138
                            }
                        ],
                        "text": "Recently, Phang et al. (2018) showed that BERT could be improved by extending pretraining with labeled data related to a target task, and Liu et al. (2019c) showed further improvements using a specialized form of multi-task learning with parameter sharing."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 142
                            }
                        ],
                        "text": "\u2026phenomena (Figure 2) measured in GLUE remain difficult, the current state of the art GLUE Score (83.8 with the BERT-based MT-DNN system from Liu et al., 2019c) is only 3.3 points behind our estimate of global human performance (87.1 from Nangia and Bowman, 2019), and in fact exceeds this\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 135
                            }
                        ],
                        "text": "Much recent work has observed this for NLI and QA (Jia and Liang, 2017; Naik et al., 2018; McCoy and Linzen, 2019; McCoy et al., 2019; Liu et al., 2019a,b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 128345418,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ebed46b7f3ec913e508e6468304fcaea832eda1",
            "isKey": true,
            "numCitedBy": 103,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper explores the use of knowledge distillation to improve a Multi-Task Deep Neural Network (MT-DNN) (Liu et al., 2019) for learning text representations across multiple natural language understanding tasks. Although ensemble learning can improve model performance, serving an ensemble of large DNNs such as MT-DNN can be prohibitively expensive. Here we apply the knowledge distillation method (Hinton et al., 2015) in the multi-task learning setting. For each task, we train an ensemble of different MT-DNNs (teacher) that outperforms any single model, and then train a single MT-DNN (student) via multi-task learning to \\emph{distill} knowledge from these ensemble teachers. We show that the distilled MT-DNN significantly outperforms the original MT-DNN on 7 out of 9 GLUE tasks, pushing the GLUE benchmark (single model) to 83.7\\% (1.5\\% absolute improvement\\footnote{ Based on the GLUE leaderboard at this https URL as of April 1, 2019.}). The code and pre-trained models will be made publicly available at this https URL."
            },
            "slug": "Improving-Multi-Task-Deep-Neural-Networks-via-for-Liu-He",
            "title": {
                "fragments": [],
                "text": "Improving Multi-Task Deep Neural Networks via Knowledge Distillation for Natural Language Understanding"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "This paper explores the use of knowledge distillation to improve a Multi-Task Deep Neural Network (MT-DNN) (Liu et al., 2019) for learning text representations across multiple natural language understanding tasks and shows that the distilled MT-dNN significantly outperforms the original MT- DNN on 7 out of 9 GLUE tasks."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2480903"
                        ],
                        "name": "A. Conneau",
                        "slug": "A.-Conneau",
                        "structuredName": {
                            "firstName": "Alexis",
                            "lastName": "Conneau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Conneau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743722"
                        ],
                        "name": "Douwe Kiela",
                        "slug": "Douwe-Kiela",
                        "structuredName": {
                            "firstName": "Douwe",
                            "lastName": "Kiela",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Douwe Kiela"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 54
                            }
                        ],
                        "text": "Other similarly-motivated benchmarks include SentEval (Conneau and Kiela, 2018), which evaluates fixed-size sentence embeddings, and DecaNLP (McCann et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 55
                            }
                        ],
                        "text": "Other similarly-motivated benchmarks include SentEval (Conneau and Kiela, 2018), which evaluates fixed-size sentence embeddings, and DecaNLP (McCann et al., 2018), which recasts a set of target tasks into a general question-answering format and prohibits task-specific parameters."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 349,
                                "start": 197
                            }
                        ],
                        "text": "Much work prior to GLUE has demonstrated that training neural models with large amounts of available supervision can produce representations that effectively transfer to a broad range of NLP tasks (Collobert and Weston, 2008; Dai and Le, 2015; Kiros et al., 2015; Hill et al., 2016; Conneau and Kiela, 2018; McCann et al., 2017; Peters et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 252,
                                "start": 229
                            }
                        ],
                        "text": "\u2026neural models with large amounts of available supervision can produce representations that effectively transfer to a broad range of NLP tasks (Collobert and Weston, 2008; Dai and Le, 2015; Kiros et al., 2015; Hill et al., 2016; Conneau and Kiela, 2018; McCann et al., 2017; Peters et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3932228,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7113bd87c3e6f727efae24ee52f20c81358da761",
            "isKey": true,
            "numCitedBy": 324,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce SentEval, a toolkit for evaluating the quality of universal sentence representations. SentEval encompasses a variety of tasks, including binary and multi-class classification, natural language inference and sentence similarity. The set of tasks was selected based on what appears to be the community consensus regarding the appropriate evaluations for universal sentence representations. The toolkit comes with scripts to download and preprocess datasets, and an easy interface to evaluate sentence encoders. The aim is to provide a fairer, less cumbersome and more centralized way for evaluating sentence representations."
            },
            "slug": "SentEval:-An-Evaluation-Toolkit-for-Universal-Conneau-Kiela",
            "title": {
                "fragments": [],
                "text": "SentEval: An Evaluation Toolkit for Universal Sentence Representations"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "SentEval is introduced, a toolkit for evaluating the quality of universal sentence representations that encompasses a variety of tasks, including binary and multi-class classification, natural language inference and sentence similarity."
            },
            "venue": {
                "fragments": [],
                "text": "LREC"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "26997985"
                        ],
                        "name": "Vid Kocijan",
                        "slug": "Vid-Kocijan",
                        "structuredName": {
                            "firstName": "Vid",
                            "lastName": "Kocijan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vid Kocijan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "100797192"
                        ],
                        "name": "Ana-Maria Cretu",
                        "slug": "Ana-Maria-Cretu",
                        "structuredName": {
                            "firstName": "Ana-Maria",
                            "lastName": "Cretu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ana-Maria Cretu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3317152"
                        ],
                        "name": "Oana-Maria Camburu",
                        "slug": "Oana-Maria-Camburu",
                        "structuredName": {
                            "firstName": "Oana-Maria",
                            "lastName": "Camburu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oana-Maria Camburu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15923813"
                        ],
                        "name": "Yordan Yordanov",
                        "slug": "Yordan-Yordanov",
                        "structuredName": {
                            "firstName": "Yordan",
                            "lastName": "Yordanov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yordan Yordanov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690572"
                        ],
                        "name": "Thomas Lukasiewicz",
                        "slug": "Thomas-Lukasiewicz",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Lukasiewicz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Lukasiewicz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "2 In the past few months, several works (Kocijan et al., 2019; Liu et al., 2019d) have made rapid progress via a hueristic data augmentation scheme, raising machine performance to 90."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 155091369,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c57298fe3faf87f9f24414821b0df7ebb7634320",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "The Winograd Schema Challenge (WSC) dataset WSC273 and its inference counterpart WNLI are popular benchmarks for natural language understanding and commonsense reasoning. In this paper, we show that the performance of three language models on WSC273 strongly improves when fine-tuned on a similar pronoun disambiguation problem dataset (denoted WSCR). We additionally generate a large unsupervised WSC-like dataset. By fine-tuning the BERT language model both on the introduced and on the WSCR dataset, we achieve overall accuracies of 72.2% and 71.9% on WSC273 and WNLI, improving the previous state-of-the-art solutions by 8.5% and 6.8%, respectively. Furthermore, our fine-tuned models are also consistently more robust on the \u201ccomplex\u201d subsets of WSC273, introduced by Trichelair et al. (2018)."
            },
            "slug": "A-Surprisingly-Robust-Trick-for-the-Winograd-Schema-Kocijan-Cretu",
            "title": {
                "fragments": [],
                "text": "A Surprisingly Robust Trick for the Winograd Schema Challenge"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper shows that the performance of three language models on WSC273 strongly improves when fine-tuned on a similar pronoun disambiguation problem dataset (denoted WSCR), and generates a large unsupervised WSC-like dataset."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6117577"
                        ],
                        "name": "Ian Tenney",
                        "slug": "Ian-Tenney",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Tenney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ian Tenney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2465658"
                        ],
                        "name": "Patrick Xia",
                        "slug": "Patrick-Xia",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Xia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Patrick Xia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108381400"
                        ],
                        "name": "Berlin Chen",
                        "slug": "Berlin-Chen",
                        "structuredName": {
                            "firstName": "Berlin",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Berlin Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144906624"
                        ],
                        "name": "Alex Wang",
                        "slug": "Alex-Wang",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48926630"
                        ],
                        "name": "Adam Poliak",
                        "slug": "Adam-Poliak",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Poliak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adam Poliak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145534175"
                        ],
                        "name": "R. Thomas McCoy",
                        "slug": "R.-Thomas-McCoy",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "McCoy",
                            "middleNames": [
                                "Thomas"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Thomas McCoy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8756748"
                        ],
                        "name": "Najoung Kim",
                        "slug": "Najoung-Kim",
                        "structuredName": {
                            "firstName": "Najoung",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Najoung Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7536576"
                        ],
                        "name": "Benjamin Van Durme",
                        "slug": "Benjamin-Van-Durme",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Durme",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benjamin Van Durme"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3644767"
                        ],
                        "name": "Samuel R. Bowman",
                        "slug": "Samuel-R.-Bowman",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Bowman",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samuel R. Bowman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143790066"
                        ],
                        "name": "Dipanjan Das",
                        "slug": "Dipanjan-Das",
                        "structuredName": {
                            "firstName": "Dipanjan",
                            "lastName": "Das",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dipanjan Das"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2949185"
                        ],
                        "name": "Ellie Pavlick",
                        "slug": "Ellie-Pavlick",
                        "structuredName": {
                            "firstName": "Ellie",
                            "lastName": "Pavlick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ellie Pavlick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 66
                            }
                        ],
                        "text": "For WSC, which is a a span-based task, we use a model inspired by Tenney et al. (2019)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 108300988,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e2587eddd57bc4ba286d91b27c185083f16f40ee",
            "isKey": false,
            "numCitedBy": 496,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "Contextualized representation models such as ELMo (Peters et al., 2018a) and BERT (Devlin et al., 2018) have recently achieved state-of-the-art results on a diverse array of downstream NLP tasks. Building on recent token-level probing work, we introduce a novel edge probing task design and construct a broad suite of sub-sentence tasks derived from the traditional structured NLP pipeline. We probe word-level contextual representations from four recent models and investigate how they encode sentence structure across a range of syntactic, semantic, local, and long-range phenomena. We find that existing models trained on language modeling and translation produce strong representations for syntactic phenomena, but only offer comparably small improvements on semantic tasks over a non-contextual baseline."
            },
            "slug": "What-do-you-learn-from-context-Probing-for-sentence-Tenney-Xia",
            "title": {
                "fragments": [],
                "text": "What do you learn from context? Probing for sentence structure in contextualized word representations"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel edge probing task design is introduced and a broad suite of sub-sentence tasks derived from the traditional structured NLP pipeline are constructed to investigate how sentence structure is encoded across a range of syntactic, semantic, local, and long-range phenomena."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939803"
                        ],
                        "name": "Ronan Collobert",
                        "slug": "Ronan-Collobert",
                        "structuredName": {
                            "firstName": "Ronan",
                            "lastName": "Collobert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronan Collobert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 144
                            }
                        ],
                        "text": "\u2026neural models with large amounts of available supervision can produce representations that effectively transfer to a broad range of NLP tasks (Collobert and Weston, 2008; Dai and Le, 2015; Kiros et al., 2015; Hill et al., 2016; Conneau and Kiela, 2018; McCann et al., 2017; Peters et al.,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 349,
                                "start": 197
                            }
                        ],
                        "text": "Much work prior to GLUE has demonstrated that training neural models with large amounts of available supervision can produce representations that effectively transfer to a broad range of NLP tasks (Collobert and Weston, 2008; Dai and Le, 2015; Kiros et al., 2015; Hill et al., 2016; Conneau and Kiela, 2018; McCann et al., 2017; Peters et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2617020,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "57458bc1cffe5caa45a885af986d70f723f406b4",
            "isKey": false,
            "numCitedBy": 5024,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, semantically similar words and the likelihood that the sentence makes sense (grammatically and semantically) using a language model. The entire network is trained jointly on all these tasks using weight-sharing, an instance of multitask learning. All the tasks use labeled data except the language model which is learnt from unlabeled text and represents a novel form of semi-supervised learning for the shared tasks. We show how both multitask learning and semi-supervised learning improve the generalization of the shared tasks, resulting in state-of-the-art-performance."
            },
            "slug": "A-unified-architecture-for-natural-language-deep-Collobert-Weston",
            "title": {
                "fragments": [],
                "text": "A unified architecture for natural language processing: deep neural networks with multitask learning"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "This work describes a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, semantically similar words and the likelihood that the sentence makes sense using a language model."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1779225"
                        ],
                        "name": "Manaal Faruqui",
                        "slug": "Manaal-Faruqui",
                        "structuredName": {
                            "firstName": "Manaal",
                            "lastName": "Faruqui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manaal Faruqui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143790066"
                        ],
                        "name": "Dipanjan Das",
                        "slug": "Dipanjan-Das",
                        "structuredName": {
                            "firstName": "Dipanjan",
                            "lastName": "Das",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dipanjan Das"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 77
                            }
                        ],
                        "text": "8BERT achieved very high or superhuman performance on Query Well-Formedness (Faruqui and Das, 2018) and PAWS (Zhang et al., 2019), Discovering Ongoing Conversations (Zanzotto and Ferrone, 2017), and GAP (Webster et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 78
                            }
                        ],
                        "text": "(8)BERT achieved very high or superhuman performance on Query Well-Formedness (Faruqui and Das, 2018) and PAWS (Zhang et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 31
                            }
                        ],
                        "text": "For the Query Well-Formedness (Faruqui and Das, 2018) task, the authors set an estimate human performance at 88.4% accuracy."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 52111971,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "18d62040534012818abb90e37eade5dab6dca716",
            "isKey": true,
            "numCitedBy": 25,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Understanding search queries is a hard problem as it involves dealing with \u201cword salad\u201d text ubiquitously issued by users. However, if a query resembles a well-formed question, a natural language processing pipeline is able to perform more accurate interpretation, thus reducing downstream compounding errors. Hence, identifying whether or not a query is well formed can enhance query understanding. Here, we introduce a new task of identifying a well-formed natural language question. We construct and release a dataset of 25,100 publicly available questions classified into well-formed and non-wellformed categories and report an accuracy of 70.7% on the test set. We also show that our classifier can be used to improve the performance of neural sequence-to-sequence models for generating questions for reading comprehension."
            },
            "slug": "Identifying-Well-formed-Natural-Language-Questions-Faruqui-Das",
            "title": {
                "fragments": [],
                "text": "Identifying Well-formed Natural Language Questions"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A new task of identifying a well-formed natural language question is introduced and a classifier is introduced that can be used to improve the performance of neural sequence-to-sequence models for generating questions for reading comprehension."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2706258"
                        ],
                        "name": "Pranav Rajpurkar",
                        "slug": "Pranav-Rajpurkar",
                        "structuredName": {
                            "firstName": "Pranav",
                            "lastName": "Rajpurkar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pranav Rajpurkar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2151810148"
                        ],
                        "name": "Jian Zhang",
                        "slug": "Jian-Zhang",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2787620"
                        ],
                        "name": "Konstantin Lopyrev",
                        "slug": "Konstantin-Lopyrev",
                        "structuredName": {
                            "firstName": "Konstantin",
                            "lastName": "Lopyrev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Konstantin Lopyrev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145419642"
                        ],
                        "name": "Percy Liang",
                        "slug": "Percy-Liang",
                        "structuredName": {
                            "firstName": "Percy",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Percy Liang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 295,
                                "start": 273
                            }
                        ],
                        "text": "\u2026to maximize difficulty and diversity, and were drawn from among those submitted to an open call for proposals.3\n2The Quora Question Pairs, The Microsoft Research Paraphrase Corpus (Dolan and Brockett, 2005), and QNLI, an answer sentence selection task derived from SQuAD (Rajpurkar et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 294,
                                "start": 289
                            }
                        ],
                        "text": "These tasks were chosen to maximize difficulty and diversity, and were drawn from among those submitted to an open call for proposals.3\n2The Quora Question Pairs, The Microsoft Research Paraphrase Corpus (Dolan and Brockett, 2005), and QNLI, an answer sentence selection task derived from SQuAD (Rajpurkar et al., 2016)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 158
                            }
                        ],
                        "text": "The Quora Question Pairs, The Microsoft Research Paraphrase Corpus (Dolan and Brockett, 2005), and QNLI, an answer sentence selection task derived from SQuAD (Rajpurkar et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11816014,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "05dd7254b632376973f3a1b4d39485da17814df5",
            "isKey": false,
            "numCitedBy": 4266,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We present the Stanford Question Answering Dataset (SQuAD), a new reading comprehension dataset consisting of 100,000+ questions posed by crowdworkers on a set of Wikipedia articles, where the answer to each question is a segment of text from the corresponding reading passage. We analyze the dataset to understand the types of reasoning required to answer the questions, leaning heavily on dependency and constituency trees. We build a strong logistic regression model, which achieves an F1 score of 51.0%, a significant improvement over a simple baseline (20%). However, human performance (86.8%) is much higher, indicating that the dataset presents a good challenge problem for future research. \nThe dataset is freely available at this https URL"
            },
            "slug": "SQuAD:-100,000+-Questions-for-Machine-Comprehension-Rajpurkar-Zhang",
            "title": {
                "fragments": [],
                "text": "SQuAD: 100,000+ Questions for Machine Comprehension of Text"
            },
            "tldr": {
                "abstractSimilarityScore": 35,
                "text": "A strong logistic regression model is built, which achieves an F1 score of 51.0%, a significant improvement over a simple baseline (20%)."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2870504"
                        ],
                        "name": "Stephen H. Bach",
                        "slug": "Stephen-H.-Bach",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Bach",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen H. Bach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064658972"
                        ],
                        "name": "Daniel Rodriguez",
                        "slug": "Daniel-Rodriguez",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Rodriguez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Rodriguez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108018867"
                        ],
                        "name": "Yintao Liu",
                        "slug": "Yintao-Liu",
                        "structuredName": {
                            "firstName": "Yintao",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yintao Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112753555"
                        ],
                        "name": "Chong Luo",
                        "slug": "Chong-Luo",
                        "structuredName": {
                            "firstName": "Chong",
                            "lastName": "Luo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chong Luo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056791033"
                        ],
                        "name": "Haidong Shao",
                        "slug": "Haidong-Shao",
                        "structuredName": {
                            "firstName": "Haidong",
                            "lastName": "Shao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Haidong Shao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144100064"
                        ],
                        "name": "Cassandra Xia",
                        "slug": "Cassandra-Xia",
                        "structuredName": {
                            "firstName": "Cassandra",
                            "lastName": "Xia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cassandra Xia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115762850"
                        ],
                        "name": "Souvik Sen",
                        "slug": "Souvik-Sen",
                        "structuredName": {
                            "firstName": "Souvik",
                            "lastName": "Sen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Souvik Sen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143711421"
                        ],
                        "name": "Alexander J. Ratner",
                        "slug": "Alexander-J.-Ratner",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Ratner",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexander J. Ratner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34302368"
                        ],
                        "name": "Braden Hancock",
                        "slug": "Braden-Hancock",
                        "structuredName": {
                            "firstName": "Braden",
                            "lastName": "Hancock",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Braden Hancock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2906040"
                        ],
                        "name": "H. Alborzi",
                        "slug": "H.-Alborzi",
                        "structuredName": {
                            "firstName": "Houman",
                            "lastName": "Alborzi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Alborzi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "114678802"
                        ],
                        "name": "Rahul Kuchhal",
                        "slug": "Rahul-Kuchhal",
                        "structuredName": {
                            "firstName": "Rahul",
                            "lastName": "Kuchhal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rahul Kuchhal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114485554"
                        ],
                        "name": "C. R\u00e9",
                        "slug": "C.-R\u00e9",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "R\u00e9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. R\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153715045"
                        ],
                        "name": "Rob Malkin",
                        "slug": "Rob-Malkin",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Malkin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rob Malkin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "(2019d,c) and Bach et al. (2018) get further improvements respectively via multi-task finetuning and using massive amounts of weak supervision."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 54206588,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa24f72d8d0b9bfc308b30aa56aa237eaddcf993",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "Labeling training data is one of the most costly bottlenecks in developing machine learning-based applications. We present a first-of-its-kind study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude, and introduce Snorkel DryBell, a new weak supervision management system for this setting. Snorkel DryBell builds on the Snorkel framework, extending it in three critical aspects: flexible, template-based ingestion of diverse organizational knowledge, cross-feature production serving, and scalable, sampling-free execution. On three classification tasks at Google, we find that Snorkel DryBell creates classifiers of comparable quality to ones trained with tens of thousands of hand-labeled examples, converts non-servable organizational resources to servable models for an average 52% performance improvement, and executes over millions of data points in tens of minutes."
            },
            "slug": "Snorkel-DryBell:-A-Case-Study-in-Deploying-Weak-at-Bach-Rodriguez",
            "title": {
                "fragments": [],
                "text": "Snorkel DryBell: A Case Study in Deploying Weak Supervision at Industrial Scale"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A first-of-its-kind study showing how existing knowledge resources from across an organization can be used as weak supervision in order to bring development time and cost down by an order of magnitude, and introducing Snorkel DryBell, a new weak supervision management system for this setting."
            },
            "venue": {
                "fragments": [],
                "text": "SIGMOD Conference"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3450996"
                        ],
                        "name": "Ryan Kiros",
                        "slug": "Ryan-Kiros",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "Kiros",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan Kiros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1844940337"
                        ],
                        "name": "Yukun Zhu",
                        "slug": "Yukun-Zhu",
                        "structuredName": {
                            "firstName": "Yukun",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yukun Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804104"
                        ],
                        "name": "R. Zemel",
                        "slug": "R.-Zemel",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Zemel",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zemel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2422559"
                        ],
                        "name": "R. Urtasun",
                        "slug": "R.-Urtasun",
                        "structuredName": {
                            "firstName": "Raquel",
                            "lastName": "Urtasun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Urtasun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37895334"
                        ],
                        "name": "S. Fidler",
                        "slug": "S.-Fidler",
                        "structuredName": {
                            "firstName": "Sanja",
                            "lastName": "Fidler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Fidler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "(Collobert and Weston, 2008; Dai and Le, 2015; Kiros et al., 2015; Hill et al., 2016; Conneau and Kiela, 2018; McCann et al., 2017; Peters et al., 2018)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 190
                            }
                        ],
                        "text": "\u2026neural models with large amounts of available supervision can produce representations that effectively transfer to a broad range of NLP tasks (Collobert and Weston, 2008; Dai and Le, 2015; Kiros et al., 2015; Hill et al., 2016; Conneau and Kiela, 2018; McCann et al., 2017; Peters et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9126867,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6e795c6e9916174ae12349f5dc3f516570c17ce8",
            "isKey": false,
            "numCitedBy": 1928,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an approach for unsupervised learning of a generic, distributed sentence encoder. Using the continuity of text from books, we train an encoder-decoder model that tries to reconstruct the surrounding sentences of an encoded passage. Sentences that share semantic and syntactic properties are thus mapped to similar vector representations. We next introduce a simple vocabulary expansion method to encode words that were not seen as part of training, allowing us to expand our vocabulary to a million words. After training our model, we extract and evaluate our vectors with linear models on 8 tasks: semantic relatedness, paraphrase detection, image-sentence ranking, question-type classification and 4 benchmark sentiment and subjectivity datasets. The end result is an off-the-shelf encoder that can produce highly generic sentence representations that are robust and perform well in practice."
            },
            "slug": "Skip-Thought-Vectors-Kiros-Zhu",
            "title": {
                "fragments": [],
                "text": "Skip-Thought Vectors"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "The approach for unsupervised learning of a generic, distributed sentence encoder is described, using the continuity of text from books to train an encoder-decoder model that tries to reconstruct the surrounding sentences of an encoded passage."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "81840293"
                        ],
                        "name": "Adina Williams",
                        "slug": "Adina-Williams",
                        "structuredName": {
                            "firstName": "Adina",
                            "lastName": "Williams",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adina Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10666396"
                        ],
                        "name": "Nikita Nangia",
                        "slug": "Nikita-Nangia",
                        "structuredName": {
                            "firstName": "Nikita",
                            "lastName": "Nangia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nikita Nangia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3644767"
                        ],
                        "name": "Samuel R. Bowman",
                        "slug": "Samuel-R.-Bowman",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Bowman",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samuel R. Bowman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 55
                            }
                        ],
                        "text": "We get further gains by training on related tasks like MultiNLI and SWAG."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 15
                            }
                        ],
                        "text": "However, since MultiNLI is not part of SuperGLUE, we collapse contradiction and neutral into a single not_entailment label, and request that submissions include predictions on the collapsed diagnostic set from their RTE model."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 28
                            }
                        ],
                        "text": "Given the productive use of MultiNLI in pretraining and intermediate fine-tuning of pretrained language models (Conneau et al., 2017; Phang et al., 2018, i.a.), for CB and RTE, we use MultiNLI as a transfer task by first using the above procedure on MultiNLI."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 159
                            }
                        ],
                        "text": "Each entry in the diagnostic set is a sentence pair labeled with a three-way entailment relation\u2014 entailment, neutral, or contradiction, matching the MultiNLI (Williams et al., 2018) label set\u2014and tagged with labels that indicate a broad set of linguistic phenomena that characterize the relationship between the two sentences."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 137
                            }
                        ],
                        "text": "10http://commonsensereasoning.org/disambiguation.html\nto the GLUE leaderboard were requested to include predictions from the submission\u2019s MultiNLI classifier on the diagnostic set, and analyses of the results were shown alongside the main leaderboard."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 149
                            }
                        ],
                        "text": "\u2026in the diagnostic set is a sentence pair labeled with a three-way entailment relation\u2014 entailment, neutral, or contradiction, matching the MultiNLI (Williams et al., 2018) label set\u2014and tagged with labels that indicate a broad set of linguistic phenomena that characterize the relationship between\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3432876,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5ded2b8c64491b4a67f6d39ce473d4b9347a672e",
            "isKey": false,
            "numCitedBy": 2037,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces the Multi-Genre Natural Language Inference (MultiNLI) corpus, a dataset designed for use in the development and evaluation of machine learning models for sentence understanding. At 433k examples, this resource is one of the largest corpora available for natural language inference (a.k.a. recognizing textual entailment), improving upon available resources in both its coverage and difficulty. MultiNLI accomplishes this by offering data from ten distinct genres of written and spoken English, making it possible to evaluate systems on nearly the full complexity of the language, while supplying an explicit setting for evaluating cross-genre domain adaptation. In addition, an evaluation using existing machine learning models designed for the Stanford NLI corpus shows that it represents a substantially more difficult task than does that corpus, despite the two showing similar levels of inter-annotator agreement."
            },
            "slug": "A-Broad-Coverage-Challenge-Corpus-for-Sentence-Williams-Nangia",
            "title": {
                "fragments": [],
                "text": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "The Multi-Genre Natural Language Inference corpus is introduced, a dataset designed for use in the development and evaluation of machine learning models for sentence understanding and shows that it represents a substantially more difficult task than does the Stanford NLI corpus."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2890423"
                        ],
                        "name": "Eunsol Choi",
                        "slug": "Eunsol-Choi",
                        "structuredName": {
                            "firstName": "Eunsol",
                            "lastName": "Choi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eunsol Choi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39455775"
                        ],
                        "name": "Omer Levy",
                        "slug": "Omer-Levy",
                        "structuredName": {
                            "firstName": "Omer",
                            "lastName": "Levy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Omer Levy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699545"
                        ],
                        "name": "Yejin Choi",
                        "slug": "Yejin-Choi",
                        "structuredName": {
                            "firstName": "Yejin",
                            "lastName": "Choi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yejin Choi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 94
                            }
                        ],
                        "text": "The tags from this validation had high agreement, and were included in the publicly available Ultrafine Entity Typing dataset,15 This constitutes our set of positive examples."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 236,
                                "start": 218
                            }
                        ],
                        "text": "\u2026estimates for human performance on several tasks that we did not ultimately include in SuperGLUE, including GAP (Webster et al., 2018), PAWS (Zhang et al., 2019), Quora Insincere Questions,14 Ultrafine Entity Typing (Choi et al., 2018b), and Empathetic Reactions datasets (Buechel et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 61
                            }
                        ],
                        "text": "Similarly, on recast version of the Ultrafine Entity Typing (Choi et al., 2018b), we observe too small a gap between human (60.2 F1) and machine performance (55.0 F1)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 0
                            }
                        ],
                        "text": "Ultrafine Entity Typing We cast the task into a binary classification problem to make it an easier task for non-expert crowd workers."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 248,
                                "start": 224
                            }
                        ],
                        "text": "7It was challenging to train annotators to do well on Quora Insincere Questions (https://www.kaggle. com/c/quora-insincere-questions-classification/data), Empathetic Reactions (Buechel et al., 2018), and a recast version of Ultra-Fine Entity Typing (Choi et al., 2018b, see Appendix A for details), leading to low human performance."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 257,
                                "start": 205
                            }
                        ],
                        "text": "We collected data to produce conservative estimates for human performance on several tasks that we did not ultimately include in SuperGLUE, including GAP (Webster et al., 2018), PAWS (Zhang et al., 2019), Quora Insincere Questions,14 Ultrafine Entity Typing (Choi et al., 2018b), and Empathetic Reactions datasets (Buechel et al., 2018)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 211
                            }
                        ],
                        "text": "\u2026to do well on Quora Insincere Questions (https://www.kaggle. com/c/quora-insincere-questions-classification/data), Empathetic Reactions (Buechel et al., 2018), and a recast version of Ultra-Fine Entity Typing (Choi et al., 2018b, see Appendix A for details), leading to low human performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 18
                            }
                        ],
                        "text": "6Tasks like QuAC (Choi et al., 2018a) and STREUSLE (Schneider and Smith, 2015) differed substantially from the format of other tasks in SuperGLUE, which we worried would incentivize users to spend significant effort on task-specific model designs, rather than focusing on general-purpose techniques."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 56
                            }
                        ],
                        "text": "We work in cooperation with the authors of the dataset (Choi et al., 2018b) to do this reformulation: We give workers one possible tag for a word or phrase and asked them to classify the tag as being applicable or not."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 49212016,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4157834ed2d2fea6b6f652a72a9d0487edbc9f57",
            "isKey": false,
            "numCitedBy": 117,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new entity typing task: given a sentence with an entity mention, the goal is to predict a set of free-form phrases (e.g. skyscraper, songwriter, or criminal) that describe appropriate types for the target entity. This formulation allows us to use a new type of distant supervision at large scale: head words, which indicate the type of the noun phrases they appear in. We show that these ultra-fine types can be crowd-sourced, and introduce new evaluation sets that are much more diverse and fine-grained than existing benchmarks. We present a model that can predict ultra-fine types, and is trained using a multitask objective that pools our new head-word supervision with prior supervision from entity linking. Experimental results demonstrate that our model is effective in predicting entity types at varying granularity; it achieves state of the art performance on an existing fine-grained entity typing benchmark, and sets baselines for our newly-introduced datasets."
            },
            "slug": "Ultra-Fine-Entity-Typing-Choi-Levy",
            "title": {
                "fragments": [],
                "text": "Ultra-Fine Entity Typing"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A model that can predict ultra-fine types is presented, and is trained using a multitask objective that pools the authors' new head-word supervision with prior supervision from entity linking, and achieves state of the art performance on an existing fine-grained entity typing benchmark, and sets baselines for newly-introduced datasets."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3422908"
                        ],
                        "name": "Robin Jia",
                        "slug": "Robin-Jia",
                        "structuredName": {
                            "firstName": "Robin",
                            "lastName": "Jia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robin Jia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145419642"
                        ],
                        "name": "Percy Liang",
                        "slug": "Percy-Liang",
                        "structuredName": {
                            "firstName": "Percy",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Percy Liang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 51
                            }
                        ],
                        "text": "Much recent work has observed this for NLI and QA (Jia and Liang, 2017; Naik et al., 2018; McCoy and Linzen, 2019; McCoy et al., 2019; Liu et al., 2019a,b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7228830,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ffb949d3493c3b2f3c9acf9c75cb03938933ddf0",
            "isKey": false,
            "numCitedBy": 1077,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Standard accuracy metrics indicate that reading comprehension systems are making rapid progress, but the extent to which these systems truly understand language remains unclear. To reward systems with real language understanding abilities, we propose an adversarial evaluation scheme for the Stanford Question Answering Dataset (SQuAD). Our method tests whether systems can answer questions about paragraphs that contain adversarially inserted sentences, which are automatically generated to distract computer systems without changing the correct answer or misleading humans. In this adversarial setting, the accuracy of sixteen published models drops from an average of 75% F1 score to 36%; when the adversary is allowed to add ungrammatical sequences of words, average accuracy on four models decreases further to 7%. We hope our insights will motivate the development of new models that understand language more precisely."
            },
            "slug": "Adversarial-Examples-for-Evaluating-Reading-Systems-Jia-Liang",
            "title": {
                "fragments": [],
                "text": "Adversarial Examples for Evaluating Reading Comprehension Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work proposes an adversarial evaluation scheme for the Stanford Question Answering Dataset that tests whether systems can answer questions about paragraphs that contain adversarially inserted sentences without changing the correct answer or misleading humans."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145534175"
                        ],
                        "name": "R. Thomas McCoy",
                        "slug": "R.-Thomas-McCoy",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "McCoy",
                            "middleNames": [
                                "Thomas"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Thomas McCoy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2467508"
                        ],
                        "name": "Tal Linzen",
                        "slug": "Tal-Linzen",
                        "structuredName": {
                            "firstName": "Tal",
                            "lastName": "Linzen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tal Linzen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 91
                            }
                        ],
                        "text": "Much recent work has observed this for NLI and QA (Jia and Liang, 2017; Naik et al., 2018; McCoy and Linzen, 2019; McCoy et al., 2019; Liu et al., 2019a,b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 54076487,
            "fieldsOfStudy": [
                "Philosophy",
                "Computer Science",
                "Biology"
            ],
            "id": "1ba4d91d934a006a08f1df64f9b29ae0d943d2f2",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural network models have shown great success at natural language inference (NLI), the task of determining whether a premise entails a hypothesis. However, recent studies suggest that these models may rely on fallible heuristics rather than deep language understanding. We introduce a challenge set to test whether NLI systems adopt one such heuristic: assuming that a sentence entails all of its subsequences, such as assuming that \"Alice believes Mary is lying\" entails \"Alice believes Mary.\" We evaluate several competitive NLI models on this challenge set and find strong evidence that they do rely on the subsequence heuristic."
            },
            "slug": "Non-entailed-subsequences-as-a-challenge-for-McCoy-Linzen",
            "title": {
                "fragments": [],
                "text": "Non-entailed subsequences as a challenge for natural language inference"
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "23175870"
                        ],
                        "name": "Aakanksha Naik",
                        "slug": "Aakanksha-Naik",
                        "structuredName": {
                            "firstName": "Aakanksha",
                            "lastName": "Naik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aakanksha Naik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3023068"
                        ],
                        "name": "Abhilasha Ravichander",
                        "slug": "Abhilasha-Ravichander",
                        "structuredName": {
                            "firstName": "Abhilasha",
                            "lastName": "Ravichander",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abhilasha Ravichander"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2464164"
                        ],
                        "name": "N. Sadeh",
                        "slug": "N.-Sadeh",
                        "structuredName": {
                            "firstName": "Norman",
                            "lastName": "Sadeh",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sadeh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35959897"
                        ],
                        "name": "C. Ros\u00e9",
                        "slug": "C.-Ros\u00e9",
                        "structuredName": {
                            "firstName": "Carolyn",
                            "lastName": "Ros\u00e9",
                            "middleNames": [
                                "Penstein"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Ros\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700325"
                        ],
                        "name": "Graham Neubig",
                        "slug": "Graham-Neubig",
                        "structuredName": {
                            "firstName": "Graham",
                            "lastName": "Neubig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Graham Neubig"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 72
                            }
                        ],
                        "text": "Much recent work has observed this for NLI and QA (Jia and Liang, 2017; Naik et al., 2018; McCoy and Linzen, 2019; McCoy et al., 2019; Liu et al., 2019a,b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 46932607,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "175b58fe7e49bb5c0c771b73f8834bcff21b59c7",
            "isKey": false,
            "numCitedBy": 203,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Natural language inference (NLI) is the task of determining if a natural language hypothesis can be inferred from a given premise in a justifiable manner. NLI was proposed as a benchmark task for natural language understanding. Existing models perform well at standard datasets for NLI, achieving impressive results across different genres of text. However, the extent to which these models understand the semantic content of sentences is unclear. In this work, we propose an evaluation methodology consisting of automatically constructed \u201cstress tests\u201d that allow us to examine whether systems have the ability to make real inferential decisions. Our evaluation of six sentence-encoder models on these stress tests reveals strengths and weaknesses of these models with respect to challenging linguistic phenomena, and suggests important directions for future work in this area."
            },
            "slug": "Stress-Test-Evaluation-for-Natural-Language-Naik-Ravichander",
            "title": {
                "fragments": [],
                "text": "Stress Test Evaluation for Natural Language Inference"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work proposes an evaluation methodology consisting of automatically constructed \u201cstress tests\u201d that allow us to examine whether systems have the ability to make real inferential decisions, and reveals strengths and weaknesses of these models with respect to challenging linguistic phenomena."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2480903"
                        ],
                        "name": "A. Conneau",
                        "slug": "A.-Conneau",
                        "structuredName": {
                            "firstName": "Alexis",
                            "lastName": "Conneau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Conneau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743722"
                        ],
                        "name": "Douwe Kiela",
                        "slug": "Douwe-Kiela",
                        "structuredName": {
                            "firstName": "Douwe",
                            "lastName": "Kiela",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Douwe Kiela"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144518416"
                        ],
                        "name": "Holger Schwenk",
                        "slug": "Holger-Schwenk",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Schwenk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Holger Schwenk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2934336"
                        ],
                        "name": "Lo\u00efc Barrault",
                        "slug": "Lo\u00efc-Barrault",
                        "structuredName": {
                            "firstName": "Lo\u00efc",
                            "lastName": "Barrault",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lo\u00efc Barrault"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713934"
                        ],
                        "name": "Antoine Bordes",
                        "slug": "Antoine-Bordes",
                        "structuredName": {
                            "firstName": "Antoine",
                            "lastName": "Bordes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antoine Bordes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 111
                            }
                        ],
                        "text": "Given the productive use of MultiNLI in pretraining and intermediate fine-tuning of pretrained language models (Conneau et al., 2017; Phang et al., 2018), for CB and RTE, we use MultiNLI as a transfer task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 112
                            }
                        ],
                        "text": "Given the productive use of MultiNLI in pretraining and intermediate fine-tuning of pretrained language models (Conneau et al., 2017; Phang et al., 2018, i.a.), for CB and RTE, we use MultiNLI as a transfer task by first using the above procedure on MultiNLI."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 28971531,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ee7b883e35d754ae4f71c21bb71f9f03e4ffbb2c",
            "isKey": false,
            "numCitedBy": 1513,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Many modern NLP systems rely on word embeddings, previously trained in an unsupervised manner on large corpora, as base features. Efforts to obtain embeddings for larger chunks of text, such as sentences, have however not been so successful. Several attempts at learning unsupervised representations of sentences have not reached satisfactory enough performance to be widely adopted. In this paper, we show how universal sentence representations trained using the supervised data of the Stanford Natural Language Inference datasets can consistently outperform unsupervised methods like SkipThought vectors on a wide range of transfer tasks. Much like how computer vision uses ImageNet to obtain features, which can then be transferred to other tasks, our work tends to indicate the suitability of natural language inference for transfer learning to other NLP tasks. Our encoder is publicly available."
            },
            "slug": "Supervised-Learning-of-Universal-Sentence-from-Data-Conneau-Kiela",
            "title": {
                "fragments": [],
                "text": "Supervised Learning of Universal Sentence Representations from Natural Language Inference Data"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown how universal sentence representations trained using the supervised data of the Stanford Natural Language Inference datasets can consistently outperform unsupervised methods like SkipThought vectors on a wide range of transfer tasks."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113221447"
                        ],
                        "name": "Hai Wang",
                        "slug": "Hai-Wang",
                        "structuredName": {
                            "firstName": "Hai",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hai Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41190054"
                        ],
                        "name": "Dian Yu",
                        "slug": "Dian-Yu",
                        "structuredName": {
                            "firstName": "Dian",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dian Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49871029"
                        ],
                        "name": "Kai Sun",
                        "slug": "Kai-Sun",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720246"
                        ],
                        "name": "Jianshu Chen",
                        "slug": "Jianshu-Chen",
                        "structuredName": {
                            "firstName": "Jianshu",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianshu Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144580027"
                        ],
                        "name": "Dong Yu",
                        "slug": "Dong-Yu",
                        "structuredName": {
                            "firstName": "Dong",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dong Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145689002"
                        ],
                        "name": "David A. McAllester",
                        "slug": "David-A.-McAllester",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "McAllester",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David A. McAllester"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 142
                            }
                        ],
                        "text": "In this context, the GLUE benchmark (organized by some of the same authors as this work, short for General Language Understanding Evaluation; Wang et al., 2019) has become a prominent evaluation framework and leaderboard for research towards general-purpose language understanding technologies."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 67856029,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb104dc51121a0f64a5327526fad449cb03dd1bb",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "Remarkable success has been achieved in the last few years on some limited machine reading comprehension (MRC) tasks. However, it is still difficult to interpret the predictions of existing MRC models. In this paper, we focus on extracting evidence sentences that can explain or support the answers of multiple-choice MRC tasks, where the majority of answer options cannot be directly extracted from reference documents. Due to the lack of ground truth evidence sentence labels in most cases, we apply distant supervision to generate imperfect labels and then use them to train an evidence sentence extractor. To denoise the noisy labels, we apply a recently proposed deep probabilistic logic learning framework to incorporate both sentence-level and cross-sentence linguistic indicators for indirect supervision. We feed the extracted evidence sentences into existing MRC models and evaluate the end-to-end performance on three challenging multiple-choice MRC datasets: MultiRC, RACE, and DREAM, achieving comparable or better performance than the same models that take as input the full reference document. To the best of our knowledge, this is the first work extracting evidence sentences for multiple-choice MRC."
            },
            "slug": "Evidence-Sentence-Extraction-for-Machine-Reading-Wang-Yu",
            "title": {
                "fragments": [],
                "text": "Evidence Sentence Extraction for Machine Reading Comprehension"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper focuses on extracting evidence sentences that can explain or support the answers of multiple-choice MRC tasks, where the majority of answer options cannot be directly extracted from reference documents."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143634377"
                        ],
                        "name": "H. Levesque",
                        "slug": "H.-Levesque",
                        "structuredName": {
                            "firstName": "Hector",
                            "lastName": "Levesque",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Levesque"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144883814"
                        ],
                        "name": "E. Davis",
                        "slug": "E.-Davis",
                        "structuredName": {
                            "firstName": "Ernest",
                            "lastName": "Davis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Davis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40429476"
                        ],
                        "name": "L. Morgenstern",
                        "slug": "L.-Morgenstern",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Morgenstern",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Morgenstern"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 42
                            }
                        ],
                        "text": "Top performance on Winograd-NLI (based on Levesque et al., 2012) is still at the majority baseline, with accuracy (65.1) far below human-level (95.9)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 40
                            }
                        ],
                        "text": "WSC The Winograd Schema Challenge (WSC, Levesque et al., 2012) is a reading comprehension task in which a system must read a sentence with a pronoun and select the referent of that pronoun from a list of choices."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 90
                            }
                        ],
                        "text": "The training and validation examples are drawn from the original Winograd Schema dataset (Levesque et al., 2012), as well as those distributed by the affiliated organization Commonsense Reasoning.10 The test examples are derived from fiction books and have been shared with us by the authors of the\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 89
                            }
                        ],
                        "text": "The training and validation examples are drawn from the original Winograd Schema dataset (Levesque et al., 2012), as well as those distributed by the affiliated organization Commonsense Reasoning."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15710851,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "128cb6b891aee1b5df099acb48e2efecfcff689f",
            "isKey": true,
            "numCitedBy": 691,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present an alternative to the Turing Test that has some conceptual and practical advantages. Like the original, it involves responding to typed English sentences, and English-speaking adults will have no difficulty with it. Unlike the original, the subject is not required to engage in a conversation and fool an interrogator into believing she is dealing with a person. Moreover, the test is arranged in such a way that having full access to a large corpus of English text might not help much. Finally, the interrogator or a third party will be able to decide unambiguously after a few minutes whether or not a subject has passed the test."
            },
            "slug": "The-Winograd-Schema-Challenge-Levesque-Davis",
            "title": {
                "fragments": [],
                "text": "The Winograd Schema Challenge"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This paper presents an alternative to the Turing Test that has some conceptual and practical advantages, and English-speaking adults will have no difficulty with it, and the subject is not required to engage in a conversation and fool an interrogator into believing she is dealing with a person."
            },
            "venue": {
                "fragments": [],
                "text": "KR"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3407277"
                        ],
                        "name": "Adam Paszke",
                        "slug": "Adam-Paszke",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Paszke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adam Paszke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39793298"
                        ],
                        "name": "S. Gross",
                        "slug": "S.-Gross",
                        "structuredName": {
                            "firstName": "Sam",
                            "lastName": "Gross",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gross"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2127604"
                        ],
                        "name": "Soumith Chintala",
                        "slug": "Soumith-Chintala",
                        "structuredName": {
                            "firstName": "Soumith",
                            "lastName": "Chintala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Soumith Chintala"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "114250963"
                        ],
                        "name": "Gregory Chanan",
                        "slug": "Gregory-Chanan",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Chanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gregory Chanan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052812305"
                        ],
                        "name": "E. Yang",
                        "slug": "E.-Yang",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2375710"
                        ],
                        "name": "Zach DeVito",
                        "slug": "Zach-DeVito",
                        "structuredName": {
                            "firstName": "Zach",
                            "lastName": "DeVito",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zach DeVito"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3370429"
                        ],
                        "name": "Zeming Lin",
                        "slug": "Zeming-Lin",
                        "structuredName": {
                            "firstName": "Zeming",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zeming Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3050846"
                        ],
                        "name": "Alban Desmaison",
                        "slug": "Alban-Desmaison",
                        "structuredName": {
                            "firstName": "Alban",
                            "lastName": "Desmaison",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alban Desmaison"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3029482"
                        ],
                        "name": "L. Antiga",
                        "slug": "L.-Antiga",
                        "structuredName": {
                            "firstName": "Luca",
                            "lastName": "Antiga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Antiga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1977806"
                        ],
                        "name": "Adam Lerer",
                        "slug": "Adam-Lerer",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Lerer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adam Lerer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 95
                            }
                        ],
                        "text": "Software Tools To facilitate using SuperGLUE, we will release a toolkit, built around PyTorch (Paszke et al., 2017) and components from AllenNLP (Gardner et al., 2017), which implements our baselines and supports the evaluation of custom models and training methods on the benchmark tasks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 94
                            }
                        ],
                        "text": "Specifically, we use the BERT-LARGE-CASED variant.11 Following standard practice\n11We use the PyTorch implementation by HuggingFace: https://github.com/huggingface/ pytorch-pretrained-BERT"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 261,
                                "start": 240
                            }
                        ],
                        "text": "\u2022 To facilitate the development of unified new methods for this more diverse set of tasks, SuperGLUE is distributed with a modular modeling toolkit for work on pretraining, multitask learning, and transfer learning in NLP, built on PyTorch (Paszke et al., 2017) and AllenNLP (Gardner et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 94
                            }
                        ],
                        "text": "Software Tools To facilitate using SuperGLUE, we will release a toolkit, built around PyTorch (Paszke et al., 2017) and components from AllenNLP (Gardner et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 259,
                                "start": 240
                            }
                        ],
                        "text": "\u2022 To facilitate the development of unified new methods for this more diverse set of tasks, SuperGLUE is distributed with a modular modeling toolkit for work on pretraining, multitask learning, and transfer learning in NLP, built on PyTorch (Paszke et al., 2017) and AllenNLP (Gardner et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 40027675,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b36a5bb1707bb9c70025294b3a310138aae8327a",
            "isKey": true,
            "numCitedBy": 10330,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "In this article, we describe an automatic differentiation module of PyTorch \u2014 a library designed to enable rapid research on machine learning models. It builds upon a few projects, most notably Lua Torch, Chainer, and HIPS Autograd [4], and provides a high performance environment with easy access to automatic differentiation of models executed on different devices (CPU and GPU). To make prototyping easier, PyTorch does not follow the symbolic approach used in many other deep learning frameworks, but focuses on differentiation of purely imperative programs, with a focus on extensibility and low overhead. Note that this preprint is a draft of certain sections from an upcoming paper covering all PyTorch features."
            },
            "slug": "Automatic-differentiation-in-PyTorch-Paszke-Gross",
            "title": {
                "fragments": [],
                "text": "Automatic differentiation in PyTorch"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "An automatic differentiation module of PyTorch is described \u2014 a library designed to enable rapid research on machine learning models that focuses on differentiation of purely imperative programs, with a focus on extensibility and low overhead."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46236380"
                        ],
                        "name": "Alex Warstadt",
                        "slug": "Alex-Warstadt",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Warstadt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Warstadt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50286460"
                        ],
                        "name": "Amanpreet Singh",
                        "slug": "Amanpreet-Singh",
                        "structuredName": {
                            "firstName": "Amanpreet",
                            "lastName": "Singh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amanpreet Singh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3644767"
                        ],
                        "name": "Samuel R. Bowman",
                        "slug": "Samuel-R.-Bowman",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Bowman",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samuel R. Bowman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 44072099,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "cb0f3ee1e98faf92429d601cdcd76c69c1e484eb",
            "isKey": false,
            "numCitedBy": 546,
            "numCiting": 111,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract This paper investigates the ability of artificial neural networks to judge the grammatical acceptability of a sentence, with the goal of testing their linguistic competence. We introduce the Corpus of Linguistic Acceptability (CoLA), a set of 10,657 English sentences labeled as grammatical or ungrammatical from published linguistics literature. As baselines, we train several recurrent neural network models on acceptability classification, and find that our models outperform unsupervised models by Lau et al. (2016) on CoLA. Error-analysis on specific grammatical phenomena reveals that both Lau et al.\u2019s models and ours learn systematic generalizations like subject-verb-object order. However, all models we test perform far below human level on a wide range of grammatical constructions."
            },
            "slug": "Neural-Network-Acceptability-Judgments-Warstadt-Singh",
            "title": {
                "fragments": [],
                "text": "Neural Network Acceptability Judgments"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "This paper introduces the Corpus of Linguistic Acceptability (CoLA), a set of 10,657 English sentences labeled as grammatical or ungrammatical from published linguistics literature, and trains several recurrent neural network models on acceptability classification, and finds that the authors' models outperform unsupervised models by Lau et al. (2016) on CoLA."
            },
            "venue": {
                "fragments": [],
                "text": "Transactions of the Association for Computational Linguistics"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39139825"
                        ],
                        "name": "Matthew E. Peters",
                        "slug": "Matthew-E.-Peters",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Peters",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew E. Peters"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50043859"
                        ],
                        "name": "Mark Neumann",
                        "slug": "Mark-Neumann",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Neumann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Neumann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2136562"
                        ],
                        "name": "Mohit Iyyer",
                        "slug": "Mohit-Iyyer",
                        "structuredName": {
                            "firstName": "Mohit",
                            "lastName": "Iyyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mohit Iyyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40642935"
                        ],
                        "name": "Matt Gardner",
                        "slug": "Matt-Gardner",
                        "structuredName": {
                            "firstName": "Matt",
                            "lastName": "Gardner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matt Gardner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143997772"
                        ],
                        "name": "Christopher Clark",
                        "slug": "Christopher-Clark",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Clark",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher Clark"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2544107"
                        ],
                        "name": "Kenton Lee",
                        "slug": "Kenton-Lee",
                        "structuredName": {
                            "firstName": "Kenton",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenton Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 132
                            }
                        ],
                        "text": "The past year has seen a surge of progress across many natural language processing (NLP) tasks, led by pretrained models like ELMo (Peters et al., 2018), OpenAI GPT (Radford et al., 2018), and BERT (Devlin et al., 2019)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 110
                            }
                        ],
                        "text": "On GLUE, GPT and BERT achieved scores of 72.8 and 80.2 respectively, relative to 66.5 for an ELMobased model (Peters et al., 2018) and 63.7 for the strongest baseline with no multitask learning or pretraining above the word level."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 288,
                                "start": 284
                            }
                        ],
                        "text": "These results demonstrate the value of sharing knowledge through self-supervised objectives that maximize the available training signal, modeling word occurrence conditioned on ever-richer context: from nearby unigrams (traditional distributional methods) to one-directional context (ELMo, GPT) and finally to bidirectional context (BERT)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 294,
                                "start": 275
                            }
                        ],
                        "text": "\u2026neural models with large amounts of available supervision can produce representations that effectively transfer to a broad range of NLP tasks (Collobert and Weston, 2008; Dai and Le, 2015; Kiros et al., 2015; Hill et al., 2016; Conneau and Kiela, 2018; McCann et al., 2017; Peters et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 69
                            }
                        ],
                        "text": "Besides their striking gains in performance on many such tasks, both ELMo and BERT have been recognized with best paper awards at major conferences and widespread deployment in industry."
                    },
                    "intents": []
                }
            ],
            "corpusId": 3626819,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3febb2bed8865945e7fddc99efd791887bb7e14f",
            "isKey": true,
            "numCitedBy": 7988,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals."
            },
            "slug": "Deep-Contextualized-Word-Representations-Peters-Neumann",
            "title": {
                "fragments": [],
                "text": "Deep Contextualized Word Representations"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A new type of deep contextualized word representation is introduced that models both complex characteristics of word use and how these uses vary across linguistic contexts, allowing downstream models to mix different types of semi-supervision signals."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145783676"
                        ],
                        "name": "Felix Hill",
                        "slug": "Felix-Hill",
                        "structuredName": {
                            "firstName": "Felix",
                            "lastName": "Hill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Felix Hill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1979489"
                        ],
                        "name": "Kyunghyun Cho",
                        "slug": "Kyunghyun-Cho",
                        "structuredName": {
                            "firstName": "Kyunghyun",
                            "lastName": "Cho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kyunghyun Cho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145762466"
                        ],
                        "name": "A. Korhonen",
                        "slug": "A.-Korhonen",
                        "structuredName": {
                            "firstName": "Anna",
                            "lastName": "Korhonen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Korhonen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 349,
                                "start": 197
                            }
                        ],
                        "text": "Much work prior to GLUE has demonstrated that training neural models with large amounts of available supervision can produce representations that effectively transfer to a broad range of NLP tasks (Collobert and Weston, 2008; Dai and Le, 2015; Kiros et al., 2015; Hill et al., 2016; Conneau and Kiela, 2018; McCann et al., 2017; Peters et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 210
                            }
                        ],
                        "text": "\u2026neural models with large amounts of available supervision can produce representations that effectively transfer to a broad range of NLP tasks (Collobert and Weston, 2008; Dai and Le, 2015; Kiros et al., 2015; Hill et al., 2016; Conneau and Kiela, 2018; McCann et al., 2017; Peters et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2937095,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "26e743d5bd465f49b9538deaf116c15e61b7951f",
            "isKey": false,
            "numCitedBy": 458,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Unsupervised methods for learning distributed representations of words are ubiquitous in today's NLP research, but far less is known about the best ways to learn distributed phrase or sentence representations from unlabelled data. This paper is a systematic comparison of models that learn such representations. We find that the optimal approach depends critically on the intended application. Deeper, more complex models are preferable for representations to be used in supervised systems, but shallow log-linear models work best for building representation spaces that can be decoded with simple spatial distance metrics. We also propose two new unsupervised representation-learning objectives designed to optimise the trade-off between training time, domain portability and performance."
            },
            "slug": "Learning-Distributed-Representations-of-Sentences-Hill-Cho",
            "title": {
                "fragments": [],
                "text": "Learning Distributed Representations of Sentences from Unlabelled Data"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A systematic comparison of models that learn distributed phrase or sentence representations from unlabelled data finds that the optimal approach depends critically on the intended application."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109512754"
                        ],
                        "name": "Zhilin Yang",
                        "slug": "Zhilin-Yang",
                        "structuredName": {
                            "firstName": "Zhilin",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhilin Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3422912"
                        ],
                        "name": "Zihang Dai",
                        "slug": "Zihang-Dai",
                        "structuredName": {
                            "firstName": "Zihang",
                            "lastName": "Dai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zihang Dai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35729970"
                        ],
                        "name": "Yiming Yang",
                        "slug": "Yiming-Yang",
                        "structuredName": {
                            "firstName": "Yiming",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiming Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143712374"
                        ],
                        "name": "J. Carbonell",
                        "slug": "J.-Carbonell",
                        "structuredName": {
                            "firstName": "Jaime",
                            "lastName": "Carbonell",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Carbonell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827616"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Le",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Recent models (Liu et al., 2019d; Yang et al., 2019) have clearly surpassed estimates of non-expert human performance on GLUE (Nangia and Bowman, 2019)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "3% accuracy (Liu et al., 2019d; Yang et al., 2019) at the time of writing."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 195069387,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c",
            "isKey": false,
            "numCitedBy": 4228,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "With the capability of modeling bidirectional contexts, denoising autoencoding based pretraining like BERT achieves better performance than pretraining approaches based on autoregressive language modeling. However, relying on corrupting the input with masks, BERT neglects dependency between the masked positions and suffers from a pretrain-finetune discrepancy. In light of these pros and cons, we propose XLNet, a generalized autoregressive pretraining method that (1) enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization order and (2) overcomes the limitations of BERT thanks to its autoregressive formulation. Furthermore, XLNet integrates ideas from Transformer-XL, the state-of-the-art autoregressive model, into pretraining. Empirically, under comparable experiment settings, XLNet outperforms BERT on 20 tasks, often by a large margin, including question answering, natural language inference, sentiment analysis, and document ranking."
            },
            "slug": "XLNet:-Generalized-Autoregressive-Pretraining-for-Yang-Dai",
            "title": {
                "fragments": [],
                "text": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "XLNet is proposed, a generalized autoregressive pretraining method that enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization order and overcomes the limitations of BERT thanks to its autore progressive formulation."
            },
            "venue": {
                "fragments": [],
                "text": "NeurIPS"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143775536"
                        ],
                        "name": "Bryan McCann",
                        "slug": "Bryan-McCann",
                        "structuredName": {
                            "firstName": "Bryan",
                            "lastName": "McCann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bryan McCann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40518045"
                        ],
                        "name": "James Bradbury",
                        "slug": "James-Bradbury",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Bradbury",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Bradbury"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2228109"
                        ],
                        "name": "Caiming Xiong",
                        "slug": "Caiming-Xiong",
                        "structuredName": {
                            "firstName": "Caiming",
                            "lastName": "Xiong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Caiming Xiong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 349,
                                "start": 197
                            }
                        ],
                        "text": "Much work prior to GLUE has demonstrated that training neural models with large amounts of available supervision can produce representations that effectively transfer to a broad range of NLP tasks (Collobert and Weston, 2008; Dai and Le, 2015; Kiros et al., 2015; Hill et al., 2016; Conneau and Kiela, 2018; McCann et al., 2017; Peters et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 273,
                                "start": 254
                            }
                        ],
                        "text": "\u2026neural models with large amounts of available supervision can produce representations that effectively transfer to a broad range of NLP tasks (Collobert and Weston, 2008; Dai and Le, 2015; Kiros et al., 2015; Hill et al., 2016; Conneau and Kiela, 2018; McCann et al., 2017; Peters et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9447219,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bc8fa64625d9189f5801837e7b133e7fe3c581f7",
            "isKey": false,
            "numCitedBy": 710,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": "Computer vision has benefited from initializing multiple deep layers with weights pretrained on large supervised training sets like ImageNet. Natural language processing (NLP) typically sees initialization of only the lowest layer of deep models with pretrained word vectors. In this paper, we use a deep LSTM encoder from an attentional sequence-to-sequence model trained for machine translation (MT) to contextualize word vectors. We show that adding these context vectors (CoVe) improves performance over using only unsupervised word and character vectors on a wide variety of common NLP tasks: sentiment analysis (SST, IMDb), question classification (TREC), entailment (SNLI), and question answering (SQuAD). For fine-grained sentiment analysis and entailment, CoVe improves performance of our baseline models to the state of the art."
            },
            "slug": "Learned-in-Translation:-Contextualized-Word-Vectors-McCann-Bradbury",
            "title": {
                "fragments": [],
                "text": "Learned in Translation: Contextualized Word Vectors"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Adding context vectors to a deep LSTM encoder from an attentional sequence-to-sequence model trained for machine translation to contextualize word vectors improves performance over using only unsupervised word and character vectors on a wide variety of common NLP tasks."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143845796"
                        ],
                        "name": "Jeffrey Pennington",
                        "slug": "Jeffrey-Pennington",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Pennington",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeffrey Pennington"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 280,
                                "start": 257
                            }
                        ],
                        "text": "We also include a baseline where for each task we simply predict the majority class, as well as a bag-of-words baseline where each input is represented as an average of its tokens\u2019 GloVe word vectors (300-dimensional and trained on 840B Common Crawl tokens, Pennington et al., 2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1957433,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f37e1b62a767a307c046404ca96bc140b3e68cb5",
            "isKey": false,
            "numCitedBy": 22538,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition."
            },
            "slug": "GloVe:-Global-Vectors-for-Word-Representation-Pennington-Socher",
            "title": {
                "fragments": [],
                "text": "GloVe: Global Vectors for Word Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods and produces a vector space with meaningful substructure."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20825661"
                        ],
                        "name": "Kellie Webster",
                        "slug": "Kellie-Webster",
                        "structuredName": {
                            "firstName": "Kellie",
                            "lastName": "Webster",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kellie Webster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144409897"
                        ],
                        "name": "Marta Recasens",
                        "slug": "Marta-Recasens",
                        "structuredName": {
                            "firstName": "Marta",
                            "lastName": "Recasens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marta Recasens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "82840075"
                        ],
                        "name": "Vera Axelrod",
                        "slug": "Vera-Axelrod",
                        "structuredName": {
                            "firstName": "Vera",
                            "lastName": "Axelrod",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vera Axelrod"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1387994164"
                        ],
                        "name": "Jason Baldridge",
                        "slug": "Jason-Baldridge",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Baldridge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jason Baldridge"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 62
                            }
                        ],
                        "text": "GAP For the Gendered Ambiguous Pronoun Coreference task (GAP, Webster et al., 2018), we simplified the task by providing noun phrase spans as part of the input, thus reducing the original structure prediction task to a classification task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 81
                            }
                        ],
                        "text": ", 2019), Discovering Ongoing Conversations (Zanzotto and Ferrone, 2017), and GAP (Webster et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 8
                            }
                        ],
                        "text": "On GAP (Webster et al., 2018), when taken as a classification problem without the interrelated task of span selection (details in A.2), BERT performs (91.0 F1) comparably to our human baseline (94.9 F1)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 143
                            }
                        ],
                        "text": "\u2026data to produce conservative estimates for human performance on several tasks that we did not ultimately include in SuperGLUE, including GAP (Webster et al., 2018), PAWS (Zhang et al., 2019), Quora Insincere Questions,14 Ultrafine Entity Typing (Choi et al., 2018b), and Empathetic Reactions\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 204
                            }
                        ],
                        "text": "8BERT achieved very high or superhuman performance on Query Well-Formedness (Faruqui and Das, 2018) and PAWS (Zhang et al., 2019), Discovering Ongoing Conversations (Zanzotto and Ferrone, 2017), and GAP (Webster et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 52980889,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "57032c1e327c88a53ab41c17e91bf1406f9ef5c9",
            "isKey": true,
            "numCitedBy": 157,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "Coreference resolution is an important task for natural language understanding, and the resolution of ambiguous pronouns a longstanding challenge. Nonetheless, existing corpora do not capture ambiguous pronouns in sufficient volume or diversity to accurately indicate the practical utility of models. Furthermore, we find gender bias in existing corpora and systems favoring masculine entities. To address this, we present and release GAP, a gender-balanced labeled corpus of 8,908 ambiguous pronoun\u2013name pairs sampled to provide diverse coverage of challenges posed by real-world text. We explore a range of baselines that demonstrate the complexity of the challenge, the best achieving just 66.9% F1. We show that syntactic structure and continuous neural models provide promising, complementary cues for approaching the challenge."
            },
            "slug": "Mind-the-GAP:-A-Balanced-Corpus-of-Gendered-Webster-Recasens",
            "title": {
                "fragments": [],
                "text": "Mind the GAP: A Balanced Corpus of Gendered Ambiguous Pronouns"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "GAP, a gender-balanced labeled corpus of 8,908 ambiguous pronoun\u2013name pairs sampled, is presented and released to provide diverse coverage of challenges posed by real-world text and shows that syntactic structure and continuous neural models provide promising, complementary cues for approaching the challenge."
            },
            "venue": {
                "fragments": [],
                "text": "TACL"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145534175"
                        ],
                        "name": "R. Thomas McCoy",
                        "slug": "R.-Thomas-McCoy",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "McCoy",
                            "middleNames": [
                                "Thomas"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Thomas McCoy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2949185"
                        ],
                        "name": "Ellie Pavlick",
                        "slug": "Ellie-Pavlick",
                        "structuredName": {
                            "firstName": "Ellie",
                            "lastName": "Pavlick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ellie Pavlick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2467508"
                        ],
                        "name": "Tal Linzen",
                        "slug": "Tal-Linzen",
                        "structuredName": {
                            "firstName": "Tal",
                            "lastName": "Linzen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tal Linzen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 59599752,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "42ed4a9994e6121a9f325f5b901c5b3d7ce104f5",
            "isKey": false,
            "numCitedBy": 580,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "A machine learning system can score well on a given test set by relying on heuristics that are effective for frequent example types but break down in more challenging cases. We study this issue within natural language inference (NLI), the task of determining whether one sentence entails another. We hypothesize that statistical NLI models may adopt three fallible syntactic heuristics: the lexical overlap heuristic, the subsequence heuristic, and the constituent heuristic. To determine whether models have adopted these heuristics, we introduce a controlled evaluation set called HANS (Heuristic Analysis for NLI Systems), which contains many examples where the heuristics fail. We find that models trained on MNLI, including BERT, a state-of-the-art model, perform very poorly on HANS, suggesting that they have indeed adopted these heuristics. We conclude that there is substantial room for improvement in NLI systems, and that the HANS dataset can motivate and measure progress in this area."
            },
            "slug": "Right-for-the-Wrong-Reasons:-Diagnosing-Syntactic-McCoy-Pavlick",
            "title": {
                "fragments": [],
                "text": "Right for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural Language Inference"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "There is substantial room for improvement in NLI systems, and the HANS dataset can motivate and measure progress in this area, which contains many examples where the heuristics fail."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689108"
                        ],
                        "name": "Oriol Vinyals",
                        "slug": "Oriol-Vinyals",
                        "structuredName": {
                            "firstName": "Oriol",
                            "lastName": "Vinyals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oriol Vinyals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49959210"
                        ],
                        "name": "J. Dean",
                        "slug": "J.-Dean",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Dean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dean"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 48
                            }
                        ],
                        "text": "(2019b) demonstrate that knowledge distillation (Hinton et al., 2015; Furlanello et al., 2018) can lead to student networks that outperform their teachers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7200347,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0c908739fbff75f03469d13d4a1a07de3414ee19",
            "isKey": false,
            "numCitedBy": 8705,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "A very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel."
            },
            "slug": "Distilling-the-Knowledge-in-a-Neural-Network-Hinton-Vinyals",
            "title": {
                "fragments": [],
                "text": "Distilling the Knowledge in a Neural Network"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work shows that it can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model and introduces a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2555924"
                        ],
                        "name": "Andrew M. Dai",
                        "slug": "Andrew-M.-Dai",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Dai",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew M. Dai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827616"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Le",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 349,
                                "start": 197
                            }
                        ],
                        "text": "Much work prior to GLUE has demonstrated that training neural models with large amounts of available supervision can produce representations that effectively transfer to a broad range of NLP tasks (Collobert and Weston, 2008; Dai and Le, 2015; Kiros et al., 2015; Hill et al., 2016; Conneau and Kiela, 2018; McCann et al., 2017; Peters et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 172
                            }
                        ],
                        "text": "\u2026neural models with large amounts of available supervision can produce representations that effectively transfer to a broad range of NLP tasks (Collobert and Weston, 2008; Dai and Le, 2015; Kiros et al., 2015; Hill et al., 2016; Conneau and Kiela, 2018; McCann et al., 2017; Peters et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7138078,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4aa9f5150b46320f534de4747a2dd0cd7f3fe292",
            "isKey": false,
            "numCitedBy": 881,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "We present two approaches to use unlabeled data to improve Sequence Learning with recurrent networks. The first approach is to predict what comes next in a sequence, which is a language model in NLP. The second approach is to use a sequence autoencoder, which reads the input sequence into a vector and predicts the input sequence again. These two algorithms can be used as a \"pretraining\" algorithm for a later supervised sequence learning algorithm. In other words, the parameters obtained from the pretraining step can then be used as a starting point for other supervised training models. In our experiments, we find that long short term memory recurrent networks after pretrained with the two approaches become more stable to train and generalize better. With pretraining, we were able to achieve strong performance in many classification tasks, such as text classification with IMDB, DBpedia or image recognition in CIFAR-10."
            },
            "slug": "Semi-supervised-Sequence-Learning-Dai-Le",
            "title": {
                "fragments": [],
                "text": "Semi-supervised Sequence Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "Two approaches to use unlabeled data to improve Sequence Learning with recurrent networks are presented and it is found that long short term memory recurrent networks after pretrained with the two approaches become more stable to train and generalize better."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2890423"
                        ],
                        "name": "Eunsol Choi",
                        "slug": "Eunsol-Choi",
                        "structuredName": {
                            "firstName": "Eunsol",
                            "lastName": "Choi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eunsol Choi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144533687"
                        ],
                        "name": "He He",
                        "slug": "He-He",
                        "structuredName": {
                            "firstName": "He",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "He He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2136562"
                        ],
                        "name": "Mohit Iyyer",
                        "slug": "Mohit-Iyyer",
                        "structuredName": {
                            "firstName": "Mohit",
                            "lastName": "Iyyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mohit Iyyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064210"
                        ],
                        "name": "Mark Yatskar",
                        "slug": "Mark-Yatskar",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Yatskar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Yatskar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144105277"
                        ],
                        "name": "Wen-tau Yih",
                        "slug": "Wen-tau-Yih",
                        "structuredName": {
                            "firstName": "Wen-tau",
                            "lastName": "Yih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wen-tau Yih"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699545"
                        ],
                        "name": "Yejin Choi",
                        "slug": "Yejin-Choi",
                        "structuredName": {
                            "firstName": "Yejin",
                            "lastName": "Choi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yejin Choi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145419642"
                        ],
                        "name": "Percy Liang",
                        "slug": "Percy-Liang",
                        "structuredName": {
                            "firstName": "Percy",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Percy Liang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 94
                            }
                        ],
                        "text": "The tags from this validation had high agreement, and were included in the publicly available Ultrafine Entity Typing dataset,15 This constitutes our set of positive examples."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 236,
                                "start": 218
                            }
                        ],
                        "text": "\u2026estimates for human performance on several tasks that we did not ultimately include in SuperGLUE, including GAP (Webster et al., 2018), PAWS (Zhang et al., 2019), Quora Insincere Questions,14 Ultrafine Entity Typing (Choi et al., 2018b), and Empathetic Reactions datasets (Buechel et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 61
                            }
                        ],
                        "text": "Similarly, on recast version of the Ultrafine Entity Typing (Choi et al., 2018b), we observe too small a gap between human (60.2 F1) and machine performance (55.0 F1)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 0
                            }
                        ],
                        "text": "Ultrafine Entity Typing We cast the task into a binary classification problem to make it an easier task for non-expert crowd workers."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 248,
                                "start": 224
                            }
                        ],
                        "text": "7It was challenging to train annotators to do well on Quora Insincere Questions (https://www.kaggle. com/c/quora-insincere-questions-classification/data), Empathetic Reactions (Buechel et al., 2018), and a recast version of Ultra-Fine Entity Typing (Choi et al., 2018b, see Appendix A for details), leading to low human performance."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 257,
                                "start": 205
                            }
                        ],
                        "text": "We collected data to produce conservative estimates for human performance on several tasks that we did not ultimately include in SuperGLUE, including GAP (Webster et al., 2018), PAWS (Zhang et al., 2019), Quora Insincere Questions,14 Ultrafine Entity Typing (Choi et al., 2018b), and Empathetic Reactions datasets (Buechel et al., 2018)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 211
                            }
                        ],
                        "text": "\u2026to do well on Quora Insincere Questions (https://www.kaggle. com/c/quora-insincere-questions-classification/data), Empathetic Reactions (Buechel et al., 2018), and a recast version of Ultra-Fine Entity Typing (Choi et al., 2018b, see Appendix A for details), leading to low human performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 18
                            }
                        ],
                        "text": "6Tasks like QuAC (Choi et al., 2018a) and STREUSLE (Schneider and Smith, 2015) differed substantially from the format of other tasks in SuperGLUE, which we worried would incentivize users to spend significant effort on task-specific model designs, rather than focusing on general-purpose techniques."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 56
                            }
                        ],
                        "text": "We work in cooperation with the authors of the dataset (Choi et al., 2018b) to do this reformulation: We give workers one possible tag for a word or phrase and asked them to classify the tag as being applicable or not."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 52057510,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "39e734da43eb8c72e9549b42e96760545036f8e5",
            "isKey": true,
            "numCitedBy": 435,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We present QuAC, a dataset for Question Answering in Context that contains 14K information-seeking QA dialogs (100K questions in total). The dialogs involve two crowd workers: (1) a student who poses a sequence of freeform questions to learn as much as possible about a hidden Wikipedia text, and (2) a teacher who answers the questions by providing short excerpts from the text. QuAC introduces challenges not found in existing machine comprehension datasets: its questions are often more open-ended, unanswerable, or only meaningful within the dialog context, as we show in a detailed qualitative evaluation. We also report results for a number of reference models, including a recently state-of-the-art reading comprehension architecture extended to model dialog context. Our best model underperforms humans by 20 F1, suggesting that there is significant room for future work on this data. Dataset, baseline, and leaderboard available at http://quac.ai."
            },
            "slug": "QuAC:-Question-Answering-in-Context-Choi-He",
            "title": {
                "fragments": [],
                "text": "QuAC: Question Answering in Context"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "QuAC introduces challenges not found in existing machine comprehension datasets: its questions are often more open-ended, unanswerable, or only meaningful within the dialog context, as it shows in a detailed qualitative evaluation."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2486762"
                        ],
                        "name": "L. Bentivogli",
                        "slug": "L.-Bentivogli",
                        "structuredName": {
                            "firstName": "Luisa",
                            "lastName": "Bentivogli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bentivogli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48323507"
                        ],
                        "name": "Peter Clark",
                        "slug": "Peter-Clark",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Clark",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Clark"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7465342"
                        ],
                        "name": "Ido Dagan",
                        "slug": "Ido-Dagan",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Dagan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2380885"
                        ],
                        "name": "Danilo Giampiccolo",
                        "slug": "Danilo-Giampiccolo",
                        "structuredName": {
                            "firstName": "Danilo",
                            "lastName": "Giampiccolo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Danilo Giampiccolo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 197
                            }
                        ],
                        "text": "RTE was previously included in GLUE, and we use the same data and format as before: We merge data from RTE1 (Dagan et al., 2006), RTE2 (Bar Haim et al., 2006), RTE3 (Giampiccolo et al., 2007), and RTE5 (Bentivogli et al., 2009).9 All datasets are combined and converted to two-class classification: entailment and not_entailment."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 173
                            }
                        ],
                        "text": "\u2026GLUE, and we use the same data and format as before: We merge data from RTE1 (Dagan et al., 2006), RTE2 (Bar Haim et al., 2006), RTE3 (Giampiccolo et al., 2007), and RTE5 (Bentivogli et al., 2009).9 All datasets are combined and converted to two-class classification: entailment and not_entailment."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 858065,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "db8885a0037fe47d973ade79d696586453710233",
            "isKey": false,
            "numCitedBy": 439,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents the Sixth Recognizing Textual Entailment (RTE-6) challenge. This year a major innovation was introduced, as the traditional Main Task was replaced by a new task, similar to the RTE-5 Search Pilot, in which Textual Entailment is performed on a real corpus in the Update Summarization scenario. A subtask was also proposed, aimed at detecting novel information. To continue the effort of testing RTE in NLP applications, a KBP Validation Pilot Task was set up, in which RTE systems had to validate the output of systems participating in the KBP Slot Filling Task. Eighteen teams participated in the Main Task (48 submitted runs) and 9 in the Novelty Detection Subtask (22 submitted runs). As for the Pilot, 10 runs were submitted by 3 participants. Finally, the exploratory effort started in RTE-5 to perform resource evaluation through ablation tests was not only reiterated in RTE-6, but also extended to tools."
            },
            "slug": "The-Sixth-PASCAL-Recognizing-Textual-Entailment-Bentivogli-Clark",
            "title": {
                "fragments": [],
                "text": "The Sixth PASCAL Recognizing Textual Entailment Challenge"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "This paper presents the Sixth Recognizing Textual Entailment (RTE-6) challenge, as the traditional Main Task was replaced by a new task, similar to the RTE-5 Search Pilot, in which TextualEntailment is performed on a real corpus in the Update Summarization scenario."
            },
            "venue": {
                "fragments": [],
                "text": "TAC"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717641"
                        ],
                        "name": "Mohammad Taher Pilehvar",
                        "slug": "Mohammad-Taher-Pilehvar",
                        "structuredName": {
                            "firstName": "Mohammad",
                            "lastName": "Pilehvar",
                            "middleNames": [
                                "Taher"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mohammad Taher Pilehvar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1387447871"
                        ],
                        "name": "Jos\u00e9 Camacho-Collados",
                        "slug": "Jos\u00e9-Camacho-Collados",
                        "structuredName": {
                            "firstName": "Jos\u00e9",
                            "lastName": "Camacho-Collados",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jos\u00e9 Camacho-Collados"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 30
                            }
                        ],
                        "text": "WiC The Word-in-Context (WiC, Pilehvar and Camacho-Collados, 2019) dataset supports a word sense disambiguation task cast as binary classification over sentence pairs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 0
                            }
                        ],
                        "text": "Pilehvar and Camacho-Collados (2019) provide an estimate for human performance on WiC in their paper."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 102353817,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a925f818f787e142c5f6bcb7bbd7ede2deb34860",
            "isKey": false,
            "numCitedBy": 175,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "By design, word embeddings are unable to model the dynamic nature of words\u2019 semantics, i.e., the property of words to correspond to potentially different meanings. To address this limitation, dozens of specialized meaning representation techniques such as sense or contextualized embeddings have been proposed. However, despite the popularity of research on this topic, very few evaluation benchmarks exist that specifically focus on the dynamic semantics of words. In this paper we show that existing models have surpassed the performance ceiling of the standard evaluation dataset for the purpose, i.e., Stanford Contextual Word Similarity, and highlight its shortcomings. To address the lack of a suitable benchmark, we put forward a large-scale Word in Context dataset, called WiC, based on annotations curated by experts, for generic evaluation of context-sensitive representations. WiC is released in https://pilehvar.github.io/wic/."
            },
            "slug": "WiC:-the-Word-in-Context-Dataset-for-Evaluating-Pilehvar-Camacho-Collados",
            "title": {
                "fragments": [],
                "text": "WiC: the Word-in-Context Dataset for Evaluating Context-Sensitive Meaning Representations"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A large-scale Word in Context dataset, called WiC, based on annotations curated by experts, for generic evaluation of context-sensitive representations, and shows that existing models have surpassed the performance ceiling of the standard evaluation dataset for the purpose."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46724030"
                        ],
                        "name": "Daniel Matthew Cer",
                        "slug": "Daniel-Matthew-Cer",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Cer",
                            "middleNames": [
                                "Matthew"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Matthew Cer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700007"
                        ],
                        "name": "Mona T. Diab",
                        "slug": "Mona-T.-Diab",
                        "structuredName": {
                            "firstName": "Mona",
                            "lastName": "Diab",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mona T. Diab"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733049"
                        ],
                        "name": "Eneko Agirre",
                        "slug": "Eneko-Agirre",
                        "structuredName": {
                            "firstName": "Eneko",
                            "lastName": "Agirre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eneko Agirre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1405529953"
                        ],
                        "name": "I. Lopez-Gazpio",
                        "slug": "I.-Lopez-Gazpio",
                        "structuredName": {
                            "firstName": "I\u00f1igo",
                            "lastName": "Lopez-Gazpio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Lopez-Gazpio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702974"
                        ],
                        "name": "Lucia Specia",
                        "slug": "Lucia-Specia",
                        "structuredName": {
                            "firstName": "Lucia",
                            "lastName": "Specia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lucia Specia"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4421747,
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology"
            ],
            "id": "a23fa96e7217ba0e9405d9e1fe3cdedd57b6e096",
            "isKey": false,
            "numCitedBy": 935,
            "numCiting": 96,
            "paperAbstract": {
                "fragments": [],
                "text": "Semantic Textual Similarity (STS) measures the meaning similarity of sentences. Applications include machine translation (MT), summarization, generation, question answering (QA), short answer grading, semantic search, dialog and conversational systems. The STS shared task is a venue for assessing the current state-of-the-art. The 2017 task focuses on multilingual and cross-lingual pairs with one sub-track exploring MT quality estimation (MTQE) data. The task obtained strong participation from 31 teams, with 17 participating in all language tracks. We summarize performance and review a selection of well performing methods. Analysis highlights common errors, providing insight into the limitations of existing models. To support ongoing work on semantic representations, the STS Benchmark is introduced as a new shared training and evaluation set carefully selected from the corpus of English STS shared task data (2012-2017)."
            },
            "slug": "SemEval-2017-Task-1:-Semantic-Textual-Similarity-Cer-Diab",
            "title": {
                "fragments": [],
                "text": "SemEval-2017 Task 1: Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The STS Benchmark is introduced as a new shared training and evaluation set carefully selected from the corpus of English STS shared task data (2012-2017), providing insight into the limitations of existing models."
            },
            "venue": {
                "fragments": [],
                "text": "SemEval@ACL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Yuan Zhang",
                        "slug": "Yuan-Zhang",
                        "structuredName": {
                            "firstName": "Yuan",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuan Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1387994164"
                        ],
                        "name": "Jason Baldridge",
                        "slug": "Jason-Baldridge",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Baldridge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jason Baldridge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2265599"
                        ],
                        "name": "Luheng He",
                        "slug": "Luheng-He",
                        "structuredName": {
                            "firstName": "Luheng",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luheng He"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 178
                            }
                        ],
                        "text": "We collected data to produce conservative estimates for human performance on several tasks that we did not ultimately include in SuperGLUE, including GAP (Webster et al., 2018), PAWS (Zhang et al., 2019), Quora Insincere Questions,14 Ultrafine Entity Typing (Choi et al., 2018b), and Empathetic Reactions datasets (Buechel et al., 2018)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 15
                            }
                        ],
                        "text": "For PAWS-Wiki, Zhang et al. (2019) report that BERT achieves an accuracy of 91.9%, while our human baseline achieved 84% accuracy."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 110
                            }
                        ],
                        "text": "8BERT achieved very high or superhuman performance on Query Well-Formedness (Faruqui and Das, 2018) and PAWS (Zhang et al., 2019), Discovering Ongoing Conversations (Zanzotto and Ferrone, 2017), and GAP (Webster et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 111
                            }
                        ],
                        "text": "(8)BERT achieved very high or superhuman performance on Query Well-Formedness (Faruqui and Das, 2018) and PAWS (Zhang et al., 2019), Discovering Ongoing Conversations (Zanzotto and Ferrone, 2017), and GAP (Webster et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 143
                            }
                        ],
                        "text": "\u2026estimates for human performance on several tasks that we did not ultimately include in SuperGLUE, including GAP (Webster et al., 2018), PAWS (Zhang et al., 2019), Quora Insincere Questions,14 Ultrafine Entity Typing (Choi et al., 2018b), and Empathetic Reactions datasets (Buechel et al.,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 91184042,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fc09d6486be1c9bbfbef4165ce3c1ab664e5d084",
            "isKey": true,
            "numCitedBy": 182,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Existing paraphrase identification datasets lack sentence pairs that have high lexical overlap without being paraphrases. Models trained on such data fail to distinguish pairs like flights from New York to Florida and flights from Florida to New York. This paper introduces PAWS (Paraphrase Adversaries from Word Scrambling), a new dataset with 108,463 well-formed paraphrase and non-paraphrase pairs with high lexical overlap. Challenging pairs are generated by controlled word swapping and back translation, followed by fluency and paraphrase judgments by human raters. State-of-the-art models trained on existing datasets have dismal performance on PAWS (<40% accuracy); however, including PAWS training data for these models improves their accuracy to 85% while maintaining performance on existing tasks. In contrast, models that do not capture non-local contextual information fail even with PAWS training examples. As such, PAWS provides an effective instrument for driving further progress on models that better exploit structure, context, and pairwise comparisons."
            },
            "slug": "PAWS:-Paraphrase-Adversaries-from-Word-Scrambling-Zhang-Baldridge",
            "title": {
                "fragments": [],
                "text": "PAWS: Paraphrase Adversaries from Word Scrambling"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "PAWS (Paraphrase Adversaries from Word Scrambling), a new dataset with 108,463 well-formed paraphrase and non-paraphrase pairs with high lexical overlap, is introduced, providing an effective instrument for driving further progress on models that better exploit structure, context, and pairwise comparisons."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33524946"
                        ],
                        "name": "Jieyu Zhao",
                        "slug": "Jieyu-Zhao",
                        "structuredName": {
                            "firstName": "Jieyu",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jieyu Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785372925"
                        ],
                        "name": "Tianlu Wang",
                        "slug": "Tianlu-Wang",
                        "structuredName": {
                            "firstName": "Tianlu",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tianlu Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064210"
                        ],
                        "name": "Mark Yatskar",
                        "slug": "Mark-Yatskar",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Yatskar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Yatskar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2004053"
                        ],
                        "name": "Vicente Ordonez",
                        "slug": "Vicente-Ordonez",
                        "structuredName": {
                            "firstName": "Vicente",
                            "lastName": "Ordonez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vicente Ordonez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2782886"
                        ],
                        "name": "Kai-Wei Chang",
                        "slug": "Kai-Wei-Chang",
                        "structuredName": {
                            "firstName": "Kai-Wei",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai-Wei Chang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4952494,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0be19fd9896e5d40222c690cc3ff553adc7c0e27",
            "isKey": false,
            "numCitedBy": 356,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we introduce a new benchmark for co-reference resolution focused on gender bias, WinoBias. Our corpus contains Winograd-schema style sentences with entities corresponding to people referred by their occupation (e.g. the nurse, the doctor, the carpenter). We demonstrate that a rule-based, a feature-rich, and a neural coreference system all link gendered pronouns to pro-stereotypical entities with higher accuracy than anti-stereotypical entities, by an average difference of 21.1 in F1 score. Finally, we demonstrate a data-augmentation approach that, in combination with existing word-embedding debiasing techniques, removes the bias demonstrated by these systems in WinoBias without significantly affecting their performance on existing datasets."
            },
            "slug": "Gender-Bias-in-Coreference-Resolution:-Evaluation-Zhao-Wang",
            "title": {
                "fragments": [],
                "text": "Gender Bias in Coreference Resolution: Evaluation and Debiasing Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A data-augmentation approach is demonstrated that, in combination with existing word-embedding debiasing techniques, removes the bias demonstrated by rule-based, feature-rich, and neural coreference systems in WinoBias without significantly affecting their performance on existing datasets."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48926630"
                        ],
                        "name": "Adam Poliak",
                        "slug": "Adam-Poliak",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Poliak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adam Poliak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "28926612"
                        ],
                        "name": "Aparajita Haldar",
                        "slug": "Aparajita-Haldar",
                        "structuredName": {
                            "firstName": "Aparajita",
                            "lastName": "Haldar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aparajita Haldar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2034613"
                        ],
                        "name": "Rachel Rudinger",
                        "slug": "Rachel-Rudinger",
                        "structuredName": {
                            "firstName": "Rachel",
                            "lastName": "Rudinger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rachel Rudinger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157840220"
                        ],
                        "name": "J. E. Hu",
                        "slug": "J.-E.-Hu",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Hu",
                            "middleNames": [
                                "Edward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. E. Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2949185"
                        ],
                        "name": "Ellie Pavlick",
                        "slug": "Ellie-Pavlick",
                        "structuredName": {
                            "firstName": "Ellie",
                            "lastName": "Pavlick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ellie Pavlick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2352617"
                        ],
                        "name": "Aaron Steven White",
                        "slug": "Aaron-Steven-White",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "White",
                            "middleNames": [
                                "Steven"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aaron Steven White"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7536576"
                        ],
                        "name": "Benjamin Van Durme",
                        "slug": "Benjamin-Van-Durme",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Durme",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benjamin Van Durme"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The outside results for COPA, MultiRC, and RTE are from Sap et al. (2019), Trivedi et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We use the Diverse Natural Language Inference Collection (Poliak et al., 2018) version that casts Winogender as a textual entailment task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 52123220,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74d8a800d73fc68a398f92ed0536912d1b7a32f3",
            "isKey": false,
            "numCitedBy": 115,
            "numCiting": 82,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a large-scale collection of diverse natural language inference (NLI) datasets that help provide insight into how well a sentence representation captures distinct types of reasoning. The collection results from recasting 13 existing datasets from 7 semantic phenomena into a common NLI structure, resulting in over half a million labeled context-hypothesis pairs in total. We refer to our collection as the DNC: Diverse Natural Language Inference Collection. The DNC is available online at https://www.decomp.net, and will grow over time as additional resources are recast and added from novel sources."
            },
            "slug": "Collecting-Diverse-Natural-Language-Inference-for-Poliak-Haldar",
            "title": {
                "fragments": [],
                "text": "Collecting Diverse Natural Language Inference Problems for Sentence Representation Evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A large-scale collection of diverse natural language inference datasets that help provide insight into how well a sentence representation captures distinct types of reasoning are presented."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72655349"
                        ],
                        "name": "Sheng Zhang",
                        "slug": "Sheng-Zhang",
                        "structuredName": {
                            "firstName": "Sheng",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sheng Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108860856"
                        ],
                        "name": "Xiaodong Liu",
                        "slug": "Xiaodong-Liu",
                        "structuredName": {
                            "firstName": "Xiaodong",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaodong Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46700348"
                        ],
                        "name": "Jingjing Liu",
                        "slug": "Jingjing-Liu",
                        "structuredName": {
                            "firstName": "Jingjing",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jingjing Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800422"
                        ],
                        "name": "Jianfeng Gao",
                        "slug": "Jianfeng-Gao",
                        "structuredName": {
                            "firstName": "Jianfeng",
                            "lastName": "Gao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianfeng Gao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800354"
                        ],
                        "name": "Kevin Duh",
                        "slug": "Kevin-Duh",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Duh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Duh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7536576"
                        ],
                        "name": "Benjamin Van Durme",
                        "slug": "Benjamin-Van-Durme",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Durme",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benjamin Van Durme"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 53116244,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a5b66ee341cb990f7f70a124b5fab3316d3b7e27",
            "isKey": false,
            "numCitedBy": 158,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a large-scale dataset, ReCoRD, for machine reading comprehension requiring commonsense reasoning. Experiments on this dataset demonstrate that the performance of state-of-the-art MRC systems fall far behind human performance. ReCoRD represents a challenge for future research to bridge the gap between human and machine commonsense reading comprehension. ReCoRD is available at this http URL"
            },
            "slug": "ReCoRD:-Bridging-the-Gap-between-Human-and-Machine-Zhang-Liu",
            "title": {
                "fragments": [],
                "text": "ReCoRD: Bridging the Gap between Human and Machine Commonsense Reading Comprehension"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "This work presents a large-scale dataset, ReCoRD, for machine reading comprehension requiring commonsense reasoning, and demonstrates that the performance of state-of-the-art MRC systems fall far behind human performance."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6365809"
                        ],
                        "name": "H. Trivedi",
                        "slug": "H.-Trivedi",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Trivedi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Trivedi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050205"
                        ],
                        "name": "Heeyoung Kwon",
                        "slug": "Heeyoung-Kwon",
                        "structuredName": {
                            "firstName": "Heeyoung",
                            "lastName": "Kwon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Heeyoung Kwon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2236429"
                        ],
                        "name": "Tushar Khot",
                        "slug": "Tushar-Khot",
                        "structuredName": {
                            "firstName": "Tushar",
                            "lastName": "Khot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tushar Khot"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48229640"
                        ],
                        "name": "Ashish Sabharwal",
                        "slug": "Ashish-Sabharwal",
                        "structuredName": {
                            "firstName": "Ashish",
                            "lastName": "Sabharwal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ashish Sabharwal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35217367"
                        ],
                        "name": "Niranjan Balasubramanian",
                        "slug": "Niranjan-Balasubramanian",
                        "structuredName": {
                            "firstName": "Niranjan",
                            "lastName": "Balasubramanian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Niranjan Balasubramanian"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 75
                            }
                        ],
                        "text": "The outside results for COPA, MultiRC, and RTE are from Sap et al. (2019), Trivedi et al. (2019), and Liu et al. (2019c) respectively."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 128344862,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dfbbb0338123de44ef3c0bdc05e9785d20d430cc",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Question Answering (QA) naturally reduces to an entailment problem, namely, verifying whether some text entails the answer to a question. However, for multi-hop QA tasks, which require reasoning with multiple sentences, it remains unclear how best to utilize entailment models pre-trained on large scale datasets such as SNLI, which are based on sentence pairs. We introduce Multee, a general architecture that can effectively use entailment models for multi-hop QA tasks. Multee uses (i) a local module that helps locate important sentences, thereby avoiding distracting information, and (ii) a global module that aggregates information by effectively incorporating importance weights. Importantly, we show that both modules can use entailment functions pre-trained on a large scale NLI datasets. We evaluate performance on MultiRC and OpenBookQA, two multihop QA datasets. When using an entailment function pre-trained on NLI datasets, Multee outperforms QA models trained only on the target QA datasets and the OpenAI transformer models."
            },
            "slug": "Repurposing-Entailment-for-Multi-Hop-Question-Tasks-Trivedi-Kwon",
            "title": {
                "fragments": [],
                "text": "Repurposing Entailment for Multi-Hop Question Answering Tasks"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Multee is introduced, a general architecture that can effectively use entailment models for multi-hop QA tasks and outperforms QA models trained only on the target QA datasets and the OpenAI transformer models when using an entailment function pre-trained on NLI datasets."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403835575"
                        ],
                        "name": "Roy Bar-Haim",
                        "slug": "Roy-Bar-Haim",
                        "structuredName": {
                            "firstName": "Roy",
                            "lastName": "Bar-Haim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roy Bar-Haim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7465342"
                        ],
                        "name": "Ido Dagan",
                        "slug": "Ido-Dagan",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Dagan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66648221"
                        ],
                        "name": "Bill Dolan",
                        "slug": "Bill-Dolan",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Dolan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bill Dolan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36405930"
                        ],
                        "name": "L. Ferro",
                        "slug": "L.-Ferro",
                        "structuredName": {
                            "firstName": "Lisa",
                            "lastName": "Ferro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Ferro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2380885"
                        ],
                        "name": "Danilo Giampiccolo",
                        "slug": "Danilo-Giampiccolo",
                        "structuredName": {
                            "firstName": "Danilo",
                            "lastName": "Giampiccolo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Danilo Giampiccolo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712352"
                        ],
                        "name": "B. Magnini",
                        "slug": "B.-Magnini",
                        "structuredName": {
                            "firstName": "Bernardo",
                            "lastName": "Magnini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Magnini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711977"
                        ],
                        "name": "Idan Szpektor",
                        "slug": "Idan-Szpektor",
                        "structuredName": {
                            "firstName": "Idan",
                            "lastName": "Szpektor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Idan Szpektor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 140
                            }
                        ],
                        "text": "RTE was previously included in GLUE, and we use the same data and format as before: We merge data from RTE1 (Dagan et al., 2006), RTE2 (Bar Haim et al., 2006), RTE3 (Giampiccolo et al., 2007), and RTE5 (Bentivogli et al., 2009).9 All datasets are combined and converted to two-class classification:\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13385138,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "136326377c122560768db674e35f5bcd6de3bc40",
            "isKey": false,
            "numCitedBy": 408,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the Second PASCAL Recognising Textual Entailment Challenge (RTE-2). 1 We describe the RTE2 dataset and overview the submissions for the challenge. One of the main goals for this year\u2019s dataset was to provide more \u201crealistic\u201d text-hypothesis examples, based mostly on outputs of actual systems. The 23 submissions for the challenge present diverse approaches and research directions, and the best results achieved this year are considerably higher than last year\u2019s state of the art."
            },
            "slug": "The-Second-PASCAL-Recognising-Textual-Entailment-Bar-Haim-Dagan",
            "title": {
                "fragments": [],
                "text": "The Second PASCAL Recognising Textual Entailment Challenge"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The RTE2 dataset is described and the submissions for the challenge are overviewed, to provide more \u201crealistic\u201d text-hypothesis examples, based mostly on outputs of actual systems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "24590005"
                        ],
                        "name": "Alex Perelygin",
                        "slug": "Alex-Perelygin",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Perelygin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Perelygin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110402830"
                        ],
                        "name": "Jean Wu",
                        "slug": "Jean-Wu",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1964541"
                        ],
                        "name": "Jason Chuang",
                        "slug": "Jason-Chuang",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Chuang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jason Chuang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144922861"
                        ],
                        "name": "Christopher Potts",
                        "slug": "Christopher-Potts",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Potts",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher Potts"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 990233,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "687bac2d3320083eb4530bf18bb8f8f721477600",
            "isKey": false,
            "numCitedBy": 5367,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "Semantic word spaces have been very useful but cannot express the meaning of longer phrases in a principled way. Further progress towards understanding compositionality in tasks such as sentiment detection requires richer supervised training and evaluation resources and more powerful models of composition. To remedy this, we introduce a Sentiment Treebank. It includes fine grained sentiment labels for 215,154 phrases in the parse trees of 11,855 sentences and presents new challenges for sentiment compositionality. To address them, we introduce the Recursive Neural Tensor Network. When trained on the new treebank, this model outperforms all previous methods on several metrics. It pushes the state of the art in single sentence positive/negative classification from 80% up to 85.4%. The accuracy of predicting fine-grained sentiment labels for all phrases reaches 80.7%, an improvement of 9.7% over bag of features baselines. Lastly, it is the only model that can accurately capture the effects of negation and its scope at various tree levels for both positive and negative phrases."
            },
            "slug": "Recursive-Deep-Models-for-Semantic-Compositionality-Socher-Perelygin",
            "title": {
                "fragments": [],
                "text": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A Sentiment Treebank that includes fine grained sentiment labels for 215,154 phrases in the parse trees of 11,855 sentences and presents new challenges for sentiment compositionality, and introduces the Recursive Neural Tensor Network."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35168946"
                        ],
                        "name": "A. Gordon",
                        "slug": "A.-Gordon",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Gordon",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gordon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714932"
                        ],
                        "name": "Zornitsa Kozareva",
                        "slug": "Zornitsa-Kozareva",
                        "structuredName": {
                            "firstName": "Zornitsa",
                            "lastName": "Kozareva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zornitsa Kozareva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3316824"
                        ],
                        "name": "Melissa Roemmele",
                        "slug": "Melissa-Roemmele",
                        "structuredName": {
                            "firstName": "Melissa",
                            "lastName": "Roemmele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Melissa Roemmele"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 49
                            }
                        ],
                        "text": "COPA The Choice Of Plausible Alternatives (COPA, Roemmele et al., 2011) dataset is a causal reasoning task in which a system is given a premise sentence and two possible alternatives."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 434646,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "fb0b11046474b8f1c810f947f313c7c7229a988f",
            "isKey": false,
            "numCitedBy": 276,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "SemEval-2012 Task 7 presented a deceptively simple challenge: given an English sentence as a premise, select the sentence amongst two alternatives that more plausibly has a causal relation to the premise. In this paper, we describe the development of this task and its motivation. We describe the two systems that competed in this task as part of SemEval-2012, and compare their results to those achieved in previously published research. We discuss the characteristics that make this task so difficult, and offer our thoughts on how progress can be made in the future."
            },
            "slug": "SemEval-2012-Task-7:-Choice-of-Plausible-An-of-Gordon-Kozareva",
            "title": {
                "fragments": [],
                "text": "SemEval-2012 Task 7: Choice of Plausible Alternatives: An Evaluation of Commonsense Causal Reasoning"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The two systems that competed in this task as part of SemEval-2012 are described, and their results are compared to those achieved in previously published research."
            },
            "venue": {
                "fragments": [],
                "text": "*SEMEVAL"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39853709"
                        ],
                        "name": "Fei Liu",
                        "slug": "Fei-Liu",
                        "structuredName": {
                            "firstName": "Fei",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fei Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144154709"
                        ],
                        "name": "Jacob Eisenstein",
                        "slug": "Jacob-Eisenstein",
                        "structuredName": {
                            "firstName": "Jacob",
                            "lastName": "Eisenstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jacob Eisenstein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 102
                            }
                        ],
                        "text": "The outside results for COPA, MultiRC, and RTE are from Sap et al. (2019), Trivedi et al. (2019), and Liu et al. (2019c) respectively."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 48
                            }
                        ],
                        "text": "%) at the time of GLUE\u2019s launch to 85% accuracy (Liu et al., 2019c) at the time of writing."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 138
                            }
                        ],
                        "text": "Recently, Phang et al. (2018) showed that BERT could be improved by extending pretraining with labeled data related to a target task, and Liu et al. (2019c) showed further improvements using a specialized form of multi-task learning with parameter sharing."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 142
                            }
                        ],
                        "text": "\u2026phenomena (Figure 2) measured in GLUE remain difficult, the current state of the art GLUE Score (83.8 with the BERT-based MT-DNN system from Liu et al., 2019c) is only 3.3 points behind our estimate of global human performance (87.1 from Nangia and Bowman, 2019), and in fact exceeds this\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 135
                            }
                        ],
                        "text": "Much recent work has observed this for NLI and QA (Jia and Liang, 2017; Naik et al., 2018; McCoy and Linzen, 2019; McCoy et al., 2019; Liu et al., 2019a,b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59604441,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8af29a137e8fea8a9560a86a8e2ec8074bbd1dec",
            "isKey": true,
            "numCitedBy": 10,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new architecture for storing and accessing entity mentions during online text processing. While reading the text, entity references are identified, and may be stored by either updating or overwriting a cell in a fixed-length memory. The update operation implies coreference with the other mentions that are stored in the same cell; the overwrite operation causes these mentions to be forgotten. By encoding the memory operations as differentiable gates, it is possible to train the model end-to-end, using both a supervised anaphora resolution objective as well as a supplementary language modeling objective. Evaluation on a dataset of pronoun-name anaphora demonstrates strong performance with purely incremental text processing."
            },
            "slug": "The-Referential-Reader:-A-Recurrent-Entity-Network-Liu-Zettlemoyer",
            "title": {
                "fragments": [],
                "text": "The Referential Reader: A Recurrent Entity Network for Anaphora Resolution"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "A new architecture for storing and accessing entity mentions during online text processing is presented, and it is possible to train the model end-to-end, using both a supervised anaphora resolution objective as well as a supplementary language modeling objective."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2486762"
                        ],
                        "name": "L. Bentivogli",
                        "slug": "L.-Bentivogli",
                        "structuredName": {
                            "firstName": "Luisa",
                            "lastName": "Bentivogli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bentivogli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48323507"
                        ],
                        "name": "Peter Clark",
                        "slug": "Peter-Clark",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Clark",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Clark"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7465342"
                        ],
                        "name": "Ido Dagan",
                        "slug": "Ido-Dagan",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Dagan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2380885"
                        ],
                        "name": "Danilo Giampiccolo",
                        "slug": "Danilo-Giampiccolo",
                        "structuredName": {
                            "firstName": "Danilo",
                            "lastName": "Giampiccolo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Danilo Giampiccolo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": ", 2007), and RTE5 (Bentivogli et al., 2009)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5791809,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0f8468de03ee9f12d693237bec87916311bf1c24",
            "isKey": false,
            "numCitedBy": 390,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents the Seventh Recognizing Textual Entailment (RTE-7) challenge. This year\u2019s challenge replicated the exercise proposed in RTE-6, consisting of a Main Task, in which Textual Entailment is performed on a real corpus in the Update Summarization scenario; a Main subtask aimed at detecting novel information; and a KBP Validation Task, in which RTE systems had to validate the output of systems participating in the KBP Slot Filling Task. Thirteen teams participated in the Main Task (submitting 33 runs) and 5 in the Novelty Detection Subtask (submitting 13 runs). The KBP Validation Task was undertaken by 2 participants which submitted 5 runs. The ablation test experiment, introduced in RTE-5 to evaluate the impact of knowledge resources used by the systems participating in the Main Task and extended also to tools in RTE-6, was also repeated in RTE-7."
            },
            "slug": "The-Seventh-PASCAL-Recognizing-Textual-Entailment-Bentivogli-Clark",
            "title": {
                "fragments": [],
                "text": "The Seventh PASCAL Recognizing Textual Entailment Challenge"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "This paper presents the Seventh Recognizing Textual Entailment (RTE-7) challenge, which replicated the exercise proposed in RTE-6, consisting of a Main Task, a Main subtask aimed at detecting novel information; and a KBP Validation Task, in which RTE systems had to validate the output of systems participating in the KBP Slot Filling Task."
            },
            "venue": {
                "fragments": [],
                "text": "TAC"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145254207"
                        ],
                        "name": "Nathan Schneider",
                        "slug": "Nathan-Schneider",
                        "structuredName": {
                            "firstName": "Nathan",
                            "lastName": "Schneider",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nathan Schneider"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144365875"
                        ],
                        "name": "Noah A. Smith",
                        "slug": "Noah-A.-Smith",
                        "structuredName": {
                            "firstName": "Noah",
                            "lastName": "Smith",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Noah A. Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 52
                            }
                        ],
                        "text": "6Tasks like QuAC (Choi et al., 2018a) and STREUSLE (Schneider and Smith, 2015) differed substantially from the format of other tasks in SuperGLUE, which we worried would incentivize users to spend significant effort on task-specific model designs, rather than focusing on general-purpose techniques."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 22
                            }
                        ],
                        "text": ", 2018a) and STREUSLE (Schneider and Smith, 2015) differed substantially from the format of other tasks in SuperGLUE, which we worried would incentivize users to spend significant effort on task-specific model designs, rather than focusing on general-purpose techniques."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 896190,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "ad90c64a99928c920ae5058e566b283e24952bd7",
            "isKey": false,
            "numCitedBy": 72,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces a task of identifying and semantically classifying lexical expressions in running text. We investigate the online reviews genre, adding semantic supersense annotations to a 55,000 word English corpus that was previously annotated for multiword expressions. The noun and verb supersenses apply to full lexical expressions, whether single- or multiword. We then present a sequence tagging model that jointly infers lexical expressions and their supersenses. Results show that even with our relatively small training corpus in a noisy domain, the joint task can be performed to attain 70% class labeling F1."
            },
            "slug": "A-Corpus-and-Model-Integrating-Multiword-and-Schneider-Smith",
            "title": {
                "fragments": [],
                "text": "A Corpus and Model Integrating Multiword Expressions and Supersenses"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "The online reviews genre is investigated, adding semantic supersense annotations to a 55,000 word English corpus that was previously annotated for multiword expressions, and a sequence tagging model is presented that jointly infers lexical expressions and their supersenses."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2545335"
                        ],
                        "name": "Rowan Zellers",
                        "slug": "Rowan-Zellers",
                        "structuredName": {
                            "firstName": "Rowan",
                            "lastName": "Zellers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rowan Zellers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3312309"
                        ],
                        "name": "Yonatan Bisk",
                        "slug": "Yonatan-Bisk",
                        "structuredName": {
                            "firstName": "Yonatan",
                            "lastName": "Bisk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yonatan Bisk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4671928"
                        ],
                        "name": "Roy Schwartz",
                        "slug": "Roy-Schwartz",
                        "structuredName": {
                            "firstName": "Roy",
                            "lastName": "Schwartz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roy Schwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699545"
                        ],
                        "name": "Yejin Choi",
                        "slug": "Yejin-Choi",
                        "structuredName": {
                            "firstName": "Yejin",
                            "lastName": "Choi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yejin Choi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 68
                            }
                        ],
                        "text": "We get further gains by training on related tasks like MultiNLI and SWAG."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 49
                            }
                        ],
                        "text": "Similarly, given the similarity of COPA to SWAG (Zellers et al., 2018), we first fine-tune BERT on SWAG."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 52019251,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "af5c4b80fbf847f69a202ba5a780a3dd18c1a027",
            "isKey": false,
            "numCitedBy": 456,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": "Given a partial description like \u201cshe opened the hood of the car,\u201d humans can reason about the situation and anticipate what might come next (\u201dthen, she examined the engine\u201d). In this paper, we introduce the task of grounded commonsense inference, unifying natural language inference and commonsense reasoning. We present SWAG, a new dataset with 113k multiple choice questions about a rich spectrum of grounded situations. To address the recurring challenges of the annotation artifacts and human biases found in many existing datasets, we propose Adversarial Filtering (AF), a novel procedure that constructs a de-biased dataset by iteratively training an ensemble of stylistic classifiers, and using them to filter the data. To account for the aggressive adversarial filtering, we use state-of-the-art language models to massively oversample a diverse set of potential counterfactuals. Empirical results demonstrate that while humans can solve the resulting inference problems with high accuracy (88%), various competitive models struggle on our task. We provide comprehensive analysis that indicates significant opportunities for future research."
            },
            "slug": "SWAG:-A-Large-Scale-Adversarial-Dataset-for-Zellers-Bisk",
            "title": {
                "fragments": [],
                "text": "SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper introduces the task of grounded commonsense inference, unifying natural language inference and commonsense reasoning, and proposes Adversarial Filtering (AF), a novel procedure that constructs a de-biased dataset by iteratively training an ensemble of stylistic classifiers, and using them to filter the data."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763608"
                        ],
                        "name": "Chris Callison-Burch",
                        "slug": "Chris-Callison-Burch",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Callison-Burch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Callison-Burch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057788"
                        ],
                        "name": "M. Osborne",
                        "slug": "M.-Osborne",
                        "structuredName": {
                            "firstName": "Miles",
                            "lastName": "Osborne",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Osborne"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755162"
                        ],
                        "name": "Philipp Koehn",
                        "slug": "Philipp-Koehn",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Koehn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Koehn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7647892,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "0a1f4cc5e1d7ccdce98c65545bbcccc23a6c16e7",
            "isKey": false,
            "numCitedBy": 720,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We argue that the machine translation community is overly reliant on the Bleu machine translation evaluation metric. We show that an improved Bleu score is neither necessary nor sufficient for achieving an actual improvement in translation quality, and give two significant counterexamples to Bleu\u2019s correlation with human judgments of quality. This offers new potential for research which was previously deemed unpromising by an inability to improve upon Bleu scores."
            },
            "slug": "Re-evaluating-the-Role-of-Bleu-in-Machine-Research-Callison-Burch-Osborne",
            "title": {
                "fragments": [],
                "text": "Re-evaluating the Role of Bleu in Machine Translation Research"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "It is shown that an improved Bleu score is neither necessary nor sufficient for achieving an actual improvement in translation quality, and two significant counterexamples to Bleu\u2019s correlation with human judgments of quality are given."
            },
            "venue": {
                "fragments": [],
                "text": "EACL"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2729164"
                        ],
                        "name": "Maarten Sap",
                        "slug": "Maarten-Sap",
                        "structuredName": {
                            "firstName": "Maarten",
                            "lastName": "Sap",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Maarten Sap"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2516777"
                        ],
                        "name": "Hannah Rashkin",
                        "slug": "Hannah-Rashkin",
                        "structuredName": {
                            "firstName": "Hannah",
                            "lastName": "Rashkin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hannah Rashkin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51250248"
                        ],
                        "name": "Derek Chen",
                        "slug": "Derek-Chen",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39227408"
                        ],
                        "name": "Ronan Le Bras",
                        "slug": "Ronan-Le-Bras",
                        "structuredName": {
                            "firstName": "Ronan",
                            "lastName": "Le Bras",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronan Le Bras"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699545"
                        ],
                        "name": "Yejin Choi",
                        "slug": "Yejin-Choi",
                        "structuredName": {
                            "firstName": "Yejin",
                            "lastName": "Choi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yejin Choi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 56
                            }
                        ],
                        "text": "The outside results for COPA, MultiRC, and RTE are from Sap et al. (2019), Trivedi et al. (2019), and Liu et al. (2019c) respectively."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 128296356,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "421cb75cc91e8e5683d41ee6a918121aedf6d24d",
            "isKey": false,
            "numCitedBy": 200,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce Social IQa, the first large-scale benchmark for commonsense reasoning about social situations. Social IQa contains 38,000 multiple choice questions for probing emotional and social intelligence in a variety of everyday situations (e.g., Q: \u201cJordan wanted to tell Tracy a secret, so Jordan leaned towards Tracy. Why did Jordan do this?\u201d A: \u201cMake sure no one else could hear\u201d). Through crowdsourcing, we collect commonsense questions along with correct and incorrect answers about social interactions, using a new framework that mitigates stylistic artifacts in incorrect answers by asking workers to provide the right answer to a different but related question. Empirical results show that our benchmark is challenging for existing question-answering models based on pretrained language models, compared to human performance (>20% gap). Notably, we further establish Social IQa as a resource for transfer learning of commonsense knowledge, achieving state-of-the-art performance on multiple commonsense reasoning tasks (Winograd Schemas, COPA)."
            },
            "slug": "Social-IQA:-Commonsense-Reasoning-about-Social-Sap-Rashkin",
            "title": {
                "fragments": [],
                "text": "Social IQA: Commonsense Reasoning about Social Interactions"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "It is established that Social IQa, the first large-scale benchmark for commonsense reasoning about social situations, is challenging for existing question-answering models based on pretrained language models, compared to human performance (>20% gap)."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP 2019"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2337426"
                        ],
                        "name": "Fabio Massimo Zanzotto",
                        "slug": "Fabio-Massimo-Zanzotto",
                        "structuredName": {
                            "firstName": "Fabio",
                            "lastName": "Zanzotto",
                            "middleNames": [
                                "Massimo"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fabio Massimo Zanzotto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40637359"
                        ],
                        "name": "L. Ferrone",
                        "slug": "L.-Ferrone",
                        "structuredName": {
                            "firstName": "Lorenzo",
                            "lastName": "Ferrone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Ferrone"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 166
                            }
                        ],
                        "text": "8BERT achieved very high or superhuman performance on Query Well-Formedness (Faruqui and Das, 2018) and PAWS (Zhang et al., 2019), Discovering Ongoing Conversations (Zanzotto and Ferrone, 2017), and GAP (Webster et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 38
                            }
                        ],
                        "text": "On Discovering Ongoing Conversations (Zanzotto and Ferrone, 2017), our BERT baseline achieves an F1 of 51.9 on a version of the task cast as sentence pair classification (given two snippets of texts from plays, determine if the second snippet is a continuation of the first)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 43
                            }
                        ],
                        "text": ", 2019), Discovering Ongoing Conversations (Zanzotto and Ferrone, 2017), and GAP (Webster et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 809818,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d7874b4742c2f30c7ec4a98c869f923084410e5e",
            "isKey": true,
            "numCitedBy": 2,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": "Finding threads in textual dialogs is emerging as a need to better organize stored knowledge. We capture this need by introducing the novel task of discovering ongoing conversations in scattered dialog blocks. Our aim in this article is twofold. First, we propose a publicly available testbed for the task by solving the insurmountable problem of privacy of Big Personal Data. In fact, we showed that personal dialogs can be surrogated with theatrical plays. Second, we propose a suite of computationally light learning models that can use syntactic and semantic features. With this suite, we showed that models for this challenging task should include features capturing shifts in language use and, possibly, modeling underlying scripts."
            },
            "slug": "Have-You-Lost-the-Thread-Discovering-Ongoing-in-Zanzotto-Ferrone",
            "title": {
                "fragments": [],
                "text": "Have You Lost the Thread? Discovering Ongoing Conversations in Scattered Dialog Blocks"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A publicly available testbed for the novel task of discovering ongoing conversations in scattered dialog blocks is proposed by solving the insurmountable problem of privacy of Big Personal Data and a suite of computationally light learning models that can use syntactic and semantic features are proposed."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Trans. Interact. Intell. Syst."
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "83415753"
                        ],
                        "name": "W. Dolan",
                        "slug": "W.-Dolan",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Dolan",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Dolan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3125776"
                        ],
                        "name": "Chris Brockett",
                        "slug": "Chris-Brockett",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Brockett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Brockett"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 67
                            }
                        ],
                        "text": "The Quora Question Pairs, The Microsoft Research Paraphrase Corpus (Dolan and Brockett, 2005), and QNLI, an answer sentence selection task derived from SQuAD (Rajpurkar et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 182
                            }
                        ],
                        "text": "\u2026to maximize difficulty and diversity, and were drawn from among those submitted to an open call for proposals.3\n2The Quora Question Pairs, The Microsoft Research Paraphrase Corpus (Dolan and Brockett, 2005), and QNLI, an answer sentence selection task derived from SQuAD (Rajpurkar et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 141
                            }
                        ],
                        "text": "These tasks were chosen to maximize difficulty and diversity, and were drawn from among those submitted to an open call for proposals.3\n2The Quora Question Pairs, The Microsoft Research Paraphrase Corpus (Dolan and Brockett, 2005), and QNLI, an answer sentence selection task derived from SQuAD (Rajpurkar et al., 2016)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 16639476,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "475354f10798f110d34792b6d88f31d6d5cb099e",
            "isKey": false,
            "numCitedBy": 834,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "An obstacle to research in automatic paraphrase identification and generation is the lack of large-scale, publiclyavailable labeled corpora of sentential paraphrases. This paper describes the creation of the recently-released Microsoft Research Paraphrase Corpus, which contains 5801 sentence pairs, each hand-labeled with a binary judgment as to whether the pair constitutes a paraphrase. The corpus was created using heuristic extraction techniques in conjunction with an SVM-based classifier to select likely sentence-level paraphrases from a large corpus of topicclustered news data. These pairs were then submitted to human judges, who confirmed that 67% were in fact semantically equivalent. In addition to describing the corpus itself, we explore a number of issues that arose in defining guidelines for the human raters."
            },
            "slug": "Automatically-Constructing-a-Corpus-of-Sentential-Dolan-Brockett",
            "title": {
                "fragments": [],
                "text": "Automatically Constructing a Corpus of Sentential Paraphrases"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The creation of the recently-released Microsoft Research Paraphrase Corpus, which contains 5801 sentence pairs, each hand-labeled with a binary judgment as to whether the pair constitutes a paraphrase, is described."
            },
            "venue": {
                "fragments": [],
                "text": "IJCNLP"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7465342"
                        ],
                        "name": "Ido Dagan",
                        "slug": "Ido-Dagan",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Dagan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2807469"
                        ],
                        "name": "Oren Glickman",
                        "slug": "Oren-Glickman",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Glickman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Glickman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712352"
                        ],
                        "name": "B. Magnini",
                        "slug": "B.-Magnini",
                        "structuredName": {
                            "firstName": "Bernardo",
                            "lastName": "Magnini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Magnini"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 103
                            }
                        ],
                        "text": "RTE was previously included in GLUE, and we use the same data and format as before: We merge data from RTE1 (Dagan et al., 2006), RTE2 (Bar Haim et al., 2006), RTE3 (Giampiccolo et al., 2007), and RTE5 (Bentivogli et al., 2009).9 All datasets are combined and converted to two-class classification: entailment and not_entailment."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 109
                            }
                        ],
                        "text": "RTE was previously included in GLUE, and we use the same data and format as before: We merge data from RTE1 (Dagan et al., 2006), RTE2 (Bar Haim et al., 2006), RTE3 (Giampiccolo et al., 2007), and RTE5 (Bentivogli et al., 2009).9 All datasets are combined and converted to two-class classification:\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8587959,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de794d50713ea5f91a7c9da3d72041e2f5ef8452",
            "isKey": false,
            "numCitedBy": 1762,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents the Third PASCAL Recognising Textual Entailment Challenge (RTE-3), providing an overview of the dataset creating methodology and the submitted systems. In creating this year's dataset, a number of longer texts were introduced to make the challenge more oriented to realistic scenarios. Additionally, a pool of resources was offered so that the participants could share common tools. A pilot task was also set up, aimed at differentiating unknown entailments from identified contradictions and providing justifications for overall system decisions. 26 participants submitted 44 runs, using different approaches and generally presenting new entailment models and achieving higher scores than in the previous challenges."
            },
            "slug": "The-PASCAL-Recognising-Textual-Entailment-Challenge-Dagan-Glickman",
            "title": {
                "fragments": [],
                "text": "The PASCAL Recognising Textual Entailment Challenge"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper presents the Third PASCAL Recognising Textual Entailment Challenge (RTE-3), providing an overview of the dataset creating methodology and the submitted systems."
            },
            "venue": {
                "fragments": [],
                "text": "MLCW"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51153248"
                        ],
                        "name": "Kaiji Lu",
                        "slug": "Kaiji-Lu",
                        "structuredName": {
                            "firstName": "Kaiji",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaiji Lu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3251561"
                        ],
                        "name": "Piotr Mardziel",
                        "slug": "Piotr-Mardziel",
                        "structuredName": {
                            "firstName": "Piotr",
                            "lastName": "Mardziel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Piotr Mardziel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51149912"
                        ],
                        "name": "Fangjing Wu",
                        "slug": "Fangjing-Wu",
                        "structuredName": {
                            "firstName": "Fangjing",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fangjing Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51150647"
                        ],
                        "name": "Preetam Amancharla",
                        "slug": "Preetam-Amancharla",
                        "structuredName": {
                            "firstName": "Preetam",
                            "lastName": "Amancharla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Preetam Amancharla"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33374965"
                        ],
                        "name": "Anupam Datta",
                        "slug": "Anupam-Datta",
                        "structuredName": {
                            "firstName": "Anupam",
                            "lastName": "Datta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anupam Datta"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 51888520,
            "fieldsOfStudy": [
                "Computer Science",
                "Sociology"
            ],
            "id": "fef9d9eb2d527174ac5b329b0a044e98a1808971",
            "isKey": false,
            "numCitedBy": 136,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We examine whether neural natural language processing (NLP) systems reflect historical biases in training data. We define a general benchmark to quantify gender bias in a variety of neural NLP tasks. Our empirical evaluation with state-of-the-art neural coreference resolution and textbook RNN-based language models trained on benchmark datasets finds significant gender bias in how models view occupations. We then mitigate bias with CDA: a generic methodology for corpus augmentation via causal interventions that breaks associations between gendered and gender-neutral words. We empirically show that CDA effectively decreases gender bias while preserving accuracy. We also explore the space of mitigation strategies with CDA, a prior approach to word embedding debiasing (WED), and their compositions. We show that CDA outperforms WED, drastically so when word embeddings are trained. For pre-trained embeddings, the two methods can be effectively composed. We also find that as training proceeds on the original data set with gradient descent the gender bias grows as the loss reduces, indicating that the optimization encourages bias; CDA mitigates this behavior."
            },
            "slug": "Gender-Bias-in-Neural-Natural-Language-Processing-Lu-Mardziel",
            "title": {
                "fragments": [],
                "text": "Gender Bias in Neural Natural Language Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is empirically show that CDA effectively decreases gender bias while preserving accuracy, and it is found that as training proceeds on the original data set with gradient descent the gender bias grows as the loss reduces, indicating that the optimization encourages bias; CDA mitigates this behavior."
            },
            "venue": {
                "fragments": [],
                "text": "Logic, Language, and Security"
            },
            "year": 2020
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144634184"
                        ],
                        "name": "Chia-Wei Liu",
                        "slug": "Chia-Wei-Liu",
                        "structuredName": {
                            "firstName": "Chia-Wei",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chia-Wei Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054294"
                        ],
                        "name": "Ryan Lowe",
                        "slug": "Ryan-Lowe",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "Lowe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan Lowe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35224828"
                        ],
                        "name": "Iulian Serban",
                        "slug": "Iulian-Serban",
                        "structuredName": {
                            "firstName": "Iulian",
                            "lastName": "Serban",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Iulian Serban"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38107789"
                        ],
                        "name": "Michael Noseworthy",
                        "slug": "Michael-Noseworthy",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Noseworthy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Noseworthy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778839"
                        ],
                        "name": "Laurent Charlin",
                        "slug": "Laurent-Charlin",
                        "structuredName": {
                            "firstName": "Laurent",
                            "lastName": "Charlin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laurent Charlin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145134886"
                        ],
                        "name": "Joelle Pineau",
                        "slug": "Joelle-Pineau",
                        "structuredName": {
                            "firstName": "Joelle",
                            "lastName": "Pineau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joelle Pineau"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "(2019), and Liu et al. (2019d) respectively."
                    },
                    "intents": []
                }
            ],
            "corpusId": 9197196,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "129cbad01be98ee88a930e31898cb76be79c41c1",
            "isKey": false,
            "numCitedBy": 930,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate evaluation metrics for dialogue response generation systems where supervised labels, such as task completion, are not available. Recent works in response generation have adopted metrics from machine translation to compare a model's generated response to a single target response. We show that these metrics correlate very weakly with human judgements in the non-technical Twitter domain, and not at all in the technical Ubuntu domain. We provide quantitative and qualitative results highlighting specific weaknesses in existing metrics, and provide recommendations for future development of better automatic evaluation metrics for dialogue systems."
            },
            "slug": "How-NOT-To-Evaluate-Your-Dialogue-System:-An-Study-Liu-Lowe",
            "title": {
                "fragments": [],
                "text": "How NOT To Evaluate Your Dialogue System: An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response Generation"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "This work investigates evaluation metrics for dialogue response generation systems where supervised labels, such as task completion, are not available and shows that these metrics correlate very weakly with human judgements in the non-technical Twitter domain, and not at all in the technical Ubuntu domain."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726807"
                        ],
                        "name": "Diederik P. Kingma",
                        "slug": "Diederik-P.-Kingma",
                        "structuredName": {
                            "firstName": "Diederik",
                            "lastName": "Kingma",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diederik P. Kingma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2503659"
                        ],
                        "name": "Jimmy Ba",
                        "slug": "Jimmy-Ba",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Ba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy Ba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 27
                            }
                        ],
                        "text": "Specifically, we use Adam (Kingma and Ba, 2014) with an initial learning rate of 10\u22125 and fine-tune for a maximum of 10 epochs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6628106,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6cb366736791bcccc5c8639de5a8f9636bf87e8",
            "isKey": false,
            "numCitedBy": 90091,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm."
            },
            "slug": "Adam:-A-Method-for-Stochastic-Optimization-Kingma-Ba",
            "title": {
                "fragments": [],
                "text": "Adam: A Method for Stochastic Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This work introduces Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments, and provides a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2135004"
                        ],
                        "name": "K. Schuler",
                        "slug": "K.-Schuler",
                        "structuredName": {
                            "firstName": "Karin",
                            "lastName": "Schuler",
                            "middleNames": [
                                "Kipper"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Schuler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145755155"
                        ],
                        "name": "Martha Palmer",
                        "slug": "Martha-Palmer",
                        "structuredName": {
                            "firstName": "Martha",
                            "lastName": "Palmer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martha Palmer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 58
                            }
                        ],
                        "text": "Sentences are drawn from WordNet (Miller, 1995), VerbNet (Schuler, 2005), and Wiktionary."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 60771008,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "bb6898d6041e97c4946661b3a3df0f82286a43b5",
            "isKey": false,
            "numCitedBy": 996,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Despite the proliferation of approaches to lexicon development, the field of natural language processing has yet to develop a clear consensus on guidelines for computational verb lexicons, which has severely limited their utility in information processing applications. James Pustejovsky's Generative Lexicon has concentrated on nouns rather than verbs. WordNet does not provide a comprehensive account of possible syntactic frames and predicate argument structures associated with individual verb senses and ComLex provides syntactic frames but ignores sense distinctions. Dorr's LCS lexicon attempts to address these limitations, but does not provide broad coverage of syntactic frames or different senses or links to actual instances in corpora. \nIn order to address this gap, we created VerbNet, a verb lexicon compatible with Word-Net but with explicitly stated syntactic and semantic information, using Levin verb classes to systematically construct lexical entries. Classes are hierarchically organized to ensure that all their members have common semantic and syntactic properties. Each class in the hierarchy is characterized extensionally by its set of verbs, and intensionally by syntactic frames and semantic predicates and a list of typical verb arguments. \nOne of VerbNet's primary applications has been as a basis for Parameterized Action Representations (PARs), which are used to animate the actions of virtual human agents in a simulated 3D environment. In order to support the animation of the actions, PARs have to make explicit many details that are often underspecified in the language. This detailed level of representation also provides a suitable pivot representation for generation in other natural languages, i.e., a form of interlingua. \nTo evaluate VerbNet's syntactic coverage it has been mapped to the Proposition Bank. VerbNet syntactic frames account for over 84% exact matches to the frames found in PropBank. \nVerbNet provides mappings between its verbs and WordNet senses and between its verbs and FameNet II frames, and mappings between the syntactic frames and Xtag tree families. All these resources are complementary and can be used as extensions of each other. \nThe original set of classes described by Levin has been refined and extended in many ways through systematic efforts: the coverage experiment against PropBank corpus instances proposed a large set of new syntactic frames and a better treatment of prepositions; new classes from Korhonen and Briscoe's resource were integrated into the lexicon; and new members from the LCS database were added. \nTaking advantage of VerbNet's class-based approach automatic acquisition methods were investigated. Additional verbs derived from Kingsbury's clustering experiments and from Loper's VerbNet-WordNet correlation experiment were integrated into the lexicon. These experiments show that it is possible to semi-automatically supplement and tune VerbNet with novel information from corpus data. These approaches reduce the manual classification and enable easy adaptation of the lexicon to specific tasks and applications."
            },
            "slug": "Verbnet:-a-broad-coverage,-comprehensive-verb-Schuler-Palmer",
            "title": {
                "fragments": [],
                "text": "Verbnet: a broad-coverage, comprehensive verb lexicon"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "VerbNet is created, a verb lexicon compatible with Word-Net but with explicitly stated syntactic and semantic information, using Levin verb classes to systematically construct lexical entries, to address the gap in coverage of syntactic frames and predicate argument structures associated with individual verb senses."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1821892"
                        ],
                        "name": "Hila Gonen",
                        "slug": "Hila-Gonen",
                        "structuredName": {
                            "firstName": "Hila",
                            "lastName": "Gonen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hila Gonen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2089067"
                        ],
                        "name": "Yoav Goldberg",
                        "slug": "Yoav-Goldberg",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Goldberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoav Goldberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 73729169,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "94cf3f2c4410fcb06a90abebd99f7113c69e1ed9",
            "isKey": false,
            "numCitedBy": 328,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Word embeddings are widely used in NLP for a vast range of tasks. It was shown that word embeddings derived from text corpora reflect gender biases in society, causing serious concern. Several recent works tackle this problem, and propose methods for significantly reducing this gender bias in word embeddings, demonstrating convincing results. However, we argue that this removal is superficial. While the bias is indeed substantially reduced according to the provided bias definition, the actual effect is mostly hiding the bias, not removing it. The gender bias information is still reflected in the distances between \u201cgender-neutralized\u201d words in the debiased embeddings, and can be recovered from them. We present a series of experiments to support this claim, for two debiasing methods. We conclude that existing bias removal techniques are insufficient, and should not be trusted for providing gender-neutral modeling."
            },
            "slug": "Lipstick-on-a-Pig:-Debiasing-Methods-Cover-up-in-do-Gonen-Goldberg",
            "title": {
                "fragments": [],
                "text": "Lipstick on a Pig: Debiasing Methods Cover up Systematic Gender Biases in Word Embeddings But do not Remove Them"
            },
            "venue": {
                "fragments": [],
                "text": "NAACL-HLT"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144096985"
                        ],
                        "name": "G. Miller",
                        "slug": "G.-Miller",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Miller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Miller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 34
                            }
                        ],
                        "text": "Sentences are drawn from WordNet (Miller, 1995), VerbNet (Schuler, 2005), and Wiktionary."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 26
                            }
                        ],
                        "text": "The authors used WordNet (Miller, 1995) to expand the set of labels to include synonyms and hypernyms from WordNet."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1671874,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "68c03788224000794d5491ab459be0b2a2c38677",
            "isKey": false,
            "numCitedBy": 13889,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Because meaningful sentences are composed of meaningful words, any system that hopes to process natural languages as people do must have information about words and their meanings. This information is traditionally provided through dictionaries, and machine-readable dictionaries are now widely available. But dictionary entries evolved for the convenience of human readers, not for machines. WordNet1 provides a more effective combination of traditional lexicographic information and modern computing. WordNet is an online lexical database designed for use under program control. English nouns, verbs, adjectives, and adverbs are organized into sets of synonyms, each representing a lexicalized concept. Semantic relations link the synonym sets [4]."
            },
            "slug": "WordNet:-A-Lexical-Database-for-English-Miller",
            "title": {
                "fragments": [],
                "text": "WordNet: A Lexical Database for English"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "WordNet1 provides a more effective combination of traditional lexicographic information and modern computing, and is an online lexical database designed for use under program control."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "22243769"
                        ],
                        "name": "Nelson F. Liu",
                        "slug": "Nelson-F.-Liu",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Liu",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nelson F. Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4671928"
                        ],
                        "name": "Roy Schwartz",
                        "slug": "Roy-Schwartz",
                        "structuredName": {
                            "firstName": "Roy",
                            "lastName": "Schwartz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roy Schwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144365875"
                        ],
                        "name": "Noah A. Smith",
                        "slug": "Noah-A.-Smith",
                        "structuredName": {
                            "firstName": "Noah",
                            "lastName": "Smith",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Noah A. Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 102
                            }
                        ],
                        "text": "The outside results for COPA, MultiRC, and RTE are from Sap et al. (2019), Trivedi et al. (2019), and Liu et al. (2019c) respectively."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 48
                            }
                        ],
                        "text": "%) at the time of GLUE\u2019s launch to 85% accuracy (Liu et al., 2019c) at the time of writing."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 138
                            }
                        ],
                        "text": "Recently, Phang et al. (2018) showed that BERT could be improved by extending pretraining with labeled data related to a target task, and Liu et al. (2019c) showed further improvements using a specialized form of multi-task learning with parameter sharing."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 142
                            }
                        ],
                        "text": "\u2026phenomena (Figure 2) measured in GLUE remain difficult, the current state of the art GLUE Score (83.8 with the BERT-based MT-DNN system from Liu et al., 2019c) is only 3.3 points behind our estimate of global human performance (87.1 from Nangia and Bowman, 2019), and in fact exceeds this\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 135
                            }
                        ],
                        "text": "Much recent work has observed this for NLI and QA (Jia and Liang, 2017; Naik et al., 2018; McCoy and Linzen, 2019; McCoy et al., 2019; Liu et al., 2019a,b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 102350590,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9fed0a5813d5c7ea87c48bf3ce7862b0c2fbf0f7",
            "isKey": true,
            "numCitedBy": 72,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Several datasets have recently been constructed to expose brittleness in models trained on existing benchmarks. While model performance on these challenge datasets is significantly lower compared to the original benchmark, it is unclear what particular weaknesses they reveal. For example, a challenge dataset may be difficult because it targets phenomena that current models cannot capture, or because it simply exploits blind spots in a model\u2019s specific training set. We introduce inoculation by fine-tuning, a new analysis method for studying challenge datasets by exposing models (the metaphorical patient) to a small amount of data from the challenge dataset (a metaphorical pathogen) and assessing how well they can adapt. We apply our method to analyze the NLI \u201cstress tests\u201d (Naik et al., 2018) and the Adversarial SQuAD dataset (Jia and Liang, 2017). We show that after slight exposure, some of these datasets are no longer challenging, while others remain difficult. Our results indicate that failures on challenge datasets may lead to very different conclusions about models, training datasets, and the challenge datasets themselves."
            },
            "slug": "Inoculation-by-Fine-Tuning:-A-Method-for-Analyzing-Liu-Schwartz",
            "title": {
                "fragments": [],
                "text": "Inoculation by Fine-Tuning: A Method for Analyzing Challenge Datasets"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work introduces inoculation by fine-tuning, a new analysis method for studying challenge datasets by exposing models to a small amount of data from the challenge dataset (a metaphorical pathogen) and assessing how well they can adapt."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143775536"
                        ],
                        "name": "Bryan McCann",
                        "slug": "Bryan-McCann",
                        "structuredName": {
                            "firstName": "Bryan",
                            "lastName": "McCann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bryan McCann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2844898"
                        ],
                        "name": "N. Keskar",
                        "slug": "N.-Keskar",
                        "structuredName": {
                            "firstName": "Nitish",
                            "lastName": "Keskar",
                            "middleNames": [
                                "Shirish"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Keskar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2228109"
                        ],
                        "name": "Caiming Xiong",
                        "slug": "Caiming-Xiong",
                        "structuredName": {
                            "firstName": "Caiming",
                            "lastName": "Xiong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Caiming Xiong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 142
                            }
                        ],
                        "text": "Other similarly-motivated benchmarks include SentEval (Conneau and Kiela, 2018), which evaluates fixed-size sentence embeddings, and DecaNLP (McCann et al., 2018), which recasts a set of target tasks into a general question-answering format and prohibits task-specific parameters."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 49393754,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "9784fbf77295860b2e412137b86356d70b25e3c0",
            "isKey": false,
            "numCitedBy": 410,
            "numCiting": 138,
            "paperAbstract": {
                "fragments": [],
                "text": "Presented on August 28, 2018 at 12:15 p.m. in the Pettit Microelectronics Research Center, Room 102 A/B."
            },
            "slug": "The-Natural-Language-Decathlon:-Multitask-Learning-McCann-Keskar",
            "title": {
                "fragments": [],
                "text": "The Natural Language Decathlon: Multitask Learning as Question Answering"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Presented on August 28, 2018 at 12:15 p.m. in the Pettit Microelectronics Research Center, Room 102 A/B."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2241127"
                        ],
                        "name": "Marie-Catherine de Marneffe",
                        "slug": "Marie-Catherine-de-Marneffe",
                        "structuredName": {
                            "firstName": "Marie-Catherine",
                            "lastName": "Marneffe",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marie-Catherine de Marneffe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14736364"
                        ],
                        "name": "M. Simons",
                        "slug": "M.-Simons",
                        "structuredName": {
                            "firstName": "Mandy",
                            "lastName": "Simons",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Simons"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741404"
                        ],
                        "name": "Judith Tonhauser",
                        "slug": "Judith-Tonhauser",
                        "structuredName": {
                            "firstName": "Judith",
                            "lastName": "Tonhauser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Judith Tonhauser"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 26
                            }
                        ],
                        "text": "CB The CommitmentBank (De Marneffe et al., 2019) is a corpus of short texts in which at least one sentence contains an embedded clause."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 98
                            }
                        ],
                        "text": "We then collapse the annotations into 3 classes by using the same ranges for bucketing used by De Marneffe et al. (2019)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 203595067,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "39e801ca0dbc69c3697f118e24dac964abb63d4a",
            "isKey": false,
            "numCitedBy": 98,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a new resource, the CommitmentBank, developed for the empirical investigation of the projection of finite clausal complements. A clausal complement is said to project when its content is understood as a commitment of the speaker even though the clause occurs under the scope of an entailment canceling operator such as negation or a question. The study of projection is therefore part of the study of commitments expressed by speakers to non-asserted sentence content. The content of clausal complements has been a central case for the study of projection, as there is a long-standing claim that clause-taking predicates fall into two classes\u2014factives and nonfactives\u2014distinguished on the basis of whether the contents of their complements project. This claim identifies the embedding predicate as the primary determinant of the projection behavior of these contents. The CommitmentBank is a corpus of naturally occurring discourses whose final sentence contains a clause-embedding predicate under an entailment canceling operator. In this paper, we describe the CommitmentBank and present initial results of analyses designed to evaluate the factive/nonfactive distinction and to investigate additional factors which affect the projectivity of clausal complements."
            },
            "slug": "The-CommitmentBank:-Investigating-projection-in-Marneffe-Simons",
            "title": {
                "fragments": [],
                "text": "The CommitmentBank: Investigating projection in naturally occurring discourse"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The CommitmentBank is a corpus of naturally occurring discourses whose final sentence contains a clause-embedding predicate under an entailment canceling operator and initial results of analyses designed to evaluate the factive/nonfactive distinction and to investigate additional factors which affect the projectivity of clausal complements are presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2034613"
                        ],
                        "name": "Rachel Rudinger",
                        "slug": "Rachel-Rudinger",
                        "structuredName": {
                            "firstName": "Rachel",
                            "lastName": "Rudinger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rachel Rudinger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2300343"
                        ],
                        "name": "Jason Naradowsky",
                        "slug": "Jason-Naradowsky",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Naradowsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jason Naradowsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056398837"
                        ],
                        "name": "Brian Leonard",
                        "slug": "Brian-Leonard",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Leonard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brian Leonard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7536576"
                        ],
                        "name": "Benjamin Van Durme",
                        "slug": "Benjamin-Van-Durme",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Durme",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benjamin Van Durme"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "To promote the detection of such biases, we include Winogender (Rudinger et al., 2018) as an additional diagnostic dataset."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13756572,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9967cb4fd949039c6f04dd9f2f4c3331dbebe6f7",
            "isKey": false,
            "numCitedBy": 267,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an empirical study of gender bias in coreference resolution systems. We first introduce a novel, Winograd schema-style set of minimal pair sentences that differ only by pronoun gender. With these \u201cWinogender schemas,\u201d we evaluate and confirm systematic gender bias in three publicly-available coreference resolution systems, and correlate this bias with real-world and textual gender statistics."
            },
            "slug": "Gender-Bias-in-Coreference-Resolution-Rudinger-Naradowsky",
            "title": {
                "fragments": [],
                "text": "Gender Bias in Coreference Resolution"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "A novel, Winograd schema-style set of minimal pair sentences that differ only by pronoun gender are introduced, and systematic gender bias in three publicly-available coreference resolution systems is evaluated and confirmed."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2886725"
                        ],
                        "name": "Svetlana Kiritchenko",
                        "slug": "Svetlana-Kiritchenko",
                        "structuredName": {
                            "firstName": "Svetlana",
                            "lastName": "Kiritchenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Svetlana Kiritchenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143880621"
                        ],
                        "name": "Saif M. Mohammad",
                        "slug": "Saif-M.-Mohammad",
                        "structuredName": {
                            "firstName": "Saif",
                            "lastName": "Mohammad",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Saif M. Mohammad"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 21670658,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5d4af8c9321168f9ba7a501f33fb019fa2deaa22",
            "isKey": false,
            "numCitedBy": 210,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatic machine learning systems can inadvertently accentuate and perpetuate inappropriate human biases. Past work on examining inappropriate biases has largely focused on just individual systems. Further, there is no benchmark dataset for examining inappropriate biases in systems. Here for the first time, we present the Equity Evaluation Corpus (EEC), which consists of 8,640 English sentences carefully chosen to tease out biases towards certain races and genders. We use the dataset to examine 219 automatic sentiment analysis systems that took part in a recent shared task, SemEval-2018 Task 1 \u2018Affect in Tweets\u2019. We find that several of the systems show statistically significant bias; that is, they consistently provide slightly higher sentiment intensity predictions for one race or one gender. We make the EEC freely available."
            },
            "slug": "Examining-Gender-and-Race-Bias-in-Two-Hundred-Kiritchenko-Mohammad",
            "title": {
                "fragments": [],
                "text": "Examining Gender and Race Bias in Two Hundred Sentiment Analysis Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The Equity Evaluation Corpus (EEC) is presented, which consists of 8,640 English sentences carefully chosen to tease out biases towards certain races and genders, and it is found that several of the systems show statistically significant bias."
            },
            "venue": {
                "fragments": [],
                "text": "*SEMEVAL"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3449424"
                        ],
                        "name": "Sven Buechel",
                        "slug": "Sven-Buechel",
                        "structuredName": {
                            "firstName": "Sven",
                            "lastName": "Buechel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sven Buechel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46843152"
                        ],
                        "name": "Anneke Buffone",
                        "slug": "Anneke-Buffone",
                        "structuredName": {
                            "firstName": "Anneke",
                            "lastName": "Buffone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anneke Buffone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50413693"
                        ],
                        "name": "Barry Slaff",
                        "slug": "Barry-Slaff",
                        "structuredName": {
                            "firstName": "Barry",
                            "lastName": "Slaff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Barry Slaff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1412391493"
                        ],
                        "name": "L. Ungar",
                        "slug": "L.-Ungar",
                        "structuredName": {
                            "firstName": "Lyle",
                            "lastName": "Ungar",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Ungar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2662374"
                        ],
                        "name": "Jo\u00e3o Sedoc",
                        "slug": "Jo\u00e3o-Sedoc",
                        "structuredName": {
                            "firstName": "Jo\u00e3o",
                            "lastName": "Sedoc",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jo\u00e3o Sedoc"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 294,
                                "start": 274
                            }
                        ],
                        "text": "\u2026estimates for human performance on several tasks that we did not ultimately include in SuperGLUE, including GAP (Webster et al., 2018), PAWS (Zhang et al., 2019), Quora Insincere Questions,14 Ultrafine Entity Typing (Choi et al., 2018b), and Empathetic Reactions datasets (Buechel et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 48
                            }
                        ],
                        "text": "Similarly, on the Empathetic Reactions dataset (Buechel et al., 2018), BERT outperforms our human baseline, where BERT\u2019s predictions have a Pearson correlation of 0.45 on empathy and 0.55 on distress, compared to 0.45 and 0.35 for our human baseline."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 155
                            }
                        ],
                        "text": "7It was challenging to train annotators to do well on Quora Insincere Questions (https://www.kaggle. com/c/quora-insincere-questions-classification/data), Empathetic Reactions (Buechel et al., 2018), and a recast version of Ultra-Fine Entity Typing (Choi et al., 2018b, see Appendix A for details), leading to low human performance."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 304,
                                "start": 284
                            }
                        ],
                        "text": "We collected data to produce conservative estimates for human performance on several tasks that we did not ultimately include in SuperGLUE, including GAP (Webster et al., 2018), PAWS (Zhang et al., 2019), Quora Insincere Questions,14 Ultrafine Entity Typing (Choi et al., 2018b), and Empathetic Reactions datasets (Buechel et al., 2018)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 149
                            }
                        ],
                        "text": "\u2026annotators to do well on Quora Insincere Questions (https://www.kaggle. com/c/quora-insincere-questions-classification/data), Empathetic Reactions (Buechel et al., 2018), and a recast version of Ultra-Fine Entity Typing (Choi et al., 2018b, see Appendix A for details), leading to low human\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 75
                            }
                        ],
                        "text": "com/c/quora-insincere-questions-classification/data), Empathetic Reactions (Buechel et al., 2018), and a recast version of Ultra-Fine Entity Typing (Choi et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 52136564,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "2331cb6cdf3a7b55ad38a5026f3b7e80092d4b8e",
            "isKey": true,
            "numCitedBy": 46,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Computational detection and understanding of empathy is an important factor in advancing human-computer interaction. Yet to date, text-based empathy prediction has the following major limitations: It underestimates the psychological complexity of the phenomenon, adheres to a weak notion of ground truth where empathic states are ascribed by third parties, and lacks a shared corpus. In contrast, this contribution presents the first publicly available gold standard for empathy prediction. It is constructed using a novel annotation methodology which reliably captures empathy assessments by the writer of a statement using multi-item scales. This is also the first computational work distinguishing between multiple forms of empathy, empathic concern, and personal distress, as recognized throughout psychology. Finally, we present experimental results for three different predictive models, of which a CNN performs the best."
            },
            "slug": "Modeling-Empathy-and-Distress-in-Reaction-to-News-Buechel-Buffone",
            "title": {
                "fragments": [],
                "text": "Modeling Empathy and Distress in Reaction to News Stories"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This contribution presents the first publicly available gold standard for empathy prediction, constructed using a novel annotation methodology which reliably captures empathy assessments by the writer of a statement using multi-item scales."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2034613"
                        ],
                        "name": "Rachel Rudinger",
                        "slug": "Rachel-Rudinger",
                        "structuredName": {
                            "firstName": "Rachel",
                            "lastName": "Rudinger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rachel Rudinger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "98868399"
                        ],
                        "name": "Chandler May",
                        "slug": "Chandler-May",
                        "structuredName": {
                            "firstName": "Chandler",
                            "lastName": "May",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chandler May"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7536576"
                        ],
                        "name": "Benjamin Van Durme",
                        "slug": "Benjamin-Van-Durme",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Durme",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benjamin Van Durme"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5310359,
            "fieldsOfStudy": [
                "Psychology",
                "Computer Science"
            ],
            "id": "a20ecabd83e0962329448d8af5025b8061c4ba36",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We analyze the Stanford Natural Language Inference (SNLI) corpus in an investigation of bias and stereotyping in NLP data. The SNLI human-elicitation protocol makes it prone to amplifying bias and stereotypical associations, which we demonstrate statistically (using pointwise mutual information) and with qualitative examples."
            },
            "slug": "Social-Bias-in-Elicited-Natural-Language-Inferences-Rudinger-May",
            "title": {
                "fragments": [],
                "text": "Social Bias in Elicited Natural Language Inferences"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The SNLI human-elicitation protocol makes it prone to amplifying bias and stereotypical associations, which is demonstrated statistically and with qualitative examples."
            },
            "venue": {
                "fragments": [],
                "text": "EthNLP@EACL"
            },
            "year": 2017
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 132
                            }
                        ],
                        "text": "The past year has seen a surge of progress across many natural language processing (NLP) tasks, led by pretrained models like ELMo (Peters et al., 2018), OpenAI GPT (Radford et al., 2018), and BERT (Devlin et al., 2019)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 110
                            }
                        ],
                        "text": "On GLUE, GPT and BERT achieved scores of 72.8 and 80.2 respectively, relative to 66.5 for an ELMobased model (Peters et al., 2018) and 63.7 for the strongest baseline with no multitask learning or pretraining above the word level."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 288,
                                "start": 284
                            }
                        ],
                        "text": "These results demonstrate the value of sharing knowledge through self-supervised objectives that maximize the available training signal, modeling word occurrence conditioned on ever-richer context: from nearby unigrams (traditional distributional methods) to one-directional context (ELMo, GPT) and finally to bidirectional context (BERT)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 294,
                                "start": 275
                            }
                        ],
                        "text": "\u2026neural models with large amounts of available supervision can produce representations that effectively transfer to a broad range of NLP tasks (Collobert and Weston, 2008; Dai and Le, 2015; Kiros et al., 2015; Hill et al., 2016; Conneau and Kiela, 2018; McCann et al., 2017; Peters et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 345,
                                "start": 193
                            }
                        ],
                        "text": "Much work prior to GLUE demonstrated that training neural models with large amounts of available supervision can produce representations that effectively transfer to a broad range of NLP tasks (Collobert and Weston, 2008; Dai and Le, 2015; Kiros et al., 2015; Hill et al., 2016; Conneau and Kiela, 2018; McCann et al., 2017; Peters et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 69
                            }
                        ],
                        "text": "Besides their striking gains in performance on many such tasks, both ELMo and BERT have been recognized with best paper awards at major conferences and widespread deployment in industry."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 131
                            }
                        ],
                        "text": "In the past year, there has been notable progress across many natural language processing (NLP) tasks, led by methods such as ELMo (Peters et al., 2018), OpenAI GPT (Radford et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Deep contextualized word representations. In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)"
            },
            "venue": {
                "fragments": [],
                "text": "Association for Computational Linguistics,"
            },
            "year": 2018
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 94
                            }
                        ],
                        "text": "The tags from this validation had high agreement, and were included in the publicly available Ultrafine Entity Typing dataset,15 This constitutes our set of positive examples."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 236,
                                "start": 218
                            }
                        ],
                        "text": "\u2026estimates for human performance on several tasks that we did not ultimately include in SuperGLUE, including GAP (Webster et al., 2018), PAWS (Zhang et al., 2019), Quora Insincere Questions,14 Ultrafine Entity Typing (Choi et al., 2018b), and Empathetic Reactions datasets (Buechel et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 61
                            }
                        ],
                        "text": "Similarly, on recast version of the Ultrafine Entity Typing (Choi et al., 2018b), we observe too small a gap between human (60.2 F1) and machine performance (55.0 F1)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 0
                            }
                        ],
                        "text": "Ultrafine Entity Typing We cast the task into a binary classification problem to make it an easier task for non-expert crowd workers."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 248,
                                "start": 224
                            }
                        ],
                        "text": "7It was challenging to train annotators to do well on Quora Insincere Questions (https://www.kaggle. com/c/quora-insincere-questions-classification/data), Empathetic Reactions (Buechel et al., 2018), and a recast version of Ultra-Fine Entity Typing (Choi et al., 2018b, see Appendix A for details), leading to low human performance."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 257,
                                "start": 205
                            }
                        ],
                        "text": "We collected data to produce conservative estimates for human performance on several tasks that we did not ultimately include in SuperGLUE, including GAP (Webster et al., 2018), PAWS (Zhang et al., 2019), Quora Insincere Questions,14 Ultrafine Entity Typing (Choi et al., 2018b), and Empathetic Reactions datasets (Buechel et al., 2018)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 211
                            }
                        ],
                        "text": "\u2026to do well on Quora Insincere Questions (https://www.kaggle. com/c/quora-insincere-questions-classification/data), Empathetic Reactions (Buechel et al., 2018), and a recast version of Ultra-Fine Entity Typing (Choi et al., 2018b, see Appendix A for details), leading to low human performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 18
                            }
                        ],
                        "text": "6Tasks like QuAC (Choi et al., 2018a) and STREUSLE (Schneider and Smith, 2015) differed substantially from the format of other tasks in SuperGLUE, which we worried would incentivize users to spend significant effort on task-specific model designs, rather than focusing on general-purpose techniques."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 56
                            }
                        ],
                        "text": "We work in cooperation with the authors of the dataset (Choi et al., 2018b) to do this reformulation: We give workers one possible tag for a word or phrase and asked them to classify the tag as being applicable or not."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Ultra-fine entity typing. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 87\u201396, Melbourne, Australia, July 2018b"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2018
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 0
                            }
                        ],
                        "text": "Nangia and Bowman (2019) establish human performance for RTE."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 149
                            }
                        ],
                        "text": "\u2026Score (83.8 with the BERT-based MT-DNN system from Liu et al., 2019c) is only 3.3 points behind our estimate of global human performance (87.1 from Nangia and Bowman, 2019), and in fact exceeds this human performance estimate on three tasks.2\nIn response to this significant (and surprising)\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 162
                            }
                        ],
                        "text": "We follow a two step procedure where a crowd worker completes a short training phase before proceeding to the annotations phase, modeled after the method used by Nangia and Bowman (2019) for GLUE."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A conservative human baseline estimate for GLUE: People still (mostly) beat machines. Unpublished manuscript available at gluebenchmark.com, 2019"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2380885"
                        ],
                        "name": "Danilo Giampiccolo",
                        "slug": "Danilo-Giampiccolo",
                        "structuredName": {
                            "firstName": "Danilo",
                            "lastName": "Giampiccolo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Danilo Giampiccolo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712352"
                        ],
                        "name": "B. Magnini",
                        "slug": "B.-Magnini",
                        "structuredName": {
                            "firstName": "Bernardo",
                            "lastName": "Magnini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Magnini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7465342"
                        ],
                        "name": "Ido Dagan",
                        "slug": "Ido-Dagan",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Dagan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "83415753"
                        ],
                        "name": "W. Dolan",
                        "slug": "W.-Dolan",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Dolan",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Dolan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 160
                            }
                        ],
                        "text": "RTE was previously included in GLUE, and we use the same data and format as before: We merge data from RTE1 (Dagan et al., 2006), RTE2 (Bar Haim et al., 2006), RTE3 (Giampiccolo et al., 2007), and RTE5 (Bentivogli et al., 2009).9 All datasets are combined and converted to two-class classification: entailment and not_entailment."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 14
                            }
                        ],
                        "text": ", 2006), RTE3 (Giampiccolo et al., 2007), and RTE5 (Bentivogli et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 148
                            }
                        ],
                        "text": "\u2026included in GLUE, and we use the same data and format as before: We merge data from RTE1 (Dagan et al., 2006), RTE2 (Bar Haim et al., 2006), RTE3 (Giampiccolo et al., 2007), and RTE5 (Bentivogli et al., 2009).9 All datasets are combined and converted to two-class classification: entailment and\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 195352006,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "b2815bc4c9e4260227cd7ca0c9d68d41c4c2f58b",
            "isKey": false,
            "numCitedBy": 474,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Third-PASCAL-Recognizing-Textual-Entailment-Giampiccolo-Magnini",
            "title": {
                "fragments": [],
                "text": "The Third PASCAL Recognizing Textual Entailment Challenge"
            },
            "venue": {
                "fragments": [],
                "text": "ACL-PASCAL@ACL"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3177568"
                        ],
                        "name": "J. Q. Candela",
                        "slug": "J.-Q.-Candela",
                        "structuredName": {
                            "firstName": "Joaquin",
                            "lastName": "Candela",
                            "middleNames": [
                                "Qui\u00f1onero"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Q. Candela"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69440470"
                        ],
                        "name": "Magnini B Dagan I",
                        "slug": "Magnini-B-Dagan-I",
                        "structuredName": {
                            "firstName": "Magnini",
                            "lastName": "Dagan I",
                            "middleNames": [
                                "B"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Magnini B Dagan I"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11393449"
                        ],
                        "name": "F. Lauria",
                        "slug": "F.-Lauria",
                        "structuredName": {
                            "firstName": "Francesco",
                            "lastName": "Lauria",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Lauria"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 103
                            }
                        ],
                        "text": "RTE was previously included in GLUE, and we use the same data and format as before: We merge data from RTE1 (Dagan et al., 2006), RTE2 (Bar Haim et al., 2006), RTE3 (Giampiccolo et al., 2007), and RTE5 (Bentivogli et al., 2009).9 All datasets are combined and converted to two-class classification: entailment and not_entailment."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 108
                            }
                        ],
                        "text": "RTE was previously included in GLUE, and we use the same data and format as before: We merge data from RTE1 (Dagan et al., 2006), RTE2 (Bar Haim et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 109
                            }
                        ],
                        "text": "RTE was previously included in GLUE, and we use the same data and format as before: We merge data from RTE1 (Dagan et al., 2006), RTE2 (Bar Haim et al., 2006), RTE3 (Giampiccolo et al., 2007), and RTE5 (Bentivogli et al., 2009).9 All datasets are combined and converted to two-class classification:\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8564414,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e03d300581e16f6664157d2c1c6ceec33ec528ce",
            "isKey": false,
            "numCitedBy": 209,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Machine-Learning-Challenges.-Evaluating-Predictive-Candela-MagniniBDagan",
            "title": {
                "fragments": [],
                "text": "Machine Learning Challenges. Evaluating Predictive Uncertainty, Visual Object Classification, and Recognising Tectual Entailment"
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neural network acceptability judgments. Transactions of the Association of Computational Linguists"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2019
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "SWAG: A large-scale adversarial"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2017
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Born-again multi-task networks for natural language understanding"
            },
            "venue": {
                "fragments": [],
                "text": "Anonymous preprint under review,"
            },
            "year": 2018
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "2019a, see paper for a description of the categories)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2019
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 349,
                                "start": 197
                            }
                        ],
                        "text": "Much work prior to GLUE has demonstrated that training neural models with large amounts of available supervision can produce representations that effectively transfer to a broad range of NLP tasks (Collobert and Weston, 2008; Dai and Le, 2015; Kiros et al., 2015; Hill et al., 2016; Conneau and Kiela, 2018; McCann et al., 2017; Peters et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 190
                            }
                        ],
                        "text": "\u2026neural models with large amounts of available supervision can produce representations that effectively transfer to a broad range of NLP tasks (Collobert and Weston, 2008; Dai and Le, 2015; Kiros et al., 2015; Hill et al., 2016; Conneau and Kiela, 2018; McCann et al., 2017; Peters et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Skip-thought vectors. In Advances in neural information processing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2015
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 142
                            }
                        ],
                        "text": "In this context, the GLUE benchmark (organized by some of the same authors as this work, short for General Language Understanding Evaluation; Wang et al., 2019) has become a prominent evaluation framework and leaderboard for research towards general-purpose language understanding technologies."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "jiant 1.0: A software toolkit for research on general-purpose text understanding models. http://jiant.info/, 2019b"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2019
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 56
                            }
                        ],
                        "text": "The outside results for COPA, MultiRC, and RTE are from Sap et al. (2019), Trivedi et al. (2019), and Liu et al. (2019c) respectively."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Socialiqa: Commonsense reasoning about social interactions, 2019"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2019
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 48,
            "methodology": 44,
            "result": 4
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 87,
        "totalPages": 9
    },
    "page_url": "https://www.semanticscholar.org/paper/SuperGLUE:-A-Stickier-Benchmark-for-General-Purpose-Wang-Pruksachatkun/d9f6ada77448664b71128bb19df15765336974a6?sort=total-citations"
}