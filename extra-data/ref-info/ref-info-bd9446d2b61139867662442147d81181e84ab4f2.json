{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48950628"
                        ],
                        "name": "N. Dalal",
                        "slug": "N.-Dalal",
                        "structuredName": {
                            "firstName": "Navneet",
                            "lastName": "Dalal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Dalal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 27
                            }
                        ],
                        "text": "We follow the procedure in [8] to extract the HOG feature."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 112
                            }
                        ],
                        "text": "The LBPs extracted from cells are concatenate into a cellstructured LBP, similar to the cell-block structure in [8]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 529,
                                "start": 502
                            }
                        ],
                        "text": "The contribution of this paper is three-fold: 1) Through occlusion inference on sliding window classification results, we propose an approach to integrate the advantage of part-based detectors in occlusion handling to the slidingwindow detectors; 2) An augmented feature, HOG-LBP, which combines HOG with cell-structured Local Binary Pattern (LBP) [3], is proposed as the feature, based on which the HOG-LBP human detector achieves better performance than all of known state-of-the-art human detectors [8, 28, 18, 34, 25, 27, 20] on INRIA dataset (refer to section 3."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 86
                            }
                        ],
                        "text": "Through the study of the classification scores of the linear SVM on the INRIA dataset [8, 9], we found an interesting phenomenon: If a portion of the pedestrian is occluded, the densely extracted blocks of Histograms of Oriented Gradients (HOG) feature [8] in that area uniformly respond to the linear SVM classifier with negative inner products."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 135
                            }
                        ],
                        "text": "Evaluated using both criteria, our HOG-LBP detector (with/without occlusion handling) out perform all known state-of-the-art detectors [8, 13, 28, 10, 31, 25, 34, 18] on the INRIA dataset."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 100
                            }
                        ],
                        "text": "Trilinear interpolation and Gaussian weighting are two important sub-procedures in HOG construction [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 60
                            }
                        ],
                        "text": "As a dense version of the dominating SIFT [17] feature, HOG [8] has shown great success in object detection and recognition [8, 9, 13, 25, 34]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 83
                            }
                        ],
                        "text": "The results of The Pascal Challenge from 2005 to 2008 [12] and the recent research [8, 13, 15, 28, 18, 21] indicate that sliding window classifiers are presently the predominant method being used in object detection, or more specifically, human detection, due to their good performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206590483,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cec734d7097ab6b1e60d95228ffd64248eb89d66",
            "isKey": true,
            "numCitedBy": 29262,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the question of feature sets for robust visual object recognition; adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds."
            },
            "slug": "Histograms-of-oriented-gradients-for-human-Dalal-Triggs",
            "title": {
                "fragments": [],
                "text": "Histograms of oriented gradients for human detection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection, and the influence of each stage of the computation on performance is studied."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 21
                            }
                        ],
                        "text": "part based detectors [16, 19, 32] can alleviate the occlusion problem to some extent by relying on the unoccluded part to determine the human position."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 108
                            }
                        ],
                        "text": "Although preferred for its performance in general, compared to other detectors such as part-based detectors [1, 14, 16, 19, 32], the sliding window approach handles partial occlusions poorly."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3870070,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9cc6155cd69023a736a7b8f8680bcd6232c840e",
            "isKey": false,
            "numCitedBy": 764,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a novel method for human detection in single images which can detect full bodies as well as close-up views in the presence of clutter and occlusion. Humans are modeled as flexible assemblies of parts, and robust part detection is the key to the approach. The parts are represented by co-occurrences of local features which captures the spatial layout of the partrsquos appearance. Feature selection and the part detectors are learnt from training images using AdaBoost. The detection algorithm is very efficient as (i) all part detectors use the same initial features, (ii) a coarse-to-fine cascade approach is used for part detection, (iii) a part assembly strategy reduces the number of spurious detections and the search space. The results outperform existing human detectors."
            },
            "slug": "Human-Detection-Based-on-a-Probabilistic-Assembly-Mikolajczyk-Schmid",
            "title": {
                "fragments": [],
                "text": "Human Detection Based on a Probabilistic Assembly of Robust Part Detectors"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A novel method for human detection in single images which can detect full bodies as well as close-up views in the presence of clutter and occlusion is described."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111328101"
                        ],
                        "name": "Michael Jones",
                        "slug": "Michael-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 53
                            }
                        ],
                        "text": "Within the framework of the integral image/histogram [29, 24, 34], the extraction of the features for scanning windows has a constant complexityO(c) (two vector addition and two vector subtraction)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 29
                            }
                        ],
                        "text": "The integral image/histogram [29, 24, 34], the efficient subwindow search [15], and the increasingly powerful parallel computing hardware (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 235084,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4cb4d685b47001652b29dc41c1b3e786277e7647",
            "isKey": false,
            "numCitedBy": 4016,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a visual object detection framework that is capable of processing images extremely rapidly while achieving high detection rates. There are three key contributions. The first is the introduction of a new image representation called the \u201cIntegral Image\u201d which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features and yields extremely efficient classifiers [4]. The third contribution is a method for combining classifiers in a \u201ccascade\u201d which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. A set of experiments in the domain of face detection are presented. The system yields face detection performance comparable to the best previous systems [16, 11, 14, 10, 1]. Implemented on a conventional desktop, face detection proceeds at 15 frames per second. Author email: fPaul.Viola,Mike.J.Jonesg@compaq.com c Compaq Computer Corporation, 2001 This work may not be copied or reproduced in whole or in part for any commercial purpose. Permission to copy in whole or in part without payment of fee is granted for nonprofit educational and research purposes provided that all such whole or partial copies include the following: a notice that such copying is by permission of the Cambridge Research Laboratory of Compaq Computer Corporation in Cambridge, Massachusetts; an acknowledgment of the authors and individual contributors to the work; and all applicable portions of the copyright notice. Copying, reproducing, or republishing for any other purpose shall require a license with payment of fee to the Cambridge Research Laboratory. All rights reserved. CRL Technical reports are available on the CRL\u2019s web page at http://crl.research.compaq.com. Compaq Computer Corporation Cambridge Research Laboratory One Cambridge Center Cambridge, Massachusetts 02142 USA"
            },
            "slug": "Robust-Real-time-Object-Detection-Viola-Jones",
            "title": {
                "fragments": [],
                "text": "Robust Real-time Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "A visual object detection framework that is capable of processing images extremely rapidly while achieving high detection rates is described, with the introduction of a new image representation called the \u201cIntegral Image\u201d which allows the features used by the detector to be computed very quickly."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48950628"
                        ],
                        "name": "N. Dalal",
                        "slug": "N.-Dalal",
                        "structuredName": {
                            "firstName": "Navneet",
                            "lastName": "Dalal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Dalal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8729004,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "44f3ac3277c2eb6e5599739eb875888c46e21d4c",
            "isKey": false,
            "numCitedBy": 1776,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Detecting humans in films and videos is a challenging problem owing to the motion of the subjects, the camera and the background and to variations in pose, appearance, clothing, illumination and background clutter. We develop a detector for standing and moving people in videos with possibly moving cameras and backgrounds, testing several different motion coding schemes and showing empirically that orientated histograms of differential optical flow give the best overall performance. These motion-based descriptors are combined with our Histogram of Oriented Gradient appearance descriptors. The resulting detector is tested on several databases including a challenging test set taken from feature films and containing wide ranges of pose, motion and background variations, including moving cameras and backgrounds. We validate our results on two challenging test sets containing more than 4400 human examples. The combined detector reduces the false alarm rate by a factor of 10 relative to the best appearance-based detector, for example giving false alarm rates of 1 per 20,000 windows tested at 8% miss rate on our Test Set 1."
            },
            "slug": "Human-Detection-Using-Oriented-Histograms-of-Flow-Dalal-Triggs",
            "title": {
                "fragments": [],
                "text": "Human Detection Using Oriented Histograms of Flow and Appearance"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A detector for standing and moving people in videos with possibly moving cameras and backgrounds is developed, testing several different motion coding schemes and showing empirically that orientated histograms of differential optical flow give the best overall performance."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143847264"
                        ],
                        "name": "Bo Wu",
                        "slug": "Bo-Wu",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144862593"
                        ],
                        "name": "R. Nevatia",
                        "slug": "R.-Nevatia",
                        "structuredName": {
                            "firstName": "Ramakant",
                            "lastName": "Nevatia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nevatia"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206769463,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de1ac0baea1f907388ff5fe9fa22f25f406e2ca6",
            "isKey": false,
            "numCitedBy": 881,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a method for human detection in crowded scene from static images. An individual human is modeled as an assembly of natural body parts. We introduce edgelet features, which are a new type of silhouette oriented features. Part detectors, based on these features, are learned by a boosting method. Responses of part detectors are combined to form a joint likelihood model that includes cases of multiple, possibly inter-occluded humans. The human detection problem is formulated as maximum a posteriori (MAP) estimation. We show results on a commonly used previous dataset as well as new data sets that could not be processed by earlier methods."
            },
            "slug": "Detection-of-multiple,-partially-occluded-humans-in-Wu-Nevatia",
            "title": {
                "fragments": [],
                "text": "Detection of multiple, partially occluded humans in a single image by Bayesian combination of edgelet part detectors"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The human detection problem is formulated as maximum a posteriori (MAP) estimation, and edgelet features are introduced, which are a new type of silhouette oriented features that are learned by a boosting method."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144238410"
                        ],
                        "name": "Qiang Zhu",
                        "slug": "Qiang-Zhu",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39369497"
                        ],
                        "name": "Mei-Chen Yeh",
                        "slug": "Mei-Chen-Yeh",
                        "structuredName": {
                            "firstName": "Mei-Chen",
                            "lastName": "Yeh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mei-Chen Yeh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143766349"
                        ],
                        "name": "K. Cheng",
                        "slug": "K.-Cheng",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Cheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Cheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1815078"
                        ],
                        "name": "S. Avidan",
                        "slug": "S.-Avidan",
                        "structuredName": {
                            "firstName": "Shai",
                            "lastName": "Avidan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Avidan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 137
                            }
                        ],
                        "text": "While the integrated HOG feature without trilinear interpolation is fast to compute, it is inferior to the original HOG, as mentioned in [34]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 29
                            }
                        ],
                        "text": "The integral image/histogram [29, 24, 34], the efficient subwindow search [15], and the increasingly powerful parallel computing hardware (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 529,
                                "start": 502
                            }
                        ],
                        "text": "The contribution of this paper is three-fold: 1) Through occlusion inference on sliding window classification results, we propose an approach to integrate the advantage of part-based detectors in occlusion handling to the slidingwindow detectors; 2) An augmented feature, HOG-LBP, which combines HOG with cell-structured Local Binary Pattern (LBP) [3], is proposed as the feature, based on which the HOG-LBP human detector achieves better performance than all of known state-of-the-art human detectors [8, 28, 18, 34, 25, 27, 20] on INRIA dataset (refer to section 3."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 31
                            }
                        ],
                        "text": "Many state-ofthe-art detectors [28, 15, 34, 30, 25] based on sliding window classifiers use the integral image method to increase the running speeds by several folds."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 135
                            }
                        ],
                        "text": "Evaluated using both criteria, our HOG-LBP detector (with/without occlusion handling) out perform all known state-of-the-art detectors [8, 13, 28, 10, 31, 25, 34, 18] on the INRIA dataset."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 53
                            }
                        ],
                        "text": "Within the framework of the integral image/histogram [29, 24, 34], the extraction of the features for scanning windows has a constant complexityO(c) (two vector addition and two vector subtraction)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 94
                            }
                        ],
                        "text": "It was believed that the trilinear interpolation didn\u2019t fit well into integral image approach [34]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 124
                            }
                        ],
                        "text": "As a dense version of the dominating SIFT [17] feature, HOG [8] has shown great success in object detection and recognition [8, 9, 13, 25, 34]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7800101,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "05fe01b57b3ba58dc5029c068a48567b55018ea5",
            "isKey": true,
            "numCitedBy": 1568,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We integrate the cascade-of-rejectors approach with the Histograms of Oriented Gradients (HoG) features to achieve a fast and accurate human detection system. The features used in our system are HoGs of variable-size blocks that capture salient features of humans automatically. Using AdaBoost for feature selection, we identify the appropriate set of blocks, from a large set of possible blocks. In our system, we use the integral image representation and a rejection cascade which significantly speed up the computation. For a 320 \u00d7 280 image, the system can process 5 to 30 frames per second depending on the density in which we scan the image, while maintaining an accuracy level similar to existing methods."
            },
            "slug": "Fast-Human-Detection-Using-a-Cascade-of-Histograms-Zhu-Yeh",
            "title": {
                "fragments": [],
                "text": "Fast Human Detection Using a Cascade of Histograms of Oriented Gradients"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This work integrates the cascade-of-rejectors approach with the Histograms of Oriented Gradients features to achieve a fast and accurate human detection system that can process 5 to 30 frames per second depending on the density in which the image is scanned, while maintaining an accuracy level similar to existing methods."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111328101"
                        ],
                        "name": "Michael Jones",
                        "slug": "Michael-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Within the framework of the integral image/histogram [ 29 , 24, 34], the extraction of the features for scanning windows has a constant complexity O(c) (two vector addition and two vector subtraction)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The integral image/histogram [ 29 , 24, 34], the efficient subwindow search [15], and the increasingly powerful parallel computing hardware (e.g."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2796017,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b09ec0b350f8352bce46a2f5bf7ae97c83a7b9ca",
            "isKey": false,
            "numCitedBy": 11227,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a face detection framework that is capable of processing images extremely rapidly while achieving high detection rates. There are three key contributions. The first is the introduction of a new image representation called the \u201cIntegral Image\u201d which allows the features used by our detector to be computed very quickly. The second is a simple and efficient classifier which is built using the AdaBoost learning algorithm (Freund and Schapire, 1995) to select a small number of critical visual features from a very large set of potential features. The third contribution is a method for combining classifiers in a \u201ccascade\u201d which allows background regions of the image to be quickly discarded while spending more computation on promising face-like regions. A set of experiments in the domain of face detection is presented. The system yields face detection performance comparable to the best previous systems (Sung and Poggio, 1998; Rowley et al., 1998; Schneiderman and Kanade, 2000; Roth et al., 2000). Implemented on a conventional desktop, face detection proceeds at 15 frames per second."
            },
            "slug": "Robust-Real-Time-Face-Detection-Viola-Jones",
            "title": {
                "fragments": [],
                "text": "Robust Real-Time Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new image representation called the \u201cIntegral Image\u201d is introduced which allows the features used by the detector to be computed very quickly and a method for combining classifiers in a \u201ccascade\u201d which allows background regions of the image to be quickly discarded while spending more computation on promising face-like regions."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145353089"
                        ],
                        "name": "Yadong Mu",
                        "slug": "Yadong-Mu",
                        "structuredName": {
                            "firstName": "Yadong",
                            "lastName": "Mu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yadong Mu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143653681"
                        ],
                        "name": "Shuicheng Yan",
                        "slug": "Shuicheng-Yan",
                        "structuredName": {
                            "firstName": "Shuicheng",
                            "lastName": "Yan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shuicheng Yan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153628944"
                        ],
                        "name": "Yi Liu",
                        "slug": "Yi-Liu",
                        "structuredName": {
                            "firstName": "Yi",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yi Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2857372"
                        ],
                        "name": "Bingfeng Zhou",
                        "slug": "Bingfeng-Zhou",
                        "structuredName": {
                            "firstName": "Bingfeng",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bingfeng Zhou"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 128
                            }
                        ],
                        "text": "As shown in Figure 6(a) in the experiments section, the detection results based on our cell-structured LBP are much better than [20]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "We also compared our cell-structured LBP with S-LBP in [20]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 28
                            }
                        ],
                        "text": "The performance of F-LBP in [20] is not available in the normal INRIA training-testing setup."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 529,
                                "start": 502
                            }
                        ],
                        "text": "The contribution of this paper is three-fold: 1) Through occlusion inference on sliding window classification results, we propose an approach to integrate the advantage of part-based detectors in occlusion handling to the slidingwindow detectors; 2) An augmented feature, HOG-LBP, which combines HOG with cell-structured Local Binary Pattern (LBP) [3], is proposed as the feature, based on which the HOG-LBP human detector achieves better performance than all of known state-of-the-art human detectors [8, 28, 18, 34, 25, 27, 20] on INRIA dataset (refer to section 3."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[20] state that traditional LBP operator in [2] does not suit the human detection problem well."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 75
                            }
                        ],
                        "text": "The LBP with proper parameter setting outperforms vector S-LBP proposed in [20]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 206591103,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cf5feccca7eeed4929a5cd75078cc5fa4936e196",
            "isKey": false,
            "numCitedBy": 316,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "In recent years, local pattern based object detection and recognition have attracted increasing interest in computer vision research community. However, to our best knowledge no previous work has focused on utilizing local patterns for the task of human detection. In this paper we develop a novel human detection system in personal albums based on LBP (local binary pattern) descriptor. Firstly we review the existing gradient based local features widely used in human detection, analyze their limitations and argue that LBP is more discriminative. Secondly, original LBP descriptor does not suit the human detecting problem well due to its high complexity and lack of semantic consistency, thus we propose two variants of LBP: Semantic-LBP and Fourier-LBP. Carefully designed experiments demonstrate the superiority of LBP over other traditional features for human detection. Especially we adopt a random ensemble algorithm for better comparison between different descriptors. All experiments are conducted on INRIA human database."
            },
            "slug": "Discriminative-local-binary-patterns-for-human-in-Mu-Yan",
            "title": {
                "fragments": [],
                "text": "Discriminative local binary patterns for human detection in personal album"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A novel human detection system in personal albums based on LBP (local binary pattern) descriptor is developed and carefully designed experiments demonstrate the superiority of LBP over other traditional features for human detection."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48950628"
                        ],
                        "name": "N. Dalal",
                        "slug": "N.-Dalal",
                        "structuredName": {
                            "firstName": "Navneet",
                            "lastName": "Dalal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Dalal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 197
                            }
                        ],
                        "text": "In order to take the advantage of the integral image without impairing the performance, we propose an approach, named as Convoluted Trilinear Interpolation (CTI), to do the trilinear interpolation [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 37581938,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "47980c6e42f1a3381e6c5f3db7230e6a64c40218",
            "isKey": false,
            "numCitedBy": 369,
            "numCiting": 218,
            "paperAbstract": {
                "fragments": [],
                "text": "This thesis targets the detection of humans and other object classes in images and videos. Our focus is on developing robust feature extraction algorithms that encode image regions as highdimensional feature vectors that support high accuracy object/non-object decisions. To test our feature sets we adopt a relatively simple learning framework that uses linear Support Vector Machines to classify each possible image region as an object or as a non-object. The approach is data-driven and purely bottom-up using low-level appearance and motion vectors to detect objects. As a test case we focus on person detection as people are one of the most challenging object classes with many applications, for example in film and video analysis, pedestrian detection for smart cars and video surveillance. Nevertheless we do not make any strong class specific assumptions and the resulting object detection framework also gives state-of-the-art performance for many other classes including cars, motorbikes, cows and sheep. This thesis makes four main contributions. Firstly, we introduce grids of locally normalised Histograms of Oriented Gradients (HOG) as descriptors for object detection in static images. The HOG descriptors are computed over dense and overlapping grids of spatial blocks, with image gradient orientation features extracted at fixed resolution and gathered into a highdimensional feature vector. They are designed to be robust to small changes in image contour locations and directions, and significant changes in image illumination and colour, while remaining highly discriminative for overall visual form. We show that unsmoothed gradients, fine orientation voting, moderately coarse spatial binning, strong normalisation and overlapping blocks are all needed for good performance. Secondly, to detect moving humans in videos, we propose descriptors based on oriented histograms of differential optical flow. These are similar to static HOG descriptors, but instead of image gradients, they are based on local differentials of dense optical flow. They encode the noisy optical flow estimates into robust feature vectors in a manner that is robust to the overall camera motion. Several variants are proposed, some capturing motion boundaries while others encode the relative motions of adjacent image regions. Thirdly, we propose a general method based on kernel density estimation for fusing multiple overlapping detections, that takes into account the number of detections, their confidence scores and the scales of the detections. Lastly, we present work in progress on a parts based approach to person detection that first detects local body parts like heads, torso, and legs and then fuses them to create a global overall person detector."
            },
            "slug": "Finding-People-in-Images-and-Videos-Dalal",
            "title": {
                "fragments": [],
                "text": "Finding People in Images and Videos"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This thesis introduces grids of locally normalised Histograms of Oriented Gradients (HOG) as descriptors for object detection in static images and proposes descriptors based on oriented histograms of differential optical flow to detect moving humans in videos."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1787591"
                        ],
                        "name": "Christoph H. Lampert",
                        "slug": "Christoph-H.-Lampert",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Lampert",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christoph H. Lampert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758219"
                        ],
                        "name": "Matthew B. Blaschko",
                        "slug": "Matthew-B.-Blaschko",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Blaschko",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew B. Blaschko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143936663"
                        ],
                        "name": "Thomas Hofmann",
                        "slug": "Thomas-Hofmann",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Hofmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Hofmann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 83
                            }
                        ],
                        "text": "The results of The Pascal Challenge from 2005 to 2008 [12] and the recent research [8, 13, 15, 28, 18, 21] indicate that sliding window classifiers are presently the predominant method being used in object detection, or more specifically, human detection, due to their good performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 74
                            }
                        ],
                        "text": "The integral image/histogram [29, 24, 34], the efficient subwindow search [15], and the increasingly powerful parallel computing hardware (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 31
                            }
                        ],
                        "text": "Many state-ofthe-art detectors [28, 15, 34, 30, 25] based on sliding window classifiers use the integral image method to increase the running speeds by several folds."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6131848,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "54b224478a63e33441c651175c522f3702062fc4",
            "isKey": false,
            "numCitedBy": 800,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Most successful object recognition systems rely on binary classification, deciding only if an object is present or not, but not providing information on the actual object location. To perform localization, one can take a sliding window approach, but this strongly increases the computational cost, because the classifier function has to be evaluated over a large set of candidate subwindows. In this paper, we propose a simple yet powerful branch-and-bound scheme that allows efficient maximization of a large class of classifier functions over all possible subimages. It converges to a globally optimal solution typically in sublinear time. We show how our method is applicable to different object detection and retrieval scenarios. The achieved speedup allows the use of classifiers for localization that formerly were considered too slow for this task, such as SVMs with a spatial pyramid kernel or nearest neighbor classifiers based on the chi2-distance. We demonstrate state-of-the-art performance of the resulting systems on the UIUC Cars dataset, the PASCAL VOC 2006 dataset and in the PASCAL VOC 2007 competition."
            },
            "slug": "Beyond-sliding-windows:-Object-localization-by-Lampert-Blaschko",
            "title": {
                "fragments": [],
                "text": "Beyond sliding windows: Object localization by efficient subwindow search"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A simple yet powerful branch-and-bound scheme that allows efficient maximization of a large class of classifier functions over all possible subimages and converges to a globally optimal solution typically in sublinear time is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1807606"
                        ],
                        "name": "Dahua Lin",
                        "slug": "Dahua-Lin",
                        "structuredName": {
                            "firstName": "Dahua",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dahua Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50295995"
                        ],
                        "name": "Xiaoou Tang",
                        "slug": "Xiaoou-Tang",
                        "structuredName": {
                            "firstName": "Xiaoou",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaoou Tang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 13
                            }
                        ],
                        "text": "Lin and Tang [6] presents a framework to automatically detect and recover the occluded facial region."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10214620,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb709c8c026a9ad23705387f66f3a77aa7382d31",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a framework to automatically detect and recover the occluded facial region. We first derive a Bayesian formulation unifying the occlusion detection and recovery stages. Then a quality assessment model is developed to drive both the detection and recovery processes, which captures the face priors in both global correlation and local patterns. Based on this formulation, we further propose GraphCut-based detection and confidence-oriented sampling to attain optimal detection and recovery respectively. Compared to traditional works in image repairing, our approach is distinct in three aspects: (1) it frees the user from marking the occlusion area by incorporating an automatic occlusion detector; (2) it learns a face quality model as a criterion to guide the whole procedure; (3) it couples the detection and occlusion stages to simultaneously achieve two goals: accurate occlusion detection and high quality recovery. The comparative experiments show that our method can recover the occluded faces with both the global coherence and local details well preserved."
            },
            "slug": "Quality-Driven-Face-Occlusion-Detection-and-Lin-Tang",
            "title": {
                "fragments": [],
                "text": "Quality-Driven Face Occlusion Detection and Recovery"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A Bayesian formulation unifying the occlusion detection and recovery stages is derived and GraphCut-based detection and confidence-oriented sampling are proposed to attain optimal detection and recover respectively."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2919518"
                        ],
                        "name": "S. Munder",
                        "slug": "S.-Munder",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Munder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Munder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144854796"
                        ],
                        "name": "D. Gavrila",
                        "slug": "D.-Gavrila",
                        "structuredName": {
                            "firstName": "Dariu",
                            "lastName": "Gavrila",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gavrila"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 83
                            }
                        ],
                        "text": "The results of The Pascal Challenge from 2005 to 2008 [12] and the recent research [8, 13, 15, 28, 18, 21] indicate that sliding window classifiers are presently the predominant method being used in object detection, or more specifically, human detection, due to their good performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10769792,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4ebbf3ec461f9b347937e4a5b993f12940558934",
            "isKey": false,
            "numCitedBy": 636,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Detecting people in images is key for several important application domains in computer vision. This paper presents an in-depth experimental study on pedestrian classification; multiple feature-classifier combinations are examined with respect to their ROC performance and efficiency. We investigate global versus local and adaptive versus nonadaptive features, as exemplified by PCA coefficients, Haar wavelets, and local receptive fields (LRFs). In terms of classifiers, we consider the popular support vector machines (SVMs), feedforward neural networks, and k-nearest neighbor classifier. Experiments are performed on a large data set consisting of 4,000 pedestrian and more than 25,000 nonpedestrian (labeled) images captured in outdoor urban environments. Statistically meaningful results are obtained by analyzing performance variances caused by varying training and test sets. Furthermore, we investigate how classification performance and training sample size are correlated. Sample size is adjusted by increasing the number of manually labeled training data or by employing automatic bootstrapping or cascade techniques. Our experiments show that the novel combination of SVMs with LRF features performs best. A boosted cascade of Haar wavelets can, however, reach quite competitive results, at a fraction of computational cost. The data set used in this paper is made public, establishing a benchmark for this important problem"
            },
            "slug": "An-Experimental-Study-on-Pedestrian-Classification-Munder-Gavrila",
            "title": {
                "fragments": [],
                "text": "An Experimental Study on Pedestrian Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "An in-depth experimental study on pedestrian classification; multiple feature-classifier combinations are examined with respect to their ROC performance and efficiency and show that the novel combination of SVMs with LRF features performs best."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143847264"
                        ],
                        "name": "Bo Wu",
                        "slug": "Bo-Wu",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144862593"
                        ],
                        "name": "R. Nevatia",
                        "slug": "R.-Nevatia",
                        "structuredName": {
                            "firstName": "Ramakant",
                            "lastName": "Nevatia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nevatia"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 15
                            }
                        ],
                        "text": "Wu and Nevatia [32, 33] use Bayesian combination to combine the part detectors to get a robust detection in the situation of partial occlusion."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16134208,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dee79dd2876a74e3f98e7537841aa0fb57dfead8",
            "isKey": false,
            "numCitedBy": 253,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Tracking of humans in videos is important for many applications. A major source of difficulty in performing this task is due to inter-human or scene occlusion. We present an approach based on representing humans as an assembly of four body parts and detection of the body parts in single frames which makes the method insensitive to camera motions. The responses of the body part detectors and a combined human detector provide the \"observations\" used for tracking. Trajectory initialization and termination are both fully automatic and rely on the confidences computed from the detection responses. An object is tracked by data association if its corresponding detection response can be found; otherwise it is tracked by a meanshift style tracker. Our method can track humans with both inter-object and scene occlusions. The system is evaluated on three sets of videos and compared with previous method."
            },
            "slug": "Tracking-of-Multiple,-Partially-Occluded-Humans-on-Wu-Nevatia",
            "title": {
                "fragments": [],
                "text": "Tracking of Multiple, Partially Occluded Humans based on Static Body Part Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work presents an approach based on representing humans as an assembly of four body parts and detection of the body parts in single frames which makes the method insensitive to camera motions."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758056"
                        ],
                        "name": "A. Stein",
                        "slug": "A.-Stein",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Stein",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Stein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 6
                            }
                        ],
                        "text": "Stein [26] takes advantage of occlusion boundaries to help high-level reasoning and improve object segmentation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 58585550,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b5148ebb4e8e88fefe42bd1016e5dcc3e78909fe",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 190,
            "paperAbstract": {
                "fragments": [],
                "text": "The boundaries of objects in an image are often considered a nuisance to be \u201chandled\u201d due to the occlusion they exhibit. Since most, if not all, computer vision techniques aggregate information spatially within a scene, information spanning these boundaries, and therefore from different physical surfaces, is invariably and erroneously considered together. In addition, these boundaries convey important perceptual information about 3D scene structure and shape. Consequently, their identification can benefit many different computer vision pursuits, from low-level processing techniques to high-level reasoning tasks. \nWhile much focus in computer vision is placed on the processing of individual, static images, many applications actually offer video, or sequences of images, as input. The extra temporal dimension of the data allows the motion of the camera or the scene to be used in processing. In this thesis, we focus on the exploitation of subtle relative-motion cues present at occlusion boundaries. When combined with more standard appearance information, we demonstrate these cues' utility in detecting occlusion boundaries locally. We also present a novel, mid-level model for reasoning more globally about object boundaries and propagating such local information to extract improved, extended boundaries. \nBuilding on these methods, we also demonstrate enhancement of two high-level vision tasks by incorporating boundary information. First we employ boundary fragments to suggest multiple \u201chints\u201d of a scene segmentation and then use these suggestions collectively to achieve more consistent and parsimonious delineation of generic whole objects. Second, we augment a popular feature-based recognition technique for specific objects (the Scale Invariant Feature Transform) with boundary information in order to yield a method more robust to changes in background and scale. \nThis thesis thus contributes to research on occlusion at several levels, from low-level motion estimation and feature extraction; to mid-level reasoning, classification, and propagation; and finally to high-level segmentation and recognition. In addition, a new video dataset is presented to enable further research in this area."
            },
            "slug": "Occlusion-boundaries:-low-level-detection-to-Hebert-Stein",
            "title": {
                "fragments": [],
                "text": "Occlusion boundaries: low-level detection to high-level reasoning"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This thesis focuses on the exploitation of subtle relative-motion cues present at occlusion boundaries, and presents a novel, mid-level model for reasoning more globally about object boundaries and propagating such local information to extract improved, extended boundaries."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 108
                            }
                        ],
                        "text": "Although preferred for its performance in general, compared to other detectors such as part-based detectors [1, 14, 16, 19, 32], the sliding window approach handles partial occlusions poorly."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5745749,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62837ab473124ea43cb8d7c6a4b4ee0f6f14e8c5",
            "isKey": false,
            "numCitedBy": 2487,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method to learn and recognize object class models from unlabeled and unsegmented cluttered scenes in a scale invariant manner. Objects are modeled as flexible constellations of parts. A probabilistic representation is used for all aspects of the object: shape, appearance, occlusion and relative scale. An entropy-based feature detector is used to select regions and their scale within the image. In learning the parameters of the scale-invariant object model are estimated. This is done using expectation-maximization in a maximum-likelihood setting. In recognition, this model is used in a Bayesian manner to classify images. The flexible nature of the model is demonstrated by excellent results over a range of datasets including geometrically constrained classes (e.g. faces, cars) and flexible objects (such as animals)."
            },
            "slug": "Object-class-recognition-by-unsupervised-learning-Fergus-Perona",
            "title": {
                "fragments": [],
                "text": "Object class recognition by unsupervised scale-invariant learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The flexible nature of the model is demonstrated by excellent results over a range of datasets including geometrically constrained classes (e.g. faces, cars) and flexible objects (such as animals)."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "98106833"
                        ],
                        "name": "B. K. Julsing",
                        "slug": "B.-K.-Julsing",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Julsing",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. K. Julsing"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 44
                            }
                        ],
                        "text": "[20] state that traditional LBP operator in [2] does not suit the human detection problem well."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1612882,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "15885415819f2a9db8eee46ea6b6224c759801fa",
            "isKey": false,
            "numCitedBy": 1147,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "This report is about a bachelor assignment in which research has been done to face recognition with Local Binary Patterns (LBP). LBP is a very powerful method to describe the texture and shape of a digital image. Therefore it appeared to be suitable for feature extraction in face recognition systems. A face image is first divided into small regions from which LBP histograms are extracted and then concatenated into a single feature vector. This feature vector forms an efficient representation of the face and can be used to measure similarities between images. The report describes the principles of the method and how exactly it can be implemented to perform face recognition. Experiments have been carried out on the different sets of the FERET database. High recognition rates are obtained, especially compared to other face recognition methods. Also a few extensions are investigated to further improve the performance of the method. It appeared that LBP can easily be combined with Principal Component Analysis to reduce the length of the feature vector, while the recognition performance only slightly decreases."
            },
            "slug": "Face-Recognition-with-Local-Binary-Patterns-Julsing",
            "title": {
                "fragments": [],
                "text": "Face Recognition with Local Binary Patterns"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It appeared that LBP can easily be combined with Principal Component Analysis to reduce the length of the feature vector, while the recognition performance only slightly decreases, especially compared to other face recognition methods."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2797063"
                        ],
                        "name": "S. Agarwal",
                        "slug": "S.-Agarwal",
                        "structuredName": {
                            "firstName": "Shivani",
                            "lastName": "Agarwal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Agarwal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32177941"
                        ],
                        "name": "A. Awan",
                        "slug": "A.-Awan",
                        "structuredName": {
                            "firstName": "Aatif",
                            "lastName": "Awan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Awan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 108
                            }
                        ],
                        "text": "Although preferred for its performance in general, compared to other detectors such as part-based detectors [1, 14, 16, 19, 32], the sliding window approach handles partial occlusions poorly."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8855331,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b82d251ed367593366680acebc81fdb070b04a18",
            "isKey": false,
            "numCitedBy": 963,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the problem of detecting objects in still, gray-scale images. Our primary focus is the development of a learning-based approach to the problem that makes use of a sparse, part-based representation. A vocabulary of distinctive object parts is automatically constructed from a set of sample images of the object class of interest; images are then represented using parts from this vocabulary, together with spatial relations observed among the parts. Based on this representation, a learning algorithm is used to automatically learn to detect instances of the object class in new images. The approach can be applied to any object with distinguishable parts in a relatively fixed spatial configuration; it is evaluated here on difficult sets of real-world images containing side views of cars, and is seen to successfully detect objects in varying conditions amidst background clutter and mild occlusion. In evaluating object detection approaches, several important methodological issues arise that have not been satisfactorily addressed in the previous work. A secondary focus of this paper is to highlight these issues, and to develop rigorous evaluation standards for the object detection problem. A critical evaluation of our approach under the proposed standards is presented."
            },
            "slug": "Learning-to-detect-objects-in-images-via-a-sparse,-Agarwal-Awan",
            "title": {
                "fragments": [],
                "text": "Learning to detect objects in images via a sparse, part-based representation"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A learning-based approach to the problem of detecting objects in still, gray-scale images that makes use of a sparse, part-based representation is developed and a critical evaluation of the approach under the proposed standards is presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789756"
                        ],
                        "name": "B. Leibe",
                        "slug": "B.-Leibe",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Leibe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Leibe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2083209039"
                        ],
                        "name": "Edgar Seemann",
                        "slug": "Edgar-Seemann",
                        "structuredName": {
                            "firstName": "Edgar",
                            "lastName": "Seemann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Edgar Seemann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48920094"
                        ],
                        "name": "B. Schiele",
                        "slug": "B.-Schiele",
                        "structuredName": {
                            "firstName": "Bernt",
                            "lastName": "Schiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schiele"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 21
                            }
                        ],
                        "text": "part based detectors [16, 19, 32] can alleviate the occlusion problem to some extent by relying on the unoccluded part to determine the human position."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 108
                            }
                        ],
                        "text": "Although preferred for its performance in general, compared to other detectors such as part-based detectors [1, 14, 16, 19, 32], the sliding window approach handles partial occlusions poorly."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14395688,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1854005a7178b2df6afaacdcf91bc35d90616075",
            "isKey": false,
            "numCitedBy": 932,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we address the problem of detecting pedestrians in crowded real-world scenes with severe overlaps. Our basic premise is that this problem is too difficult for any type of model or feature alone. Instead, we present an algorithm that integrates evidence in multiple iterations and from different sources. The core part of our method is the combination of local and global cues via probabilistic top-down segmentation. Altogether, this approach allows examining and comparing object hypotheses with high precision down to the pixel level. Qualitative and quantitative results on a large data set confirm that our method is able to reliably detect pedestrians in crowded scenes, even when they overlap and partially occlude each other. In addition, the flexible nature of our approach allows it to operate on very small training sets."
            },
            "slug": "Pedestrian-detection-in-crowded-scenes-Leibe-Seemann",
            "title": {
                "fragments": [],
                "text": "Pedestrian detection in crowded scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Qualitative and quantitative results on a large data set confirm that the core part of the method is the combination of local and global cues via probabilistic top-down segmentation that allows examining and comparing object hypotheses with high precision down to the pixel level."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685089"
                        ],
                        "name": "Pedro F. Felzenszwalb",
                        "slug": "Pedro-F.-Felzenszwalb",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Felzenszwalb",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pedro F. Felzenszwalb"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145689002"
                        ],
                        "name": "David A. McAllester",
                        "slug": "David-A.-McAllester",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "McAllester",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David A. McAllester"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770537"
                        ],
                        "name": "D. Ramanan",
                        "slug": "D.-Ramanan",
                        "structuredName": {
                            "firstName": "Deva",
                            "lastName": "Ramanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ramanan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 135
                            }
                        ],
                        "text": "Evaluated using both criteria, our HOG-LBP detector (with/without occlusion handling) out perform all known state-of-the-art detectors [8, 13, 28, 10, 31, 25, 34, 18] on the INRIA dataset."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 21
                            }
                        ],
                        "text": "LatSVM: The detector [13] using deformable model."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 83
                            }
                        ],
                        "text": "The results of The Pascal Challenge from 2005 to 2008 [12] and the recent research [8, 13, 15, 28, 18, 21] indicate that sliding window classifiers are presently the predominant method being used in object detection, or more specifically, human detection, due to their good performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 124
                            }
                        ],
                        "text": "As a dense version of the dominating SIFT [17] feature, HOG [8] has shown great success in object detection and recognition [8, 9, 13, 25, 34]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14327585,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "860a9d55d87663ca88e74b3ca357396cd51733d0",
            "isKey": true,
            "numCitedBy": 2616,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a discriminatively trained, multiscale, deformable part model for object detection. Our system achieves a two-fold improvement in average precision over the best performance in the 2006 PASCAL person detection challenge. It also outperforms the best results in the 2007 challenge in ten out of twenty categories. The system relies heavily on deformable parts. While deformable part models have become quite popular, their value had not been demonstrated on difficult benchmarks such as the PASCAL challenge. Our system also relies heavily on new methods for discriminative training. We combine a margin-sensitive approach for data mining hard negative examples with a formalism we call latent SVM. A latent SVM, like a hidden CRF, leads to a non-convex training problem. However, a latent SVM is semi-convex and the training problem becomes convex once latent information is specified for the positive examples. We believe that our training methods will eventually make possible the effective use of more latent information such as hierarchical (grammar) models and models involving latent three dimensional pose."
            },
            "slug": "A-discriminatively-trained,-multiscale,-deformable-Felzenszwalb-McAllester",
            "title": {
                "fragments": [],
                "text": "A discriminatively trained, multiscale, deformable part model"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "A discriminatively trained, multiscale, deformable part model for object detection, which achieves a two-fold improvement in average precision over the best performance in the 2006 PASCAL person detection challenge and outperforms the best results in the 2007 challenge in ten out of twenty categories."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053815434"
                        ],
                        "name": "Ping Fu",
                        "slug": "Ping-Fu",
                        "structuredName": {
                            "firstName": "Ping",
                            "lastName": "Fu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ping Fu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109235259"
                        ],
                        "name": "Weijia Liu",
                        "slug": "Weijia-Liu",
                        "structuredName": {
                            "firstName": "Weijia",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Weijia Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144820871"
                        ],
                        "name": "Dingyu Xue",
                        "slug": "Dingyu-Xue",
                        "structuredName": {
                            "firstName": "Dingyu",
                            "lastName": "Xue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dingyu Xue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685248"
                        ],
                        "name": "Xinhe Xu",
                        "slug": "Xinhe-Xu",
                        "structuredName": {
                            "firstName": "Xinhe",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xinhe Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2579561"
                        ],
                        "name": "Daoxiang Gao",
                        "slug": "Daoxiang-Gao",
                        "structuredName": {
                            "firstName": "Daoxiang",
                            "lastName": "Gao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daoxiang Gao"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[23] proposed a detection algorithm based on the occlusion reasoning and partial division block template matching for tracking task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18436105,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6fc2ec34875fc7b6e4934dd259d8f39db11068b0",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "A detection algorithm based on the occlusion reasoning and partial division block template matching is proposed since the occluded target can not be located accurately by the common located algorithm during tracking process. Locating target accurately is critical factors that affect the tracking performance and reliability. Occlusion reasoning method provides the occlusion alarm status of multiple targets in the frame t. By using the predicted information, the occlusion status is verified once again in the frame (t+1). If the occlusion status is enabled, partial division block template matching technique is employed. Using these algorithms, we can obtain the reliable locations of occluded objects respectively. Finally, the proposed algorithms are applied to real image sequences. Experimental results on the high way and urban road demonstrate the usefulness of the proposed method"
            },
            "slug": "Research-on-Occlusion-in-the-Multiple-Vehicle-and-Fu-Liu",
            "title": {
                "fragments": [],
                "text": "Research on Occlusion in the Multiple Vehicle Detecting and Tracking System"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "A detection algorithm based on the occlusion reasoning and partial division block template matching is proposed since the Occlusion target can not be located accurately by the common located algorithm during tracking process."
            },
            "venue": {
                "fragments": [],
                "text": "2006 6th World Congress on Intelligent Control and Automation"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2762198"
                        ],
                        "name": "E. R\u00fcckert",
                        "slug": "E.-R\u00fcckert",
                        "structuredName": {
                            "firstName": "Elmar",
                            "lastName": "R\u00fcckert",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. R\u00fcckert"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "Shapelet: The detector [25] using shapelet features."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 529,
                                "start": 502
                            }
                        ],
                        "text": "The contribution of this paper is three-fold: 1) Through occlusion inference on sliding window classification results, we propose an approach to integrate the advantage of part-based detectors in occlusion handling to the slidingwindow detectors; 2) An augmented feature, HOG-LBP, which combines HOG with cell-structured Local Binary Pattern (LBP) [3], is proposed as the feature, based on which the HOG-LBP human detector achieves better performance than all of known state-of-the-art human detectors [8, 28, 18, 34, 25, 27, 20] on INRIA dataset (refer to section 3."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 31
                            }
                        ],
                        "text": "Many state-ofthe-art detectors [28, 15, 34, 30, 25] based on sliding window classifiers use the integral image method to increase the running speeds by several folds."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 135
                            }
                        ],
                        "text": "Evaluated using both criteria, our HOG-LBP detector (with/without occlusion handling) out perform all known state-of-the-art detectors [8, 13, 28, 10, 31, 25, 34, 18] on the INRIA dataset."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 124
                            }
                        ],
                        "text": "As a dense version of the dominating SIFT [17] feature, HOG [8] has shown great success in object detection and recognition [8, 9, 13, 25, 34]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14422151,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c725cc9d67e8f2c237e16cacf4123848cdab3f16",
            "isKey": true,
            "numCitedBy": 206,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "I introduce in this paper a method of detecting pedestrians, presented by Payam Sabzmeydani and Greg Mori [1]. Local gradient information is used for the classification task and the results are 14 percentage points lower (at 10\u22126 FPPW, false positive per window) than a previous state of the art detector of Dalal and Triggs [2]. During the explanations I will often draw a comparison to a composition of Andreas Opelt, Axel Pinz and Andrew Zisserman [4]. There are several similarities but Andreas Opelt has also the ability to locate the object in an image. This could be a big advantage to have this information for real time applications."
            },
            "slug": "Detecting-Pedestrians-by-Learning-Shapelet-Features-R\u00fcckert",
            "title": {
                "fragments": [],
                "text": "Detecting Pedestrians by Learning Shapelet Features"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A method of detecting pedestrians, presented by Payam Sabzmeydani and Greg Mori, and a comparison to a composition of Andreas Opelt, Axel Pinz and Andrew Zisserman."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685020"
                        ],
                        "name": "D. Comaniciu",
                        "slug": "D.-Comaniciu",
                        "structuredName": {
                            "firstName": "Dorin",
                            "lastName": "Comaniciu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Comaniciu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145776090"
                        ],
                        "name": "P. Meer",
                        "slug": "P.-Meer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Meer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Meer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 25
                            }
                        ],
                        "text": "The mean shift algorithm [4, 5] is applied to segment the binary image for each window."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 25
                            }
                        ],
                        "text": "The mean shift algorithm [4, 5] is applied to segment this binary image for each sliding window."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 38
                            }
                        ],
                        "text": "|fi(Bi)|) is used as the weight \u03c9i in [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 691081,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74f4ecc3e4e5b91fbb54330b285ed5214afe2001",
            "isKey": false,
            "numCitedBy": 11480,
            "numCiting": 122,
            "paperAbstract": {
                "fragments": [],
                "text": "A general non-parametric technique is proposed for the analysis of a complex multimodal feature space and to delineate arbitrarily shaped clusters in it. The basic computational module of the technique is an old pattern recognition procedure: the mean shift. For discrete data, we prove the convergence of a recursive mean shift procedure to the nearest stationary point of the underlying density function and, thus, its utility in detecting the modes of the density. The relation of the mean shift procedure to the Nadaraya-Watson estimator from kernel regression and the robust M-estimators; of location is also established. Algorithms for two low-level vision tasks discontinuity-preserving smoothing and image segmentation - are described as applications. In these algorithms, the only user-set parameter is the resolution of the analysis, and either gray-level or color images are accepted as input. Extensive experimental results illustrate their excellent performance."
            },
            "slug": "Mean-Shift:-A-Robust-Approach-Toward-Feature-Space-Comaniciu-Meer",
            "title": {
                "fragments": [],
                "text": "Mean Shift: A Robust Approach Toward Feature Space Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is proved the convergence of a recursive mean shift procedure to the nearest stationary point of the underlying density function and, thus, its utility in detecting the modes of the density."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29905643"
                        ],
                        "name": "F. Porikli",
                        "slug": "F.-Porikli",
                        "structuredName": {
                            "firstName": "Fatih",
                            "lastName": "Porikli",
                            "middleNames": [
                                "Murat"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Porikli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 53
                            }
                        ],
                        "text": "Within the framework of the integral image/histogram [29, 24, 34], the extraction of the features for scanning windows has a constant complexityO(c) (two vector addition and two vector subtraction)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 29
                            }
                        ],
                        "text": "The integral image/histogram [29, 24, 34], the efficient subwindow search [15], and the increasingly powerful parallel computing hardware (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1122429,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fbf4d36e787e2e5c8444e1a2229b821e9cd68adf",
            "isKey": false,
            "numCitedBy": 810,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel method, which we refer as an integral histogram, to compute the histograms of all possible target regions in a Cartesian data space. Our method has three distinct advantages: 1) It is computationally superior to the conventional approach. The integral histogram method makes it possible to employ even an exhaustive search process in real-time, which was impractical before. 2) It can be extended to higher data dimensions, uniform and nonuniform bin formations, and multiple target scales without sacrificing its computational advantages. 3) It enables the description of higher level histogram features. We exploit the spatial arrangement of data points, and recursively propagate an aggregated histogram by starting from the origin and traversing through the remaining points along either a scan-line or a wave-front. At each step, we update a single bin using the values of integral histogram at the previously visited neighboring data points. After the integral histogram is propagated, histogram of any target region can be computed easily by using simple arithmetic operations."
            },
            "slug": "Integral-histogram:-a-fast-way-to-extract-in-spaces-Porikli",
            "title": {
                "fragments": [],
                "text": "Integral histogram: a fast way to extract histograms in Cartesian spaces"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The integral histogram method makes it possible to employ even an exhaustive search process in real-time, which was impractical before, and enables the description of higher level histogram features."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35208858"
                        ],
                        "name": "Subhransu Maji",
                        "slug": "Subhransu-Maji",
                        "structuredName": {
                            "firstName": "Subhransu",
                            "lastName": "Maji",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Subhransu Maji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39668247"
                        ],
                        "name": "A. Berg",
                        "slug": "A.-Berg",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Berg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 41
                            }
                        ],
                        "text": "We improve the detection rate by 1.5% at FPPW=10\u22125 and by 8.0% at FPPW=10\u22126."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 33
                            }
                        ],
                        "text": "Multi-Level HOG(1): The detector [18] using Multilevel HOG and IKSVM."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 137
                            }
                        ],
                        "text": "It is\nreported in [18] that the Multi-Level HOG can get only 50% detection rate using linear SVM, but it is improved by about 47% at 10\u22124 FPPW [18] by using IKSVM."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 83
                            }
                        ],
                        "text": "We use two different criteria: 1) The detection rate vs. False Positive PerWindow (FPPW); and 2) The detection rate vs False Positive Per Image (FPPI)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 44
                            }
                        ],
                        "text": "We achieve a detection rate of 91.3% at 10\u22126 FPPW and 94.7% at 10\u22125 FPPW."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 38
                            }
                        ],
                        "text": "We save all the miss detection at 10\u22126 FPPW and find that only 28 positvie images are missclassified because of partial occlusion."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 137
                            }
                        ],
                        "text": "Since we achieved the desired performance on INRIA data (only 25 positive samples are missed out of 1126 testing positive image with the FPPW=10\u22124), we test the HOGLBP detector on a very challenging upper body dataset (with 6000 positive samples and 4000 negative images), which is made available to public for download 2 ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 529,
                                "start": 502
                            }
                        ],
                        "text": "The contribution of this paper is three-fold: 1) Through occlusion inference on sliding window classification results, we propose an approach to integrate the advantage of part-based detectors in occlusion handling to the slidingwindow detectors; 2) An augmented feature, HOG-LBP, which combines HOG with cell-structured Local Binary Pattern (LBP) [3], is proposed as the feature, based on which the HOG-LBP human detector achieves better performance than all of known state-of-the-art human detectors [8, 28, 18, 34, 25, 27, 20] on INRIA dataset (refer to section 3."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 135
                            }
                        ],
                        "text": "Evaluated using both criteria, our HOG-LBP detector (with/without occlusion handling) out perform all known state-of-the-art detectors [8, 13, 28, 10, 31, 25, 34, 18] on the INRIA dataset."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 29
                            }
                        ],
                        "text": "Multi-Level HOG:The detector [18] using Multilevel HOG and IKSVM."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 12
                            }
                        ],
                        "text": "reported in [18] that the Multi-Level HOG can get only 50% detection rate using linear SVM, but it is improved by about 47% at 10 FPPW [18] by using IKSVM."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[18] using Multi-Level HOG and Intersection Kernel SVM (IKSVM)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 61
                            }
                        ],
                        "text": "1It has been reported in [11] that the features extracted in [18] contains the boundary of the cropped positive examples, which implicitly encodes the label information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 83
                            }
                        ],
                        "text": "The results of The Pascal Challenge from 2005 to 2008 [12] and the recent research [8, 13, 15, 28, 18, 21] indicate that sliding window classifiers are presently the predominant method being used in object detection, or more specifically, human detection, due to their good performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2990061,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a7086378e68dae59975cf749c101c53a0fa90eab",
            "isKey": true,
            "numCitedBy": 1082,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Straightforward classification using kernelized SVMs requires evaluating the kernel for a test vector and each of the support vectors. For a class of kernels we show that one can do this much more efficiently. In particular we show that one can build histogram intersection kernel SVMs (IKSVMs) with runtime complexity of the classifier logarithmic in the number of support vectors as opposed to linear for the standard approach. We further show that by precomputing auxiliary tables we can construct an approximate classifier with constant runtime and space requirements, independent of the number of support vectors, with negligible loss in classification accuracy on various tasks. This approximation also applies to 1 - chi2 and other kernels of similar form. We also introduce novel features based on a multi-level histograms of oriented edge energy and present experiments on various detection datasets. On the INRIA pedestrian dataset an approximate IKSVM classifier based on these features has the current best performance, with a miss rate 13% lower at 10-6 False Positive Per Window than the linear SVM detector of Dalal & Triggs. On the Daimler Chrysler pedestrian dataset IKSVM gives comparable accuracy to the best results (based on quadratic SVM), while being 15times faster. In these experiments our approximate IKSVM is up to 2000times faster than a standard implementation and requires 200times less memory. Finally we show that a 50times speedup is possible using approximate IKSVM based on spatial pyramid features on the Caltech 101 dataset with negligible loss of accuracy."
            },
            "slug": "Classification-using-intersection-kernel-support-is-Maji-Berg",
            "title": {
                "fragments": [],
                "text": "Classification using intersection kernel support vector machines is efficient"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that one can build histogram intersection kernel SVMs (IKSVMs) with runtime complexity of the classifier logarithmic in the number of support vectors as opposed to linear for the standard approach."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2828154"
                        ],
                        "name": "Duan Tran",
                        "slug": "Duan-Tran",
                        "structuredName": {
                            "firstName": "Duan",
                            "lastName": "Tran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Duan Tran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 529,
                                "start": 502
                            }
                        ],
                        "text": "The contribution of this paper is three-fold: 1) Through occlusion inference on sliding window classification results, we propose an approach to integrate the advantage of part-based detectors in occlusion handling to the slidingwindow detectors; 2) An augmented feature, HOG-LBP, which combines HOG with cell-structured Local Binary Pattern (LBP) [3], is proposed as the feature, based on which the HOG-LBP human detector achieves better performance than all of known state-of-the-art human detectors [8, 28, 18, 34, 25, 27, 20] on INRIA dataset (refer to section 3."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13902758,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "35570297681daa3973498eabead361d0be961672",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Fair discriminative pedestrian finders are now available. In fact, these pedestrian finders make most errors on pedestrians in configurations that are uncommon in the training data, for example, mounting a bicycle. This is undesirable. However, the human configuration can itself be estimated discriminatively using structure learning. We demonstrate a pedestrian finder which first finds the most likely human pose in the window using a discriminative procedure trained with structure learning on a small dataset. We then present features (local histogram of oriented gradient and local PCA of gradient) based on that configuration to an SVM classifier. We show, using the INRIA Person dataset, that estimates of configuration significantly improve the accuracy of a discriminative pedestrian finder."
            },
            "slug": "Configuration-Estimates-Improve-Pedestrian-Finding-Tran-Forsyth",
            "title": {
                "fragments": [],
                "text": "Configuration Estimates Improve Pedestrian Finding"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown, using the INRIA Person dataset, that estimates of configuration significantly improve the accuracy of a discriminative pedestrian finder."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3127283"
                        ],
                        "name": "Piotr Doll\u00e1r",
                        "slug": "Piotr-Doll\u00e1r",
                        "structuredName": {
                            "firstName": "Piotr",
                            "lastName": "Doll\u00e1r",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Piotr Doll\u00e1r"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145492205"
                        ],
                        "name": "Hai Tao",
                        "slug": "Hai-Tao",
                        "structuredName": {
                            "firstName": "Hai",
                            "lastName": "Tao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hai Tao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "FtrMine: The detector [10] using Haar features and feature mining algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 135
                            }
                        ],
                        "text": "Evaluated using both criteria, our HOG-LBP detector (with/without occlusion handling) out perform all known state-of-the-art detectors [8, 13, 28, 10, 31, 25, 34, 18] on the INRIA dataset."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8961509,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "69deed411eeff65cc0cba9e7db94ac337322089b",
            "isKey": false,
            "numCitedBy": 226,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "The efficiency and robustness of a vision system is often largely determined by the quality of the image features available to it. In data mining, one typically works with immense volumes of raw data, which demands effective algorithms to explore the data space. In analogy to data mining, the space of meaningful features for image analysis is also quite vast. Recently, the challenges associated with these problem areas have become more tractable through progress made in machine learning and concerted research effort in manual feature design by domain experts. In this paper, we propose a feature mining paradigm for image classification and examine several feature mining strategies. We also derive a principled approach for dealing with features with varying computational demands. Our goal is to alleviate the burden of manual feature design, which is a key problem in computer vision and machine learning. We include an in-depth empirical study on three typical data sets and offer theoretical explanations for the performance of various feature mining strategies. As a final confirmation of our ideas, we show results of a system, that utilizing feature mining strategies matches or outperforms the best reported results on pedestrian classification (where considerable effort has been devoted to expert feature design)."
            },
            "slug": "Feature-Mining-for-Image-Classification-Doll\u00e1r-Tu",
            "title": {
                "fragments": [],
                "text": "Feature Mining for Image Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A feature mining paradigm for image classification is proposed and several feature mining strategies are examined to alleviate the burden of manual feature design, which is a key problem in computer vision and machine learning."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2577513"
                        ],
                        "name": "Oncel Tuzel",
                        "slug": "Oncel-Tuzel",
                        "structuredName": {
                            "firstName": "Oncel",
                            "lastName": "Tuzel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oncel Tuzel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29905643"
                        ],
                        "name": "F. Porikli",
                        "slug": "F.-Porikli",
                        "structuredName": {
                            "firstName": "Fatih",
                            "lastName": "Porikli",
                            "middleNames": [
                                "Murat"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Porikli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145776090"
                        ],
                        "name": "P. Meer",
                        "slug": "P.-Meer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Meer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Meer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2161048,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "b5702b5726b3dc58d97100061b4f54020631d9e6",
            "isKey": false,
            "numCitedBy": 535,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new algorithm to detect humans in still images utilizing covariance matrices as object descriptors. Since these descriptors do not lie on a vector space, well known machine learning techniques are not adequate to learn the classifiers. The space of d-dimensional nonsingular covariance matrices can be represented as a connected Riemannian manifold. We present a novel approach for classifying points lying on a Riemannian manifold by incorporating the a priori information about the geometry of the space. The algorithm is tested on INRIA human database where superior detection rates are observed over the previous approaches."
            },
            "slug": "Human-Detection-via-Classification-on-Riemannian-Tuzel-Porikli",
            "title": {
                "fragments": [],
                "text": "Human Detection via Classification on Riemannian Manifolds"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A novel approach for classifying points lying on a Riemannian manifold by incorporating the a priori information about the geometry of the space."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48345000"
                        ],
                        "name": "T. Ahonen",
                        "slug": "T.-Ahonen",
                        "structuredName": {
                            "firstName": "Timo",
                            "lastName": "Ahonen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Ahonen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144979251"
                        ],
                        "name": "A. Hadid",
                        "slug": "A.-Hadid",
                        "structuredName": {
                            "firstName": "Abdenour",
                            "lastName": "Hadid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hadid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145962204"
                        ],
                        "name": "M. Pietik\u00e4inen",
                        "slug": "M.-Pietik\u00e4inen",
                        "structuredName": {
                            "firstName": "Matti",
                            "lastName": "Pietik\u00e4inen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pietik\u00e4inen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 103
                            }
                        ],
                        "text": "It has been widely used in various applications and has achieved very good results in face recognition [3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 351,
                                "start": 348
                            }
                        ],
                        "text": "The contribution of this paper is three-fold: 1) Through occlusion inference on sliding window classification results, we propose an approach to integrate the advantage of part-based detectors in occlusion handling to the slidingwindow detectors; 2) An augmented feature, HOG-LBP, which combines HOG with cell-structured Local Binary Pattern (LBP) [3], is proposed as the feature, based on which the HOG-LBP human detector achieves better performance than all of known state-of-the-art human detectors [8, 28, 18, 34, 25, 27, 20] on INRIA dataset (refer to section 3."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 369876,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e7c4665ce36a53484f8a7b7dfa821a9f6273eab4",
            "isKey": false,
            "numCitedBy": 5461,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel and efficient facial image representation based on local binary pattern (LBP) texture features. The face image is divided into several regions from which the LBP feature distributions are extracted and concatenated into an enhanced feature vector to be used as a face descriptor. The performance of the proposed method is assessed in the face recognition problem under different challenges. Other applications and several extensions are also discussed"
            },
            "slug": "Face-Description-with-Local-Binary-Patterns:-to-Ahonen-Hadid",
            "title": {
                "fragments": [],
                "text": "Face Description with Local Binary Patterns: Application to Face Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "This paper presents a novel and efficient facial image representation based on local binary pattern (LBP) texture features that is assessed in the face recognition problem under different challenges."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2340109"
                        ],
                        "name": "C. Wojek",
                        "slug": "C.-Wojek",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Wojek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Wojek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48920094"
                        ],
                        "name": "B. Schiele",
                        "slug": "B.-Schiele",
                        "structuredName": {
                            "firstName": "Bernt",
                            "lastName": "Schiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schiele"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 135
                            }
                        ],
                        "text": "Evaluated using both criteria, our HOG-LBP detector (with/without occlusion handling) out perform all known state-of-the-art detectors [8, 13, 28, 10, 31, 25, 34, 18] on the INRIA dataset."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "MultiFtr: The detector [31] using Shape Context and Haar wavelets feature."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 39046756,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3e6fa6cf1fe2e23fdf7716f89b160333c7a93b26",
            "isKey": false,
            "numCitedBy": 266,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Over the years a number of powerful people detectors have been proposed. While it is standard to test complete detectors on publicly available datasets, it is often unclear how the different components (e.g. features and classifiers) of the respective detectors compare. Therefore, this paper contributes a systematic comparison of the most prominent and successful people detectors. Based on this evaluation we also propose a new detector that outperforms the state-of-art on the INRIA person dataset by combining multiple features."
            },
            "slug": "A-Performance-Evaluation-of-Single-and-People-Wojek-Schiele",
            "title": {
                "fragments": [],
                "text": "A Performance Evaluation of Single and Multi-feature People Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A systematic comparison of the most prominent and successful people detectors is contributed and a new detector is proposed that outperforms the state-of-art on the INRIA person dataset by combining multiple features."
            },
            "venue": {
                "fragments": [],
                "text": "DAGM-Symposium"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059876008"
                        ],
                        "name": "Matthijs C. Dorst",
                        "slug": "Matthijs-C.-Dorst",
                        "structuredName": {
                            "firstName": "Matthijs",
                            "lastName": "Dorst",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthijs C. Dorst"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 42
                            }
                        ],
                        "text": "As a dense version of the dominating SIFT [17] feature, HOG [8] has shown great success in object detection and recognition [8, 9, 13, 25, 34]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 130535382,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bcae70dce393c1796d4f15c7b8bbf0ed6f468be1",
            "isKey": false,
            "numCitedBy": 15904,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The Scale-Invariant Feature Transform (or SIFT) algorithm is a highly robust method to extract and consequently match distinctive invariant features from images. These features can then be used to reliably match objects in diering images. The algorithm was rst proposed by Lowe [12] and further developed to increase performance resulting in the classic paper [13] that served as foundation for SIFT which has played an important role in robotic and machine vision in the past decade."
            },
            "slug": "Distinctive-Image-Features-from-Scale-Invariant-Dorst",
            "title": {
                "fragments": [],
                "text": "Distinctive Image Features from Scale-Invariant Keypoints"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "The Scale-Invariant Feature Transform (or SIFT) algorithm is a highly robust method to extract and consequently match distinctive invariant features from images that can then be used to reliably match objects in diering images."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49097100"
                        ],
                        "name": "Yizong Cheng",
                        "slug": "Yizong-Cheng",
                        "structuredName": {
                            "firstName": "Yizong",
                            "lastName": "Cheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yizong Cheng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 25
                            }
                        ],
                        "text": "The mean shift algorithm [4, 5] is applied to segment the binary image for each window."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 25
                            }
                        ],
                        "text": "The mean shift algorithm [4, 5] is applied to segment this binary image for each sliding window."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14842224,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1c168275c59ba382588350ee1443537f59978183",
            "isKey": false,
            "numCitedBy": 3718,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Mean shift, a simple interactive procedure that shifts each data point to the average of data points in its neighborhood is generalized and analyzed in the paper. This generalization makes some k-means like clustering algorithms its special cases. It is shown that mean shift is a mode-seeking process on the surface constructed with a \"shadow\" kernal. For Gaussian kernels, mean shift is a gradient mapping. Convergence is studied for mean shift iterations. Cluster analysis if treated as a deterministic problem of finding a fixed point of mean shift that characterizes the data. Applications in clustering and Hough transform are demonstrated. Mean shift is also considered as an evolutionary strategy that performs multistart global optimization. >"
            },
            "slug": "Mean-Shift,-Mode-Seeking,-and-Clustering-Cheng",
            "title": {
                "fragments": [],
                "text": "Mean Shift, Mode Seeking, and Clustering"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "Mean shift, a simple interactive procedure that shifts each data point to the average of data points in its neighborhood is generalized and analyzed and makes some k-means like clustering algorithms its special cases."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144522420"
                        ],
                        "name": "T. Ojala",
                        "slug": "T.-Ojala",
                        "structuredName": {
                            "firstName": "Timo",
                            "lastName": "Ojala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Ojala"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145962204"
                        ],
                        "name": "M. Pietik\u00e4inen",
                        "slug": "M.-Pietik\u00e4inen",
                        "structuredName": {
                            "firstName": "Matti",
                            "lastName": "Pietik\u00e4inen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pietik\u00e4inen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145298122"
                        ],
                        "name": "D. Harwood",
                        "slug": "D.-Harwood",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Harwood",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Harwood"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "While the LBP operator [22] is an exceptional texture descriptors."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 62
                            }
                        ],
                        "text": "It can filter out noises using the concept of uniform pattern [22]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 73
                            }
                        ],
                        "text": "The pattern that satisfies this constraint is called uniform patterns in [22]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 26881819,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5985014dda6d502469614aae17349b4d08f9f74c",
            "isKey": true,
            "numCitedBy": 6553,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-comparative-study-of-texture-measures-with-based-Ojala-Pietik\u00e4inen",
            "title": {
                "fragments": [],
                "text": "A comparative study of texture measures with classification based on featured distributions"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056091"
                        ],
                        "name": "M. Everingham",
                        "slug": "M.-Everingham",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Everingham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Everingham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145715698"
                        ],
                        "name": "Christopher K. I. Williams",
                        "slug": "Christopher-K.-I.-Williams",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Williams",
                            "middleNames": [
                                "K.",
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher K. I. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 34
                            }
                        ],
                        "text": "It has been widely used in various applications and has achieved very good results in face recognition [3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61615905,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a2ed19ac684022aa3186887cd4893484ab8f80c",
            "isKey": false,
            "numCitedBy": 2169,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "This report presents the results of the 2006 PASCAL Visual Object Classes Challenge (VOC2006). Details of the challenge, data, and evaluation are presented. Participants in the challenge submitted descriptions of their methods, and these have been included verbatim. This document should be considered preliminary, and subject to change."
            },
            "slug": "The-PASCAL-visual-object-classes-challenge-2006-Everingham-Zisserman",
            "title": {
                "fragments": [],
                "text": "The PASCAL visual object classes challenge 2006 (VOC2006) results"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This report presents the results of the 2006 PASCAL Visual Object Classes Challenge (VOC2006)."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2141732326"
                        ],
                        "name": "Jianguo Zhang",
                        "slug": "Jianguo-Zhang",
                        "structuredName": {
                            "firstName": "Jianguo",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianguo Zhang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 54
                            }
                        ],
                        "text": "The results of The Pascal Challenge from 2005 to 2008 [12] and the recent research [8, 13, 15, 28, 18, 21] indicate that sliding window classifiers are presently the predominant method being used in object detection, or more specifically, human detection, due to their good performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 63925014,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "0ec48ac86456cea3d6d6172ca81ef68e98b21a61",
            "isKey": false,
            "numCitedBy": 3322,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-PASCAL-Visual-Object-Classes-Challenge-Zhang",
            "title": {
                "fragments": [],
                "text": "The PASCAL Visual Object Classes Challenge"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 24,
            "methodology": 16,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 34,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/An-HOG-LBP-human-detector-with-partial-occlusion-Wang-Han/bd9446d2b61139867662442147d81181e84ab4f2?sort=total-citations"
}