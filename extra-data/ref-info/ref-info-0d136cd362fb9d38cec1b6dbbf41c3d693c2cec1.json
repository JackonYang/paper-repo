{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50785579"
                        ],
                        "name": "N. Friedman",
                        "slug": "N.-Friedman",
                        "structuredName": {
                            "firstName": "Nir",
                            "lastName": "Friedman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Friedman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770007"
                        ],
                        "name": "M. Goldszmidt",
                        "slug": "M.-Goldszmidt",
                        "structuredName": {
                            "firstName": "Mois\u00e9s",
                            "lastName": "Goldszmidt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Goldszmidt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 34
                            }
                        ],
                        "text": "We refer the interested reader to Friedman & Goldszmidt (1996) and Koller & Sahami (1996) for more details\nOur algorithm, called KDB, is supplied with both a database of pre-classi ed instances, DB, and the k value for the maximum allowable degree of feature dependence."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 0
                            }
                        ],
                        "text": "Friedman & Goldszmidt (1996) have also developed an algorithm, named TAN, which is similar to Geiger's method for inducing conditional trees."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8544653,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cbea68b4fca4e095e2dc93031877c1855c683de9",
            "isKey": false,
            "numCitedBy": 236,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent work in supervised learning has shown that a surprisingly simple Bayesian classifier with strong assumptions of independence among features, called naive Bayes, is competitive with state of the art classifiers such as C4.5. This fact raises the question of whether a classifier with less restrictive assumptions can perform even better. In this paper we examine and evaluate approaches for inducing classifiers from data, based on recent results in the theory of learning Bayesian networks. Bayesian networks are factored representations of probability distributions that generalize the naive Bayes classifier and explicitly represent statements about independence. Among these approaches we single out a method we call Tree Augmented Naive Bayes (TAN), which outperforms naive Bayes, yet at the same time maintains the computational simplicity (no search involved) and robustness which are characteristic of naive Bayes. We experimentally tested these approaches using benchmark problems from the U. C. Irvine repository, and compared them against C4.5, naive Bayes, and wrapper-based feature selection methods."
            },
            "slug": "Building-Classifiers-Using-Bayesian-Networks-Friedman-Goldszmidt",
            "title": {
                "fragments": [],
                "text": "Building Classifiers Using Bayesian Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Tree Augmented Naive Bayes (TAN) is single out, which outperforms naive Bayes, yet at the same time maintains the computational simplicity and robustness which are characteristic of naive Baye."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI, Vol. 2"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694780"
                        ],
                        "name": "M. Pazzani",
                        "slug": "M.-Pazzani",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Pazzani",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pazzani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 237,
                                "start": 225
                            }
                        ],
                        "text": "Thus we present an alternative to the general trend in Bayesian network learning algorithms which do an expensive search through the space of network structures (Heckerman, Geiger, & Chickering 1995) or feature dependencies (Pazzani 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 20
                            }
                        ],
                        "text": "Moreover, we wanted to see if we could uncover various levels of dependencies that we know exist in a few arti cial domains by seeing how classi cation accuracy varied with the value of k."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17119891,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "09eec628ca1d377b4b1878f912411ebba5e82651",
            "isKey": false,
            "numCitedBy": 228,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Naive Bayesian classifiers which make independence assumptions perform remarkably well on some data sets but poorly on others. We explore ways to improve the Bayesian classifier by searching for dependencies among attributes. We propose and evaluate two algorithms for detecting dependencies among attributes and show that the backward sequential elimination and joining algorithm provides the most improvement over the naive Bayesian classifier. The domains on which the most improvement occurs are those domains on which the naive Bayesian classifier is significantly less accurate than a decision tree learner. This suggests that the attributes used in some common databases are not independent conditioned on the class and that the violations of the independence assumption that affect the accuracy of the classifier can be detected from training data."
            },
            "slug": "Searching-for-Dependencies-in-Bayesian-Classifiers-Pazzani",
            "title": {
                "fragments": [],
                "text": "Searching for Dependencies in Bayesian Classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that the backward sequential elimination and joining algorithm provides the most improvement over the naive Bayesian classifier and that the violations of the independence assumption that affect the accuracy of the classifier can be detected from training data."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736370"
                        ],
                        "name": "D. Koller",
                        "slug": "D.-Koller",
                        "structuredName": {
                            "firstName": "Daphne",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Koller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764547"
                        ],
                        "name": "M. Sahami",
                        "slug": "M.-Sahami",
                        "structuredName": {
                            "firstName": "Mehran",
                            "lastName": "Sahami",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sahami"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 67
                            }
                        ],
                        "text": "We refer the interested reader to Friedman & Goldszmidt (1996) and Koller & Sahami (1996) for more details\nOur algorithm, called KDB, is supplied with both a database of pre-classi ed instances, DB, and the k value for the maximum allowable degree of feature dependence."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1455429,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5ed4e1dbe10c0ac9fa00b30d1882cae1249a5a6a",
            "isKey": false,
            "numCitedBy": 1746,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we examine a method for feature subset selection based on Information Theory. Initially, a framework for defining the theoretically optimal, but computationally intractable, method for feature subset selection is presented. We show that our goal should be to eliminate a feature if it gives us little or no additional information beyond that subsumed by the remaining features. In particular, this will be the case for both irrelevant and redundant features. We then give an efficient algorithm for feature selection which computes an approximation to the optimal feature selection criterion. The conditions under which the approximate algorithm is successful are examined. Empirical results are given on a number of data sets, showing that the algorithm effectively handles datasets with a very large number of features."
            },
            "slug": "Toward-Optimal-Feature-Selection-Koller-Sahami",
            "title": {
                "fragments": [],
                "text": "Toward Optimal Feature Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "An efficient algorithm for feature selection which computes an approximation to the optimal feature selection criterion is given, showing that the algorithm effectively handles datasets with a very large number of features."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143986204"
                        ],
                        "name": "I. Kononenko",
                        "slug": "I.-Kononenko",
                        "structuredName": {
                            "firstName": "Igor",
                            "lastName": "Kononenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Kononenko"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 103
                            }
                        ],
                        "text": "The computational e ciency of this classier has made it the benefactor of a number of research e orts (Kononenko 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1590400,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "343115f687957110e56dfdf430a65ee4490a77ab",
            "isKey": false,
            "numCitedBy": 374,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "In the paper the algorithm of the 'naive' Bayesian classifier (that assumes the independence of attributes) is extended to detect the dependencies between attributes. The idea is to optimize the tradeoff between the 'non-naivety' and the reliability of approximations of probabilities. Experiments in four medical diagnostic problems are described. In two domains where by the experts opinion the attributes are in fact independent the semi- naive Bayesian classifier achieved the same classification accuracy as naive Bayes. In two other domains the semi-naive Bayesian classifier slightly outperformed the naive Bayesian classifier."
            },
            "slug": "Semi-Naive-Bayesian-Classifier-Kononenko",
            "title": {
                "fragments": [],
                "text": "Semi-Naive Bayesian Classifier"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "The algorithm of the 'naive' Bayesian classifier (that assumes the independence of attributes) is extended to detect the dependencies between attributes to optimize the tradeoff between the 'non-naivety' and the reliability of approximations of probabilities."
            },
            "venue": {
                "fragments": [],
                "text": "EWSL"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70219052"
                        ],
                        "name": "Wray L. Buntine",
                        "slug": "Wray-L.-Buntine",
                        "structuredName": {
                            "firstName": "Wray",
                            "lastName": "Buntine",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wray L. Buntine"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 102
                            }
                        ],
                        "text": "Recently, work in Bayesian methods for classi cation has grown enormously (Cooper & Herskovits 1992) (Buntine 1994)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 11672931,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa7a32d9ce76cd016cf21d4f956e19d90e87b0dc",
            "isKey": false,
            "numCitedBy": 654,
            "numCiting": 143,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper is a multidisciplinary review of empirical, statistical learning from a graphical model perspective. Well-known examples of graphical models include Bayesian networks, directed graphs representing a Markov chain, and undirected networks representing a Markov field. These graphical models are extended to model data analysis and empirical learning using the notation of plates. Graphical operations for simplifying and manipulating a problem are provided including decomposition, differentiation, andthe manipulation of probability models from the exponential family. Two standard algorithm schemas for learning are reviewed in a graphical framework: Gibbs sampling and the expectation maximizationalgorithm. Using these operations and schemas, some popular algorithms can be synthesized from their graphical specification. This includes versions of linear regression, techniques for feed-forward networks, and learning Gaussian and discrete Bayesian networks from data. The paper concludes by sketching some implications for data analysis and summarizing how some popular algorithms fall within the framework presented. The main original contributions here are the decompositiontechniques and the demonstration that graphical models provide a framework for understanding and developing complex learning algorithms."
            },
            "slug": "Operations-for-Learning-with-Graphical-Models-Buntine",
            "title": {
                "fragments": [],
                "text": "Operations for Learning with Graphical Models"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The main original contributions here are the decompositiontechniques and the demonstration that graphical models provide a framework for understanding and developing complex learning algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif. Intell. Res."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144527211"
                        ],
                        "name": "D. Geiger",
                        "slug": "D.-Geiger",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Geiger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geiger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 201
                            }
                        ],
                        "text": "Thus we present an alternative to the general trend in Bayesian network learning algorithms which do an expensive search through the space of network structures (Heckerman, Geiger, & Chickering 1995) or feature dependencies (Pazzani 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 0
                            }
                        ],
                        "text": "Geiger (1992) has de ned the related notion of a conditional dependence tree."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1568101,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "70fe236bdc5071ffd3b13bf518946702c9ba6895",
            "isKey": false,
            "numCitedBy": 73,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-Entropy-based-Learning-Algorithm-of-Bayesian-Geiger",
            "title": {
                "fragments": [],
                "text": "An Entropy-based Learning Algorithm of Bayesian Conditional Trees"
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3227241"
                        ],
                        "name": "K. Ezawa",
                        "slug": "K.-Ezawa",
                        "structuredName": {
                            "firstName": "Kazuo",
                            "lastName": "Ezawa",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Ezawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1949559"
                        ],
                        "name": "Til Schuermann",
                        "slug": "Til-Schuermann",
                        "structuredName": {
                            "firstName": "Til",
                            "lastName": "Schuermann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Til Schuermann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 35
                            }
                        ],
                        "text": "We have recently become aware that Ezawa & Schuermann (1995) also have an algorithm similar in avor to ours, but with some important di erences, which attempts to discover feature dependencies directly using mutual information, as opposed to employing a general search for network structure."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1256074,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8571adee5c0eb341b71e024f7ff5f12f61d65716",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "The fraud/uncollectible debt problem in the telecommunications industry presents two technical challenges: the detection and the treatment of the account given the detection. In this paper, we focus on the first problem of detection using Bayesian network models, and we briefly discuss the application of a normative expert system for the treatment at the end. We apply Bayesian network models to the problem of fraud/uncollectible debt detection for telecommunication services. In addition to being quite successful at predicting rare event outcomes, it is able to handle a mixture of categorical and continuous data. We present a performance comparison using linear and non-linear discriminant analysis, classification and regression trees, and Bayesian network models."
            },
            "slug": "Fraud/Uncollectible-Debt-Detection-Using-a-Bayesian-Ezawa-Schuermann",
            "title": {
                "fragments": [],
                "text": "Fraud/Uncollectible Debt Detection Using a Bayesian Network Based Learning System: A Rare Binary Outcome with Mixed Data Structures"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This paper applies Bayesian network models to the problem of fraud/uncollectible debt detection for telecommunication services and presents a performance comparison using linear and non-linear discriminant analysis, classification and regression trees, and Bayesiannetwork models."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 123
                            }
                        ],
                        "text": "1The question becomes one of determining if the model has allowed for enough dependencies to represent the Markov Blanket (Pearl 1988) of each feature."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 19
                            }
                        ],
                        "text": "Bayesian networks (Pearl 1988) have long been a popular medium for graphically representing the probabilistic dependencies which exist in a domain."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 32583695,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "70ef29e6f0ce082bb8a47fd85b9bfb7cc0f20c93",
            "isKey": false,
            "numCitedBy": 18219,
            "numCiting": 230,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nProbabilistic Reasoning in Intelligent Systems is a complete andaccessible account of the theoretical foundations and computational methods that underlie plausible reasoning under uncertainty. The author provides a coherent explication of probability as a language for reasoning with partial belief and offers a unifying perspective on other AI approaches to uncertainty, such as the Dempster-Shafer formalism, truth maintenance systems, and nonmonotonic logic. The author distinguishes syntactic and semantic approaches to uncertainty\u0097and offers techniques, based on belief networks, that provide a mechanism for making semantics-based systems operational. Specifically, network-propagation techniques serve as a mechanism for combining the theoretical coherence of probability theory with modern demands of reasoning-systems technology: modular declarative inputs, conceptually meaningful inferences, and parallel distributed computation. Application areas include diagnosis, forecasting, image interpretation, multi-sensor fusion, decision support systems, plan recognition, planning, speech recognition\u0097in short, almost every task requiring that conclusions be drawn from uncertain clues and incomplete information. \nProbabilistic Reasoning in Intelligent Systems will be of special interest to scholars and researchers in AI, decision theory, statistics, logic, philosophy, cognitive psychology, and the management sciences. Professionals in the areas of knowledge-based systems, operations research, engineering, and statistics will find theoretical and computational tools of immediate practical use. The book can also be used as an excellent text for graduate-level courses in AI, operations research, or applied probability."
            },
            "slug": "Probabilistic-reasoning-in-intelligent-systems-of-Pearl",
            "title": {
                "fragments": [],
                "text": "Probabilistic reasoning in intelligent systems - networks of plausible inference"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The author provides a coherent explication of probability as a language for reasoning with partial belief and offers a unifying perspective on other AI approaches to uncertainty, such as the Dempster-Shafer formalism, truth maintenance systems, and nonmonotonic logic."
            },
            "venue": {
                "fragments": [],
                "text": "Morgan Kaufmann series in representation and reasoning"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2932960"
                        ],
                        "name": "Ross D. Shachter",
                        "slug": "Ross-D.-Shachter",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Shachter",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross D. Shachter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 40
                            }
                        ],
                        "text": "It is insightful to apply arc reversal (Shachter 1986) to the network in Figure 1(a) to produce the equivalent dependence structure in Figure 1(b)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5770960,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9e0daca0acc6ee3baf7573fe2e2b3cc94276e7f4",
            "isKey": false,
            "numCitedBy": 1287,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "An influence diagram is a graphical structure for modeling uncertain variables and decisions and explicitly revealing probabilistic dependence and the flow of information. It is an intuitive framework in which to formulate problems as perceived by decision makers and to incorporate the knowledge of experts. At the same time, it is a precise description of information that can be stored and manipulated by a computer. We develop an algorithm that can evaluate any well-formed influence diagram and determine the optimal policy for its decisions. Since the diagram can be analyzed directly, there is no need to construct other representations such as a decision tree. As a result, the analysis can be performed using the decision maker's perspective on the problem. Questions of sensitivity and the value of information are natural and easily posed. Modifications to the model suggested by such analyses can be made directly to the problem formulation, and then evaluated directly."
            },
            "slug": "Evaluating-Influence-Diagrams-Shachter",
            "title": {
                "fragments": [],
                "text": "Evaluating Influence Diagrams"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An algorithm is developed that can evaluate any well-formed influence diagram and determine the optimal policy for its decisions and can be performed using the decision maker's perspective on the problem."
            },
            "venue": {
                "fragments": [],
                "text": "Oper. Res."
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145298005"
                        ],
                        "name": "Catherine Blake",
                        "slug": "Catherine-Blake",
                        "structuredName": {
                            "firstName": "Catherine",
                            "lastName": "Blake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Catherine Blake"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 54
                            }
                        ],
                        "text": "We tested KDB on ve datasets from the UCI repository (Murphy & Aha 1995) as well as a text classication domain with many features (a small subset of the Reuters Text database (Reuters 1995))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62622768,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e068be31ded63600aea068eacd12931efd2a1029",
            "isKey": false,
            "numCitedBy": 13446,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "UCI-Repository-of-machine-learning-databases-Blake",
            "title": {
                "fragments": [],
                "text": "UCI Repository of machine learning databases"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52024479"
                        ],
                        "name": "B. M. Hill",
                        "slug": "B.-M.-Hill",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "Hill",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. M. Hill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145179124"
                        ],
                        "name": "I. Good",
                        "slug": "I.-Good",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Good",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Good"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 64
                            }
                        ],
                        "text": "A particularly restrictive model, the Naive Bayesian classi er (Good 1965), has had a longer history as a simple, yet powerful classi cation technique."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61353144,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "52c80779f47d3c4edd5e37ebe7d341b378c3a5d7",
            "isKey": false,
            "numCitedBy": 631,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Estimation-of-Probabilities:-An-Essay-on-Modern-Hill-Good",
            "title": {
                "fragments": [],
                "text": "The Estimation of Probabilities: An Essay on Modern Bayesian Methods"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1965
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 34
                            }
                        ],
                        "text": "We refer the interested reader to Friedman & Goldszmidt (1996) and Koller & Sahami (1996) for more details\nOur algorithm, called KDB, is supplied with both a database of pre-classi ed instances, DB, and the k value for the maximum allowable degree of feature dependence."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 0
                            }
                        ],
                        "text": "Friedman & Goldszmidt (1996) have also developed an algorithm, named TAN, which is similar to Geiger's method for inducing conditional trees."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Building classi ers using bayesian networks"
            },
            "venue": {
                "fragments": [],
                "text": "AAAI-96."
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fraud/uncollectible debt detection using a bayesian network learning system"
            },
            "venue": {
                "fragments": [],
                "text": "UAI-95"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 103
                            }
                        ],
                        "text": "The computational e ciency of this classier has made it the benefactor of a number of research e orts (Kononenko 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Semi-naive b a y esian classiier"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Sixth European Working Session on Learning"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 0
                            }
                        ],
                        "text": "Alternatively, the Naive Bayesian classifer, while very e cient for inference, makes very strong independence assumptions that are often violated in practice and can lead to poor predictive generalization."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Probabilistic inference using belief networks is NP-Hard Fraud/uncollectible debt detection using a bayesian network learning system"
            },
            "venue": {
                "fragments": [],
                "text": "UAI-95"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Workshop on AI and Statistics"
            },
            "venue": {
                "fragments": [],
                "text": "Workshop on AI and Statistics"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 46
                            }
                        ],
                        "text": "Now, we can see that the true complexity in such an unrestricted model (i.e. no independencies) comes from the large number of feature dependence arcs which are present in the model."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 40
                            }
                        ],
                        "text": "It is insightful to apply arc reversal (Shachter 1986) to the network in Figure 1(a) to produce the equivalent dependence structure in Figure 1(b)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Evaluating innuence diagrams"
            },
            "venue": {
                "fragments": [],
                "text": "Operations Research"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 40
                            }
                        ],
                        "text": "It is insightful to apply arc reversal (Shachter 1986) to the network in Figure 1(a) to produce the equivalent dependence structure in Figure 1(b)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Evaluating in uence diagrams"
            },
            "venue": {
                "fragments": [],
                "text": "Operations Research"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 64
                            }
                        ],
                        "text": "A particularly restrictive model, the Naive Bayesian classi er (Good 1965), has had a longer history as a simple, yet powerful classi cation technique."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Estimation of Probabilities"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1965
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 114
                            }
                        ],
                        "text": "Introduction Recently, work in Bayesian methods for classi cation has grown enormously (Cooper & Herskovits 1992) (Buntine 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 102
                            }
                        ],
                        "text": "Recently, work in Bayesian methods for classi cation has grown enormously (Cooper & Herskovits 1992) (Buntine 1994)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Operations for learning with"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 34
                            }
                        ],
                        "text": "We refer the interested reader to Friedman & Goldszmidt (1996) and Koller & Sahami (1996) for more details\nOur algorithm, called KDB, is supplied with both a database of pre-classi ed instances, DB, and the k value for the maximum allowable degree of feature dependence."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 0
                            }
                        ],
                        "text": "Friedman & Goldszmidt (1996) have also developed an algorithm, named TAN, which is similar to Geiger's method for inducing conditional trees."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Buildingclassi ers using bayesian networks"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 35
                            }
                        ],
                        "text": "We have recently become aware that Ezawa & Schuermann (1995) also have an algorithm similar in avor to ours, but with some important di erences, which attempts to discover feature dependencies directly using mutual information, as opposed to employing a general search for network structure."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fraud / uncollectible debt detection using a bayesian network learning system"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 0
                            }
                        ],
                        "text": "Geiger (1992) has de ned the related notion of a conditional dependence tree."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An entropy-based learning algorithm"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fraudduncollectible debt detection using a bayesian network learning system"
            },
            "venue": {
                "fragments": [],
                "text": "UAI-95"
            },
            "year": 1577
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 78
                            }
                        ],
                        "text": "Moreover, inference in such unrestricted models has been shown to be NP-hard (Cooper 1987)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Probabilistic inference using"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 34
                            }
                        ],
                        "text": "We refer the interested reader to Friedman & Goldszmidt (1996) and Koller & Sahami (1996) for more details\nOur algorithm, called KDB, is supplied with both a database of pre-classi ed instances, DB, and the k value for the maximum allowable degree of feature dependence."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 0
                            }
                        ],
                        "text": "Friedman & Goldszmidt (1996) have also developed an algorithm, named TAN, which is similar to Geiger's method for inducing conditional trees."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Building classiiers using bayesian networks"
            },
            "venue": {
                "fragments": [],
                "text": "AAAI-96"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 215,
                                "start": 191
                            }
                        ],
                        "text": "It has only been in the past few years, however, that this framework has been employed with the goal of automatically learning the graphical structure of such a network from a store of data (Cooper & Herskovits 1992) (Heckerman, Geiger, & Chickering 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 75
                            }
                        ],
                        "text": "Recently, work in Bayesian methods for classi cation has grown enormously (Cooper & Herskovits 1992) (Buntine 1994)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A bayesianmethod for the induction of probabilistic networksfrom data"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 176
                            }
                        ],
                        "text": "We tested KDB on ve datasets from the UCI repository (Murphy & Aha 1995) as well as a text classication domain with many features (a small subset of the Reuters Text database (Reuters 1995))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Reuters document collection. ftp: ciir-ftp"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 123
                            }
                        ],
                        "text": "1The question becomes one of determining if the model has allowed for enough dependencies to represent the Markov Blanket (Pearl 1988) of each feature."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 19
                            }
                        ],
                        "text": "Bayesian networks (Pearl 1988) have long been a popular medium for graphically representing the probabilistic dependencies which exist in a domain."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Probabilistic Reasoning in Intelligent"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Operations for learning withgraphical models"
            },
            "venue": {
                "fragments": [],
                "text": "JAIR"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 176
                            }
                        ],
                        "text": "We tested KDB on ve datasets from the UCI repository (Murphy & Aha 1995) as well as a text classication domain with many features (a small subset of the Reuters Text database (Reuters 1995))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Reuters document collection"
            },
            "venue": {
                "fragments": [],
                "text": "Reuters document collection"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 67
                            }
                        ],
                        "text": "We refer the interested reader to Friedman & Goldszmidt (1996) and Koller & Sahami (1996) for more details\nOur algorithm, called KDB, is supplied with both a database of pre-classi ed instances, DB, and the k value for the maximum allowable degree of feature dependence."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Toward optimalfeature selection"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 237,
                                "start": 225
                            }
                        ],
                        "text": "Thus we present an alternative to the general trend in Bayesian network learning algorithms which do an expensive search through the space of network structures (Heckerman, Geiger, & Chickering 1995) or feature dependencies (Pazzani 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Searching for dependencies"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 35
                            }
                        ],
                        "text": "We have recently become aware that Ezawa & Schuermann (1995) also have an algorithm similar in avor to ours, but with some important di erences, which attempts to discover feature dependencies directly using mutual information, as opposed to employing a general search for network structure."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fraud / uncollectible debt detection using a bayesiannetwork learning system"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 78
                            }
                        ],
                        "text": "Moreover, inference in such unrestricted models has been shown to be NP-hard (Cooper 1987)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Probabilistic inference using belief networks is NP-Hard"
            },
            "venue": {
                "fragments": [],
                "text": "Probabilistic inference using belief networks is NP-Hard"
            },
            "year": 1987
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 12,
            "methodology": 21
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 35,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Learning-Limited-Dependence-Bayesian-Classifiers-Sahami/0d136cd362fb9d38cec1b6dbbf41c3d693c2cec1?sort=total-citations"
}