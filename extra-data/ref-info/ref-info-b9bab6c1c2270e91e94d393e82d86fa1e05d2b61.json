{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144973459"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144768792"
                        ],
                        "name": "Yihong Gong",
                        "slug": "Yihong-Gong",
                        "structuredName": {
                            "firstName": "Yihong",
                            "lastName": "Gong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yihong Gong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743808"
                        ],
                        "name": "S. Smoliar",
                        "slug": "S.-Smoliar",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Smoliar",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Smoliar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153635925"
                        ],
                        "name": "Shuang Yeo Tan",
                        "slug": "Shuang-Yeo-Tan",
                        "structuredName": {
                            "firstName": "Shuang",
                            "lastName": "Tan",
                            "middleNames": [
                                "Yeo"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shuang Yeo Tan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 35961225,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "05edc783def10174ca1d9952deb444f1e1c5baa1",
            "isKey": false,
            "numCitedBy": 207,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Video content parsing is possible when one has an a priori model of a video's structure based on domain knowledge. This paper presents work on using domain knowledge to parse content of news video programs. Approaches to locating and identifying frame structure models based on temporal and spatial structure of news video data, along with algorithms to apply these models in parsing news video, have been developed and are presented in detail in this paper. Experimental results are also discussed in detail to evaluate the approaches and algorithms. Finally, proposals for future work are summarized.<<ETX>>"
            },
            "slug": "Automatic-parsing-of-news-video-Zhang-Gong",
            "title": {
                "fragments": [],
                "text": "Automatic parsing of news video"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Approaches to locating and identifying frame structure models based on temporal and spatial structure of news video data, along with algorithms to apply these models in parsing news video, have been developed and are presented in detail in this paper."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE International Conference on Multimedia Computing and Systems"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36066491"
                        ],
                        "name": "Tong Zhang",
                        "slug": "Tong-Zhang",
                        "structuredName": {
                            "firstName": "Tong",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tong Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9363144"
                        ],
                        "name": "C.-C. Jay Kuo",
                        "slug": "C.-C.-Jay-Kuo",
                        "structuredName": {
                            "firstName": "C.-C.",
                            "lastName": "Kuo",
                            "middleNames": [
                                "Jay"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C.-C. Jay Kuo"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62219340,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c8e52675539c964f39fc64243819964e029bfa06",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "While previous research on audiovisual data segmentation and indexing primarily focuses on the pictorial part, significant clues contained in the accompanying audio flow are often ignored. A fully functional system for video content parsing can be achieved more successfully through a proper combination of audio and visual information. By investigating the data structure of different video types, we present tools for both audio and visual content analysis and a scheme for video segmentation and annotation in this research. In the proposed system, video data are segmented into audio scenes and visual shots by detecting abrupt changes in audio and visual features, respectively. Then, the audio scene is categorized and indexed as one of the basic audio types while a visual shot is presented by keyframes and associate image features. An index table is then generated automatically for each video clip based on the integration of outputs from audio and visual analysis. It is shown that the proposed system provides satisfying video indexing results."
            },
            "slug": "Video-content-parsing-based-on-combined-audio-and-Zhang-Kuo",
            "title": {
                "fragments": [],
                "text": "Video content parsing based on combined audio and visual information"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "By investigating the data structure of different video types, tools for both audio and visual content analysis and a scheme for video segmentation and annotation are presented and it is shown that the proposed system provides satisfying video indexing results."
            },
            "venue": {
                "fragments": [],
                "text": "Optics East"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7661726"
                        ],
                        "name": "Alexander Hauptmann",
                        "slug": "Alexander-Hauptmann",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Hauptmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexander Hauptmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116645662"
                        ],
                        "name": "Michael Smith",
                        "slug": "Michael-Smith",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Smith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 36119549,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "02e95ad680fc3b216a11181638ef5d31f66f423a",
            "isKey": false,
            "numCitedBy": 118,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe three technologies involved in creating a digital video library suitable for fullcontent search and retrieval. Image processing analyzes scenes, speech processing transcribes the audio signal, and natural language processing determines word relevance. The integration of these technologies enables us to include vast amounts of video data in the library."
            },
            "slug": "Text,-Speech,-and-Vision-for-Video-Segmentation:-Hauptmann-Smith",
            "title": {
                "fragments": [],
                "text": "Text, Speech, and Vision for Video Segmentation: The InformediaTM Project"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "Three technologies involved in creating a digital video library suitable for fullcontent search and retrieval are described: image processing analyzes scenes, speech processing transcribes the audio signal, and natural language processing determines word relevance."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2719487"
                        ],
                        "name": "J. Boreczky",
                        "slug": "J.-Boreczky",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Boreczky",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Boreczky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144115507"
                        ],
                        "name": "L. Wilcox",
                        "slug": "L.-Wilcox",
                        "structuredName": {
                            "firstName": "Lynn",
                            "lastName": "Wilcox",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Wilcox"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17684339,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "16109d5c9d61a36dfcd499a1faeda15baf8d47ec",
            "isKey": false,
            "numCitedBy": 246,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a technique for segmenting video using hidden Markov models (HMM). Video is segmented into regions defined by shots, shot boundaries, and camera movement within shots. Features for segmentation include an image-based distance between adjacent video frames, an audio distance based on the acoustic difference in intervals just before and after the frames, and an estimate of motion between the two frames. Typical video segmentation algorithms classify shot boundaries by computing an image-based distance between adjacent frames and comparing this distance to fixed, manually determined thresholds. Motion and audio information is used separately. In contrast, our segmentation technique allows features to be combined within the HMM framework. Further, thresholds are not required since automatically trained HMMs take their place. This algorithm has been tested on a video data base, and has been shown to improve the accuracy of video segmentation over standard threshold-based systems."
            },
            "slug": "A-hidden-Markov-model-framework-for-video-using-and-Boreczky-Wilcox",
            "title": {
                "fragments": [],
                "text": "A hidden Markov model framework for video segmentation using audio and image features"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "This technique for segmenting video using hidden Markov models (HMM) has been tested on a video data base, and has been shown to improve the accuracy of video segmentation over standard threshold-based systems."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 1998 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP '98 (Cat. No.98CH36181)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46772671"
                        ],
                        "name": "Xiangrong Chen",
                        "slug": "Xiangrong-Chen",
                        "structuredName": {
                            "firstName": "Xiangrong",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiangrong Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108698841"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In such cases, extracting text information directly from image sequence plays a key role in news video content analysis, which often referred as video OCR .F or this purpose, another important component of our news parsing and browsing system is automated video OCR [3,  7 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We developed a fast and robust video OCR algorithm [ 7 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 39497408,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "950933213eac28c7f5a665e760e2e8f3f6d62e95",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Text area detection from video frame is an essential step for Video OCR. The key problem is the complex background of the video frames. This paper proposes a novel approach to this problem. First, we use the vertical edge information to detect candidate text areas. The horizontal edge information is then used to eliminate some of the false candidates. Finally, shape suppression technique is applied to further refine the results. Experimental results have shown the proposed approach is very effective in text area detection."
            },
            "slug": "Text-Area-Detection-from-Video-Frames-Chen-Zhang",
            "title": {
                "fragments": [],
                "text": "Text Area Detection from Video Frames"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A novel approach that uses the vertical edge information to detect candidate text areas and the horizontal edge information is used to eliminate some of the false candidates in text area detection."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Pacific Rim Conference on Multimedia"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728602"
                        ],
                        "name": "S. Dumais",
                        "slug": "S.-Dumais",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "Dumais",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dumais"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189092"
                        ],
                        "name": "John C. Platt",
                        "slug": "John-C.-Platt",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Platt",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John C. Platt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1934343"
                        ],
                        "name": "David Hecherman",
                        "slug": "David-Hecherman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hecherman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Hecherman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764547"
                        ],
                        "name": "M. Sahami",
                        "slug": "M.-Sahami",
                        "structuredName": {
                            "firstName": "Mehran",
                            "lastName": "Sahami",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sahami"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 617436,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "02adea3455cd7b09e1dac9ddf2637a1e7ae84005",
            "isKey": false,
            "numCitedBy": 1291,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "1. ABSTRACT Text categorization \u2013 the assignment of natural language texts to one or more predefined categories based on their content \u2013 is an important component in many information organization and management tasks. We compare the effectiveness of five different automatic learning algorithms for text categorization in terms of learning speed, realtime classification speed, and classification accuracy. We also examine training set size, and alternative document representations. Very accurate text classifiers can be learned automatically from training examples. Linear Support Vector Machines (SVMs) are particularly promising because they are very accurate, quick to train, and quick to evaluate. 1.1"
            },
            "slug": "Inductive-learning-algorithms-and-representations-Dumais-Platt",
            "title": {
                "fragments": [],
                "text": "Inductive learning algorithms and representations for text categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A comparison of the effectiveness of five different automatic learning algorithms for text categorization in terms of learning speed, realtime classification speed, and classification accuracy is compared."
            },
            "venue": {
                "fragments": [],
                "text": "CIKM '98"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2413848"
                        ],
                        "name": "B. Shahraray",
                        "slug": "B.-Shahraray",
                        "structuredName": {
                            "firstName": "Behzad",
                            "lastName": "Shahraray",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Shahraray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2387879"
                        ],
                        "name": "D. Gibbon",
                        "slug": "D.-Gibbon",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Gibbon",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gibbon"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5224918,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dcf83f7c59600adc5cab55f2a56a52ff445d7230",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Automated-authoring-of-hypermedia-documents-of-Shahraray-Gibbon",
            "title": {
                "fragments": [],
                "text": "Automated authoring of hypermedia documents of video programs"
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '95"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 137
                            }
                        ],
                        "text": "The test on hours of CNN news video shows that accuracy of the clustering based news segmentation approach as described above achieve close to 98%[6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Audio content analysis in video structure analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Audio content analysis in video structure analysis"
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 1,
            "methodology": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 8,
        "totalPages": 1
    },
    "page_url": "https://www.semanticscholar.org/paper/Integrating-visual,-audio-and-text-analysis-for-Qi-Gu/b9bab6c1c2270e91e94d393e82d86fa1e05d2b61?sort=total-citations"
}