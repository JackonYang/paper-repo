{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143865718"
                        ],
                        "name": "V. Ferrari",
                        "slug": "V.-Ferrari",
                        "structuredName": {
                            "firstName": "Vittorio",
                            "lastName": "Ferrari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Ferrari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10004927,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "461d2c494d0353834c54f13e74cc80cd56dbe365",
            "isKey": false,
            "numCitedBy": 443,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a probabilistic generative model of visual attributes, together with an efficient learning algorithm. Attributes are visual qualities of objects, such as 'red', 'striped', or 'spotted'. The model sees attributes as patterns of image segments, repeatedly sharing some characteristic properties. These can be any combination of appearance, shape, or the layout of segments within the pattern. Moreover, attributes with general appearance are taken into account, such as the pattern of alternation of any two colors which is characteristic for stripes. To enable learning from unsegmented training images, the model is learnt discriminatively, by optimizing a likelihood ratio. \n \nAs demonstrated in the experimental evaluation, our model can learn in a weakly supervised setting and encompasses a broad range of attributes. We show that attributes can be learnt starting from a text query to Google image search, and can then be used to recognize the attribute and determine its spatial extent in novel real-world images."
            },
            "slug": "Learning-Visual-Attributes-Ferrari-Zisserman",
            "title": {
                "fragments": [],
                "text": "Learning Visual Attributes"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that attributes can be learnt starting from a text query to Google image search, and can then be used to recognize the attribute and determine its spatial extent in novel real-world images."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2096527"
                        ],
                        "name": "G. Wang",
                        "slug": "G.-Wang",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16140390,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb4362bd6f0bc5bb467fc8f169723243caa97d1d",
            "isKey": false,
            "numCitedBy": 174,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method to learn visual attributes (eg.\u201cred\u201d, \u201cmetal\u201d, \u201cspotted\u201d) and object classes (eg. \u201ccar\u201d, \u201cdress\u201d, \u201cumbrella\u201d) together. We assume images are labeled with category, but not location, of an instance. We estimate models with an iterative procedure: the current model is used to produce a saliency score, which, together with a homogeneity cue, identifies likely locations for the object (resp. attribute); then those locations are used to produce better models with multiple instance learning. Crucially, the object and attribute models must agree on the potential locations of an object. This means that the more accurate of the two models can guide the improvement of the less accurate model. Our method is evaluated on two data sets of images of real scenes, one in which the attribute is color and the other in which it is material. We show that our joint learning produces improved detectors. We demonstrate generalization by detecting attribute-object pairs which do not appear in our training data. The iteration gives significant improvement in performance."
            },
            "slug": "Joint-learning-of-visual-attributes,-object-classes-Wang-Forsyth",
            "title": {
                "fragments": [],
                "text": "Joint learning of visual attributes, object classes and visual saliency"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "A method to learn visual attributes and object classes together and shows that the more accurate of the two models can guide the improvement of the less accurate model."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1787591"
                        ],
                        "name": "Christoph H. Lampert",
                        "slug": "Christoph-H.-Lampert",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Lampert",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christoph H. Lampert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748758"
                        ],
                        "name": "H. Nickisch",
                        "slug": "H.-Nickisch",
                        "structuredName": {
                            "firstName": "Hannes",
                            "lastName": "Nickisch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Nickisch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734990"
                        ],
                        "name": "S. Harmeling",
                        "slug": "S.-Harmeling",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Harmeling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Harmeling"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10301835,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0566bf06a0368b518b8b474166f7b1dfef3f9283",
            "isKey": false,
            "numCitedBy": 1951,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the problem of object classification when training and test classes are disjoint, i.e. no training examples of the target classes are available. This setup has hardly been studied in computer vision research, but it is the rule rather than the exception, because the world contains tens of thousands of different object classes and for only a very few of them image, collections have been formed and annotated with suitable class labels. In this paper, we tackle the problem by introducing attribute-based classification. It performs object detection based on a human-specified high-level description of the target objects instead of training images. The description consists of arbitrary semantic attributes, like shape, color or even geographic information. Because such properties transcend the specific learning task at hand, they can be pre-learned, e.g. from image datasets unrelated to the current task. Afterwards, new classes can be detected based on their attribute representation, without the need for a new training phase. In order to evaluate our method and to facilitate research in this area, we have assembled a new large-scale dataset, \u201cAnimals with Attributes\u201d, of over 30,000 animal images that match the 50 classes in Osherson's classic table of how strongly humans associate 85 semantic attributes with animal classes. Our experiments show that by using an attribute layer it is indeed possible to build a learning object detection system that does not require any training images of the target classes."
            },
            "slug": "Learning-to-detect-unseen-object-classes-by-Lampert-Nickisch",
            "title": {
                "fragments": [],
                "text": "Learning to detect unseen object classes by between-class attribute transfer"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The experiments show that by using an attribute layer it is indeed possible to build a learning object detection system that does not require any training images of the target classes, and assembled a new large-scale dataset, \u201cAnimals with Attributes\u201d, of over 30,000 animal images that match the 50 classes in Osherson's classic table of how strongly humans associate 85 semantic attributes with animal classes."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143787583"
                        ],
                        "name": "Ali Farhadi",
                        "slug": "Ali-Farhadi",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Farhadi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ali Farhadi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2831988"
                        ],
                        "name": "Ian Endres",
                        "slug": "Ian-Endres",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Endres",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ian Endres"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433269"
                        ],
                        "name": "Derek Hoiem",
                        "slug": "Derek-Hoiem",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Hoiem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Hoiem"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14171860,
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology"
            ],
            "id": "5d33a10752af9ea30993139ac6e3a323992a5831",
            "isKey": false,
            "numCitedBy": 212,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose an approach to find and describe objects within broad domains. We introduce a new dataset that provides annotation for sharing models of appearance and correlation across categories. We use it to learn part and category detectors. These serve as the visual basis for an integrated model of objects. We describe objects by the spatial arrangement of their attributes and the interactions between them. Using this model, our system can find animals and vehicles that it has not seen and infer attributes, such as function and pose. Our experiments demonstrate that we can more reliably locate and describe both familiar and unfamiliar objects, compared to a baseline that relies purely on basic category detectors."
            },
            "slug": "Attribute-centric-recognition-for-cross-category-Farhadi-Endres",
            "title": {
                "fragments": [],
                "text": "Attribute-centric recognition for cross-category generalization"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This work introduces a new dataset that provides annotation for sharing models of appearance and correlation across categories and uses it to learn part and category detectors that serve as the visual basis for an integrated model of objects."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685089"
                        ],
                        "name": "Pedro F. Felzenszwalb",
                        "slug": "Pedro-F.-Felzenszwalb",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Felzenszwalb",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pedro F. Felzenszwalb"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145689002"
                        ],
                        "name": "David A. McAllester",
                        "slug": "David-A.-McAllester",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "McAllester",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David A. McAllester"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770537"
                        ],
                        "name": "D. Ramanan",
                        "slug": "D.-Ramanan",
                        "structuredName": {
                            "firstName": "Deva",
                            "lastName": "Ramanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ramanan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14327585,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "860a9d55d87663ca88e74b3ca357396cd51733d0",
            "isKey": false,
            "numCitedBy": 2616,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a discriminatively trained, multiscale, deformable part model for object detection. Our system achieves a two-fold improvement in average precision over the best performance in the 2006 PASCAL person detection challenge. It also outperforms the best results in the 2007 challenge in ten out of twenty categories. The system relies heavily on deformable parts. While deformable part models have become quite popular, their value had not been demonstrated on difficult benchmarks such as the PASCAL challenge. Our system also relies heavily on new methods for discriminative training. We combine a margin-sensitive approach for data mining hard negative examples with a formalism we call latent SVM. A latent SVM, like a hidden CRF, leads to a non-convex training problem. However, a latent SVM is semi-convex and the training problem becomes convex once latent information is specified for the positive examples. We believe that our training methods will eventually make possible the effective use of more latent information such as hierarchical (grammar) models and models involving latent three dimensional pose."
            },
            "slug": "A-discriminatively-trained,-multiscale,-deformable-Felzenszwalb-McAllester",
            "title": {
                "fragments": [],
                "text": "A discriminatively trained, multiscale, deformable part model"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "A discriminatively trained, multiscale, deformable part model for object detection, which achieves a two-fold improvement in average precision over the best performance in the 2006 PASCAL person detection challenge and outperforms the best results in the 2007 challenge in ten out of twenty categories."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143787583"
                        ],
                        "name": "Ali Farhadi",
                        "slug": "Ali-Farhadi",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Farhadi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ali Farhadi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2831988"
                        ],
                        "name": "Ian Endres",
                        "slug": "Ian-Endres",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Endres",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ian Endres"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433269"
                        ],
                        "name": "Derek Hoiem",
                        "slug": "Derek-Hoiem",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Hoiem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Hoiem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14940757,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c6a8aef1bf134294482d8088f982d5643347d2ff",
            "isKey": false,
            "numCitedBy": 1665,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose to shift the goal of recognition from naming to describing. Doing so allows us not only to name familiar objects, but also: to report unusual aspects of a familiar object (\u201cspotty dog\u201d, not just \u201cdog\u201d); to say something about unfamiliar objects (\u201chairy and four-legged\u201d, not just \u201cunknown\u201d); and to learn how to recognize new objects with few or no visual examples. Rather than focusing on identity assignment, we make inferring attributes the core problem of recognition. These attributes can be semantic (\u201cspotty\u201d) or discriminative (\u201cdogs have it but sheep do not\u201d). Learning attributes presents a major new challenge: generalization across object categories, not just across instances within a category. In this paper, we also introduce a novel feature selection method for learning attributes that generalize well across categories. We support our claims by thorough evaluation that provides insights into the limitations of the standard recognition paradigm of naming and demonstrates the new abilities provided by our attribute-based framework."
            },
            "slug": "Describing-objects-by-their-attributes-Farhadi-Endres",
            "title": {
                "fragments": [],
                "text": "Describing objects by their attributes"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "This paper proposes to shift the goal of recognition from naming to describing, and introduces a novel feature selection method for learning attributes that generalize well across categories."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46396571"
                        ],
                        "name": "Yang Wang",
                        "slug": "Yang-Wang",
                        "structuredName": {
                            "firstName": "Yang",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yang Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10771328"
                        ],
                        "name": "Greg Mori",
                        "slug": "Greg-Mori",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Mori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Greg Mori"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 938625,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b0f54c8595fd4da87f9b5d5f1948d346d22e9415",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new method for classification with structured latent variables. Our model is formulated using the max-margin formalism in the discriminative learning literature. We propose an efficient learning algorithm based on the cutting plane method and decomposed dual optimization. We apply our model to the problem of recognizing human actions from video sequences, where we model a human action as a global root template and a constellation of several \u201cparts\u201d. We show that our model outperforms another similar method that uses hidden conditional random fields, and is comparable to other state-of-the-art approaches. More importantly, our proposed work is quite general and can potentially be applied in a wide variety of vision problems that involve various complex, interdependent latent structures."
            },
            "slug": "Max-margin-hidden-conditional-random-fields-for-Wang-Mori",
            "title": {
                "fragments": [],
                "text": "Max-margin hidden conditional random fields for human action recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This work proposes an efficient learning algorithm based on the cutting plane method and decomposed dual optimization for classification with structured latent variables that outperforms another similar method that uses hidden conditional random fields, and is comparable to other state-of-the-art approaches."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2096527"
                        ],
                        "name": "G. Wang",
                        "slug": "G.-Wang",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433269"
                        ],
                        "name": "Derek Hoiem",
                        "slug": "Derek-Hoiem",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Hoiem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Hoiem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6315634,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4d99b1ce531b47b9be9d3958cc58ed56bd9c8b20",
            "isKey": false,
            "numCitedBy": 77,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a text-based image feature and demonstrate that it consistently improves performance on hard object classification problems. The feature is built using an auxiliary dataset of images annotated with tags, downloaded from the Internet. We do not inspect or correct the tags and expect that they are noisy. We obtain the text feature of an unannotated image from the tags of its k-nearest neighbors in this auxiliary collection. A visual classifier presented with an object viewed under novel circumstances (say, a new viewing direction) must rely on its visual examples. Our text feature may not change, because the auxiliary dataset likely contains a similar picture. While the tags associated with images are noisy, they are more stable when appearance changes. We test the performance of this feature using PASCAL VOC 2006 and 2007 datasets. Our feature performs well, consistently improves the performance of visual object classifiers, and is particularly effective when the training dataset is small."
            },
            "slug": "Building-text-features-for-object-image-Wang-Hoiem",
            "title": {
                "fragments": [],
                "text": "Building text features for object image classification"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A text-based image feature is introduced and it is demonstrated that it consistently improves performance on hard object classification problems, and is particularly effective when the training dataset is small."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2000950"
                        ],
                        "name": "D. Vaquero",
                        "slug": "D.-Vaquero",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Vaquero",
                            "middleNames": [
                                "Andr\u00e9"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Vaquero"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723233"
                        ],
                        "name": "R. Feris",
                        "slug": "R.-Feris",
                        "structuredName": {
                            "firstName": "Rog\u00e9rio",
                            "lastName": "Feris",
                            "middleNames": [
                                "Schmidt"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Feris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2828154"
                        ],
                        "name": "Duan Tran",
                        "slug": "Duan-Tran",
                        "structuredName": {
                            "firstName": "Duan",
                            "lastName": "Tran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Duan Tran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49860655"
                        ],
                        "name": "L. Brown",
                        "slug": "L.-Brown",
                        "structuredName": {
                            "firstName": "Lisa",
                            "lastName": "Brown",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690709"
                        ],
                        "name": "A. Hampapur",
                        "slug": "A.-Hampapur",
                        "structuredName": {
                            "firstName": "Arun",
                            "lastName": "Hampapur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hampapur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144097660"
                        ],
                        "name": "M. Turk",
                        "slug": "M.-Turk",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Turk",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Turk"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12446691,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "58b0be2db0aeda2edb641273fe52946a24a714c3",
            "isKey": false,
            "numCitedBy": 214,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel framework for searching for people in surveillance environments. Rather than relying on face recognition technology, which is known to be sensitive to typical surveillance conditions such as lighting changes, face pose variation, and low-resolution imagery, we approach the problem in a different way: we search for people based on a parsing of human parts and their attributes, including facial hair, eyewear, clothing color, etc. These attributes can be extracted using detectors learned from large amounts of training data. A complete system that implements our framework is presented. At the interface, the user can specify a set of personal characteristics, and the system then retrieves events that match the provided description. For example, a possible query is \u201cshow me the bald people who entered a given building last Saturday wearing a red shirt and sunglasses.\u201d This capability is useful in several applications, such as finding suspects or missing people. To evaluate the performance of our approach, we present extensive experiments on a set of images collected from the Internet, on infrared imagery, and on two-and-a-half months of video from a real surveillance environment. We are not aware of any similar surveillance system capable of automatically finding people in video based on their fine-grained body parts and attributes."
            },
            "slug": "Attribute-based-people-search-in-surveillance-Vaquero-Feris",
            "title": {
                "fragments": [],
                "text": "Attribute-based people search in surveillance environments"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "A novel framework for searching for people in surveillance environments based on a parsing of human parts and their attributes, including facial hair, eyewear, clothing color, etc, which can be extracted using detectors learned from large amounts of training data is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "2009 Workshop on Applications of Computer Vision (WACV)"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144996078"
                        ],
                        "name": "Neeraj Kumar",
                        "slug": "Neeraj-Kumar",
                        "structuredName": {
                            "firstName": "Neeraj",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Neeraj Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39668247"
                        ],
                        "name": "A. Berg",
                        "slug": "A.-Berg",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Berg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767767"
                        ],
                        "name": "P. Belhumeur",
                        "slug": "P.-Belhumeur",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Belhumeur",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Belhumeur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750470"
                        ],
                        "name": "S. Nayar",
                        "slug": "S.-Nayar",
                        "structuredName": {
                            "firstName": "Shree",
                            "lastName": "Nayar",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nayar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3136364,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d3046251ec5d6e7f90ef5ef2b0ac885c01138555",
            "isKey": false,
            "numCitedBy": 1479,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We present two novel methods for face verification. Our first method - \u201cattribute\u201d classifiers - uses binary classifiers trained to recognize the presence or absence of describable aspects of visual appearance (e.g., gender, race, and age). Our second method - \u201csimile\u201d classifiers - removes the manual labeling required for attribute classification and instead learns the similarity of faces, or regions of faces, to specific reference people. Neither method requires costly, often brittle, alignment between image pairs; yet, both methods produce compact visual descriptions, and work on real-world images. Furthermore, both the attribute and simile classifiers improve on the current state-of-the-art for the LFW data set, reducing the error rates compared to the current best by 23.92% and 26.34%, respectively, and 31.68% when combined. For further testing across pose, illumination, and expression, we introduce a new data set - termed PubFig - of real-world images of public figures (celebrities and politicians) acquired from the internet. This data set is both larger (60,000 images) and deeper (300 images per individual) than existing data sets of its kind. Finally, we present an evaluation of human performance."
            },
            "slug": "Attribute-and-simile-classifiers-for-face-Kumar-Berg",
            "title": {
                "fragments": [],
                "text": "Attribute and simile classifiers for face verification"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "Two novel methods for face verification using binary classifiers trained to recognize the presence or absence of describable aspects of visual appearance and a new data set of real-world images of public figures acquired from the internet."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40277674"
                        ],
                        "name": "C. Desai",
                        "slug": "C.-Desai",
                        "structuredName": {
                            "firstName": "Chaitanya",
                            "lastName": "Desai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Desai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770537"
                        ],
                        "name": "D. Ramanan",
                        "slug": "D.-Ramanan",
                        "structuredName": {
                            "firstName": "Deva",
                            "lastName": "Ramanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ramanan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143800213"
                        ],
                        "name": "Charless C. Fowlkes",
                        "slug": "Charless-C.-Fowlkes",
                        "structuredName": {
                            "firstName": "Charless",
                            "lastName": "Fowlkes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charless C. Fowlkes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9620297,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "45496e8f03c43e94d23c0f0587e7da0ea35d408f",
            "isKey": false,
            "numCitedBy": 116,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We advocate an approach to activity recognition based on modeling contextual interactions between postured human bodies and nearby objects. We focus on the difficult task of recognizing actions from static images and formulate the problem as a latent structured labeling problem. We develop a unified, discriminative model for such context-based action recognition building on recent techniques for learning large-scale discriminative models. The resulting contextual models learned by our system outperform previously published results on a database of sports actions."
            },
            "slug": "Discriminative-models-for-static-human-object-Desai-Ramanan",
            "title": {
                "fragments": [],
                "text": "Discriminative models for static human-object interactions"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A unified, discriminative model is developed for context-based action recognition based on modeling contextual interactions between postured human bodies and nearby objects, which outperform previously published results on a database of sports actions."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Workshops"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056091"
                        ],
                        "name": "M. Everingham",
                        "slug": "M.-Everingham",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Everingham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Everingham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145715698"
                        ],
                        "name": "Christopher K. I. Williams",
                        "slug": "Christopher-K.-I.-Williams",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Williams",
                            "middleNames": [
                                "K.",
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher K. I. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33652486"
                        ],
                        "name": "J. Winn",
                        "slug": "J.-Winn",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Winn",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Winn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4246903,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "82635fb63640ae95f90ee9bdc07832eb461ca881",
            "isKey": false,
            "numCitedBy": 11694,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "The Pascal Visual Object Classes (VOC) challenge is a benchmark in visual object category recognition and detection, providing the vision and machine learning communities with a standard dataset of images and annotation, and standard evaluation procedures. Organised annually from 2005 to present, the challenge and its associated dataset has become accepted as the benchmark for object detection.This paper describes the dataset and evaluation procedure. We review the state-of-the-art in evaluated methods for both classification and detection, analyse whether the methods are statistically different, what they are learning from the images (e.g. the object or its context), and what the methods find easy or confuse. The paper concludes with lessons learnt in the three year history of the challenge, and proposes directions for future improvement and extension."
            },
            "slug": "The-Pascal-Visual-Object-Classes-(VOC)-Challenge-Everingham-Gool",
            "title": {
                "fragments": [],
                "text": "The Pascal Visual Object Classes (VOC) Challenge"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The state-of-the-art in evaluated methods for both classification and detection are reviewed, whether the methods are statistically different, what they are learning from the images, and what the methods find easy or confuse."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49230687"
                        ],
                        "name": "Weilong Yang",
                        "slug": "Weilong-Yang",
                        "structuredName": {
                            "firstName": "Weilong",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Weilong Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46396571"
                        ],
                        "name": "Yang Wang",
                        "slug": "Yang-Wang",
                        "structuredName": {
                            "firstName": "Yang",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yang Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10771328"
                        ],
                        "name": "Greg Mori",
                        "slug": "Greg-Mori",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Mori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Greg Mori"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14211475,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c93fcbc5512a4634a557f420bcfad4caa313c470",
            "isKey": false,
            "numCitedBy": 220,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of recognizing human actions from still images. We propose a novel approach that treats the pose of the person in the image as latent variables that will help with recognition. Different from other work that learns separate systems for pose estimation and action recognition, then combines them in an ad-hoc fashion, our system is trained in an integrated fashion that jointly considers poses and actions. Our learning objective is designed to directly exploit the pose information for action recognition. Our experimental results demonstrate that by inferring the latent poses, we can improve the final action recognition results."
            },
            "slug": "Recognizing-human-actions-from-still-images-with-Yang-Wang",
            "title": {
                "fragments": [],
                "text": "Recognizing human actions from still images with latent poses"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "This work proposes a novel approach that treats the pose of the person in the image as latent variables that will help with recognition, and shows that by inferring the latent poses, it can improve the final action recognition results."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2272096"
                        ],
                        "name": "Guo-Jun Qi",
                        "slug": "Guo-Jun-Qi",
                        "structuredName": {
                            "firstName": "Guo-Jun",
                            "lastName": "Qi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guo-Jun Qi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143863244"
                        ],
                        "name": "Xiansheng Hua",
                        "slug": "Xiansheng-Hua",
                        "structuredName": {
                            "firstName": "Xiansheng",
                            "lastName": "Hua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiansheng Hua"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145459057"
                        ],
                        "name": "Y. Rui",
                        "slug": "Y.-Rui",
                        "structuredName": {
                            "firstName": "Yong",
                            "lastName": "Rui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Rui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8053308"
                        ],
                        "name": "Jinhui Tang",
                        "slug": "Jinhui-Tang",
                        "structuredName": {
                            "firstName": "Jinhui",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jinhui Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144025741"
                        ],
                        "name": "Tao Mei",
                        "slug": "Tao-Mei",
                        "structuredName": {
                            "firstName": "Tao",
                            "lastName": "Mei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tao Mei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108698841"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13044872,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ae11fe0736e1fed743b6ad389d3843c6d682a27d",
            "isKey": false,
            "numCitedBy": 475,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatically annotating concepts for video is a key to semantic-level video browsing, search and navigation. The research on this topic evolved through two paradigms. The first paradigm used binary classification to detect each individual concept in a concept set. It achieved only limited success, as it did not model the inherent correlation between concepts, e.g., urban and building. The second paradigm added a second step on top of the individual concept detectors to fuse multiple concepts. However, its performance varies because the errors incurred in the first detection step can propagate to the second fusion step and therefore degrade the overall performance. To address the above issues, we propose a third paradigm which simultaneously classifies concepts and models correlations between them in a single step by using a novel Correlative Multi-Label (CML) framework. We compare the performance between our proposed approach and the state-of-the-art approaches in the first and second paradigms on the widely used TRECVID data set. We report superior performance from the proposed approach."
            },
            "slug": "Correlative-multi-label-video-annotation-Qi-Hua",
            "title": {
                "fragments": [],
                "text": "Correlative multi-label video annotation"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A third paradigm is proposed which simultaneously classifies concepts and models correlations between them in a single step by using a novel Correlative Multi-Label (CML) framework and is compared with the state-of-the-art approaches in the first and second paradigms on the widely used TRECVID data set."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Multimedia"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3171632"
                        ],
                        "name": "A. Quattoni",
                        "slug": "A.-Quattoni",
                        "structuredName": {
                            "firstName": "Ariadna",
                            "lastName": "Quattoni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Quattoni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108648318"
                        ],
                        "name": "Sy Bor Wang",
                        "slug": "Sy-Bor-Wang",
                        "structuredName": {
                            "firstName": "Sy",
                            "lastName": "Wang",
                            "middleNames": [
                                "Bor"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sy Bor Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49933077"
                        ],
                        "name": "Louis-Philippe Morency",
                        "slug": "Louis-Philippe-Morency",
                        "structuredName": {
                            "firstName": "Louis-Philippe",
                            "lastName": "Morency",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Louis-Philippe Morency"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13298437,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c29f33e3d13a6447ea0ece36cf5add5f5e32fab2",
            "isKey": false,
            "numCitedBy": 556,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a discriminative latent variable model for classification problems in structured domains where inputs can be represented by a graph of local observations. A hidden-state conditional random field framework learns a set of latent variables conditioned on local features. Observations need not be independent and may overlap in space and time."
            },
            "slug": "Hidden-Conditional-Random-Fields-Quattoni-Wang",
            "title": {
                "fragments": [],
                "text": "Hidden Conditional Random Fields"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "A discriminative latent variable model for classification problems in structured domains where inputs can be represented by a graph of local observations and a hidden-state conditional random field framework learns a set of latent variables conditioned on local features."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2828154"
                        ],
                        "name": "Duan Tran",
                        "slug": "Duan-Tran",
                        "structuredName": {
                            "firstName": "Duan",
                            "lastName": "Tran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Duan Tran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13902758,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "35570297681daa3973498eabead361d0be961672",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Fair discriminative pedestrian finders are now available. In fact, these pedestrian finders make most errors on pedestrians in configurations that are uncommon in the training data, for example, mounting a bicycle. This is undesirable. However, the human configuration can itself be estimated discriminatively using structure learning. We demonstrate a pedestrian finder which first finds the most likely human pose in the window using a discriminative procedure trained with structure learning on a small dataset. We then present features (local histogram of oriented gradient and local PCA of gradient) based on that configuration to an SVM classifier. We show, using the INRIA Person dataset, that estimates of configuration significantly improve the accuracy of a discriminative pedestrian finder."
            },
            "slug": "Configuration-Estimates-Improve-Pedestrian-Finding-Tran-Forsyth",
            "title": {
                "fragments": [],
                "text": "Configuration Estimates Improve Pedestrian Finding"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown, using the INRIA Person dataset, that estimates of configuration significantly improve the accuracy of a discriminative pedestrian finder."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696931"
                        ],
                        "name": "H. Barrow",
                        "slug": "H.-Barrow",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Barrow",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Barrow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144592244"
                        ],
                        "name": "J. Tenenbaum",
                        "slug": "J.-Tenenbaum",
                        "structuredName": {
                            "firstName": "Jay",
                            "lastName": "Tenenbaum",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tenenbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14892007,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bd580fad7a14f93d6d59765a5fe91974e2653281",
            "isKey": false,
            "numCitedBy": 922,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We suggest that an appropriate role of early visual processing is to describe a scene in terms of intrinsic (vertical) characteristics -- such as range, orientation, reflectance, and incident illumination -- of the surface element visible at each point in the image. Support for this idea comes from three sources: the obvious utility of intrinsic characteristics for higher-level scene analysis; the apparent ability of humans to determine these characteristics, regardless of viewing conditions or familiarity with the scene; and a theoretical argument that such a description is obtainable, by a noncognitive and nonpurposive process, at least, for simple scene domains. The central problem in recovering intrinsic scene characteristics is that the information is confounded in the original light-intensity image: a single intensity value encodes all the characteristics of the corresponding scene point. Recovery depends on exploiting constraints, derived from assumptions about the nature of the scene and the physics of the imaging process."
            },
            "slug": "RECOVERING-INTRINSIC-SCENE-CHARACTERISTICS-FROM-Barrow-Tenenbaum",
            "title": {
                "fragments": [],
                "text": "RECOVERING INTRINSIC SCENE CHARACTERISTICS FROM IMAGES"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "It is suggested that an appropriate role of early visual processing is to describe a scene in terms of intrinsic (vertical) characteristics -- such as range, orientation, reflectance, and incident illumination -- of the surface element visible at each point in the image."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2413711"
                        ],
                        "name": "M. Ranjbar",
                        "slug": "M.-Ranjbar",
                        "structuredName": {
                            "firstName": "Mani",
                            "lastName": "Ranjbar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ranjbar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10771328"
                        ],
                        "name": "Greg Mori",
                        "slug": "Greg-Mori",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Mori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Greg Mori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46396571"
                        ],
                        "name": "Yang Wang",
                        "slug": "Yang-Wang",
                        "structuredName": {
                            "firstName": "Yang",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yang Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10585394,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1858573a93399fbb785b9fcc1e8fb38f70af6932",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we develop an algorithm for structured prediction that optimizes against complex performance measures, those which are a function of false positive and false negative counts. The approach can be directly applied to performance measures such as F\u03b2 score (natural language processing), intersection over union (image segmentation), Precision/Recall at k (search engines) and ROC area (binary classifiers). We attack this optimization problem by approximating the loss function with a piecewise linear function and relaxing the obtained QP problem to a LP which we solve with an off-the-shelf LP solver. We present experiments on object class-specific segmentation and show significant improvement over baseline approaches that either use simple loss functions or simple compatibility functions on VOC 2009."
            },
            "slug": "Optimizing-Complex-Loss-Functions-in-Structured-Ranjbar-Mori",
            "title": {
                "fragments": [],
                "text": "Optimizing Complex Loss Functions in Structured Prediction"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "An algorithm for structured prediction that optimizes against complex performance measures, those which are a function of false positive and false negative counts, which is directly applied to performance measures such as F\u03b2 score, intersection over union, Precision/Recall at k, and ROC area."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685978"
                        ],
                        "name": "B. Taskar",
                        "slug": "B.-Taskar",
                        "structuredName": {
                            "firstName": "Ben",
                            "lastName": "Taskar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Taskar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388317459"
                        ],
                        "name": "S. Lacoste-Julien",
                        "slug": "S.-Lacoste-Julien",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Lacoste-Julien",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lacoste-Julien"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14842644,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7669c8e2edb9409dec9911ff20a5ba2d53d48ac0",
            "isKey": false,
            "numCitedBy": 123,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a simple and scalable algorithm for maximum-margin estimation of structured output models, including an important class of Markov networks and combinatorial models. We formulate the estimation problem as a convex-concave saddle-point problem that allows us to use simple projection methods based on the dual extragradient algorithm (Nesterov, 2003). The projection step can be solved using dynamic programming or combinatorial algorithms for min-cost convex flow, depending on the structure of the problem. We show that this approach provides a memory-efficient alternative to formulations based on reductions to a quadratic program (QP). We analyze the convergence of the method and present experiments on two very different structured prediction tasks: 3D image segmentation and word alignment, illustrating the favorable scaling properties of our algorithm."
            },
            "slug": "Structured-Prediction,-Dual-Extragradient-and-Taskar-Lacoste-Julien",
            "title": {
                "fragments": [],
                "text": "Structured Prediction, Dual Extragradient and Bregman Projections"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "A simple and scalable algorithm for maximum-margin estimation of structured output models, including an important class of Markov networks and combinatorial models, based on the dual extragradient algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5649543"
                        ],
                        "name": "T. Do",
                        "slug": "T.-Do",
                        "structuredName": {
                            "firstName": "Trinh",
                            "lastName": "Do",
                            "middleNames": [
                                "Minh",
                                "Tri"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Do"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7364123"
                        ],
                        "name": "T. Arti\u00e8res",
                        "slug": "T.-Arti\u00e8res",
                        "structuredName": {
                            "firstName": "Thierry",
                            "lastName": "Arti\u00e8res",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Arti\u00e8res"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14133156,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "803abe8ba1aa314cc85ba01f4312a8a417933483",
            "isKey": false,
            "numCitedBy": 119,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Large margin learning of Continuous Density HMMs with a partially labeled dataset has been extensively studied in the speech and handwriting recognition fields. Yet due to the non-convexity of the optimization problem, previous works usually rely on severe approximations so that it is still an open problem. We propose a new learning algorithm that relies on non-convex optimization and bundle methods and allows tackling the original optimization problem as is. It is proved to converge to a solution with accuracy \u03b5 with a rate O (1/\u03b5). We provide experimental results gained on speech and handwriting recognition that demonstrate the potential of the method."
            },
            "slug": "Large-margin-training-for-hidden-Markov-models-with-Do-Arti\u00e8res",
            "title": {
                "fragments": [],
                "text": "Large margin training for hidden Markov models with partially observed states"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A new learning algorithm that relies on non-convex optimization and bundle methods and allows tackling the original optimization problem as is is proposed and proved to converge to a solution with accuracy \u03b5 with a rate O (1/\u03b5)."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '09"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1115550,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "175c1bb60ee46dac56d942ef8c7339977b4ebb0e",
            "isKey": false,
            "numCitedBy": 845,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a Support Vector Method for optimizing multivariate nonlinear performance measures like the F1-score. Taking a multivariate prediction approach, we give an algorithm with which such multivariate SVMs can be trained in polynomial time for large classes of potentially non-linear performance measures, in particular ROCArea and all measures that can be computed from the contingency table. The conventional classification SVM arises as a special case of our method."
            },
            "slug": "A-support-vector-method-for-multivariate-measures-Joachims",
            "title": {
                "fragments": [],
                "text": "A support vector method for multivariate performance measures"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "An algorithm with which such multivariate SVMs can be trained in polynomial time for large classes of potentially non-linear performance measures, in particular ROCArea and all measures that can be computed from the contingency table are given."
            },
            "venue": {
                "fragments": [],
                "text": "K\u00fcnstliche Intell."
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102636025"
                        ],
                        "name": "C. Chow",
                        "slug": "C.-Chow",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Chow",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Chow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2119394814"
                        ],
                        "name": "C. N. Liu",
                        "slug": "C.-N.-Liu",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Liu",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. N. Liu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 27127853,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "683fe3bbf2b2e628cf40d90e35fb39effc63b7e9",
            "isKey": false,
            "numCitedBy": 2729,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "A method is presented to approximate optimally an n -dimensional discrete probability distribution by a product of second-order distributions, or the distribution of the first-order tree dependence. The problem is to find an optimum set of n - 1 first order dependence relationship among the n variables. It is shown that the procedure derived in this paper yields an approximation of a minimum difference in information. It is further shown that when this procedure is applied to empirical observations from an unknown distribution of tree dependence, the procedure is the maximum-likelihood estimate of the distribution."
            },
            "slug": "Approximating-discrete-probability-distributions-Chow-Liu",
            "title": {
                "fragments": [],
                "text": "Approximating discrete probability distributions with dependence trees"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "It is shown that the procedure derived in this paper yields an approximation of a minimum difference in information when applied to empirical observations from an unknown distribution of tree dependence, and the procedure is the maximum-likelihood estimate of the distribution."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31338632"
                        ],
                        "name": "E. Riseman",
                        "slug": "E.-Riseman",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Riseman",
                            "middleNames": [
                                "M."
                            ],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Riseman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733922"
                        ],
                        "name": "A. Hanson",
                        "slug": "A.-Hanson",
                        "structuredName": {
                            "firstName": "Allen",
                            "lastName": "Hanson",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hanson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 202767279,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c64d7a25a406fbf6fae266dc9f04f3ce796a9873",
            "isKey": false,
            "numCitedBy": 726,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Computer-Vision-Systems-Riseman-Hanson",
            "title": {
                "fragments": [],
                "text": "Computer Vision Systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 23,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/A-Discriminative-Latent-Model-of-Object-Classes-and-Wang-Mori/fc23a386c2189f221b25dbd0bb34fcd26ccf60fa?sort=total-citations"
}