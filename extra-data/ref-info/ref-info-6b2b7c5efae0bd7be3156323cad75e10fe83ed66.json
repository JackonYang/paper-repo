{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "Tu [17] learns context cues by cascad ing models for pixel-level labeling."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 52805831,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "969be710d87f31ea323fafa0041b21a6b4cebefc",
            "isKey": false,
            "numCitedBy": 272,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "The notion of using context information for solving high-level vision problems has been increasingly realized in the field. However, how to learn an effective and efficient context model, together with the image appearance, remains mostly unknown. The current literature using Markov random fields (MRFs) and conditional random fields (CRFs) often involves specific algorithm design, in which the modeling and computing stages are studied in isolation. In this paper, we propose an auto-context algorithm. Given a set of training images and their corresponding label maps, we first learn a classifier on local image patches. The discriminative probability (or classification confidence) maps by the learned classifier are then used as context information, in addition to the original image patches, to train a new classifier. The algorithm then iterates to approach the ground truth. Auto-context learns an integrated low-level and context model, and is very general and easy to implement. Under nearly the identical parameter setting in the training, we apply the algorithm on three challenging vision applications: object segmentation, human body configuration, and scene region labeling. It typically takes about 30 ~ 70 seconds to run the algorithm in testing. Moreover, the scope of the proposed algorithm goes beyond high-level vision. It has the potential to be used for a wide variety of problems of multi-variate labeling."
            },
            "slug": "Auto-context-and-its-application-to-high-level-Tu",
            "title": {
                "fragments": [],
                "text": "Auto-context and its application to high-level vision tasks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "An auto-context algorithm that learns an integrated low-level and context model, and is very general and easy to implement, and has the potential to be used for a wide variety of problems of multi-variate labeling."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6387937,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7a2252ccce2b65abc3759149b5c06587cc318e2f",
            "isKey": false,
            "numCitedBy": 3886,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel approach to learn and recognize natural scene categories. Unlike previous work, it does not require experts to annotate the training set. We represent the image of a scene by a collection of local regions, denoted as codewords obtained by unsupervised learning. Each region is represented as part of a \"theme\". In previous work, such themes were learnt from hand-annotations of experts, while our method learns the theme distributions as well as the codewords distribution over the themes without supervision. We report satisfactory categorization performances on a large set of 13 categories of complex scenes."
            },
            "slug": "A-Bayesian-hierarchical-model-for-learning-natural-Fei-Fei-Perona",
            "title": {
                "fragments": [],
                "text": "A Bayesian hierarchical model for learning natural scene categories"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "This work proposes a novel approach to learn and recognize natural scene categories by representing the image of a scene by a collection of local regions, denoted as codewords obtained by unsupervised learning."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433269"
                        ],
                        "name": "Derek Hoiem",
                        "slug": "Derek-Hoiem",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Hoiem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Hoiem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 59
                            }
                        ],
                        "text": "In independent contemporary work, Hoiem et al. [8] propose an innovative system for integrating he tasks of object recognition, surface orientation estimation, and occlusion boundary detection."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5763563,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b7d60c907426cc69f9db7472df063c6de10f1a2d",
            "isKey": false,
            "numCitedBy": 173,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Image understanding involves analyzing many different aspects of the scene. In this paper, we are concerned with how these tasks can be combined in a way that improves the performance of each of them. Inspired by Barrow and Tenenbaum, we present a flexible framework for interfacing scene analysis processes using intrinsic images. Each intrinsic image is a registered map describing one characteristic of the scene. We apply this framework to develop an integrated 3D scene understanding system with estimates of surface orientations, occlusion boundaries, objects, camera viewpoint, and relative depth. Our experiments on a set of 300 outdoor images demonstrate that these tasks reinforce each other, and we illustrate a coherent scene understanding with automatically reconstructed 3D models."
            },
            "slug": "Closing-the-loop-in-scene-interpretation-Hoiem-Efros",
            "title": {
                "fragments": [],
                "text": "Closing the loop in scene interpretation"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper presents a flexible framework for interfacing scene analysis processes using intrinsic images, and applies this framework to develop an integrated 3D scene understanding system with estimates of surface orientations, occlusion boundaries, objects, camera viewpoint, and relative depth."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145349582"
                        ],
                        "name": "Sanjiv Kumar",
                        "slug": "Sanjiv-Kumar",
                        "structuredName": {
                            "firstName": "Sanjiv",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sanjiv Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6958332,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "83bf1e6d239dd5bc1b8f7499f7241a8802a43e22",
            "isKey": false,
            "numCitedBy": 274,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a two-layer hierarchical formulation to exploit different levels of contextual information in images for robust classification. Each layer is modeled as a conditional field that allows one to capture arbitrary observation-dependent label interactions. The proposed framework has two main advantages. First, it encodes both the short-range interactions (e.g., pixelwise label smoothing) as well as the long-range interactions (e.g., relative configurations of objects or regions) in a tractable manner. Second, the formulation is general enough to be applied to different domains ranging from pixelwise image labeling to contextual object detection. The parameters of the model are learned using a sequential maximum-likelihood approximation. The benefits of the proposed framework are demonstrated on four different datasets and comparison results are presented"
            },
            "slug": "A-hierarchical-field-framework-for-unified-Kumar-Hebert",
            "title": {
                "fragments": [],
                "text": "A hierarchical field framework for unified context-based classification"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A two-layer hierarchical formulation to exploit different levels of contextual information in images for robust classification and is general enough to be applied to different domains ranging from pixelwise image labeling to contextual object detection."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145273587"
                        ],
                        "name": "Stephen Gould",
                        "slug": "Stephen-Gould",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Gould",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen Gould"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33869638"
                        ],
                        "name": "J. Rodgers",
                        "slug": "J.-Rodgers",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Rodgers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Rodgers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115017312"
                        ],
                        "name": "David S. Cohen",
                        "slug": "David-S.-Cohen",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Cohen",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David S. Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684677"
                        ],
                        "name": "G. Elidan",
                        "slug": "G.-Elidan",
                        "structuredName": {
                            "firstName": "Gal",
                            "lastName": "Elidan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Elidan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736370"
                        ],
                        "name": "D. Koller",
                        "slug": "D.-Koller",
                        "structuredName": {
                            "firstName": "Daphne",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Koller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[7] who make use of rel ative location\u2014the preference for classes to be arranged in a consistent configuration with res pect to one another (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[7], and 3d reconstruction of Saxena et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 80
                            }
                        ],
                        "text": "This has the advantage of being able to encode scale, which was not possible in [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9779450,
            "fieldsOfStudy": [
                "Computer Science",
                "Environmental Science"
            ],
            "id": "599c8d460575ddfea702075b8ccde01b6fe987e8",
            "isKey": false,
            "numCitedBy": 432,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Multi-class image segmentation has made significant advances in recent years through the combination of local and global features. One important type of global feature is that of inter-class spatial relationships. For example, identifying \u201ctree\u201d pixels indicates that pixels above and to the sides are more likely to be \u201csky\u201d whereas pixels below are more likely to be \u201cgrass.\u201d Incorporating such global information across the entire image and between all classes is a computational challenge as it is image-dependent, and hence, cannot be precomputed.In this work we propose a method for capturing global information from inter-class spatial relationships and encoding it as a local feature. We employ a two-stage classification process to label all image pixels. First, we generate predictions which are used to compute a local relative location feature from learned relative location maps. In the second stage, we combine this with appearance-based features to provide a final segmentation. We compare our results to recent published results on several multi-class image segmentation databases and show that the incorporation of relative location information allows us to significantly outperform the current state-of-the-art."
            },
            "slug": "Multi-Class-Segmentation-with-Relative-Location-Gould-Rodgers",
            "title": {
                "fragments": [],
                "text": "Multi-Class Segmentation with Relative Location Prior"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work proposes a method for capturing global information from inter-class spatial relationships and encoding it as a local feature and shows that the incorporation of relative location information allows it to significantly outperform the current state-of-the-art."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056417995"
                        ],
                        "name": "K. Murphy",
                        "slug": "K.-Murphy",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Murphy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Murphy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[16] use context to significantly boost objec t detection performance, and Sudderth et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 606341,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a5f39edf5d270c6fd67d8a1ffeab2cc357deb118",
            "isKey": false,
            "numCitedBy": 413,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We seek to both detect and segment objects in images. To exploit both local image data as well as contextual information, we introduce Boosted Random Fields (BRFs), which uses Boosting to learn the graph structure and local evidence of a conditional random field (CRF). The graph structure is learned by assembling graph fragments in an additive model. The connections between individual pixels are not very informative, but by using dense graphs, we can pool information from large regions of the image; dense models also support efficient inference. We show how contextual information from other objects can improve detection performance, both in terms of accuracy and speed, by using a computational cascade. We apply our system to detect stuff and things in office and street scenes."
            },
            "slug": "Contextual-Models-for-Object-Detection-Using-Random-Torralba-Murphy",
            "title": {
                "fragments": [],
                "text": "Contextual Models for Object Detection Using Boosted Random Fields"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This work introduces Boosted Random Fields (BRFs), which uses Boosting to learn the graph structure and local evidence of a conditional random field (CRF) and applies it to detect stuff and things in office and street scenes."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145736680"
                        ],
                        "name": "S. Brubaker",
                        "slug": "S.-Brubaker",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Brubaker",
                            "middleNames": [
                                "Charles"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Brubaker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808816"
                        ],
                        "name": "Jianxin Wu",
                        "slug": "Jianxin-Wu",
                        "structuredName": {
                            "firstName": "Jianxin",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianxin Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46968797"
                        ],
                        "name": "Jie Sun",
                        "slug": "Jie-Sun",
                        "structuredName": {
                            "firstName": "Jie",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jie Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31562428"
                        ],
                        "name": "M. D. Mullin",
                        "slug": "M.-D.-Mullin",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Mullin",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. D. Mullin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144177248"
                        ],
                        "name": "James M. Rehg",
                        "slug": "James-M.-Rehg",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Rehg",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James M. Rehg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 152
                            }
                        ],
                        "text": "In computer vision, this idea has been very successfully applied to the task of fa ce detection using the so-called Cascade of Boosted Ensembles (CoBE) [18, 2] framework."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14879931,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b949267eaf04af99f786ab70cac352b1a0bff5a0",
            "isKey": false,
            "numCitedBy": 171,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract\nCascades of boosted ensembles have become popular in the object detection community following their highly successful introduction in the face detector of Viola and Jones. Since then, researchers have sought to improve upon the original approach by incorporating new methods along a variety of axes (e.g. alternative boosting methods, feature sets, etc.). Nevertheless, key decisions about how many hypotheses to include in an ensemble and the appropriate balance of detection and false positive rates in the individual stages are often made by user intervention or by an automatic method that produces unnecessarily slow detectors. We propose a novel method for making these decisions, which exploits the shape of the stage ROC curves in ways that have been previously ignored. The result is a detector that is significantly faster than the one produced by the standard automatic method. When this algorithm is combined with a recycling method for reusing the outputs of early stages in later ones and with a retracing method that inserts new early rejection points in the cascade, the detection speed matches that of the best hand-crafted detector. We also exploit joint distributions over several features in weak learning to improve overall detector accuracy, and explore ways to improve training time by aggressively filtering features.\n"
            },
            "slug": "On-the-Design-of-Cascades-of-Boosted-Ensembles-for-Brubaker-Wu",
            "title": {
                "fragments": [],
                "text": "On the Design of Cascades of Boosted Ensembles for Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel method is proposed for making decisions about how many hypotheses to include in an ensemble and the appropriate balance of detection and false positive rates in the individual stages, which exploits the shape of the stage ROC curves in ways that have been previously ignored."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111328101"
                        ],
                        "name": "Michael Jones",
                        "slug": "Michael-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 152
                            }
                        ],
                        "text": "In computer vision, this idea has been very successfully applied to the task of fa ce detection using the so-called Cascade of Boosted Ensembles (CoBE) [18, 2] framework."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 235084,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4cb4d685b47001652b29dc41c1b3e786277e7647",
            "isKey": false,
            "numCitedBy": 4016,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a visual object detection framework that is capable of processing images extremely rapidly while achieving high detection rates. There are three key contributions. The first is the introduction of a new image representation called the \u201cIntegral Image\u201d which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features and yields extremely efficient classifiers [4]. The third contribution is a method for combining classifiers in a \u201ccascade\u201d which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. A set of experiments in the domain of face detection are presented. The system yields face detection performance comparable to the best previous systems [16, 11, 14, 10, 1]. Implemented on a conventional desktop, face detection proceeds at 15 frames per second. Author email: fPaul.Viola,Mike.J.Jonesg@compaq.com c Compaq Computer Corporation, 2001 This work may not be copied or reproduced in whole or in part for any commercial purpose. Permission to copy in whole or in part without payment of fee is granted for nonprofit educational and research purposes provided that all such whole or partial copies include the following: a notice that such copying is by permission of the Cambridge Research Laboratory of Compaq Computer Corporation in Cambridge, Massachusetts; an acknowledgment of the authors and individual contributors to the work; and all applicable portions of the copyright notice. Copying, reproducing, or republishing for any other purpose shall require a license with payment of fee to the Cambridge Research Laboratory. All rights reserved. CRL Technical reports are available on the CRL\u2019s web page at http://crl.research.compaq.com. Compaq Computer Corporation Cambridge Research Laboratory One Cambridge Center Cambridge, Massachusetts 02142 USA"
            },
            "slug": "Robust-Real-time-Object-Detection-Viola-Jones",
            "title": {
                "fragments": [],
                "text": "Robust Real-time Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "A visual object detection framework that is capable of processing images extremely rapidly while achieving high detection rates is described, with the introduction of a new image representation called the \u201cIntegral Image\u201d which allows the features used by the detector to be computed very quickly."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799035"
                        ],
                        "name": "Erik B. Sudderth",
                        "slug": "Erik-B.-Sudderth",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Sudderth",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Erik B. Sudderth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701607"
                        ],
                        "name": "A. Willsky",
                        "slug": "A.-Willsky",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Willsky",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Willsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[14] use object recognition for 3d structure estimati on."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14305678,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2e2a35ca0fe09d96130b0cf5dfad7af083560a71",
            "isKey": false,
            "numCitedBy": 76,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop an integrated, probabilistic model for the appearance and three-dimensional geometry of cluttered scenes. Object categories are modeled via distributions over the 3D location and appearance of visual features. Uncertainty in the number of object instances depicted in a particular image is then achieved via a transformed Dirichlet process. In contrast with image-based approaches to object recognition, we model scale variations as the perspective projection of objects in different 3D poses. To calibrate the underlying geometry, we incorporate binocular stereo images into the training process. A robust likelihood model accounts for outliers in matched stereo features, allowing effective learning of 3D object structure from partial 2D segmentations. Applied to a dataset of office scenes, our model detects objects at multiple scales via a coarse reconstruction of the corresponding 3D geometry."
            },
            "slug": "Depth-from-Familiar-Objects:-A-Hierarchical-Model-Sudderth-Torralba",
            "title": {
                "fragments": [],
                "text": "Depth from Familiar Objects: A Hierarchical Model for 3D Scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "An integrated, probabilistic model for the appearance and three-dimensional geometry of cluttered scenes and a robust likelihood model accounts for outliers in matched stereo features, allowing effective learning of 3D object structure from partial 2D segmentations."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145160921"
                        ],
                        "name": "Bryan C. Russell",
                        "slug": "Bryan-C.-Russell",
                        "structuredName": {
                            "firstName": "Bryan",
                            "lastName": "Russell",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bryan C. Russell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056417995"
                        ],
                        "name": "K. Murphy",
                        "slug": "K.-Murphy",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Murphy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Murphy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1900911,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "092c275005ae49dc1303214f6d02d134457c7053",
            "isKey": false,
            "numCitedBy": 3076,
            "numCiting": 82,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract\nWe seek to build a large collection of images with ground truth labels to be used for object detection and recognition research. Such data is useful for supervised learning and quantitative evaluation. To achieve this, we developed a web-based tool that allows easy image annotation and instant sharing of such annotations. Using this annotation tool, we have collected a large dataset that spans many object categories, often containing multiple instances over a wide variety of images. We quantify the contents of the dataset and compare against existing state of the art datasets used for object recognition and detection. Also, we show how to extend the dataset to automatically enhance object labels with WordNet, discover object parts, recover a depth ordering of objects in a scene, and increase the number of labels using minimal user supervision and images from the web.\n"
            },
            "slug": "LabelMe:-A-Database-and-Web-Based-Tool-for-Image-Russell-Torralba",
            "title": {
                "fragments": [],
                "text": "LabelMe: A Database and Web-Based Tool for Image Annotation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A web-based tool that allows easy image annotation and instant sharing of such annotations is developed and a large dataset that spans many object categories, often containing multiple instances over a wide variety of images is collected."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696931"
                        ],
                        "name": "H. Barrow",
                        "slug": "H.-Barrow",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Barrow",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Barrow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144592244"
                        ],
                        "name": "J. Tenenbaum",
                        "slug": "J.-Tenenbaum",
                        "structuredName": {
                            "firstName": "Jay",
                            "lastName": "Tenenbaum",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tenenbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 35
                            }
                        ],
                        "text": "In the case of \u201cintrinsi c images\u201d [1], the output of each component is converted into an image-sized feature map (e."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 177
                            }
                        ],
                        "text": "The goal of holistic scene understanding dates back to the ea rly d ys of computer vision, and is highlighted in the \u201cintrinsic images\u201d system proposed by Ba rrow and Tenenbaum [1], where maps of various image properties (depth, reflectance, color) are computed using information present in other maps."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 163
                            }
                        ],
                        "text": "The goal of holistic scene understanding dates back to the early d ys of computer vision, and is highlighted in the \u201cintrinsic images\u201d system proposed by Barrow and Tenenbaum [1], where maps of various image properties (depth, reflectance, color) arecomputed using information present in other maps."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14892007,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bd580fad7a14f93d6d59765a5fe91974e2653281",
            "isKey": true,
            "numCitedBy": 922,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We suggest that an appropriate role of early visual processing is to describe a scene in terms of intrinsic (vertical) characteristics -- such as range, orientation, reflectance, and incident illumination -- of the surface element visible at each point in the image. Support for this idea comes from three sources: the obvious utility of intrinsic characteristics for higher-level scene analysis; the apparent ability of humans to determine these characteristics, regardless of viewing conditions or familiarity with the scene; and a theoretical argument that such a description is obtainable, by a noncognitive and nonpurposive process, at least, for simple scene domains. The central problem in recovering intrinsic scene characteristics is that the information is confounded in the original light-intensity image: a single intensity value encodes all the characteristics of the corresponding scene point. Recovery depends on exploiting constraints, derived from assumptions about the nature of the scene and the physics of the imaging process."
            },
            "slug": "RECOVERING-INTRINSIC-SCENE-CHARACTERISTICS-FROM-Barrow-Tenenbaum",
            "title": {
                "fragments": [],
                "text": "RECOVERING INTRINSIC SCENE CHARACTERISTICS FROM IMAGES"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "It is suggested that an appropriate role of early visual processing is to describe a scene in terms of intrinsic (vertical) characteristics -- such as range, orientation, reflectance, and incident illumination -- of the surface element visible at each point in the image."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056091"
                        ],
                        "name": "M. Everingham",
                        "slug": "M.-Everingham",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Everingham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Everingham"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 313,
                                "start": 310
                            }
                        ],
                        "text": "Our much larger second dataset DS2was assembled by combining 362 images from the DS1dataset (including either the segmentation or detection labels, bu t not both), 296 images from the Microsoft Research Segmentation dataset [3] (labeled with segments) , 557 images from the PASCAL VOC 2005 and 2006 challenges [5] (labeled with objects), and 534 images with ground truth depth information."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16328598,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ae0c928816d7ca1ea3213b5739db4141fed7d4b5",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1.2 Detection task For each of the four classes predict the bounding boxes of each object of that class in a test image (if any). Each bounding box should be output with an associated real-valued confidence of the detection so that a precision/recall curve can be drawn. To be considered a correct detection, the area of overlap ao between the predicted bounding box Bp and ground truth bounding box Bgt must exceed 50% by the formula: ao = area(Bp \u2229 Bgt) area(Bp \u222a Bgt) (1)"
            },
            "slug": "The-PASCAL-Visual-Object-Classes-Challenge-2005-Kit-Everingham",
            "title": {
                "fragments": [],
                "text": "The PASCAL Visual Object Classes Challenge 2005 Development Kit"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "One class predicts the bounding boxes of each object of that class in a test image (if any) and each bounding box should be output with an associated real-valued confidence of the detection so that a precision/recall curve can be drawn."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111328101"
                        ],
                        "name": "Michael Jones",
                        "slug": "Michael-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In computer vision, this idea has been very successfully applied to the task of fa ce detection using the so-called Cascade of Boosted Ensembles (CoBE) [ 18 , 2] framework."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2796017,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b09ec0b350f8352bce46a2f5bf7ae97c83a7b9ca",
            "isKey": false,
            "numCitedBy": 11229,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a face detection framework that is capable of processing images extremely rapidly while achieving high detection rates. There are three key contributions. The first is the introduction of a new image representation called the \u201cIntegral Image\u201d which allows the features used by our detector to be computed very quickly. The second is a simple and efficient classifier which is built using the AdaBoost learning algorithm (Freund and Schapire, 1995) to select a small number of critical visual features from a very large set of potential features. The third contribution is a method for combining classifiers in a \u201ccascade\u201d which allows background regions of the image to be quickly discarded while spending more computation on promising face-like regions. A set of experiments in the domain of face detection is presented. The system yields face detection performance comparable to the best previous systems (Sung and Poggio, 1998; Rowley et al., 1998; Schneiderman and Kanade, 2000; Roth et al., 2000). Implemented on a conventional desktop, face detection proceeds at 15 frames per second."
            },
            "slug": "Robust-Real-Time-Face-Detection-Viola-Jones",
            "title": {
                "fragments": [],
                "text": "Robust Real-Time Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new image representation called the \u201cIntegral Image\u201d is introduced which allows the features used by the detector to be computed very quickly and a method for combining classifiers in a \u201ccascade\u201d which allows background regions of the image to be quickly discarded while spending more computation on promising face-like regions."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48950628"
                        ],
                        "name": "N. Dalal",
                        "slug": "N.-Dalal",
                        "structuredName": {
                            "firstName": "Navneet",
                            "lastName": "Dalal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Dalal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 120
                            }
                        ],
                        "text": "For example, in our work, we build on the prior work in scene categorization of Li and Perona [10], object detection of Dalal and Triggs [4], multi-class image segmentation of Gould et al. [7], and 3d reconstruction of Saxena et al. [13]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 85
                            }
                        ],
                        "text": "Object DetectorsOur detection module builds on the HOG detector of Dalal and T riggs [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 67
                            }
                        ],
                        "text": "Object DetectorsOur detection module builds on the HOG detector of Dalal and Triggs [4]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 138
                            }
                        ],
                        "text": "For example, in our work, we build on the prior work in scene categorization of Li and Pe rona [10], object detection of Dalal and Triggs [4], multi-class image segmentation of Gould et a l."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206590483,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cec734d7097ab6b1e60d95228ffd64248eb89d66",
            "isKey": true,
            "numCitedBy": 29264,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the question of feature sets for robust visual object recognition; adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds."
            },
            "slug": "Histograms-of-oriented-gradients-for-human-Dalal-Triggs",
            "title": {
                "fragments": [],
                "text": "Histograms of oriented gradients for human detection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection, and the influence of each stage of the computation on performance is studied."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703537"
                        ],
                        "name": "Y. Freund",
                        "slug": "Y.-Freund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Freund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 9
                            }
                        ],
                        "text": "Boosting [6], in which many weak learners are combined into a highly accurate classifier, is one of the most common and powe rful such scemes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6644398,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ccf5208521cb8c35f50ee8873df89294b8ed7292",
            "isKey": false,
            "numCitedBy": 13127,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "In the first part of the paper we consider the problem of dynamically apportioning resources among a set of options in a worst-case on-line framework. The model we study can be interpreted as a broad, abstract extension of the well-studied on-line prediction model to a general decision-theoretic setting. We show that the multiplicative weight-update Littlestone?Warmuth rule can be adapted to this model, yielding bounds that are slightly weaker in some cases, but applicable to a considerably more general class of learning problems. We show how the resulting learning algorithm can be applied to a variety of problems, including gambling, multiple-outcome prediction, repeated games, and prediction of points in Rn. In the second part of the paper we apply the multiplicative weight-update technique to derive a new boosting algorithm. This boosting algorithm does not require any prior knowledge about the performance of the weak learning algorithm. We also study generalizations of the new boosting algorithm to the problem of learning functions whose range, rather than being binary, is an arbitrary finite set or a bounded segment of the real line."
            },
            "slug": "A-decision-theoretic-generalization-of-on-line-and-Freund-Schapire",
            "title": {
                "fragments": [],
                "text": "A decision-theoretic generalization of on-line learning and an application to boosting"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "The model studied can be interpreted as a broad, abstract extension of the well-studied on-line prediction model to a general decision-theoretic setting, and it is shown that the multiplicative weight-update Littlestone?Warmuth rule can be adapted to this model, yielding bounds that are slightly weaker in some cases, but applicable to a considerably more general class of learning problems."
            },
            "venue": {
                "fragments": [],
                "text": "EuroCOLT"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37210858"
                        ],
                        "name": "Charles Sutton",
                        "slug": "Charles-Sutton",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Sutton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charles Sutton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 23
                            }
                        ],
                        "text": "Foexample, the work of Sutton and McCallum [15] combines a parsing model with a semantic role labeling model into a unified probabilistic framework that solves both simultaneously."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 44
                            }
                        ],
                        "text": "Fo example, the work of Sutton and McCallum [15] combines a parsing model with a semantic role labeli ng model into a unified probabilistic framework that solves both simultaneously."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1544330,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "48b4524a3b1207157b1b2f87885c434c96fc7a19",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A striking feature of human syntactic processing is that it is context-dependent, that is, it seems to take into account semantic information from the discourse context and world knowledge. In this paper, we attempt to use this insight to bridge the gap between SRL results from gold parses and from automatically-generated parses. To do this, we jointly perform parsing and semantic role labeling, using a probabilistic SRL system to rerank the results of a probabilistic parser. Our current results are negative, because a locally-trained SRL model can return inaccurate probability estimates."
            },
            "slug": "Joint-Parsing-and-Semantic-Role-Labeling-Sutton-McCallum",
            "title": {
                "fragments": [],
                "text": "Joint Parsing and Semantic Role Labeling"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper jointly performs parsing and semantic role labeling, using a probabilistic SRL system to rerank the results of a ProbabilisticParser, because a locally-trained SRL model can return inaccurate probability estimates."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734174"
                        ],
                        "name": "M. Marcus",
                        "slug": "M.-Marcus",
                        "structuredName": {
                            "firstName": "Mitchell",
                            "lastName": "Marcus",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Marcus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2424234"
                        ],
                        "name": "Beatrice Santorini",
                        "slug": "Beatrice-Santorini",
                        "structuredName": {
                            "firstName": "Beatrice",
                            "lastName": "Santorini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Beatrice Santorini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2063206"
                        ],
                        "name": "Mary Ann Marcinkiewicz",
                        "slug": "Mary-Ann-Marcinkiewicz",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Marcinkiewicz",
                            "middleNames": [
                                "Ann"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mary Ann Marcinkiewicz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 59
                            }
                        ],
                        "text": ", the LabelMe dataset [ 12] in vision or the Penn Treebank [11] in language processing), is likely to provide large amounts of heterogeneously labeled data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 127
                            }
                        ],
                        "text": "This is appealing since the prevalence of large, volunteer-annotated datasets (e.g., the LabelMe dataset [12] in vision or the Penn Treebank [11] in language processing), is likely to provide large amounts ofheterogeneously labeled data."
                    },
                    "intents": []
                }
            ],
            "corpusId": 252796,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0b44fcbeea9415d400c5f5789d6b892b6f98daff",
            "isKey": false,
            "numCitedBy": 8177,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : As a result of this grant, the researchers have now published oil CDROM a corpus of over 4 million words of running text annotated with part-of- speech (POS) tags, with over 3 million words of that material assigned skeletal grammatical structure. This material now includes a fully hand-parsed version of the classic Brown corpus. About one half of the papers at the ACL Workshop on Using Large Text Corpora this past summer were based on the materials generated by this grant."
            },
            "slug": "Building-a-Large-Annotated-Corpus-of-English:-The-Marcus-Santorini",
            "title": {
                "fragments": [],
                "text": "Building a Large Annotated Corpus of English: The Penn Treebank"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "As a result of this grant, the researchers have now published on CDROM a corpus of over 4 million words of running text annotated with part-of- speech (POS) tags, which includes a fully hand-parsed version of the classic Brown corpus."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 0
                            }
                        ],
                        "text": "Kumar and Hebert [9], for example, develop a large MRF-based probabilistic model linking multiclass segmentation and object detection."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 17
                            }
                        ],
                        "text": "Kumar and Hebert [9], fo r example, develop a large MRF-based probabilistic model linking multiclass segmentation and o bject detection."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A hier"
            },
            "venue": {
                "fragments": [],
                "text": "field framework for unified contex  t-based classification. In  ICCV"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 95
                            }
                        ],
                        "text": "For example, in our work, we build on the prior work in scene categorization of Li and Pe rona [10], object detection of Dalal and Triggs [4], multi-class image segmentation of Gould et a l."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A bayesian hier"
            },
            "venue": {
                "fragments": [],
                "text": "model for learning natura  l scene categories. In  CVPR"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Microsoft research cambridge object recognition image database (version 1.0 and 2.0)., 2004. Available Online: http://research.microsoft.com/vision/cambridge/recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Microsoft research cambridge object recognition image database (version 1.0 and 2.0)., 2004. Available Online: http://research.microsoft.com/vision/cambridge/recognition"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 106
                            }
                        ],
                        "text": "For example, in our work, we build on the prior work in scene categorization of Li and Perona [10], object detection of Dalal and Triggs [4], multi-class image segmentation of Gould et al. [7], and 3d reconstruction of Saxena et al. [13]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A bayesian hier. model for learning natural scene categories"
            },
            "venue": {
                "fragments": [],
                "text": "CVPR"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 226,
                                "start": 223
                            }
                        ],
                        "text": "Our much larger second dataset DS2was assembled by combining 362 images from the DS1dataset (including either the segmentation or detection labels, but not both), 296 images from the Microsoft Research Segmentation dataset [3] (labeled with segments), 557 images from the PASCAL VOC 2005 and 2006 challenges [5] (labeled with objects), and 534 images with ground truth depth information."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Microsoft research cambridge object recognition image database (version 1.0 and 2.0)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 224
                            }
                        ],
                        "text": "Our much larger second dataset DS2was assembled by combining 362 images from the DS1dataset (including either the segmentation or detection labels, bu t not both), 296 images from the Microsoft Research Segmentation dataset [3] (labeled with segments) , 557 images from the PASCAL VOC 2005 and 2006 challenges [5] (labeled with objects), and 534 images with ground truth depth information."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Microsoft research cambridge object recognition imag e database (version 1.0 and 2.0)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 22
                            }
                        ],
                        "text": "Kumar and Hebert [9], for example, develop a large MRF-based probabilistic model linking multiclass segmentation and object detection."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A hier. field framework for unified context-based classification"
            },
            "venue": {
                "fragments": [],
                "text": "ICCV"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[8], which uses different components and a smaller number of object classes ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[8] propose an innovative system for integratin g he tasks of object recognition, surface orientation estimation, and occlusion boundary detection ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and M"
            },
            "venue": {
                "fragments": [],
                "text": "Hebert. Closing the loop on scene inter  pretation"
            },
            "year": 2008
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 8,
            "methodology": 14
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 25,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Cascaded-Classification-Models:-Combining-Models-Heitz-Gould/6b2b7c5efae0bd7be3156323cad75e10fe83ed66?sort=total-citations"
}