{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46597039"
                        ],
                        "name": "P. Sinha",
                        "slug": "P.-Sinha",
                        "structuredName": {
                            "firstName": "Pawan",
                            "lastName": "Sinha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sinha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 150
                            }
                        ],
                        "text": "2003; Bergboer et al., 2003; Haralick, 1983; Bileschi and Heisele, 2003), as well as statistics of low level visual features of the scene as a whole (Torralba and Sinha, 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: context, learning, streetscenes, object detection, scene understanding"
                    },
                    "intents": []
                }
            ],
            "corpusId": 9982531,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6a48c0dbff6e7fa752fdcf8ef34f8cba8202b41",
            "isKey": false,
            "numCitedBy": 202,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "There is general consensus that context can be a rich source of information about an object's identity, location and scale. However the issue of how to formalize centextual influences is still largely open. Here we introduce a simple probabilistic framework for modeling the relationship between context and object properties. We represent global context information in terms of the spatial layout of spectral components. The resulting scheme serves as an effective procedure for context driven focus of attention and scale-selection on real-world scenes. Based on a simple holistic analysis of an image, the scheme is able to accurately predict object locations and sizes."
            },
            "slug": "Statistical-context-priming-for-object-detection-Torralba-Sinha",
            "title": {
                "fragments": [],
                "text": "Statistical Context Priming for Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A simple probabilistic framework for modeling the relationship between context and object properties is introduced, representing global context information in terms of the spatial layout of spectral components and serving as an effective procedure for context driven focus of attention and scale-selection on real-world scenes."
            },
            "venue": {
                "fragments": [],
                "text": "ICCV"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724876"
                        ],
                        "name": "P. Carbonetto",
                        "slug": "P.-Carbonetto",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Carbonetto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Carbonetto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145602732"
                        ],
                        "name": "Kobus Barnard",
                        "slug": "Kobus-Barnard",
                        "structuredName": {
                            "firstName": "Kobus",
                            "lastName": "Barnard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kobus Barnard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 143
                            }
                        ],
                        "text": "\u2026loosely defined, encapsulating at once the nature of nearby objects (Murphy et al., 2003; Strat and Fischler, 1991; Hanson and Riseman, 1978; Carbonetto et al., 2004), the relative position and scale of those objects (Singhal et al., 2003; Kruppa and Schiele, 2003; Fink and Perona,\n\u2217Both\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 129
                            }
                        ],
                        "text": "Systems which pre-segment the image and then model the relationships between neighboring segments, i.e. (Kumar and Hebert, 2003; Carbonetto et al., 2004), suffer from similar issues."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 150
                            }
                        ],
                        "text": "\u2026a detector for each such object\u2019s appearance with a detector for that same object\u2019s context, we will support previous studies (Torralaba et al., 2004; Carbonetto et al., 2004) which show that, for at least the objects tested in our street-scenes database, context does aid in detection performance,\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 93
                            }
                        ],
                        "text": "Finally, it is shown that when the target object is unambiguously visible, context is only marginally useful."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 193
                            }
                        ],
                        "text": "Context is presumed to be an important cue for object detection in humans, believed to reduce processing time and to help disambiguate low quality inputs by mitigating the effect of clutter, noise and ambiguous inputs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8270758,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7925221db50d93142cb5e5a4e31d6b72b2c5af8b",
            "isKey": true,
            "numCitedBy": 315,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider object recognition as the process of attaching meaningful labels to specific regions of an image, and propose a model that learns spatial relationships between objects. Given a set of images and their associated text (e.g. keywords, captions, descriptions), the objective is to segment an image, in either a crude or sophisticated fashion, then to find the proper associations between words and regions. Previous models are limited by the scope of the representation. In particular, they fail to exploit spatial context in the images and words. We develop a more expressive model that takes this into account. We formulate a spatially consistent probabilistic mapping between continuous image feature vectors and the supplied word tokens. By learning both word-to-region associations and object relations, the proposed model augments scene segmentations due to smoothing implicit in spatial consistency. Context introduces cycles to the undirected graph, so we cannot rely on a straightforward implementation of the EM algorithm for estimating the model parameters and densities of the unknown alignment variables. Instead, we develop an approximate EM algorithm that uses loopy belief propagation in the inference step and iterative scaling on the pseudo-likelihood approximation in the parameter update step. The experiments indicate that our approximate inference and learning algorithm converges to good local solutions. Experiments on a diverse array of images show that spatial context considerably improves the accuracy of object recognition. Most significantly, spatial context combined with a nonlinear discrete object representation allows our models to cope well with over-segmented scenes."
            },
            "slug": "A-Statistical-Model-for-General-Contextual-Object-Carbonetto-Freitas",
            "title": {
                "fragments": [],
                "text": "A Statistical Model for General Contextual Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Experiments show that spatial context considerably improves the accuracy of object recognition, and an approximate EM algorithm that uses loopy belief propagation in the inference step and iterative scaling on the pseudo-likelihood approximation in the parameter update step converges to good local solutions."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056417995"
                        ],
                        "name": "K. Murphy",
                        "slug": "K.-Murphy",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Murphy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Murphy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 606341,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a5f39edf5d270c6fd67d8a1ffeab2cc357deb118",
            "isKey": false,
            "numCitedBy": 413,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We seek to both detect and segment objects in images. To exploit both local image data as well as contextual information, we introduce Boosted Random Fields (BRFs), which uses Boosting to learn the graph structure and local evidence of a conditional random field (CRF). The graph structure is learned by assembling graph fragments in an additive model. The connections between individual pixels are not very informative, but by using dense graphs, we can pool information from large regions of the image; dense models also support efficient inference. We show how contextual information from other objects can improve detection performance, both in terms of accuracy and speed, by using a computational cascade. We apply our system to detect stuff and things in office and street scenes."
            },
            "slug": "Contextual-Models-for-Object-Detection-Using-Random-Torralba-Murphy",
            "title": {
                "fragments": [],
                "text": "Contextual Models for Object Detection Using Boosted Random Fields"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This work introduces Boosted Random Fields (BRFs), which uses Boosting to learn the graph structure and local evidence of a conditional random field (CRF) and applies it to detect stuff and things in office and street scenes."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1073705,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c99f2391b956dc189855541e49e53c21ae5ec603",
            "isKey": false,
            "numCitedBy": 888,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "There is general consensus that context can be a rich source of information about an object's identity, location and scale. In fact, the structure of many real-world scenes is governed by strong configurational rules akin to those that apply to a single object. Here we introduce a simple framework for modeling the relationship between context and object properties based on the correlation between the statistics of low-level features across the entire scene and the objects that it contains. The resulting scheme serves as an effective procedure for object priming, context driven focus of attention and automatic scale-selection on real-world scenes."
            },
            "slug": "Contextual-Priming-for-Object-Detection-Torralba",
            "title": {
                "fragments": [],
                "text": "Contextual Priming for Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A simple framework for modeling the relationship between context and object properties based on the correlation between the statistics of low-level features across the entire scene and the objects that it contains serves as an effective procedure for object priming, context driven focus of attention and automatic scale-selection on real-world scenes."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2866369"
                        ],
                        "name": "T. Strat",
                        "slug": "T.-Strat",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Strat",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Strat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2465976"
                        ],
                        "name": "M. Fischler",
                        "slug": "M.-Fischler",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Fischler",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fischler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 136
                            }
                        ],
                        "text": "The notion of contextual-features is somewhat loosely defined, encapsulating at once the nature of nearby objects (Murphy et al., 2003; Strat and Fischler, 1991; Hanson and Riseman, 1978; Carbonetto et al., 2004), the relative position and scale of those objects (Singhal et al., 2003; Kruppa and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 41
                            }
                        ],
                        "text": "Finally, it is shown that when the target object is unambiguously visible, context is only marginally useful."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15374748,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "06c908a5dea82fdbffa8285beae1c3d60b028902",
            "isKey": false,
            "numCitedBy": 195,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Results from an ongoing project concerned with recognizing objects in complex scene domains, especially in the domain that includes the natural outdoor world, are described. Traditional machine recognition paradigms assume either that all objects of interest are definable by a relatively small number of explicit shape models or that all objects of interest have characteristic, locally measurable features. The failure of both assumptions has a dramatic impact on the form of an acceptable architecture for an object recognition system. In this work, the use of the contextual information is a central issue, and a system is explicitly designed to identify and use context as an integral part of recognition that eliminates the traditional dependence on stored geometric models and universal image partitioning algorithms. This paradigm combines the results of many simple procedures that analyze monochrome, color, stereo, or 3D range images. Interpreting the results along with relevant contextual knowledge makes it possible to achieve a reliable recognition result, even when using imperfect visual procedures. Initial experimentation with the system on ground-level outdoor imagery has demonstrated competence beyond what is attainable with other vision systems. >"
            },
            "slug": "Context-Based-Vision:-Recognizing-Objects-Using-2D-Strat-Fischler",
            "title": {
                "fragments": [],
                "text": "Context-Based Vision: Recognizing Objects Using Information from Both 2D and 3D Imagery"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "In this work, a system is explicitly designed to identify and use context as an integral part of recognition that eliminates the traditional dependence on stored geometric models and universal image partitioning algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3074803"
                        ],
                        "name": "H. Kruppa",
                        "slug": "H.-Kruppa",
                        "structuredName": {
                            "firstName": "Hannes",
                            "lastName": "Kruppa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kruppa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48920094"
                        ],
                        "name": "B. Schiele",
                        "slug": "B.-Schiele",
                        "structuredName": {
                            "firstName": "Bernt",
                            "lastName": "Schiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schiele"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 210
                            }
                        ],
                        "text": "\u2026at once the nature of nearby objects (Murphy et al., 2003; Strat and Fischler, 1991; Hanson and Riseman, 1978; Carbonetto et al., 2004), the relative position and scale of those objects (Singhal et al., 2003; Kruppa and Schiele, 2003; Fink and Perona,\n\u2217Both authors contributed equally."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14924117,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1512300d7a9ac49823151613b6cc8dc4b4dd77dc",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Most face detection algorithms locate faces by classifying the content of a detection window iterating over all positions and scales of the input image. Recent developments have accelerated this process up to real-time performance at high levels of accuracy. However, even the best of today\u2019s computational systems are far from being able to compete with the detection capabilities of the human visual system. Psychophysical experiments have shown the importance of local context in the face detection process. In this paper we investigate the role of local context for face detection algorithms. In experiments on two large data sets we find that using local context can significantly increase the number of correct detections, particularly in low resolution cases, uncommon poses or individual appearances as well as occlusions."
            },
            "slug": "Using-Local-Context-To-Improve-Face-Detection-Kruppa-Schiele",
            "title": {
                "fragments": [],
                "text": "Using Local Context To Improve Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "In experiments on two large data sets, it is found that using local context can significantly increase the number of correct detections, particularly in low resolution cases, uncommon poses or individual appearances as well as occlusions."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056417995"
                        ],
                        "name": "K. Murphy",
                        "slug": "K.-Murphy",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Murphy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Murphy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 419324,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a4300efb6895695205dfc1b74e124f9fea6aff2",
            "isKey": false,
            "numCitedBy": 413,
            "numCiting": 84,
            "paperAbstract": {
                "fragments": [],
                "text": "Standard approaches to object detection focus on local patches of the image, and try to classify them as background or not. We propose to use the scene context (image as a whole) as an extra source of (global) information, to help resolve local ambiguities. We present a conditional random field for jointly solving the tasks of object detection and scene classification."
            },
            "slug": "Using-the-Forest-to-See-the-Trees:-A-Graphical-and-Murphy-Torralba",
            "title": {
                "fragments": [],
                "text": "Using the Forest to See the Trees: A Graphical Model Relating Features, Objects, and Scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This work presents a conditional random field for jointly solving the tasks of object detection and scene classification, and proposes to use the scene context as an extra source of (global) information, to help resolve local ambiguities."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105534484"
                        ],
                        "name": "Michael Fink",
                        "slug": "Michael-Fink",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Fink",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Fink"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 37
                            }
                        ],
                        "text": "Functional MRI evidence\n252 Wolf and Bileschi\nof humans using contextual cues was provided by Cox et al. (2004) and Bar et al. (2005), among others."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 53
                            }
                        ],
                        "text": "2003; Bergboer et al., 2003; Haralick, 1983; Bileschi and Heisele, 2003), as well as statistics of low level visual features of the scene as a whole (Torralba and Sinha, 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 33
                            }
                        ],
                        "text": "Fink describes a similar system (Fink and Perona, 2003) for which detections of objects\u2019 parts, as well as detections of other objects in a scene, are employed in a modification of the Viola-Jones cascaded object detection architecture (Viola and Jones, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3128334,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4f465ea564f56f69f002db534e1beedce3d052a8",
            "isKey": false,
            "numCitedBy": 112,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Mutual Boosting is a method aimed at incorporating contextual information to augment object detection. When multiple detectors of objects and parts are trained in parallel using AdaBoost [1], object detectors might use the remaining intermediate detectors to enrich the weak learner set. This method generalizes the efficient features suggested by Viola and Jones [2] thus enabling information inference between parts and objects in a compositional hierarchy. In our experiments eye-, nose-, mouth- and face detectors are trained using the Mutual Boosting framework. Results show that the method outperforms applications overlooking contextual information. We suggest that achieving contextual integration is a step toward human-like detection capabilities."
            },
            "slug": "Mutual-Boosting-for-Contextual-Inference-Fink-Perona",
            "title": {
                "fragments": [],
                "text": "Mutual Boosting for Contextual Inference"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "In these experiments eye-, nose-, mouth- and face detectors are trained using the Mutual Boosting framework and it is suggested that achieving contextual integration is a step toward human-like detection capabilities."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145163573"
                        ],
                        "name": "A. Singhal",
                        "slug": "A.-Singhal",
                        "structuredName": {
                            "firstName": "Amit",
                            "lastName": "Singhal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Singhal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33642939"
                        ],
                        "name": "Jiebo Luo",
                        "slug": "Jiebo-Luo",
                        "structuredName": {
                            "firstName": "Jiebo",
                            "lastName": "Luo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiebo Luo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34763422"
                        ],
                        "name": "W. Zhu",
                        "slug": "W.-Zhu",
                        "structuredName": {
                            "firstName": "Weiyu",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Zhu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 59
                            }
                        ],
                        "text": "Keywords: context, learning, streetscenes, object detection, scene understanding"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 188
                            }
                        ],
                        "text": "\u2026at once the nature of nearby objects (Murphy et al., 2003; Strat and Fischler, 1991; Hanson and Riseman, 1978; Carbonetto et al., 2004), the relative position and scale of those objects (Singhal et al., 2003; Kruppa and Schiele, 2003; Fink and Perona,\n\u2217Both authors contributed equally."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14356209,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "01c2f706c107c9853a86d1a2d6cd8e6f82b31db1",
            "isKey": false,
            "numCitedBy": 191,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Scene content understanding facilitates a large number of applications, ranging from content-based image retrieval to other multimedia applications. Material detection refers to the problem of identifying key semantic material types (such as sky, grass, foliage, water, and snow in images). In this paper, we present a holistic approach to determining scene content, based on a set of individual material detection algorithms, as well as probabilistic spatial context models. A major limitation of individual material detectors is the significant number of misclassifications that occur because of the similarities in color and texture characteristics of various material types. We have developed a spatial context-aware material detection system that reduces misclassification by constraining the beliefs to conform to the probabilistic spatial context models. Experimental results show that the accuracy of materials detection is improved by 13% using the spatial context models over the individual material detectors themselves."
            },
            "slug": "Probabilistic-spatial-context-models-for-scene-Singhal-Luo",
            "title": {
                "fragments": [],
                "text": "Probabilistic spatial context models for scene content understanding"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A spatial context-aware material detection system that reduces misclassification by constraining the beliefs to conform to the probabilistic spatial context models is developed."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145319478"
                        ],
                        "name": "Michael J. Jones",
                        "slug": "Michael-J.-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 80
                            }
                        ],
                        "text": "A good definition of context might be information relevant to the detection task but not directly due to the physical appearance of the object."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 257,
                                "start": 236
                            }
                        ],
                        "text": "Fink describes a similar system (Fink and Perona, 2003) for which detections of objects\u2019 parts, as well as detections of other objects in a scene, are employed in a modification of the Viola-Jones cascaded object detection architecture (Viola and Jones, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2715202,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc6ea0e30e46163b706f2f8bdc9c67ca87f83d63",
            "isKey": false,
            "numCitedBy": 17884,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates. This work is distinguished by three key contributions. The first is the introduction of a new image representation called the \"integral image\" which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features from a larger set and yields extremely efficient classifiers. The third contribution is a method for combining increasingly more complex classifiers in a \"cascade\" which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. The cascade can be viewed as an object specific focus-of-attention mechanism which unlike previous approaches provides statistical guarantees that discarded regions are unlikely to contain the object of interest. In the domain of face detection the system yields detection rates comparable to the best previous systems. Used in real-time applications, the detector runs at 15 frames per second without resorting to image differencing or skin color detection."
            },
            "slug": "Rapid-object-detection-using-a-boosted-cascade-of-Viola-Jones",
            "title": {
                "fragments": [],
                "text": "Rapid object detection using a boosted cascade of simple features"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates and the introduction of a new image representation called the \"integral image\" which allows the features used by the detector to be computed very quickly."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13919023"
                        ],
                        "name": "F. Huang",
                        "slug": "F.-Huang",
                        "structuredName": {
                            "firstName": "Fu",
                            "lastName": "Huang",
                            "middleNames": [
                                "Jie"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 712708,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f354310098e09c1e1dc88758fca36767fd9d084d",
            "isKey": false,
            "numCitedBy": 1306,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We assess the applicability of several popular learning methods for the problem of recognizing generic visual categories with invariance to pose, lighting, and surrounding clutter. A large dataset comprising stereo image pairs of 50 uniform-colored toys under 36 azimuths, 9 elevations, and 6 lighting conditions was collected (for a total of 194,400 individual images). The objects were 10 instances of 5 generic categories: four-legged animals, human figures, airplanes, trucks, and cars. Five instances of each category were used for training, and the other five for testing. Low-resolution grayscale images of the objects with various amounts of variability and surrounding clutter were used for training and testing. Nearest neighbor methods, support vector machines, and convolutional networks, operating on raw pixels or on PCA-derived features were tested. Test error rates for unseen object instances placed on uniform backgrounds were around 13% for SVM and 7% for convolutional nets. On a segmentation/recognition task with highly cluttered images, SVM proved impractical, while convolutional nets yielded 16/7% error. A real-time version of the system was implemented that can detect and classify objects in natural scenes at around 10 frames per second."
            },
            "slug": "Learning-methods-for-generic-object-recognition-to-LeCun-Huang",
            "title": {
                "fragments": [],
                "text": "Learning methods for generic object recognition with invariance to pose and lighting"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A real-time version of the system was implemented that can detect and classify objects in natural scenes at around 10 frames per second and proved impractical, while convolutional nets yielded 16/7% error."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145349582"
                        ],
                        "name": "Sanjiv Kumar",
                        "slug": "Sanjiv-Kumar",
                        "structuredName": {
                            "firstName": "Sanjiv",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sanjiv Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 191,
                                "start": 169
                            }
                        ],
                        "text": "Context is presumed to be an important cue for object detection in humans, believed to reduce processing time and to help disambiguate low quality inputs by mitigating the effect of clutter, noise and ambiguous inputs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 105
                            }
                        ],
                        "text": "Systems which pre-segment the image and then model the relationships between neighboring segments, i.e. (Kumar and Hebert, 2003; Carbonetto et al., 2004), suffer from similar issues."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10689850,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e54f01884e1fba4a0bbd2f0989ad21a16ebb13e3",
            "isKey": false,
            "numCitedBy": 530,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work we present discriminative random fields (DRFs), a discriminative framework for the classification of image regions by incorporating neighborhood interactions in the labels as well as the observed data. The discriminative random fields offer several advantages over the conventional Markov random field (MRF) framework. First, the DRFs allow to relax the strong assumption of conditional independence of the observed data generally used in the MRF framework for tractability. This assumption is too restrictive for a large number of applications in vision. Second, the DRFs derive their classification power by exploiting the probabilistic discriminative models instead of the generative models used in the MRF framework. Finally, all the parameters in the DRF model are estimated simultaneously from the training data unlike the MRF framework where likelihood parameters are usually learned separately from the field parameters. We illustrate the advantages of the DRFs over the MRF framework in an application of man-made structure detection in natural images taken from the Corel database."
            },
            "slug": "Discriminative-random-fields:-a-discriminative-for-Kumar-Hebert",
            "title": {
                "fragments": [],
                "text": "Discriminative random fields: a discriminative framework for contextual interaction in classification"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "This work presents discriminative random fields (DRFs), a discrim inative framework for the classification of image regions by incorporating neighborhood interactions in the labels as well as the observed data that offers several advantages over the conventional Markov random field framework."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2299972"
                        ],
                        "name": "I. Biederman",
                        "slug": "I.-Biederman",
                        "structuredName": {
                            "firstName": "Irving",
                            "lastName": "Biederman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Biederman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153014854"
                        ],
                        "name": "R. J. Mezzanotte",
                        "slug": "R.-J.-Mezzanotte",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mezzanotte",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. J. Mezzanotte"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "117606629"
                        ],
                        "name": "J. C. Rabinowitz",
                        "slug": "J.-C.-Rabinowitz",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Rabinowitz",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. C. Rabinowitz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: context, learning, streetscenes, object detection, scene understanding"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 0
                            }
                        ],
                        "text": "Biederman et al. (1982) shows that humans detecting objects that violate their standard context take longer and make more errors."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16232587,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "a5b309957c0113d45458268f2324b36c52ae3f73",
            "isKey": false,
            "numCitedBy": 982,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Scene-perception:-Detecting-and-judging-objects-Biederman-Mezzanotte",
            "title": {
                "fragments": [],
                "text": "Scene perception: Detecting and judging objects undergoing relational violations"
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive Psychology"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085375589"
                        ],
                        "name": "H. Schneiderman",
                        "slug": "H.-Schneiderman",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Schneiderman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Schneiderman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10226261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "208b4a0637b4b60b2406be7112563ed2b30e6b09",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Many classes of images have the characteristics of sparse structuring of statistical dependency and the presence of conditional independencies among various groups of variables. Such characteristics make it possible to construct a powerful classifier by only representing the stronger direct dependencies among the variables. In particular, a Bayesian network compactly represents such structuring. However, learning the structure of a Bayesian network is known to be NP complete. The high dimensionality of images makes structure learning especially challenging. This paper describes an algorithm that searches for the structure of a Bayesian network based classifier in this large space of possible structures. The algorithm seeks to optimize two cost functions: a localized error in the log-likelihood ratio function to restrict the structure and a global classification error to choose the final structure of the network. The final network structure is restricted such that the search can take advantage of pre-computed estimates and evaluations. We use this method to automatically train detectors of frontal faces, eyes, and the iris of the human eye. In particular, the frontal face detector achieves state-of-the-art performance on the MIT-CMU test set for face detection."
            },
            "slug": "Learning-a-restricted-Bayesian-network-for-object-Schneiderman",
            "title": {
                "fragments": [],
                "text": "Learning a restricted Bayesian network for object detection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper describes an algorithm that searches for the structure of a Bayesian network based classifier in this large space of possible structures and uses this method to automatically train detectors of frontal faces, eyes, and the iris of the human eye."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064714301"
                        ],
                        "name": "David Cox",
                        "slug": "David-Cox",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Cox",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Cox"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145062299"
                        ],
                        "name": "Ethan M Meyers",
                        "slug": "Ethan-M-Meyers",
                        "structuredName": {
                            "firstName": "Ethan",
                            "lastName": "Meyers",
                            "middleNames": [
                                "M"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ethan M Meyers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46597039"
                        ],
                        "name": "P. Sinha",
                        "slug": "P.-Sinha",
                        "structuredName": {
                            "firstName": "Pawan",
                            "lastName": "Sinha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sinha"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 94
                            }
                        ],
                        "text": "Functional MRI evidence\n252 Wolf and Bileschi\nof humans using contextual cues was provided by Cox et al. (2004) and Bar et al. (2005), among others."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "of humans using contextual cues was provided by  Cox et al. (2004)  and Bar et al. (2005), among others."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 45009282,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "ab2d3733971d5ac5bc182dfe3ea73609a4016bbf",
            "isKey": false,
            "numCitedBy": 118,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Human visual recognition processes are remarkably robust and can function effectively even under highly degraded viewing conditions. Contextual information may play a critical role in such circumstances. Here, we provide neurophysiological evidence that contextual cues can elicit object-specific neural responses, which have hitherto been believed to be based on intrinsic cues alone. Specifically, we find that the \u201cfusiform face area\u201d (FFA) maintains its selectivity for faces without regard to whether the faces are defined intrinsically or contextually. This finding further elucidates the role of the FFA and reveals neural correlates of contextual processing in the service of robust object recognition."
            },
            "slug": "Contextually-Evoked-Object-Specific-Responses-in-Cox-Meyers",
            "title": {
                "fragments": [],
                "text": "Contextually Evoked Object-Specific Responses in Human Visual Cortex"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is found that the \u201cfusiform face area\u201d (FFA) maintains its selectivity for faces without regard to whether the faces are defined intrinsically or contextually."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747918"
                        ],
                        "name": "S. Bileschi",
                        "slug": "S.-Bileschi",
                        "structuredName": {
                            "firstName": "Stanley",
                            "lastName": "Bileschi",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bileschi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684626"
                        ],
                        "name": "B. Heisele",
                        "slug": "B.-Heisele",
                        "structuredName": {
                            "firstName": "Bernd",
                            "lastName": "Heisele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Heisele"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 45
                            }
                        ],
                        "text": "2003; Bergboer et al., 2003; Haralick, 1983; Bileschi and Heisele, 2003), as well as statistics of low level visual features of the scene as a whole (Torralba and Sinha, 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: context, learning, streetscenes, object detection, scene understanding"
                    },
                    "intents": []
                }
            ],
            "corpusId": 7893123,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0db7735e7adbe6e34dd058af31e278033040ab18",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the design of a component based face detector for gray scale images. We show that including pans of the face into the negative training sets of the component classifiers leads to improved system performance. We also introduce a method of using pairwise position statistics between component locations to more accurately locate the parts of a face. Finally, we illustrate an application of this technology in the creation of an accurate eye detection system."
            },
            "slug": "Advances-in-component-based-face-detection-Bileschi-Heisele",
            "title": {
                "fragments": [],
                "text": "Advances in component based face detection"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "It is shown that including pans of the face into the negative training sets of the component classifiers leads to improved system performance and a method of using pairwise position statistics between component locations to more accurately locate the parts of a face."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE International SOI Conference. Proceedings (Cat. No.03CH37443)"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2969789"
                        ],
                        "name": "C. Carson",
                        "slug": "C.-Carson",
                        "structuredName": {
                            "firstName": "Chad",
                            "lastName": "Carson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Carson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143942875"
                        ],
                        "name": "H. Greenspan",
                        "slug": "H.-Greenspan",
                        "structuredName": {
                            "firstName": "Hayit",
                            "lastName": "Greenspan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Greenspan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "To produce low-level features we first downsize the input image to 60\u00d7 80 pixels and compute color and texture spaces as in the Blobworld system of  Carson et al. (1998) ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 756703,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e81cdb9911bf84546f67b5f5b2a7f04b4b847d30",
            "isKey": false,
            "numCitedBy": 558,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Retrieving images from large and varied collections using image content as a key is a challenging and important problem. In this paper we present a new image representation which provides a transformation from the raw pixel data to a small set of image regions which are coherent in color and texture space. This so-called \"blobworld\" representation is based on segmentation using the expectation-maximization algorithm on combined color and texture features. The texture features we use for the segmentation arise from a new approach to texture description and scale selection. We describe a system that uses the blobworld representation to retrieve images. An important and unique aspect of the system is that, in the context of similarity-based querying, the user is allowed to view the internal representation of the submitted image and the query results. Similar systems do not offer the user this view into the workings of the system; consequently, the outcome of many queries on these systems can be quite inexplicable, despite the availability of knobs for adjusting the similarity metric."
            },
            "slug": "Color-and-texture-based-image-segmentation-using-EM-Belongie-Carson",
            "title": {
                "fragments": [],
                "text": "Color- and texture-based image segmentation using EM and its application to content-based image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "A new image representation is presented which provides a transformation from the raw pixel data to a small set of image regions which are coherent in color and texture space based on segmentation using the expectation-maximization algorithm on combined color andtexture features."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717973"
                        ],
                        "name": "Juan R. Vidal",
                        "slug": "Juan-R.-Vidal",
                        "structuredName": {
                            "firstName": "Juan",
                            "lastName": "Vidal",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Juan R. Vidal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4245957"
                        ],
                        "name": "H\u00e9l\u00e8ne L. Gauchou",
                        "slug": "H\u00e9l\u00e8ne-L.-Gauchou",
                        "structuredName": {
                            "firstName": "H\u00e9l\u00e8ne",
                            "lastName": "Gauchou",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H\u00e9l\u00e8ne L. Gauchou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401740051"
                        ],
                        "name": "C. Tallon-Baudry",
                        "slug": "C.-Tallon-Baudry",
                        "structuredName": {
                            "firstName": "Catherine",
                            "lastName": "Tallon-Baudry",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Tallon-Baudry"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398984373"
                        ],
                        "name": "J. O'Regan",
                        "slug": "J.-O'Regan",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "O'Regan",
                            "middleNames": [
                                "Kevin"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. O'Regan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13234265,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "5894a6a31ef8d79bfe6aa189487726ebdb642540",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Over the past 20 years, storage of visual items in visual short-term memory has been extensively studied by many research groups. In addition to questions concerning the format of object storage is a more global question that focuses on the organization of information in visual short-term memory. In a series of experiments we investigated how relations across visual items determined the accessibility of individual item information. This relational information seems to be very strong within the store devoted to each feature dimension. We also investigated the role of selective attention on the storage of relational information. The experiments suggest a broadening of the parallel store model of visual short-term memory proposed by M. E. Wheeler and A. M. Treisman (2002) to include the notion of what we call \"structural gist.\""
            },
            "slug": "Relational-information-in-visual-short-term-memory:-Vidal-Gauchou",
            "title": {
                "fragments": [],
                "text": "Relational information in visual short-term memory: the structural gist."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of vision"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 29
                            }
                        ],
                        "text": "2003; Bergboer et al., 2003; Haralick, 1983; Bileschi and Heisele, 2003), as well as statistics of low level visual features of the scene as a whole (Torralba and Sinha, 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: context, learning, streetscenes, object detection, scene understanding"
                    },
                    "intents": []
                }
            ],
            "corpusId": 3332651,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "8566d8dcf52f59dd157803283971f0145f832614",
            "isKey": false,
            "numCitedBy": 103,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "From a Bayesian decision theoretic framework, we show that the reason why the usual statistical approaches do not take context into account is because of the assumptions made on the joint prior probability function and because of the simplistic loss function chosen. We illustrate how the constraints sometimes employed by artificial intelligence researchers constitute a different kind of assumption on the joint prior probability function. We discuss a couple of loss functions which do take context into account and when combined with the joint prior probability constraint create a decision problem requiring a combinatorial state space search. We also give a theory for how probabilistic relaxation works from a Bayesian point of view."
            },
            "slug": "Decision-Making-in-Context-Haralick",
            "title": {
                "fragments": [],
                "text": "Decision Making in Context"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "From a Bayesian decision theoretic framework, it is shown that the reason why the usual statistical approaches do not take context into account is because of the assumptions made on the joint prior probability function andBecause of the simplistic loss function chosen."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 144
                            }
                        ],
                        "text": "As an example of a system from the first set, Torralaba et al. (2004) employ boosting and graphical networks to learn associations between the likely co-occurrence and relative position of objects."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 72
                            }
                        ],
                        "text": "This is one of the main results of Vapnik\u2019s statistical learning theory (Vapnik, 1999)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 7138354,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8213dbed4db44e113af3ed17d6dad57471a0c048",
            "isKey": false,
            "numCitedBy": 38755,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Setting of the learning problem consistency of learning processes bounds on the rate of convergence of learning processes controlling the generalization ability of learning processes constructing learning algorithms what is important in learning theory?."
            },
            "slug": "The-Nature-of-Statistical-Learning-Theory-Vapnik",
            "title": {
                "fragments": [],
                "text": "The Nature of Statistical Learning Theory"
            },
            "venue": {
                "fragments": [],
                "text": "Statistics for Engineering and Information Science"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2741887"
                        ],
                        "name": "M. Bar",
                        "slug": "M.-Bar",
                        "structuredName": {
                            "firstName": "Moshe",
                            "lastName": "Bar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2240829"
                        ],
                        "name": "E. Aminoff",
                        "slug": "E.-Aminoff",
                        "structuredName": {
                            "firstName": "Elissa",
                            "lastName": "Aminoff",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Aminoff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6639326"
                        ],
                        "name": "J. Boshyan",
                        "slug": "J.-Boshyan",
                        "structuredName": {
                            "firstName": "Jasmine",
                            "lastName": "Boshyan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Boshyan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39157328"
                        ],
                        "name": "M. Fenske",
                        "slug": "M.-Fenske",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Fenske",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fenske"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "113976302"
                        ],
                        "name": "Nurit Gronauo",
                        "slug": "Nurit-Gronauo",
                        "structuredName": {
                            "firstName": "Nurit",
                            "lastName": "Gronauo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nurit Gronauo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7014924"
                        ],
                        "name": "K. Kassam",
                        "slug": "K.-Kassam",
                        "structuredName": {
                            "firstName": "Karim",
                            "lastName": "Kassam",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kassam"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 116
                            }
                        ],
                        "text": "Functional MRI evidence\n252 Wolf and Bileschi\nof humans using contextual cues was provided by Cox et al. (2004) and Bar et al. (2005), among others."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 70
                            }
                        ],
                        "text": "In object detection, the goal is to locate and identify all instances of a particular object class within an image, i.e., finding all the cars in a snapshot of a street."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 143671192,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ef2f9da80aad43710b3c7366c167565eb76417bc",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-contribution-of-context-to-visual-object-Bar-Aminoff",
            "title": {
                "fragments": [],
                "text": "The contribution of context to visual object recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "This research was sponsored by grants from: Office of Naval Research (DARPA) Contract No. MDA972-04-1-0037"
            },
            "venue": {
                "fragments": [],
                "text": "Office of Naval Research (DARPA) Contract No"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 6
                            }
                        ],
                        "text": "2003; Bergboer et al., 2003; Haralick, 1983; Bileschi and Heisele, 2003), as well as statistics of low level visual features of the scene as a whole (Torralba and Sinha, 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: context, learning, streetscenes, object detection, scene understanding"
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Contextenhanced object detection in natural images"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of the Belgian-Netherlands AI Conference (BNAIC"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 94
                            }
                        ],
                        "text": "Functional MRI evidence\n252 Wolf and Bileschi\nof humans using contextual cues was provided by Cox et al. (2004) and Bar et al. (2005), among others."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 48
                            }
                        ],
                        "text": "In object detection, the goal is to locate and identify all instances of a particular object class within an image, i.e., finding all the cars in a snapshot of a street."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Contextually evoked objectspecific responses in human visual cortex"
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Colorand texture-based image segmentation using em and its application to content-based image retrieval"
            },
            "venue": {
                "fragments": [],
                "text": "Colorand texture-based image segmentation using em and its application to content-based image retrieval"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Colorand texture-based image segmentation using em and its application to content-based image retrieval, ICCV"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: context, learning, streetscenes, object detection, scene understanding"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 210
                            }
                        ],
                        "text": "\u2026at once the nature of nearby objects (Murphy et al., 2003; Strat and Fischler, 1991; Hanson and Riseman, 1978; Carbonetto et al., 2004), the relative position and scale of those objects (Singhal et al., 2003; Kruppa and Schiele, 2003; Fink and Perona,\n\u2217Both authors contributed equally."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Using context to improve face detection"
            },
            "venue": {
                "fragments": [],
                "text": "British machine Vision Conference (BMCV)"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 67
                            }
                        ],
                        "text": "Finally, it is shown that when the target object is unambiguously visible, context is only marginally useful."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 149
                            }
                        ],
                        "text": "\u2026contextual-features is somewhat loosely defined, encapsulating at once the nature of nearby objects (Murphy et al., 2003; Strat and Fischler, 1991; Hanson and Riseman, 1978; Carbonetto et al., 2004), the relative position and scale of those objects (Singhal et al., 2003; Kruppa and Schiele, 2003;\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Visions: A computer system for interpreting scenes"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Vision Systems"
            },
            "year": 1978
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 29
                            }
                        ],
                        "text": "2003; Bergboer et al., 2003; Haralick, 1983; Bileschi and Heisele, 2003), as well as statistics of low level visual features of the scene as a whole (Torralba and Sinha, 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Decision making in context, PAMI"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 18,
            "methodology": 6,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 29,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/A-Critical-View-of-Context-Wolf-Bileschi/a371956d45a362f6613d87086c1f6e5947d0c084?sort=total-citations"
}