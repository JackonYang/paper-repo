{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733733"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2213649"
                        ],
                        "name": "C. Wellekens",
                        "slug": "C.-Wellekens",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Wellekens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Wellekens"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 128
                            }
                        ],
                        "text": "For instance, while it has been shown that the outputs of a feedforward network can be used as emission probabilities in an HMM [Bourlard et al., 1989], the corresponding word recognition performance can be very poor."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62637304,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "72820bb2e725b73af7e2cd848ef0b103d15cdc39",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Speech recognition must contend with the statistical and sequential nature of the human speech production system. Hidden Markov Models (HMM) provide a powerful method to cope with both of these, and their use made a breakthrough in speech recognition. However, the a priori choice of a model topology and weak discriminative power limit HMM capabilities. Recently, connectionist models have been recognized as an alternative tool. Their main useful properties lie in their discriminative power while capturing input-output relations. They have also proved useful in dealing with statistical data. However, the sequential aspect remains difficult to handle in connectionist models. The statistical use of a particular classic form of a connectionist system, the Multilayer Perceptron (MLP), is described in the context of the recognition of continuous speech. Relations with Hidden Markov Models are explained and preliminary results are reported."
            },
            "slug": "Statistical-Inference-in-Multilayer-Perceptrons-and-Bourlard-Morgan",
            "title": {
                "fragments": [],
                "text": "Statistical Inference in Multilayer Perceptrons and Hidden Markov Models with Applications in Continuous Speech Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The statistical use of a particular classic form of a connectionist system, the Multilayer Perceptron (MLP), is described in the context of the recognition of continuous speech."
            },
            "venue": {
                "fragments": [],
                "text": "NATO Neurocomputing"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40396597"
                        ],
                        "name": "Toshiyuki Hanazawa",
                        "slug": "Toshiyuki-Hanazawa",
                        "structuredName": {
                            "firstName": "Toshiyuki",
                            "lastName": "Hanazawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Toshiyuki Hanazawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9243990"
                        ],
                        "name": "K. Shikano",
                        "slug": "K.-Shikano",
                        "structuredName": {
                            "firstName": "Kiyohiro",
                            "lastName": "Shikano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Shikano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49464494"
                        ],
                        "name": "Kevin J. Lang",
                        "slug": "Kevin-J.-Lang",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Lang",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin J. Lang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12251177,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "834b3738673dacc767563c2714239852a8a6d4b4",
            "isKey": false,
            "numCitedBy": 172,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A time-delay neural network (TDNN) for phoneme recognition is discussed. By the use of two hidden layers in addition to an input and output layer it is capable of representing complex nonlinear decision surfaces. Three important properties of the TDNNs have been observed. First, it was able to invent without human interference meaningful linguistic abstractions in time and frequency such as formant tracking and segmentation. Second, it has learned to form alternate representations linking different acoustic events with the same higher level concept. In this fashion it can implement trading relations between lower level acoustic events leading to robust recognition performance despite considerable variability in the input speech. Third, the network is translation-invariant and does not rely on precise alignment or segmentation of the input. The TDNNs performance is compared with the best of hidden Markov models (HMMs) on a speaker-dependent phoneme-recognition task. The TDNN achieved a recognition of 98.5% compared to 93.7% for the HMM, i.e., a fourfold reduction in error.<<ETX>>"
            },
            "slug": "Phoneme-recognition:-neural-networks-vs.-hidden-vs.-Waibel-Hanazawa",
            "title": {
                "fragments": [],
                "text": "Phoneme recognition: neural networks vs. hidden Markov models vs. hidden Markov models"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "A time-delay neural network for phoneme recognition that was able to invent without human interference meaningful linguistic abstractions in time and frequency such as formant tracking and segmentation and does not rely on precise alignment or segmentation of the input."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP-88., International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065228513"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2213649"
                        ],
                        "name": "C. Wellekens",
                        "slug": "C.-Wellekens",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Wellekens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Wellekens"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 24
                            }
                        ],
                        "text": "In the original scheme [Bourlard & Wellekens, 1989], MLP outputs were used as MAP probabilities for the HMM directly."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 30
                            }
                        ],
                        "text": "As shown by both theoretical [Bourlard & Wellekens, 1989] and experimental [Bourlard & Morgan, 1989] results, MLP output values may be considered to be good estimates of MAP probabilities for pattern classification."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 14700006,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ee50abb5aff3e5c43a38f24396b9552d593a9ae0",
            "isKey": false,
            "numCitedBy": 420,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "The statistical use of a particular classic form of a connectionist system, the multilayer perceptron (MLP), is described in the context of the recognition of continuous speech. A discriminant hidden Markov model (HMM) is defined, and it is shown how a particular MLP with contextual and extra feedback input units can be considered as a general form of such a Markov model. A link between these discriminant HMMs, trained along the Viterbi algorithm, and any other approach based on least mean square minimization of an error function (LMSE) is established. It is shown theoretically and experimentally that the outputs of the MLP (when trained along the LMSE or the entropy criterion) approximate the probability distribution over output classes conditioned on the input, i.e. the maximum a posteriori probabilities. Results of a series of speech recognition experiments are reported. The possibility of embedding MLP into HMM is described. Relations with other recurrent networks are also explained. >"
            },
            "slug": "Links-Between-Markov-Models-and-Multilayer-Bourlard-Wellekens",
            "title": {
                "fragments": [],
                "text": "Links Between Markov Models and Multilayer Perceptrons"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown theoretically and experimentally that the outputs of the MLP approximate the probability distribution over output classes conditioned on the input, i.e. the maximum a posteriori probabilities."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1801257"
                        ],
                        "name": "A. Noll",
                        "slug": "A.-Noll",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Noll",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Noll"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61023354,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "280d0643b26a10ecc302d986514a154374a8fda4",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Deals with the use of continuous mixture densities for phenome modelling in large vocabulary continuous speech recognition. The concept of continuous mixture densities is applied to the emission probability density functions of hidden Markov models for phonemes in order to take into account phonetic-context dependencies. It is shown that the advantage of continuous mixture densities is the ability to lead to parameter estimates that are accurate and at the same time robust with respect to the limited amount of training data. Training and recognition algorithms for mixture densities in the framework of phoneme modelling are described. Recognition results for a 917-word task, requiring only 7 min of speech for training and an overlap of 43 words between training vocabulary and test vocabulary, are presented.<<ETX>>"
            },
            "slug": "Phoneme-modelling-using-continuous-mixture-Ney-Noll",
            "title": {
                "fragments": [],
                "text": "Phoneme modelling using continuous mixture densities"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "It is shown that the advantage of continuous mixture densities is the ability to lead to parameter estimates that are accurate and at the same time robust with respect to the limited amount of training data."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP-88., International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1822055"
                        ],
                        "name": "Raymond L. Watrous",
                        "slug": "Raymond-L.-Watrous",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Watrous",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Raymond L. Watrous"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48462607"
                        ],
                        "name": "L. Shastri",
                        "slug": "L.-Shastri",
                        "structuredName": {
                            "firstName": "Lokendra",
                            "lastName": "Shastri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Shastri"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12357500,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f1e40283ecd4633c36c70fbc8dbb14e9a4afb37f",
            "isKey": false,
            "numCitedBy": 81,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for learning phonetic features from speech data using connectionist networks is described. A temporal flow model is introduced in which sampled speech data flows through a parallel network from input to output units. The network uses hidden units with recurrent links to capture spectral/temporal characteristics of phonetic features. A supervised learning algorithm is presented which performs gradient descent in weight space using a coarse approximation of the desired output as an evaluation function. \n \nA simple connectionist network with recurrent links was trained on a single instance of the word pair \"no\" and \"go\", and successful learned a discriminatory mechanism. The trained network also correctly discriminated 98% of 25 other tokens of each word by the same speaker. A single integrated spectral feature was formed without segmentation of the input, and without a direct comparison of the two items."
            },
            "slug": "Learning-Phonetic-Features-Using-Connectionist-Watrous-Shastri",
            "title": {
                "fragments": [],
                "text": "Learning Phonetic Features Using Connectionist Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "A method for learning phonetic features from speech data using connectionist networks is described and a supervised learning algorithm is presented which performs gradient descent in weight space using a coarse approximation of the desired output as an evaluation function."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2120460"
                        ],
                        "name": "L. Niles",
                        "slug": "L.-Niles",
                        "structuredName": {
                            "firstName": "Les",
                            "lastName": "Niles",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Niles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748100"
                        ],
                        "name": "H. Silverman",
                        "slug": "H.-Silverman",
                        "structuredName": {
                            "firstName": "Harvey",
                            "lastName": "Silverman",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Silverman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1918411"
                        ],
                        "name": "G. Tajchman",
                        "slug": "G.-Tajchman",
                        "structuredName": {
                            "firstName": "Gary",
                            "lastName": "Tajchman",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Tajchman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144959145"
                        ],
                        "name": "M. Bush",
                        "slug": "M.-Bush",
                        "structuredName": {
                            "firstName": "Marcia",
                            "lastName": "Bush",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bush"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61646362,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "853e23daa0704cd5f2aae6d55341fdf2423928e2",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Experiments comparing artificial neural network (ANN), k-nearest-neighbor (KNN), and Bayes' rule with Gaussian distributions and maximum-likelihood estimation (BGM) classifiers were performed. Classifier error rate as a function of training set size was tested for synthetic data drawn from several different probability distributions. In cases where the true distributions were poorly modeled, ANN was significantly better than BGM. In some cases, ANN was also better than KNN. Similar experiments were performed on a voiced/unvoiced speech classification task. ANN had a lower error rate than KNN or BGM for all training set sizes, although BGM approached the ANN error rate as the training set became larger. It is concluded that there are pattern classification tasks in which an ANN is able to make better use of training data to achieve a lower error rate with a particular size training set.<<ETX>>"
            },
            "slug": "How-limited-training-data-can-allow-a-neural-to-an-Niles-Silverman",
            "title": {
                "fragments": [],
                "text": "How limited training data can allow a neural network to outperform an 'optimal' statistical classifier"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is concluded that there are pattern classification tasks in which an ANN is able to make better use of training data to achieve a lower error rate with a particular size training set."
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Acoustics, Speech, and Signal Processing,"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2392554"
                        ],
                        "name": "S. M. Peeling",
                        "slug": "S.-M.-Peeling",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Peeling",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. M. Peeling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145914568"
                        ],
                        "name": "Roger K. Moore",
                        "slug": "Roger-K.-Moore",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Moore",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roger K. Moore"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62627748,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9bc28ae97fa99fc2463b6e8a107c01ff84db9fdd",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : The multi-layer perceptron is investigated as a new approach to the automatic recognition of spoken isolated digits. The choice of the parameters for the multi-layer perceptron is discussed and experimental results are reported. A comparison is made with established techniques such as dynamic time-warping and hidden Markov modelling applied to the same data. The results, for this particular task, show that the recognition accuracy obtained using the multi-layer perceptron is comparable with that from using hidden Markov modelling."
            },
            "slug": "Experiments-in-Isolated-Digit-Recognition-Using-the-Peeling-Moore",
            "title": {
                "fragments": [],
                "text": "Experiments in Isolated Digit Recognition Using the Multi-Layer Perceptron,"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The results show that the recognition accuracy obtained using the multi-layer perceptron is comparable with that from using hidden Markov modelling."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733733"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18821787,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6f3175b3930d0c71495a52a7bccb3889e5f33520",
            "isKey": false,
            "numCitedBy": 269,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We have done an empirical study of the relation of the number of parameters (weights) in a feedforward net to generalization performance. Two experiments are reported. In one, we use simulated data sets with well-controlled parameters, such as the signal-to-noise ratio of continuous-valued data. In the second, we train the network on vector-quantized mel cepstra from real speech samples. In each case, we use back-propagation to train the feedforward net to discriminate in a multiple class pattern classification problem. We report the results of these studies, and show the application of cross-validation techniques to prevent overfitting."
            },
            "slug": "Generalization-and-Parameter-Estimation-in-Netws:-Morgan-Bourlard",
            "title": {
                "fragments": [],
                "text": "Generalization and Parameter Estimation in Feedforward Netws: Some Experiments"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "An empirical study of the relation of the number of parameters (weights) in a feedforward net to generalization performance and the application of cross-validation techniques to prevent overfitting is done."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706196"
                        ],
                        "name": "S. Makino",
                        "slug": "S.-Makino",
                        "structuredName": {
                            "firstName": "Shozo",
                            "lastName": "Makino",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Makino"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1798454"
                        ],
                        "name": "T. Kawabata",
                        "slug": "T.-Kawabata",
                        "structuredName": {
                            "firstName": "Takeshi",
                            "lastName": "Kawabata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kawabata"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2241277"
                        ],
                        "name": "K. Kido",
                        "slug": "K.-Kido",
                        "structuredName": {
                            "firstName": "Ken'iti",
                            "lastName": "Kido",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kido"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 286,
                                "start": 219
                            }
                        ],
                        "text": "are consistent with other research showing the capabilities of MLPs trained with backpropagation-styled learning schemes for the recognition of voiced-unvoiced speech segments [Gevins & Morgan, 1984], isolated phonemes [Watrous & Shastri, 1987; Waibel et al., 1988; Makino et al., 1983], or of isolated words [peeling & Moore, 1988]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 37752577,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8f93ee2e335d83ee32787693861f4d48e78e6786",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a new method for the recognition of consonant based on the Perceptron model. The recognition model is composed of the sensory, feature extraction, response and lateral inhibition layers. The recognition scores of 90.4% to 98.4% are obtained for unvoiced affricates, unvoiced plosives, unvoiced and voiced fricatives."
            },
            "slug": "Recognition-of-consonant-based-on-the-perceptron-Makino-Kawabata",
            "title": {
                "fragments": [],
                "text": "Recognition of consonant based on the perceptron model"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "This paper proposes a new method for the recognition of consonant based on the Perceptron model, which is composed of the sensory, feature extraction, response and lateral inhibition layers."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34680849"
                        ],
                        "name": "A. Gevins",
                        "slug": "A.-Gevins",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Gevins",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gevins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143909996"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 9182120,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cbd05f1b1f325e4514a3ef20563d9e00a438ec58",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent work in artificial intelligence and signal processing has suggested that a merger of the two fields would be profitable for both (Kopec et al, 1982). Here we discuss the improvement of decision systems by the use of iterative mathematical techniques. These techniques could be called \"ignorance-based\" since they can be characterized by exhaustive searches for useful combinations of problem-relevant variables in data spaces for which human knowledge is incomplete."
            },
            "slug": "\"Ignorance-based\"-systems-Gevins-Morgan",
            "title": {
                "fragments": [],
                "text": "\"Ignorance-based\" systems"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work discusses the improvement of decision systems by the use of iterative mathematical techniques that can be characterized by exhaustive searches for useful combinations of problem-relevant variables in data spaces for which human knowledge is incomplete."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14942773"
                        ],
                        "name": "M. Stone",
                        "slug": "M.-Stone",
                        "structuredName": {
                            "firstName": "Mervyn",
                            "lastName": "Stone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Stone"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 119852865,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "3c429ad74f9f4cf2ad65b7fb292c34f78569da20",
            "isKey": false,
            "numCitedBy": 189,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Cross-validation:a-review-2-Stone",
            "title": {
                "fragments": [],
                "text": "Cross-validation:a review 2"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2122690"
                        ],
                        "name": "X. Aubert",
                        "slug": "X.-Aubert",
                        "structuredName": {
                            "firstName": "Xavier",
                            "lastName": "Aubert",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Aubert"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 38188868,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c6c6ddb031abf44b140c1d0939f6a41653ee29a7",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Supervised-segmentation-with-application-to-speech-Aubert",
            "title": {
                "fragments": [],
                "text": "Supervised segmentation with application to speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": "ECST"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Generalization and Parameter Estimation in Feedforward Nets: Some Experiments'\" Advances in Neural Information Processing Systems II"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Cross-validation: a review"
            },
            "venue": {
                "fragments": [],
                "text": "Matb. Operationforscb. Statist. Ser. Statist .@BULLET"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "How Limited Training Data Can Allow a Neural Network Classifier to Outperform an 'Optimal' Statistical Classifier"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE IntI. ConE. on Acoustics, Speecb, & Signal Processing"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "How Limited Training Data Can Allow a Neural Network Classifier to Outperform an 'Optimal' Statistical Classifier"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE IntI. ConE. on Acoustics, Speecb, & Signal Processing"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 76
                            }
                        ],
                        "text": "As shown by both theoretical [Bourlard & Wellekens, 1989] and experimental [Bourlard & Morgan, 1989] results, MLP output values may be considered to be good estimates of MAP probabilities for pattern classification."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Merging Multilayer Perceptrons and Hidden Markov Models: Some Experiments in Continuous Speech Recognition\" International Computer Science Institute lR-89-033"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Cross-validation: a review'\" Matb"
            },
            "venue": {
                "fragments": [],
                "text": "Operationforscb. Statist. Ser. Statist .\u2022"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 76
                            }
                        ],
                        "text": "As shown by both theoretical [Bourlard & Wellekens, 1989] and experimental [Bourlard & Morgan, 1989] results, MLP output values may be considered to be good estimates of MAP probabilities for pattern classification."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Merging Multilayer Perceptrons and Hidden Markov Models: Some Experiments in Continuous Speech Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "International Computer Science Institute"
            },
            "year": 1989
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 1,
            "methodology": 1,
            "result": 4
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 19,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/A-Continuous-Speech-Recognition-System-Embedding-Bourlard-Morgan/5001470e8808afe9887afbe48e2eaaf1a0395d10?sort=total-citations"
}