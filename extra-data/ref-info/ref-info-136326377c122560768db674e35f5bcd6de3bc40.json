{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7465342"
                        ],
                        "name": "Ido Dagan",
                        "slug": "Ido-Dagan",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Dagan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2807469"
                        ],
                        "name": "Oren Glickman",
                        "slug": "Oren-Glickman",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Glickman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Glickman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712352"
                        ],
                        "name": "B. Magnini",
                        "slug": "B.-Magnini",
                        "structuredName": {
                            "firstName": "Bernardo",
                            "lastName": "Magnini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Magnini"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 68
                            }
                        ],
                        "text": "The first PASCAL Recognising Textual Entailment Challenge (RTE-1), (Dagan et al., 2006) introduced the first benchmark for the entailment recognition task."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 216
                            }
                        ],
                        "text": "Similarly, semantic inference needs of other text understanding applications such as Information Retrieval (IR), Information Extraction (IE), and Machine Translation evaluation can be cast as entailment recognition (Dagan et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The 23 submissions for the challenge present diverse approaches and research directions, and the best results achieved this year are considerably higher than last year\u2019s state of the art."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8587959,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de794d50713ea5f91a7c9da3d72041e2f5ef8452",
            "isKey": false,
            "numCitedBy": 1762,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents the Third PASCAL Recognising Textual Entailment Challenge (RTE-3), providing an overview of the dataset creating methodology and the submitted systems. In creating this year's dataset, a number of longer texts were introduced to make the challenge more oriented to realistic scenarios. Additionally, a pool of resources was offered so that the participants could share common tools. A pilot task was also set up, aimed at differentiating unknown entailments from identified contradictions and providing justifications for overall system decisions. 26 participants submitted 44 runs, using different approaches and generally presenting new entailment models and achieving higher scores than in the previous challenges."
            },
            "slug": "The-PASCAL-Recognising-Textual-Entailment-Challenge-Dagan-Glickman",
            "title": {
                "fragments": [],
                "text": "The PASCAL Recognising Textual Entailment Challenge"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper presents the Third PASCAL Recognising Textual Entailment Challenge (RTE-3), providing an overview of the dataset creating methodology and the submitted systems."
            },
            "venue": {
                "fragments": [],
                "text": "MLCW"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1909300"
                        ],
                        "name": "Lucy Vanderwende",
                        "slug": "Lucy-Vanderwende",
                        "structuredName": {
                            "firstName": "Lucy",
                            "lastName": "Vanderwende",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lucy Vanderwende"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "83415753"
                        ],
                        "name": "W. Dolan",
                        "slug": "W.-Dolan",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Dolan",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Dolan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 55
                            }
                        ],
                        "text": "This approach is related to an earlier observation in (Vanderwende et al., 2005), which suggested that it is often easier to detect false entailment."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 44773438,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2237a7191a8fbf708aae9bab302a3990f51470e3",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe our submission to the PASCAL Recognizing Textual Entailment Challenge, which attempts to isolate the set of Text-Hypothesis pairs whose categorization can be accurately predicted based solely on syntactic cues. Two human annotators examined each pair, showing that a surprisingly large proportion of the data \u2013 34% of the test items \u2013 can be handled with syntax alone, while adding information from a general-purpose thesaurus increases this to 48%."
            },
            "slug": "What-Syntax-Can-Contribute-in-the-Entailment-Task-Vanderwende-Dolan",
            "title": {
                "fragments": [],
                "text": "What Syntax Can Contribute in the Entailment Task"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Two human annotators examined each pair of Text-Hypothesis pairs, showing that a surprisingly large proportion of the data can be handled with syntax alone, while adding information from a general-purpose thesaurus increases this to 48%."
            },
            "venue": {
                "fragments": [],
                "text": "MLCW"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5416402"
                        ],
                        "name": "J. Burger",
                        "slug": "J.-Burger",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Burger",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Burger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36405930"
                        ],
                        "name": "L. Ferro",
                        "slug": "L.-Ferro",
                        "structuredName": {
                            "firstName": "Lisa",
                            "lastName": "Ferro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Ferro"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 103
                            }
                        ],
                        "text": "Hickl et al. utilized a very large entailment corpus, automatically collected from the web, following (Burger and Ferro, 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2941806,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0724231630ccbc6e7b15740e49c42044507e6f39",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe our efforts to generate a large (100,000 instance) corpus of textual entailment pairs from the lead paragraph and headline of news articles. We manually inspected a small set of news stories in order to locate the most productive source of entailments, then built an annotation interface for rapid manual evaluation of further exemplars. With this training data we built an SVM-based document classifier, which we used for corpus refinement purposes---we believe that roughly three-quarters of the resulting corpus are genuine entailment pairs. We also discuss the difficulties inherent in manual entailment judgment, and suggest ways to ameliorate some of these."
            },
            "slug": "Generating-an-Entailment-Corpus-from-News-Headlines-Burger-Ferro",
            "title": {
                "fragments": [],
                "text": "Generating an Entailment Corpus from News Headlines"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This work manually inspected a small set of news stories in order to locate the most productive source of entailments, then built an annotation interface for rapid manual evaluation of further exemplars, and built an SVM-based document classifier for corpus refinement purposes."
            },
            "venue": {
                "fragments": [],
                "text": "EMSEE@ACL"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693525"
                        ],
                        "name": "Roy Bar-Haim",
                        "slug": "Roy-Bar-Haim",
                        "structuredName": {
                            "firstName": "Roy",
                            "lastName": "Bar-Haim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roy Bar-Haim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711977"
                        ],
                        "name": "Idan Szpektor",
                        "slug": "Idan-Szpektor",
                        "structuredName": {
                            "firstName": "Idan",
                            "lastName": "Szpektor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Idan Szpektor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2807469"
                        ],
                        "name": "Oren Glickman",
                        "slug": "Oren-Glickman",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Glickman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Glickman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 17
                            }
                        ],
                        "text": "Bar-Haim et al. (Bar-Haim et al., 2005) also showed by manually analyzing the RTE-1 dataset, that lexical systems are expected to achieve up to around 60%, if we require thath is fully lexically entailed from (covered by)t."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4940347,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "6f3da864c5f02f88443dc1254f20d71d3006fdea",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we define two intermediate models of textual entailment, which correspond to lexical and lexical-syntactic levels of representation. We manually annotated a sample from the RTE dataset according to each model, compared the outcome for the two models, and explored how well they approximate the notion of entailment. We show that the lexical-syntactic model outperforms the lexical model, mainly due to a much lower rate of false-positives, but both models fail to achieve high recall. Our analysis also shows that paraphrases stand out as a dominant contributor to the entailment task. We suggest that our models and annotation methods can serve as an evaluation scheme for entailment at these levels."
            },
            "slug": "Definition-and-Analysis-of-Intermediate-Entailment-Bar-Haim-Szpektor",
            "title": {
                "fragments": [],
                "text": "Definition and Analysis of Intermediate Entailment Levels"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "This paper defines two intermediate models of textual entailment, which correspond to lexical and lexical-syntactic levels of representation, and suggests that these models and annotation methods can serve as an evaluation scheme for entailment at these levels."
            },
            "venue": {
                "fragments": [],
                "text": "EMSEE@ACL"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749194"
                        ],
                        "name": "Collin F. Baker",
                        "slug": "Collin-F.-Baker",
                        "structuredName": {
                            "firstName": "Collin",
                            "lastName": "Baker",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Collin F. Baker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2912454"
                        ],
                        "name": "C. Fillmore",
                        "slug": "C.-Fillmore",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Fillmore",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fillmore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1406118956"
                        ],
                        "name": "John B. Lowe",
                        "slug": "John-B.-Lowe",
                        "structuredName": {
                            "firstName": "John B.",
                            "lastName": "Lowe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John B. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2505531,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "547f23597f9ec8a93f66cedaa6fbfb73960426b1",
            "isKey": false,
            "numCitedBy": 2882,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "FrameNet is a three-year NSF-supported project in corpus-based computational lexicography, now in its second year (NSF IRI-9618838, \"Tools for Lexicon Building\"). The project's key features are (a) a commitment to corpus evidence for semantic and syntactic generalizations, and (b) the representation of the valences of its target words (mostly nouns, adjectives, and verbs) in which the semantic portion makes use of frame semantics. The resulting database will contain (a) descriptions of the semantic frames underlying the meanings of the words described, and (b) the valence representation (semantic and syntactic) of several thousand words and phrases, each accompanied by (c) a representative collection of annotated corpus attestations, which jointly exemplify the observed linkings between \"frame elements\" and their syntactic realizations (e.g. grammatical function, phrase type, and other syntactic traits). This report will present the project's goals and workflow, and information about the computational tools that have been adapted or created in-house for this work."
            },
            "slug": "The-Berkeley-FrameNet-Project-Baker-Fillmore",
            "title": {
                "fragments": [],
                "text": "The Berkeley FrameNet Project"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This report will present the project's goals and workflow, and information about the computational tools that have been adapted or created in-house for this work."
            },
            "venue": {
                "fragments": [],
                "text": "COLING-ACL"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2807469"
                        ],
                        "name": "Oren Glickman",
                        "slug": "Oren-Glickman",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Glickman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Glickman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7465342"
                        ],
                        "name": "Ido Dagan",
                        "slug": "Ido-Dagan",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Dagan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145200175"
                        ],
                        "name": "Moshe Koppel",
                        "slug": "Moshe-Koppel",
                        "structuredName": {
                            "firstName": "Moshe",
                            "lastName": "Koppel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Moshe Koppel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 109
                            }
                        ],
                        "text": "In the RTE-1 challenge, one of the two best performing systems was based on lexical statistics from the web (Glickman et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18932093,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "5b615430893b698341d9da67f1bf7c8a72fc9b4f",
            "isKey": false,
            "numCitedBy": 89,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a general probabilistic setting that formalizes the notion of textual entailment. In addition we describe a concrete model for lexical entailment based on web co-occurrence statistics in a bag of words representation."
            },
            "slug": "Web-Based-Probabilistic-Textual-Entailment-Glickman-Dagan",
            "title": {
                "fragments": [],
                "text": "Web Based Probabilistic Textual Entailment"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A general probabilistic setting that formalizes the notion of textual entailment and a concrete model for lexical entailment based on web co-occurrence statistics in a bag of words representation are proposed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145312626"
                        ],
                        "name": "J. R. Landis",
                        "slug": "J.-R.-Landis",
                        "structuredName": {
                            "firstName": "J",
                            "lastName": "Landis",
                            "middleNames": [
                                "Richard"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. R. Landis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31839425"
                        ],
                        "name": "G. Koch",
                        "slug": "G.-Koch",
                        "structuredName": {
                            "firstName": "Gary",
                            "lastName": "Koch",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Koch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 195
                            }
                        ],
                        "text": "The average agreement on the test set (between each pair of annotators who shared at least 100 examples), was 89.2%, with average Kappa level of 0.78, which corresponds to \u201csubstantial agreement\u201d (Landis and Koch, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11077516,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "7e7343a5608fff1c68c5259db0c77b9193f1546d",
            "isKey": true,
            "numCitedBy": 59422,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a general statistical methodology for the analysis of multivariate categorical data arising from observer reliability studies. The procedure essentially involves the construction of functions of the observed proportions which are directed at the extent to which the observers agree among themselves and the construction of test statistics for hypotheses involving these functions. Tests for interobserver bias are presented in terms of first-order marginal homogeneity and measures of interobserver agreement are developed as generalized kappa-type statistics. These procedures are illustrated with a clinical diagnosis example from the epidemiological literature."
            },
            "slug": "The-measurement-of-observer-agreement-for-data.-Landis-Koch",
            "title": {
                "fragments": [],
                "text": "The measurement of observer agreement for categorical data."
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A general statistical methodology for the analysis of multivariate categorical data arising from observer reliability studies is presented and tests for interobserver bias are presented in terms of first-order marginal homogeneity and measures of interob server agreement are developed as generalized kappa-type statistics."
            },
            "venue": {
                "fragments": [],
                "text": "Biometrics"
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746656"
                        ],
                        "name": "E. Voorhees",
                        "slug": "E.-Voorhees",
                        "structuredName": {
                            "firstName": "Ellen",
                            "lastName": "Voorhees",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Voorhees"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 86
                            }
                        ],
                        "text": "\u2022 Cases in which inference is very probable (but\nnot completely certain) are judged as YES."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 350,
                                "start": 347
                            }
                        ],
                        "text": "This task was evaluated using theAverage precisionmeasure, which is a common evaluation measure for ranking (e.g. in information retrieval), and is computed as the average of the system\u2019s precision values at all points in the ranked list in which recall increases, that is at all points in the ranked list for which the gold standard annotation is YES (Voorhees and Harman, 1999)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 290,
                                "start": 265
                            }
                        ],
                        "text": "\u2026measure for ranking (e.g. in information retrieval), and is computed as the average of the system\u2019s precision values at all points in the ranked list in which recall increases, that is at all points in the ranked list for which the gold standard annotation is YES (Voorhees and Harman, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 95
                            }
                        ],
                        "text": "Within each application setting the annotators selected positive entailment examples (annotatedYES), wheret does entailh, as well as negative examples (annotatedNO), where entailment does not hold (50%-50% split, as in RTE-1)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 86
                            }
                        ],
                        "text": "Each pair was annotated with its related task (IE/IR/QA/SUM) and entailment judgment (YES/NO, released only in the development set)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 60993275,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a07c4d5acf87e012a1a40c82d48d056b43b4aabc",
            "isKey": true,
            "numCitedBy": 198,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Overview-of-the-Seventh-Text-REtrieval-Conference-Voorhees",
            "title": {
                "fragments": [],
                "text": "Overview of the Seventh Text REtrieval Conference"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7465342"
                        ],
                        "name": "Ido Dagan",
                        "slug": "Ido-Dagan",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Dagan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2807469"
                        ],
                        "name": "Oren Glickman",
                        "slug": "Oren-Glickman",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Glickman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Glickman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 25
                            }
                        ],
                        "text": "This task, introduced by Dagan and Glickman (2004), captures generically a broad range of inferences that are relevant for multiple applications."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 127
                            }
                        ],
                        "text": "One of the main goals for this year\u2019s dataset was to provide more \u201crealistic\u201d text-hypothesis examples, based mostly on outputs of actual systems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17200692,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "da236f03773145a3a1e3246c94c5e0e526fcbe4b",
            "isKey": false,
            "numCitedBy": 264,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "PROBABILISTIC-TEXTUAL-ENTAILMENT:-GENERIC-APPLIED-Dagan-Glickman",
            "title": {
                "fragments": [],
                "text": "PROBABILISTIC TEXTUAL ENTAILMENT: GENERIC APPLIED MODELING OF LANGUAGE VARIABILITY"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 78
                            }
                        ],
                        "text": "These methods include lexical overlapping, based on lexicons such as WordNet (Miller, 1995) and automatically acquired resources which are based on statistical measures; ngram matching and subsequence overlapping be-\ntween t and h; syntactic matching, e.g. relation matching, and tree edit distance\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 69
                            }
                        ],
                        "text": "These methods include lexical overlapping, based on lexicons such as WordNet (Miller, 1995) and automatically acquired resources which are based on statistical measures; ngram matching and subsequence overlapping be-\ntween t and h; syntactic matching, e.g. relation matching, and tree edit distance algorithms; semantic annotation induced using resources such as FrameNet (Baker et al., 1998); logical inference using logic provers; statistics computed from local corpora or the Web (including statical measures available for lexical resources such as WordNet); usage of background knowledge, including inference rules and paraphrase templates, and acquisition (automatic and manual) of additional entailment corpora."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "WordNet: A Lexical Databases for English"
            },
            "venue": {
                "fragments": [],
                "text": "Communications of the ACM"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "@BULLET MUC-4 information extraction dataset, from the National Institute of Standards and Technology (NIST)"
            },
            "venue": {
                "fragments": [],
                "text": "@BULLET MUC-4 information extraction dataset, from the National Institute of Standards and Technology (NIST)"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "@BULLET New York University's information extraction system, provided by Ralph Grishman"
            },
            "venue": {
                "fragments": [],
                "text": "@BULLET New York University's information extraction system, provided by Ralph Grishman"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "@BULLET ITC-irst's information extraction system, provided by Lorenza Romano, Cognitive and Communication Technologies (TCC) division, ITC-irst"
            },
            "venue": {
                "fragments": [],
                "text": "@BULLET ITC-irst's information extraction system, provided by Lorenza Romano, Cognitive and Communication Technologies (TCC) division, ITC-irst"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "02/related projects/muc/ @BULLET ACE 2004 information extraction templates, from the National Institute of Standards and Technology (NIST)"
            },
            "venue": {
                "fragments": [],
                "text": "02/related projects/muc/ @BULLET ACE 2004 information extraction templates, from the National Institute of Standards and Technology (NIST)"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "@BULLET IBM's information extraction system"
            },
            "venue": {
                "fragments": [],
                "text": "@BULLET IBM's information extraction system"
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 6,
            "methodology": 2,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 15,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/The-Second-PASCAL-Recognising-Textual-Entailment-Bar-Haim-Dagan/136326377c122560768db674e35f5bcd6de3bc40?sort=total-citations"
}