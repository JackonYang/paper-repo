{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689647"
                        ],
                        "name": "Peter D. Turney",
                        "slug": "Peter-D.-Turney",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Turney",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter D. Turney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 152
                            }
                        ],
                        "text": "PMI-IR has been empirically evaluated using 80 synonym test questions from the Test of English as a Foreign Language (TOEFL), obtaining a score of 74% (Turney, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 83
                            }
                        ],
                        "text": "The PMI-IR algorithm is employed to estimate the semantic orientation of a phrase (Turney, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 126
                            }
                        ],
                        "text": "Previous work has shown that NEAR performs better than AND when measuring the strength of semantic association between words (Turney, 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 99
                            }
                        ],
                        "text": "The core of the algorithm is the second step, which uses PMI-IR to calculate semantic orientation (Turney, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5509836,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e517e1645708e7b050787bb4734002ea194a1958",
            "isKey": false,
            "numCitedBy": 1474,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a simple unsupervised learning algorithm for recognizing synonyms, based on statistical data acquired by querying a Web search engine. The algorithm, called PMI-IR, uses Pointwise Mutual Information (PMI) and Information Retrieval (IR) to measure the similarity of pairs of words. PMI-IR is empirically evaluated using 80 synonym test questions from the Test of English as a Foreign Language (TOEFL) and 50 synonym test questions from a collection of tests for students of English as a Second Language (ESL). On both tests, the algorithm obtains a score of 74%. PMI-IR is contrasted with Latent Semantic Analysis (LSA), which achieves a score of 64% on the same 80 TOEFL questions. The paper discusses potential applications of the new unsupervised learning algorithm and some implications of the results for LSA and LSI (Latent Semantic Indexing)."
            },
            "slug": "Mining-the-Web-for-Synonyms:-PMI-IR-versus-LSA-on-Turney",
            "title": {
                "fragments": [],
                "text": "Mining the Web for Synonyms: PMI-IR versus LSA on TOEFL"
            },
            "venue": {
                "fragments": [],
                "text": "ECML"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244184"
                        ],
                        "name": "Kenneth Ward Church",
                        "slug": "Kenneth-Ward-Church",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Church",
                            "middleNames": [
                                "Ward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Ward Church"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145165877"
                        ],
                        "name": "P. Hanks",
                        "slug": "P.-Hanks",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Hanks",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hanks"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9558665,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "9e2caa39ac534744a180972a30a320ad0ae41ea3",
            "isKey": false,
            "numCitedBy": 4363,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "The term word association is used in a very particular sense in the psycholinguistic literature. (Generally speaking, subjects respond quicker than normal to the word nurse if it follows a highly associated word such as doctor. ) We will extend the term to provide the basis for a statistical description of a variety of interesting linguistic phenomena, ranging from semantic relations of the doctor/nurse type (content word/content word) to lexico-syntactic co-occurrence constraints between verbs and prepositions (content word/function word). This paper will propose an objective measure based on the information theoretic notion of mutual information, for estimating word association norms from computer readable corpora. (The standard method of obtaining word association norms, testing a few thousand subjects on a few hundred words, is both costly and unreliable.) The proposed measure, the association ratio, estimates word association norms directly from computer readable corpora, making it possible to estimate norms for tens of thousands of words."
            },
            "slug": "Word-Association-Norms,-Mutual-Information-and-Church-Hanks",
            "title": {
                "fragments": [],
                "text": "Word Association Norms, Mutual Information and Lexicography"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The proposed measure, the association ratio, estimates word association norms directly from computer readable corpora, making it possible to estimate norms for tens of thousands of words."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799688"
                        ],
                        "name": "V. Hatzivassiloglou",
                        "slug": "V.-Hatzivassiloglou",
                        "structuredName": {
                            "firstName": "Vasileios",
                            "lastName": "Hatzivassiloglou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Hatzivassiloglou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145590324"
                        ],
                        "name": "K. McKeown",
                        "slug": "K.-McKeown",
                        "structuredName": {
                            "firstName": "Kathleen",
                            "lastName": "McKeown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. McKeown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8162001,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b62b80384f402d38c3425db6a99899d1cb9c50c6",
            "isKey": false,
            "numCitedBy": 1301,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We identify and validate from a large corpus constraints from conjunctions on the positive or negative semantic orientation of the conjoined adjectives. A log-linear regression model uses these constraints to predict whether conjoined adjectives are of same or different orientations, achieving 82% accuracy in this task when each conjunction is considered independently. Combining the constraints across many adjectives, a clustering algorithm separates the adjectives into groups of different orientations, and finally, adjectives are labeled positive or negative. Evaluations on real data and simulation experiments indicate high levels of performance: classification precision is more than 90% for adjectives that occur in a modest number of conjunctions in the corpus."
            },
            "slug": "Predicting-the-Semantic-Orientation-of-Adjectives-Hatzivassiloglou-McKeown",
            "title": {
                "fragments": [],
                "text": "Predicting the Semantic Orientation of Adjectives"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "A log-linear regression model uses constraints from conjunctions to predict whether conjoined adjectives are of same or different orientations, achieving 82% accuracy in this task when each conjunction is considered independently."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144120827"
                        ],
                        "name": "J. Wiebe",
                        "slug": "J.-Wiebe",
                        "structuredName": {
                            "firstName": "Janyce",
                            "lastName": "Wiebe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wiebe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 145
                            }
                        ],
                        "text": "Past work has demonstrated that adjectives are good indicators of subjective, evaluative sentences (Hatzivassiloglou\n2 http://www.epinions.com\n& Wiebe, 2000; Wiebe, 2000; Wiebe et al., 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 136
                            }
                        ],
                        "text": "The task is to distinguish sentences that present opinions and evaluations from sentences that objectively present factual information (Wiebe, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 82
                            }
                        ],
                        "text": "Other related work is concerned with determining subjectivity (Hatzivassiloglou & Wiebe, 2000; Wiebe, 2000; Wiebe et al., 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14170522,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5581992944c66522dd1b11f8a6150aeef2d95b7a",
            "isKey": false,
            "numCitedBy": 598,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Subjectivity tagging is distinguishing sentences used to present opinions and evaluations from sentences used to objectively present factual information. There are numerous applications for which subjectivity tagging is relevant, including information extraction and information retrieval. This paper identifies strong clues of subjectivity using the results of a method for clustering words according to distributional similarity (Lin 1998), seeded by a small amount of detailed manual annotation. These features are then further refined with the addition of lexical semantic features of adjectives, specifically polarity and gradability (Hatzivassiloglou & McKeown 1997), which can be automatically learned from corpora. In 10-fold cross validation experiments, features based on both similarity clusters and the lexical semantic features are shown to have higher precision than features based on each alone."
            },
            "slug": "Learning-Subjective-Adjectives-from-Corpora-Wiebe",
            "title": {
                "fragments": [],
                "text": "Learning Subjective Adjectives from Corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper identifies strong clues of subjectivity using the results of a method for clustering words according to distributional similarity (Lin 1998), seeded by a small amount of detailed manual annotation."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1836606"
                        ],
                        "name": "T. Landauer",
                        "slug": "T.-Landauer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Landauer",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Landauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728602"
                        ],
                        "name": "S. Dumais",
                        "slug": "S.-Dumais",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "Dumais",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dumais"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 283,
                                "start": 260
                            }
                        ],
                        "text": "For comparison, Latent Semantic Analysis (LSA), another statistical measure of word association, attains a score of 64% on the\n3 http://www.cs.jhu.edu/~brill/RBT1_14.tar.Z 4 See Santorini (1995) for a complete description of the tags.\nsame 80 TOEFL questions (Landauer & Dumais, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "same 80 TOEFL questions ( Landauer & Dumais,  1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1144461,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "68dd4b89ce1407372a29d05ca9e4e1a2e0513617",
            "isKey": false,
            "numCitedBy": 5788,
            "numCiting": 210,
            "paperAbstract": {
                "fragments": [],
                "text": "How do people know as much as they do with as little information as they get? The problem takes many forms; learning vocabulary from text is an especially dramatic and convenient case for research. A new general theory of acquired similarity and knowledge representation, latent semantic analysis (LSA), is presented and used to successfully simulate such learning and several other psycholinguistic phenomena. By inducing global knowledge indirectly from local co-occurrence data in a large body of representative text, LSA acquired knowledge about the full vocabulary of English at a comparable rate to schoolchildren. LSA uses no prior linguistic or perceptual similarity knowledge; it is based solely on a general mathematical learning method that achieves powerful inductive effects by extracting the right number of dimensions (e.g., 300) to represent objects and contexts. Relations to other theories, phenomena, and problems are sketched."
            },
            "slug": "A-Solution-to-Plato's-Problem:-The-Latent-Semantic-Landauer-Dumais",
            "title": {
                "fragments": [],
                "text": "A Solution to Plato's Problem: The Latent Semantic Analysis Theory of Acquisition, Induction, and Representation of Knowledge."
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A new general theory of acquired similarity and knowledge representation, latent semantic analysis (LSA), is presented and used to successfully simulate such learning and several other psycholinguistic phenomena."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716902"
                        ],
                        "name": "Marti A. Hearst",
                        "slug": "Marti-A.-Hearst",
                        "structuredName": {
                            "firstName": "Marti",
                            "lastName": "Hearst",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marti A. Hearst"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16266534,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3c4e3462e3e9f0dd7b379f3e300ff47eefa803e5",
            "isKey": false,
            "numCitedBy": 151,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "A Text-Based Intelligent System should provide more in-depth information about the contents of its corpus than does a standard information retrieval system, while at the same time avoiding the complexity and resource-consuming behavior of detailed text understanders. Instead of focusing on discovering documents that pertain to some topic of interest to the user, an approach is introduced based on the criterion of directionality (e.g., Is the agent in favor of, neutral, or opposed to the event?). A method is described for coercing sentence meanings into a metaphoric model such that the only semantic interpretation needed in order to determine the directionality of a sentence is done with respect to the model. This interpretation method is designed to be an integrated component of a hybrid information access system."
            },
            "slug": "Direction-based-text-interpretation-as-an-access-Hearst",
            "title": {
                "fragments": [],
                "text": "Direction-based text interpretation as an information access refinement"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A method is described for coercing sentence meanings into a metaphoric model such that the only semantic interpretation needed in order to determine the directionality of a sentence is done with respect to the model."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143713826"
                        ],
                        "name": "Eibe Frank",
                        "slug": "Eibe-Frank",
                        "structuredName": {
                            "firstName": "Eibe",
                            "lastName": "Frank",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eibe Frank"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "118860642"
                        ],
                        "name": "M. Hall",
                        "slug": "M.-Hall",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Hall",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hall"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "I plan to experiment with ordinal classification of reviews in the five star rating system, using the algorithm of Frank and Hall (2001). For ordinal classification, the average semantic orientation would be supplemented with other features in a supervised classification system."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 115
                            }
                        ],
                        "text": "I plan to experiment with ordinal classification of reviews in the five star rating system, using the algorithm of Frank and Hall (2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12269265,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "76fc26939d73c565431e1f38107a4245e739284e",
            "isKey": false,
            "numCitedBy": 509,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Machine learning methods for classification problems commonly assume that the class values are unordered. However, in many practical applications the class values do exhibit a natural order--for example, when learning how to grade. The standard approach to ordinal classification converts the class value into a numeric quantity and applies a regression learner to the transformed data, translating the output back into a discrete class value in a post-processing step. A disadvantage of this method is that it can only be applied in conjunction with a regression scheme. \n \nIn this paper we present a simple method that enables standard classification algorithms to make use of ordering information in class attributes. By applying it in conjunction with a decision tree learner we show that it outperforms the naive approach, which treats the class values as an unordered set. Compared to special-purpose algorithms for ordinal classification our method has the advantage that it can be applied without any modification to the underlying learning scheme."
            },
            "slug": "A-Simple-Approach-to-Ordinal-Classification-Frank-Hall",
            "title": {
                "fragments": [],
                "text": "A Simple Approach to Ordinal Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper presents a simple method that enables standard classification algorithms to make use of ordering information in class attributes and shows that it outperforms the naive approach, which treats the class values as an unordered set."
            },
            "venue": {
                "fragments": [],
                "text": "ECML"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2424234"
                        ],
                        "name": "Beatrice Santorini",
                        "slug": "Beatrice-Santorini",
                        "structuredName": {
                            "firstName": "Beatrice",
                            "lastName": "Santorini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Beatrice Santorini"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 178
                            }
                        ],
                        "text": "For comparison, Latent Semantic Analysis (LSA), another statistical measure of word association, attains a score of 64% on the\n3 http://www.cs.jhu.edu/~brill/RBT1_14.tar.Z 4 See Santorini (1995) for a complete description of the tags.\nsame 80 TOEFL questions (Landauer & Dumais, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "See http://www.conman.org/people/spc/robots2.html.\ntroduction, one application is to provide summary statistics for search engines."
                    },
                    "intents": []
                }
            ],
            "corpusId": 60354878,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a145854ede2f62098bf4e92de1584ab270b676c9",
            "isKey": false,
            "numCitedBy": 483,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "This manual addresses the linguistic issues that arise in connection with annotating texts by part of speech (\"tagging\"). Section 2 is an alphabetical list of the parts of speech encoded in the annotation systems of the Penn Treebank Project, along with their corresponding abbreviations (\"tags\") and some information concerning their definition. This section allows you to find an unfamiliar tag by looking up a familiar part of speech. Section 3 recapitulates the information in Section 2, but this time the information is alphabetically ordered by tags. This is the section to consult in order to find out what an unfamiliar tag means. Since the parts of speech are probably familiar to you from high school English, you should have little difficulty in assimilating the tags themselves. However, it is often quite difficult to decide which tag is appropriate in a particular context. The two sections 4 and 5 therefore include examples and guidelines on how to tag problematic cases. If you are uncertain about whether a given tag is correct or not, refer to these sections in order to ensure a consistently annotated text. Section 4 discusses parts of speech that are easily confused and gives guidelines on how to tag such cases, while Section 5 contains an alphabetical list of specific problematic words and collocations. Finally, Section 6 discusses some general tagging conventions. One general rule, however, is so important that we state it here. Many texts are not models of good prose, and some contain outright errors and slips of the pen. Do not be tempted to correct a tag to what it would be if the text were correct; rather, it is the incorrect word that should be tagged correctly. Disciplines Computer Sciences Comments University of Pennsylvania Department of Computer and Information Science Technical Report No. MSCIS-90-47. This technical report is available at ScholarlyCommons: http://repository.upenn.edu/cis_reports/570 Part-of-S peech Tagging Guidelines For The Penn Treebank Project (3rd Revision) MS-CIS-90-47 LINC LAB 178"
            },
            "slug": "Part-of-Speech-Tagging-Guidelines-for-the-Penn-(3rd-Santorini",
            "title": {
                "fragments": [],
                "text": "Part-of-Speech Tagging Guidelines for the Penn Treebank Project (3rd Revision)"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "This manual addresses the linguistic issues that arise in connection with annotating texts by part of speech (\"tagging\") and discusses parts of speech that are easily confused and gives guidelines on how to tag such cases."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799688"
                        ],
                        "name": "V. Hatzivassiloglou",
                        "slug": "V.-Hatzivassiloglou",
                        "structuredName": {
                            "firstName": "Vasileios",
                            "lastName": "Hatzivassiloglou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Hatzivassiloglou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144120827"
                        ],
                        "name": "J. Wiebe",
                        "slug": "J.-Wiebe",
                        "structuredName": {
                            "firstName": "Janyce",
                            "lastName": "Wiebe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wiebe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 100
                            }
                        ],
                        "text": "Past work has demonstrated that adjectives are good indicators of subjective, evaluative sentences (Hatzivassiloglou\n2 http://www.epinions.com\n& Wiebe, 2000; Wiebe, 2000; Wiebe et al., 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 63
                            }
                        ],
                        "text": "Other related work is concerned with determining subjectivity (Hatzivassiloglou & Wiebe, 2000; Wiebe, 2000; Wiebe et al., 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 566696,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3a8d4fd2c30e5031a574bc25363c8639912b3bbd",
            "isKey": false,
            "numCitedBy": 752,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Subjectivity is a pragmatic, sentence-level feature that has important implications for text processing applications such as information extraction and information retrieval. We study the effects of dynamic adjectives, semantically oriented adjectives, and gradable adjectives on a simple subjectivity classifier, and establish that they are strong predictors of subjectivity. A novel trainable method that statistically combines two indicators of gradability is presented and evaluated, complementing existing automatic techniques for assigning orientation labels."
            },
            "slug": "Effects-of-Adjective-Orientation-and-Gradability-on-Hatzivassiloglou-Wiebe",
            "title": {
                "fragments": [],
                "text": "Effects of Adjective Orientation and Gradability on Sentence Subjectivity"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel trainable method that statistically combines two indicators of gradability is presented and evaluated, complementing existing automatic techniques for assigning orientation labels."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145022783"
                        ],
                        "name": "E. Brill",
                        "slug": "E.-Brill",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Brill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Brill"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12309040,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "733234e097dceb9011baa8914930861996eb0b5e",
            "isKey": false,
            "numCitedBy": 624,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Most recent research in trainable part of speech taggers has explored stochastic tagging. While these taggers obtain high accuracy, linguistic information is captured indirectly, typically in tens of thousands of lexical and contextual probabilities. In (Brill 1992), a trainable rule-based tagger was described that obtained performance comparable to that of stochastic taggers, but captured relevant linguistic information in a small number of simple non-stochastic rules. In this paper, we describe a number of extensions to this rule-based tagger. First, we describe a method for expressing lexical relations in tagging that stochastic taggers are currently unable to express. Next, we show a rule-based approach to tagging unknown words. Finally, we show how the tagger-can be extended into a k-best tagger, where multiple tags can be assigned to words in some cases of uncertainty."
            },
            "slug": "Some-Advances-in-Transformation-Based-Part-of-Brill",
            "title": {
                "fragments": [],
                "text": "Some Advances in Transformation-Based Part of Speech Tagging"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A method for expressing lexical relations in tagging that stochastic taggers are currently unable to express is described and how the tagger-can be extended into a k-best tagger, where multiple tags can be assigned to words in some cases of uncertainty."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144120827"
                        ],
                        "name": "J. Wiebe",
                        "slug": "J.-Wiebe",
                        "structuredName": {
                            "firstName": "Janyce",
                            "lastName": "Wiebe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wiebe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2614094"
                        ],
                        "name": "Rebecca F. Bruce",
                        "slug": "Rebecca-F.-Bruce",
                        "structuredName": {
                            "firstName": "Rebecca",
                            "lastName": "Bruce",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rebecca F. Bruce"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070448281"
                        ],
                        "name": "Matthew Bell",
                        "slug": "Matthew-Bell",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Bell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew Bell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110731789"
                        ],
                        "name": "Melanie J. Martin",
                        "slug": "Melanie-J.-Martin",
                        "structuredName": {
                            "firstName": "Melanie",
                            "lastName": "Martin",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Melanie J. Martin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47481818"
                        ],
                        "name": "Theresa Wilson",
                        "slug": "Theresa-Wilson",
                        "structuredName": {
                            "firstName": "Theresa",
                            "lastName": "Wilson",
                            "middleNames": [],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Theresa Wilson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 171
                            }
                        ],
                        "text": "Past work has demonstrated that adjectives are good indicators of subjective, evaluative sentences (Hatzivassiloglou\n2 http://www.epinions.com\n& Wiebe, 2000; Wiebe, 2000; Wiebe et al., 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 0
                            }
                        ],
                        "text": "Wiebe et al. (2001) list a variety of potential applications for automated subjectivity tagging, such as recognizing \u201c flames\u201d (Spertus, 1997), classifying email, recognizing speaker role in radio broadcasts, and mining reviews."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 108
                            }
                        ],
                        "text": "Other related work is concerned with determining subjectivity (Hatzivassiloglou & Wiebe, 2000; Wiebe, 2000; Wiebe et al., 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 470433,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "473801b545a666f5409ef7f3cbc5725976902a5a",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a corpus study of evaluative and speculative language. Knowledge of such language would be useful in many applications, such as text categorization and summarization. Analyses of annotator agreement and of characteristics of subjective language are performed. This study yields knowledge needed to design effective machine learning systems for identifying subjective language."
            },
            "slug": "A-Corpus-Study-of-Evaluative-and-Speculative-Wiebe-Bruce",
            "title": {
                "fragments": [],
                "text": "A Corpus Study of Evaluative and Speculative Language"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This study yields knowledge needed to design effective machine learning systems for identifying subjective language, and analyses of annotator agreement and of characteristics of subjective language are performed."
            },
            "venue": {
                "fragments": [],
                "text": "SIGDIAL Workshop"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3093018"
                        ],
                        "name": "Ellen Spertus",
                        "slug": "Ellen-Spertus",
                        "structuredName": {
                            "firstName": "Ellen",
                            "lastName": "Spertus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ellen Spertus"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 86
                            }
                        ],
                        "text": "Other potential applications include recognizing \u201c flames\u201d (abusive newsgroup messages) (Spertus, 1997) and developing new kinds of search tools (Hearst, 1992)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 113
                            }
                        ],
                        "text": "(2001) list a variety of potential applications for automated subjectivity tagging, such as recognizing \u201cflames\u201d (Spertus, 1997), classifying email, recognizing speaker role in radio broadcasts, and mining reviews."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 125
                            }
                        ],
                        "text": "Wiebe et al. (2001) list a variety of potential applications for automated subjectivity tagging, such as recognizing \u201c flames\u201d (Spertus, 1997), classifying email, recognizing speaker role in radio broadcasts, and mining reviews."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 87
                            }
                        ],
                        "text": "Other potential applications include recognizing \u201cflames\u201d (abusive newsgroup messages) (Spertus, 1997) and developing new kinds of search tools (Hearst, 1992)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 66
                            }
                        ],
                        "text": "Another potential application is filtering \u201c flames\u201d for newsgroups (Spertus, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 67
                            }
                        ],
                        "text": "Another potential application is filtering \u201cflames\u201d for newsgroups (Spertus, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 26817854,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9567b8782f7bcf3f94c7543e36062f77bf584f5b",
            "isKey": true,
            "numCitedBy": 309,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Abusive messages (flames) can be both a source of frustration and a waste of time for Internet users. This paper . describes some approaches to flame recognition, mcluding a prototype system, Smokey. Smokey builds a 47-element feature vector based on the syntax and semantics of each sentence, combining the vectors for the sentences within each message. A training set of 720 messages was used by Quinlan's C4.5 decision-tree generator to determine feature-based rules that were able to correctly categorize 64% of the flames and 98% of the nonflames in a separate test set of 460 messages. Additional techniques for greater accuracy and user customization are also discussed."
            },
            "slug": "Smokey:-Automatic-Recognition-of-Hostile-Messages-Spertus",
            "title": {
                "fragments": [],
                "text": "Smokey: Automatic Recognition of Hostile Messages"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "Some approaches to flame recognition are described, mcluding a prototype system, Smokey, which builds a 47-element feature vector based on the syntax and semantics of each sentence, combining the vectors for the sentences within each message."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2817272"
                        ],
                        "name": "A. Agresti",
                        "slug": "A.-Agresti",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Agresti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Agresti"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 286,
                                "start": 273
                            }
                        ],
                        "text": "\u2026(1) and (2) with\n5 http://www.altavista.com/sites/search/adv\nsome minor algebraic manipulation, if cooccurrence is interpreted as NEAR:\nSO(phrase) =\nhits(phrase NEAR \u201cexcellent\u201d ) hits(\u201cpoor\u201d) log2 hits(phrase NEAR \u201cpoor\u201d) hits(\u201cexcellent\u201d )\n(3)\nEquation (3) is a log-odds ratio (Agresti, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 63
                            }
                        ],
                        "text": "It might benefit from more sophisticated statistical analysis (Agresti, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 91176244,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "e217ab0cbe2d9db16c37756e84341fda7999520d",
            "isKey": false,
            "numCitedBy": 6957,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Two--Way Contingency Tables. Three--Way Contingency Tables. Generalized Linear Models. Logistic Regression. Loglinear Models for Contingency Tables. Building and Applying Logit and Loglinear Models. Multicategory Logit Models. Models for Matched Pairs. A Twentieth--Century Tour of Categorical Data Analysis. Appendix. Table of Chi--Squared Distribution Values for Various Right--Tail Probabilities. Bibliography. Indexes."
            },
            "slug": "An-introduction-to-categorical-data-analysis-Agresti",
            "title": {
                "fragments": [],
                "text": "An introduction to categorical data analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 152
                            }
                        ],
                        "text": "PMI-IR has been empirically evaluated using 80 synonym test questions from the Test of English as a Foreign Language (TOEFL), obtaining a score of 74% (Turney, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 83
                            }
                        ],
                        "text": "The PMI-IR algorithm is employed to estimate the semantic orientation of a phrase (Turney, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 126
                            }
                        ],
                        "text": "Previous work has shown that NEAR performs better than AND when measuring the strength of semantic association between words (Turney, 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 99
                            }
                        ],
                        "text": "The core of the algorithm is the second step, which uses PMI-IR to calculate semantic orientation (Turney, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An operational system for detecting and tracking opinions in on - line discussions"
            },
            "venue": {
                "fragments": [],
                "text": "Working Notes of the ACM SIGIR 2001 Workshop on Operational Text Classification"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770316"
                        ],
                        "name": "P. Jacobs",
                        "slug": "P.-Jacobs",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Jacobs",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Jacobs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 143
                            }
                        ],
                        "text": "Other potential applications include recognizing \u201c flames\u201d (abusive newsgroup messages) (Spertus, 1997) and developing new kinds of search tools (Hearst, 1992)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 108
                            }
                        ],
                        "text": "Similarly, a search engine could allow the user to specify the topic and the rating of the desired reviews (Hearst, 1992)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 0
                            }
                        ],
                        "text": "Hearst (1992) observes that most search engines focus on finding documents on a given topic, but do not allow the user to specify the directionality of the documents (e.g., is the author in favor of, neutral, or opposed to the event or item discussed in the document?)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1580100,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "666ca7242ced9a8e89aa0624395704cfc647ad73",
            "isKey": false,
            "numCitedBy": 159,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "Contents: P.S. Jacobs, Introduction: Text Power and Intelligent Systems. Part I:Broad-Scale NLP. J.R. Hobbs, D.E. Appelt, J. Bear, M. Tyson, D. Magerman, Robust Processing of Real-World Natural-Language Texts. Y. Wilks, L. Guthrie, J. Guthrie, J. Cowie, Combining Weak Methods in Large-Scale Text Processing. G. Hirst, M. Ryan, Mixed-Depth Representations for Natural Language Text. D.D. McDonald, Robust Partial-Parsing Through Incremental, Multi-Algorithm Processing. Corpus-Based Thematic Analysis. Part II:\"Traditional\" Information Retrieval. W.B. Croft, H.R. Turtle, Text Retrieval and Inference. K.S. Jones, Assumptions and Issues in Text-Based Retrieval. D.D. Lewis, Text Representation for Intelligent Text Retrieval: A Classification-Oriented View. G. Salton, C. Buckley, Automatic Text Structuring Experiments. Part III:Emerging Applications. C. Stanfill, D.L. Waltz, Statistical Methods, Artificial Intelligence, and Information Retrieval. P.J. Hayes, Intelligent High-Volume Text Processing Using Shallow, Domain-Specific Techniques. Y.S. Maarek, Automatically Constructing Simple Help Systems from Natural Language Documentation. M.A. Hearst, Direction-Based Text Interpretation as an Information Access Refinement."
            },
            "slug": "Text-based-intelligent-systems:-current-research-in-Jacobs",
            "title": {
                "fragments": [],
                "text": "Text-based intelligent systems: current research and practice in information extraction and retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This chapter discusses Text Representation for Intelligent Text Retrieval: A Classification-Oriented View, and Intelligent High-Volume Text Processing Using Shallow, Domain-Specific Techniques."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 63
                            }
                        ],
                        "text": "Other related work is concerned with determining subjectivity (Hatzivassiloglou & Wiebe, 2000; Wiebe, 2000; Wiebe et al., 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Effects o  f adjective orientation and gradability on sentence s ubjectivity"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 18th International Conference on Computational Linguistics"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An operational system for detecting and tracking opinions in on-line discussions"
            },
            "venue": {
                "fragments": [],
                "text": "Working Notes of the ACM SIGIR 2001 Workshop on Operational Text Classification (pp. 1-6). New York, NY: ACM."
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 178
                            }
                        ],
                        "text": "For comparison, Latent Semantic Analysis (LSA), another statistical measure of word association, attains a score of 64% on the\n3 http://www.cs.jhu.edu/~brill/RBT1_14.tar.Z 4 See Santorini (1995) for a complete description of the tags.\nsame 80 TOEFL questions (Landauer & Dumais, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "See http://www.conman.org/people/spc/robots2.html.\ntroduction, one application is to provide summary statistics for search engines."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Part-of-Speech Tagging Guidelines for the Penn Treebank Project (3rd revision, 2nd printing)"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Report, Department of Computer and Information Science, University of Pennsylvania."
            },
            "year": 1995
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 12,
            "methodology": 3
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 18,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Thumbs-Up-or-Thumbs-Down-Semantic-Orientation-to-of-Turney/9e7c7853a16a378cc24a082153b282257a9675b7?sort=total-citations"
}