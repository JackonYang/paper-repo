{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749609"
                        ],
                        "name": "S. Lazebnik",
                        "slug": "S.-Lazebnik",
                        "structuredName": {
                            "firstName": "Svetlana",
                            "lastName": "Lazebnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lazebnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 106
                            }
                        ],
                        "text": "For simplicity we formulate categorization as supervised learning over a \u2018bag of features\u2019 representation [5, 7, 15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 0
                            }
                        ],
                        "text": "[5, 7, 15, 19]) have proposed \u2018bag of features\u2019 methods based on normalized patches or SIFT descriptors [19] over Difference of Gaussian, Harrisscale or Harris-affine keypoints [22], vector quantized using k-means."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206763997,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "72bf4b2ce534b95bc24118491dbc4f8d550734a2",
            "isKey": false,
            "numCitedBy": 1158,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces a texture representation suitable for recognizing images of textured surfaces under a wide range of transformations, including viewpoint changes and nonrigid deformations. At the feature extraction stage, a sparse set of affine Harris and Laplacian regions is found in the image. Each of these regions can be thought of as a texture element having a characteristic elliptic shape and a distinctive appearance pattern. This pattern is captured in an affine-invariant fashion via a process of shape normalization followed by the computation of two novel descriptors, the spin image and the RIFT descriptor. When affine invariance is not required, the original elliptical shape serves as an additional discriminative feature for texture recognition. The proposed approach is evaluated in retrieval and classification tasks using the entire Brodatz database and a publicly available collection of 1,000 photographs of textured surfaces taken from different viewpoints."
            },
            "slug": "A-sparse-texture-representation-using-local-affine-Lazebnik-Schmid",
            "title": {
                "fragments": [],
                "text": "A sparse texture representation using local affine regions"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The proposed texture representation is evaluated in retrieval and classification tasks using the entire Brodatz database and a publicly available collection of 1,000 photographs of textured surfaces taken from different viewpoints."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2990188"
                        ],
                        "name": "J. Willamowski",
                        "slug": "J.-Willamowski",
                        "structuredName": {
                            "firstName": "Jutta",
                            "lastName": "Willamowski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Willamowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3168148"
                        ],
                        "name": "Dami\u00e1n Arregui",
                        "slug": "Dami\u00e1n-Arregui",
                        "structuredName": {
                            "firstName": "Dami\u00e1n",
                            "lastName": "Arregui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dami\u00e1n Arregui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69931662"
                        ],
                        "name": "Gabriella Csurka",
                        "slug": "Gabriella-Csurka",
                        "structuredName": {
                            "firstName": "Gabriella",
                            "lastName": "Csurka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gabriella Csurka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3344005"
                        ],
                        "name": "C. Dance",
                        "slug": "C.-Dance",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Dance",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Dance"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2034793"
                        ],
                        "name": "Lixin Fan",
                        "slug": "Lixin-Fan",
                        "structuredName": {
                            "firstName": "Lixin",
                            "lastName": "Fan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lixin Fan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 248,
                                "start": 227
                            }
                        ],
                        "text": "Traditionally one codes a dense set of patches (\u2018texton\u2019 representation) [18], but sparser sets based on keypoints or \u2018points of interest\u2019 detected by invariant local feature detectors have generated a lot of interest recently [1, 5, 7, 17, 26, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 87
                            }
                        ],
                        "text": "2%, whereas the (k-means and sparse feature based, but otherwise comparable) method of [27] has an error rate of 15%."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 175
                            }
                        ],
                        "text": "We tested two ways of producing feature vectors from codebook based labelings: binary indicator vectors and hisFigure 4: Three images from each class of the \u2018Xerox 7\u2019 dataset [27]: faces, buildings, trees, cars, phones, bikes and books."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 183
                            }
                        ],
                        "text": "Representations based on loose collections of invariant appearance descriptors extracted from local image patches have become very popular for texture analysis and visual recognition [1, 5, 7, 9, 12, 17, 18, 19, 25, 24, 26, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "The second, \u2018Xerox 7\u2019 [27], contains 1776 images from seven categories."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10582358,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ee3391a1c0288ccf150b7d4c883918cfedb655bc",
            "isKey": true,
            "numCitedBy": 211,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel method for generic visual categorization: the problem of identifying the object content of natural images while generalizing across variations inherent to the object class. This bag of keypoints method is based on vector quantization of affine invariant descriptors of image patches. We propose and compare two alternative implementations using different classifiers: Naive Bayes and SVM. The main advantages of the method are that it is simple, computationally efficient and intrinsically invariant. We present results for classifying nine semantic visual categories and comment on results obtained by Fergus et al using a different method on the same data set. We obtain excellent results as well for multi class categorization as for object detection. A thorough evaluation clearly demonstrates that our method is robust to background clutter and produces good categorization accuracy even without exploiting geometric information."
            },
            "slug": "Categorizing-Nine-Visual-Classes-using-Local-Willamowski-Arregui",
            "title": {
                "fragments": [],
                "text": "Categorizing Nine Visual Classes using Local Appearance Descriptors"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A thorough evaluation clearly demonstrates that the bag of keypoints method is robust to background clutter and produces good categorization accuracy even without exploiting geometric information."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "82117876"
                        ],
                        "name": "F. Jurie",
                        "slug": "F.-Jurie",
                        "structuredName": {
                            "firstName": "Fr\u00e9d\u00e9ric",
                            "lastName": "Jurie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jurie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 77
                            }
                        ],
                        "text": ") often fail to detect the most informative patches for image classification [14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3252062,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "59754439e2a0eecd9fe926233505f53e5078bd42",
            "isKey": false,
            "numCitedBy": 129,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new class of distinguished regions based on detecting the most salient convex local arrangements of contours in the image. The regions are used in a similar way to the local interest points extracted from gray-level images, but they capture shape rather than texture. Local convexity is characterized by measuring the extent to which the detected image contours support circle or arc-like local structures at each position and scale in the image. Our saliency measure combines two cost functions defined on the tangential edges near the circle: a tangential-gradient energy term, and an entropy term that ensures local support from a wide range of angular positions around the circle. The detected regions are invariant to scale changes and rotations, and robust against clutter, occlusions and spurious edge detections. Experimental results show very good performance for both shape matching and recognition of object categories."
            },
            "slug": "Scale-invariant-shape-features-for-recognition-of-Jurie-Schmid",
            "title": {
                "fragments": [],
                "text": "Scale-invariant shape features for recognition of object categories"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A new class of distinguished regions based on detecting the most salient convex local arrangements of contours in the image are introduced, which are invariant to scale changes and rotations, and robust against clutter, occlusions and spurious edge detections."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2005362"
                        ],
                        "name": "A. Koloydenko",
                        "slug": "A.-Koloydenko",
                        "structuredName": {
                            "firstName": "Alexey",
                            "lastName": "Koloydenko",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Koloydenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707642"
                        ],
                        "name": "D. Geman",
                        "slug": "D.-Geman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 111
                            }
                        ],
                        "text": "Such textons are typically extracted densely, representing small and relatively generic image micro-structures [10, 18, 28] \u2013 blobs, bars, corners, etc."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 168645,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd197959eaf0fafc67d55a45e9f69d8e7c5bbf10",
            "isKey": false,
            "numCitedBy": 46,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Fort Collins, CO, June, 1999. (Published on Web). Invariant Statistics and Coding of Natural Microimages Donald Geman1 and Alexey Koloydenko2 Abstract We search for universal characteristics of the microstructure of natural images. Our data consist of a very large set of 3 3 patches randomly extracted from indoor and outdoor grey level scenes. The patches are grouped into natural equivalence classes (\\patterns\") based on photometry, \\complexity\" and geometry. We analyze the stability of the pattern statistics over image sets, resolutions and grey scale distortions. Important aspects of the probability distribution of the patterns, e.g., the dominant masses, are stable in our experiments. We also compare the statistics of the natural patch world with those of arti cially generated images; the results are consistent with recently proposed \\scaling laws\" for the sizes of objects in natural images. These results suggest that well-chosen patch labels might serve as elementary features in pattern recognition and other imaging problems in which the ne structure of the grey level con gurations is not essential, and we sketch a computationally e cient way to carry this out using tree-structured vector quantization."
            },
            "slug": "Invariant-Statistics-and-Coding-of-Natural-Koloydenko-Geman",
            "title": {
                "fragments": [],
                "text": "Invariant Statistics and Coding of Natural Microimages"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The results suggest that well-chosen patch labels might serve as elementary features in pattern recognition and other imaging problems in which the structure of the grey level con gurations is not essential, and a computationally feasible way to carry this out using tree-structured vector quantization is sketched."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808423"
                        ],
                        "name": "G. Csurka",
                        "slug": "G.-Csurka",
                        "structuredName": {
                            "firstName": "Gabriela",
                            "lastName": "Csurka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Csurka"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 106
                            }
                        ],
                        "text": "For simplicity we formulate categorization as supervised learning over a \u2018bag of features\u2019 representation [5, 7, 15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 248,
                                "start": 227
                            }
                        ],
                        "text": "Traditionally one codes a dense set of patches (\u2018texton\u2019 representation) [18], but sparser sets based on keypoints or \u2018points of interest\u2019 detected by invariant local feature detectors have generated a lot of interest recently [1, 5, 7, 17, 26, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 0
                            }
                        ],
                        "text": "[5, 7, 15, 19]) have proposed \u2018bag of features\u2019 methods based on normalized patches or SIFT descriptors [19] over Difference of Gaussian, Harrisscale or Harris-affine keypoints [22], vector quantized using k-means."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 183
                            }
                        ],
                        "text": "Representations based on loose collections of invariant appearance descriptors extracted from local image patches have become very popular for texture analysis and visual recognition [1, 5, 7, 9, 12, 17, 18, 19, 25, 24, 26, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17606900,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b91180d8853d00e8f2df7ee3532e07d3d0cce2af",
            "isKey": true,
            "numCitedBy": 5008,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel method for generic visual categorization: the problem of identifying the object content of natural images while generalizing across variations inherent to the object class. This bag of keypoints method is based on vector quantization of affine invariant descriptors of image patches. We propose and compare two alternative implementations using different classifiers: Naive Bayes and SVM. The main advantages of the method are that it is simple, computationally efficient and intrinsically invariant. We present results for simultaneously classifying seven semantic visual categories. These results clearly demonstrate that the method is robust to background clutter and produces good categorization accuracy even without exploiting geometric information."
            },
            "slug": "Visual-categorization-with-bags-of-keypoints-Csurka",
            "title": {
                "fragments": [],
                "text": "Visual categorization with bags of keypoints"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This bag of keypoints method is based on vector quantization of affine invariant descriptors of image patches and shows that it is simple, computationally efficient and intrinsically invariant."
            },
            "venue": {
                "fragments": [],
                "text": "eccv 2004"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2797063"
                        ],
                        "name": "S. Agarwal",
                        "slug": "S.-Agarwal",
                        "structuredName": {
                            "firstName": "Shivani",
                            "lastName": "Agarwal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Agarwal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32177941"
                        ],
                        "name": "A. Awan",
                        "slug": "A.-Awan",
                        "structuredName": {
                            "firstName": "Aatif",
                            "lastName": "Awan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Awan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 311,
                                "start": 307
                            }
                        ],
                        "text": "At the individual patch level, the horses, dogs and cows have\n0 0.1 0.2 0.3 0.4 0.5 0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n1\u2212precision\nR ec al l\nDense sampling, Our Clustering method Dense sampling, k\u2212means Clustering Keypoints sampling, k\u2212means clustering\nFigure 5: MI based feature selection on the Agarwal-Roth car data set."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[1] adopted a similar approach incorporating spatial relations between parts."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 248,
                                "start": 227
                            }
                        ],
                        "text": "Traditionally one codes a dense set of patches (\u2018texton\u2019 representation) [18], but sparser sets based on keypoints or \u2018points of interest\u2019 detected by invariant local feature detectors have generated a lot of interest recently [1, 5, 7, 17, 26, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 51
                            }
                        ],
                        "text": "Bottom left & centre: Car detection on the Agarwal-Roth data set using our dense codebooks."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "The first experiment uses the Agarwal & Roth test set [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 85
                            }
                        ],
                        "text": "Several authors have used agglomerative clustering for the centre allocation problem [17, 1]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 48
                            }
                        ],
                        "text": "3 shows the first 100 codewords for the Agarwal-Roth set of side views of cars."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 83
                            }
                        ],
                        "text": "Our precision at equal rate error is more than 10% higher than the best results of [1], despite the fact that we rely on a simple linear SVM classifier and incorporate no inter-patch geometry (whereas [1] uses spatial relations between pairs of features)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 44
                            }
                        ],
                        "text": "Histograms performed better for the Agarwal-Roth and Xerox 7 datasets \u2013 see fig."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 60
                            }
                        ],
                        "text": "Performance is measured by precision/recall as suggested in [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 183
                            }
                        ],
                        "text": "Representations based on loose collections of invariant appearance descriptors extracted from local image patches have become very popular for texture analysis and visual recognition [1, 5, 7, 9, 12, 17, 18, 19, 25, 24, 26, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 50
                            }
                        ],
                        "text": "The first, side views of cars from Agarwal & Roth [1], was designed to evaluate object detection algorithms."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 72
                            }
                        ],
                        "text": "use (we believe) the same experimental and precision/recall protocol as [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8855331,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b82d251ed367593366680acebc81fdb070b04a18",
            "isKey": true,
            "numCitedBy": 963,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the problem of detecting objects in still, gray-scale images. Our primary focus is the development of a learning-based approach to the problem that makes use of a sparse, part-based representation. A vocabulary of distinctive object parts is automatically constructed from a set of sample images of the object class of interest; images are then represented using parts from this vocabulary, together with spatial relations observed among the parts. Based on this representation, a learning algorithm is used to automatically learn to detect instances of the object class in new images. The approach can be applied to any object with distinguishable parts in a relatively fixed spatial configuration; it is evaluated here on difficult sets of real-world images containing side views of cars, and is seen to successfully detect objects in varying conditions amidst background clutter and mild occlusion. In evaluating object detection approaches, several important methodological issues arise that have not been satisfactorily addressed in the previous work. A secondary focus of this paper is to highlight these issues, and to develop rigorous evaluation standards for the object detection problem. A critical evaluation of our approach under the proposed standards is presented."
            },
            "slug": "Learning-to-detect-objects-in-images-via-a-sparse,-Agarwal-Awan",
            "title": {
                "fragments": [],
                "text": "Learning to detect objects in images via a sparse, part-based representation"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A learning-based approach to the problem of detecting objects in still, gray-scale images that makes use of a sparse, part-based representation is developed and a critical evaluation of the approach under the proposed standards is presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266088"
                        ],
                        "name": "T. Leung",
                        "slug": "T.-Leung",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Leung",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Leung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[18] use Gabor texture features for texture classification."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 73
                            }
                        ],
                        "text": "Traditionally one codes a dense set of patches (\u2018texton\u2019 representation) [18], but sparser sets based on keypoints or \u2018points of interest\u2019 detected by invariant local feature detectors have generated a lot of interest recently [1, 5, 7, 17, 26, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 111
                            }
                        ],
                        "text": "Such textons are typically extracted densely, representing small and relatively generic image micro-structures [10, 18, 28] \u2013 blobs, bars, corners, etc."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 183
                            }
                        ],
                        "text": "Representations based on loose collections of invariant appearance descriptors extracted from local image patches have become very popular for texture analysis and visual recognition [1, 5, 7, 9, 12, 17, 18, 19, 25, 24, 26, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14915716,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "90d6e7f2202f754d8588f9536e3f5b4a24701f24",
            "isKey": true,
            "numCitedBy": 1713,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the recognition of surfaces made from different materials such as concrete, rug, marble, or leather on the basis of their textural appearance. Such natural textures arise from spatial variation of two surface attributes: (1) reflectance and (2) surface normal. In this paper, we provide a unified model to address both these aspects of natural texture. The main idea is to construct a vocabulary of prototype tiny surface patches with associated local geometric and photometric properties. We call these 3D textons. Examples might be ridges, grooves, spots or stripes or combinations thereof. Associated with each texton is an appearance vector, which characterizes the local irradiance distribution, represented as a set of linear Gaussian derivative filter outputs, under different lighting and viewing conditions.Given a large collection of images of different materials, a clustering approach is used to acquire a small (on the order of 100) 3D texton vocabulary. Given a few (1 to 4) images of any material, it can be characterized using these textons. We demonstrate the application of this representation for recognition of the material viewed under novel lighting and viewing conditions. We also illustrate how the 3D texton model can be used to predict the appearance of materials under novel conditions."
            },
            "slug": "Representing-and-Recognizing-the-Visual-Appearance-Leung-Malik",
            "title": {
                "fragments": [],
                "text": "Representing and Recognizing the Visual Appearance of Materials using Three-dimensional Textons"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A unified model to construct a vocabulary of prototype tiny surface patches with associated local geometric and photometric properties, represented as a set of linear Gaussian derivative filter outputs, under different lighting and viewing conditions is provided."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1891864"
                        ],
                        "name": "Gyuri Dork\u00f3",
                        "slug": "Gyuri-Dork\u00f3",
                        "structuredName": {
                            "firstName": "Gyuri",
                            "lastName": "Dork\u00f3",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gyuri Dork\u00f3"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 106
                            }
                        ],
                        "text": "For simplicity we formulate categorization as supervised learning over a \u2018bag of features\u2019 representation [5, 7, 15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 248,
                                "start": 227
                            }
                        ],
                        "text": "Traditionally one codes a dense set of patches (\u2018texton\u2019 representation) [18], but sparser sets based on keypoints or \u2018points of interest\u2019 detected by invariant local feature detectors have generated a lot of interest recently [1, 5, 7, 17, 26, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 0
                            }
                        ],
                        "text": "[5, 7, 15, 19]) have proposed \u2018bag of features\u2019 methods based on normalized patches or SIFT descriptors [19] over Difference of Gaussian, Harrisscale or Harris-affine keypoints [22], vector quantized using k-means."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 183
                            }
                        ],
                        "text": "Representations based on loose collections of invariant appearance descriptors extracted from local image patches have become very popular for texture analysis and visual recognition [1, 5, 7, 9, 12, 17, 18, 19, 25, 24, 26, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7887211,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "96d9ab468299fe51a4e14d86d8ea953ccf62b900",
            "isKey": true,
            "numCitedBy": 355,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a novel method for constructing and selecting scale-invariant object parts. Scale-invariant local descriptors are first grouped into basic parts. A classifier is then learned for each of these parts, and feature selection is used to determine the most discriminative ones. This approach allows robust pan detection, and it is invariant under scale changes-that is, neither the training images nor the test images have to be normalized. The proposed method is evaluated in car detection tasks with significant variations in viewing conditions, and promising results are demonstrated. Different local regions, classifiers and feature selection methods are quantitatively compared. Our evaluation shows that local invariant descriptors are an appropriate representation for object classes such as cars, and it underlines the importance of feature selection."
            },
            "slug": "Selection-of-scale-invariant-parts-for-object-class-Dork\u00f3-Schmid",
            "title": {
                "fragments": [],
                "text": "Selection of scale-invariant parts for object class recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The evaluation shows that local invariant descriptors are an appropriate representation for object classes such as cars, and it underlines the importance of feature selection."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747498"
                        ],
                        "name": "B. Georgescu",
                        "slug": "B.-Georgescu",
                        "structuredName": {
                            "firstName": "Bogdan",
                            "lastName": "Georgescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Georgescu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782918"
                        ],
                        "name": "I. Shimshoni",
                        "slug": "I.-Shimshoni",
                        "structuredName": {
                            "firstName": "Ilan",
                            "lastName": "Shimshoni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Shimshoni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145776090"
                        ],
                        "name": "P. Meer",
                        "slug": "P.-Meer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Meer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Meer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1833221,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c41bf09e692ae81b7f81e8c657303b30a4d807b5",
            "isKey": false,
            "numCitedBy": 484,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Feature space analysis is the main module in many computer vision tasks. The most popular technique, k-means clustering, however, has two inherent limitations: the clusters are constrained to be spherically symmetric and their number has to be known a priori. In nonparametric clustering methods, like the one based on mean shift, these limitations are eliminated but the amount of computation becomes prohibitively large as the dimension of the space increases. We exploit a recently proposed approximation technique, locality-sensitive hashing (LSH), to reduce the computational complexity of adaptive mean shift. In our implementation of LSH the optimal parameters of the data structure are determined by a pilot learning procedure, and the partitions are data driven. As an application, the performance of mode and k-means based textons are compared in a texture classification study."
            },
            "slug": "Mean-shift-based-clustering-in-high-dimensions:-a-Georgescu-Shimshoni",
            "title": {
                "fragments": [],
                "text": "Mean shift based clustering in high dimensions: a texture classification example"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work exploits a recently proposed approximation technique, locality-sensitive hashing (LSH), to reduce the computational complexity of adaptive mean shift and implements the implementation of LSH, where the optimal parameters of the data structure are determined by a pilot learning procedure, and the partitions are data driven."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398995671"
                        ],
                        "name": "Michel Vidal-Naquet",
                        "slug": "Michel-Vidal-Naquet",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Vidal-Naquet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michel Vidal-Naquet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743045"
                        ],
                        "name": "S. Ullman",
                        "slug": "S.-Ullman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Ullman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ullman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 186
                            }
                        ],
                        "text": "To show how the approach behaves when only a restricted subset of the vocabulary is used, we report on three different feature selection methods: maximization of mutual information (MI) [2, 25], and of odds ratio (OR) [2], and training an initial linear SVM classifier on the full feature set and retaining only the features that have the highest weights (SVM) [2, 23]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 163
                            }
                        ],
                        "text": "Another strategy is to select patches by testing many potential templates and selecting the ones that maximize an informativeness score such as mutual information [25, 24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 117
                            }
                        ],
                        "text": "For indicator vectors, each codeword\u2019s feature is 1 if a patch with the codeword occurs in the image and 0 otherwise [25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 33
                            }
                        ],
                        "text": "Information Gain was also tested [2, 25] but performed less well than MI."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 183
                            }
                        ],
                        "text": "Representations based on loose collections of invariant appearance descriptors extracted from local image patches have become very popular for texture analysis and visual recognition [1, 5, 7, 9, 12, 17, 18, 19, 25, 24, 26, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15620181,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a0d4b0618eb4e5ebcd3f86e9948921ba9f49b77c",
            "isKey": true,
            "numCitedBy": 303,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We show that efficient object recognition can be obtained by combining informative features with linear classification. The results demonstrate the superiority of informative class-specific features, as compared with generic type features such as wavelets, for the task of object recognition. We show that information rich features can reach optimal performance with simple linear separation rules, while generic feature based classifiers require more complex classification schemes. This is significant because efficient and optimal methods have been developed for spaces that allow linear separation. To compare different strategies for feature extraction, we trained and compared classifiers working in feature spaces of the same low dimensionality, using two feature types (image fragments vs. wavelets) and two classification rules (linear hyperplane and a Bayesian network). The results show that by maximizing the individual information of the features, it is possible to obtain efficient classification by a simple linear separating rule, as well as more efficient learning."
            },
            "slug": "Object-recognition-with-informative-features-and-Vidal-Naquet-Ullman",
            "title": {
                "fragments": [],
                "text": "Object recognition with informative features and linear classification"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The results show that by maximizing the individual information of the features, it is possible to obtain efficient classification by a simple linear separating rule, as well as more efficient learning."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 183
                            }
                        ],
                        "text": "Representations based on loose collections of invariant appearance descriptors extracted from local image patches have become very popular for texture analysis and visual recognition [1, 5, 7, 9, 12, 17, 18, 19, 25, 24, 26, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5745749,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62837ab473124ea43cb8d7c6a4b4ee0f6f14e8c5",
            "isKey": false,
            "numCitedBy": 2487,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method to learn and recognize object class models from unlabeled and unsegmented cluttered scenes in a scale invariant manner. Objects are modeled as flexible constellations of parts. A probabilistic representation is used for all aspects of the object: shape, appearance, occlusion and relative scale. An entropy-based feature detector is used to select regions and their scale within the image. In learning the parameters of the scale-invariant object model are estimated. This is done using expectation-maximization in a maximum-likelihood setting. In recognition, this model is used in a Bayesian manner to classify images. The flexible nature of the model is demonstrated by excellent results over a range of datasets including geometrically constrained classes (e.g. faces, cars) and flexible objects (such as animals)."
            },
            "slug": "Object-class-recognition-by-unsupervised-learning-Fergus-Perona",
            "title": {
                "fragments": [],
                "text": "Object class recognition by unsupervised scale-invariant learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The flexible nature of the model is demonstrated by excellent results over a range of datasets including geometrically constrained classes (e.g. faces, cars) and flexible objects (such as animals)."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110604335"
                        ],
                        "name": "Markus Weber",
                        "slug": "Markus-Weber",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Weber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Markus Weber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678311"
                        ],
                        "name": "M. Welling",
                        "slug": "M.-Welling",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Welling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Welling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 248,
                                "start": 227
                            }
                        ],
                        "text": "Traditionally one codes a dense set of patches (\u2018texton\u2019 representation) [18], but sparser sets based on keypoints or \u2018points of interest\u2019 detected by invariant local feature detectors have generated a lot of interest recently [1, 5, 7, 17, 26, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[26] learn a generative model for face recognition from a set of training images by detecting F\u00f6rstner keypoints at a single scale and quantizing the selected (small) raw image patches using k-means."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 183
                            }
                        ],
                        "text": "Representations based on loose collections of invariant appearance descriptors extracted from local image patches have become very popular for texture analysis and visual recognition [1, 5, 7, 9, 12, 17, 18, 19, 25, 24, 26, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8970876,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1cf1527807ebb16020b04d4166e7ba8d27652302",
            "isKey": false,
            "numCitedBy": 757,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method to learn object class models from unlabeled and unsegmented cluttered scenes for the purpose of visual object recognition. We focus on a particular type of model where objects are represented as flexible constellations of rigid parts (features). The variability within a class is represented by a joint probability density function (pdf) on the shape of the constellation and the output of part detectors. In a first stage, the method automatically identifies distinctive parts in the training set by applying a clustering algorithm to patterns selected by an interest operator. It then learns the statistical shape model using expectation maximization. The method achieves very good classification results on human faces and rear views of cars."
            },
            "slug": "Unsupervised-Learning-of-Models-for-Recognition-Weber-Welling",
            "title": {
                "fragments": [],
                "text": "Unsupervised Learning of Models for Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A method to learn object class models from unlabeled and unsegmented cluttered cluttered scenes for the purpose of visual object recognition that achieves very good classification results on human faces and rear views of cars."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056417995"
                        ],
                        "name": "K. Murphy",
                        "slug": "K.-Murphy",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Murphy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Murphy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 163
                            }
                        ],
                        "text": "Another strategy is to select patches by testing many potential templates and selecting the ones that maximize an informativeness score such as mutual information [25, 24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 183
                            }
                        ],
                        "text": "Representations based on loose collections of invariant appearance descriptors extracted from local image patches have become very popular for texture analysis and visual recognition [1, 5, 7, 9, 12, 17, 18, 19, 25, 24, 26, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11194336,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "42de22c119f25d303032396b8f7d962f62d6498b",
            "isKey": false,
            "numCitedBy": 440,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of detecting a large number of different object classes in cluttered scenes. Traditional approaches require applying a battery of different classifiers to the image, which can be slow and require much training data. We present a multi-class boosting procedure (joint boosting) that reduces both the computational and sample complexity, by finding common features that can be shared across the classes. The detectors for each class are trained jointly, rather than independently. For a given performance level, the total number of features required is observed to scale approximately logarithmically with the number of classes. In addition, we find that the features selected by independently trained classifiers are often specific to the class, whereas the features selected by the jointly trained classifiers are more generic features, such as lines and edges."
            },
            "slug": "Sharing-features:-efficient-boosting-procedures-for-Torralba-Murphy",
            "title": {
                "fragments": [],
                "text": "Sharing features: efficient boosting procedures for multiclass object detection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A multi-class boosting procedure (joint boosting) is presented that reduces both the computational and sample complexity, by finding common features that can be shared across the classes."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685020"
                        ],
                        "name": "D. Comaniciu",
                        "slug": "D.-Comaniciu",
                        "structuredName": {
                            "firstName": "Dorin",
                            "lastName": "Comaniciu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Comaniciu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145776090"
                        ],
                        "name": "P. Meer",
                        "slug": "P.-Meer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Meer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Meer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 103
                            }
                        ],
                        "text": "Our algorithm: Our proposed strategy combines the advantages of on-line clustering [20] and mean-shift [4] in an undersampling framework [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 177
                            }
                        ],
                        "text": "At each step, we draw N patches uniformly and randomly from the currently unlabeled part of the data set, compute their maximal density region by running a mean-shift estimator [4] with a Gaussian kernel of width h on them, allocate a new centre at the maximal density position, and (notionally \u2013 in practice this is done lazily) sweep the dataset, labeling and eliminating all of the patches that are assigned to this centre."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 69
                            }
                        ],
                        "text": "method for allocating centers more uniformly, inspired by mean shift [4] and on-line facility location [20]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 691081,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74f4ecc3e4e5b91fbb54330b285ed5214afe2001",
            "isKey": false,
            "numCitedBy": 11480,
            "numCiting": 122,
            "paperAbstract": {
                "fragments": [],
                "text": "A general non-parametric technique is proposed for the analysis of a complex multimodal feature space and to delineate arbitrarily shaped clusters in it. The basic computational module of the technique is an old pattern recognition procedure: the mean shift. For discrete data, we prove the convergence of a recursive mean shift procedure to the nearest stationary point of the underlying density function and, thus, its utility in detecting the modes of the density. The relation of the mean shift procedure to the Nadaraya-Watson estimator from kernel regression and the robust M-estimators; of location is also established. Algorithms for two low-level vision tasks discontinuity-preserving smoothing and image segmentation - are described as applications. In these algorithms, the only user-set parameter is the resolution of the analysis, and either gray-level or color images are accepted as input. Extensive experimental results illustrate their excellent performance."
            },
            "slug": "Mean-Shift:-A-Robust-Approach-Toward-Feature-Space-Comaniciu-Meer",
            "title": {
                "fragments": [],
                "text": "Mean Shift: A Robust Approach Toward Feature Space Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is proved the convergence of a recursive mean shift procedure to the nearest stationary point of the underlying density function and, thus, its utility in detecting the modes of the density."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789756"
                        ],
                        "name": "B. Leibe",
                        "slug": "B.-Leibe",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Leibe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Leibe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48920094"
                        ],
                        "name": "B. Schiele",
                        "slug": "B.-Schiele",
                        "structuredName": {
                            "firstName": "Bernt",
                            "lastName": "Schiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schiele"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 60
                            }
                        ],
                        "text": "The last dataset contains 4 classes from the ETH80 database [17]: models of cars, horses, dogs and cows."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 248,
                                "start": 227
                            }
                        ],
                        "text": "Traditionally one codes a dense set of patches (\u2018texton\u2019 representation) [18], but sparser sets based on keypoints or \u2018points of interest\u2019 detected by invariant local feature detectors have generated a lot of interest recently [1, 5, 7, 17, 26, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 85
                            }
                        ],
                        "text": "Several authors have used agglomerative clustering for the centre allocation problem [17, 1]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[17] proposed a similar method based on a codebook learned by agglomeratively clustering raw pixel intensity vectors of Harris keypoints."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 183
                            }
                        ],
                        "text": "Representations based on loose collections of invariant appearance descriptors extracted from local image patches have become very popular for texture analysis and visual recognition [1, 5, 7, 9, 12, 17, 18, 19, 25, 24, 26, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2900658,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "398bff5abb9c35b2de63bf6b5ecae244c082ca6e",
            "isKey": true,
            "numCitedBy": 181,
            "numCiting": 203,
            "paperAbstract": {
                "fragments": [],
                "text": "This thesis is concerned with the problem of visual object categorization, that is of reeognizing unseen-before objects, localizing them in cluttered real-worid images, and assigning the correct category label. This capability is one of the core compe\u00ac tencies of the human visual system. Yet, Computer vision Systems are still far from reaching a comparable level of Performance.Moreover,Computer visionresearch has in the past mainly focused on the simpler and more specific problem of identifying known objects under novel viewing conditions. The visual categorization problem is closely linked to the task of figure-ground segmentation, that is of dividing the image into an object and a non-objeet part. Historically, figure-ground segmentation has often been seen as an important and even necessary preprocessing step for object recognition. However, purely bottomup approacheshave so far been unable to yield segmentationsof sufficient quality, so that most current recognition approacheshave been designed to work independently from segmentation. In contrast,this thesis considers object categorization and figure-ground segmen\u00ac tation as two interleaved processes that closely collaborate towards a common goal. The core part of our work is a probabilisticformulation which integrates both capabilities into a common framework. As shown in our experiments, the tight coupling between those two processes allows them to profit from each other and improve their individual Performances. The resulting approach can detect categorical objects in novel images and automatically compute a segmentationfor them. This segmenta\u00ac tion is then used to again improve recognition by allowing the System to focus its effort on object pixels and discard misleading influencesfrom the background. In addition to improving the recognition Performance for individual hypotheses, the top-down segmentation also allows to determine exactly from where a hypoth\u00ac esis draws its support. We use this information to design a hypothesis verification stage based on the MDL principle that resolves ambiguities between overlapping hypotheseson a per-pixel level and factorsout the effects of partialocclusion. Altogether, this procedureconstitutes a novel mechanismin object detection that allows to analyze scenes containing multiple objects in a principled manner. Our results show that it presents an improvement over conventional criteria based on bounding box overlap and permitsmore aecurate aeeeptancedecisions. Our approach is based on a highly flexible implicit representation for object shape that can combine the information of local parts observed on different training exam\u00ac ples and interpolate between the correspondingobjects. As a result, the proposed method can learn object modeis already from few training examples and achieve competitive object detection Performance with training sets that are between one and two orders of magnitude smaller than those used in comparable Systems. An extensive evaluation on several large data sets shows that the system is applicable to many different object categories, including both rigid and articulated objects."
            },
            "slug": "Interleaved-Object-Categorization-and-Segmentation-Leibe-Schiele",
            "title": {
                "fragments": [],
                "text": "Interleaved Object Categorization and Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This thesis considers object categorization and figure-ground segmentation as two interleaved processes that closely collaborate towards a common goal and develops a probabilistic formulation which integrates both capabilities into a common framework that allows to analyze scenes containing multiple objects in a principled manner."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684626"
                        ],
                        "name": "B. Heisele",
                        "slug": "B.-Heisele",
                        "structuredName": {
                            "firstName": "Bernd",
                            "lastName": "Heisele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Heisele"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35541734"
                        ],
                        "name": "Purdy Ho",
                        "slug": "Purdy-Ho",
                        "structuredName": {
                            "firstName": "Purdy",
                            "lastName": "Ho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Purdy Ho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109186479"
                        ],
                        "name": "Jane Wu",
                        "slug": "Jane-Wu",
                        "structuredName": {
                            "firstName": "Jane",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jane Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 183
                            }
                        ],
                        "text": "Representations based on loose collections of invariant appearance descriptors extracted from local image patches have become very popular for texture analysis and visual recognition [1, 5, 7, 9, 12, 17, 18, 19, 25, 24, 26, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13344451,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "43b249b6398cf759cebde761c97aac557ba48450",
            "isKey": false,
            "numCitedBy": 457,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Face-recognition:-component-based-versus-global-Heisele-Ho",
            "title": {
                "fragments": [],
                "text": "Face recognition: component-based versus global approaches"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 177
                            }
                        ],
                        "text": "[5, 7, 15, 19]) have proposed \u2018bag of features\u2019 methods based on normalized patches or SIFT descriptors [19] over Difference of Gaussian, Harrisscale or Harris-affine keypoints [22], vector quantized using k-means."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8571961,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "9c7a96155f10f152cae0866102c061cdf6da02e8",
            "isKey": false,
            "numCitedBy": 1683,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel approach for detecting affine invariant interest points. Our method can deal with significant affine transformations including large scale changes. Such transformations introduce significant changes in the point location as well as in the scale and the shape of the neighbourhood of an interest point. Our approach allows to solve for these problems simultaneously. It is based on three key ideas : 1) The second moment matrix computed in a point can be used to normalize a region in an affine invariant way (skew and stretch). 2) The scale of the local structure is indicated by local extrema of normalized derivatives over scale. 3) An affine-adapted Harris detector determines the location of interest points. A multi-scale version of this detector is used for initialization. An iterative algorithm then modifies location, scale and neighbourhood of each point and converges to affine invariant points. For matching and recognition, the image is characterized by a set of affine invariant points; the affine transformation associated with each point allows the computation of an affine invariant descriptor which is also invariant to affine illumination changes. A quantitative comparison of our detector with existing ones shows a significant improvement in the presence of large affine deformations. Experimental results for wide baseline matching show an excellent performance in the presence of large perspective transformations including significant scale changes. Results for recognition are very good for a database with more than 5000 images."
            },
            "slug": "An-Affine-Invariant-Interest-Point-Detector-Mikolajczyk-Schmid",
            "title": {
                "fragments": [],
                "text": "An Affine Invariant Interest Point Detector"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A novel approach for detecting affine invariant interest points that can deal with significant affine transformations including large scale changes and shows an excellent performance in the presence of large perspective transformations including significant scale changes."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1832448"
                        ],
                        "name": "Ann B. Lee",
                        "slug": "Ann-B.-Lee",
                        "structuredName": {
                            "firstName": "Ann",
                            "lastName": "Lee",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ann B. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "117481816"
                        ],
                        "name": "D. Mumford",
                        "slug": "D.-Mumford",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mumford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mumford"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145738882"
                        ],
                        "name": "Jinggang Huang",
                        "slug": "Jinggang-Huang",
                        "structuredName": {
                            "firstName": "Jinggang",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jinggang Huang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 264,
                                "start": 260
                            }
                        ],
                        "text": ") occur far more frequently than others (faces, stop signs); and (ii) the amount of any given texture that appears is extremely variable owing to the multiscale region structure of natural scenes (the statistics of this is captured quite well by \u201cdead leaves\u201d [16] \u2013 sets of opaque, homogeneous patches occurring randomly at all positions and scales \u2013 and similar fractal models)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13343075,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "556767b5a36ed8f7f8183882bde33399b5199328",
            "isKey": false,
            "numCitedBy": 155,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop a scale-invariant version of Matheron's \u201cdead leaves model\u201d for the statistics of natural images. The model takes occlusions into account and resembles the image formation process by randomly adding independent elementary shapes, such as disks, in layers. We compare the empirical statistics of two large databases of natural images with the statistics of the occlusion model, and find an excellent qualitative, and good quantitative agreement. At this point, this is the only image model which comes close to duplicating the simplest, elementary statistics of natural images\u2014such as, the scale invariance property of marginal distributions of filter responses, the full co-occurrence statistics of two pixels, and the joint statistics of pairs of Haar wavelet responses."
            },
            "slug": "Occlusion-Models-for-Natural-Images:-A-Statistical-Lee-Mumford",
            "title": {
                "fragments": [],
                "text": "Occlusion Models for Natural Images: A Statistical Study of a Scale-Invariant Dead Leaves Model"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A scale-invariant version of Matheron's \u201cdead leaves model\u201d for the statistics of natural images that takes occlusions into account and resembles the image formation process by randomly adding independent elementary shapes, such as disks, in layers."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3133664"
                        ],
                        "name": "D. Cutting",
                        "slug": "D.-Cutting",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Cutting",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cutting"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34165212"
                        ],
                        "name": "Jan O. Pedersen",
                        "slug": "Jan-O.-Pedersen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Pedersen",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jan O. Pedersen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743286"
                        ],
                        "name": "D. Karger",
                        "slug": "D.-Karger",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Karger",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Karger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2016914"
                        ],
                        "name": "J. Tukey",
                        "slug": "J.-Tukey",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Tukey",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tukey"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 62
                            }
                        ],
                        "text": "Such methods typically use some form of subsampling for speed [6, 21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 373655,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "827e1fc081f62f245946df1f347d86af635716eb",
            "isKey": false,
            "numCitedBy": 1191,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Document clustering has not been well received as an information retrieval tool. Objections to its use fall into two main categories: first, that clustering is too slow for large corpora (with running time often quadratic in the number of documents); and second, that clustering does not appreciably improve retrieval.\nWe argue that these problems arise only when clustering is used in an attempt to improve conventional search techniques. However, looking at clustering as an information access tool in its own right obviates these objections, and provides a powerful new access paradigm. We present a document browsing technique that employs document clustering as its primary operation. We also present fast (linear time) clustering algorithms which support this interactive browsing paradigm."
            },
            "slug": "Scatter/Gather:-a-cluster-based-approach-to-large-Cutting-Pedersen",
            "title": {
                "fragments": [],
                "text": "Scatter/Gather: a cluster-based approach to browsing large document collections"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work presents a document browsing technique that employs document clustering as its primary operation, and presents fast (linear time) clustering algorithms which support this interactive browsing paradigm."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '92"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1795846"
                        ],
                        "name": "J. Brank",
                        "slug": "J.-Brank",
                        "structuredName": {
                            "firstName": "Janez",
                            "lastName": "Brank",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Brank"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775954"
                        ],
                        "name": "M. Grobelnik",
                        "slug": "M.-Grobelnik",
                        "structuredName": {
                            "firstName": "Marko",
                            "lastName": "Grobelnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Grobelnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398136050"
                        ],
                        "name": "Natasa Milic-Frayling",
                        "slug": "Natasa-Milic-Frayling",
                        "structuredName": {
                            "firstName": "Natasa",
                            "lastName": "Milic-Frayling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Natasa Milic-Frayling"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 173
                            }
                        ],
                        "text": "In each case we select the 600 best codewords by maximizing the mutual information between optimally thresholded codeword occurrence counts and categories, and use a linear SVM classifier with 10-fold cross validation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 96
                            }
                        ],
                        "text": "We studied three feature selection methods: mutual information (MI), odds ratio (OR) and linear SVM weights (LSVM)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 1
                            }
                        ],
                        "text": "LSVM selection topped most of our experiments (see fig."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 403,
                                "start": 400
                            }
                        ],
                        "text": "These codewords are not the first ones to be produced by our algorithm, so the initial codebook will generally be larger than the final number of useful features, and subsequent feature selection is advis-\n0 100 200 300 400 500 600 700 800 0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\nNumber of centers\nO ve\nra ll\nE rr\nor R\nat e\nDense Codebook/ MI F.S. / Naive Bayes Classifier Dense Codebook/ MI F.S. / Linear SVM Classifier Dense Codebook / Linear SVM F.S. / Naive Bayes Classifier Dense Codebook / Linear SVM F.S. / Linear SVM Classifier Keypoints Codebook/ MI F.S. / Naive Bayes Classifier Keypoints Codebook/ MI F. S. / Linear SVM Classifier Keypoints Codebook / Linear SVM F.S. / Naive Bayes Classifier Keypoints Codebook / Linear SVM F.S. / Linear SVM Classifier\n10 0\n10 2\n10 4\n10 6\n10 8\n0\n0.05\n0.1\n0.15\n0.2\n0.25\n0.3\n0.35\n0.4\nAverage number of points per image\nO ve\nra ll\nm is\ncl as\nsi fic\nat io\nn R\nat e\nRandom detection Key\u2212point detection\n0 500 1000 1500 2000 0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\nNumber of centers\nO ve\nra ll\nE rr\no r\nR a te\nHistogram Features: MI F.S. / Naive Bayes Classifier Histogram Features: MI F.S. / Linear SVM Classifier Histogram Features: Linear SVM F.S. / Naive Bayes Classifier Histogram Features: Linear SVM F.S. / Linear SVM Classifier Binary Features: MI F.S. / Naive Bayes Classifier Binary Features: MI F.S. / Linear SVM Classifier Binary Features: Linear SVM F.S. / Naive Bayes Classifier Binary Features: Linear SVM F.S. / Linear SVM Classifier\n0 500 1000 1500 2000 2500 3000 0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\nNumber of centers\nR ec\nal l a\nt E qu\nal E\nrr or\nR at\ne\nFeatures: histograms / Feature Selection: MI Features: binary / Feature Selection: MI Features: histograms / Feature Selection: LSVM Features: binary / Feature Selection : LSVM Features: histograms / Feature Selection : OR Features: binary / Feature Selection : OR\n0 500 1000 1500 2000 2500 3000 0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\nNumber of centers\nR ec\nal l a\nt E qu\nal E\nrr or\nR at e Features: histograms / F.S.: MI Features: binary / F.S.: MI Features: histograms / F.S.: LSVM Features: binary / F.S.: LSVM Features: histograms / F.S.: OR Features: binary / F.S.: OR\n0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n1\u2212precision\nR e ca ll\n50 centers,Dense Online Clustering, LSVM F.S., LSVM Classifier 100 centers,Dense Online Clustering, LSVM F.S., LSVM Classifier 270 centers,Dense Online Clustering, LSVM F.S., LSVM Classifier 3000 centers,Dense Online Clustering, LSVM F.S., LSVM Classifier Best results obtained by Agarwal et al. (270 centers +rel. features)\nFigure 6: Top left: ETH80 dataset."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 72
                            }
                        ],
                        "text": "Bottom: the Precision-Recall curves for these codebooks, using a linear SVM classifier over 600 features selected using MI."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 186
                            }
                        ],
                        "text": "To show how the approach behaves when only a restricted subset of the vocabulary is used, we report on three different feature selection methods: maximization of mutual information (MI) [2, 25], and of odds ratio (OR) [2], and training an initial linear SVM classifier on the full feature set and retaining only the features that have the highest weights (SVM) [2, 23]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 1
                            }
                        ],
                        "text": "LSVM feature selection with either histogram or binary based coding performs best."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 137
                            }
                        ],
                        "text": "Our precision at equal rate error is more than 10% higher than the best results of [1], despite the fact that we rely on a simple linear SVM classifier and incorporate no inter-patch geometry (whereas [1] uses spatial relations between pairs of features)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 11
                            }
                        ],
                        "text": "The linear SVM classifier over histogram features has the lowest error rate, with either MI (for many centres) or LSVM (for few centres) feature selection."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 33
                            }
                        ],
                        "text": "Information Gain was also tested [2, 25] but performed less well than MI."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 30
                            }
                        ],
                        "text": "Naive Bayes (left) and linear SVM (centre) classifiers."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 87
                            }
                        ],
                        "text": "On the Xerox 7 dataset, the best results were obtained with our codebooks and a linear SVM. Fig."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 51
                            }
                        ],
                        "text": "When there were more than two classes, the OR and LSVM criteria were calculated by averaging the corresponding two-class criteria over the possible one-against-all subproblems."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "SVM\u2019s are known to produce reliable results in high-dimensional problems, and here they easily outperform Naive Bayes in all of the tests performed \u2013 see fig 6."
                    },
                    "intents": []
                }
            ],
            "corpusId": 3231555,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7c714989e5c3b05794dd3c394b582906a67dc2b4",
            "isKey": true,
            "numCitedBy": 110,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we explore effects of various feature selection algorithms on document classification performance. We propose to use two, possibly distinct linear classifiers: one used exclusively for feature selection in order to obtain the feature space for training the second classifier, using possibly a different training set. The resulting classifier is used to classify new documents. Experiments show that feature selection based on the linear SVM algorithm combines well with different types of classifiers. Based on the experimental results we make a conjecture that it is the level of sophis tication at which the scoring method takes into account information about features, rather than its compatibility with the classifier in terms of its design, that makes the feature selection method more or less successful."
            },
            "slug": "Interaction-of-Feature-Selection-Methods-and-Linear-Brank-Grobelnik",
            "title": {
                "fragments": [],
                "text": "Interaction of Feature Selection Methods and Linear Classification Models"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "It is a conjecture that it is the level of sophis tication at which the scoring method takes into account information about features, rather than its compatibility with the classifier in terms of its design, that makes the feature selection method more or less successful."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716881"
                        ],
                        "name": "A. Meyerson",
                        "slug": "A.-Meyerson",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Meyerson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Meyerson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1387448259"
                        ],
                        "name": "Liadan O'Callaghan",
                        "slug": "Liadan-O'Callaghan",
                        "structuredName": {
                            "firstName": "Liadan",
                            "lastName": "O'Callaghan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liadan O'Callaghan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40527599"
                        ],
                        "name": "Serge A. Plotkin",
                        "slug": "Serge-A.-Plotkin",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Plotkin",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge A. Plotkin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Such methods typically use some form of subsampling for speed [6,  21 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 19826354,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "2439d257ab57d5ca277669833c2a9499fb96ee13",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "AbstractWe give a sampling-based algorithm for the k-Median problem, with running time O(k\n$$(\\frac{{k^2 }}{ \\in } \\log k)^2 $$\n log\n$$(\\frac{k}{ \\in } \\log k)$$\n), where k is the desired number of clusters and \u2208 is a confidence parameter. This is the first k-Median algorithm with fully polynomial running time that is independent of n, the size of the data set. It gives a solution that is, with high probability, an O(1)-approximation, if each cluster in some optimal solution has \u03a9\n$$(\\frac{{n \\in }}{k})$$\n points. We also give weakly-polynomial-time algorithms for this problem and a relaxed version of k-Median in which a small fraction of outliers can be excluded. We give near-matching lower bounds showing that this assumption about cluster size is necessary. We also present a related algorithm for finding a clustering that excludes a small number of outliers."
            },
            "slug": "A-k-Median-Algorithm-with-Running-Time-Independent-Meyerson-O'Callaghan",
            "title": {
                "fragments": [],
                "text": "A k-Median Algorithm with Running Time Independent of Data Size"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This is the first k-Median algorithm with fully polynomial running time that is independent of n, the size of the data set, and gives a solution that is, with high probability, an O(1)-approximation, if each cluster in some optimal solution has \u03a9."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764321"
                        ],
                        "name": "D. Mladenic",
                        "slug": "D.-Mladenic",
                        "structuredName": {
                            "firstName": "Dunja",
                            "lastName": "Mladenic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mladenic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1795846"
                        ],
                        "name": "J. Brank",
                        "slug": "J.-Brank",
                        "structuredName": {
                            "firstName": "Janez",
                            "lastName": "Brank",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Brank"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775954"
                        ],
                        "name": "M. Grobelnik",
                        "slug": "M.-Grobelnik",
                        "structuredName": {
                            "firstName": "Marko",
                            "lastName": "Grobelnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Grobelnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398136050"
                        ],
                        "name": "Natasa Milic-Frayling",
                        "slug": "Natasa-Milic-Frayling",
                        "structuredName": {
                            "firstName": "Natasa",
                            "lastName": "Milic-Frayling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Natasa Milic-Frayling"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1673876,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "73bc87477e45d49f7254fccd5f34d23b4ae5f254",
            "isKey": false,
            "numCitedBy": 204,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper explores feature scoring and selection based on weights from linear classification models. It investigates how these methods combine with various learning models. Our comparative analysis includes three learning algorithms: Na\u00efve Bayes, Perceptron, and Support Vector Machines (SVM) in combination with three feature weighting methods: Odds Ratio, Information Gain, and weights from linear models, the linear SVM and Perceptron. Experiments show that feature selection using weights from linear SVMs yields better classification performance than other feature weighting methods when combined with the three explored learning algorithms. The results support the conjecture that it is the sophistication of the feature weighting method rather than its apparent compatibility with the learning algorithm that improves classification performance."
            },
            "slug": "Feature-selection-using-linear-classifier-weights:-Mladenic-Brank",
            "title": {
                "fragments": [],
                "text": "Feature selection using linear classifier weights: interaction with classification models"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "Experiments show that feature selection using weights from linear SVMs yields better classification performance than other feature weighting methods when combined with the three explored learning algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3326400"
                        ],
                        "name": "B. Julesz",
                        "slug": "B.-Julesz",
                        "structuredName": {
                            "firstName": "B\u00e9la",
                            "lastName": "Julesz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Julesz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[13]) we mean a set of representative classes of image patches that suffice to characterize an image object or texture."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4327694,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "8999355e47248bc60f5768fc2168fd28295b5f27",
            "isKey": false,
            "numCitedBy": 1772,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Research with texture pairs having identical second-order statistics has revealed that the pre-attentive texture discrimination system cannot globally process third- and higher-order statistics, and that discrimination is the result of a few local conspicuous features, called textons. It seems that only the first-order statistics of these textons have perceptual significance, and the relative phase between textons cannot be perceived without detailed scrutiny by focal attention."
            },
            "slug": "Textons,-the-elements-of-texture-perception,-and-Julesz",
            "title": {
                "fragments": [],
                "text": "Textons, the elements of texture perception, and their interactions"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Research with texture pairs having identical second-order statistics has revealed that the pre-attentive texture discrimination system cannot globally process third- and higher- order statistics, and that discrimination is the result of a few local conspicuous features, called textons."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644050191"
                        ],
                        "name": "G. LoweDavid",
                        "slug": "G.-LoweDavid",
                        "structuredName": {
                            "firstName": "G",
                            "lastName": "LoweDavid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. LoweDavid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 0
                            }
                        ],
                        "text": "[5, 7, 15, 19]) have proposed \u2018bag of features\u2019 methods based on normalized patches or SIFT descriptors [19] over Difference of Gaussian, Harrisscale or Harris-affine keypoints [22], vector quantized using k-means."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 309,
                                "start": 305
                            }
                        ],
                        "text": "We report results for three 2500-centre codebooks based on both positive and negative images from the training set: one built by densely sampling patches and using our clustering method; one built using dense patches and k-means; and one built with k-means using keypoints detected by Lowe\u2019s DoG detector [19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 183
                            }
                        ],
                        "text": "Representations based on loose collections of invariant appearance descriptors extracted from local image patches have become very popular for texture analysis and visual recognition [1, 5, 7, 9, 12, 17, 18, 19, 25, 24, 26, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 103
                            }
                        ],
                        "text": "2 (right), the corresponding distribution for patches selected using a keypoint detector (here, Lowe\u2019s [19]) is much more uniform, with most of the bins having comparatively similar probabilities and only a few being rare."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 196
                            }
                        ],
                        "text": "Appearance is represented simply as vectors of raw pixel intensities compared using ZNCC, but other vector valued appearance descriptors can be used and informal experiments with SIFT descriptors [19] gave similar results."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 174065,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4cab9c4b571761203ed4c3a4c5a07dd615f57a91",
            "isKey": true,
            "numCitedBy": 25497,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are ..."
            },
            "slug": "Distinctive-Image-Features-from-Scale-Invariant-LoweDavid",
            "title": {
                "fragments": [],
                "text": "Distinctive Image Features from Scale-Invariant Keypoints"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712539"
                        ],
                        "name": "Andrew Estabrooks",
                        "slug": "Andrew-Estabrooks",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Estabrooks",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Estabrooks"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2665454"
                        ],
                        "name": "T. Jo",
                        "slug": "T.-Jo",
                        "structuredName": {
                            "firstName": "Taeho",
                            "lastName": "Jo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743642"
                        ],
                        "name": "N. Japkowicz",
                        "slug": "N.-Japkowicz",
                        "structuredName": {
                            "firstName": "Nathalie",
                            "lastName": "Japkowicz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Japkowicz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 121
                            }
                        ],
                        "text": "In practice, subsampling based methods have trouble with unbalanced densities, especially if uniform subsampling is used [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 137
                            }
                        ],
                        "text": "Our algorithm: Our proposed strategy combines the advantages of on-line clustering [20] and mean-shift [4] in an undersampling framework [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15305650,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1152d9bfb6cbfda1b919ff6e9013f48344f9926f",
            "isKey": false,
            "numCitedBy": 833,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Resampling methods are commonly used for dealing with the class\u2010imbalance problem. Their advantage over other methods is that they are external and thus, easily transportable. Although such approaches can be very simple to implement, tuning them most effectively is not an easy task. In particular, it is unclear whether oversampling is more effective than undersampling and which oversampling or undersampling rate should be used. This paper presents an experimental study of these questions and concludes that combining different expressions of the resampling approach is an effective solution to the tuning problem. The proposed combination scheme is evaluated on imbalanced subsets of the Reuters\u201021578 text collection and is shown to be quite effective for these problems."
            },
            "slug": "A-Multiple-Resampling-Method-for-Learning-from-Data-Estabrooks-Jo",
            "title": {
                "fragments": [],
                "text": "A Multiple Resampling Method for Learning from Imbalanced Data Sets"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is concluded that combining different expressions of the resampling approach is an effective solution to the tuning problem and the proposed combination scheme is evaluated on imbalanced subsets of the Reuters\u201021578 text collection and is shown to be quite effective for these problems."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Intell."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716881"
                        ],
                        "name": "A. Meyerson",
                        "slug": "A.-Meyerson",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Meyerson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Meyerson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 83
                            }
                        ],
                        "text": "Our algorithm: Our proposed strategy combines the advantages of on-line clustering [20] and mean-shift [4] in an undersampling framework [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 103
                            }
                        ],
                        "text": "method for allocating centers more uniformly, inspired by mean shift [4] and on-line facility location [20]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 131
                            }
                        ],
                        "text": "The proposed methods are rather inefficient but there are interesting alternatives such as the on-line facility location algorithm [20]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 198045,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8fa146a47927ace433ba93f71d23ed35830bb80e",
            "isKey": false,
            "numCitedBy": 253,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the online variant of facility location, in which demand points arrive one at a time and we must maintain a set of facilities to service these points. We provide a randomized online O(1)-competitive algorithm in the case where points arrive in random order. If points are ordered adversarially, we show that no algorithm can be constant-competitive, and provide an O(log n)-competitive algorithm. Our algorithms are randomized and the analysis depends heavily on the concept of expected waiting time. We also combine our techniques with those of M. Charikar and S. Guha (1999) to provide a linear-time constant approximation for the offline facility location problem."
            },
            "slug": "Online-facility-location-Meyerson",
            "title": {
                "fragments": [],
                "text": "Online facility location"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "This work considers the online variant of facility location, in which demand points arrive one at a time and the operator must maintain a set of facilities to service these points, and provides a randomized online O(1)-competitive algorithm in the case where points arrive in random order."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 2001 IEEE International Conference on Cluster Computing"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 213,
                                "start": 210
                            }
                        ],
                        "text": "Proposed solutions include different forms of resampling such as random oversampling, random undersampling, and importance weighting methods that adjust the cost of the various regions to counter the imbalance [3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 113
                            }
                        ],
                        "text": "This leads k-means to choose suboptimal codebooks in which most of the centers cluster near high density regions [11, 3], thus under-representing equally discriminant low-to-medium density ones."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 217504299,
            "fieldsOfStudy": [],
            "id": "5ef87a84be5e94abfda2dc0c6480995f49b002b3",
            "isKey": false,
            "numCitedBy": 1288,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Editors",
            "title": {
                "fragments": [],
                "text": "Editors"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "ICML'03 Workshop on Learning from Imbalanced Data Sets"
            },
            "venue": {
                "fragments": [],
                "text": "ICML'03 Workshop on Learning from Imbalanced Data Sets"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[13]) we mean a set of representative classes of image patches that suffice to characterize an image object or texture."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Textons"
            },
            "venue": {
                "fragments": [],
                "text": "the elements of texture perception, and their interactions. Nature, 290:91\u201397"
            },
            "year": 1981
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 121
                            }
                        ],
                        "text": "Such textons are typically extracted densely, representing small and relatively generic image micro-structures [10, 18, 28] \u2013 blobs, bars, corners, etc."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "What are textons? IJCV"
            },
            "venue": {
                "fragments": [],
                "text": "What are textons? IJCV"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proceedings of the Tenth IEEE International Conference on Computer Vision"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Tenth IEEE International Conference on Computer Vision"
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 19,
            "methodology": 16,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 31,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Creating-efficient-codebooks-for-visual-recognition-Jurie-Triggs/8d32093cd04d6beffb6d757f58b5ac950543ff7d?sort=total-citations"
}