{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703537"
                        ],
                        "name": "Y. Freund",
                        "slug": "Y.-Freund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Freund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6644398,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ccf5208521cb8c35f50ee8873df89294b8ed7292",
            "isKey": false,
            "numCitedBy": 13130,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "In the first part of the paper we consider the problem of dynamically apportioning resources among a set of options in a worst-case on-line framework. The model we study can be interpreted as a broad, abstract extension of the well-studied on-line prediction model to a general decision-theoretic setting. We show that the multiplicative weight-update Littlestone?Warmuth rule can be adapted to this model, yielding bounds that are slightly weaker in some cases, but applicable to a considerably more general class of learning problems. We show how the resulting learning algorithm can be applied to a variety of problems, including gambling, multiple-outcome prediction, repeated games, and prediction of points in Rn. In the second part of the paper we apply the multiplicative weight-update technique to derive a new boosting algorithm. This boosting algorithm does not require any prior knowledge about the performance of the weak learning algorithm. We also study generalizations of the new boosting algorithm to the problem of learning functions whose range, rather than being binary, is an arbitrary finite set or a bounded segment of the real line."
            },
            "slug": "A-decision-theoretic-generalization-of-on-line-and-Freund-Schapire",
            "title": {
                "fragments": [],
                "text": "A decision-theoretic generalization of on-line learning and an application to boosting"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "The model studied can be interpreted as a broad, abstract extension of the well-studied on-line prediction model to a general decision-theoretic setting, and it is shown that the multiplicative weight-update Littlestone?Warmuth rule can be adapted to this model, yielding bounds that are slightly weaker in some cases, but applicable to a considerably more general class of learning problems."
            },
            "venue": {
                "fragments": [],
                "text": "EuroCOLT"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "146468468"
                        ],
                        "name": "D. Blackwell",
                        "slug": "D.-Blackwell",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Blackwell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blackwell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15946738,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "f3867cb34340d049c10605dee5e7e587db51ceaa",
            "isKey": false,
            "numCitedBy": 729,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "for all i, j . Thus in the (two-person, zero-sum) game with matrix \u039bf, player I has a strategy insuring an expected gain of at least v, and player II has a strategy insuring an expected loss of at most v. An alternative statement, which follows from the von Neumann theorem and an appropriate law of large numbers is that, for any e>0, I can, in a long series of plays of the game with matrix M, guarantee, with probability approaching 1 as the number of plays becomes infinite, that his average actual gain per play exceeds v \u2014 e and that II can similarly restrict his average actual loss to v-he. These facts are assertions about the extent to which each player can control the center of gravity of the actual payoffs in a long series of plays. In this paper we investigate the extent to which this center of gravity can be controlled by the players for the case of matrices M whose elements m(i9 j) are points of \u039b\u0393-space. Roughly, we seek to answer the following question. Given a matrix M and a set S in iV-space, can I guarantee that the center of gravity of the payoffs in a long series of plays is in or arbitrarily near St with probability approaching 1 as the number of plays becomes infinite ? The question is formulated more precisely below, and a complete solution is given in two cases: the case JV=1 and the case of convex S. Let"
            },
            "slug": "An-analog-of-the-minimax-theorem-for-vector-Blackwell",
            "title": {
                "fragments": [],
                "text": "An analog of the minimax theorem for vector payoffs."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1956
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2783939"
                        ],
                        "name": "D. Fudenberg",
                        "slug": "D.-Fudenberg",
                        "structuredName": {
                            "firstName": "Drew",
                            "lastName": "Fudenberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Fudenberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3116213"
                        ],
                        "name": "D. Levine",
                        "slug": "D.-Levine",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Levine",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Levine"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Also, Fudenberg and Levine [10] independently proposed an algorithm equivalent to LW and proved a slightly weaker version of Corollary 2."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 266978,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "6809a81bb501c589105bafab23efb970db38c05e",
            "isKey": false,
            "numCitedBy": 295,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Consistency-and-Cautious-Fictitious-Play-Fudenberg-Levine",
            "title": {
                "fragments": [],
                "text": "Consistency and Cautious Fictitious Play"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388387856"
                        ],
                        "name": "N. Cesa-Bianchi",
                        "slug": "N.-Cesa-Bianchi",
                        "structuredName": {
                            "firstName": "Nicol\u00f2",
                            "lastName": "Cesa-Bianchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cesa-Bianchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703537"
                        ],
                        "name": "Y. Freund",
                        "slug": "Y.-Freund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Freund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772099"
                        ],
                        "name": "D. Helmbold",
                        "slug": "D.-Helmbold",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Helmbold",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Helmbold"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 124263,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "239ae23dc2f934cfa005261ade01023fe7950b82",
            "isKey": false,
            "numCitedBy": 624,
            "numCiting": 85,
            "paperAbstract": {
                "fragments": [],
                "text": "We analyze algorithms that predict a binary value by combining the predictions of several prediction strategies, called `experts''. Our analysis is for worst-case situations, i.e., we make no assumptions about the way the sequence of bits to be predicted is generated. We measure the performance of the algorithm by the difference between the expected number of mistakes it makes on the bit sequence and the expected number of mistakes made by the best expert on this sequence, where the expectation is taken with respect to the randomization in the predictions. We show that the minimum achievable difference is on the order of the square root of the number of mistakes of the best expert, and we give efficient algorithms that achieve this. Our upper and lower bounds have matching leading constants in most cases. We then show how this leads to certain kinds of pattern recognition/learning algorithms with performance bounds that improve on the best results currently known in this context. We also extend our analysis to the case in which log loss is used instead of the expected number of mistakes."
            },
            "slug": "How-to-use-expert-advice-Cesa-Bianchi-Freund",
            "title": {
                "fragments": [],
                "text": "How to use expert advice"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "This work analyzes algorithms that predict a binary value by combining the predictions of several prediction strategies, called `experts', and shows how this leads to certain kinds of pattern recognition/learning algorithms with performance bounds that improve on the best results currently known in this context."
            },
            "venue": {
                "fragments": [],
                "text": "STOC '93"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703537"
                        ],
                        "name": "Y. Freund",
                        "slug": "Y.-Freund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Freund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Freund"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Freund [7] subsequently presented a much improved boosting algorithm which is optimal in particular circumstances."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 19728033,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "121afb1502c90d510f64a0b3276a5454616a64e7",
            "isKey": false,
            "numCitedBy": 1286,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract We present an algorithm for improving the accuracy of algorithms for learning binary concepts. The improvement is achieved by combining a large number of hypotheses, each of which is generated by training the given learning algorithm on a different set of examples. Our algorithm is based on ideas presented by Schapire and represents an improvement over his results, The analysis of our algorithm provides general upper bounds on the resources required for learning in Valiant\u2032s polynomial PAC learning framework, which are the best general upper bounds known today. We show that the number of hypotheses that are combined by our algorithm is the smallest number possible. Other outcomes of our analysis are results regarding the representational power of threshold circuits, the relation between learnability and compression, and a method for parallelizing PAC learning algorithms. We provide extensions of our algorithms to cases in which the concepts are not binary and to the case where the accuracy of the learning algorithm depends on the distribution of the instances."
            },
            "slug": "Boosting-a-weak-learning-algorithm-by-majority-Freund",
            "title": {
                "fragments": [],
                "text": "Boosting a weak learning algorithm by majority"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "An algorithm for improving the accuracy of algorithms for learning binary concepts by combining a large number of hypotheses, each of which is generated by training the given learning algorithm on a different set of examples, is presented."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '90"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2961287"
                        ],
                        "name": "N. Littlestone",
                        "slug": "N.-Littlestone",
                        "structuredName": {
                            "firstName": "Nick",
                            "lastName": "Littlestone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Littlestone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Proof: The proof follows directly from Theorem 2 of Freund and Schapire [9], which in turn is a simple and direct generalization of Littlestone and Warmuth [15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "for learning to play repeated games based on the on-line prediction methods of Littlestone and Warmuth [15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Littlestone and Warmuth [15] generalize their results to countably infinite sets of hypotheses, and Freund and Schapire [9] and Freund [8] give generalizations to uncountably infinite sets of hypotheses."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "4 is a direct generalization of the on-line prediction algorithm of Littlestone and Warmuth [15], it is not surprising that an on-line prediction algorithm can be derived from the more general game-playing algorithm by an appropriate choice of game M."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "An algorithm for solving this problem can be derived by a direct generalization of Littlestone and Warmuth\u2019s \u201cweighted majority algorithm\u201d [15], and is essentially equivalent to our earlier \u201cHedge\u201d algorithm [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "A more careful analysis (using Theorem 1 rather than Corollary 2) gives a better bound identical to that obtained by Littlestone and Warmuth [15] (not surprisingly)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 12843330,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "35582a30685083c62dca992553eec44123be9d07",
            "isKey": true,
            "numCitedBy": 1675,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "The construction of prediction algorithms in a situation in which a learner faces a sequence of trials, with a prediction to be made in each, and the goal of the learner is to make few mistakes is studied. It is assumed that the learner has reason to believe that one of some pool of known algorithms will perform well but does not know which one. A simple and effective method, based on weighted voting, is introduced for constructing a compound algorithm in such a circumstance. It is called the weighted majority algorithm and is shown to be robust with respect to errors in the data. Various versions of the weighted majority algorithm are discussed, and error bounds for them that are closely related to the error bounds of the best algorithms of the pool are proved.<<ETX>>"
            },
            "slug": "The-weighted-majority-algorithm-Littlestone-Warmuth",
            "title": {
                "fragments": [],
                "text": "The Weighted Majority Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A simple and effective method, based on weighted voting, is introduced for constructing a compound algorithm in a situation in which a learner faces a sequence of trials, and the goal of the learner is to make few mistakes."
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Comput."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703537"
                        ],
                        "name": "Y. Freund",
                        "slug": "Y.-Freund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Freund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Freund"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Littlestone and Warmuth [15] generalize their results to countably infinite sets of hypotheses, and Freund and Schapire [9] and Freund [8] give generalizations to uncountably infinite sets of hypotheses."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 284504,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9f64cc9c4e8ea4b98e304161b02e5f41627830e0",
            "isKey": false,
            "numCitedBy": 77,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "We apply the exponential weight algorithm, introduced and Littlestone and Warmuth [26]and by Vovk [35]to the problem of predicting a binary sequence almost as well as the best biased coin. We first show that for the case of the logarithmic loss, the derived algorithm is equivalent to the Bayes algorithm with Jeffreys prior, that was studied by Xie and Barron [38]under probabilistic assumptions. We derive a uniform bound on the regret which holds for any sequence. We also show that if the empirical distribution of the sequence is bounded away from 0 and from 1, then, as the length of the sequence increases to infinity, the difference between this bound and a corresponding bound on the average case regret of the same algorithm (which is asymptotically optimal in that case) is only 1/2. We show that this gap of 1/2 is necessary by calculating the regret of the min\u2013max optimal algorithm for this problem and showing that the asymptotic upper bound is tight. We also study the application of this algorithm to the square loss and show that the algorithm that is derived in this case is different from the Bayes algorithm and is better than it for prediction in the worstcase."
            },
            "slug": "Predicting-a-binary-sequence-almost-as-well-as-the-Freund",
            "title": {
                "fragments": [],
                "text": "Predicting a binary sequence almost as well as the optimal biased coin"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is shown that for the case of the logarithmic loss, the derived algorithm is equivalent to the Bayes algorithm with Jeffreys prior, that was studied by Xie and Barron under probabilistic assumptions."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '96"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2961287"
                        ],
                        "name": "N. Littlestone",
                        "slug": "N.-Littlestone",
                        "structuredName": {
                            "firstName": "Nick",
                            "lastName": "Littlestone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Littlestone"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In the on-line prediction model, first introduced by Littlestone [ 14 ], the learner observes a sequence of examples and predicts their labels one at a time."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6334230,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a1dace286582d91916fe470d08f30381cf453f20",
            "isKey": false,
            "numCitedBy": 1612,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Valiant (1984) and others have studied the problem of learning various classes of Boolean functions from examples. Here we discuss incremental learning of these functions. We consider a setting in which the learner responds to each example according to a current hypothesis. Then the learner updates the hypothesis, if necessary, based on the correct classification of the example. One natural measure of the quality of learning in this setting is the number of mistakes the learner makes. For suitable classes of functions, learning algorithms are available that make a bounded number of mistakes, with the bound independent of the number of examples seen by the learner. We present one such algorithm that learns disjunctive Boolean functions, along with variants for learning other classes of Boolean functions. The basic method can be expressed as a linear-threshold algorithm. A primary advantage of this algorithm is that the number of mistakes grows only logarithmically with the number of irrelevant attributes in the examples. At the same time, the algorithm is computationally efficient in both time and space."
            },
            "slug": "Learning-Quickly-When-Irrelevant-Attributes-Abound:-Littlestone",
            "title": {
                "fragments": [],
                "text": "Learning Quickly When Irrelevant Attributes Abound: A New Linear-Threshold Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work presents one such algorithm that learns disjunctive Boolean functions, along with variants for learning other classes of Boolean functions."
            },
            "venue": {
                "fragments": [],
                "text": "28th Annual Symposium on Foundations of Computer Science (sfcs 1987)"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145346320"
                        ],
                        "name": "Dean P. Foster",
                        "slug": "Dean-P.-Foster",
                        "structuredName": {
                            "firstName": "Dean",
                            "lastName": "Foster",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dean P. Foster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2539286"
                        ],
                        "name": "R. Vohra",
                        "slug": "R.-Vohra",
                        "structuredName": {
                            "firstName": "Rakesh",
                            "lastName": "Vohra",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Vohra"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 207241863,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "4e6da9fb23e71f32e5d43bddd3c6fab62f270597",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a randomized strategy for selecting/combining forecasts that is better than the forecasts used to produce it in a sense made precise in this paper. Unlike traditional methods this approach requires that no assumptions be made about the distribution of the event being forecasted or the error distribution and stationarity of the constituent forecasts. The method is simple and easy to implement."
            },
            "slug": "A-Randomization-Rule-for-Selecting-Forecasts-Foster-Vohra",
            "title": {
                "fragments": [],
                "text": "A Randomization Rule for Selecting Forecasts"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A randomized strategy for selecting/combining forecasts that is better than the forecasts used to produce it in a sense made precise is proposed in this paper."
            },
            "venue": {
                "fragments": [],
                "text": "Oper. Res."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70988756"
                        ],
                        "name": "G. S. Rogers",
                        "slug": "G.-S.-Rogers",
                        "structuredName": {
                            "firstName": "Gerald",
                            "lastName": "Rogers",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. S. Rogers"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 83
                            }
                        ],
                        "text": "For a discussion of infinite matrix games see, for instance, Chapter 2 in Ferguson [3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 14
                            }
                        ],
                        "text": "[3] Thomas S. Ferguson."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 73
                            }
                        ],
                        "text": "For a discussion of infinite marnx games \nsee, for instance, Chapter 2 in Ferguson [3]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 121859210,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "9c191a25ddbdc47a7b596b34bd756f4540f7a81f",
            "isKey": true,
            "numCitedBy": 1469,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Mathematical-Statistics:-A-Decision-Theoretic-Rogers",
            "title": {
                "fragments": [],
                "text": "Mathematical Statistics: A Decision Theoretic Approach"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40527599"
                        ],
                        "name": "Serge A. Plotkin",
                        "slug": "Serge-A.-Plotkin",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Plotkin",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge A. Plotkin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747127"
                        ],
                        "name": "D. Shmoys",
                        "slug": "D.-Shmoys",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Shmoys",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Shmoys"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746222"
                        ],
                        "name": "\u00c9. Tardos",
                        "slug": "\u00c9.-Tardos",
                        "structuredName": {
                            "firstName": "\u00c9va",
                            "lastName": "Tardos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00c9. Tardos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 578485,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d361d6c60a95bd11d87f11f9220b5c4a034e4480",
            "isKey": false,
            "numCitedBy": 359,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Fast algorithms that find approximate solutions for a general class of problems, which are called fractional packing and covering problems, are presented. The only previously known algorithms for solving these problems are based on general linear programming techniques. The techniques developed greatly outperform the general methods in many applications, and are extensions of a method previously applied to find approximate solutions to multicommodity flow problems. The algorithms are based on a Lagrangian relaxation technique, and an important result is a theoretical analysis of the running time of a Lagrangian relaxation based algorithm. Several applications of the algorithms are presented.<<ETX>>"
            },
            "slug": "Fast-approximation-algorithms-for-fractional-and-Plotkin-Shmoys",
            "title": {
                "fragments": [],
                "text": "Fast approximation algorithms for fractional packing and covering problems"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "Fast algorithms that find approximate solutions for a general class of problems, which are called fractional packing and covering problems, are presented, and an important result is a theoretical analysis of the running time of a Lagrangian relaxation based algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "[1991] Proceedings 32nd Annual Symposium of Foundations of Computer Science"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 53
                            }
                        ],
                        "text": "In the on-line prediction model, first introduced by Lit\u00adtlestone \n[14], the learner observes a sequence of examples and predicts their labels one at a time."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 141
                            }
                        ],
                        "text": "After a brief review of game \ntheory, we describe an algorithm for learning to play repeated games based on the on-line prediction \nmethods of Littlestone and War\u00admuth."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 10
                            }
                        ],
                        "text": "[14] Nick Littlestone."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 65
                            }
                        ],
                        "text": "In the on-line prediction model, first introduced by Littlestone [14], the learner observes a sequence of examples and predicts their labels one at a time."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 0
                            }
                        ],
                        "text": "Littlestone and Warmuth [15] generalize their results to \ncountably infinite sets of hypotheses, and Freund and Schapire [9] and Freund [8] give generalizations \nto uncountably infinite sets of hypotheses."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 500,
                                "start": 489
                            }
                        ],
                        "text": "The main theorem concerning this algorithm is the \nfol\u00adlowing: Theorem 1 For any matrix M with n rows and entries in [0, 1], and for any sequence of mixed \nstrategies Ql, . . . . QT played by the environment, the sequence of mixed strategies P1,..., PT produced \nby algorithm LW with parameter ~ E [0, 1) satisfi: t=l t=l where ln(l /6) 1 .,1/ ad= l j3 Cp = g Proofi \nThe proof follows directly from Theorem 2 of Freund and Schapire [9], which in turn is a simple and direct \ngeneral\u00ad ization of Littlestone and Warrnuth [15]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 148
                            }
                        ],
                        "text": "3 ON-LINE PREDICTION Since \nthe game-playing algorithm LW presented in Sec\u00adtion 2.4 is a direct generalization of the on-line prediction \nalgorithm of Littlestone and Warmuth [15], it is not surpris\u00ading that an on-line prediction algorithm \ncan be derived from the more general game-playing algorithm by an appropriate choice of game M."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 116
                            }
                        ],
                        "text": "A more careful analysis (using Theorem 1 rather &#38;an \nCorollary 2) gives a better bound identical to that obtained by Littlestone and Warmuth [15] (not surprisingly)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 89
                            }
                        ],
                        "text": "P t=l An algorithm for solving \nthis problem can be derived by a direct generalization of Littlestone and Warmuth s weighted majority \nalgorithm [15], and is essentially equivalent to our earlier Hedge algorithm [9]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 154
                            }
                        ],
                        "text": "COLT 96, Deaenzano del Garda, Italy \n@1996 ACM 0-89791-81 1-8/96/06 ..$3.50 for learning to play repeated games based on the on-line prediction \nmethods of Littlestone and Warrnuth [15]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 87
                            }
                        ],
                        "text": "As a concrete \nexample, the boosting algorithm described in this paper was derived from Littlestone and Warmuth S weighted \nmajority algorithm by following this dual connection."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 10
                            }
                        ],
                        "text": "[15] Nick Littlestone and Manfred K. Warmuth."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning when irrelevant attributes abound: A new linear-threshold algorithm"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning,"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 108
                            }
                        ],
                        "text": "Indeed, algorithms for this problem with similar properties \nwere derived by Han\u00adnan [13],1 Blackwell [1] and Foster and Vohra [6, 5, 4]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 33
                            }
                        ],
                        "text": "[6] Dean \nP. Foster and Rakesh V. Vohra."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 125
                            }
                        ],
                        "text": "Indeed, algorithms for this problem with similar properties were derived by Hannan [13],1 Blackwell [1] and Foster and Vohra [6, 5, 4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 102
                            }
                        ],
                        "text": "Acknowledgments Thanks to Manfred WarmUth for many \nhelpful discussions, and to Dean Foster and Rakesh Vohra for pointing us to relevant literature."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 30
                            }
                        ],
                        "text": "[5] Dean Foster and Rakesh V. Vohra."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 27
                            }
                        ],
                        "text": "[4] Dean Foster and Rakesh Vohra."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Regret in on-line decision making"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "82548657"
                        ],
                        "name": "J. Hannan",
                        "slug": "J.-Hannan",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Hannan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hannan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 11
                            }
                        ],
                        "text": "[13] \nJames Hannan."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 76
                            }
                        ],
                        "text": "Indeed, algorithms for this problem with similar properties \nwere derived by Han\u00adnan [13],1 Blackwell [1] and Foster and Vohra [6, 5, 4]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 83
                            }
                        ],
                        "text": "Indeed, algorithms for this problem with similar properties were derived by Hannan [13],1 Blackwell [1] and Foster and Vohra [6, 5, 4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 123624867,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "71bf3808d24c9d986fd4a2cf5d93b727479d1e81",
            "isKey": false,
            "numCitedBy": 472,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "4.-APPROXIMATION-TO-RAYES-RISK-IN-REPEATED-PLAY-Hannan",
            "title": {
                "fragments": [],
                "text": "4. APPROXIMATION TO RAYES RISK IN REPEATED PLAY"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1958
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145675281"
                        ],
                        "name": "V. Vovk",
                        "slug": "V.-Vovk",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vovk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vovk"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5226318,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8f80ae7531ae8c8e06f53ca78d5ad8a2dfbc8697",
            "isKey": false,
            "numCitedBy": 714,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Aggregating-strategies-Vovk",
            "title": {
                "fragments": [],
                "text": "Aggregating strategies"
            },
            "venue": {
                "fragments": [],
                "text": "COLT '90"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Schapire . The strength of weak learnability"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A draft of the journal version is available electronically (on our web pages, or by email request)"
            },
            "venue": {
                "fragments": [],
                "text": "[18] Second European Conference, EuroCOLT '95"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Warmuth . How to use expert advice"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Twenty - Fifth Annual ACM Symposium on the Theory of Computing"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Asymptotic calibration . unpublished manuscript"
            },
            "venue": {
                "fragments": [],
                "text": "Asymptotic calibration . unpublished manuscript"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Warmuth . The weighted majority algorithm"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A decisiontheoretic generalization of on-line learning and an application to boosting A draft of the journal version is available electronically (on our web pages, or by email request)"
            },
            "venue": {
                "fragments": [],
                "text": "Computational Learning Theory: Second European Conference, EuroCOLT '95"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning when irrelevant attributes abound : A new lineax - threshold algorithm Warmuth . The weighted majority algorithm"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Levine . Consistency and cautious fictitious play"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Economic Dynamics and Control"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Regret in on-line decision making. unpublished manuscript"
            },
            "venue": {
                "fragments": [],
                "text": "Regret in on-line decision making. unpublished manuscript"
            },
            "year": 1996
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 6,
            "methodology": 3,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 24,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Game-theory,-on-line-prediction-and-boosting-Freund-Schapire/888c09de60ce427669fe5a264fa3e787803eb9d2?sort=total-citations"
}