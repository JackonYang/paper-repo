{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144518416"
                        ],
                        "name": "Holger Schwenk",
                        "slug": "Holger-Schwenk",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Schwenk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Holger Schwenk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398996347"
                        ],
                        "name": "M. Costa-juss\u00e0",
                        "slug": "M.-Costa-juss\u00e0",
                        "structuredName": {
                            "firstName": "Marta",
                            "lastName": "Costa-juss\u00e0",
                            "middleNames": [
                                "Ruiz"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Costa-juss\u00e0"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1779548"
                        ],
                        "name": "Jos\u00e9 A. R. Fonollosa",
                        "slug": "Jos\u00e9-A.-R.-Fonollosa",
                        "structuredName": {
                            "firstName": "Jos\u00e9",
                            "lastName": "Fonollosa",
                            "middleNames": [
                                "A.",
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jos\u00e9 A. R. Fonollosa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6368136,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "028a35d6835b2717c02a7acd5be1c71e0749df26",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "The language model of the target language plays an important role in statistical machine translation systems. In this work, we propose to use a new statistical language model that is based on a continuous representation of the words in the vocabulary. A neural network is used to perform the projection and the probability estimation. This kind of approach is in particular promising for tasks where a very limited amount of resources are available, like the BTEC corpus of tourism related questions. This language model is used in two state-of-the-art statistical machine translation systems that were developed by UPC for the 2006 IWSLT evaluation campaign: a phraseand an n-gram-based approach. An experimental evaluation for four different language pairs is provided (translation of Mandarin, Japanese, Arabic and Italian to English). The proposed method achieved improvements in the BLEU score of up to 3 points on the development data and of almost 2 points on the official test data."
            },
            "slug": "Continuous-space-language-models-for-the-IWSLT-2006-Schwenk-Costa-juss\u00e0",
            "title": {
                "fragments": [],
                "text": "Continuous space language models for the IWSLT 2006 task"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "This work proposes a new statistical language model that is based on a continuous representation of the words in the vocabulary that is promising for tasks where a very limited amount of resources are available, like the BTEC corpus of tourism related questions."
            },
            "venue": {
                "fragments": [],
                "text": "IWSLT"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783839"
                        ],
                        "name": "Katrin Kirchhoff",
                        "slug": "Katrin-Kirchhoff",
                        "structuredName": {
                            "firstName": "Katrin",
                            "lastName": "Kirchhoff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Katrin Kirchhoff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111076629"
                        ],
                        "name": "Mei Yang",
                        "slug": "Mei-Yang",
                        "structuredName": {
                            "firstName": "Mei",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mei Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 97
                            }
                        ],
                        "text": "In another study, a factored LM using POS information achieved the same results as the 4-gram LM (Kirchhoff and Yang, 2005)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 1966857,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a5f9307b8b8473b233432b0e8aa0b4bef311996",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Statistical machine translation systems use a combination of one or more translation models and a language model. While there is a significant body of research addressing the improvement of translation models, the problem of optimizing language models for a specific translation task has not received much attention. Typically, standard word trigram models are used as an out-of-the-box component in a statistical machine translation system. In this paper we apply language modeling techniques that have proved beneficial in automatic speech recognition to the ACL05 machine translation shared data task and demonstrate improvements over a baseline system with a standard language model."
            },
            "slug": "Improved-Language-Modeling-for-Statistical-Machine-Kirchhoff-Yang",
            "title": {
                "fragments": [],
                "text": "Improved Language Modeling for Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Language modeling techniques that have proved beneficial in automatic speech recognition to the ACL05 machine translation shared data task are applied and improvements over a baseline system with a standard language model are demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "ParallelText@ACL"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102811815"
                        ],
                        "name": "Marcello Federico",
                        "slug": "Marcello-Federico",
                        "structuredName": {
                            "firstName": "Marcello",
                            "lastName": "Federico",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marcello Federico"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3077970"
                        ],
                        "name": "M. Cettolo",
                        "slug": "M.-Cettolo",
                        "structuredName": {
                            "firstName": "Mauro",
                            "lastName": "Cettolo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Cettolo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 603858,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f76b28565a0c677f14f802dca10d8d0db09a6cc3",
            "isKey": false,
            "numCitedBy": 92,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Statistical machine translation, as well as other areas of human language processing, have recently pushed toward the use of large scale n-gram language models. This paper presents efficient algorithmic and architectural solutions which have been tested within the Moses decoder, an open source toolkit for statistical machine translation. Experiments are reported with a high performing baseline, trained on the Chinese-English NIST 2006 Evaluation task and running on a standard Linux 64-bit PC architecture. Comparative tests show that our representation halves the memory required by SRI LM Toolkit, at the cost of 44% slower translation speed. However, as it can take advantage of memory mapping on disk, the proposed implementation seems to scale-up much better to very large language models: decoding with a 289-million 5-gram language model runs in 2.1Gb of RAM."
            },
            "slug": "Efficient-Handling-of-N-gram-Language-Models-for-Federico-Cettolo",
            "title": {
                "fragments": [],
                "text": "Efficient Handling of N-gram Language Models for Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper presents efficient algorithmic and architectural solutions which have been tested within the Moses decoder, an open source toolkit for statistical machine translation, and shows that the proposed implementation seems to scale-up much better to very large language models."
            },
            "venue": {
                "fragments": [],
                "text": "WMT@ACL"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144518416"
                        ],
                        "name": "Holger Schwenk",
                        "slug": "Holger-Schwenk",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Schwenk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Holger Schwenk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680233"
                        ],
                        "name": "Marta R. Costa-juss\u00e0",
                        "slug": "Marta-R.-Costa-juss\u00e0",
                        "structuredName": {
                            "firstName": "Marta",
                            "lastName": "Costa-juss\u00e0",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marta R. Costa-juss\u00e0"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1779548"
                        ],
                        "name": "Jos\u00e9 A. R. Fonollosa",
                        "slug": "Jos\u00e9-A.-R.-Fonollosa",
                        "structuredName": {
                            "firstName": "Jos\u00e9",
                            "lastName": "Fonollosa",
                            "middleNames": [
                                "A.",
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jos\u00e9 A. R. Fonollosa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 69
                            }
                        ],
                        "text": "Table 2 presents those results for the Italian/English language pair (Schwenk et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3130183,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "057cb927b59c7cc16141fca2c825da1e3e3ef81a",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of smoothing translation probabilities in a bilingual N-grambased statistical machine translation system. It is proposed to project the bilingual tuples onto a continuous space and to estimate the translation probabilities in this representation. A neural network is used to perform the projection and the probability estimation. Smoothing probabilities is most important for tasks with a limited amount of training material. We consider here the BTEC task of the 2006 IWSLT evaluation. Improvements in all official automatic measures are reported when translating from Italian to English. Using a continuous space model for the translation model and the target language model, an improvement of 1.5 BLEU on the test data is observed."
            },
            "slug": "Smooth-Bilingual-N-Gram-Translation-Schwenk-Costa-juss\u00e0",
            "title": {
                "fragments": [],
                "text": "Smooth Bilingual N-Gram Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "It is proposed to project the bilingual tuples onto a continuous space and to estimate the translation probabilities in this representation and a neural network is used to perform the projection and the probability estimation."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144518416"
                        ],
                        "name": "Holger Schwenk",
                        "slug": "Holger-Schwenk",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Schwenk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Holger Schwenk"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We just need to apply the sentence splitting algorithm on the training data used to build the LM during decoding."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 11
                            }
                        ],
                        "text": "It can be\nclearly seen that joining the lattices and recalculat-\ning the LM probabilities gives better results than\njust concatenating the 1-best solutions of the individual chunks (first line: BLEU score of 41.63 compared to 40.20)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 132
                            }
                        ],
                        "text": "Table 2 compares the results for different ways to translate the individual chunks (using a standard 3-gram LM versus an LM trained on texts with sentence breaks inserted), and to extracted the global solution (con-\nLM used Concatenate Lattice during decoding 1-best join\nWithout sentence breaks\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 207041403,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0fcc184b3b90405ec3ceafd6a4007c749df7c363",
            "isKey": false,
            "numCitedBy": 555,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Continuous-space-language-models-Schwenk",
            "title": {
                "fragments": [],
                "text": "Continuous space language models"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Speech Lang."
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144518416"
                        ],
                        "name": "Holger Schwenk",
                        "slug": "Holger-Schwenk",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Schwenk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Holger Schwenk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685010"
                        ],
                        "name": "J. Gauvain",
                        "slug": "J.-Gauvain",
                        "structuredName": {
                            "firstName": "Jean-Luc",
                            "lastName": "Gauvain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Gauvain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "For details about the implemented algorithm, the reader is referred to (D\u00e9chelotte et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 54720660,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ee0a696d885b8c0062340d0c1c8c949ac3d520cb",
            "isKey": false,
            "numCitedBy": 1,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents the LIMSI statistical machine translation system developed for 2006 T C-STAR evaluation campaign. We describe an A*-decoder that generates translation lattices using a word-based translation model. A lattice is a rich and compact representation of alternative translations that includes the probability scores of all the involved sub-models. These lattices are then used in subsequent processing steps, in particular to perform sentence splitting and joining, maximum BLEU training and to use improved statistical target language models."
            },
            "slug": "The-2006-LIMSI-Statistical-Machine-Translation-for-Schwenk-Gauvain",
            "title": {
                "fragments": [],
                "text": "The 2006 LIMSI Statistical Machine Translation System for TC-STAR"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "An A*-decoder that generates translation lattices using a word-based translation model that is used to perform sentence splitting and joining, maximum BLEU training and to use improved statistical target language models."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144518416"
                        ],
                        "name": "Holger Schwenk",
                        "slug": "Holger-Schwenk",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Schwenk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Holger Schwenk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736665"
                        ],
                        "name": "Y. Est\u00e8ve",
                        "slug": "Y.-Est\u00e8ve",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Est\u00e8ve",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Est\u00e8ve"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 63
                            }
                        ],
                        "text": "It can be\nclearly seen that joining the lattices and recalculat-\ning the LM probabilities gives better results than\njust concatenating the 1-best solutions of the individual chunks (first line: BLEU score of 41.63 compared to 40.20)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 2855467,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4aadf030f9fa316f041d00a90d74b2c553772d29",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper gives a detailed description of a statistical machine translation system developed for the 2008 NIST open MT evaluation. The system is based on the open source toolkit Moses with extensions for language model rescoring in a second pass. Significant improvements were obtained with data selection methods for the language and translation model. An improvement of more than 1 point BLEU on the test set was achieved by a continuous space language model which performs the probability estimation with a neural network. The described system has achieved a very good ranking in the 2008 NIST open MT evaluation."
            },
            "slug": "Data-selection-and-smoothing-in-an-open-source-for-Schwenk-Est\u00e8ve",
            "title": {
                "fragments": [],
                "text": "Data selection and smoothing in an open-source system for the 2008 NIST machine translation evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "This paper gives a detailed description of a statistical machine translation system developed for the 2008 NIST open MT evaluation based on the open source toolkit Moses with extensions for language model rescoring in a second pass."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145250904"
                        ],
                        "name": "J. Mari\u00f1o",
                        "slug": "J.-Mari\u00f1o",
                        "structuredName": {
                            "firstName": "Jos\u00e9",
                            "lastName": "Mari\u00f1o",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mari\u00f1o"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786911"
                        ],
                        "name": "A. Gispert",
                        "slug": "A.-Gispert",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Gispert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gispert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694652"
                        ],
                        "name": "Rafael E. Banchs",
                        "slug": "Rafael-E.-Banchs",
                        "structuredName": {
                            "firstName": "Rafael",
                            "lastName": "Banchs",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rafael E. Banchs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40010027"
                        ],
                        "name": "Patrik Lambert",
                        "slug": "Patrik-Lambert",
                        "structuredName": {
                            "firstName": "Patrik",
                            "lastName": "Lambert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Patrik Lambert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2074051395"
                        ],
                        "name": "Marta Ruiz",
                        "slug": "Marta-Ruiz",
                        "structuredName": {
                            "firstName": "Marta",
                            "lastName": "Ruiz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marta Ruiz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This approach basically uses a language model on bilingual tuples (Mari\u00f1o et al., 2006), resulting in the same data sparseness problems as for the model on the target language."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7523633,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "68709f1c324bcc485b4895240fab59353570be9b",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a statistical machine translation system that uses a translation model which is based on bilingual n-grams. When this translation model is log-linearly combined with four specific feature functions, state of the art translations are achieved for Spanish-to-English and English-to-Spanish translation tasks. Some specific results obtained for the EPPS (European Parliament Plenary Sessions) data are presented and discussed. Finally, future research issues are depicted."
            },
            "slug": "Bilingual-N-gram-Statistical-Machine-Translation-Mari\u00f1o-Gispert",
            "title": {
                "fragments": [],
                "text": "Bilingual N-gram Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "This paper describes a statistical machine translation system that uses a translation model which is based on bilingual n-grams and when this translation model is log-linearly combined with four specific feature functions, state of the art translations are achieved for Spanish-to-English and English- to-Spanish translation tasks."
            },
            "venue": {
                "fragments": [],
                "text": "MTSUMMIT"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144518416"
                        ],
                        "name": "Holger Schwenk",
                        "slug": "Holger-Schwenk",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Schwenk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Holger Schwenk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685010"
                        ],
                        "name": "J. Gauvain",
                        "slug": "J.-Gauvain",
                        "structuredName": {
                            "firstName": "Jean-Luc",
                            "lastName": "Gauvain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Gauvain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 46
                            }
                        ],
                        "text": "Training is done using a resampling algorithm (Schwenk and Gauvain, 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 161
                            }
                        ],
                        "text": "The continuous space language model was trained on exactly the same data than the back-off reference language model, using the resampling algorithm described in (Schwenk and Gauvain, 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 75
                            }
                        ],
                        "text": "This approach was successfully used in large vocabulary speech recognition (Schwenk and Gauvain, 2005), and we are interested here if similar ideas can be applied to statistical machine translation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12469208,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b395470a57c48d174c4216ea21a7a58bc046917",
            "isKey": false,
            "numCitedBy": 128,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "During the last years there has been growing interest in using neural networks for language modeling. In contrast to the well known back-off n-gram language models, the neural network approach attempts to overcome the data sparseness problem by performing the estimation in a continuous space. This type of language model was mostly used for tasks for which only a very limited amount of in-domain training data is available.In this paper we present new algorithms to train a neural network language model on very large text corpora. This makes possible the use of the approach in domains where several hundreds of millions words of texts are available. The neural network language model is evaluated in a state-of-the-art real-time continuous speech recognizer for French Broadcast News. Word error reductions of 0.5% absolute are reported using only a very limited amount of additional processing time."
            },
            "slug": "Training-Neural-Network-Language-Models-on-Very-Schwenk-Gauvain",
            "title": {
                "fragments": [],
                "text": "Training Neural Network Language Models on Very Large Corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "New algorithms to train a neural network language model on very large text corpora are presented, making possible the use of the approach in domains where several hundreds of millions words of texts are available."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2002316"
                        ],
                        "name": "F. Och",
                        "slug": "F.-Och",
                        "structuredName": {
                            "firstName": "Franz",
                            "lastName": "Och",
                            "middleNames": [
                                "Josef"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Och"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We also present algorithms to improve the estimation of the language model probabilities when splitting long sentences into shorter chunks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 50
                            }
                        ],
                        "text": "The inputs to the neural network are the indices of then\u22121 previous words in the vocabularyhj=wj\u2212n+1, . . . , wj\u22122, wj\u22121 and the outputs are the posterior probabilities ofall words of the vocabulary:\nP (wj = i|hj) \u2200i \u2208 [1, N ] (2)\nwhereN is the size of the vocabulary."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 284436,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "37fadfb6d60e83e24c72d8a90da5644b39d6e8f0",
            "isKey": false,
            "numCitedBy": 1228,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a framework for statistical machine translation of natural languages based on direct maximum entropy models, which contains the widely used source-channel approach as a special case. All knowledge sources are treated as feature functions, which depend on the source language sentence, the target language sentence and possible hidden variables. This approach allows a baseline machine translation system to be extended easily by adding new feature functions. We show that a baseline statistical machine translation system is significantly improved using this approach."
            },
            "slug": "Discriminative-Training-and-Maximum-Entropy-Models-Och-Ney",
            "title": {
                "fragments": [],
                "text": "Discriminative Training and Maximum Entropy Models for Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "A framework for statistical machine translation of natural languages based on direct maximum entropy models, which contains the widely used source-channel approach as a special case and shows that a baseline statistical machinetranslation system is significantly improved using this approach."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784037"
                        ],
                        "name": "T. Brants",
                        "slug": "T.-Brants",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Brants",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Brants"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054252"
                        ],
                        "name": "Ashok Popat",
                        "slug": "Ashok-Popat",
                        "structuredName": {
                            "firstName": "Ashok",
                            "lastName": "Popat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ashok Popat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2092025743"
                        ],
                        "name": "P. Xu",
                        "slug": "P.-Xu",
                        "structuredName": {
                            "firstName": "Peng",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2002316"
                        ],
                        "name": "F. Och",
                        "slug": "F.-Och",
                        "structuredName": {
                            "firstName": "Franz",
                            "lastName": "Och",
                            "middleNames": [
                                "Josef"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Och"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49959210"
                        ],
                        "name": "J. Dean",
                        "slug": "J.-Dean",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Dean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dean"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 243,
                                "start": 168
                            }
                        ],
                        "text": "Several authors propose variants of the back-off n-gram approach to tackle the enormous computational and storage complexity during training and decoding, for instance (Federico and Cettolo, 2007; Brants et al., 2007; Talbot and Osborne, 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 633992,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ba786c46373892554b98df42df7af6f5da343c9d",
            "isKey": false,
            "numCitedBy": 533,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Systems, methods, and computer program products for machine translation are provided. In some implementations a system is provided. The system includes a language model including a collection of n-grams from a corpus, each n-gram having a corresponding relative frequency in the corpus and an order n corresponding to a number of tokens in the n-gram, each n-gram corresponding to a backoff n-gram having an order of n-1 and a collection of backoff scores, each backoff score associated with an n-gram, the backoff score determined as a function of a backoff factor and a relative frequency of a corresponding backoff n-gram in the corpus."
            },
            "slug": "Large-Language-Models-in-Machine-Translation-Brants-Popat",
            "title": {
                "fragments": [],
                "text": "Large Language Models in Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "Systems, methods, and computer program products for machine translation are provided for backoff score determination as a function of a backoff factor and a relative frequency of a corresponding backoff n-gram in the corpus."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2092025743"
                        ],
                        "name": "P. Xu",
                        "slug": "P.-Xu",
                        "structuredName": {
                            "firstName": "Peng",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 9
                            }
                        ],
                        "text": "Separate LMs were first trained on the English EPPS texts (33.8M words) and the transcriptions of the acoustic training material (740k words) respectively."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 12
                            }
                        ],
                        "text": "Syntaxbased LMs were investigated in (Charniak et al.,\n723\n2003), and reranking of translation hypothesis using structural properties in (Hasan et al., 2006)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "Therefore, we suggest to use more complex statistical LMs that are expected to take better advantage of the limited amount of appropriate training data."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 13
                            }
                        ],
                        "text": "All back-off LMs were built using modified KneserNey smoothing and the SRI LM-toolkit (Stolcke, 2002)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 79
                            }
                        ],
                        "text": "For a value of 1.0 the backoff LM is used alone, while only the neural network LMs are used for a value of 0.0."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 80
                            }
                        ],
                        "text": "It has even turned out that it was advantageous to train several neural network LMs with different context sizes3 and to interpolate them altogether."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 360,
                                "start": 357
                            }
                        ],
                        "text": "For the sake of simplicity we will still call this interpolation the neural network LM.\nBack-off LM Neural LM 3-gram 4-gram 4-gram\nPerplexity 85.5 79.6 65.0 Dev data:\nBLEU 42.35 43.36 44.42 WER 45.9% 45.1% 44.4% PER 31.8% 31.3% 30.8% Eval data: BLEU 39.77 40.62 41.45 WER 48.2% 47.4% 46.7% PER 33.6% 33.1% 32.8%\nTable 3: Result comparison for the different LMs. BLEU uses 2 reference translations."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 33
                            }
                        ],
                        "text": "In this work, we use only 4-gram LMs, but the complexity of the neural network LM increases only slightly with the order of the LM."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 44
                            }
                        ],
                        "text": "Promising candidates are random forest LMs (Xu and Jelinek, 2004), random cluster LMs (Emami and Jelinek, 2005) and the neural network LM (Bengio et al., 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 115
                            }
                        ],
                        "text": "We believe that this would not make a notable difference in our experiments since we do interpolate the individual LMs, the coefficients being optimized to minimize perplexity on the development data."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 10
                            }
                        ],
                        "text": "These two LMs were then interpolated together."
                    },
                    "intents": []
                }
            ],
            "corpusId": 18686747,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4c1c954d03f80210d2bf27e5dee86ddc44f0f531",
            "isKey": true,
            "numCitedBy": 85,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we explore the use of Random Forests (RFs) (Amit and Geman, 1997; Breiman, 2001) in language modeling, the problem of predicting the next word based on words already seen before. The goal in this work is to develop a new language modeling approach based on randomly grown Decision Trees (DTs) and apply it to automatic speech recognition. We study our RF approach in the context of -gram type language modeling. Unlike regular -gram language models, RF language models have the potential to generalize well to unseen data, even when a complicated history is used. We show that our RF language models are superior to regular -gram language models in reducing both the perplexity (PPL) and word error rate (WER) in a large vocabulary speech recognition system."
            },
            "slug": "Random-Forests-in-Language-Modelin-Xu-Jelinek",
            "title": {
                "fragments": [],
                "text": "Random Forests in Language Modelin"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is shown that the RF language models are superior to regular -gram language models in reducing both the perplexity (PPL) and word error rate (WER) in a large vocabulary speech recognition system."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51012238"
                        ],
                        "name": "H. Schwenk",
                        "slug": "H.-Schwenk",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Schwenk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Schwenk"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 58
                            }
                        ],
                        "text": "To speed up the processing several improvements were used (Schwenk, 2004):"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16930073,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d6fb7546a29320eadad868af66835059db93d99f",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently there has been increasing interest in using neural networks for language modeling. In contrast to the well-known backoff n-gram language models, the neural network approach tries to limit the data sparseness problem by performing the estimation in a continuous space, allowing by this means smooth interpolations. The complexity to train such a model and to calculate one n-gram probability is however several orders of magnitude higher than for the backoff models, making the new approach difficult to use in real applications. In this paper several techniques are presented that allow the use of a neural network language model in a large vocabulary speech recognition system, in particular very, fast lattice rescoring and efficient training of large neural networks on training corpora of over 10 million words. The described approach achieves significant word error reductions with respect to a carefully tuned 4-gram backoff language model in a state of the art conversational speech recognizer for the DARPA rich transcriptions evaluations."
            },
            "slug": "Efficient-training-of-large-neural-networks-for-Schwenk",
            "title": {
                "fragments": [],
                "text": "Efficient training of large neural networks for language modeling"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The described approach achieves significant word error reductions with respect to a carefully tuned 4-gram backoff language model in a state of the art conversational speech recognizer for the DARPA rich transcriptions evaluations."
            },
            "venue": {
                "fragments": [],
                "text": "2004 IEEE International Joint Conference on Neural Networks (IEEE Cat. No.04CH37541)"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36037226"
                        ],
                        "name": "R\u00e9jean Ducharme",
                        "slug": "R\u00e9jean-Ducharme",
                        "structuredName": {
                            "firstName": "R\u00e9jean",
                            "lastName": "Ducharme",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R\u00e9jean Ducharme"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120247189"
                        ],
                        "name": "Pascal Vincent",
                        "slug": "Pascal-Vincent",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Vincent",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pascal Vincent"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1909943744"
                        ],
                        "name": "Christian Janvin",
                        "slug": "Christian-Janvin",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Janvin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Janvin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 139
                            }
                        ],
                        "text": "Promising candidates are random forest LMs (Xu and Jelinek, 2004), random cluster LMs (Emami and Jelinek, 2005) and the neural network LM (Bengio et al., 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 221275765,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c2b28f9354f667cd5bd07afc0471d8334430da7",
            "isKey": false,
            "numCitedBy": 6014,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "A goal of statistical language modeling is to learn the joint probability function of sequences of words in a language. This is intrinsically difficult because of the curse of dimensionality: a word sequence on which the model will be tested is likely to be different from all the word sequences seen during training. Traditional but very successful approaches based on n-grams obtain generalization by concatenating very short overlapping sequences seen in the training set. We propose to fight the curse of dimensionality by learning a distributed representation for words which allows each training sentence to inform the model about an exponential number of semantically neighboring sentences. The model learns simultaneously (1) a distributed representation for each word along with (2) the probability function for word sequences, expressed in terms of these representations. Generalization is obtained because a sequence of words that has never been seen before gets high probability if it is made of words that are similar (in the sense of having a nearby representation) to words forming an already seen sentence. Training such large models (with millions of parameters) within a reasonable time is itself a significant challenge. We report on experiments using neural networks for the probability function, showing on two text corpora that the proposed approach significantly improves on state-of-the-art n-gram models, and that the proposed approach allows to take advantage of longer contexts."
            },
            "slug": "A-Neural-Probabilistic-Language-Model-Bengio-Ducharme",
            "title": {
                "fragments": [],
                "text": "A Neural Probabilistic Language Model"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work proposes to fight the curse of dimensionality by learning a distributed representation for words which allows each training sentence to inform the model about an exponential number of semantically neighboring sentences."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32538203"
                        ],
                        "name": "P. Brown",
                        "slug": "P.-Brown",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Brown",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2714577"
                        ],
                        "name": "S. D. Pietra",
                        "slug": "S.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Pietra",
                            "middleNames": [
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39944066"
                        ],
                        "name": "V. D. Pietra",
                        "slug": "V.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Pietra",
                            "middleNames": [
                                "J.",
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 75
                            }
                        ],
                        "text": "The classical Bayes relation is used to introduce a target language model (Brown et al., 1993):\ne\u0302 = arg max e Pr(e|f) = arg max e Pr(f |e) Pr(e) wherePr(f |e) is the translation model andPr(e)\nis the target language model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 76
                            }
                        ],
                        "text": "A word-based translation engine is used based on the so-called IBM-4 model (Brown et al., 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13259913,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ab7b5917515c460b90451e67852171a531671ab8",
            "isKey": false,
            "numCitedBy": 4745,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a series of five statistical models of the translation process and give algorithms for estimating the parameters of these models given a set of pairs of sentences that are translations of one another. We define a concept of word-by-word alignment between such pairs of sentences. For any given pair of such sentences each of our models assigns a probability to each of the possible word-by-word alignments. We give an algorithm for seeking the most probable of these alignments. Although the algorithm is suboptimal, the alignment thus obtained accounts well for the word-by-word relationships in the pair of sentences. We have a great deal of data in French and English from the proceedings of the Canadian Parliament. Accordingly, we have restricted our work to these two languages; but we feel that because our algorithms have minimal linguistic content they would work well on other pairs of languages. We also feel, again because of the minimal linguistic content of our algorithms, that it is reasonable to argue that word-by-word alignments are inherent in any sufficiently large bilingual corpus."
            },
            "slug": "The-Mathematics-of-Statistical-Machine-Translation:-Brown-Pietra",
            "title": {
                "fragments": [],
                "text": "The Mathematics of Statistical Machine Translation: Parameter Estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is reasonable to argue that word-by-word alignments are inherent in any sufficiently large bilingual corpus, given a set of pairs of sentences that are translations of one another."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755162"
                        ],
                        "name": "Philipp Koehn",
                        "slug": "Philipp-Koehn",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Koehn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Koehn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152378023"
                        ],
                        "name": "Hieu T. Hoang",
                        "slug": "Hieu-T.-Hoang",
                        "structuredName": {
                            "firstName": "Hieu",
                            "lastName": "Hoang",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hieu T. Hoang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2539211"
                        ],
                        "name": "Alexandra Birch",
                        "slug": "Alexandra-Birch",
                        "structuredName": {
                            "firstName": "Alexandra",
                            "lastName": "Birch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexandra Birch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763608"
                        ],
                        "name": "Chris Callison-Burch",
                        "slug": "Chris-Callison-Burch",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Callison-Burch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Callison-Burch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102811815"
                        ],
                        "name": "Marcello Federico",
                        "slug": "Marcello-Federico",
                        "structuredName": {
                            "firstName": "Marcello",
                            "lastName": "Federico",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marcello Federico"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895952"
                        ],
                        "name": "N. Bertoldi",
                        "slug": "N.-Bertoldi",
                        "structuredName": {
                            "firstName": "Nicola",
                            "lastName": "Bertoldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Bertoldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46898156"
                        ],
                        "name": "Brooke Cowan",
                        "slug": "Brooke-Cowan",
                        "structuredName": {
                            "firstName": "Brooke",
                            "lastName": "Cowan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brooke Cowan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2529583"
                        ],
                        "name": "Wade Shen",
                        "slug": "Wade-Shen",
                        "structuredName": {
                            "firstName": "Wade",
                            "lastName": "Shen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wade Shen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055137469"
                        ],
                        "name": "C. Moran",
                        "slug": "C.-Moran",
                        "structuredName": {
                            "firstName": "Christine",
                            "lastName": "Moran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Moran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1983801"
                        ],
                        "name": "R. Zens",
                        "slug": "R.-Zens",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Zens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745899"
                        ],
                        "name": "Chris Dyer",
                        "slug": "Chris-Dyer",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Dyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Dyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143832874"
                        ],
                        "name": "Ondrej Bojar",
                        "slug": "Ondrej-Bojar",
                        "structuredName": {
                            "firstName": "Ondrej",
                            "lastName": "Bojar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ondrej Bojar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057195055"
                        ],
                        "name": "Alexandra Constantin",
                        "slug": "Alexandra-Constantin",
                        "structuredName": {
                            "firstName": "Alexandra",
                            "lastName": "Constantin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexandra Constantin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2082901914"
                        ],
                        "name": "Evan Herbst",
                        "slug": "Evan-Herbst",
                        "structuredName": {
                            "firstName": "Evan",
                            "lastName": "Herbst",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Evan Herbst"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 794019,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4ee2eab4c298c1824a9fb8799ad8eed21be38d21",
            "isKey": false,
            "numCitedBy": 5930,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an open-source toolkit for statistical machine translation whose novel contributions are (a) support for linguistically motivated factors, (b) confusion network decoding, and (c) efficient data formats for translation models and language models. In addition to the SMT decoder, the toolkit also includes a wide variety of tools for training, tuning and applying the system to many translation tasks."
            },
            "slug": "Moses:-Open-Source-Toolkit-for-Statistical-Machine-Koehn-Hoang",
            "title": {
                "fragments": [],
                "text": "Moses: Open Source Toolkit for Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "An open-source toolkit for statistical machine translation whose novel contributions are support for linguistically motivated factors, confusion network decoding, and efficient data formats for translation models and language models."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144251066"
                        ],
                        "name": "David Talbot",
                        "slug": "David-Talbot",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Talbot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Talbot"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057788"
                        ],
                        "name": "M. Osborne",
                        "slug": "M.-Osborne",
                        "structuredName": {
                            "firstName": "Miles",
                            "lastName": "Osborne",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Osborne"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 969780,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1375ffa728c1c7ae2b471fc2443d8342cfea84d1",
            "isKey": false,
            "numCitedBy": 87,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "A Bloom filter (BF) is a randomised data structure for set membership queries. Its space requirements are significantly below lossless information-theoretic lower bounds but it produces false positives with some quantifiable probability. Here we explore the use of BFs for language modelling in statistical machine translation. We show how a BF containing n-grams can enable us to use much larger corpora and higher-order models complementing a conventional n-gram LM within an SMT system. We also consider (i) how to include approximate frequency information efficiently within a BF and (ii) how to reduce the error rate of these models by first checking for lower-order sub-sequences in candidate ngrams. Our solutions in both cases retain the one-sided error guarantees of the BF while takingadvantageof theZipf-likedistribution of word frequencies to reduce the space requirements."
            },
            "slug": "Randomised-Language-Modelling-for-Statistical-Talbot-Osborne",
            "title": {
                "fragments": [],
                "text": "Randomised Language Modelling for Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 35,
                "text": "It is shown how a BF containing n-grams can enable us to use much larger corpora and higher-order models complementing a conventional n- gram LM within an SMT system."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2002316"
                        ],
                        "name": "F. Och",
                        "slug": "F.-Och",
                        "structuredName": {
                            "firstName": "Franz",
                            "lastName": "Och",
                            "middleNames": [
                                "Josef"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Och"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793218"
                        ],
                        "name": "D. Gildea",
                        "slug": "D.-Gildea",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Gildea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gildea"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2803071"
                        ],
                        "name": "S. Khudanpur",
                        "slug": "S.-Khudanpur",
                        "structuredName": {
                            "firstName": "Sanjeev",
                            "lastName": "Khudanpur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Khudanpur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3028658"
                        ],
                        "name": "Anoop Sarkar",
                        "slug": "Anoop-Sarkar",
                        "structuredName": {
                            "firstName": "Anoop",
                            "lastName": "Sarkar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anoop Sarkar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109821889"
                        ],
                        "name": "Kenji Yamada",
                        "slug": "Kenji-Yamada",
                        "structuredName": {
                            "firstName": "Kenji",
                            "lastName": "Yamada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenji Yamada"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2277248"
                        ],
                        "name": "Alexander M. Fraser",
                        "slug": "Alexander-M.-Fraser",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Fraser",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexander M. Fraser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9567965"
                        ],
                        "name": "Shankar Kumar",
                        "slug": "Shankar-Kumar",
                        "structuredName": {
                            "firstName": "Shankar",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shankar Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39839719"
                        ],
                        "name": "Libin Shen",
                        "slug": "Libin-Shen",
                        "structuredName": {
                            "firstName": "Libin",
                            "lastName": "Shen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Libin Shen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32941713"
                        ],
                        "name": "David A. Smith",
                        "slug": "David-A.-Smith",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Smith",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David A. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073371"
                        ],
                        "name": "Katherine Eng",
                        "slug": "Katherine-Eng",
                        "structuredName": {
                            "firstName": "Katherine",
                            "lastName": "Eng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Katherine Eng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2061365480"
                        ],
                        "name": "Viren Jain",
                        "slug": "Viren-Jain",
                        "structuredName": {
                            "firstName": "Viren",
                            "lastName": "Jain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Viren Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47305151"
                        ],
                        "name": "Zhenglin Jin",
                        "slug": "Zhenglin-Jin",
                        "structuredName": {
                            "firstName": "Zhenglin",
                            "lastName": "Jin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhenglin Jin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9215251"
                        ],
                        "name": "Dragomir R. Radev",
                        "slug": "Dragomir-R.-Radev",
                        "structuredName": {
                            "firstName": "Dragomir",
                            "lastName": "Radev",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dragomir R. Radev"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 51
                            }
                        ],
                        "text": "Many different feature functions were explored in (Och et al., 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6244213,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cb3dcb13abd096a33780e6268ee4aaa583b198e8",
            "isKey": false,
            "numCitedBy": 316,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a methodology for rapid experimentation in statistical machine translation which we use to add a large number of features to a baseline system exploiting features from a wide range of levels of syntactic representation. Feature values were combined in a log-linear model to select the highest scoring candidate translation from an n-best list. Feature weights were optimized directly against the BLEU evaluation metric on held-out data. We present results for a small selection of features at each level of syntactic representation."
            },
            "slug": "A-Smorgasbord-of-Features-for-Statistical-Machine-Och-Gildea",
            "title": {
                "fragments": [],
                "text": "A Smorgasbord of Features for Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A methodology for rapid experimentation in statistical machine translation which is used to add a large number of features to a baseline system exploiting features from a wide range of levels of syntactic representation is described."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40126871"
                        ],
                        "name": "S. Hasan",
                        "slug": "S.-Hasan",
                        "structuredName": {
                            "firstName": "Sasa",
                            "lastName": "Hasan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hasan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068731664"
                        ],
                        "name": "Oliver Bender",
                        "slug": "Oliver-Bender",
                        "structuredName": {
                            "firstName": "Oliver",
                            "lastName": "Bender",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oliver Bender"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 138
                            }
                        ],
                        "text": "Syntaxbased LMs were investigated in (Charniak et al.,\n723\n2003), and reranking of translation hypothesis using structural properties in (Hasan et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5995203,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1a8c3a6e8b773fb475b376bee7c9622390a5ff88",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate methods that add syntactically motivated features to a statistical machine translation system in a reranking framework. The goal is to analyze whether shallow parsing techniques help in identifying ungrammatical hypotheses. We show that improvements are possible by utilizing supertagging, lightweight dependency analysis, a link grammar parser and a maximum-entropy based chunk parser. Adding features to n-best lists and discriminatively training the system on a development set increases the BLEU score up to 0.7% on the test set."
            },
            "slug": "Reranking-Translation-Hypotheses-Using-Structural-Hasan-Bender",
            "title": {
                "fragments": [],
                "text": "Reranking Translation Hypotheses Using Structural Properties"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "Improvements are possible by utilizing supertagging, lightweight dependency analysis, a link grammar parser and a maximum-entropy based chunk parser to investigate methods that add syntactically motivated features to a statistical machine translation system in a reranking framework."
            },
            "venue": {
                "fragments": [],
                "text": "Learning Structured Information@EACL"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35797272"
                        ],
                        "name": "Ahmad Emami",
                        "slug": "Ahmad-Emami",
                        "structuredName": {
                            "firstName": "Ahmad",
                            "lastName": "Emami",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ahmad Emami"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 9
                            }
                        ],
                        "text": "Separate LMs were first trained on the English EPPS texts (33.8M words) and the transcriptions of the acoustic training material (740k words) respectively."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 12
                            }
                        ],
                        "text": "Syntaxbased LMs were investigated in (Charniak et al.,\n723\n2003), and reranking of translation hypothesis using structural properties in (Hasan et al., 2006)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "Therefore, we suggest to use more complex statistical LMs that are expected to take better advantage of the limited amount of appropriate training data."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 13
                            }
                        ],
                        "text": "All back-off LMs were built using modified KneserNey smoothing and the SRI LM-toolkit (Stolcke, 2002)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 79
                            }
                        ],
                        "text": "For a value of 1.0 the backoff LM is used alone, while only the neural network LMs are used for a value of 0.0."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 80
                            }
                        ],
                        "text": "It has even turned out that it was advantageous to train several neural network LMs with different context sizes3 and to interpolate them altogether."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 86
                            }
                        ],
                        "text": "Promising candidates are random forest LMs (Xu and Jelinek, 2004), random cluster LMs (Emami and Jelinek, 2005) and the neural network LM (Bengio et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 360,
                                "start": 357
                            }
                        ],
                        "text": "For the sake of simplicity we will still call this interpolation the neural network LM.\nBack-off LM Neural LM 3-gram 4-gram 4-gram\nPerplexity 85.5 79.6 65.0 Dev data:\nBLEU 42.35 43.36 44.42 WER 45.9% 45.1% 44.4% PER 31.8% 31.3% 30.8% Eval data: BLEU 39.77 40.62 41.45 WER 48.2% 47.4% 46.7% PER 33.6% 33.1% 32.8%\nTable 3: Result comparison for the different LMs. BLEU uses 2 reference translations."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 33
                            }
                        ],
                        "text": "In this work, we use only 4-gram LMs, but the complexity of the neural network LM increases only slightly with the order of the LM."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 39
                            }
                        ],
                        "text": "Promising candidates are random forest LMs (Xu and Jelinek, 2004), random cluster LMs (Emami and Jelinek, 2005) and the neural network LM (Bengio et al., 2003)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 115
                            }
                        ],
                        "text": "We believe that this would not make a notable difference in our experiments since we do interpolate the individual LMs, the coefficients being optimized to minimize perplexity on the development data."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 10
                            }
                        ],
                        "text": "These two LMs were then interpolated together."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5779171,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a493a23b86192aa74e6f394061288082e1e7cdb7",
            "isKey": true,
            "numCitedBy": 31,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an application of randomization techniques to class-based n-gram language models used in speech recognizers. The idea is to derive a language model from the combination of a set of random class-based models. Each of the constituent random class-based models is built using a separate clustering obtained via a different run of a randomized clustering algorithm. The random class-based model can compensate for some of the shortcomings of conventional class-based models by combining the different solutions obtained through random clusterings. Experimental results show that the combined random class-based model improves considerably in perplexity (PPL) and word error rate (WER) over both the n-gram and baseline class-based models."
            },
            "slug": "Random-clusterings-for-language-modeling-Emami-Jelinek",
            "title": {
                "fragments": [],
                "text": "Random clusterings for language modeling"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Experimental results show that the combined random class-based model improves considerably in perplexity (PPL) and word error rate (WER) over both the n-gram and baseline class- based models."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. (ICASSP '05). IEEE International Conference on Acoustics, Speech, and Signal Processing, 2005."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762744"
                        ],
                        "name": "A. Stolcke",
                        "slug": "A.-Stolcke",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Stolcke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Stolcke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 86
                            }
                        ],
                        "text": "All back-off LMs were built using modified KneserNey smoothing and the SRI LM-toolkit (Stolcke, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1988103,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "399da68d3b97218b6c80262df7963baa89dcc71b",
            "isKey": false,
            "numCitedBy": 4998,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "SRILM is a collection of C++ libraries, executable programs, and helper scripts designed to allow both production of and experimentation with statistical language models for speech recognition and other applications. SRILM is freely available for noncommercial purposes. The toolkit supports creation and evaluation of a variety of language model types based on N-gram statistics, as well as several related tasks, such as statistical tagging and manipulation of N-best lists and word lattices. This paper summarizes the functionality of the toolkit and discusses its design and implementation, highlighting ease of rapid prototyping, reusability, and combinability of tools."
            },
            "slug": "SRILM-an-extensible-language-modeling-toolkit-Stolcke",
            "title": {
                "fragments": [],
                "text": "SRILM - an extensible language modeling toolkit"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The functionality of the SRILM toolkit is summarized and its design and implementation is discussed, highlighting ease of rapid prototyping, reusability, and combinability of tools."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3165395"
                        ],
                        "name": "Christian Gollan",
                        "slug": "Christian-Gollan",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Gollan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Gollan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2750400"
                        ],
                        "name": "M. Bisani",
                        "slug": "M.-Bisani",
                        "structuredName": {
                            "firstName": "Maximilian",
                            "lastName": "Bisani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bisani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110479"
                        ],
                        "name": "Stephan Kanthak",
                        "slug": "Stephan-Kanthak",
                        "structuredName": {
                            "firstName": "Stephan",
                            "lastName": "Kanthak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephan Kanthak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144490010"
                        ],
                        "name": "R. Schl\u00fcter",
                        "slug": "R.-Schl\u00fcter",
                        "structuredName": {
                            "firstName": "Ralf",
                            "lastName": "Schl\u00fcter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schl\u00fcter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 141
                            }
                        ],
                        "text": "The training material consists of the minutes edited by the European Parliament in several languages, also known as the Final Text Editions (Gollan et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2851476,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5ed0f2a01ccd10405910ca281574404ca207a72a",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the ongoing development of the British English European Parliament Plenary Session corpus. This corpus will be part of the speech-to-speech translation evaluation infrastructure of the European TC-STAR project. Furthermore, we present first recognition results on the English speech recordings. The transcription system has been derived from an older speech recognition system built for the North-American broadcast news task. We report on the measures taken for rapid cross-domain porting and present encouraging results."
            },
            "slug": "Cross-domain-automatic-transcription-on-the-TC-STAR-Gollan-Bisani",
            "title": {
                "fragments": [],
                "text": "Cross domain automatic transcription on the TC-STAR EPPS corpus"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "The ongoing development of the British English European Parliament Plenary Session corpus will be part of the speech-to-speech translation evaluation infrastructure of the European TC-STAR project and first recognition results on the English speech recordings are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. (ICASSP '05). IEEE International Conference on Acoustics, Speech, and Signal Processing, 2005."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710580"
                        ],
                        "name": "A. Berger",
                        "slug": "A.-Berger",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Berger",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Berger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2714577"
                        ],
                        "name": "S. D. Pietra",
                        "slug": "S.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Pietra",
                            "middleNames": [
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39944066"
                        ],
                        "name": "V. D. Pietra",
                        "slug": "V.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Pietra",
                            "middleNames": [
                                "J.",
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. D. Pietra"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 108
                            }
                        ],
                        "text": "Several algorithms have been proposed in the literature that try to find the best splits, see for instance (Berger et al., 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1085832,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fb486e03369a64de2d5b0df86ec0a7b55d3907db",
            "isKey": false,
            "numCitedBy": 3452,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "The concept of maximum entropy can be traced back along multiple threads to Biblical times. Only recently, however, have computers become powerful enough to permit the widescale application of this concept to real world problems in statistical estimation and pattern recognition. In this paper, we describe a method for statistical modeling based on maximum entropy. We present a maximum-likelihood approach for automatically constructing maximum entropy models and describe how to implement this approach efficiently, using as examples several problems in natural language processing."
            },
            "slug": "A-Maximum-Entropy-Approach-to-Natural-Language-Berger-Pietra",
            "title": {
                "fragments": [],
                "text": "A Maximum Entropy Approach to Natural Language Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A maximum-likelihood approach for automatically constructing maximum entropy models is presented and how to implement this approach efficiently is described, using as examples several problems in natural language processing."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644094255"
                        ],
                        "name": "F. BrownPeter",
                        "slug": "F.-BrownPeter",
                        "structuredName": {
                            "firstName": "F",
                            "lastName": "BrownPeter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. BrownPeter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644109094"
                        ],
                        "name": "PietraVincent J. Della",
                        "slug": "PietraVincent-J.-Della",
                        "structuredName": {
                            "firstName": "PietraVincent",
                            "lastName": "Della",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "PietraVincent J. Della"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644109090"
                        ],
                        "name": "PietraStephen A. Della",
                        "slug": "PietraStephen-A.-Della",
                        "structuredName": {
                            "firstName": "PietraStephen",
                            "lastName": "Della",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "PietraStephen A. Della"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1643955684"
                        ],
                        "name": "L. MercerRobert",
                        "slug": "L.-MercerRobert",
                        "structuredName": {
                            "firstName": "L",
                            "lastName": "MercerRobert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. MercerRobert"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 215920513,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5b74d6c7cd6b7c172ffce98f80b2f7b810d49abc",
            "isKey": false,
            "numCitedBy": 183,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a series of five statistical models of the translation process and give algorithms for estimating the parameters of these models given a set of pairs of sentences that are translations ..."
            },
            "slug": "The-mathematics-of-statistical-machine-translation-BrownPeter-Della",
            "title": {
                "fragments": [],
                "text": "The mathematics of statistical machine translation"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "A series of five statistical models of the translation process are described and algorithms for estimating the parameters of these models given a set of pairs of sentences that are translations are given."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66581256"
                        ],
                        "name": "Frank Vanden Berghen",
                        "slug": "Frank-Vanden-Berghen",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Berghen",
                            "middleNames": [
                                "Vanden"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frank Vanden Berghen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775694"
                        ],
                        "name": "H. Bersini",
                        "slug": "H.-Bersini",
                        "structuredName": {
                            "firstName": "Hugues",
                            "lastName": "Bersini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bersini"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1398084,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7d2f37aae718709d2c6e8f6ba48e19f7a5f7c14d",
            "isKey": false,
            "numCitedBy": 146,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "CONDOR,-a-new-parallel,-constrained-extension-of-Berghen-Bersini",
            "title": {
                "fragments": [],
                "text": "CONDOR, a new parallel, constrained extension of Powell's UOBYQA algorithm: experimental results and comparison with the DFO algorithm"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39535769"
                        ],
                        "name": "M. F.",
                        "slug": "M.-F.",
                        "structuredName": {
                            "firstName": "M",
                            "lastName": "F.",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. F."
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1455573056"
                        ],
                        "name": "Pemikiran Karl Marx",
                        "slug": "Pemikiran-Karl-Marx",
                        "structuredName": {
                            "firstName": "Pemikiran",
                            "lastName": "Marx",
                            "middleNames": [
                                "Karl"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pemikiran Karl Marx"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1455403858"
                        ],
                        "name": "Dari Sosialis",
                        "slug": "Dari-Sosialis",
                        "structuredName": {
                            "firstName": "Dari",
                            "lastName": "Sosialis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dari Sosialis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1455151864"
                        ],
                        "name": "Utopis ke Perselisihan",
                        "slug": "Utopis-ke-Perselisihan",
                        "structuredName": {
                            "firstName": "Utopis",
                            "lastName": "Perselisihan",
                            "middleNames": [
                                "ke"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Utopis ke Perselisihan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 208786267,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "f86c0a4caae451dc8ba319013e30f14987fa5b26",
            "isKey": false,
            "numCitedBy": 9902,
            "numCiting": 123,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Bibliography-M.-Marx",
            "title": {
                "fragments": [],
                "text": "Bibliography"
            },
            "venue": {
                "fragments": [],
                "text": "Experimental Gerontology"
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 9
                            }
                        ],
                        "text": "Separate LMs were first trained on the English EPPS texts (33.8M words) and the transcriptions of the acoustic training material (740k words) respectively."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 12
                            }
                        ],
                        "text": "Syntaxbased LMs were investigated in (Charniak et al.,\n723\n2003), and reranking of translation hypothesis using structural properties in (Hasan et al., 2006)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "Therefore, we suggest to use more complex statistical LMs that are expected to take better advantage of the limited amount of appropriate training data."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 13
                            }
                        ],
                        "text": "All back-off LMs were built using modified KneserNey smoothing and the SRI LM-toolkit (Stolcke, 2002)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 79
                            }
                        ],
                        "text": "For a value of 1.0 the backoff LM is used alone, while only the neural network LMs are used for a value of 0.0."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 80
                            }
                        ],
                        "text": "It has even turned out that it was advantageous to train several neural network LMs with different context sizes3 and to interpolate them altogether."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 43
                            }
                        ],
                        "text": "Promising candidates are random forest LMs (Xu and Jelinek, 2004), random cluster LMs (Emami and Jelinek, 2005) and the neural network LM (Bengio et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 360,
                                "start": 357
                            }
                        ],
                        "text": "For the sake of simplicity we will still call this interpolation the neural network LM.\nBack-off LM Neural LM 3-gram 4-gram 4-gram\nPerplexity 85.5 79.6 65.0 Dev data:\nBLEU 42.35 43.36 44.42 WER 45.9% 45.1% 44.4% PER 31.8% 31.3% 30.8% Eval data: BLEU 39.77 40.62 41.45 WER 48.2% 47.4% 46.7% PER 33.6% 33.1% 32.8%\nTable 3: Result comparison for the different LMs. BLEU uses 2 reference translations."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 33
                            }
                        ],
                        "text": "In this work, we use only 4-gram LMs, but the complexity of the neural network LM increases only slightly with the order of the LM."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 39
                            }
                        ],
                        "text": "Promising candidates are random forest LMs (Xu and Jelinek, 2004), random cluster LMs (Emami and Jelinek, 2005) and the neural network LM (Bengio et al., 2003)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 115
                            }
                        ],
                        "text": "We believe that this would not make a notable difference in our experiments since we do interpolate the individual LMs, the coefficients being optimized to minimize perplexity on the development data."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 10
                            }
                        ],
                        "text": "These two LMs were then interpolated together."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Random forest in language modeling"
            },
            "venue": {
                "fragments": [],
                "text": "In"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 80
                            }
                        ],
                        "text": "An interesting experiment was reported at the NIST 2005 MT evaluation workshop (Och, 2005): starting with a 5-gram LM trained on 75 million words of Broadcast News data, a gain of about 0.5 point BLEU was observed each time when the amount of LM training data was doubled, using at the end 237\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 79
                            }
                        ],
                        "text": "An interesting experiment was reported at the NIST 2005 MT evaluation workshop (Och, 2005): starting with a 5-gram LM trained on 75 million words of Broadcast News data, a gain of about 0."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Google statistical machine translation system for the 2005 Nist MT evaluation, Oral presentation at the 2005"
            },
            "venue": {
                "fragments": [],
                "text": "Nist MT Evaluation workshop,"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 221583858,
            "fieldsOfStudy": [],
            "id": "769dbbe88801b57a9b44f89c5516264f16cbed60",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An empirical study of smoothing techniques for language modeling"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110909951"
                        ],
                        "name": "Stanley F. Chen",
                        "slug": "Stanley-F.-Chen",
                        "structuredName": {
                            "firstName": "Stanley",
                            "lastName": "Chen",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stanley F. Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "17446277"
                        ],
                        "name": "J. Goodman",
                        "slug": "J.-Goodman",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Goodman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Goodman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 216805232,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "611e948f2cf0b6e519ac04ce689d48a43a78f9ce",
            "isKey": false,
            "numCitedBy": 263,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an extensive empirical comparison of several smoothing techniques in the domain of language modeling, including those described by Jelinek and Mercer (1980), Katz (1987), and Church and Gale (1991). We investigate for the first time how factors such as training data size, corpus (e.g., Brown versus Wall Street Journal), and n-gram order (bigram versus trigram) affect the relative performance of these methods, which we measure through the cross-entropy of test data. In addition, we introduce two novel smoothing techniques, one a variation of Jelinek-Mercer smoothing and one a very simple linear interpolation technique, both of which outperform existing methods."
            },
            "slug": "An-Empirical-Study-of-Smoothing-Techniques-for-Chen-Goodman",
            "title": {
                "fragments": [],
                "text": "An Empirical Study of Smoothing Techniques for Language Modeling"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "An extensive empirical comparison of several smoothing techniques in the domain of language modeling is presented, including those described by Jelinek and Mercer (1980), Katz (1987), and Church and Gale (1991)."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 119
                            }
                        ],
                        "text": "Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 723\u2013730, Sydney, July 2006.c\u00a92006 Association for Computational Linguistics\nStatistical machine translation systems are based on one or more translation models and a language model of the target language."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Philipp. Moses: Open source toolkit for statistical machine translation"
            },
            "venue": {
                "fragments": [],
                "text": "ACL, demonstration session"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Reranking translation hypothesis using structural properties . In LREC . Katrin Kirchhoff and Mei Yang . 2005 . Improved language modeling for statistical machine translation"
            },
            "venue": {
                "fragments": [],
                "text": "ACL \u2019 05 workshop on Building and Using Parallel Text"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Costa-juss\u00e0. Bilingual n-gram statistical machine translation"
            },
            "venue": {
                "fragments": [],
                "text": "Computational Linguistics"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We also present algorithms to improve the estimation of the language model probabilities when splitting long sentences into shorter chunks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Syntax-based language models for machine translation"
            },
            "venue": {
                "fragments": [],
                "text": "In Machine Translation Summit"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We also present algorithms to improve the estimation of the language model probabilities when splitting long sentences into shorter chunks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Google statistical machine translation system for the 2005 Nist MT evaluation, Oral presentation at the 2005 Nist MT Evaluation workshop"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 108
                            }
                        ],
                        "text": "Several algorithms have been proposed in the literature that try to find the best splits, see for instance (Berger et al., 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A maximum entropy approach to natural language processing.Computational Linguistics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 12,
            "methodology": 12,
            "result": 3
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 36,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Continuous-Space-Language-Models-for-Statistical-Schwenk/d4a258df43cc14e46988de9a4a7b2f0ea817529b?sort=total-citations"
}