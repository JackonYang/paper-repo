{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770859"
                        ],
                        "name": "R. Gallager",
                        "slug": "R.-Gallager",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gallager",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gallager"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 137
                            }
                        ],
                        "text": "4 Belief network decoding We have developed a `belief net decoder' for the problem Ax = zmod2, which generalizes the methods of Gallager [4] and Meier and Sta elbach [9] by using methods of belief propagation over networks [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 48
                            }
                        ],
                        "text": "2 Relationship to Gallager's algorithm Gallager [4] and Meier and Sta elbach [9] implemented algorithms very similar to this belief net decoder, also studied by Mihaljevi c and Goli c [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 56
                            }
                        ],
                        "text": "The decoding problem is of the type studied by Gallager [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12709402,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "206f827fad201506c315d40c1469b41a45141893",
            "isKey": false,
            "numCitedBy": 10569,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "A low-density parity-check code is a code specified by a parity-check matrix with the following properties: each column contains a small fixed number j \\geq 3 of l's and each row contains a small fixed number k > j of l's. The typical minimum distance of these codes increases linearly with block length for a fixed rate and fixed j . When used with maximum likelihood decoding on a sufficiently quiet binary-input symmetric channel, the typical probability of decoding error decreases exponentially with block length for a fixed rate and fixed j . A simple but nonoptimum decoding scheme operating directly from the channel a posteriori probabilities is described. Both the equipment complexity and the data-handling capacity in bits per second of this decoder increase approximately linearly with block length. For j > 3 and a sufficiently low rate, the probability of error using this decoder on a binary symmetric channel is shown to decrease at least exponentially with a root of the block length. Some experimental results show that the actual probability of decoding error is much smaller than this theoretical bound."
            },
            "slug": "Low-density-parity-check-codes-Gallager",
            "title": {
                "fragments": [],
                "text": "Low-density parity-check codes"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A simple but nonoptimum decoding scheme operating directly from the channel a posteriori probabilities is described and the probability of error using this decoder on a binary symmetric channel is shown to decrease at least exponentially with a root of the block length."
            },
            "venue": {
                "fragments": [],
                "text": "IRE Trans. Inf. Theory"
            },
            "year": 1962
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2516166"
                        ],
                        "name": "J. Rissanen",
                        "slug": "J.-Rissanen",
                        "structuredName": {
                            "firstName": "Jorma",
                            "lastName": "Rissanen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Rissanen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3337260"
                        ],
                        "name": "G. Langdon",
                        "slug": "G.-Langdon",
                        "structuredName": {
                            "firstName": "Glen",
                            "lastName": "Langdon",
                            "middleNames": [
                                "G."
                            ],
                            "suffix": "Jr."
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Langdon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 108
                            }
                        ],
                        "text": "Redundant sources of this type can be produced from other sources by using a variation on arithmetic coding [16, 13]; one simply reverses the role of encoder and decoder in a standard arithmetic coder based on a model corresponding to the sparse messages [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 39909636,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "20d673dc3200ac1742ee0827535a291eb6e051f8",
            "isKey": false,
            "numCitedBy": 759,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "The earlier introduced arithmetic coding idea has been generalized to a very broad and flexible coding technique which includes virtually all known variable rate noiseless coding techniques as special cases. An outstanding feature of this technique is that alphabet extensions are not required. A complete decodability analysis is given. The relationship of arithmetic coding to other known nonblock codes is illuminated."
            },
            "slug": "Arithmetic-Coding-Rissanen-Langdon",
            "title": {
                "fragments": [],
                "text": "Arithmetic Coding"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The earlier introduced arithmetic coding idea has been generalized to a very broad and flexible coding technique which includes virtually all known variable rate noiseless coding techniques as special cases."
            },
            "venue": {
                "fragments": [],
                "text": "IBM J. Res. Dev."
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144572614"
                        ],
                        "name": "D. Mackay",
                        "slug": "D.-Mackay",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Mackay",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mackay"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122017062,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "be01b49cec664c21e6789cc77d9c836e62cc3b99",
            "isKey": false,
            "numCitedBy": 76,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm is derived for inferring a binary vector s given noisy observations of As modulo 2, where A is a binary matrix. The binary vector is replaced by a vector of probabilities, optimised by free energy minimisation. Experiments on the inference of the state of a linear feedback shift register indicate that this algorithm supersedes the Meier and Staffelbach polynomial algorithm."
            },
            "slug": "Free-energy-minimisation-algorithm-for-decoding-and-Mackay",
            "title": {
                "fragments": [],
                "text": "Free energy minimisation algorithm for decoding and cryptanalysis"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "An algorithm is derived for inferring a binary vector given noisy observations of As modulo 2, where A is a binary matrix and the binary vector is replaced by a vector of probabilities optimised by free energy minimisation."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2298244"
                        ],
                        "name": "M. Tsfasman",
                        "slug": "M.-Tsfasman",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Tsfasman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Tsfasman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 53
                            }
                        ],
                        "text": "Goppa's recent algebraic geometry codes (reviewed in [15]) appear to be both practical and good, but we believe that the literature has not established whether they are very good."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 44595767,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "e187f9e411dbc17bf96cf29cf99e791a572a047d",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Algebraic-geometric-codes-and-asymptotic-problems-Tsfasman",
            "title": {
                "fragments": [],
                "text": "Algebraic-geometric codes and asymptotic problems"
            },
            "venue": {
                "fragments": [],
                "text": "Discret. Appl. Math."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2095201599"
                        ],
                        "name": "O. Antoine",
                        "slug": "O.-Antoine",
                        "structuredName": {
                            "firstName": "O",
                            "lastName": "Antoine",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Antoine"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076266876"
                        ],
                        "name": "Berthet",
                        "slug": "Berthet",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Berthet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Berthet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 237,
                                "start": 234
                            }
                        ],
                        "text": "The Gilbert bound GV (fn) is GV (fn) = 1 H2(2fn) fn < 1=4 0 fn 1=4: (2) This is the rate at which one can communicate with a code whose codewords satisfy the Gilbert-Varshamov minimumdistance bound, assuming bounded distance decoding [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13454875,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9cbc6bc1bec461f1bb7ddc4b68509ae9a4c6ef6b",
            "isKey": false,
            "numCitedBy": 4584,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "The field of channel coding started with Claude Shannon's 1948 landmark paper. Fifty years of efforts and invention have finally produced coding schemes that closely approach Shannon's channel capacity limit on AWGN channels, both power-limited and band-limited. Similar gains are being achieved in other important applications, such as wireless channels. This course is divided in two parts. In the first part, we remind students of the basics of the theory of linear codes for conventional memoryless ergodic channels. We then introduce more advanced notions so as to make comprehensible some of the most recent coding schemes proposed in the literature. In the second part, we expound the principles of coded modulations for the Gaussian channel and, if time permits, for Rician and Rayleigh fading channels (fully interleaved). We will conclude the course by evoking some aspects of code design for non-ergodic block-fading channels. Basic definitions \u2013 Classification of channels, random codes Coding theorem for DMC \u2013 Upper bounds on error probability Coding theorem for DMC \u2013 Lower bounds on error probability Strong converse theorem for discrete channels [Wolfowitz] Generalization of results to BIOS memoryless channels Hard or soft decoding, information loss Cutoff rate Lecture 2. Codes with algebraic structures [4][5] Detection and correction capabilities of block codes Lower and upper bounds on code parameters \u2013 General case Linear block codes \u2013 Minimum distance, duality, elementary transformations Lower and upper bounds on code parameters \u2013 GV, Hamming, Plotkin, Singleton Convolutional codes"
            },
            "slug": "Theory-of-Error-correcting-Codes-Antoine-Berthet",
            "title": {
                "fragments": [],
                "text": "Theory of Error-correcting Codes"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This course expounds the principles of coded modulations for the Gaussian channel and, if time permits, for Rician and Rayleigh fading channels (fully interleaved), and reminds students of the basics of the theory of linear codes for conventional memoryless ergodic channels."
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9419406"
                        ],
                        "name": "I. Witten",
                        "slug": "I.-Witten",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Witten",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Witten"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764325"
                        ],
                        "name": "Radford M. Neal",
                        "slug": "Radford-M.-Neal",
                        "structuredName": {
                            "firstName": "Radford",
                            "lastName": "Neal",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Radford M. Neal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752317"
                        ],
                        "name": "J. Cleary",
                        "slug": "J.-Cleary",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Cleary",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cleary"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Redundant sources of this type can be produced from other sources by using a variation on arithmetic coding [ 16 , 13]; one simply reverses the role of encoder and decoder in a standard arithmetic coder based on a model corresponding to the sparse messages [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3343393,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fd23c9168418324e81881365f297fb6a1caa3a07",
            "isKey": false,
            "numCitedBy": 3142,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "The state of the art in data compression is arithmetic coding, not the better-known Huffman method. Arithmetic coding gives greater compression, is faster for adaptive models, and clearly separates the model from the channel encoding."
            },
            "slug": "Arithmetic-coding-for-data-compression-Witten-Neal",
            "title": {
                "fragments": [],
                "text": "Arithmetic coding for data compression"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "The state of the art in data compression is arithmetic coding, not the better-known Huffman method, which gives greater compression, is faster for adaptive models, and clearly separates the model from the channel encoding."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3299667"
                        ],
                        "name": "M. Mihaljevic",
                        "slug": "M.-Mihaljevic",
                        "structuredName": {
                            "firstName": "Miodrag",
                            "lastName": "Mihaljevic",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mihaljevic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2997388"
                        ],
                        "name": "J. Golic",
                        "slug": "J.-Golic",
                        "structuredName": {
                            "firstName": "Jovan",
                            "lastName": "Golic",
                            "middleNames": [
                                "Dj."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Golic"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 32693123,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ba40b64112280dadf0c2dac92711a7b5dcde71ea",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Convergence of an algorithm for a linear feedback shift register initial state reconstruction using the noisy output sequence, based on a bitwise Bayesian iterative error-correction procedure and different weight parity-checks, is analyzed. It is proved that the self-composition of the Bayes error probability converges to zero if and only if the noise probability is less than a critical value expressed in terms of the numbers of parity-checks. An alternative approach to the critical noise estimation based on the residual error-rate after each iterative revision is also discussed."
            },
            "slug": "Convergence-of-a-Bayesian-Iterative-Procedure-on-a-Mihaljevic-Golic",
            "title": {
                "fragments": [],
                "text": "Convergence of a Bayesian Iterative Error-Correction Procedure on a Noisy Shift register Sequence"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is proved that the self-composition of the Bayes error probability converges to zero if and only if the noise probability is less than a critical value expressed in terms of the numbers of parity-checks."
            },
            "venue": {
                "fragments": [],
                "text": "EUROCRYPT"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2663587"
                        ],
                        "name": "E. Berlekamp",
                        "slug": "E.-Berlekamp",
                        "structuredName": {
                            "firstName": "Elwyn",
                            "lastName": "Berlekamp",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Berlekamp"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 118
                            }
                        ],
                        "text": "In principle, it may be possible in somecases to make a BCH decoder that corrects more than t errors, but according toBerlekamp [2], \\little is known about: : :how to go about nding the solutions\"and \\if there are more than t+1 errors then the situation gets very complicatedvery quickly.\""
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 130
                            }
                        ],
                        "text": "In principle, it may be possible in some cases to make a BCH decoder that corrects more than t errors, but according to Berlekamp [2], \\little is known about: : :how to go about nding the solutions\" and \\if there are more than t+1 errors then the situation gets very complicated very quickly."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 6
                            }
                        ],
                        "text": "E. R. Berlekamp."
                    },
                    "intents": []
                }
            ],
            "corpusId": 33309098,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bc7e0aa5bcbdacef451d001fed342da78465fbb7",
            "isKey": true,
            "numCitedBy": 2759,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This is the revised edition of Berlekamp's famous book, \"Algebraic Coding Theory,\" originally published in 1968, wherein he introduced several algorithms which have subsequently dominated engineering practice in this field. One of these is an algorithm for decoding Reed-Solomon and Bose\u2013Chaudhuri\u2013Hocquenghem codes that subsequently became known as the Berlekamp\u2013Massey Algorithm. Another is the Berlekamp algorithm for factoring polynomials over finite fields, whose later extensions and embellishments became widely used in symbolic manipulation systems. Other novel algorithms improved the basic methods for doing various arithmetic operations in finite fields of characteristic two. Other major research contributions in this book included a new class of Lee metric codes, and precise asymptotic results on the number of information symbols in long binary BCH codes.Selected chapters of the book became a standard graduate textbook.Both practicing engineers and scholars will find this book to be of great value."
            },
            "slug": "Algebraic-coding-theory-Berlekamp",
            "title": {
                "fragments": [],
                "text": "Algebraic coding theory"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This is the revised edition of Berlekamp's famous book, \"Algebraic Coding Theory,\" originally published in 1968, wherein he introduced several algorithms which have subsequently dominated engineering practice in this field."
            },
            "venue": {
                "fragments": [],
                "text": "McGraw-Hill series in systems science"
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145529421"
                        ],
                        "name": "G. Longo",
                        "slug": "G.-Longo",
                        "structuredName": {
                            "firstName": "Giuseppe",
                            "lastName": "Longo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Longo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 166
                            }
                        ],
                        "text": "Since 1948, few constructive and practical codes that are good have been found, fewer still that are practical, and none at all that are both practical and very good [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 29994778,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "707fe79747707a04a783d0a9d7018ef5f03652b4",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "14. M. Metivier, The stochastic integral with respect to processes with values in a reflexive Banach space, Theor. Probability 19 (1974), 758-787. 15. M. Metivier and G. Pistone, Une formule d'isom\u00e9trie pour r int\u00e9grale stochastique Hilbertienne et \u00e9quations d'\u00e9volution lin\u00e9aires stochastiques, Z. Wahrscheinlicnkeitstheorie und Verw. Gebiete 33 (1975), 1-18. 16. P. A. Meyer, A decomposition theorem for supermartingales, Illinois J. Math. 6 (1962), 193-205. 17. , Int\u00e9grales stochastiques. IV, Lecture Notes in Math., vol. 39, Springer-Verlag, Berlin and New York, 1967, pp. 142-162. 18. , Un cours sur les int\u00e9grales stochastiques, Lecture Notes in Math., vol. 511, Springer-Verlag, Berlin and New York, 1976, pp. 245-400. 19. , Int\u00e9grales Hilbertiennes, Lecture Notes in Math., vol. 581, Springer-Verlag, Berlin and New York, 1977, pp. 446-461. 20. R. E. A. C. Paley, N. Wiener and A. Zygmund, Notes on random functions, Math. Z. 37 (1933), 647-668. 21. J. Pellaumail, Sur lint\u00e9grale stochastique et la d\u00e9composition de Doob-Meyer, Asterique 9 (1973), 1-125. 22. P. E. Protter, Markov solutions of stochastic differential equations, TL Wahrscheinlichkeitstheorie und Verw. Gebiete 41 (1977), 39-58. 23. , A comparison of stochastic integrals, Ann. Probability (to appear). 24. R. L. Stratonovich, A new representation for stochastic integrals and equations, SIAM. J. Control 4 (1966), 362-371. 25. N. Wiener, Differential-space, J. Math, and Physics 2 (1923), 131-174."
            },
            "slug": "The-theory-of-information-and-coding:-A-framework-Longo",
            "title": {
                "fragments": [],
                "text": "The theory of information and coding: A mathematical framework for communication"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "The stochastic integral with respect to processes with values in a reflexive Banach space, Theor."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE"
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752732"
                        ],
                        "name": "T. Cover",
                        "slug": "T.-Cover",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Cover",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Cover"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115282352"
                        ],
                        "name": "Joy A. Thomas",
                        "slug": "Joy-A.-Thomas",
                        "structuredName": {
                            "firstName": "Joy",
                            "lastName": "Thomas",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joy A. Thomas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 137
                            }
                        ],
                        "text": "5 Theoretical properties proven for MN codes In [6] we prove properties of these codes by studying properties of a `typical set decoder' [3] for the decoding problem Ax = z, averaging over an ensemble of random matrices A."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 190432,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7dbdb4209626fd92d2436a058663206216036e68",
            "isKey": false,
            "numCitedBy": 42795,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface to the Second Edition. Preface to the First Edition. Acknowledgments for the Second Edition. Acknowledgments for the First Edition. 1. Introduction and Preview. 1.1 Preview of the Book. 2. Entropy, Relative Entropy, and Mutual Information. 2.1 Entropy. 2.2 Joint Entropy and Conditional Entropy. 2.3 Relative Entropy and Mutual Information. 2.4 Relationship Between Entropy and Mutual Information. 2.5 Chain Rules for Entropy, Relative Entropy, and Mutual Information. 2.6 Jensen's Inequality and Its Consequences. 2.7 Log Sum Inequality and Its Applications. 2.8 Data-Processing Inequality. 2.9 Sufficient Statistics. 2.10 Fano's Inequality. Summary. Problems. Historical Notes. 3. Asymptotic Equipartition Property. 3.1 Asymptotic Equipartition Property Theorem. 3.2 Consequences of the AEP: Data Compression. 3.3 High-Probability Sets and the Typical Set. Summary. Problems. Historical Notes. 4. Entropy Rates of a Stochastic Process. 4.1 Markov Chains. 4.2 Entropy Rate. 4.3 Example: Entropy Rate of a Random Walk on a Weighted Graph. 4.4 Second Law of Thermodynamics. 4.5 Functions of Markov Chains. Summary. Problems. Historical Notes. 5. Data Compression. 5.1 Examples of Codes. 5.2 Kraft Inequality. 5.3 Optimal Codes. 5.4 Bounds on the Optimal Code Length. 5.5 Kraft Inequality for Uniquely Decodable Codes. 5.6 Huffman Codes. 5.7 Some Comments on Huffman Codes. 5.8 Optimality of Huffman Codes. 5.9 Shannon-Fano-Elias Coding. 5.10 Competitive Optimality of the Shannon Code. 5.11 Generation of Discrete Distributions from Fair Coins. Summary. Problems. Historical Notes. 6. Gambling and Data Compression. 6.1 The Horse Race. 6.2 Gambling and Side Information. 6.3 Dependent Horse Races and Entropy Rate. 6.4 The Entropy of English. 6.5 Data Compression and Gambling. 6.6 Gambling Estimate of the Entropy of English. Summary. Problems. Historical Notes. 7. Channel Capacity. 7.1 Examples of Channel Capacity. 7.2 Symmetric Channels. 7.3 Properties of Channel Capacity. 7.4 Preview of the Channel Coding Theorem. 7.5 Definitions. 7.6 Jointly Typical Sequences. 7.7 Channel Coding Theorem. 7.8 Zero-Error Codes. 7.9 Fano's Inequality and the Converse to the Coding Theorem. 7.10 Equality in the Converse to the Channel Coding Theorem. 7.11 Hamming Codes. 7.12 Feedback Capacity. 7.13 Source-Channel Separation Theorem. Summary. Problems. Historical Notes. 8. Differential Entropy. 8.1 Definitions. 8.2 AEP for Continuous Random Variables. 8.3 Relation of Differential Entropy to Discrete Entropy. 8.4 Joint and Conditional Differential Entropy. 8.5 Relative Entropy and Mutual Information. 8.6 Properties of Differential Entropy, Relative Entropy, and Mutual Information. Summary. Problems. Historical Notes. 9. Gaussian Channel. 9.1 Gaussian Channel: Definitions. 9.2 Converse to the Coding Theorem for Gaussian Channels. 9.3 Bandlimited Channels. 9.4 Parallel Gaussian Channels. 9.5 Channels with Colored Gaussian Noise. 9.6 Gaussian Channels with Feedback. Summary. Problems. Historical Notes. 10. Rate Distortion Theory. 10.1 Quantization. 10.2 Definitions. 10.3 Calculation of the Rate Distortion Function. 10.4 Converse to the Rate Distortion Theorem. 10.5 Achievability of the Rate Distortion Function. 10.6 Strongly Typical Sequences and Rate Distortion. 10.7 Characterization of the Rate Distortion Function. 10.8 Computation of Channel Capacity and the Rate Distortion Function. Summary. Problems. Historical Notes. 11. Information Theory and Statistics. 11.1 Method of Types. 11.2 Law of Large Numbers. 11.3 Universal Source Coding. 11.4 Large Deviation Theory. 11.5 Examples of Sanov's Theorem. 11.6 Conditional Limit Theorem. 11.7 Hypothesis Testing. 11.8 Chernoff-Stein Lemma. 11.9 Chernoff Information. 11.10 Fisher Information and the Cram-er-Rao Inequality. Summary. Problems. Historical Notes. 12. Maximum Entropy. 12.1 Maximum Entropy Distributions. 12.2 Examples. 12.3 Anomalous Maximum Entropy Problem. 12.4 Spectrum Estimation. 12.5 Entropy Rates of a Gaussian Process. 12.6 Burg's Maximum Entropy Theorem. Summary. Problems. Historical Notes. 13. Universal Source Coding. 13.1 Universal Codes and Channel Capacity. 13.2 Universal Coding for Binary Sequences. 13.3 Arithmetic Coding. 13.4 Lempel-Ziv Coding. 13.5 Optimality of Lempel-Ziv Algorithms. Compression. Summary. Problems. Historical Notes. 14. Kolmogorov Complexity. 14.1 Models of Computation. 14.2 Kolmogorov Complexity: Definitions and Examples. 14.3 Kolmogorov Complexity and Entropy. 14.4 Kolmogorov Complexity of Integers. 14.5 Algorithmically Random and Incompressible Sequences. 14.6 Universal Probability. 14.7 Kolmogorov complexity. 14.9 Universal Gambling. 14.10 Occam's Razor. 14.11 Kolmogorov Complexity and Universal Probability. 14.12 Kolmogorov Sufficient Statistic. 14.13 Minimum Description Length Principle. Summary. Problems. Historical Notes. 15. Network Information Theory. 15.1 Gaussian Multiple-User Channels. 15.2 Jointly Typical Sequences. 15.3 Multiple-Access Channel. 15.4 Encoding of Correlated Sources. 15.5 Duality Between Slepian-Wolf Encoding and Multiple-Access Channels. 15.6 Broadcast Channel. 15.7 Relay Channel. 15.8 Source Coding with Side Information. 15.9 Rate Distortion with Side Information. 15.10 General Multiterminal Networks. Summary. Problems. Historical Notes. 16. Information Theory and Portfolio Theory. 16.1 The Stock Market: Some Definitions. 16.2 Kuhn-Tucker Characterization of the Log-Optimal Portfolio. 16.3 Asymptotic Optimality of the Log-Optimal Portfolio. 16.4 Side Information and the Growth Rate. 16.5 Investment in Stationary Markets. 16.6 Competitive Optimality of the Log-Optimal Portfolio. 16.7 Universal Portfolios. 16.8 Shannon-McMillan-Breiman Theorem (General AEP). Summary. Problems. Historical Notes. 17. Inequalities in Information Theory. 17.1 Basic Inequalities of Information Theory. 17.2 Differential Entropy. 17.3 Bounds on Entropy and Relative Entropy. 17.4 Inequalities for Types. 17.5 Combinatorial Bounds on Entropy. 17.6 Entropy Rates of Subsets. 17.7 Entropy and Fisher Information. 17.8 Entropy Power Inequality and Brunn-Minkowski Inequality. 17.9 Inequalities for Determinants. 17.10 Inequalities for Ratios of Determinants. Summary. Problems. Historical Notes. Bibliography. List of Symbols. Index."
            },
            "slug": "Elements-of-Information-Theory-Cover-Thomas",
            "title": {
                "fragments": [],
                "text": "Elements of Information Theory"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The author examines the role of entropy, inequality, and randomness in the design of codes and the construction of codes in the rapidly changing environment."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2091810890"
                        ],
                        "name": "Shirley Dex",
                        "slug": "Shirley-Dex",
                        "structuredName": {
                            "firstName": "Shirley",
                            "lastName": "Dex",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shirley Dex"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 33
                            }
                        ],
                        "text": "All relevant BCH codes listed in [12] are included."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 73
                            }
                        ],
                        "text": "In gure 5 we compare two MN codes with BCH codes, which are described in [12] as \\the best known constructive codes\" for memoryless noisy channels, and with Reed-Muller (RM) codes (block sizes up to 1024)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62267652,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5240a29f967fb85a84fb5609e453a58970ca73f5",
            "isKey": false,
            "numCitedBy": 17515,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "1. If 49 is divisible by 7, then 7 is a factor of 49. 2. An odd number multiplied by an odd number is odd. 3. An even number divided by an even number is even. 4. The number 123,456 is divisible by 8. 5. If a divides 4 and a divides 6, then a divides 24. 6. If a divides d, then divides d. 2 a 7. The sum of three consecutive numbers is divisible by 3. 8. The product of any three consecutive integers is divisible by 6. 9. The product of any four consecutive numbers is divisible by 24. 10. If a number is divisible by 3, then every digit of that number is divisible by 3."
            },
            "slug": "JR-\u65c5\u5ba2\u8ca9\u58f2\u7dcf\u5408\u30b7\u30b9\u30c6\u30e0\uff08\u30de\u30eb\u30b9\uff09\u306b\u304a\u3051\u308b\u904b\u7528\u53ca\u3073\u7ba1\u7406\u306b\u3064\u3044\u3066-Dex",
            "title": {
                "fragments": [],
                "text": "JR \u65c5\u5ba2\u8ca9\u58f2\u7dcf\u5408\u30b7\u30b9\u30c6\u30e0\uff08\u30de\u30eb\u30b9\uff09\u306b\u304a\u3051\u308b\u904b\u7528\u53ca\u3073\u7ba1\u7406\u306b\u3064\u3044\u3066"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A dictionary definition of divisible number: a number is divisible by a number so that every digit of that number isdivisible by 3."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 223
                            }
                        ],
                        "text": "4 Belief network decoding We have developed a `belief net decoder' for the problem Ax = zmod2, which generalizes the methods of Gallager [4] and Meier and Sta elbach [9] by using methods of belief propagation over networks [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 94
                            }
                        ],
                        "text": "Algorithms for the computation of such marginal probabilities in belief networks are found in [11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 32583695,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "70ef29e6f0ce082bb8a47fd85b9bfb7cc0f20c93",
            "isKey": false,
            "numCitedBy": 18219,
            "numCiting": 230,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nProbabilistic Reasoning in Intelligent Systems is a complete andaccessible account of the theoretical foundations and computational methods that underlie plausible reasoning under uncertainty. The author provides a coherent explication of probability as a language for reasoning with partial belief and offers a unifying perspective on other AI approaches to uncertainty, such as the Dempster-Shafer formalism, truth maintenance systems, and nonmonotonic logic. The author distinguishes syntactic and semantic approaches to uncertainty\u0097and offers techniques, based on belief networks, that provide a mechanism for making semantics-based systems operational. Specifically, network-propagation techniques serve as a mechanism for combining the theoretical coherence of probability theory with modern demands of reasoning-systems technology: modular declarative inputs, conceptually meaningful inferences, and parallel distributed computation. Application areas include diagnosis, forecasting, image interpretation, multi-sensor fusion, decision support systems, plan recognition, planning, speech recognition\u0097in short, almost every task requiring that conclusions be drawn from uncertain clues and incomplete information. \nProbabilistic Reasoning in Intelligent Systems will be of special interest to scholars and researchers in AI, decision theory, statistics, logic, philosophy, cognitive psychology, and the management sciences. Professionals in the areas of knowledge-based systems, operations research, engineering, and statistics will find theoretical and computational tools of immediate practical use. The book can also be used as an excellent text for graduate-level courses in AI, operations research, or applied probability."
            },
            "slug": "Probabilistic-reasoning-in-intelligent-systems-of-Pearl",
            "title": {
                "fragments": [],
                "text": "Probabilistic reasoning in intelligent systems - networks of plausible inference"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The author provides a coherent explication of probability as a language for reasoning with partial belief and offers a unifying perspective on other AI approaches to uncertainty, such as the Dempster-Shafer formalism, truth maintenance systems, and nonmonotonic logic."
            },
            "venue": {
                "fragments": [],
                "text": "Morgan Kaufmann series in representation and reasoning"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1972776"
                        ],
                        "name": "S. Andreassen",
                        "slug": "S.-Andreassen",
                        "structuredName": {
                            "firstName": "Steen",
                            "lastName": "Andreassen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Andreassen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2209769"
                        ],
                        "name": "M. Woldbye",
                        "slug": "M.-Woldbye",
                        "structuredName": {
                            "firstName": "Marianne",
                            "lastName": "Woldbye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Woldbye"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47643639"
                        ],
                        "name": "B. Falck",
                        "slug": "B.-Falck",
                        "structuredName": {
                            "firstName": "Bj\u00f6rn",
                            "lastName": "Falck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Falck"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46558286"
                        ],
                        "name": "S. K. Andersen",
                        "slug": "S.-K.-Andersen",
                        "structuredName": {
                            "firstName": "Stig",
                            "lastName": "Andersen",
                            "middleNames": [
                                "Kj\u00e6r"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. K. Andersen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6844163,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1b0ea2bf938f8a255aae6dc31afeea8925593def",
            "isKey": false,
            "numCitedBy": 259,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Experience gained through building a causal network for interpretation of electromyographic findings has shown that probabilistic inference is a realistic possibility in networks of non-trivial size. The use of nodes with many internal states has made it possible to make a conceptually simple and compact representation of knowledge. \"Deep knowledge\" in the form of pathophysiological models are used to reduce the problem of estimating thousands of conditional probabilities to a manageble size. The network has built-in mechanisms that will detect when the network is confronted with a situation outside the limits of its own knowledge and it handles conflicting evidence in a simple and consistent way."
            },
            "slug": "MUNIN-A-Causal-Probabilistic-Network-for-of-Andreassen-Woldbye",
            "title": {
                "fragments": [],
                "text": "MUNIN - A Causal Probabilistic Network for Interpretation of Electromyographic Findings"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Experience gained through building a causal network for interpretation of electromyographic findings has shown that probabilistic inference is a realistic possibility in networks of non-trivial size."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 258,
                                "start": 255
                            }
                        ],
                        "text": "Redundant sources of this type can be produced from other sources by using a variation on arithmetic coding [16, 13]; one simply reverses the role of encoder and decoder in a standard arithmetic coder based on a model corresponding to the sparse messages [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 48
                            }
                        ],
                        "text": "5 Theoretical properties proven for MN codes In [6] we prove properties of these codes by studying properties of a `typical set decoder' [3] for the decoding problem Ax = z, averaging over an ensemble of random matrices A."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 94
                            }
                        ],
                        "text": "This is expected to improve the properties of the ensemble of codes, for reasons explained in [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 51
                            }
                        ],
                        "text": "The full text of this paper may be found elsewhere [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 215,
                                "start": 212
                            }
                        ],
                        "text": "At the same time it can be proved that these codes are very good, in that sequences of codes exist which, when optimally decoded, achieve information rates up to the Shannon limit of the binary symmetric channel [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Good codes based on very sparse matrices"
            },
            "venue": {
                "fragments": [],
                "text": " Available from http://131.111.48.24/,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[5]), in which products of the di erences qnk q0 nk q1 nk are computed."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 121
                            }
                        ],
                        "text": "In sections 3 and 4 we describe empirical results of computer experiments using rst a free energy minimization algorithm [5] and second a `belief propagation' algorithm for decoding."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 102
                            }
                        ],
                        "text": "We rst attempted to solve the decoding problem using a variational free energy minimization algorithm [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Free energy minimization algorithm for decoding and cryptanal ysis"
            },
            "venue": {
                "fragments": [],
                "text": "Electronics Letters, 31(6):446{447,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "This article was processed using the L a T E X macro package with LLNCS style"
            },
            "venue": {
                "fragments": [],
                "text": "This article was processed using the L a T E X macro package with LLNCS style"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "MUNIN - a causal prob abilistic network for the interpretation of electromyographic ndings"
            },
            "venue": {
                "fragments": [],
                "text": "In Proc. of  the 10th National Conf. on AI, AAAI: Menlo Park CA., pages 121{123,"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 166
                            }
                        ],
                        "text": "4 Belief network decoding We have developed a `belief net decoder' for the problem Ax = zmod2, which generalizes the methods of Gallager [4] and Meier and Sta elbach [9] by using methods of belief propagation over networks [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 77
                            }
                        ],
                        "text": "2 Relationship to Gallager's algorithm Gallager [4] and Meier and Sta elbach [9] implemented algorithms very similar to this belief net decoder, also studied by Mihaljevi c and Goli c [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "elbach"
            },
            "venue": {
                "fragments": [],
                "text": "Fast correlation attacks on certain stream ciphers.  J. Cryptology, 1:159{176,"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 184
                            }
                        ],
                        "text": "2 Relationship to Gallager's algorithm Gallager [4] and Meier and Sta elbach [9] implemented algorithms very similar to this belief net decoder, also studied by Mihaljevi c and Goli c [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "c and J"
            },
            "venue": {
                "fragments": [],
                "text": "D. Goli  c. Convergence of a Bayesian iterative error correction procedure on a noisy shift register sequence. In Advances in Cryptology  - EUROCRYPT 92, volume 658, pages 124{137. Springer-Verlag,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Good codes based on very sparse matrices. Available from http"
            },
            "venue": {
                "fragments": [],
                "text": "Good codes based on very sparse matrices. Available from http"
            },
            "year": 1995
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 9,
            "methodology": 7
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 20,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Good-Codes-Based-on-Very-Sparse-Matrices-Mackay/f9ae39a71308a0bfe12fd5c1ba13165547be3cbd?sort=total-citations"
}