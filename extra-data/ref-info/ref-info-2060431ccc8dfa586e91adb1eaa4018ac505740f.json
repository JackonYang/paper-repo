{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1824057"
                        ],
                        "name": "Florent Monay",
                        "slug": "Florent-Monay",
                        "structuredName": {
                            "firstName": "Florent",
                            "lastName": "Monay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Florent Monay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3351018"
                        ],
                        "name": "Pedro Quelhas",
                        "slug": "Pedro-Quelhas",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Quelhas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pedro Quelhas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719610"
                        ],
                        "name": "J. Odobez",
                        "slug": "J.-Odobez",
                        "structuredName": {
                            "firstName": "Jean-Marc",
                            "lastName": "Odobez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Odobez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403029865"
                        ],
                        "name": "D. G\u00e1tica-P\u00e9rez",
                        "slug": "D.-G\u00e1tica-P\u00e9rez",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "G\u00e1tica-P\u00e9rez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. G\u00e1tica-P\u00e9rez"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 32
                            }
                        ],
                        "text": "These findings are in line with [17], which reports improved classification rates for an aspect model over an irregularly structured MRF built by connecting interest point based patches to their 5 nearest neighbors."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 303793,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "48a779329e80f4e86326c3860bc29e418811407e",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel approach for contextual segmentation of complex visual scenes, based on the use of bags of local invariant features (visterms) and probabilistic aspect models. Our approach uses context in two ways: (1) by using the fact that specific learned aspects correlate with the semantic classes, which resolves some cases of visual polysemy, and (2) by formalizing the notion that scene context is image-specific -what an individual visterm represents depends on what the rest of the visterms in the same bag represent too-. We demonstrate the validity of our approach on a man-made vs. natural visterm classification problem. Experiments on an image collection of complex scenes show that the approach improves region discrimination, producing satisfactory results, and outperforming a non-contextual method. Furthermore, through the later use of a Markov Random Field model, we also show that co-occurrence and spatial contextual information can be conveniently integrated for improved visterm classification."
            },
            "slug": "Integrating-Co-Occurrence-and-Spatial-Contexts-on-Monay-Quelhas",
            "title": {
                "fragments": [],
                "text": "Integrating Co-Occurrence and Spatial Contexts on PatchBased Scene Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A novel approach for contextual segmentation of complex visual scenes, based on the use of bags of local invariant features (visterms) and probabilistic aspect models, that improves region discrimination, producing satisfactory results, and outperforming a non-contextual method."
            },
            "venue": {
                "fragments": [],
                "text": "2006 Conference on Computer Vision and Pattern Recognition Workshop (CVPRW'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724876"
                        ],
                        "name": "P. Carbonetto",
                        "slug": "P.-Carbonetto",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Carbonetto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Carbonetto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145602732"
                        ],
                        "name": "Kobus Barnard",
                        "slug": "Kobus-Barnard",
                        "structuredName": {
                            "firstName": "Kobus",
                            "lastName": "Barnard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kobus Barnard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 196
                            }
                        ],
                        "text": "Creating such labellings requires substantially more effort than providing image-level keywords and it would be useful to develop models that allow learning from keywords alone along the lines of [2, 7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8270758,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7925221db50d93142cb5e5a4e31d6b72b2c5af8b",
            "isKey": false,
            "numCitedBy": 315,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider object recognition as the process of attaching meaningful labels to specific regions of an image, and propose a model that learns spatial relationships between objects. Given a set of images and their associated text (e.g. keywords, captions, descriptions), the objective is to segment an image, in either a crude or sophisticated fashion, then to find the proper associations between words and regions. Previous models are limited by the scope of the representation. In particular, they fail to exploit spatial context in the images and words. We develop a more expressive model that takes this into account. We formulate a spatially consistent probabilistic mapping between continuous image feature vectors and the supplied word tokens. By learning both word-to-region associations and object relations, the proposed model augments scene segmentations due to smoothing implicit in spatial consistency. Context introduces cycles to the undirected graph, so we cannot rely on a straightforward implementation of the EM algorithm for estimating the model parameters and densities of the unknown alignment variables. Instead, we develop an approximate EM algorithm that uses loopy belief propagation in the inference step and iterative scaling on the pseudo-likelihood approximation in the parameter update step. The experiments indicate that our approximate inference and learning algorithm converges to good local solutions. Experiments on a diverse array of images show that spatial context considerably improves the accuracy of object recognition. Most significantly, spatial context combined with a nonlinear discrete object representation allows our models to cope well with over-segmented scenes."
            },
            "slug": "A-Statistical-Model-for-General-Contextual-Object-Carbonetto-Freitas",
            "title": {
                "fragments": [],
                "text": "A Statistical Model for General Contextual Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Experiments show that spatial context considerably improves the accuracy of object recognition, and an approximate EM algorithm that uses loopy belief propagation in the inference step and iterative scaling on the pseudo-likelihood approximation in the parameter update step converges to good local solutions."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3351018"
                        ],
                        "name": "Pedro Quelhas",
                        "slug": "Pedro-Quelhas",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Quelhas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pedro Quelhas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1824057"
                        ],
                        "name": "Florent Monay",
                        "slug": "Florent-Monay",
                        "structuredName": {
                            "firstName": "Florent",
                            "lastName": "Monay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Florent Monay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719610"
                        ],
                        "name": "J. Odobez",
                        "slug": "J.-Odobez",
                        "structuredName": {
                            "firstName": "Jean-Marc",
                            "lastName": "Odobez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Odobez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403029865"
                        ],
                        "name": "D. G\u00e1tica-P\u00e9rez",
                        "slug": "D.-G\u00e1tica-P\u00e9rez",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "G\u00e1tica-P\u00e9rez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. G\u00e1tica-P\u00e9rez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704728"
                        ],
                        "name": "T. Tuytelaars",
                        "slug": "T.-Tuytelaars",
                        "structuredName": {
                            "firstName": "Tinne",
                            "lastName": "Tuytelaars",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tuytelaars"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 223
                            }
                        ],
                        "text": "It does seem clear that when only a few labelled training images are available, performance can be improved by representing them in terms of their aspect model topic mixtures rather than in terms of their original features [1, 13, 19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14100761,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ba6417baed41a8f0fd4cab342aa214704389dcf9",
            "isKey": false,
            "numCitedBy": 452,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new approach to model visual scenes in image collections, based on local invariant features and probabilistic latent space models. Our formulation provides answers to three open questions:(l) whether the invariant local features are suitable for scene (rather than object) classification; (2) whether unsupennsed latent space models can be used for feature extraction in the classification task; and (3) whether the latent space formulation can discover visual co-occurrence patterns, motivating novel approaches for image organization and segmentation. Using a 9500-image dataset, our approach is validated on each of these issues. First, we show with extensive experiments on binary and multi-class scene classification tasks, that a bag-of-visterm representation, derived from local invariant descriptors, consistently outperforms state-of-the-art approaches. Second, we show that probabilistic latent semantic analysis (PLSA) generates a compact scene representation, discriminative for accurate classification, and significantly more robust when less training data are available. Third, we have exploited the ability of PLSA to automatically extract visually meaningful aspects, to propose new algorithms for aspect-based image ranking and context-sensitive image segmentation."
            },
            "slug": "Modeling-scenes-with-local-descriptors-and-latent-Quelhas-Monay",
            "title": {
                "fragments": [],
                "text": "Modeling scenes with local descriptors and latent aspects"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Probabilistic latent semantic analysis generates a compact scene representation, discriminative for accurate classification, and significantly more robust when less training data are available, and the ability of PLSA to automatically extract visually meaningful aspects is exploited to propose new algorithms for aspect-based image ranking and context-sensitive image segmentation."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143774737"
                        ],
                        "name": "J. Shotton",
                        "slug": "J.-Shotton",
                        "structuredName": {
                            "firstName": "Jamie",
                            "lastName": "Shotton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shotton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33652486"
                        ],
                        "name": "J. Winn",
                        "slug": "J.-Winn",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Winn",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Winn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756036"
                        ],
                        "name": "C. Rother",
                        "slug": "C.-Rother",
                        "structuredName": {
                            "firstName": "Carsten",
                            "lastName": "Rother",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rother"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716777"
                        ],
                        "name": "A. Criminisi",
                        "slug": "A.-Criminisi",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Criminisi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Criminisi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 0
                            }
                        ],
                        "text": "Textonboost required 3 minutes to process a test image, while PLSA-MRF requires 2 seconds per image for feature extraction and 0.3\u20132 seconds for inference depending on the number of EP iterations."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 0
                            }
                        ],
                        "text": "Textonboost [21] was learned\nfrom labelled pixels so for a fair comparison we estimate the PLSA-MRF topics from labeled patches (20\u00d720 pixel patches spaced by 10 pixels as before)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 101
                            }
                        ],
                        "text": "Recently there has been considerable interest in methods for segmenting images into semantic classes [9, 11, 21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 60
                            }
                        ],
                        "text": "Now we compare the combined PLSA-MRF model with Textonboost [21] on the 591 image MSRC data set."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 54
                            }
                        ],
                        "text": "Averaging classification performance over all pixels, Textonboost achieves 72.2% while PLSA-MRF attains 73.5%."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 65
                            }
                        ],
                        "text": "(The training/test split is probably different from that used in [21])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 12
                            }
                        ],
                        "text": "Textonboost [21] was learned from labelled pixels so for a fair comparison we estimate the PLSA-MRF topics from labeled patches (20\u00d720 pixel patches spaced by 10 pixels as before)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 77
                            }
                        ],
                        "text": "Training Textonboost is much slower: 42 hours were required using 276 images [21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 109
                            }
                        ],
                        "text": "On the 21-class MSRC dataset our models achieve pixel classification accuracies at least as good as those of Textonboost at much lower computational cost."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6075144,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fb444dc25bab36a8e273ed654d49e3841905e5af",
            "isKey": true,
            "numCitedBy": 1349,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a new approach to learning a discriminative model of object classes, incorporating appearance, shape and context information efficiently. The learned model is used for automatic visual recognition and semantic segmentation of photographs. Our discriminative model exploits novel features, based on textons, which jointly model shape and texture. Unary classification and feature selection is achieved using shared boosting to give an efficient classifier which can be applied to a large number of classes. Accurate image segmentation is achieved by incorporating these classifiers in a conditional random field. Efficient training of the model on very large datasets is achieved by exploiting both random feature selection and piecewise training methods. \n \nHigh classification and segmentation accuracy are demonstrated on three different databases: i) our own 21-object class database of photographs of real objects viewed under general lighting conditions, poses and viewpoints, ii) the 7-class Corel subset and iii) the 7-class Sowerby database used in [1]. The proposed algorithm gives competitive results both for highly textured (e.g. grass, trees), highly structured (e.g. cars, faces, bikes, aeroplanes) and articulated objects (e.g. body, cow)."
            },
            "slug": "TextonBoost:-Joint-Appearance,-Shape-and-Context-Shotton-Winn",
            "title": {
                "fragments": [],
                "text": "TextonBoost: Joint Appearance, Shape and Context Modeling for Multi-class Object Recognition and Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "A new approach to learning a discriminative model of object classes, incorporating appearance, shape and context information efficiently, is proposed, which is used for automatic visual recognition and semantic segmentation of photographs."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33913193"
                        ],
                        "name": "Xuming He",
                        "slug": "Xuming-He",
                        "structuredName": {
                            "firstName": "Xuming",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xuming He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804104"
                        ],
                        "name": "R. Zemel",
                        "slug": "R.-Zemel",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Zemel",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zemel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1400347470"
                        ],
                        "name": "M. A. Carreira-Perpi\u00f1\u00e1n",
                        "slug": "M.-A.-Carreira-Perpi\u00f1\u00e1n",
                        "structuredName": {
                            "firstName": "Miguel",
                            "lastName": "Carreira-Perpi\u00f1\u00e1n",
                            "middleNames": [
                                "\u00c1."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. A. Carreira-Perpi\u00f1\u00e1n"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 101
                            }
                        ],
                        "text": "Recently there has been considerable interest in methods for segmenting images into semantic classes [9, 11, 21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11859305,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "363b56f85e12389017ba8894056a1b309e46a5f7",
            "isKey": false,
            "numCitedBy": 933,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose an approach to include contextual features for labeling images, in which each pixel is assigned to one of a finite set of labels. The features are incorporated into a probabilistic framework, which combines the outputs of several components. Components differ in the information they encode. Some focus on the image-label mapping, while others focus solely on patterns within the label field. Components also differ in their scale, as some focus on fine-resolution patterns while others on coarser, more global structure. A supervised version of the contrastive divergence algorithm is applied to learn these features from labeled image data. We demonstrate performance on two real-world image databases and compare it to a classifier and a Markov random field."
            },
            "slug": "Multiscale-conditional-random-fields-for-image-He-Zemel",
            "title": {
                "fragments": [],
                "text": "Multiscale conditional random fields for image labeling"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "An approach to include contextual features for labeling images, in which each pixel is assigned to one of a finite set of labels, are incorporated into a probabilistic framework, which combines the outputs of several components."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145349582"
                        ],
                        "name": "Sanjiv Kumar",
                        "slug": "Sanjiv-Kumar",
                        "structuredName": {
                            "firstName": "Sanjiv",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sanjiv Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 101
                            }
                        ],
                        "text": "Recently there has been considerable interest in methods for segmenting images into semantic classes [9, 11, 21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6958332,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "83bf1e6d239dd5bc1b8f7499f7241a8802a43e22",
            "isKey": false,
            "numCitedBy": 274,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a two-layer hierarchical formulation to exploit different levels of contextual information in images for robust classification. Each layer is modeled as a conditional field that allows one to capture arbitrary observation-dependent label interactions. The proposed framework has two main advantages. First, it encodes both the short-range interactions (e.g., pixelwise label smoothing) as well as the long-range interactions (e.g., relative configurations of objects or regions) in a tractable manner. Second, the formulation is general enough to be applied to different domains ranging from pixelwise image labeling to contextual object detection. The parameters of the model are learned using a sequential maximum-likelihood approximation. The benefits of the proposed framework are demonstrated on four different datasets and comparison results are presented"
            },
            "slug": "A-hierarchical-field-framework-for-unified-Kumar-Hebert",
            "title": {
                "fragments": [],
                "text": "A hierarchical field framework for unified context-based classification"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A two-layer hierarchical formulation to exploit different levels of contextual information in images for robust classification and is general enough to be applied to different domains ranging from pixelwise image labeling to contextual object detection."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144423856"
                        ],
                        "name": "Anna Bosch",
                        "slug": "Anna-Bosch",
                        "structuredName": {
                            "firstName": "Anna",
                            "lastName": "Bosch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anna Bosch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2062941326"
                        ],
                        "name": "X. Mu\u00f1oz",
                        "slug": "X.-Mu\u00f1oz",
                        "structuredName": {
                            "firstName": "Xavier",
                            "lastName": "Mu\u00f1oz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Mu\u00f1oz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 13
                            }
                        ],
                        "text": "In contrast, [6] combines color and texture by calculating 128-D SIFT independently on each component of HSV color space and vector quantizing the resulting 384-D feature vectors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1260607,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "15d2aa6511bd0a8de5cb690bf406d90eef902ff1",
            "isKey": false,
            "numCitedBy": 859,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Given a set of images of scenes containing multiple object categories (e.g. grass, roads, buildings) our objective is to discover these objects in each image in an unsupervised manner, and to use this object distribution to perform scene classification. We achieve this discovery using probabilistic Latent Semantic Analysis (pLSA), a generative model from the statistical text literature, here applied to a bag of visual words representation for each image. The scene classification on the object distribution is carried out by a k-nearest neighbour classifier. \n \nWe investigate the classification performance under changes in the visual vocabulary and number of latent topics learnt, and develop a novel vocabulary using colour SIFT descriptors. Classification performance is compared to the supervised approaches of Vogel & Schiele [19] and Oliva & Torralba [11], and the semi-supervised approach of Fei Fei & Perona [3] using their own datasets and testing protocols. In all cases the combination of (unsupervised) pLSA followed by (supervised) nearest neighbour classification achieves superior results. We show applications of this method to image retrieval with relevance feedback and to scene classification in videos."
            },
            "slug": "Scene-Classification-Via-pLSA-Bosch-Zisserman",
            "title": {
                "fragments": [],
                "text": "Scene Classification Via pLSA"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The classification performance under changes in the visual vocabulary and number of latent topics learnt is investigated, and a novel vocabulary using colour SIFT descriptors is developed using probabilistic Latent Semantic Analysis."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782755"
                        ],
                        "name": "Josef Sivic",
                        "slug": "Josef-Sivic",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Sivic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Josef Sivic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145160921"
                        ],
                        "name": "Bryan C. Russell",
                        "slug": "Bryan-C.-Russell",
                        "structuredName": {
                            "firstName": "Bryan",
                            "lastName": "Russell",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bryan C. Russell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 35
                            }
                        ],
                        "text": "At the other extreme, some authors [20, 22] argue that aspect models like Probabilistic Latent Semantic Analysis (PLSA) [10] and Latent Dirichlet Allocation (LDA) [5] can recover semantic-level visual models even under completely unsupervised training (without any labeled training data)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206769491,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a737c107623bcffefa0bac20f1b64677f6a1255a",
            "isKey": false,
            "numCitedBy": 1142,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We seek to discover the object categories depicted in a set of unlabelled images. We achieve this using a model developed in the statistical text literature: probabilistic latent semantic analysis (pLSA). In text analysis, this is used to discover topics in a corpus using the bag-of-words document representation. Here we treat object categories as topics, so that an image containing instances of several categories is modeled as a mixture of topics. The model is applied to images by using a visual analogue of a word, formed by vector quantizing SIFT-like region descriptors. The topic discovery approach successfully translates to the visual domain: for a small set of objects, we show that both the object categories and their approximate spatial layout are found without supervision. Performance of this unsupervised method is compared to the supervised approach of Fergus et al. (2003) on a set of unseen images containing only one object per image. We also extend the bag-of-words vocabulary to include 'doublets' which encode spatially local co-occurring regions. It is demonstrated that this extended vocabulary gives a cleaner image segmentation. Finally, the classification and segmentation methods are applied to a set of images containing multiple objects per image. These results demonstrate that we can successfully build object class models from an unsupervised analysis of images."
            },
            "slug": "Discovering-objects-and-their-location-in-images-Sivic-Russell",
            "title": {
                "fragments": [],
                "text": "Discovering objects and their location in images"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This work treats object categories as topics, so that an image containing instances of several categories is modeled as a mixture of topics, and develops a model developed in the statistical text literature: probabilistic latent semantic analysis (pLSA)."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145602732"
                        ],
                        "name": "Kobus Barnard",
                        "slug": "Kobus-Barnard",
                        "structuredName": {
                            "firstName": "Kobus",
                            "lastName": "Barnard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kobus Barnard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2446509"
                        ],
                        "name": "P. D. Sahin",
                        "slug": "P.-D.-Sahin",
                        "structuredName": {
                            "firstName": "Pinar",
                            "lastName": "Sahin",
                            "middleNames": [
                                "Duygulu"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. D. Sahin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796335"
                        ],
                        "name": "D. Blei",
                        "slug": "D.-Blei",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Blei",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 196
                            }
                        ],
                        "text": "Creating such labellings requires substantially more effort than providing image-level keywords and it would be useful to develop models that allow learning from keywords alone along the lines of [2, 7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 868535,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a26268d2ba9d34e5b59ae6e5c11a83cdca1a85e",
            "isKey": false,
            "numCitedBy": 1760,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new approach for modeling multi-modal data sets, focusing on the specific case of segmented images with associated text. Learning the joint distribution of image regions and words has many applications. We consider in detail predicting words associated with whole images (auto-annotation) and corresponding to particular image regions (region naming). Auto-annotation might help organize and access large collections of images. Region naming is a model of object recognition as a process of translating image regions to words, much as one might translate from one language to another. Learning the relationships between image regions and semantic correlates (words) is an interesting example of multi-modal data mining, particularly because it is typically hard to apply data mining techniques to collections of images. We develop a number of models for the joint distribution of image regions and words, including several which explicitly learn the correspondence between regions and words. We study multi-modal and correspondence extensions to Hofmann's hierarchical clustering/aspect model, a translation model adapted from statistical machine translation (Brown et al.), and a multi-modal extension to mixture of latent Dirichlet allocation (MoM-LDA). All models are assessed using a large collection of annotated images of real scenes. We study in depth the difficult problem of measuring performance. For the annotation task, we look at prediction performance on held out data. We present three alternative measures, oriented toward different types of task. Measuring the performance of correspondence methods is harder, because one must determine whether a word has been placed on the right region of an image. We can use annotation performance as a proxy measure, but accurate measurement requires hand labeled data, and thus must occur on a smaller scale. We show results using both an annotation proxy, and manually labeled data."
            },
            "slug": "Matching-Words-and-Pictures-Barnard-Sahin",
            "title": {
                "fragments": [],
                "text": "Matching Words and Pictures"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A new approach for modeling multi-modal data sets, focusing on the specific case of segmented images with associated text, is presented, and a number of models for the joint distribution of image regions and words are developed, including several which explicitly learn the correspondence between regions and Words."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145984136"
                        ],
                        "name": "A. Agarwal",
                        "slug": "A.-Agarwal",
                        "structuredName": {
                            "firstName": "Ankur",
                            "lastName": "Agarwal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Agarwal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 223
                            }
                        ],
                        "text": "It does seem clear that when only a few labelled training images are available, performance can be improved by representing them in terms of their aspect model topic mixtures rather than in terms of their original features [1, 13, 19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15284075,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8bd170564ea5e58faffd557826d442ab0baf8dc6",
            "isKey": false,
            "numCitedBy": 186,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Histograms of local appearance descriptors are a popular representation for visual recognition. They are highly discriminant and have good resistance to local occlusions and to geometric and photometric variations, but they are not able to exploit spatial co-occurrence statistics at scales larger than their local input patches. We present a new multilevel visual representation, \u2018hyperfeatures', that is designed to remedy this. The starting point is the familiar notion that to detect object parts, in practice it often suffices to detect co-occurrences of more local object fragments \u2013 a process that can be formalized as comparison (e.g. vector quantization) of image patches against a codebook of known fragments, followed by local aggregation of the resulting codebook membership vectors to detect co-occurrences. This process converts local collections of image descriptor vectors into somewhat less local histogram vectors \u2013 higher-level but spatially coarser descriptors. We observe that as the output is again a local descriptor vector, the process can be iterated, and that doing so captures and codes ever larger assemblies of object parts and increasingly abstract or \u2018semantic' image properties. We formulate the hyperfeatures model and study its performance under several different image coding methods including clustering based Vector Quantization, Gaussian Mixtures, and combinations of these with Latent Dirichlet Allocation. We find that the resulting high-level features provide improved performance in several object image and texture image classification tasks."
            },
            "slug": "Hyperfeatures-Multilevel-Local-Coding-for-Visual-Agarwal-Triggs",
            "title": {
                "fragments": [],
                "text": "Hyperfeatures - Multilevel Local Coding for Visual Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The hyperfeatures model is formulated and its performance under several different image coding methods including clustering based Vector Quantization, Gaussian Mixtures, and combinations of these with Latent Dirichlet Allocation is studied."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145160921"
                        ],
                        "name": "Bryan C. Russell",
                        "slug": "Bryan-C.-Russell",
                        "structuredName": {
                            "firstName": "Bryan",
                            "lastName": "Russell",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bryan C. Russell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782755"
                        ],
                        "name": "Josef Sivic",
                        "slug": "Josef-Sivic",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Sivic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Josef Sivic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 35
                            }
                        ],
                        "text": "At the other extreme, some authors [20, 22] argue that aspect models like Probabilistic Latent Semantic Analysis (PLSA) [10] and Latent Dirichlet Allocation (LDA) [5] can recover semantic-level visual models even under completely unsupervised training (without any labeled training data)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2066830,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "56766bab76cdcd541bf791730944a5e453006239",
            "isKey": false,
            "numCitedBy": 740,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Given a large dataset of images, we seek to automatically determine the visually similar object and scene classes together with their image segmentation. To achieve this we combine two ideas: (i) that a set of segmented objects can be partitioned into visual object classes using topic discovery models from statistical text analysis; and (ii) that visual object classes can be used to assess the accuracy of a segmentation. To tie these ideas together we compute multiple segmentations of each image and then: (i) learn the object classes; and (ii) choose the correct segmentations. We demonstrate that such an algorithm succeeds in automatically discovering many familiar objects in a variety of image datasets, including those from Caltech, MSRC and LabelMe."
            },
            "slug": "Using-Multiple-Segmentations-to-Discover-Objects-in-Russell-Freeman",
            "title": {
                "fragments": [],
                "text": "Using Multiple Segmentations to Discover Objects and their Extent in Image Collections"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work compute multiple segmentations of each image and then learns the object classes and chooses the correct segmentations, demonstrating that such an algorithm succeeds in automatically discovering many familiar objects in a variety of image datasets, including those from Caltech, MSRC and LabelMe."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749609"
                        ],
                        "name": "S. Lazebnik",
                        "slug": "S.-Lazebnik",
                        "structuredName": {
                            "firstName": "Svetlana",
                            "lastName": "Lazebnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lazebnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 23
                            }
                        ],
                        "text": "Our work is related to [18, 14] where segmentation models for textured animals are learned from images grouped by the class of animal."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15208439,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "400736e84b3b04ffa41542cf62b6546e57f590f7",
            "isKey": false,
            "numCitedBy": 145,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a framework for texture recognition based on local affine-invariant descriptors and their spatial layout. At modelling time, a generative model of local descriptors is learned from sample images using the EM algorithm. The EM framework allows the incorporation of unsegmented multitexture images into the training set. The second modelling step consists of gathering co-occurrence statistics of neighboring descriptors. At recognition time, initial probabilities computed from the generative model are refined using a relaxation step that incorporates co-occurrence statistics. Performance is evaluated on images of an indoor scene and pictures of wild animals."
            },
            "slug": "Affine-invariant-local-descriptors-and-neighborhood-Lazebnik-Schmid",
            "title": {
                "fragments": [],
                "text": "Affine-invariant local descriptors and neighborhood statistics for texture recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A framework for texture recognition based on local affine-invariant descriptors and their spatial layout is presented and initial probabilities computed from the generative model are refined using a relaxation step that incorporates co-occurrence statistics."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2820687"
                        ],
                        "name": "Joost van de Weijer",
                        "slug": "Joost-van-de-Weijer",
                        "structuredName": {
                            "firstName": "Joost",
                            "lastName": "Weijer",
                            "middleNames": [
                                "van",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joost van de Weijer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 157
                            }
                        ],
                        "text": "We use cues from M = 3 distinct modalities to characterize each image patch: a SIFT descriptor [15] captures the local texture; the robust hue descriptor of [23] describes the local color distribution; and approximate image location is coded by the index of the cell into which the patch falls, where the image is covered by a c\u00d7c grid of regular cells."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206596226,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4fb18a9f0d3a849d314daef1053d369998c5144",
            "isKey": false,
            "numCitedBy": 544,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Although color is commonly experienced as an indispensable quality in describing the world around us, state-of-the art local feature-based representations arc mostly based on shape description, and ignore color information. The description of color is hampered by the large amount of variations which causes the measured color values to vary significantly. In this paper we aim to extend the description of local features with color information. To accomplish a wide applicability of the color descriptor, it should be robust to: 1. photometric changes commonly encountered in the real world, 2. varying image quality; from high quality images to snap-shot photo quality and compressed internet images. Based on these requirements we derive a set of color descriptors. The set of proposed descriptors are compared by extensive testing on multiple applications areas, namely, matching, retrieval and classification, and on a wide variety of image qualities. The results show that color descriptors remain reliable under photometric and geometrical changes, and with decreasing image quality. For all experiments a combination of color and shape outperforms a pure shape-based approach."
            },
            "slug": "Coloring-Local-Feature-Extraction-Weijer-Schmid",
            "title": {
                "fragments": [],
                "text": "Coloring Local Feature Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The results show that color descriptors remain reliable under photometric and geometrical changes, and with decreasing image quality, and for all experiments a combination of color and shape outperforms a pure shape-based approach."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2121009"
                        ],
                        "name": "J. Puzicha",
                        "slug": "J.-Puzicha",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Puzicha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Puzicha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143936663"
                        ],
                        "name": "Thomas Hofmann",
                        "slug": "Thomas-Hofmann",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Hofmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Hofmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682548"
                        ],
                        "name": "J. Buhmann",
                        "slug": "J.-Buhmann",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Buhmann",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Buhmann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 23
                            }
                        ],
                        "text": "Our work is related to [18, 14] where segmentation models for textured animals are learned from images grouped by the class of animal."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7284769,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9006fd754a2c6c6147a683c8bf589d1c632e6406",
            "isKey": false,
            "numCitedBy": 89,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Histogram-clustering-for-unsupervised-segmentation-Puzicha-Hofmann",
            "title": {
                "fragments": [],
                "text": "Histogram clustering for unsupervised segmentation and image retrieval"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit. Lett."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2295553"
                        ],
                        "name": "Diane Larlus",
                        "slug": "Diane-Larlus",
                        "structuredName": {
                            "firstName": "Diane",
                            "lastName": "Larlus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diane Larlus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "82117876"
                        ],
                        "name": "F. Jurie",
                        "slug": "F.-Jurie",
                        "structuredName": {
                            "firstName": "Fr\u00e9d\u00e9ric",
                            "lastName": "Jurie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jurie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 223
                            }
                        ],
                        "text": "It does seem clear that when only a few labelled training images are available, performance can be improved by representing them in terms of their aspect model topic mixtures rather than in terms of their original features [1, 13, 19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "However others [13] find that unsupervised aspect models perform poorly in classification tasks, even in relatively simple cases where each image contains just one easily visible target class and inter-class variation is limited (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14737384,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ba842b1f4ec31ec41969f1b030b961402531c6a8",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "The visual vocabularyis an intermediate level representation which has been proven to be very powerful for addressing object categorization problems. It is generally built by vector quantizing a set of local image descriptors, independently of the object model used for categorizing images. We propose here to embed the visual vocabulary creation within the object model construction, allowing to make it more suited for object class discrimination. We experimentally show that the proposed model outperforms approaches not learning such an adapted visual vocabulary."
            },
            "slug": "Latent-Mixture-Vocabularies-for-Object-Larlus-Jurie",
            "title": {
                "fragments": [],
                "text": "Latent Mixture Vocabularies for Object Categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work proposes to embed the visual vocabulary creation within the object model construction, allowing to make it more suited for object class discrimination, and shows that the proposed model outperforms approaches not learning such an adapted visual vocabulary."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739581"
                        ],
                        "name": "J. Lafferty",
                        "slug": "J.-Lafferty",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Lafferty",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lafferty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "113414328"
                        ],
                        "name": "Fernando Pereira",
                        "slug": "Fernando-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando Pereira"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 68
                            }
                        ],
                        "text": "Impressive results have been achieved with conditional random field [12] based models trained using detailed pixellevel labellings."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 219683473,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4ba954b0412773d047dc41231c733de0c1f4926",
            "isKey": false,
            "numCitedBy": 13408,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "We present conditional random fields , a framework for building probabilistic models to segment and label sequence data. Conditional random fields offer several advantages over hidden Markov models and stochastic grammars for such tasks, including the ability to relax strong independence assumptions made in those models. Conditional random fields also avoid a fundamental limitation of maximum entropy Markov models (MEMMs) and other discriminative Markov models based on directed graphical models, which can be biased towards states with few successor states. We present iterative parameter estimation algorithms for conditional random fields and compare the performance of the resulting models to HMMs and MEMMs on synthetic and natural-language data."
            },
            "slug": "Conditional-Random-Fields:-Probabilistic-Models-for-Lafferty-McCallum",
            "title": {
                "fragments": [],
                "text": "Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work presents iterative parameter estimation algorithms for conditional random fields and compares the performance of the resulting models to HMMs and MEMMs on synthetic and natural-language data."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143936663"
                        ],
                        "name": "Thomas Hofmann",
                        "slug": "Thomas-Hofmann",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Hofmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Hofmann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 27
                            }
                        ],
                        "text": "Aspect models such as PLSA [10] and LDA [5] have been extensively studied as models of collections of text documents."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 120
                            }
                        ],
                        "text": "At the other extreme, some authors [20, 22] argue that aspect models like Probabilistic Latent Semantic Analysis (PLSA) [10] and Latent Dirichlet Allocation (LDA) [5] can recover semantic-level visual models even under completely unsupervised training (without any labeled training data)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7605995,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e6dd83b2aa34c806596fc619ff3fbccf5f9830ab",
            "isKey": false,
            "numCitedBy": 2499,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel statistical method for factor analysis of binary and count data which is closely related to a technique known as Latent Semantic Analysis. In contrast to the latter method which stems from linear algebra and performs a Singular Value Decomposition of co-occurrence tables, the proposed technique uses a generative latent class model to perform a probabilistic mixture decomposition. This results in a more principled approach with a solid foundation in statistical inference. More precisely, we propose to make use of a temperature controlled version of the Expectation Maximization algorithm for model fitting, which has shown excellent performance in practice. Probabilistic Latent Semantic Analysis has many applications, most prominently in information retrieval, natural language processing, machine learning from text, and in related areas. The paper presents perplexity results for different types of text and linguistic data collections and discusses an application in automated document indexing. The experiments indicate substantial and consistent improvements of the probabilistic method over standard Latent Semantic Analysis."
            },
            "slug": "Unsupervised-Learning-by-Probabilistic-Latent-Hofmann",
            "title": {
                "fragments": [],
                "text": "Unsupervised Learning by Probabilistic Latent Semantic Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper proposes to make use of a temperature controlled version of the Expectation Maximization algorithm for model fitting, which has shown excellent performance in practice, and results in a more principled approach with a solid foundation in statistical inference."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796335"
                        ],
                        "name": "D. Blei",
                        "slug": "D.-Blei",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Blei",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 23
                            }
                        ],
                        "text": "Unlike multi-modal LDA [4], in our model the three modalities of each patch share a single common topic."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "LDA provides additional regularization by encouraging the topic mixtures to be sparse and by averaging over their weights, but this only makes a significant difference for small documents and many topics, Nd 6 T ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 9
                            }
                        ],
                        "text": "Notably, LDA adds a sparse (Dirichlet) prior for the topic weights \u03b8d and treats these as hidden variables to be integrated out rather than as parameters to be estimated using Maximum Likelihood for each document."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 31
                            }
                        ],
                        "text": "Aspect models such as PLSA and LDA ignore the spatial structure of the image, modeling its patches as independent draws from the topic mixture \u03b8d."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 31
                            }
                        ],
                        "text": "Aspect models such as PLSA and LDA are probabilistic models that are well suited to this situation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 158
                            }
                        ],
                        "text": "At the other extreme, some authors [20, 22] argue that aspect models like Probabilistic Latent Semantic Analysis (PLSA) [10] and Latent Dirichlet Allocation (LDA) [5] can recover semantic-level visual models even under completely unsupervised training (without any labeled training data)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 42
                            }
                        ],
                        "text": "It is computationally more efficient than LDA and it has comparable accuracy in practice."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 36
                            }
                        ],
                        "text": "Aspect models such as PLSA [10] and LDA [5] have been extensively studied as models of collections of text documents."
                    },
                    "intents": []
                }
            ],
            "corpusId": 207561477,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "473f4b7f8ae2b03dda2593f54b316ff7d55db26b",
            "isKey": true,
            "numCitedBy": 1214,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of modeling annotated data---data with multiple types where the instance of one type (such as a caption) serves as a description of the other type (such as an image). We describe three hierarchical probabilistic mixture models which aim to describe such data, culminating in correspondence latent Dirichlet allocation, a latent variable model that is effective at modeling the joint distribution of both types and the conditional distribution of the annotation given the primary type. We conduct experiments on the Corel database of images and captions, assessing performance in terms of held-out likelihood, automatic annotation, and text-based image retrieval."
            },
            "slug": "Modeling-annotated-data-Blei-Jordan",
            "title": {
                "fragments": [],
                "text": "Modeling annotated data"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Three hierarchical probabilistic mixture models which aim to describe annotated data with multiple types, culminating in correspondence latent Dirichlet allocation, a latent variable model that is effective at modeling the joint distribution of both types and the conditional distribution of the annotation given the primary type."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1811875"
                        ],
                        "name": "F. Hamze",
                        "slug": "F.-Hamze",
                        "structuredName": {
                            "firstName": "Firas",
                            "lastName": "Hamze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hamze"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 101
                            }
                        ],
                        "text": "However there are various methods for approximating marginals, including (structured) Gibbs sampling [8], Variational Mean-Field (VMF), Loopy Belief Propagation (LBP), and Expectation Propagation (EP)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5059782,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6acc8183b0fd8d8becbe5d65af4750fc7994803b",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We present new MCMC algorithms for computing the posterior distributions and expectations of the unknown variables in undirected graphical models with regular structure. For demonstration purposes, we focus on Markov Random Fields (MRFs). By partitioning the MRFs into non-overlapping trees, it is possible to compute the posterior distribution of a particular tree exactly by conditioning on the remaining tree. These exact solutions allow us to construct efficient blocked and Rao-Blackwellised MCMC algorithms. We show empirically that tree sampling is considerably more efficient than other partitioned sampling schemes and the naive Gibbs sampler, even in cases where loopy belief propagation fails to converge. We prove that tree sampling exhibits lower variance than the naive Gibbs sampler and other naive partitioning schemes using the theoretical measure of maximal correlation. We also construct new information theory tools for comparing different MCMC schemes and show that, under these, tree sampling is more efficient."
            },
            "slug": "From-Fields-to-Trees-Hamze-Freitas",
            "title": {
                "fragments": [],
                "text": "From Fields to Trees"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is proved that tree sampling exhibits lower variance than the naive Gibbs sampler and other naive partitioning schemes using the theoretical measure of maximal correlation."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678311"
                        ],
                        "name": "M. Welling",
                        "slug": "M.-Welling",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Welling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Welling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52626911"
                        ],
                        "name": "T. Minka",
                        "slug": "T.-Minka",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Minka",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Minka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725303"
                        ],
                        "name": "Y. Teh",
                        "slug": "Y.-Teh",
                        "structuredName": {
                            "firstName": "Yee",
                            "lastName": "Teh",
                            "middleNames": [
                                "Whye"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Teh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 114
                            }
                        ],
                        "text": "2Our formulation can also be interpreted as a particular message passing scheme in Loopy Belief Propagation \u2013 see [24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1613604,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9358dbf89959aa7e79eed8ecb5ba436a33273b87",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "GBP and EP are two successful algorithms for approximate probabilistic inference, which are based on different approximation strategies. An open problem in both algorithms has been how to choose an appropriate approximation structure. We introduce \"structured region graphs,\" a formalism which marries these two strategies, reveals a deep connection between them, and suggests how to choose good approximation structures. In this formalism, each region has an internal structure which defines an exponential family, whose sufficient statistics must be matched by the parent region. Reduction operators on these structures allow conversion between EP and GBP free energies. Thus it is revealed that all EP approximations on discrete variables are special cases of GBP, and conversely that some well-known GBP approximations, such as overlapping squares, are special cases of EP. Furthermore, region graphs derived from EP have a number of good structural properties, including maxent-normality and overall counting number of one. The result is a convenient framework for producing high-quality approximations with a user-adjustable level of complexity."
            },
            "slug": "Structured-Region-Graphs:-Morphing-EP-into-GBP-Welling-Minka",
            "title": {
                "fragments": [],
                "text": "Structured Region Graphs: Morphing EP into GBP"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "\"structured region graphs,\" a formalism which marries these two strategies, reveals a deep connection between them, and suggests how to choose good approximation structures, which is a convenient framework for producing high-quality approximations with a user-adjustable level of complexity."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796335"
                        ],
                        "name": "D. Blei",
                        "slug": "D.-Blei",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Blei",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 19
                            }
                        ],
                        "text": "Unlike multi-modal LDA [4], in our model the three modalities of each patch share a single common topic."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "LDA provides additional regularization by encouraging the topic mixtures to be sparse and by averaging over their weights, but this only makes a significant difference for small documents and many topics, Nd 6 T ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 9
                            }
                        ],
                        "text": "Notably, LDA adds a sparse (Dirichlet) prior for the topic weights \u03b8d and treats these as hidden variables to be integrated out rather than as parameters to be estimated using Maximum Likelihood for each document."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 31
                            }
                        ],
                        "text": "Aspect models such as PLSA and LDA ignore the spatial structure of the image, modeling its patches as independent draws from the topic mixture \u03b8d."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 31
                            }
                        ],
                        "text": "Aspect models such as PLSA and LDA are probabilistic models that are well suited to this situation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 163
                            }
                        ],
                        "text": "At the other extreme, some authors [20, 22] argue that aspect models like Probabilistic Latent Semantic Analysis (PLSA) [10] and Latent Dirichlet Allocation (LDA) [5] can recover semantic-level visual models even under completely unsupervised training (without any labeled training data)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 42
                            }
                        ],
                        "text": "It is computationally more efficient than LDA and it has comparable accuracy in practice."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 40
                            }
                        ],
                        "text": "Aspect models such as PLSA [10] and LDA [5] have been extensively studied as models of collections of text documents."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3177797,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f198043a866e9187925a8d8db9a55e3bfdd47f2c",
            "isKey": true,
            "numCitedBy": 30945,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Latent-Dirichlet-Allocation-Blei-Ng",
            "title": {
                "fragments": [],
                "text": "Latent Dirichlet Allocation"
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764325"
                        ],
                        "name": "Radford M. Neal",
                        "slug": "Radford-M.-Neal",
                        "structuredName": {
                            "firstName": "Radford",
                            "lastName": "Neal",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Radford M. Neal"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 101
                            }
                        ],
                        "text": "Each factor is a set of 1-D MRFs whose exact marginals are calculated using the Baum-Welch algorithm [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 263,
                                "start": 260
                            }
                        ],
                        "text": "PLSA can be viewed as a probabilistic generalization of PCA \u2013 a low-rank nonnegative approximation of the matrix of (empirical word probabilities for each document)\u00d7 (documents) using factor matrices {p(w|t)}\u00d7{p(t|d)} obtained by Expectation-Maximization (EM) [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 52
                            }
                        ],
                        "text": "For an introduction to the latter three methods see [3], and for more details on EP and its relation to loopy BP, variational and other approximations see [16]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 162
                            }
                        ],
                        "text": "However there are various methods for approximating marginals, including (structured) Gibbs sampling [8], Variational Mean-Field (VMF), Loopy Belief Propagation (LBP), and Expectation Propagation (EP)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 215
                            }
                        ],
                        "text": "When the node marginals are multi-modal, EP tends to smooth over the peaks and hence over-estimate the marginal entropies, but in practice its marginals are often found to be more accurate than those of VMF and LBP [3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 73
                            }
                        ],
                        "text": "For these, (sequential) Gibbs sampling is exponentially slow and VMF and LBP tend to lock onto just one mode, while EP tends to average over multiple modes."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 49
                            }
                        ],
                        "text": "The MRF has the following prior over node labels [3]: p(Z) \u221d exp \uf8eb\uf8ed\u2211"
                    },
                    "intents": []
                }
            ],
            "corpusId": 31993898,
            "fieldsOfStudy": [
                "Mathematics",
                "Art"
            ],
            "id": "3bb5a439a0d610a7eac68f73068cdd278b8c9775",
            "isKey": true,
            "numCitedBy": 21001,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "the selection of symmetric factorial designs, that is, a design where all factors have the same number of levels. Chapter 3 focuses on selection of two-level factorial designs and discusses complementary design theory and related topics in the selection of designs. Chapter 4 covers the selection of three level designs followed by the general case of s-levels. Chapter 5 discusses estimation capacity, presenting the connections with complementary designs followed by the estimation capacity for two-level and s-level designs. Chapter 6 discusses and presents results for the construction of mixed-level designs. Giving many examples of the use of mixed two and four-level designs. The final unit of the book discusses designs where there are two-different groups of factors. Chapters 7 and 8 discuss factorial designs with restricted randomization. Focusing first on blocked designs for full factorials as well as blocked fractional factorial designs. Chapter 8 focuses on split-plot designs. The booked is concluded with a chapter on robust parameter designs. This book covers a broad range of topics for regular factorial designs and presents all of the material in very mathematical fashion. However, the authors do a wonderful job of keeping the statistical methodology at the forefront of the book and the mathematical detail is presented as the necessary tool to study these designs. The book will serve as a great text for an advanced graduate level course in design theory for students with the necessary mathematical background. The book will surely become an invaluable resource for researchers and graduate students doing research in the design of factorial experiments. In addition, practitioners will also find the book useful for the comprehensive collection of optimal designs presented at the end of many chapters. Overall, this is a very well written book and a necessary addition to the existing literature on the design of factorial experiments."
            },
            "slug": "Pattern-Recognition-and-Machine-Learning-Neal",
            "title": {
                "fragments": [],
                "text": "Pattern Recognition and Machine Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This book covers a broad range of topics for regular factorial designs and presents all of the material in very mathematical fashion and will surely become an invaluable resource for researchers and graduate students doing research in the design of factorial experiments."
            },
            "venue": {
                "fragments": [],
                "text": "Technometrics"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52626911"
                        ],
                        "name": "T. Minka",
                        "slug": "T.-Minka",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Minka",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Minka"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 155
                            }
                        ],
                        "text": "For an introduction to the latter three methods see [3], and for more details on EP and its relation to loopy BP, variational and other approximations see [16]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7585417,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a912be1031c08cb21d5bf65a7240d3ca2aee51eb",
            "isKey": false,
            "numCitedBy": 522,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a unifying view of messagepassing algorithms, as methods to approximate a complex Bayesian network by a simpler network with minimum information divergence. In this view, the difference between mean-field methods and belief propagation is not the amount of structure they model, but only the measure of loss they minimize (\u2018exclusive\u2019 versus \u2018inclusive\u2019 Kullback-Leibler divergence). In each case, message-passing arises by minimizing a localized version of the divergence, local to each factor. By examining these divergence measures, we can intuit the types of solution they prefer (symmetry-breaking, for example) and their suitability for different tasks. Furthermore, by considering a wider variety of divergence measures (such as alpha-divergences), we can achieve different complexity and performance goals."
            },
            "slug": "Divergence-measures-and-message-passing-Minka",
            "title": {
                "fragments": [],
                "text": "Divergence measures and message passing"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper presents a unifying view of messagepassing algorithms, as methods to approximate a complex Bayesian network by a simpler network with minimum information divergence."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644050191"
                        ],
                        "name": "G. LoweDavid",
                        "slug": "G.-LoweDavid",
                        "structuredName": {
                            "firstName": "G",
                            "lastName": "LoweDavid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. LoweDavid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 95
                            }
                        ],
                        "text": "We use cues from M = 3 distinct modalities to characterize each image patch: a SIFT descriptor [15] captures the local texture; the robust hue descriptor of [23] describes the local color distribution; and approximate image location is coded by the index of the cell into which the patch falls, where the image is covered by a c\u00d7c grid of regular cells."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 174065,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4cab9c4b571761203ed4c3a4c5a07dd615f57a91",
            "isKey": false,
            "numCitedBy": 25501,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are ..."
            },
            "slug": "Distinctive-Image-Features-from-Scale-Invariant-LoweDavid",
            "title": {
                "fragments": [],
                "text": "Distinctive Image Features from Scale-Invariant Keypoints"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750195"
                        ],
                        "name": "E. Trucco",
                        "slug": "E.-Trucco",
                        "structuredName": {
                            "firstName": "Emanuele",
                            "lastName": "Trucco",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Trucco"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1779107"
                        ],
                        "name": "Andrea Fusiello",
                        "slug": "Andrea-Fusiello",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Fusiello",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrea Fusiello"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066242865"
                        ],
                        "name": "V. Roberto",
                        "slug": "V.-Roberto",
                        "structuredName": {
                            "firstName": "Vito",
                            "lastName": "Roberto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Roberto"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our work is related to [ 18 , 14] where segmentation models for textured animals are learned from images grouped by the class of animal."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11974333,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "59cf728e83a91c4cd6f2a744a5c00485299b254d",
            "isKey": false,
            "numCitedBy": 195,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Robust-motion-and-correspondence-of-noisy-3-D-point-Trucco-Fusiello",
            "title": {
                "fragments": [],
                "text": "Robust motion and correspondence of noisy 3-D point sets with missing data"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit. Lett."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145671626"
                        ],
                        "name": "S. Pearce",
                        "slug": "S.-Pearce",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Pearce",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Pearce"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 111042169,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "e5e088131d75b683463f0d4865e3a6e9c7101da2",
            "isKey": false,
            "numCitedBy": 73,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Field experimentation with fruit trees and other perennial plants , Field experimentation with fruit trees and other perennial plants , \u0645\u0631\u06a9\u0632 \u0641\u0646\u0627\u0648\u0631\u06cc \u0627\u0637\u0644\u0627\u0639\u0627\u062a \u0648 \u0627\u0637\u0644\u0627\u0639 \u0631\u0633\u0627\u0646\u06cc \u06a9\u0634\u0627\u0648\u0631\u0632\u06cc"
            },
            "slug": "Field-experimentation-with-fruit-trees-and-other-Pearce",
            "title": {
                "fragments": [],
                "text": "Field experimentation with fruit trees and other perennial plants"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1953
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "4) 95.6 (3.6) 95.5 (4.7) 85.5 (10.2) 87.4 (7.8) 78.1 (3.1) I/U* PLSA* 47.8 (10.9) 73.0 (8.9) 62.3 (15.9) 79.7 (10.7) 90.2 (5.2) 90"
            },
            "venue": {
                "fragments": [],
                "text": ") 56.6 (19.6) 84.2 (13.1) 87.7 (6"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Jordan . Modeling annotated data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Jordan . Modeling annotated data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 16,
            "methodology": 10,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 29,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Region-Classification-with-Markov-Field-Aspect-Verbeek-Triggs/2060431ccc8dfa586e91adb1eaa4018ac505740f?sort=total-citations"
}