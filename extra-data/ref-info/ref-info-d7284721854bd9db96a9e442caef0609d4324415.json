{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057440295"
                        ],
                        "name": "Sebastian Schreiber",
                        "slug": "Sebastian-Schreiber",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Schreiber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sebastian Schreiber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2582412"
                        ],
                        "name": "S. Agne",
                        "slug": "S.-Agne",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Agne",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Agne"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144651288"
                        ],
                        "name": "I. Wolf",
                        "slug": "I.-Wolf",
                        "structuredName": {
                            "firstName": "Ivo",
                            "lastName": "Wolf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Wolf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145279674"
                        ],
                        "name": "A. Dengel",
                        "slug": "A.-Dengel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Dengel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dengel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734717217"
                        ],
                        "name": "Sheraz Ahmed",
                        "slug": "Sheraz-Ahmed",
                        "structuredName": {
                            "firstName": "Sheraz",
                            "lastName": "Ahmed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sheraz Ahmed"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 20
                            }
                        ],
                        "text": "Recently, DeepDeSRT [8] was proposed which uses deep learning for both table detection and table structure recognition, i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 3
                            }
                        ],
                        "text": "In DeepDSert, separate models are made for Table detection and structure recognition, which were trained on different datasets such as Marmot for table detection, and the ICDAR 2013 table dataset for table structure recognition."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 51
                            }
                        ],
                        "text": "While the results are not conclusively better than DeepDSert, they are certainly comparable and the fact that our model is end-to-end means further improvements can be made with richer semantic knowledge, and additional branches for learning row based segmentation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 10
                            }
                        ],
                        "text": "Recently, DeepDeSRT [8] was proposed which uses deep learning for both table detection and table structure recognition, i.e. identifying rows, columns, and cell positions in the detected tables."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 117
                            }
                        ],
                        "text": "Average time taken for our system for each document image is 0.3765 seconds, however this could not be compared with DeepDSert as their model was not publicly available."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 120
                            }
                        ],
                        "text": "Additionally, Experiment 3 was carried out to compare TableNet with the closest deep-learning based solution, DeepDSert [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 11
                            }
                        ],
                        "text": "As done in DeepDSert, we also randomly chose 34 images for testing and used the rest of the data images for fine-tuning our model."
                    },
                    "intents": []
                }
            ],
            "corpusId": 10191334,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f8bead3ae810cd3f7427d3004e45b4158da9b744",
            "isKey": true,
            "numCitedBy": 158,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel end-to-end system for table understanding in document images called DeepDeSRT. In particular, the contribution of DeepDeSRT is two-fold. First, it presents a deep learning-based solution for table detection in document images. Secondly, it proposes a novel deep learning-based approach for table structure recognition, i.e. identifying rows, columns, and cell positions in the detected tables. In contrast to existing rule-based methods, which rely on heuristics or additional PDF metadata (like, for example, print instructions, character bounding boxes, or line segments), the presented system is data-driven and does not need any heuristics or metadata to detect as well as to recognize tabular structures in document images. Furthermore, in contrast to most existing table detection and structure recognition methods, which are applicable only to PDFs, DeepDeSRT processes document images, which makes it equally suitable for born-digital PDFs (as they can automatically be converted into images) as well as even harder problems, e.g. scanned documents. To gauge the performance of DeepDeSRT, the system is evaluated on the publicly available ICDAR 2013 table competition dataset containing 67 documents with 238 pages overall. Evaluation results reveal that DeepDeSRT outperforms state-of-the-art methods for table detection and structure recognition and achieves F1-measures of 96.77% and 91.44% for table detection and structure recognition, respectively. Additionally, DeepDeSRT is evaluated on a closed dataset from a real use case of a major European aviation company comprising documents which are highly unlike those in ICDAR 2013. Tested on a randomly selected sample from this dataset, DeepDeSRT achieves high detection accuracy for tables which demonstrates the sound generalization capabilities of our system."
            },
            "slug": "DeepDeSRT:-Deep-Learning-for-Detection-and-of-in-Schreiber-Agne",
            "title": {
                "fragments": [],
                "text": "DeepDeSRT: Deep Learning for Detection and Structure Recognition of Tables in Document Images"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "In contrast to most existing table detection and structure recognition methods, which are applicable only to PDFs, DeepDeSRT processes document images, which makes it equally suitable for born-digital PDFs as well as even harder problems, e.g. scanned documents."
            },
            "venue": {
                "fragments": [],
                "text": "2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2912641"
                        ],
                        "name": "I. Kavasidis",
                        "slug": "I.-Kavasidis",
                        "structuredName": {
                            "firstName": "Isaak",
                            "lastName": "Kavasidis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Kavasidis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46792082"
                        ],
                        "name": "S. Palazzo",
                        "slug": "S.-Palazzo",
                        "structuredName": {
                            "firstName": "Sergio",
                            "lastName": "Palazzo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Palazzo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2441118"
                        ],
                        "name": "C. Spampinato",
                        "slug": "C.-Spampinato",
                        "structuredName": {
                            "firstName": "Concetto",
                            "lastName": "Spampinato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Spampinato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145587660"
                        ],
                        "name": "C. Pino",
                        "slug": "C.-Pino",
                        "structuredName": {
                            "firstName": "Carmelo",
                            "lastName": "Pino",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Pino"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144027622"
                        ],
                        "name": "D. Giordano",
                        "slug": "D.-Giordano",
                        "structuredName": {
                            "firstName": "Daniela",
                            "lastName": "Giordano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Giordano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076542103"
                        ],
                        "name": "D. Giuffrida",
                        "slug": "D.-Giuffrida",
                        "structuredName": {
                            "firstName": "Dario",
                            "lastName": "Giuffrida",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Giuffrida"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "19324186"
                        ],
                        "name": "P. Messina",
                        "slug": "P.-Messina",
                        "structuredName": {
                            "firstName": "Pablo",
                            "lastName": "Messina",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Messina"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 12
                            }
                        ],
                        "text": "After this, [9] combined deep convolutional neural networks, graphical models and saliency concepts for localizing tables and charts in documents."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4899629,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "03672cfa599950f208d424d5298cdc12b72c2492",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep Convolutional Neural Networks (DCNNs) have recently been applied successfully to a variety of vision and multimedia tasks, thus driving development of novel solutions in several application domains. Document analysis is a particularly promising area for DCNNs: indeed, the number of available digital documents has reached unprecedented levels, and humans are no longer able to discover and retrieve all the information contained in these documents without the help of automation. Under this scenario, DCNNs offers a viable solution to automate the information extraction process from digital documents. Within the realm of information extraction from documents, detection of tables and charts is particularly needed as they contain a visual summary of the most valuable information contained in a document. For a complete automation of visual information extraction process from tables and charts, it is necessary to develop techniques that localize them and identify precisely their boundaries. In this paper we aim at solving the table/chart detection task through an approach that combines deep convolutional neural networks, graphical models and saliency concepts. In particular, we propose a saliency-based fully-convolutional neural network performing multi-scale reasoning on visual cues followed by a fully-connected conditional random field (CRF) for localizing tables and charts in digital/digitized documents. Performance analysis carried out on an extended version of ICDAR 2013 (with annotated charts as well as tables) shows that our approach yields promising results, outperforming existing models."
            },
            "slug": "A-Saliency-based-Convolutional-Neural-Network-for-Kavasidis-Palazzo",
            "title": {
                "fragments": [],
                "text": "A Saliency-based Convolutional Neural Network for Table and Chart Detection in Digitized Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A saliency-based fully-convolutional neural network performing multi-scale reasoning on visual cues followed by a fully-connected conditional random field (CRF) for localizing tables and charts in digital/digitized documents is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "ICIAP"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115379063"
                        ],
                        "name": "Jing Fang",
                        "slug": "Jing-Fang",
                        "structuredName": {
                            "firstName": "Jing",
                            "lastName": "Fang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jing Fang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070898875"
                        ],
                        "name": "Xin Tao",
                        "slug": "Xin-Tao",
                        "structuredName": {
                            "firstName": "Xin",
                            "lastName": "Tao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xin Tao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2087321561"
                        ],
                        "name": "Zhi Tang",
                        "slug": "Zhi-Tang",
                        "structuredName": {
                            "firstName": "Zhi",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhi Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29035564"
                        ],
                        "name": "Ruiheng Qiu",
                        "slug": "Ruiheng-Qiu",
                        "structuredName": {
                            "firstName": "Ruiheng",
                            "lastName": "Qiu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ruiheng Qiu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49420283"
                        ],
                        "name": "Y. Liu",
                        "slug": "Y.-Liu",
                        "structuredName": {
                            "firstName": "Ying",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 336,
                                "start": 330
                            }
                        ],
                        "text": "In summary, the primary contributions made in this paper are as follows:\n1) We propose TableNet: a novel end-to-end deep multi-\n128\n2379-2140/19/$31.00 \u00a92019 IEEE DOI 10.1109/ICDAR.2019.00029\ntask architecture for both table detection and structure recognition yielding state of the art performance on the public benchmark ICDAR and Marmot datasets."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 41
                            }
                        ],
                        "text": "For training our model, we have used the Marmot table recognition dataset."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 49
                            }
                        ],
                        "text": "Similarly, in Experiment 2, we used the modified Marmot data-set where, the words in each document were highlighted to provide semantic context as described in Section V-B."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 50
                            }
                        ],
                        "text": "To generate comparable results, we fine-tuned our Marmot trained TableNet model, on ICDAR train and test data splits."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 135
                            }
                        ],
                        "text": "In DeepDSert, separate models are made for Table detection and structure recognition, which were trained on different datasets such as Marmot for table detection, and the ICDAR 2013 table dataset for table structure recognition."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 65
                            }
                        ],
                        "text": "In Experiment 1, we trained our model on all positive samples of Marmot and tested on the ICDAR 2013 table competition dataset for both table and structure detection."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 17
                            }
                        ],
                        "text": "Furthermore, the Marmot dataset which has previously been annotated for table detection was also manually annotated for column detection, and these new annotations will be publicly released to the community for future research."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 34
                            }
                        ],
                        "text": "4) We have manually annotated the Marmot dataset for table data extraction and will release the annotations to the community."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 12
                            }
                        ],
                        "text": "We used the Marmot table detection data and manually annotated the structure information."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "Unfortunately, there are very few datasets like Marmot [17], UW3 [18], etc for table detection and even these contain only a few hundred images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 75
                            }
                        ],
                        "text": "The manually annotated modified dataset is publicly released with the name Marmot Extended for table structure recognition 1."
                    },
                    "intents": []
                }
            ],
            "corpusId": 23786594,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9f7a62139dfd09bfad667691332bd55e31736887",
            "isKey": true,
            "numCitedBy": 41,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Table detection is an important task in the field of document analysis. It has been extensively studied since a couple of decades. Various kinds of document mediums are involved, from scanned images to web pages, from plain texts to PDF files. Numerous algorithms published bring up a challenging issue: how to evaluate algorithms in different context. Currently, most work on table detection conducts experiments on their in-house dataset. Even the few sources of online datasets are targeted at image documents only. Moreover, Precision and recall measurement are usual practice in order to account performance based on human evaluation. In this paper, we provide a dataset that is representative, large and most importantly, publicly available. The compatible format of the ground truth makes evaluation independent of document medium. We also propose a set of new measures, implement them, and open the source code. Finally, three existing table detection algorithms are evaluated to demonstrate the reliability of the dataset and metrics."
            },
            "slug": "Dataset,-Ground-Truth-and-Performance-Metrics-for-Fang-Tao",
            "title": {
                "fragments": [],
                "text": "Dataset, Ground-Truth and Performance Metrics for Table Detection Evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A dataset that is representative, large and most importantly, publicly available, and the compatible format of the ground truth makes evaluation independent of document medium is provided."
            },
            "venue": {
                "fragments": [],
                "text": "2012 10th IAPR International Workshop on Document Analysis Systems"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115379063"
                        ],
                        "name": "Jing Fang",
                        "slug": "Jing-Fang",
                        "structuredName": {
                            "firstName": "Jing",
                            "lastName": "Fang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jing Fang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143930195"
                        ],
                        "name": "P. Mitra",
                        "slug": "P.-Mitra",
                        "structuredName": {
                            "firstName": "Prasenjit",
                            "lastName": "Mitra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Mitra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2087321561"
                        ],
                        "name": "Zhi Tang",
                        "slug": "Zhi-Tang",
                        "structuredName": {
                            "firstName": "Zhi",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhi Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157784"
                        ],
                        "name": "C. Lee Giles",
                        "slug": "C.-Lee-Giles",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Giles",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lee Giles"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[6] used the table header as a starting point to detect the table region and decompose its elements."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7883959,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9fbdeb0ed5d4adbb81ea8fe830ceabd6c398c06a",
            "isKey": false,
            "numCitedBy": 64,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "\n \n In digital libraries, a table, as a specific document component as well as a condensed way to present structured and relational data, contains rich information and often the only source of .that information. In order to explore, retrieve, and reuse that data, tables should be identified and the data extracted. Table recognition is an old field of research. However, due to the diversity of table styles, the results are still far from satisfactory, and not a single algorithm performs well on all different types of tables. In this paper, we randomly take samples from the CiteSeerX to investigate diverse table styles for automatic table extraction. We find that table headers are one of the main characteristics of complex table styles. We identify a set of features that can be used to segregate headers from tabular data and build a classifier to detect table headers. Our empirical evaluation on PDF documents shows that using a Random Forest classifier achieves an accuracy of 92%.\n \n"
            },
            "slug": "Table-Header-Detection-and-Classification-Fang-Mitra",
            "title": {
                "fragments": [],
                "text": "Table Header Detection and Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is found that table headers are one of the main characteristics of complex table styles and a set of features that can be used to segregate headers from tabular data are identified and a classifier is built to detect table headers."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2047516905"
                        ],
                        "name": "Max C. G\u00f6bel",
                        "slug": "Max-C.-G\u00f6bel",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "G\u00f6bel",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Max C. G\u00f6bel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "18592170"
                        ],
                        "name": "Tamir Hassan",
                        "slug": "Tamir-Hassan",
                        "structuredName": {
                            "firstName": "Tamir",
                            "lastName": "Hassan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tamir Hassan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759801"
                        ],
                        "name": "Ermelinda Oro",
                        "slug": "Ermelinda-Oro",
                        "structuredName": {
                            "firstName": "Ermelinda",
                            "lastName": "Oro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ermelinda Oro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35203250"
                        ],
                        "name": "G. Orsi",
                        "slug": "G.-Orsi",
                        "structuredName": {
                            "firstName": "Giorgio",
                            "lastName": "Orsi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Orsi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 103
                            }
                        ],
                        "text": "This section describes the different experiments performed on the ICDAR 2013 table competition dataset [19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 167
                            }
                        ],
                        "text": "There are even fewer datasets for table structure identification such as the ICDAR 2013 table competition dataset for both table detection and its structural analysis [19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206777311,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7cbc1582175b5c03b8203ec38bb25bae9d66397d",
            "isKey": false,
            "numCitedBy": 120,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Table understanding is a well studied problem in document analysis, and many academic and commercial approaches have been developed to recognize tables in several document formats, including plain text, scanned page images and born-digital, object-based formats such as PDF. Despite the abundance of these techniques, an objective comparison of their performance is still missing. The Table Competition held in the context of ICDAR 2013 is our first attempt at objectively evaluating these techniques against each other in a standardized way, across several input formats. The competition independently addresses three problems: (i) table location, (ii) table structure recognition, and (iii) these two tasks combined. We received results from seven academic systems, which we have also compared against four commercial products. This paper presents our findings."
            },
            "slug": "ICDAR-2013-Table-Competition-G\u00f6bel-Hassan",
            "title": {
                "fragments": [],
                "text": "ICDAR 2013 Table Competition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The Table Competition held in the context of ICDAR 2013 is the first attempt at objectively evaluating these techniques against each other in a standardized way, across several input formats."
            },
            "venue": {
                "fragments": [],
                "text": "2013 12th International Conference on Document Analysis and Recognition"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2672708"
                        ],
                        "name": "D. Tran",
                        "slug": "D.-Tran",
                        "structuredName": {
                            "firstName": "Dieu",
                            "lastName": "Tran",
                            "middleNames": [
                                "Ni"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Tran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072578366"
                        ],
                        "name": "T. A. Tran",
                        "slug": "T.-A.-Tran",
                        "structuredName": {
                            "firstName": "Tuan",
                            "lastName": "Tran",
                            "middleNames": [
                                "Anh"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. A. Tran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31704596"
                        ],
                        "name": "A. Oh",
                        "slug": "A.-Oh",
                        "structuredName": {
                            "firstName": "Aran",
                            "lastName": "Oh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2355626"
                        ],
                        "name": "Soohyung Kim",
                        "slug": "Soohyung-Kim",
                        "structuredName": {
                            "firstName": "Soohyung",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Soohyung Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31725329"
                        ],
                        "name": "In Seop Na",
                        "slug": "In-Seop-Na",
                        "structuredName": {
                            "firstName": "In",
                            "lastName": "Na",
                            "middleNames": [
                                "Seop"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "In Seop Na"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[10] locates the text components and extracts text blocks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61442517,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ca02ddb5febf92ec87744d6ce3bc7a96a3b89702",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Table detection is a challenging problem and plays an important role in document layout analysis. In this paper, we propose an effective method to identify the table region from document images. First, the regions of interest (ROIs) are recognized as the table candidates. In each ROI, we locate text components and extract text blocks. After that, we check all text blocks to determine if they are arranged horizontally or vertically and compare the height of each text block with the average height. If the text blocks satisfy a series of rules, the ROI is regarded as a table. Experiments on the ICDAR 2013 dataset show that the results obtained are very encouraging. This proves the effectiveness and superiority of our proposed method."
            },
            "slug": "Table-Detection-from-Document-Image-using-Vertical-Tran-Tran",
            "title": {
                "fragments": [],
                "text": "Table Detection from Document Image using Vertical Arrangement of Text Blocks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Experiments on the ICDAR 2013 dataset show that the results obtained are very encouraging and proves the effectiveness and superiority of the proposed method."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51226106"
                        ],
                        "name": "Pranaydeep Singh",
                        "slug": "Pranaydeep-Singh",
                        "structuredName": {
                            "firstName": "Pranaydeep",
                            "lastName": "Singh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pranaydeep Singh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "26961805"
                        ],
                        "name": "Srikrishna Varadarajan",
                        "slug": "Srikrishna-Varadarajan",
                        "structuredName": {
                            "firstName": "Srikrishna",
                            "lastName": "Varadarajan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Srikrishna Varadarajan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2140475450"
                        ],
                        "name": "A. Singh",
                        "slug": "A.-Singh",
                        "structuredName": {
                            "firstName": "Ankit",
                            "lastName": "Singh",
                            "middleNames": [
                                "Narayan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Singh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "27088137"
                        ],
                        "name": "Muktabh Mayank Srivastava",
                        "slug": "Muktabh-Mayank-Srivastava",
                        "structuredName": {
                            "firstName": "Muktabh",
                            "lastName": "Srivastava",
                            "middleNames": [
                                "Mayank"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Muktabh Mayank Srivastava"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[14] use object detection techniques for Document Layout understanding."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 52069216,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "12eede12e8673888e07eb59b922227b2d0f92969",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We try to address the problem of document layout understanding using a simple algorithm which generalizes across multiple domains while training on just few examples per domain. We approach this problem via supervised object detection method and propose a methodology to overcome the requirement of large datasets. We use the concept of transfer learning by pre-training our object detector on a simple artificial (source) dataset and fine-tuning it on a tiny domain specific (target) dataset. We show that this methodology works for multiple domains with training samples as less as 10 documents. We demonstrate the effect of each component of the methodology in the end result and show the superiority of this methodology over simple object detectors."
            },
            "slug": "Multidomain-Document-Layout-Understanding-using-Few-Singh-Varadarajan",
            "title": {
                "fragments": [],
                "text": "Multidomain Document Layout Understanding using Few Shot Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work proposes a methodology to overcome the requirement of large datasets by using the concept of transfer learning by pre-training the object detector on a simple artificial dataset and fine-tuning it on a tiny domain specific dataset."
            },
            "venue": {
                "fragments": [],
                "text": "ICIAR"
            },
            "year": 2020
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768769"
                        ],
                        "name": "F. Cesarini",
                        "slug": "F.-Cesarini",
                        "structuredName": {
                            "firstName": "Francesca",
                            "lastName": "Cesarini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Cesarini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3285734"
                        ],
                        "name": "S. Marinai",
                        "slug": "S.-Marinai",
                        "structuredName": {
                            "firstName": "Simone",
                            "lastName": "Marinai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Marinai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2608269"
                        ],
                        "name": "L. Sarti",
                        "slug": "L.-Sarti",
                        "structuredName": {
                            "firstName": "Lorenzo",
                            "lastName": "Sarti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Sarti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2540925"
                        ],
                        "name": "G. Soda",
                        "slug": "G.-Soda",
                        "structuredName": {
                            "firstName": "Giovanni",
                            "lastName": "Soda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Soda"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[3] used hierarchical representations based on the MXY tree for table detection and was the first attempt at using Machine Learning techniques for this problem."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1551166,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "56d3298d06b3eb5d479b33d8d9e59eff774965f4",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an approach for table location in document images. The documents are described by means of a hierarchical representation that is based on the MXY tree. The presence of a table is hypothesized by searching parallel lines in the MXY tree of the page. This hypothesis is afterwards verified by locating perpendicular lines or white spaces in the region included between the parallel lines. Lastly, located tables can be merged on the basis of proximity and similarity criteria. The use of an optimization method, that relies on the definition of an appropriate table location index, allows us to identify, the optimal values of thresholds involved in the algorithm. In this way the algorithm can be adapted to recognize tables with different features by maximizing the performance on an appropriate training set. The algorithm has been evaluated on two data-sets containing more than 1500 pages, and comparing its results with the tables identified by two commercial OCRs."
            },
            "slug": "Trainable-table-location-in-document-images-Cesarini-Marinai",
            "title": {
                "fragments": [],
                "text": "Trainable table location in document images"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "An approach for table location in document images is described by means of a hierarchical representation that is based on the MXY tree and the use of an optimization method allows us to identify the optimal values of thresholds involved in the algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "Object recognition supported by user interaction for service robots"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2990683"
                        ],
                        "name": "Ashwin Tengli",
                        "slug": "Ashwin-Tengli",
                        "structuredName": {
                            "firstName": "Ashwin",
                            "lastName": "Tengli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ashwin Tengli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35729970"
                        ],
                        "name": "Yiming Yang",
                        "slug": "Yiming-Yang",
                        "structuredName": {
                            "firstName": "Yiming",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiming Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2027866"
                        ],
                        "name": "Nianli Ma",
                        "slug": "Nianli-Ma",
                        "structuredName": {
                            "firstName": "Nianli",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nianli Ma"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[13] exploit the formatting cues from semistructured HTML tables to extract data from web pages."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9595306,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1ab39aa2e9ef711b6e35026b3270401dc1f6cc24",
            "isKey": false,
            "numCitedBy": 72,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Information extraction from tables in web pages is a challenging problem due to the diverse nature of table formats and the vocabulary variants in attribute names. This paper presents a new approach to automated table extraction that exploits formatting cues in semi-structured HTML tables, learns lexical variants from training examples and uses a vector space model to deal with non-exact matches among labels. We conducted experiments with this method on a set of tables collected from 157 university web sites, and obtained the information extraction performance of 91.4% in the Fl-measure, showing the effectiveness of the combined use of structural table parsing and example-based label learning."
            },
            "slug": "Learning-Table-Extraction-from-Examples-Tengli-Yang",
            "title": {
                "fragments": [],
                "text": "Learning Table Extraction from Examples"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new approach to automated table extraction that exploits formatting cues in semi-structured HTML tables, learns lexical variants from training examples and uses a vector space model to deal with non-exact matches among labels is presented."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743797"
                        ],
                        "name": "I. Guyon",
                        "slug": "I.-Guyon",
                        "structuredName": {
                            "firstName": "Isabelle",
                            "lastName": "Guyon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Guyon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694191"
                        ],
                        "name": "J. Hull",
                        "slug": "J.-Hull",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Hull",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hull"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 65
                            }
                        ],
                        "text": "Unfortunately, there are very few datasets like Marmot [17], UW3 [18], etc for table detection and even these contain only a few hundred images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 58317587,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a76e38292960c7fc7576463225938fe74131611",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Several significant sets of labeled samples of image data are surveyed that can be used in the development of algorithms for offline and online handwriting recognition as well as for machine printed text recognition. The method used to gather each data set, the numbers of samples they contain, and the associated truth data are discussed. In the domain of offline handwriting, the CEDAR, NIST, and CENPARMI data sets are pre\u00ad sented. These contain primarily isolated digits and alphabetic characters. The UNIPEN data set of online handwriting was collected from a number of independent sources and it contains individual characters as well as handwritten phrases. The University of Wash\u00ad ington document image databases are also discussed. They contain a large number of English and Japanese document images that were selected from a range of publications."
            },
            "slug": "DATA-SETS-FOR-OCR-AND-DOCUMENT-IMAGE-UNDERSTANDING-Guyon-Haralick",
            "title": {
                "fragments": [],
                "text": "DATA SETS FOR OCR AND DOCUMENT IMAGE UNDERSTANDING RESEARCH"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Several significant sets of labeled samples of image data are surveyed that can be used in the development of algorithms for offline and online handwriting recognition as well as for machine printed text recognition."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782282"
                        ],
                        "name": "Evan Shelhamer",
                        "slug": "Evan-Shelhamer",
                        "structuredName": {
                            "firstName": "Evan",
                            "lastName": "Shelhamer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Evan Shelhamer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117314646"
                        ],
                        "name": "Jonathan Long",
                        "slug": "Jonathan-Long",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Long",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Long"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[15], has demonstrated the accuracy of encoder-decoder network architectures for semantic segmentation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[15], encoderdecoder model for semantic segmentation."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1629541,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "317aee7fc081f2b137a85c4f20129007fd8e717e",
            "isKey": false,
            "numCitedBy": 15652,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, improve on the previous best result in semantic segmentation. Our key insight is to build \u201cfully convolutional\u201d networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet, the VGG net, and GoogLeNet) into fully convolutional networks and transfer their learned representations by fine-tuning to the segmentation task. We then define a skip architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional networks achieve improved segmentation of PASCAL VOC (30% relative improvement to 67.2% mean IU on 2012), NYUDv2, SIFT Flow, and PASCAL-Context, while inference takes one tenth of a second for a typical image."
            },
            "slug": "Fully-Convolutional-Networks-for-Semantic-Shelhamer-Long",
            "title": {
                "fragments": [],
                "text": "Fully Convolutional Networks for Semantic Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "It is shown that convolutional networks by themselves, trained end- to-end, pixels-to-pixels, improve on the previous best result in semantic segmentation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40019398"
                        ],
                        "name": "T. Kasar",
                        "slug": "T.-Kasar",
                        "structuredName": {
                            "firstName": "Thotreingam",
                            "lastName": "Kasar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kasar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32179591"
                        ],
                        "name": "Philippine Barlas",
                        "slug": "Philippine-Barlas",
                        "structuredName": {
                            "firstName": "Philippine",
                            "lastName": "Barlas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philippine Barlas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143680806"
                        ],
                        "name": "S\u00e9bastien Adam",
                        "slug": "S\u00e9bastien-Adam",
                        "structuredName": {
                            "firstName": "S\u00e9bastien",
                            "lastName": "Adam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S\u00e9bastien Adam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712446"
                        ],
                        "name": "Cl\u00e9ment Chatelain",
                        "slug": "Cl\u00e9ment-Chatelain",
                        "structuredName": {
                            "firstName": "Cl\u00e9ment",
                            "lastName": "Chatelain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cl\u00e9ment Chatelain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690399"
                        ],
                        "name": "T. Paquet",
                        "slug": "T.-Paquet",
                        "structuredName": {
                            "firstName": "Thierry",
                            "lastName": "Paquet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Paquet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[4] identified intersecting horizontal, vertical lines and low-level features and used an SVM classifier to classify an image region as a table region or not."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18367100,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a389e078d490bde455f9ba1e58902818598bd870",
            "isKey": false,
            "numCitedBy": 79,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method to detect table regions in document images by identifying the column and row line-separators and their properties. The method employs a run-length approach to identify the horizontal and vertical lines present in the input image. From each group of intersecting horizontal and vertical lines, a set of 26 low-level features are extracted and an SVM classifier is used to test if it belongs to a table or not. The performance of the method is evaluated on a heterogeneous corpus of French, English and Arabic documents that contain various types of table structures and compared with that of the Tesseract OCR system."
            },
            "slug": "Learning-to-Detect-Tables-in-Scanned-Document-Using-Kasar-Barlas",
            "title": {
                "fragments": [],
                "text": "Learning to Detect Tables in Scanned Document Images Using Line Information"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The performance of the method is evaluated on a heterogeneous corpus of French, English and Arabic documents that contain various types of table structures and compared with that of the Tesseract OCR system."
            },
            "venue": {
                "fragments": [],
                "text": "2013 12th International Conference on Document Analysis and Recognition"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3320897"
                        ],
                        "name": "T. Kieninger",
                        "slug": "T.-Kieninger",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kieninger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kieninger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145279674"
                        ],
                        "name": "A. Dengel",
                        "slug": "A.-Dengel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Dengel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dengel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 7
                            }
                        ],
                        "text": "T-Recs [11] was one of the earliest works to extract tabular data based on clustering of given word segments and overlap of the text inside the table."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 38477730,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc9c56918069b4648806219cfd93b6d35d3cfc27",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new approach to table structure recognition as well as to layout analysis. The discussed recognition process differs significantly from existing approaches as it realizes a bottom-up clustering of given word segments, whereas conventional table structure recognizers all rely on the detection of some separators such as delineation or significant white space to analyze a page from the top-down. The following analysis of the recognized layout elements is based on the construction of a tile structure and detects row- and/or column spanning cells as well as sparse tables with a high degree of confidence. \n \nThe overall system is completely domain independent, optionally neglects textual contents and can thus be applied to arbitrary mixed-mode documents (with or without tables) of any language and even operates on low quality OCR documents (e.g. facsimiles)."
            },
            "slug": "The-T-Recs-Table-Recognition-and-Analysis-System-Kieninger-Dengel",
            "title": {
                "fragments": [],
                "text": "The T-Recs Table Recognition and Analysis System"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A new approach to table structure recognition as well as to layout analysis that realizes a bottom-up clustering of given word segments, whereas conventional table structure recognizers all rely on the detection of some separators such as delineation or significant white space to analyze a page from the top-down."
            },
            "venue": {
                "fragments": [],
                "text": "Document Analysis Systems"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694279"
                        ],
                        "name": "D. Embley",
                        "slug": "D.-Embley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Embley",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Embley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145501780"
                        ],
                        "name": "Matthew F. Hurst",
                        "slug": "Matthew-F.-Hurst",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hurst",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew F. Hurst"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 86
                            }
                        ],
                        "text": "Most of these have reported results on table detection and data extraction separately [1]"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10215983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e8eb9090db385fd6fa77f02736f48d7c98a8d6a5",
            "isKey": false,
            "numCitedBy": 149,
            "numCiting": 110,
            "paperAbstract": {
                "fragments": [],
                "text": "Tables are a ubiquitous form of communication. While everyone seems to know what a table is, a precise, analytical definition of \u201ctabularity\u201d remains elusive because some bureaucratic forms, multicolumn text layouts, and schematic drawings share many characteristics of tables. There are significant differences between typeset tables, electronic files designed for display of tables, and tables in symbolic form intended for information retrieval. Most past research has addressed the extraction of low-level geometric information from raster images of tables scanned from printed documents, although there is growing interest in the processing of tables in electronic form as well. Recent research on table composition and table analysis has improved our understanding of the distinction between the logical and physical structures of tables, and has led to improved formalisms for modeling tables. This review, which is structured in terms of generalized paradigms for table processing, indicates that progress on half-a-dozen specific research issues would open the door to using existing paper and electronic tables for database update, tabular browsing, structured information retrieval through graphical and audio interfaces, multimedia table editing, and platform-independent display."
            },
            "slug": "Table-processing-paradigms:-a-research-survey-Embley-Hurst",
            "title": {
                "fragments": [],
                "text": "Table-processing paradigms: a research survey"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This review, which is structured in terms of generalized paradigms for table processing, indicates that progress on half-a-dozen specific research issues would open the door to using existing paper and electronic tables for database update, tabular browsing, structured information retrieval through graphical and audio interfaces, multimedia table editing, and platform-independent display."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Document Analysis and Recognition (IJDAR)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49915337"
                        ],
                        "name": "A. C. E. Silva",
                        "slug": "A.-C.-E.-Silva",
                        "structuredName": {
                            "firstName": "Ana",
                            "lastName": "Silva",
                            "middleNames": [
                                "Costa",
                                "e"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. C. E. Silva"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 101
                            }
                        ],
                        "text": "(a) Table Detection: Completeness and Purity are the two standard measures used in page segmentation [20]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 16510017,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "256074b71accf193ea742736bba0d498fdfa30c2",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Is an algorithm with high precision and recall at identifying table-parts also good at locating tables? Several document analysis tasks require merging or splitting certain document elements to form others. The suitability of the commonly used precision and recall for such division/aggregation tasks is arguable, since their underlying assumption is that the granularity of the items at input is the same as at output. We propose a new pair of evaluation metrics that better suit document analysis\u2019 needs and show their application to several table tasks. In the process, we present a number of robust table location algorithms with which we draw a road-map for creating Hidden Markov Models for the task."
            },
            "slug": "Metrics-for-evaluating-performance-in-document-to-Silva",
            "title": {
                "fragments": [],
                "text": "Metrics for evaluating performance in document analysis: application to tables"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A new pair of evaluation metrics are proposed that better suit document analysis\u2019 needs and show their application to several table tasks and a road-map for creating Hidden Markov Models for the task is drawn."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal on Document Analysis and Recognition (IJDAR)"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2494216"
                        ],
                        "name": "P. Pyreddy",
                        "slug": "P.-Pyreddy",
                        "structuredName": {
                            "firstName": "Pallavi",
                            "lastName": "Pyreddy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pyreddy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144456145"
                        ],
                        "name": "W. Bruce Croft",
                        "slug": "W.-Bruce-Croft",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Croft",
                            "middleNames": [
                                "Bruce"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Bruce Croft"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 7
                            }
                        ],
                        "text": "TINTIN [2] exploited structural information to identify tables and their component fields."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13991200,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d674f1289f336d88c4ab93e7204a345a302ed2eb",
            "isKey": false,
            "numCitedBy": 96,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Tables form an important kind of data element in text retrieval. Often, the gist of an entire news article or other exposition can be concisely captured in tabular form. In this paper, we examine the utility of exploiting information other than the key words in a digital document to provide the users with more flexible and powerful query capabilities. More specifically, we exploit the structural information in a document to identify tables and their component fields and let the users query based on these fields. Our empirical results have demonstrated that heuristic method based table extraction and component tagging can be performed effectively and efficiently. Moreover, our experiments in retrieval using the TINTIN system have strongly indicated that such structural decomposition can facilitate better representation of user\u2019s information needs and hence more effective retrieval of tables."
            },
            "slug": "TINTIN:-a-system-for-retrieval-in-text-tables-Pyreddy-Croft",
            "title": {
                "fragments": [],
                "text": "TINTIN: a system for retrieval in text tables"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper examines the utility of exploiting information other than the key words in a digital document to provide the users with more flexible and powerful query capabilities and demonstrates that heuristic method based table extraction and component tagging can be performed effectively and efficiently."
            },
            "venue": {
                "fragments": [],
                "text": "DL '97"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115625054"
                        ],
                        "name": "Yalin Wang",
                        "slug": "Yalin-Wang",
                        "structuredName": {
                            "firstName": "Yalin",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yalin Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[12] estimates probabilities from geometric measurements made on the various entities in a given document."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3351839,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a46ba896cdb3386f591db1a2d6172459f1bd2523",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Table-structure-understanding-and-its-performance-Wang-Phillips",
            "title": {
                "fragments": [],
                "text": "Table structure understanding and its performance evaluation"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1411006612"
                        ],
                        "name": "M\u00b7\u62c9\u65af\u79d1\u7ef4\u514b",
                        "slug": "M\u00b7\u62c9\u65af\u79d1\u7ef4\u514b",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "M\u00b7\u62c9\u65af\u79d1\u7ef4\u514b",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M\u00b7\u62c9\u65af\u79d1\u7ef4\u514b"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1415070104"
                        ],
                        "name": "N\u00b7\u6ce2\u5179\u8fbe\u91cc\u7ef4\u514b",
                        "slug": "N\u00b7\u6ce2\u5179\u8fbe\u91cc\u7ef4\u514b",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "N\u00b7\u6ce2\u5179\u8fbe\u91cc\u7ef4\u514b",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N\u00b7\u6ce2\u5179\u8fbe\u91cc\u7ef4\u514b"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1415072132"
                        ],
                        "name": "M\u00b7\u820d\u8212\u59c6",
                        "slug": "M\u00b7\u820d\u8212\u59c6",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "M\u00b7\u820d\u8212\u59c6",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M\u00b7\u820d\u8212\u59c6"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[7] made an attempt to detect borderless tables."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 140235593,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "be18b2b4c9f1fafb4a0239bec0138bba0f2c066c",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A borderless table detection engine and associated method for identifying borderless tables appearing in data extracted from a fixed format document. Due to the lack of visible borders, reliable automated detection of a borderless table is difficult. The borderless table detection engine uses whitespace, rather than content, to detect borderless table candidates. Applying heuristic analysis, the borderless table detection engine discards borderless table candidates with a layout that lacks sufficient characteristics of a table and is unlikely to be a valid borderless table."
            },
            "slug": "Borderless-table-detection-engine-M\u00b7\u62c9\u65af\u79d1\u7ef4\u514b-N\u00b7\u6ce2\u5179\u8fbe\u91cc\u7ef4\u514b",
            "title": {
                "fragments": [],
                "text": "Borderless table detection engine"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A borderless table detection engine and associated method for identifying borderless tables appearing in data extracted from a fixed format document that uses whitespace, rather than content, to detectborderless table candidates."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49915337"
                        ],
                        "name": "A. C. E. Silva",
                        "slug": "A.-C.-E.-Silva",
                        "structuredName": {
                            "firstName": "Ana",
                            "lastName": "Silva",
                            "middleNames": [
                                "Costa",
                                "e"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. C. E. Silva"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[5] modelled the joint probability distribution over sequential observations of visual page elements and the hidden state of a line (HMM) to merge potential table lines into tables resulted in a high degree of completeness."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7260147,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "166e2f3ff52620ffc975acca6281915995498605",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Hidden Markov Models (HMM) are probabilistic graphical models for interdependent classification. In this paper we experiment with different ways of combining the components of an HMM for document analysis applications, in particular for finding tables in text. We show: a) how to integrate different document structure finders into the HMM; b) that transition probabilities should vary along the chain to embed general knowledge axioms of our field, c) some emission energies can be selectively ignored, and d) emission and transition probabilities can be weighed differently. We conclude these changes increase the expressiveness and usability of HMMs in our field."
            },
            "slug": "Learning-Rich-Hidden-Markov-Models-in-Document-Silva",
            "title": {
                "fragments": [],
                "text": "Learning Rich Hidden Markov Models in Document Analysis: Table Location"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "This paper experiments with different ways of combining the components of an HMM for document analysis applications, in particular for finding tables in text, and shows how to integrate different document structure finders into the HMM."
            },
            "venue": {
                "fragments": [],
                "text": "2009 10th International Conference on Document Analysis and Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157708855"
                        ],
                        "name": "R. Smith",
                        "slug": "R.-Smith",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Smith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7038773,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "89d9aae7e0c8b6edd56d0d79b277c07b7ab66fda",
            "isKey": false,
            "numCitedBy": 1509,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The Tesseract OCR engine, as was the HP Research Prototype in the UNLV Fourth Annual Test of OCR Accuracy, is described in a comprehensive overview. Emphasis is placed on aspects that are novel or at least unusual in an OCR engine, including in particular the line finding, features/classification methods, and the adaptive classifier."
            },
            "slug": "An-Overview-of-the-Tesseract-OCR-Engine-Smith",
            "title": {
                "fragments": [],
                "text": "An Overview of the Tesseract OCR Engine"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The Tesseract OCR engine, as was the HP Research Prototype in the UNLV Fourth Annual Test of OCR Accuracy, is described in a comprehensive overview."
            },
            "venue": {
                "fragments": [],
                "text": "Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)"
            },
            "year": 2007
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 11,
            "methodology": 8
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 20,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/TableNet:-Deep-Learning-Model-for-End-to-end-Table-Paliwal-Vishwanath/d7284721854bd9db96a9e442caef0609d4324415?sort=total-citations"
}