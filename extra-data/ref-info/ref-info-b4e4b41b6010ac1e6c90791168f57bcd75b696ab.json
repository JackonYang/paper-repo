{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144854796"
                        ],
                        "name": "D. Gavrila",
                        "slug": "D.-Gavrila",
                        "structuredName": {
                            "firstName": "Dariu",
                            "lastName": "Gavrila",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gavrila"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 27
                            }
                        ],
                        "text": "Also, the support of Larry Davis (University of Maryland) and Franz May (Daimler-Benz, Ulm) is gratefully acknowledged."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 123
                            }
                        ],
                        "text": "Multi-camera whole-body tracking; the current pose of the 3-D mod is superimposed onto the four camera views (from Gavrila [25])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 196
                            }
                        ],
                        "text": ", tapering, bending) and local deformations on the superquadrics [7, 26, 43, 53, Figure 11 shows an example of human modeling based o pered superquadrics that was used for 3-D model-based trac in [25, 26]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "[30] Gavrila and Davis [25] [26] Frankeet al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 0
                            }
                        ],
                        "text": "Finally, Gavrila and Davis [25] [26] show initial results on whole-body tracking using four cameras placed in the corners of a room; see Figure 14."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 27
                            }
                        ],
                        "text": "Finally, Gavrila and Davis [25, 26] showed instances whole-body tracking using four cameras placed in the corn of a room."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 71
                            }
                        ],
                        "text": "speech recognition and more recently in matching human m ment patterns [10, 19, 25, 78]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 0
                            }
                        ],
                        "text": "Gavrila and Davis [26] use local search based on best- rst search."
                    },
                    "intents": []
                }
            ],
            "corpusId": 11295711,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "99b22537b071aa3c46367aed0952d97c67955833",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 106,
            "paperAbstract": {
                "fragments": [],
                "text": "The ability to recognize humans and their activities by vision is essential for future machines to interact intelligently and effortlessly with a human-inhabited environment. Some of the more promising applications are discussed. \nA prototype vision system is presented for the tracking of whole-body movement using multiple cameras. 3-D body pose is recovered at each time instant based on occluding contours. The pose-recovery problem is formulated as a search problem and entails finding the pose parameters of a graphical human model whose synthesized appearance is most similar to the actual appearance of the real human in the multi-view images. Hermite deformable contours are proposed as a tool for the 2-D contour tracking problem. \nThe main contribution of this dissertation is that it demonstrates for the first time a set of techniques that allow accurate vision-based 3-D tracking of arbitrary whole-body movement without the use of markers."
            },
            "slug": "Vision-based-3-D-tracking-of-humans-in-action-Gavrila",
            "title": {
                "fragments": [],
                "text": "Vision-based 3-D tracking of humans in action"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This dissertation demonstrates for the first time a set of techniques that allow accurate vision-based 3-D tracking of arbitrary whole-body movement without the use of markers."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1967104"
                        ],
                        "name": "David C. Hogg",
                        "slug": "David-C.-Hogg",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hogg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David C. Hogg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 26
                            }
                        ],
                        "text": "Finally, work by Heap and Hogg [31] involves an example-based approach\nto articulated pose recovery."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 93
                            }
                        ],
                        "text": "[38] Leung and Yang [48] Hoffman and Flinchbaugh [35] Johansson [39] Long and Yang [49] Hogg [36] Kjeldsen and Kender [44] Niyogi and Adelson [56] [57] Holt et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 149
                            }
                        ],
                        "text": "Instea uses the measurement equation directly to synthesize the m and uses a fitting measure between synthesized and observe tures for feedback; see [22, 26, 36, 46, 58, 64, 71]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 13
                            }
                        ],
                        "text": "Baumberg and Hogg [8] apply Active Shape Models to the tracking of pedestrians."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 91
                            }
                        ],
                        "text": "In terms of experimental results on whole (or upper bo ovement using a single camera, Hogg [36] and Rohr [71] d with the restricted movement of gait (parallel to image plan The movement is essentially in 2-D with no significant tors twist."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 90
                            }
                        ],
                        "text": "In terms of experimental results on whole (or upper body) movement using a single camera, Hogg [36] and Rohr [71] deal with the restricted movement of gait (parallel to image plane)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 9
                            }
                        ],
                        "text": "Heap and Hogg [31] show preliminary tracking results on hand model and hand pose recovery."
                    },
                    "intents": []
                }
            ],
            "corpusId": 34873540,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92f98b189cec1220d479e3079b942e71b244aa65",
            "isKey": true,
            "numCitedBy": 597,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Model-based-vision:-a-program-to-see-a-walking-Hogg",
            "title": {
                "fragments": [],
                "text": "Model-based vision: a program to see a walking person"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1890438"
                        ],
                        "name": "M. Leung",
                        "slug": "M.-Leung",
                        "structuredName": {
                            "firstName": "Maylor",
                            "lastName": "Leung",
                            "middleNames": [
                                "Karhang"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Leung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35964920"
                        ],
                        "name": "Yee-Hong Yang",
                        "slug": "Yee-Hong-Yang",
                        "structuredName": {
                            "firstName": "Yee-Hong",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yee-Hong Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 77
                            }
                        ],
                        "text": "Without a priori knowledge of the type of movement being performed, Long and Yang [49] track the limbs of a human silhouette by tracking antiparallel lines (apars)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "Leung and Yang [48] report progress on the general problem of segmenting, tracking and labeling of body parts from a silhouette of the human."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": "[38] Leung and Yang [48] Ho man and Flinchbaugh [35] Johansson [39] Long and Yang [49] Hogg [36] Kjeldsen and Kender [44] Niyogi and Adelson [56] [57] Holt et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12328952,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2582dd37d3011cf50dac8c2c400eda06a651900e",
            "isKey": false,
            "numCitedBy": 215,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "First Sight, a vision system in labeling the outline of a moving human body, is proposed in this paper. The emphasis of First Sight is on the analysis of motion information gathered solely from the outline of a moving human object. Two main processes are implemented in First Sight. The first process uses a novel technique to extract the outline of a moving human body from an image sequence. The second process, which employs a new human body model, interprets the outline and produces a labeled two-dimensional human body stick figure for each frame of the image sequence. Extensive knowledge of the structure, shape, and posture of the human body is used in the model. The experimental results of applying the technique on unedited image sequences with self-occlusions and missing boundary lines are encouraging. >"
            },
            "slug": "First-Sight:-A-Human-Body-Outline-Labeling-System-Leung-Yang",
            "title": {
                "fragments": [],
                "text": "First Sight: A Human Body Outline Labeling System"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "First Sight, a vision system in labeling the outline of a moving human body, is proposed in this paper and the experimental results of applying the technique on unedited image sequences with self-occlusions and missing boundary lines are encouraging."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2637837"
                        ],
                        "name": "Zen Chen",
                        "slug": "Zen-Chen",
                        "structuredName": {
                            "firstName": "Zen",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zen Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721539"
                        ],
                        "name": "Hsi-Jian Lee",
                        "slug": "Hsi-Jian-Lee",
                        "structuredName": {
                            "firstName": "Hsi-Jian",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hsi-Jian Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 194
                            }
                        ],
                        "text": "Baumberg and Hogg [8] Akita [3] Azarbayejani and Pentland [4] Bobick and Wilson [10] Cai and Aggarwal [11] Campbell and Bobick [13] Charayaphan and Marble [16] Chang and Huang [15] Chen and Lee [17] Cootes et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 0
                            }
                        ],
                        "text": "Chen and Lee's assumption of six known feature points on the head to start the procedure and the overhead of the interpretation tree makes their approach somewhat unappealing for practical applications."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 50
                            }
                        ],
                        "text": "The constraint propagation scheme of Chen and Lee [17] starts at the human head and continues via the torso to the limbs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 11
                            }
                        ],
                        "text": "Approaches [17] [37] [60] [74] [87], which use joint locations as features and assume these are given make strong assumptions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 39569986,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "8879d4878bb7edcc9c1aaf3b800e4f99de55f472",
            "isKey": true,
            "numCitedBy": 138,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "A computer vision method is presented to determine the 3-D spatial locations of joints or feature points of human body from a film recording the human motion during walking. The proposed method first applies the geometric projection theory to obtain a set of feasible postures from a single image, then it makes use of the given dimensions of the human stick figure, physiological and motion-specific knowledge to constrain the feasible postures in both the single-frame analysis and the multi-frame analysis. Finally a unique gait interpretation is selected by an optimization algorithm. Computer simulations are used to illustrate the ideas presented. >"
            },
            "slug": "Knowledge-guided-visual-perception-of-3-D-human-a-Chen-Lee",
            "title": {
                "fragments": [],
                "text": "Knowledge-guided visual perception of 3-D human gait from a single image sequence"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A computer vision method is presented to determine the 3-D spatial locations of joints or feature points of human body from a film recording the human motion during walking with a unique gait interpretation selected by an optimization algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Syst. Man Cybern."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740663"
                        ],
                        "name": "Francis K. H. Quek",
                        "slug": "Francis-K.-H.-Quek",
                        "structuredName": {
                            "firstName": "Francis",
                            "lastName": "Quek",
                            "middleNames": [
                                "K.",
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Francis K. H. Quek"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 86
                            }
                        ],
                        "text": "[84] Kahn and Swain [41] Polana and Nelson [65] Kakadiaris and Metaxas [42] [43] Quek [66] Kuch and Huang [46] Rangarajan et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 5
                            }
                        ],
                        "text": "Quek [66] has proposed using shape and motion features alternatively for the interpretation of hand-gestures."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 5
                            }
                        ],
                        "text": "Quek [66] has put this in the context of vision-based human-computer interfaces."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 13
                            }
                        ],
                        "text": "According to Quek, when the hand is in gross motion, the movements of the individual ngers are unimportant for gesture interpretation."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14228564,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "058e71e172f62838b8b0b13f9e7a9e20f509b1c0",
            "isKey": true,
            "numCitedBy": 164,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Eyes-in-the-interface-Quek",
            "title": {
                "fragments": [],
                "text": "Eyes in the interface"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2140461"
                        ],
                        "name": "W. Long",
                        "slug": "W.-Long",
                        "structuredName": {
                            "firstName": "Warren",
                            "lastName": "Long",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Long"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35964920"
                        ],
                        "name": "Yee-Hong Yang",
                        "slug": "Yee-Hong-Yang",
                        "structuredName": {
                            "firstName": "Yee-Hong",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yee-Hong Yang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 32110994,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "794b0a815bc50cb082b5f0cf40ac9607a94c9a74",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Motion provides extra information that can aid in the recognition of objects. One of the most commonly seen objects is, perhaps, the human body. Yet little attention has been paid to the analysis of human motion. One of the key steps required for a successful motion analysis system is the ability to track moving objects. In this paper, we describe a new system called Log-Tracker, which was recently developed for tracking the motion of the different parts of the human body. Occlusion of body parts is termed a forking condition. Two classes of forks as well as the attributes required to classify them are described. Experimental results from two gymnastics sequences indicate that the system is able to track the body parts even when they are occluded for a short period of time. Occlusions that extend for a long period of time still pose problems to Log-Tracker."
            },
            "slug": "Log-Tracker:-an-Attribute-Based-Approach-to-Human-Long-Yang",
            "title": {
                "fragments": [],
                "text": "Log-Tracker: an Attribute-Based Approach to Tracking Human Body Motion"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Experimental results from two gymnastics sequences indicate that the new Log-Tracker system is able to track the body parts even when they are occluded for a short period of time, and occlusion of body parts is termed a forking condition."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Pattern Recognit. Artif. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49540989"
                        ],
                        "name": "Lee W. Campbell",
                        "slug": "Lee-W.-Campbell",
                        "structuredName": {
                            "firstName": "Lee",
                            "lastName": "Campbell",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lee W. Campbell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688328"
                        ],
                        "name": "A. Bobick",
                        "slug": "A.-Bobick",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Bobick",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bobick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 127
                            }
                        ],
                        "text": "Baumberg and Hogg [8] Akita [3] Azarbayejani and Pentland [4] Bobick and Wilson [10] Cai and Aggarwal [11] Campbell and Bobick [13] Charayaphan and Marble [16] Chang and Huang [15] Chen and Lee [17] Cootes et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 71
                            }
                        ],
                        "text": "Relevant rotations are generally described by their three Euler angles [13] [76]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": "Campbell and Bobick [13] use a phase-space representation in which the velocity dimensions are projected out, discarding the time component of the data altogether."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3074726,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "32ce6157957a7ecc960a63327efd84de968bc9b5",
            "isKey": false,
            "numCitedBy": 373,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method for representing and recognizing human body movements is presented. The basic idea is to identify sets of constraints that are diagnostic of a movement: expressed using body-centered coordinates such as joint angles and in force only during a particular movement. Assuming the availability of Cartesian tracking data, we develop techniques for a representation of movements defined by space curves in subspaces of a \"phase space.\" The phase space has axes of joint angles and torso location and attitude, and the axes of the subspaces are subsets of the axes of the phase space. Using this representation we develop a system for learning new movements from ground truth data by searching for constraints. We then use the learned representation for recognizing movements in unsegmented data. We train and test the system on nine fundamental steps from classical ballet performed by two dancers; the system accurately recognizes the movements in the unsegmented stream of motion.<<ETX>>"
            },
            "slug": "Recognition-of-human-body-motion-using-phase-space-Campbell-Bobick",
            "title": {
                "fragments": [],
                "text": "Recognition of human body motion using phase space constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "A new method for representing and recognizing human body movements is presented, to identify sets of constraints that are diagnostic of a movement: expressed using body-centered coordinates such as joint angles only during a particular movement."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145286523"
                        ],
                        "name": "K. Rohr",
                        "slug": "K.-Rohr",
                        "structuredName": {
                            "firstName": "Karl",
                            "lastName": "Rohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Rohr"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 61
                            }
                        ],
                        "text": "[78] Rehg and Kanade [69] [70] Tamura and Kawasaki [79] Rohr [71] Turk [80] Shakunaga [74] Yamato et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 190
                            }
                        ],
                        "text": "Instead, it uses the measurement equation directly to synthesize the model and uses a tting measure between synthesized and observed features for feedback; see [22] [26] [36] [46] [58] [64] [71]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 129
                            }
                        ],
                        "text": "Another modeling choice has involved simple cylindrical primitives (possibly with elliptic XY-crosssections) [22] [29] [36] [51] [71]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 109
                            }
                        ],
                        "text": "In terms of experimental results on whole (or upper body) movement using a single camera, Hogg [36] and Rohr [71] deal with the restricted movement of gait (parallel to image plane)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 208
                            }
                        ],
                        "text": "Typical measures are correlation on a raw or smoothed LOG- ltered image [29] [70], perpendicular- [31] and chamfer-distance [26] (from projected model edges to image edges) and straight-line distance metrics [71]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 122238372,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92ab4fc76e2f085dde81626794b79b5e9d1d00e0",
            "isKey": true,
            "numCitedBy": 491,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract The interpretation of the movements of articulated bodies in image sequences is one of the most challenging problems in computer vision. In this contribution, we introduce a model-based approach for the recognition of pedestrians. We represent the human body by a 3D-model consisting of cylinders, whereas for modelling the movement of walking we use data from medical motion studies. The estimation of model parameters in consecutive images is done by applying a Kalman filter. Experimental results are shown for synthetic as well as for real image data."
            },
            "slug": "Towards-model-based-recognition-of-human-movements-Rohr",
            "title": {
                "fragments": [],
                "text": "Towards model-based recognition of human movements in image sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A model-based approach for the recognition of pedestrians is introduced and the human body is represented by a 3D-model consisting of cylinders, whereas for modelling the movement of walking the authors use data from medical motion studies."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053178525"
                        ],
                        "name": "G. Johansson",
                        "slug": "G.-Johansson",
                        "structuredName": {
                            "firstName": "Gunnar",
                            "lastName": "Johansson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Johansson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 54046837,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "58ea2fa0580b2117618be6e1cc9658a5c9531dba",
            "isKey": false,
            "numCitedBy": 4094,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper reports the first phase of a research program on visual perception of motion patterns characteristic of living organisms in locomotion. Such motion patterns in animals and men are termed here as biological motion. They are characterized by a far higher degree of complexity than the patterns of simple mechanical motions usually studied in our laboratories. In everyday perceptions, the visual information from biological motion and from the corresponding figurative contour patterns (the shape of the body) are intermingled. A method for studying information from the motion pattern per se without interference with the form aspect was devised. In short, the motion of the living body was represented by a few bright spots describing the motions of the main joints. It is found that 10\u201312 such elements in adequate motion combinations in proximal stimulus evoke a compelling impression of human walking, running, dancing, etc. The kinetic-geometric model for visual vector analysis originally developed in the study of perception of motion combinations of the mechanical type was applied to these biological motion patterns. The validity of this model in the present context was experimentally tested and the results turned out to be highly positive."
            },
            "slug": "Visual-perception-of-biological-motion-and-a-model-Johansson",
            "title": {
                "fragments": [],
                "text": "Visual perception of biological motion and a model for its analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The kinetic-geometric model for visual vector analysis originally developed in the study of perception of motion combinations of the mechanical type was applied to biological motion patterns and the results turned out to be highly positive."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2739350"
                        ],
                        "name": "R. Kjeldsen",
                        "slug": "R.-Kjeldsen",
                        "structuredName": {
                            "firstName": "Rick",
                            "lastName": "Kjeldsen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kjeldsen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719062"
                        ],
                        "name": "J. Kender",
                        "slug": "J.-Kender",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Kender",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kender"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 117
                            }
                        ],
                        "text": "[38] Leung and Yang [48] Ho man and Flinchbaugh [35] Johansson [39] Long and Yang [49] Hogg [36] Kjeldsen and Kender [44] Niyogi and Adelson [56] [57] Holt et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 54
                            }
                        ],
                        "text": "Both Darell and Pentland [19] and Kjeldsen and Kender [44] use the image pixels directly as input."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6230444,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b9ad447ec3a5aed79ba8d1b04abda29f6a05802",
            "isKey": false,
            "numCitedBy": 118,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "This work describes the design of a functioning user interface based on visual recognition of hand gestures, and details its performance. In the interface, gesture replaces the mouse for many actions including selecting, moving and resizing windows. A camera below the screen observes the user. The hand is segmented from the background using color. Features of the hand's motion are extracted from the sequence of segmented images, and when needed the hand's pose is classified using a neural net. This information is parsed by a task specific grammar. The system runs in real time on standard PC hardware. It has demonstrated its abilities with various users in several different office environments. Having experimented with a functioning gestural interface, the authors discuss the practicality and best applications of this technology."
            },
            "slug": "Toward-the-use-of-gesture-in-traditional-user-Kjeldsen-Kender",
            "title": {
                "fragments": [],
                "text": "Toward the use of gesture in traditional user interfaces"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "The design of a functioning user interface based on visual recognition of hand gestures, and its performance is described, and the authors discuss the practicality and best applications of this technology."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Second International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2652428"
                        ],
                        "name": "R. Polana",
                        "slug": "R.-Polana",
                        "structuredName": {
                            "firstName": "Ramprasad",
                            "lastName": "Polana",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Polana"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113399896"
                        ],
                        "name": "R. Nelson",
                        "slug": "R.-Nelson",
                        "structuredName": {
                            "firstName": "Randall",
                            "lastName": "Nelson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nelson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "Polana and Nelson [65] detect periodic activity such as persons walking lateral to the viewing direction using spatio-temporal templates."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 70
                            }
                        ],
                        "text": "In other cases, the application involved seemingly complex activities [65] [77] with no straightforward recognition solution."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 161
                            }
                        ],
                        "text": "In each tile of the grid a simple feature is computed, and these features are combined\nto form a K K feature vector to describe the state of movement at time t. Polana and Nelson [65] use the sum of the normal ow (see Figure 1), Yamamoto et al. [86] use the number of foreground pixels and Takahashi et al. [78] de ne an average edge vector for each tile."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "Polana and Nelson [65] refer to \\getting your man without nding his body parts\"."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "Polana and Nelson [65] use the sum of the normal ow (see Figure 1), Yamamoto et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 43
                            }
                        ],
                        "text": "[84] Kahn and Swain [41] Polana and Nelson [65] Kakadiaris and Metaxas [42] [43] Quek [66] Kuch and Huang [46] Rangarajan et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 129
                            }
                        ],
                        "text": "For the above systems, action classi cation is based on hard-coded decision trees [16] [20] [79], nearest neighbor criteria [38] [65] or is based on general pattern matching techniques for time-varying data, as described in Section 6."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 0
                            }
                        ],
                        "text": "Polana and Nelson also describe a technique to deal with the more complex case of a moving camera and/or multiple (overlapping) objects, based on detecting and tracking independently moving objects."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6353138,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "1ee01bf96b5dbd441eabda533fa89da3fa4d916a",
            "isKey": true,
            "numCitedBy": 371,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The recognition of human movements such as walking, running or climbing has been approached previously by tracking a number of feature points and either classifying the trajectories directly or matching them with a high-level model of the movement. A major difficulty with these methods is acquiring and trading the requisite feature points, which are generally specific joints such as knees or angles. This requires previous recognition and/or part segmentation of the actor. We show that the recognition of walking or any repetitive motion activity can be accomplished on the basis of bottom up processing, which does not require the prior identification of specific parts, or classification of the actor. In particular, we demonstrate that repetitive motion is such a strong cue, that the moving actor can be segmented, normalized spatially and temporally, and recognized by matching against a spatiotemporal template of motion features. We have implemented a real-time system that can recognize and classify repetitive motion activities in normal gray-scale image sequences.<<ETX>>"
            },
            "slug": "Low-level-recognition-of-human-motion-(or-how-to-Polana-Nelson",
            "title": {
                "fragments": [],
                "text": "Low level recognition of human motion (or how to get your man without finding his body parts)"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is demonstrated that repetitive motion is such a strong cue, that the moving actor can be segmented, normalized spatially and temporally, and recognized by matching against a spatiotemporal template of motion features."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1994 IEEE Workshop on Motion of Non-rigid and Articulated Objects"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1917469"
                        ],
                        "name": "Shanon X. Ju",
                        "slug": "Shanon-X.-Ju",
                        "structuredName": {
                            "firstName": "Shanon",
                            "lastName": "Ju",
                            "middleNames": [
                                "X."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shanon X. Ju"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1964574"
                        ],
                        "name": "Y. Yacoob",
                        "slug": "Y.-Yacoob",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Yacoob",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Yacoob"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[40] use a parametrized motion model to analyze gait constrained to a plane."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5170789,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8e3b20fb94803d71910043059f402554aa5137b2",
            "isKey": false,
            "numCitedBy": 522,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We extend the work of Black and Yacoob (1995) on the tracking and recognition of human facial expressions using parametrized models of optical flow to deal with the articulated motion of human limbs. We define a \"card-board person model\" in which a person's limbs are represented by a set of connected planar patches. The parametrized image motion of these patches in constrained to enforce articulated motion and is solved for directly using a robust estimation technique. The recovered motion parameters provide a rich and concise description of the activity that can be used for recognition. We propose a method for performing view-based recognition of human activities from the optical flow parameters that extends previous methods to cope with the cyclical nature of human motion. We illustrate the method with examples of tracking human legs of long image sequences."
            },
            "slug": "Cardboard-people:-a-parameterized-model-of-image-Ju-Black",
            "title": {
                "fragments": [],
                "text": "Cardboard people: a parameterized model of articulated image motion"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A method for performing view-based recognition of human activities from the optical flow parameters that extends previous methods to cope with the cyclical nature of human motion is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Second International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1798094"
                        ],
                        "name": "A. Downton",
                        "slug": "A.-Downton",
                        "structuredName": {
                            "firstName": "Andy",
                            "lastName": "Downton",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Downton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2084976155"
                        ],
                        "name": "H. Drouet",
                        "slug": "H.-Drouet",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Drouet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Drouet"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 160
                            }
                        ],
                        "text": "Instead, it uses the measurement equation directly to synthesize the model and uses a tting measure between synthesized and observed features for feedback; see [22] [26] [36] [46] [58] [64] [71]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 109
                            }
                        ],
                        "text": "Another modeling choice has involved simple cylindrical primitives (possibly with elliptic XY-crosssections) [22] [29] [36] [51] [71]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 19
                            }
                        ],
                        "text": "Downton and Drouet [22] attempt to track unconstrained upper-body motion but must conclude that tracking gets lost due to propagation of errors."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 86
                            }
                        ],
                        "text": "[18] Geurtz [27] Dorner [21] Darell and Pentland [19] Goddard [28] Downton and Drouet [22] Davis and Shah [20] Guo et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60614552,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3b0134c456a71f20dfd2033a720254fd8e39cf2c",
            "isKey": true,
            "numCitedBy": 24,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent research on model-based image coding for videotelephone and videoconferencing applications has mostly been concerned with head motion tracking and typically represents the human head as a 3D wire-frame model with texture-mapped surface features. However, the movements of the arms and hands are also important, particularly in sign language communication, and therefore should be included in the overall model. The paper describes a system which uses an articulated generalised cylindrical human model to track limb movements in a sequence of images. It outlines the closed-loop strategy developed to recognise and track human body motion and presents initial results for a complete implementation of the system."
            },
            "slug": "Model-based-image-analysis-for-unconstrained-human-Downton-Drouet",
            "title": {
                "fragments": [],
                "text": "Model-based image analysis for unconstrained human upper-body motion"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A system which uses an articulated generalised cylindrical human model to track limb movements in a sequence of images to recognise and track human body motion is described."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052391642"
                        ],
                        "name": "J. O'Rourke",
                        "slug": "J.-O'Rourke",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "O'Rourke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. O'Rourke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699200"
                        ],
                        "name": "N. Badler",
                        "slug": "N.-Badler",
                        "structuredName": {
                            "firstName": "Norman",
                            "lastName": "Badler",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Badler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15680007,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9df0428c30b8aab4f7e6f367e70126efdfb8fc45",
            "isKey": false,
            "numCitedBy": 516,
            "numCiting": 112,
            "paperAbstract": {
                "fragments": [],
                "text": "A system capable of analyzing image sequences of human motion is described. The system is structured as a feedback loop between high and low levels: predictions are made at the semantic level and verifications are sought at the image level. The domain of human motion lends itself to a model-driven analysis, and the system includes a detailed model of the human body. All information extracted from the image is interpreted through a constraint network based on the structure of the human model. A constraint propagation operator is defined and its theoretical properties outlined. An implementation of this operator is described, and results of the analysis system for short image sequences are presented."
            },
            "slug": "Model-based-image-analysis-of-human-motion-using-O'Rourke-Badler",
            "title": {
                "fragments": [],
                "text": "Model-based image analysis of human motion using constraint propagation"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A system capable of analyzing image sequences of human motion is described, structured as a feedback loop between high and low levels: predictions are made at the semantic level and verifications are sought at the image level."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144854796"
                        ],
                        "name": "D. Gavrila",
                        "slug": "D.-Gavrila",
                        "structuredName": {
                            "firstName": "Dariu",
                            "lastName": "Gavrila",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gavrila"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693428"
                        ],
                        "name": "L. Davis",
                        "slug": "L.-Davis",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Davis",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Davis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Baumberg and Hogg [8] Akita [3] Azarbayejani and Pentland [4] Bobick and Wilson [10] Cai and Aggarwal [11] Campbell and Bobick [13] Charayaphan and Marble [16] Chang and Huang [15] Chen and Lee [17] Cootes et al. [18] Geurtz [27] Dorner [21] Darell and Pentland [19] Goddard [28] Downton and Drouet [22] Davis and Shah [20] Guo et al. [30] Gavrila and Davis [25] [ 26 ] Franke et al. [23] Herman [34] Goncalves et al. [29] Freeman et al. [24] Ju ..."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Some of the combinatoric pose-recovery approaches have also been applied to the multi-camera case, in simulations [58] and with real data [ 26 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The benefit of using multiple cameras to achieve tighter 3-D pose recovery has been quite evident [ 26 , 43, 69]; body poses and movements that are ambiguous from one view (by occlusion or depth) can be disambiguated from another view."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Typical measures are correlation on a raw or smoothed LOG-filtered image [29, 70], perpendicular- [31] and chamfer-distance [ 26 ] (from projected model edges to image edges) and straight-line distance metrics [71]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Figure 11 shows an example of human modeling based on tapered superquadrics that was used for 3-D model-based tracking in [25,  26 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Some work has dealt with this issue by decoupling model acquisition and pose recovery, i.e., requiring a separate initialization stage where either known poses [ 26 ] or known movements [42] simplify the acquisition of the shape parameters."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Instead, it uses the measurement equation directly to synthesize the model and uses a fitting measure between synthesized and observed features for feedback; see [22,  26 , 36, 46, 58, 64, 71]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Additional flexibility can be achieved by allowing global deformations (e.g., tapering, bending) and/or local deformations on the superquadrics [7,  26 , 43, 53, 62]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "FIG. 11. 3-D human models \u201cELLEN\u201d and \u201cDARIU\u201d using tapered superquadrics (from Gavrila and Davis [ 26 ], c \u221e 1995 IEEE)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Gavrila and Davis [ 26 ] used local search based on best-first search."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "FIG. 15. Will the Argentine Tango be danced in virtual reality? (from Gavrila and Davis [ 26 ], c \u221e 1996 IEEE)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Finally, Gavrila and Davis [25,  26 ] showed instances of whole-body tracking using four cameras placed in the corners of a room."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5697345,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cc9b263c1af95ea803c4f5c8888ef8e37f0cef80",
            "isKey": false,
            "numCitedBy": 818,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a vision system for the 3-D model-based tracking of unconstrained human movement. Using image sequences acquired simultaneously from multiple views, we recover the 3-D body pose at each time instant without the use of markers. The pose-recovery problem is formulated as a search problem and entails finding the pose parameters of a graphical human model whose synthesized appearance is most similar to the actual appearance of the real human in the multi-view images. The models used for this purpose are acquired from the images. We use a decomposition approach and a best-first technique to search through the high dimensional pose parameter space. A robust variant of chamfer matching is used as a fast similarity measure between synthesized and real edge images. We present initial tracking results from a large new Humans-in-Action (HIA) database containing more than 2500 frames in each of four orthogonal views. They contain subjects involved in a variety of activities, of various degrees of complexity, ranging from the more simple one-person hand waving to the challenging two-person close interaction in the Argentine Tango."
            },
            "slug": "3-D-model-based-tracking-of-humans-in-action:-a-Gavrila-Davis",
            "title": {
                "fragments": [],
                "text": "3-D model-based tracking of humans in action: a multi-view approach"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A vision system for the 3-D model-based tracking of unconstrained human movement and initial tracking results from a large new Humans-in-Action database containing more than 2500 frames in each of four orthogonal views are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144097660"
                        ],
                        "name": "M. Turk",
                        "slug": "M.-Turk",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Turk",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Turk"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2197125,
            "fieldsOfStudy": [
                "Computer Science",
                "Art"
            ],
            "id": "2c7d0d5b6ec8e02225c54806efa519d0e2d28ad5",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper explores the use of fast, simple computer vision techniques to add compelling visual capabilities to social user interfaces. Social interfaces involve the user in natural dialog with animated, \"lifelike\" characters. However, current systems employ spoken language as the only input modality. Used effectively, vision can greatly enhance the user's experience interacting with these characters. In addition, vision can provide key information to help manage the dialog and to aid the speech recognition process. We describe constraints imposed by the conversational environment and present a set of \"interactive-time\" vision routines that begin to support the user's expectations of a seeing character. A control structure is presented which chooses among the vision routines based on the current state of the character, the conversation and the visual environment. These capabilities are beginning to be integrated into the Persona lifelike character project."
            },
            "slug": "Visual-interaction-with-lifelike-characters-Turk",
            "title": {
                "fragments": [],
                "text": "Visual interaction with lifelike characters"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "This paper explores the use of fast, simple computer vision techniques to add compelling visual capabilities to social user interfaces and presents a set of \"interactive-time\" vision routines that begin to support the user's expectations of a seeing character."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Second International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144383434"
                        ],
                        "name": "Robert J. Holt",
                        "slug": "Robert-J.-Holt",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Holt",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert J. Holt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3317551"
                        ],
                        "name": "A. Netravali",
                        "slug": "A.-Netravali",
                        "structuredName": {
                            "firstName": "Arun",
                            "lastName": "Netravali",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Netravali"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717217"
                        ],
                        "name": "R. J. Qian",
                        "slug": "R.-J.-Qian",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Qian",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. J. Qian"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[37] provide a constraint propagation scheme for human gait, where one joint remains at a xed location."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 16
                            }
                        ],
                        "text": "Approaches [17] [37] [60] [74] [87], which use joint locations as features and assume these are given make strong assumptions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6072138,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3e59af82cbca49d3c0072748efc6cca455472fff",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem is to estimate the 3D motion of an articulated object, such as a robot arm or a human body, from a monocular sequence of 2D perspective views. We advocate an approach of decomposition. The object is decomposed into simpler parts, each containing a small number of links. We estimate the motion of the simplest part(s) and then propagate the analysis to the remaining parts of the object. Human gait is used as an example; however, the approach is general. To use this approach, we need results for the motion of simple articulated objects, motion estimation algorithms, and the number of solutions (especially, how many views are needed for uniqueness). With the help of algebraic geometry, we have results for a number of cases which are particularly useful for human gait analysis.<<ETX>>"
            },
            "slug": "Determining-articulated-motion-from-perspective-a-Holt-Huang",
            "title": {
                "fragments": [],
                "text": "Determining articulated motion from perspective views: a decomposition approach"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "With the help of algebraic geometry, this work has results for a number of cases which are particularly useful for human gait analysis, and needs results for the motion of simple articulated objects, motion estimation algorithms, and the number of solutions."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1994 IEEE Workshop on Motion of Non-rigid and Articulated Objects"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144248008"
                        ],
                        "name": "K. Akita",
                        "slug": "K.-Akita",
                        "structuredName": {
                            "firstName": "Koichiro",
                            "lastName": "Akita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Akita"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 28
                            }
                        ],
                        "text": "Baumberg and Hogg [8] Akita [3] Azarbayejani and Pentland [4] Bobick and Wilson [10] Cai and Aggarwal [11] Campbell and Bobick [13] Charayaphan and Marble [16] Chang and Huang [15] Chen and Lee [17] Cooteset al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 94
                            }
                        ],
                        "text": "An early attempt to segment and track body parts under m general conditions was made by Akita [3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 90
                            }
                        ],
                        "text": "An early attempt to segment and track body parts under more general conditions is made by Akita [3]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 33099756,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c74c4ee1466a7c083ab70fdccfbb3e4e4226c364",
            "isKey": false,
            "numCitedBy": 207,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Image-sequence-analysis-of-real-world-human-motion-Akita",
            "title": {
                "fragments": [],
                "text": "Image sequence analysis of real world human motion"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2155598311"
                        ],
                        "name": "Yan Guo",
                        "slug": "Yan-Guo",
                        "structuredName": {
                            "firstName": "Yan",
                            "lastName": "Guo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yan Guo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110690761"
                        ],
                        "name": "Gang Xu",
                        "slug": "Gang-Xu",
                        "structuredName": {
                            "firstName": "Gang",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gang Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143873014"
                        ],
                        "name": "S. Tsuji",
                        "slug": "S.-Tsuji",
                        "structuredName": {
                            "firstName": "Saburo",
                            "lastName": "Tsuji",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Tsuji"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 117
                            }
                        ],
                        "text": "A less investigated but equally interesting approach for matching time-varying data is given by Neural Networks (NN) [30] [72]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[30] Gavrila and Davis [25] [26] Franke et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 46947080,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "25ba7cc4fed70ddf865870013557db1a1da4e451",
            "isKey": false,
            "numCitedBy": 152,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the recognition of human motion patterns. We represent the human body structure in the silhouette by a stick figure model. The human motion, thus, can be recorded as a sequence of the stick figure parameters, which can be used as input of a motion pattern analyzer. The recognition of human motion pattern is divided into two stages. In the first stage, a model-driven approach is used to track human motions. This is, in fact, finding the stick figure model which represents the human silhouette in each frame. In the second stage, a BP neural network classifies motions of the stick figures into three categories: walking, running and other motions. We transform the time sequence of stick figure parameters into Fourier domain by DFT, and use only the first four Fourier components as the input of the neural network."
            },
            "slug": "Understanding-human-motion-patterns-Guo-Xu",
            "title": {
                "fragments": [],
                "text": "Understanding human motion patterns"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The human motion can be recorded as a sequence of the stick figure parameters, which can be used as input of a motion pattern analyzer, when recognition of human motion patterns is addressed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 12th IAPR International Conference on Pattern Recognition, Vol. 3 - Conference C: Signal Processing (Cat. No.94CH3440-5)"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1995364"
                        ],
                        "name": "Claudette C\u00e9dras",
                        "slug": "Claudette-C\u00e9dras",
                        "structuredName": {
                            "firstName": "Claudette",
                            "lastName": "C\u00e9dras",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Claudette C\u00e9dras"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145103012"
                        ],
                        "name": "M. Shah",
                        "slug": "M.-Shah",
                        "structuredName": {
                            "firstName": "Mubarak",
                            "lastName": "Shah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Shah"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 124
                            }
                        ],
                        "text": "Earlier reviews on non-rigid motion, motion-based recognition and gesture interpretation were given by Aggarwal et al. [1], Cedras and Shah [14] and Pavlovic, Sharma and Huang [61], respectively."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 21
                            }
                        ],
                        "text": "[1], Cedras and Shah [14] and Pavlovic, Sharma and Huang [61], respectively."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15425663,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c53c98734b05b640d8ca14ee4835c88b6e9dbb4",
            "isKey": false,
            "numCitedBy": 509,
            "numCiting": 84,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Motion-based-recognition-a-survey-C\u00e9dras-Shah",
            "title": {
                "fragments": [],
                "text": "Motion-based recognition a survey"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772763"
                        ],
                        "name": "E. Bernardo",
                        "slug": "E.-Bernardo",
                        "structuredName": {
                            "firstName": "Enrico",
                            "lastName": "Bernardo",
                            "middleNames": [
                                "Di"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Bernardo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149680415"
                        ],
                        "name": "L. Goncalves",
                        "slug": "L.-Goncalves",
                        "structuredName": {
                            "firstName": "Luis",
                            "lastName": "Goncalves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Goncalves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46614172"
                        ],
                        "name": "Enrico Ursella",
                        "slug": "Enrico-Ursella",
                        "structuredName": {
                            "firstName": "Enrico",
                            "lastName": "Ursella",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Enrico Ursella"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 49
                            }
                        ],
                        "text": "One approach using such parametrized models [21] [29] [69] [70] [81] [85] [87] updates pose by inverse kinematics, a common technique in robot control theory [76]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 114
                            }
                        ],
                        "text": "Another modeling choice has involved simple cylindrical primitives (possibly with elliptic XY-crosssections) [22] [29] [36] [51] [71]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 72
                            }
                        ],
                        "text": "Typical measures are correlation on a raw or smoothed LOG- ltered image [29] [70], perpendicular- [31] and chamfer-distance [26] (from projected model edges to image edges) and straight-line distance metrics [71]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 19164875,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "7d91d26d47289d5633693cb6e91cb23b26195486",
            "isKey": false,
            "numCitedBy": 266,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of estimating the position and motion of a human arm in 3D without any constraints on its behavior and without the use of special markers. We model the arm as two truncated right-circular cones connected with spherical joints. We propose to use a recursive estimator for arm position, and to provide the estimator with error signals obtained by comparing the projected estimated arm position with that of the actual arm in the image. The system is demonstrated and tested on a real image sequence.<<ETX>>"
            },
            "slug": "Monocular-tracking-of-the-human-arm-in-3D-Bernardo-Goncalves",
            "title": {
                "fragments": [],
                "text": "Monocular tracking of the human arm in 3D"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work proposes to use a recursive estimator for arm position, and to provide the estimator with error signals obtained by comparing the projected estimated arm position with that of the actual arm in the image."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2074973893"
                        ],
                        "name": "N. Goddard",
                        "slug": "N.-Goddard",
                        "structuredName": {
                            "firstName": "Nigel",
                            "lastName": "Goddard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Goddard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 8
                            }
                        ],
                        "text": "Goddard [28] represents activities by scenarios: a sequence of events with enabling conditions, and time constraints between successive events."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 62
                            }
                        ],
                        "text": "[18] Geurtz [27] Dorner [21] Darell and Pentland [19] Goddard [28] Downton and Drouet [22] Davis and Shah [20] Guo et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 58103262,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5057d6fe214435b6df4e54c7e071a910676d2675",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Discrimination of articulated movement is a central problem in perception. We present a model-based system designed to discriminate articulated movements and demonstrate its capabilities in distinguishing three human gaits. Recognition proceeds directly from uninterpreted visual motion features. The adaptive model of movement, the scenario, is based on discrete parameterized events separated by parameterized time intervals. Experimental results are shown for real data derived from moving light displays, demonstrating the effectiveness of the structured connectionist approach.<<ETX>>"
            },
            "slug": "Incremental-model-based-discrimination-of-movement-Goddard",
            "title": {
                "fragments": [],
                "text": "Incremental model-based discrimination of articulated movement from motion features"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This work presents a model-based system designed to discriminate articulated movements and demonstrates its capabilities in distinguishing three human gaits, based on discrete parameterized events separated by parameterized time intervals."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1994 IEEE Workshop on Motion of Non-rigid and Articulated Objects"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145650177"
                        ],
                        "name": "I. Chang",
                        "slug": "I.-Chang",
                        "structuredName": {
                            "firstName": "I-Cheng",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793389"
                        ],
                        "name": "Chung-Lin Huang",
                        "slug": "Chung-Lin-Huang",
                        "structuredName": {
                            "firstName": "Chung-Lin",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chung-Lin Huang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 15
                            }
                        ],
                        "text": "See Aizawa and Huang [2] for a good overview."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 16
                            }
                        ],
                        "text": "Chang and Huang [15] detect ribbons corresponding to the arms and feet."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 176
                            }
                        ],
                        "text": "Baumberg and Hogg [8] Akita [3] Azarbayejani and Pentland [4] Bobick and Wilson [10] Cai and Aggarwal [11] Campbell and Bobick [13] Charayaphan and Marble [16] Chang and Huang [15] Chen and Lee [17] Cootes et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 9
                            }
                        ],
                        "text": "Kuch and Huang [46] use a greedy search strategy based on perturbation of individual state parameters."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 170
                            }
                        ],
                        "text": "Earlier reviews on non-rigid motion, motion-based recognition and gesture interpretation were given by Aggarwal et al. [1], Cedras and Shah [14] and Pavlovic, Sharma and Huang [61], respectively."
                    },
                    "intents": []
                }
            ],
            "corpusId": 206842578,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "58216fff3890e8b14fb4c57f252716fcf1b969b5",
            "isKey": true,
            "numCitedBy": 20,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces a ribbon-based motion analysis approach to describe human body movements. Here, we assume that there are no markers on human body. We develop a system to extract the moving ribbons (extremities) by processing the difference between current image frame and reference image frame. By analyzing the moving ribbons on the key frames, we may produce the motion parameter curves for each joint on the ribbon. These curves may not be continuous due to ribbon-torso occlusion, and both the interpolation and extrapolation processes can be used to predict the missing parts."
            },
            "slug": "Ribbon-based-motion-analysis-of-human-body-Chang-Huang",
            "title": {
                "fragments": [],
                "text": "Ribbon-based motion analysis of human body movements"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A system to extract the moving ribbons (extremities) by processing the difference between current image frame and reference image frame is developed and may produce the motion parameter curves for each joint on the ribbon."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 13th International Conference on Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706204"
                        ],
                        "name": "I. Kakadiaris",
                        "slug": "I.-Kakadiaris",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Kakadiaris",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Kakadiaris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711560"
                        ],
                        "name": "Dimitris N. Metaxas",
                        "slug": "Dimitris-N.-Metaxas",
                        "structuredName": {
                            "firstName": "Dimitris",
                            "lastName": "Metaxas",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dimitris N. Metaxas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 91
                            }
                        ],
                        "text": "requiring a separate initialization stage where either known poses [26] or known movements [42] simplify the acquisition of the shape parameters."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 71
                            }
                        ],
                        "text": "[84] Kahn and Swain [41] Polana and Nelson [65] Kakadiaris and Metaxas [42] [43] Quek [66] Kuch and Huang [46] Rangarajan et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 0
                            }
                        ],
                        "text": "Kakadiaris and Metaxas [43] track one arm using three orthogonal cameras."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 17
                            }
                        ],
                        "text": "Although work in [42] represents a step forward on this matter, no approach has been provided that can recover both shape and pose parameters from uncontrolled movement, e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "Kakadiaris and Metaxas [42] [43] use a physics-based approach where various forces act on the di erent parts to align them with the image data; constraint forces enforce point-to-point connectivity between the parts."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15850434,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3108574e200023a5eda434dd0f7057f4bad8212a",
            "isKey": true,
            "numCitedBy": 224,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel motion-based approach for the part determination and shape estimation of a human's body parts. The novelty of the technique is that neither a prior model of the human body is employed nor prior body part segmentation is assumed. We present a human body part identification strategy (HBPIS) that recovers all the body parts of a moving human based on the spatiotemporal analysis of its deforming silhouette. We formalize the process of simultaneous part determination and 2D shape estimation by employing the supervisory control theory of discrete event systems. In addition, in order to acquire the 3D shape of the body parts, we present a new algorithm which selectively integrates the (segmented by the HBPIS) apparent contours, from three mutually orthogonal views. The effectiveness of the approach is demonstrated through a series of experiments, where a subject performs a set of movements according to a protocol that reveals the structure of the human body.<<ETX>>"
            },
            "slug": "3D-human-body-model-acquisition-from-multiple-views-Kakadiaris-Metaxas",
            "title": {
                "fragments": [],
                "text": "3D human body model acquisition from multiple views"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A human body part identification strategy (HBPIS) that recovers all the body parts of a moving human based on the spatiotemporal analysis of its deforming silhouette and a new algorithm which selectively integrates the apparent contours from three mutually orthogonal views."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47265099"
                        ],
                        "name": "F. Perales",
                        "slug": "F.-Perales",
                        "structuredName": {
                            "firstName": "Francisco",
                            "lastName": "Perales",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Perales"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075317523"
                        ],
                        "name": "J. Torres",
                        "slug": "J.-Torres",
                        "structuredName": {
                            "firstName": "Jesse",
                            "lastName": "Torres",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Torres"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 157
                            }
                        ],
                        "text": "[68] Ohya and Kishino [58] Segen and Pingali [73] O'Rourke and Badler [60] Shio and Sklansky [75] Pentland [62] Starner and Pentland [77] Perales and Torres [64] Takahashi et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 19
                            }
                        ],
                        "text": "Perales and Torres [64] describe a multi-view camera system for whole-body tracking which requires input from a human operator."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 185
                            }
                        ],
                        "text": "Instead, it uses the measurement equation directly to synthesize the model and uses a tting measure between synthesized and observed features for feedback; see [22] [26] [36] [46] [58] [64] [71]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61493162,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0bbe276e98cceec07e9363ea23f8074259b6274b",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "A system for analysis and synthesis of human motion is presented. The system consists of an analysis part and a synthesis part. The analysis part can be used automatically or interactively. The automatic analysis part includes the pre-processing, modeling, matching and interpretation phases. The interactive analysis part includes the same phases but with the possibility of user supervision. We present a global overview of the whole system. The user can define a biomechanic graphical model to represent the human body in a 3D space, and use tools to perform an automatic or interactive supervised matching between the animated model and the real images to recover the motion. The synthesis part uses the results of matching process to show the motion of the human body that is shown in the real images, from any viewpoint. We use specific criteria to match walking persons from different views. Some results and images are presented.<<ETX>>"
            },
            "slug": "A-system-for-human-motion-matching-between-and-real-Perales-Torres",
            "title": {
                "fragments": [],
                "text": "A system for human motion matching between synthetic and real images based on a biomechanic graphical model"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The system uses specific criteria to match walking persons from different views and uses the results of matching process to show the motion of the human body that is shown in the real images, from any viewpoint."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1994 IEEE Workshop on Motion of Non-rigid and Articulated Objects"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153281777"
                        ],
                        "name": "D. Marr",
                        "slug": "D.-Marr",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Marr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Marr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144901036"
                        ],
                        "name": "H. Nishihara",
                        "slug": "H.-Nishihara",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Nishihara",
                            "middleNames": [
                                "Keith"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Nishihara"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 43759520,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bdf9b8f4de001f5f37bc844efbce1210d581d599",
            "isKey": false,
            "numCitedBy": 2323,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "The human visual process can be studied by examining the computational problems associated with deriving useful information from retinal images. In this paper, we apply this approach to the problem of representing three-dimensional shapes for the purpose of recognition. 1. Three criteria, accessibility, scope and uniqueness, and stability and sensitivity, are presented for judging the usefulness of a representation for shape recognition. 2. Three aspects of a representation\u2019s design are considered, (i) the representation\u2019s coordinate system, (ii) its primitives, which are the primary units of shape information used in the representation, and (iii) the organization the representation imposes on the information in its descriptions. 3. In terms of these design issues and the criteria presented, a shape representation for recognition should: (i) use an object-centred coordinate system, (ii) include volumetric primitives of varied sizes, and (iii) have a modular organization. A representation based on a shape\u2019s natural axes (for example the axes identified by a stick figure) follows directly from these choices. 4. The basic process for deriving a shape description in this representation must involve: (i) a means for identifying the natural axes of a shape in its image and (ii) a mechanism for transforming viewer-centred axis specifications to specifications in an object-centred coordinate system. 5. Shape recognition involves: (i) a collection of stored shape descriptions, and (ii) various indexes into the collection that allow a newly derived description to be associated with an appropriate stored description. The most important of these indexes allows shape recognition to proceed conservatively from the general to the specific based on the specificity of the information available from the image. 6. New constraints supplied by a conservative recognition process can be used to extract more information from the image. A relaxation process for carrying out this constraint analysis is described."
            },
            "slug": "Representation-and-recognition-of-the-spatial-of-Marr-Nishihara",
            "title": {
                "fragments": [],
                "text": "Representation and recognition of the spatial organization of three-dimensional shapes"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "The human visual process can be studied by examining the computational problems associated with deriving useful information from retinal images by applying the approach to the problem of representing three-dimensional shapes for the purpose of recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Royal Society of London. Series B. Biological Sciences"
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2019875"
                        ],
                        "name": "A. Shio",
                        "slug": "A.-Shio",
                        "structuredName": {
                            "firstName": "Akio",
                            "lastName": "Shio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765522"
                        ],
                        "name": "J. Sklansky",
                        "slug": "J.-Sklansky",
                        "structuredName": {
                            "firstName": "Jack",
                            "lastName": "Sklansky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sklansky"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 93
                            }
                        ],
                        "text": "[68] Ohya and Kishino [58] Segen and Pingali [73] O'Rourke and Badler [60] Shio and Sklansky [75] Pentland [62] Starner and Pentland [77] Perales and Torres [64] Takahashi et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "Shio and Sklansky [75] aim to recover the average 2-D image velocity of pedestrians in a tra c"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 0
                            }
                        ],
                        "text": "Shio and Sklansky [75] aim to recover the average 2-"
                    },
                    "intents": []
                }
            ],
            "corpusId": 129637437,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "833063952e8a337db7970e81a70b134d25d12675",
            "isKey": false,
            "numCitedBy": 141,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for segmenting monocular images of people in motion from a cinematic sequence of frames is described. This method is based on image intensities, motion, and an object model-i.e., a model of the image of a person in motion. Though each part of a person may move in different directions at any instant, the time averaged motion of all parts must converge to a global average value over a few seconds. People in an image may be occluded by other people, and usually it is not easy to detect their boundaries. These boundaries can be detected with motion information if they move in different directions, even if there are almost no apparent differences among object intensities or colors. Each image of a person in a scene usually can be divided into several parts, each with distinct intensities or colors. The parts of a person can be merged into a single group by an iterative merging algorithm based on the object model and the motion information because the parts move coherently. This merging is analogous to the property of perceptual grouping in human visual perception of motion. Experiments based on a sequence of complex real scenes produced results that are supportive of the authors approach to the segmentation of people in motion.<<ETX>>"
            },
            "slug": "Segmentation-of-people-in-motion-Shio-Sklansky",
            "title": {
                "fragments": [],
                "text": "Segmentation of people in motion"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE Workshop on Visual Motion"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 67
                            }
                        ],
                        "text": "Rather than requiring the typical point features, Azarbayejani and Pentland [4] \\triangulate\" using blob features [84]; a 3-"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 49
                            }
                        ],
                        "text": "[18] Geurtz [27] Dorner [21] Darell and Pentland [19] Goddard [28] Downton and Drouet [22] Davis and Shah [20] Guo et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 25
                            }
                        ],
                        "text": "Both Darell and Pentland [19] and Kjeldsen and Kender [44] use the image pixels directly as input."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 17
                            }
                        ],
                        "text": "Azarbayejani and Pentland [4] obtain the 3-"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 199
                            }
                        ],
                        "text": "Because of conceptual simplicity and robust performance, Dynamic Time Warping was extensively used in the early days of speech recognition, and more recently in matching human movement patterns [10] [19] [25] [78]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 15
                            }
                        ],
                        "text": "In other work, Pentland [62] ts deformable superquadrics to range data."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 32
                            }
                        ],
                        "text": "The work by Darell and Pentland [19] aims to build view models automatically by adding views to the model set whenever correlation with the existing views falls below a certain threshold."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5344867,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1807058512ae2934b2be0b43f395d8583ef67303",
            "isKey": true,
            "numCitedBy": 442,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for learning, tracking, and recognizing human gestures using a view-based approach to model articulated objects is presented. Objects are represented using sets of view models, rather than single templates. Stereotypical space-time patterns, i.e., gestures, are then matched to stored gesture patterns using dynamic time warping. Real-time performance is achieved by using special purpose correlation hardware and view prediction to prune as much of the search space as possible. Both view models and view predictions are learned from examples. Results showing tracking and recognition of human hand gestures at over 10 Hz are presented.<<ETX>>"
            },
            "slug": "Space-time-gestures-Darrell-Pentland",
            "title": {
                "fragments": [],
                "text": "Space-time gestures"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A method for learning, tracking, and recognizing human gestures using a view-based approach to model articulated objects is presented and results showing tracking and recognition of human hand gestures at over 10 Hz are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144177248"
                        ],
                        "name": "James M. Rehg",
                        "slug": "James-M.-Rehg",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Rehg",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James M. Rehg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 21
                            }
                        ],
                        "text": "[78] Rehg and Kanade [69] [70] Tamura and Kawasaki [79] Rohr [71] Turk [80] Shakunaga [74] Yamato et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 54
                            }
                        ],
                        "text": "One approach using such parametrized models [21] [29] [69] [70] [81] [85] [87] updates pose by inverse kinematics, a common technique in robot control theory [76]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 34
                            }
                        ],
                        "text": "makes the resulting approach [21] [69] quite sensitive to occlusion."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 107
                            }
                        ],
                        "text": "The bene t of using multiple cameras to achieve tighter 3-D pose recovery has been quite evident [26] [43] [69]; body poses and movements that are ambiguous from one view (by occlusion or depth) can be disambiguated from another view."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 226,
                                "start": 222
                            }
                        ],
                        "text": "with the non-greedy combinatoric search approaches, one notes that the former have the advantage that they exploit gradient cues in the vicinity of a minimum and therefore are computationally more e cient, see for example [69]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 16
                            }
                        ],
                        "text": "Rehg and Kanade [69] do not require markers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10376369,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c51f0d3f863fdde988cfada25f1a07a224889129",
            "isKey": true,
            "numCitedBy": 530,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Passive sensing of human hand and limb motion is important for a wide range of applications from human-computer interaction to athletic performance measurement. High degree of freedom articulated mechanisms like the human hand are difficult to track because of their large state space and complex image appearance. This article describes a model-based hand tracking system, called DigitEyes, that can recover the state of a 27 DOF hand model from ordinary gray scale images at speeds of up to 10 Hz."
            },
            "slug": "Visual-Tracking-of-High-DOF-Articulated-Structures:-Rehg-Kanade",
            "title": {
                "fragments": [],
                "text": "Visual Tracking of High DOF Articulated Structures: an Application to Human Hand Tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A model-based hand tracking system, called DigitEyes, that can recover the state of a 27 DOF hand model from ordinary gray scale images at speeds of up to 10 Hz is described."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2173222171"
                        ],
                        "name": "K. Takahashi",
                        "slug": "K.-Takahashi",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Takahashi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Takahashi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2006078"
                        ],
                        "name": "S. Seki",
                        "slug": "S.-Seki",
                        "structuredName": {
                            "firstName": "Susumu",
                            "lastName": "Seki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Seki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070443345"
                        ],
                        "name": "E. Kojima",
                        "slug": "E.-Kojima",
                        "structuredName": {
                            "firstName": "E.",
                            "lastName": "Kojima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Kojima"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1776022"
                        ],
                        "name": "R. Oka",
                        "slug": "R.-Oka",
                        "structuredName": {
                            "firstName": "Ryu-ichi",
                            "lastName": "Oka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Oka"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 255,
                                "start": 224
                            }
                        ],
                        "text": "Another advantage of HMMs are their ability to deal with unsegmented data, i.e. dealing with continuous data streams\nwhere the beginning of a desired data segment is unknown (DTW could be adapted to handle this as well; see Continuous Dynamic Time Warping [78])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[78] Rehg and Kanade [69] [70] Tamura and Kawasaki [79] Rohr [71] Turk [80] Shakunaga [74] Yamato et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 139
                            }
                        ],
                        "text": "where the beginning of a desired data segment is unknown (DTW could be adapted to handle this as well; see Continuous Dynamic Time Warping [78])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 213,
                                "start": 209
                            }
                        ],
                        "text": "Because of conceptual simplicity and robust performance, Dynamic Time Warping was extensively used in the early days of speech recognition, and more recently in matching human movement patterns [10] [19] [25] [78]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[78] de ne an average edge vector for each tile."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61151940,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "555167ea3a8bc88f10c992d9c8371c829148f2bd",
            "isKey": true,
            "numCitedBy": 39,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for recognizing dexterous manipulation actions that we usually perform using our hands. Our method is based on model representation using spatio-temporal vector fields and a spotting algorithm that gives segmentation-free and frame-by-frame recognition. We propose a multiview motion model that is composed of several standard sequence patterns made from different viewpoints. Results indicate that our method recognizes dexterous manipulations correctly, even if the viewing direction of the input images deviates from those of standard sequence patterns.<<ETX>>"
            },
            "slug": "Recognition-of-dexterous-manipulations-from-images-Takahashi-Seki",
            "title": {
                "fragments": [],
                "text": "Recognition of dexterous manipulations from time-varying images"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "Results indicate that the method recognizes dexterous manipulations correctly, even if the viewing direction of the input images deviates from those of standard sequence patterns."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1994 IEEE Workshop on Motion of Non-rigid and Articulated Objects"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699200"
                        ],
                        "name": "N. Badler",
                        "slug": "N.-Badler",
                        "structuredName": {
                            "firstName": "Norman",
                            "lastName": "Badler",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Badler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743808"
                        ],
                        "name": "S. Smoliar",
                        "slug": "S.-Smoliar",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Smoliar",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Smoliar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 116
                            }
                        ],
                        "text": "Some of the issues have been how to specify spatial interactions and high-level tasks for the human models; see [5] [6] [50]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 19
                            }
                        ],
                        "text": "Badler and Smoliar [6] provide a good discussion of these issues."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16348644,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "381ee6987ef4ade987fc6be28e8f5087633ffbe5",
            "isKey": false,
            "numCitedBy": 206,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "There are many different approaches to the representation, wlthm a digital computer, of mformatlon describing the movement of the human body. The general Issue of movement representatmn is approached from two points of vmw: notatmn systems designed for recording movement and ammation systems designed for the display of movement. The interpretation of one partmular notation system, Labanotatlon, is examined to extract a set of \"primitive movement concepts\" which can be used to animate a realistic human body on a graphics display The body is represented computatlonally as a network of specml-purpose processors--one processor situated at each joint of the body--each with an instructmn set demgned around the movement concepts derived from Labanotatlon Movement Is achmved by slmulatmg the behawor of these processors as they interpret their respective programs."
            },
            "slug": "Digital-Representations-of-Human-Movement-Badler-Smoliar",
            "title": {
                "fragments": [],
                "text": "Digital Representations of Human Movement"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The interpretation of one partmular notation system, Labanotatlon, is examined to extract a set of \"primitive movement concepts\" which can be used to animate a realistic human body on a graphics display."
            },
            "venue": {
                "fragments": [],
                "text": "CSUR"
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2101678578"
                        ],
                        "name": "Michael Mohnhaupt",
                        "slug": "Michael-Mohnhaupt",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Mohnhaupt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Mohnhaupt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143908022"
                        ],
                        "name": "B. Neumann",
                        "slug": "B.-Neumann",
                        "structuredName": {
                            "firstName": "Bernd",
                            "lastName": "Neumann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Neumann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 39
                            }
                        ],
                        "text": "See also work by Mohnhaupt and Neumann [54]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 42887466,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "97a328e75cd18843ec6c55b8f092a70cc4c6110f",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "We showed how to exploit motion concepts associated with verbs of locomotion for top-down control in traffic scenes. Two kinds of constraints could be derived: spatial constraints through knowledge about the applicability of motion concepts, and motion constraints through knowledge about typical motion. We proposed to compute motion constraints using a spatio-temporal buffer as a shared representation for bottom-up and top-down processes. Within the buffer motion concepts are expressed as typicality distributions from which predictions about object motion can be derived. A local prediction algorithm allows for the computation of search areas for low-level motion analysis. A low-level motion representation based on spatio-temporal Gabor cells is well suited for the integration of this kind of top-down information."
            },
            "slug": "On-the-Use-of-Motion-Concepts-for-Top-Down-Control-Mohnhaupt-Neumann",
            "title": {
                "fragments": [],
                "text": "On the Use of Motion Concepts for Top-Down Control in Traffic Scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is proposed to compute motion constraints using a spatio-temporal buffer as a shared representation for bottom-up and top-down processes, within the buffer motion concepts are expressed as typicality distributions from which predictions about object motion can be derived."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152880105"
                        ],
                        "name": "M. Herman",
                        "slug": "M.-Herman",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Herman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Herman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59985580,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "2425e578af4e2da45612515d78fe4e44ea6d95e5",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This thesis presents a computational theory of understanding body language. Body language is an elaborate form of non-verbal communication wherein messages are conveyed by body movements and body positions. This study is primarily concerned with only one aspect of body language -- body posture. \nThis work views vision as a medium of communication. The ultimate goal of the visual process is to provide the viewer with a \"meaning\" description of the external world. One form of visual communication involves the type of information people convey to one another via the visual modality (such as the ideas communicated visually by sculptors, artists, and actors). A subset of this form deals with communication via body language, in particular, body postures. \nThe theory examines the kinds of information conveyed by gross body postures, as well as ways of representing this information and generating it from images. \nThe human body is represented as a stick figure, since it eliminates the problems involved in processing fleshed-out human figures without sacrificing the overall form conveyed by the gross body posture. The specific goal of the research, then, has been to develop a theory of stick figure understanding, i.e., generating descriptions of what is occurring in a 2-D scene consisting of static, human stick figures. \nAccording to the theory, three important levels at which a scene must be described are: (1) Data -- a low level description of the 2-D input scene. (2) Meaning Space Description -- a description in terms of the information communicated by the figures. (3) Physical Space Description -- a description of the 3-D configuration of the figures. \nThe understanding process involves obtaining physical and meaning space descriptions from the data. Heuristic inference rules are required for this process, along with knowledge of the external human physical structure. \nSince the set of meaning space concepts and some physical space concepts are open-ended, the inference rules must be represented in a manner such that new rules can easily be added to the model. It is proposed that the rules be represented in the form of discrimination structures, which, in addition to discriminating the input, have the following properties important for learning: (1) All related knowledge rules are grouped together. (2) Similarities and differences among rules in a group are made explicit. \nMany of the ideas in the theory have been implemented in the form of a computer program (SKELETUN), which provides context-sensitive descriptions of 2-D, static, human stick figures. To demonstrate SKELETUN's flexibility and extensibility, it has been provided with enough knowledge to make it relatively adequate in the domain of baseball. \nSKELETUN has shown the theory to be successful in understanding body postures, and in permitting easy addition of knowledge in limited domains."
            },
            "slug": "Understanding-body-postures-of-human-stick-figures-Herman",
            "title": {
                "fragments": [],
                "text": "Understanding body postures of human stick figures"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A theory of stick figure understanding is developed, i.e., generating descriptions of what is occurring in a 2-D scene consisting of static, human stick figures, and SKELETUN has shown the theory to be successful in understanding body postures, and in permitting easy addition of knowledge in limited domains."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144177248"
                        ],
                        "name": "James M. Rehg",
                        "slug": "James-M.-Rehg",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Rehg",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James M. Rehg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 26
                            }
                        ],
                        "text": "[78] Rehg and Kanade [69] [70] Tamura and Kawasaki [79] Rohr [71] Turk [80] Shakunaga [74] Yamato et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 30
                            }
                        ],
                        "text": "A later version of the system [70] does tolerate partial occlusion; a successful tracking example is shown where one nger moves over the other nger, with the rest of the hand xed."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 59
                            }
                        ],
                        "text": "One approach using such parametrized models [21] [29] [69] [70] [81] [85] [87] updates pose by inverse kinematics, a common technique in robot control theory [76]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 86
                            }
                        ],
                        "text": "One simply concatenates the residual from the available camera views; see for example [70]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 77
                            }
                        ],
                        "text": "Typical measures are correlation on a raw or smoothed LOG- ltered image [29] [70], perpendicular- [31] and chamfer-distance [26] (from projected model edges to image edges) and straight-line distance metrics [71]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17009967,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f3740a2ab2936c2d87f6a3d8b742841a383ba502",
            "isKey": true,
            "numCitedBy": 502,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Computer sensing of hand and limb motion is an important problem for applications in human computer interaction and computer graphics. We describe a framework for local trading of self occluding motion, in which one part of an object obstructs the visibility of another. Our approach uses a kinematic model to predict occlusions and windowed templates to track partially occluded objects. We present offline 3D tracking results for hand motion with significant self occlusion.<<ETX>>"
            },
            "slug": "Model-based-tracking-of-self-occluding-articulated-Rehg-Kanade",
            "title": {
                "fragments": [],
                "text": "Model-based tracking of self-occluding articulated objects"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This work describes a framework for local trading of self occluding motion, in which one part of an object obstructs the visibility of another, using a kinematic model to predict occlusions and windowed templates to track partially occluded objects."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34751187"
                        ],
                        "name": "C. R. Wren",
                        "slug": "C.-R.-Wren",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Wren",
                            "middleNames": [
                                "Richard"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. R. Wren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145271456"
                        ],
                        "name": "A. Azarbayejani",
                        "slug": "A.-Azarbayejani",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Azarbayejani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Azarbayejani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "... [20] Guo et al. [30] Gavrila and Davis [25] [26] Franke et al. [23] Herman [34] Goncalves et al. [29] Freeman et al. [24] Ju et al. [40] Heap and Hogg [31] Heisele et al. [32] Kurakake and Nevatia [47] Hel-Or and Werman [33] Hunter et al. [38] Leung and Yang [48] Hoffman and Flinchbaugh [35] Johansson [39] Long and Yang [49] Hogg [36] Kjeldsen and Kender [44] Niyogi and Adelson [56] [57] Holt et al. [37] Oren et al. [59] Wren et al. [ 84 ] ..."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Rather than requiring the typical point features, Azarbayejani and Pentland [4] \u201ctriangulated\u201d using blob features [ 84 ]; a 3-D blob (shape, orientation) is recovered from a pair of corresponding 2-D blob features using nonlinear estimation techniques."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "But it is the availability of an easy initialization procedure, which can be started up from a wide range of situations, that makes a system robust enough to be deployed in real world settings (e.g., [ 84 ])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "FIG. 9. Detecting and tracking human \u201cblobs\u201d with the Pfinder system (work by Wren et al. [ 84 ], c \u221e 1997 IEEE)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Wren et al. [ 84 ] took a region-based approach."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9458767,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "69b7efd02ea06e6aa372b5c1a46167e6a5366bfd",
            "isKey": true,
            "numCitedBy": 3548,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Pfinder is a real-time system for tracking and interpretation of people. It runs on a standard SGI Indy computer, and has performed reliably on thousands of people in many different physical locations. The system uses a multi-class statistical model of color and shape to obtain a 2-D representation of head and hands in a wide range of viewing conditions. These representations are useful for applications such as wireless interfaces, video databases, and low-bandwidth coding, without cumbersome wires or attached sensors."
            },
            "slug": "Pfinder:-real-time-tracking-of-the-human-body-Wren-Azarbayejani",
            "title": {
                "fragments": [],
                "text": "Pfinder: Real-Time Tracking of the Human Body"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Pfinder uses a multi-class statistical model of color and shape to obtain a 2-D representation of head and hands in a wide range of viewing conditions, useful for applications such as wireless interfaces, video databases, and low-bandwidth coding."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706204"
                        ],
                        "name": "I. Kakadiaris",
                        "slug": "I.-Kakadiaris",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Kakadiaris",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Kakadiaris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711560"
                        ],
                        "name": "Dimitris N. Metaxas",
                        "slug": "Dimitris-N.-Metaxas",
                        "structuredName": {
                            "firstName": "Dimitris",
                            "lastName": "Metaxas",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dimitris N. Metaxas"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 102
                            }
                        ],
                        "text": "The bene t of using multiple cameras to achieve tighter 3-D pose recovery has been quite evident [26] [43] [69]; body poses and movements that are ambiguous from one view (by occlusion or depth) can be disambiguated from another view."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 76
                            }
                        ],
                        "text": "[84] Kahn and Swain [41] Polana and Nelson [65] Kakadiaris and Metaxas [42] [43] Quek [66] Kuch and Huang [46] Rangarajan et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 75
                            }
                        ],
                        "text": "tapering, bending) and/or local deformations on the superquadrics [7] [26] [43] [53] [62]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "Kakadiaris and Metaxas [43] track one arm using three orthogonal cameras."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 28
                            }
                        ],
                        "text": "Kakadiaris and Metaxas [42] [43] use a physics-based approach where various forces act on the di erent parts to align them with the image data; constraint forces enforce point-to-point connectivity between the parts."
                    },
                    "intents": []
                }
            ],
            "corpusId": 18748251,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "4d24117d83ad925d837ed0b7d6aa065140fb0248",
            "isKey": true,
            "numCitedBy": 278,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new method for the 3D model-based tracking of human body parts. To mitigate the difficulties arising due to occlusion among body parts, we employ multiple calibrated cameras in a mutually orthogonal configuration. In addition, we develop criteria for a time varying active selection of a set of cameras to track the motion of a particular human part. In particular, at every frame, each camera tracks a number of parts depending on the visibility of these parts and the observability of their predicted motion from the specific camera. To relate points on the occluding contours of the parts to points on their models we apply concepts from projective geometry. Then, within the physics-based framework we compute the generalized forces applied from the parts' occluding contours to model points of the body parts. These forces update the translational and rotational degrees of freedom of the model, such as to minimize the discrepancy between the sensory data and the estimated model state. We present initial tracking results from a series of experiments involving the recovery of complex 3D motions in the presence of significant occlusion."
            },
            "slug": "Model-based-estimation-of-3D-human-motion-with-on-Kakadiaris-Metaxas",
            "title": {
                "fragments": [],
                "text": "Model-based estimation of 3D human motion with occlusion based on active multi-viewpoint selection"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Initial tracking results from a series of experiments involving the recovery of complex 3D motions in the presence of significant occlusion are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2130172714"
                        ],
                        "name": "Jianming Zhao",
                        "slug": "Jianming-Zhao",
                        "structuredName": {
                            "firstName": "Jianming",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianming Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699200"
                        ],
                        "name": "N. Badler",
                        "slug": "N.-Badler",
                        "structuredName": {
                            "firstName": "Norman",
                            "lastName": "Badler",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Badler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "One approach using such parametrized models [21, 29, 69, 70, 81, 85, 87] updated pose by inverse kinematics, a common technique in robot control theory [76]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Yamamoto and Koshikawa [85] Zhao [87]"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Approaches [17, 37, 60, 74, 87] used joint locations as features and assumed these are given make strong assumptions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Zhao [87] has a similar problem formulation but did not maintain the interpretation tree, considering instead only one pose at the time."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 115880876,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "01c116bc6d87d97bf79ff4cbd0b7695eca9cfb64",
            "isKey": true,
            "numCitedBy": 15,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Our goal is to reproduce a human figure's motion with a computer simulated human figure: Given a sequence of perspective projections of a set of feature joints of the moving figure, we tried to recover the original 3D postures through an accurate human figure model and the continuity requirement (temporal coherence) in the sequence. Our approach follows two clues: Given the human figure model, the responsible posture for a frame is constrained by the projections of all the feature joints and, in this limited set of postures we can choose one based on the postures in the previous frames and the temporal coherence, unless there occurs a critical condition, when the projection ray of a feature is perpendicular to the link of which the feature is the distal end. Owing to the fast inverse kinematics algorithm we developed to solve the spatial constraints, we were able to exploit the temporal coherence in projection sequences of frequencies as high as 100 Hz. We used finite state automata to detect critical conditions, and developed various strategies to overcome special difficulties around critical frames. Furthermore, we investigated the impact of errors in linear measurements of body parts on the reconstruction process. Based on mathematical analysis, we proposed some heuristics to discover and recover from the possible modeling errors. To test the theory, we implemented an experimental system. By imposing the temporal coherence constraint whenever possible, this system responds to the incoming images almost linearly: Since the error-prone critical conditions are detected and handled at the very early stage, the system is able to do away with endless recursive backtracking so that only one level of roll-back is needed to handle a limited number of critical conditions whose chances of occurrence are independent of the sampling rate. The system admits generic human motion. It has been tested on synthesized images from actual 3D human motions. Since we knew the original motion, we were able to evaluate results quantitatively. It turned out that the reconstructed motions agreed with the original ones not only in general but also in fine details."
            },
            "slug": "Moving-posture-reconstruction-from-perspective-of-Zhao-Badler",
            "title": {
                "fragments": [],
                "text": "Moving posture reconstruction from perspective projections of jointed figure motion"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work tried to recover the original 3D postures through an accurate human figure model and the continuity requirement (temporal coherence) in the sequence to reproduce a human figure's motion with a computer simulated human figure."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31951929"
                        ],
                        "name": "R. E. Kahn",
                        "slug": "R.-E.-Kahn",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Kahn",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. E. Kahn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2987811"
                        ],
                        "name": "M. Swain",
                        "slug": "M.-Swain",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Swain",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Swain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2828533"
                        ],
                        "name": "Peter N. Prokopowicz",
                        "slug": "Peter-N.-Prokopowicz",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Prokopowicz",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter N. Prokopowicz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2442139"
                        ],
                        "name": "R. Firby",
                        "slug": "R.-Firby",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Firby",
                            "middleNames": [
                                "James"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Firby"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 24
                            }
                        ],
                        "text": "Finally, Kahn and Swain [41] describe a system which uses multiple cues (intensity, edge, depth, motion) to detect people pointing laterally."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": "[84] Kahn and Swain [41] Polana and Nelson [65] Kakadiaris and Metaxas [42] [43] Quek [66] Kuch and Huang [46] Rangarajan et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 4
                            }
                        ],
                        "text": "[4] [41]) have obtained 3-D data by passive sensing techniques (i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17228707,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2edcf176e40e24caf6f5c2c06397441bebdbfedd",
            "isKey": false,
            "numCitedBy": 126,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Communication involves more than simply spoken information. Typical interactions use gestures to accurately and efficiently convey ideas that are more easily expressed with actions than words. A more intuitive interface with machines should involve not only speech recognition, but gesture recognition as well. One of the most frequently used and expressively powerful gestures is pointing. It is far easier and more accurate to point to an object than give a verbal description of its location. To produce a more efficient, accurate, and natural human-machine interface we use the Perseus architecture to interpret the pointing gesture. Perseus uses a variety of techniques to reliably solve this complex visual problem in non-engineered worlds. Knowledge about the task and environment is used at all stages of processing to best interpret the scene for the current situation. Once the visual operators are chosen, contextual knowledge is used to tune them for maximal performance. Redundant interpretation of the scene provides robustness to errors in interpretation. Fusion of independent types of information results in increased tolerance when assumptions about the environment fail. Windows of attention are used to improve speed and remove distractions from the scene. Furthermore, reuse is a major issue in the design of Perseus. Information about the environment and task is explicitly represented so it can easily be re-used in tasks other than pointing. A clean interface to Perseus is provided for symbolic higher level systems like the RAP reactive execution system. In this paper we describe Perseus in detail and show how it is used to locate objects pointed to by people."
            },
            "slug": "Gesture-recognition-using-the-Perseus-architecture-Kahn-Swain",
            "title": {
                "fragments": [],
                "text": "Gesture recognition using the Perseus architecture"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "This paper describes Perseus in detail and shows how it is used to locate objects pointed to by people and how it can be re-used in tasks other than pointing."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144840247"
                        ],
                        "name": "K. Rangarajan",
                        "slug": "K.-Rangarajan",
                        "structuredName": {
                            "firstName": "Krishnan",
                            "lastName": "Rangarajan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Rangarajan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2071418866"
                        ],
                        "name": "William Allen",
                        "slug": "William-Allen",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Allen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William Allen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145103012"
                        ],
                        "name": "M. Shah",
                        "slug": "M.-Shah",
                        "structuredName": {
                            "firstName": "Mubarak",
                            "lastName": "Shah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Shah"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 46407756,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "id": "4a6db6aa3b9308223930fd6e2cfb1a6eee474d5f",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Matching-motion-trajectories-using-scale-space-Rangarajan-Allen",
            "title": {
                "fragments": [],
                "text": "Matching motion trajectories using scale-space"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32250556"
                        ],
                        "name": "D. H. Cooper",
                        "slug": "D.-H.-Cooper",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Cooper",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. H. Cooper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47581828"
                        ],
                        "name": "J. Graham",
                        "slug": "J.-Graham",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Graham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Graham"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15242659,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f731b6745d829241941307c3ebf163e90e200318",
            "isKey": false,
            "numCitedBy": 7909,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "!, Model-based vision is firmly established as a robust approach to recognizing and locating known rigid objects in the presence of noise, clutter, and occlusion. It is more problematic to apply modelbased methods to images of objects whose appearance can vary, though a number of approaches based on the use of flexible templates have been proposed. The problem with existing methods is that they sacrifice model specificity in order to accommodate variability, thereby compromising robustness during image interpretation. We argue that a model should only be able to deform in ways characteristic of the class of objects it represents. We describe a method for building models by learning patterns of variability from a training set of correctly annotated images. These models can be used for image search in an iterative refinement algorithm analogous to that employed by Active Contour Models (Snakes). The key difference is that our Active Shape Models can only deform to fit the data in ways consistent with the training set. We show several practical examples where we have built such models and used them to locate partially occluded objects in noisy, cluttered images. Q 199s A&& prrss, IN."
            },
            "slug": "Active-Shape-Models-Their-Training-and-Application-Cootes-Taylor",
            "title": {
                "fragments": [],
                "text": "Active Shape Models-Their Training and Application"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work describes a method for building models by learning patterns of variability from a training set of correctly annotated images that can be used for image search in an iterative refinement algorithm analogous to that employed by Active Contour Models (Snakes)."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2151490155"
                        ],
                        "name": "Ken-ichi Tanaka",
                        "slug": "Ken-ichi-Tanaka",
                        "structuredName": {
                            "firstName": "Ken-ichi",
                            "lastName": "Tanaka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ken-ichi Tanaka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145434530"
                        ],
                        "name": "J. Ohta",
                        "slug": "J.-Ohta",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Ohta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ohta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109665"
                        ],
                        "name": "K. Kyuma",
                        "slug": "K.-Kyuma",
                        "structuredName": {
                            "firstName": "Kazuo",
                            "lastName": "Kyuma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kyuma"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[24] use x-y image moments and orientation histograms and Hunter et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1762073,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "59c9d35a342ad4e9540d4fa37f7bbaf35913994b",
            "isKey": false,
            "numCitedBy": 234,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The appeal of computer games may be enhanced by vision-based user inputs. The high speed and low cost requirements for near-term, mass-market game applications make system design challenging. The response time of the vision interface should be less than a video frame time and the interface should cost less than $50 U.S. We meet these constraints with algorithms tailored to particular hardware. We have developed a special detector, called the artificial retina chip, which allows for fast, on-chip image processing. We describe two algorithms, based on image moments and orientation histograms, which exploit the capabilities of the chip to provide interactive response to the player's hand or body positions at 10 msec frame time and at low-cost. We show several possible game interactions."
            },
            "slug": "Computer-vision-for-computer-games-Freeman-Tanaka",
            "title": {
                "fragments": [],
                "text": "Computer vision for computer games"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Two algorithms are described, based on image moments and orientation histograms, which exploit the capabilities of the chip to provide interactive response to the player's hand or body positions at 10 msec frame time and at low-cost."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Second International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2554241"
                        ],
                        "name": "J. Segen",
                        "slug": "J.-Segen",
                        "structuredName": {
                            "firstName": "Jakub",
                            "lastName": "Segen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Segen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 45
                            }
                        ],
                        "text": "[68] Ohya and Kishino [58] Segen and Pingali [73] O'Rourke and Badler [60] Shio and Sklansky [75] Pentland [62] Starner and Pentland [77] Perales and Torres [64] Takahashi et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "Segen and Pingali [73] group partially-overlapping feature tracks over time in a real-time implementation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 46213754,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b76cc89484dd46dab66b22b19723ba358318e712",
            "isKey": false,
            "numCitedBy": 189,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a system for real-time tracking of people in video sequences. The input to the system is live or recorded video data acquired by a stationary camera in an environment where the primary moving objects are people. The output consists of trajectories which give the spatio-temporal coordinates of individual persons as they move in the environment. The system uses a new model-based approach to object tracking. It identifies feature points in each video frame, matches feature points across frames to produce feature \"paths\", then groups short-lived and partially overlapping feature paths into longer living trajectories representing motion of individual persons. The path grouping is based on a novel model-based algorithm for motion clustering. The system runs on an SGI Indy workstation at an average rate of 14 frames a second. The system has numerous applications since various statistics and indicators of human activity can be derived from the motion trajectories. Examples of these indicators described in the paper include people counts, presence and time spent in a region, traffic density maps and directional traffic statistics."
            },
            "slug": "A-camera-based-system-for-tracking-people-in-real-Segen",
            "title": {
                "fragments": [],
                "text": "A camera-based system for tracking people in real time"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The system has numerous applications since various statistics and indicators of human activity can be derived from the motion trajectories, including people counts, presence and time spent in a region, traffic density maps and directional traffic statistics."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 13th International Conference on Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2874997"
                        ],
                        "name": "S. Niyogi",
                        "slug": "S.-Niyogi",
                        "structuredName": {
                            "firstName": "Sourabh",
                            "lastName": "Niyogi",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Niyogi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145358192"
                        ],
                        "name": "E. Adelson",
                        "slug": "E.-Adelson",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Adelson",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Adelson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 19
                            }
                        ],
                        "text": "Niyogi and Adelson [56] [57] advocate segmentation over time because of robustness; their procedure involves nding human silhouettes with deformable contours in X-T space [56] or deformable surfaces in X-Y-T space [57]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 141
                            }
                        ],
                        "text": "[38] Leung and Yang [48] Ho man and Flinchbaugh [35] Johansson [39] Long and Yang [49] Hogg [36] Kjeldsen and Kender [44] Niyogi and Adelson [56] [57] Holt et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18566850,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "57854a0e8309af7ad6f5d9612e20e2ba1a171a96",
            "isKey": false,
            "numCitedBy": 661,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a novel algorithm for gait analysis. A person walking frontoparallel to the image plane generates a characteristic \"braided\" pattern in a spatiotemporal (XYT) volume. Our algorithm detects this pattern, and fits it with a set of spatiotemporal snakes. The snakes can be used to find the bounding contours of the walker. The contours vary over time in a manner characteristic of each walker. Individual gaits can be recognized by applying standard pattern recognition techniques to the contour signals.<<ETX>>"
            },
            "slug": "Analyzing-and-recognizing-walking-figures-in-XYT-Niyogi-Adelson",
            "title": {
                "fragments": [],
                "text": "Analyzing and recognizing walking figures in XYT"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "A novel algorithm for gait analysis that fits a characteristic \"braided\" pattern in a spatiotemporal volume, and fits it with a set of spatiotsemporal snakes that can be used to find the bounding contours of the walker."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145328018"
                        ],
                        "name": "M. Oren",
                        "slug": "M.-Oren",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Oren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Oren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145030811"
                        ],
                        "name": "C. Papageorgiou",
                        "slug": "C.-Papageorgiou",
                        "structuredName": {
                            "firstName": "Constantine",
                            "lastName": "Papageorgiou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Papageorgiou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46597039"
                        ],
                        "name": "P. Sinha",
                        "slug": "P.-Sinha",
                        "structuredName": {
                            "firstName": "Pawan",
                            "lastName": "Sinha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sinha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781874"
                        ],
                        "name": "E. Osuna",
                        "slug": "E.-Osuna",
                        "structuredName": {
                            "firstName": "Edgar",
                            "lastName": "Osuna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Osuna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 5
                            }
                        ],
                        "text": "[23] [59]) is that dealing with partial occlusion is relatively straightforward."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[59] perform object detection in static images."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7967646,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bd0534a87e09b3d64b7e7462e2684c60c9aca1f5",
            "isKey": false,
            "numCitedBy": 837,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a trainable object detection architecture that is applied to detecting people in static images of cluttered scenes. This problem poses several challenges. People are highly non-rigid objects with a high degree of variability in size, shape, color, and texture. Unlike previous approaches, this system learns from examples and does not rely on any a priori (hand-crafted) models or on motion. The detection technique is based on the novel idea of the wavelet template that defines the shape of an object in terms of a subset of the wavelet coefficients of the image. It is invariant to changes in color and texture and can be used to robustly define a rich and complex class of objects such as people. We show how the invariant properties and computational efficiency of the wavelet template make it an effective tool for object detection."
            },
            "slug": "Pedestrian-detection-using-wavelet-templates-Oren-Papageorgiou",
            "title": {
                "fragments": [],
                "text": "Pedestrian detection using wavelet templates"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This paper presents a trainable object detection architecture that is applied to detecting people in static images of cluttered scenes and shows how the invariant properties and computational efficiency of the wavelet template make it an effective tool for object detection."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695509"
                        ],
                        "name": "Takeshi Shakunaga",
                        "slug": "Takeshi-Shakunaga",
                        "structuredName": {
                            "firstName": "Takeshi",
                            "lastName": "Shakunaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Takeshi Shakunaga"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 10
                            }
                        ],
                        "text": "Shakunaga [74] identi es such a set of primitive sub-parts for which he solves the pose recovery problem using the angles between projected line features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 86
                            }
                        ],
                        "text": "[78] Rehg and Kanade [69] [70] Tamura and Kawasaki [79] Rohr [71] Turk [80] Shakunaga [74] Yamato et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 26
                            }
                        ],
                        "text": "Approaches [17] [37] [60] [74] [87], which use joint locations as features and assume these are given make strong assumptions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 19847651,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f5283edcdfc71bdcefedf747dffe3978d7c49986",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A framework is proposed for model-based monocular vision covering not only conventional 3-D rigid models, but also flexible structures made up of 3-D rigid bodies connected by rotational joints. Pose-estimation problems from a single view are defined and discussed according to this object model composed of rigid bodies and rotational axes, respectively represented by sets of unit vectors and by single unit vectors. The authors define primitive problems as those which are solvable, but which would be unsolvable if any vector in the problem were invisible. A theorem is derived to extract a primitive problem family, members of which correspond to models containing rigid bodies and invisible rotational axes. Two generic rotation-estimation algorithms applicable to this problem family are also constructed. Experimental results from several primitive problems show the effectiveness of the proposed framework.<<ETX>>"
            },
            "slug": "Pose-estimation-of-jointed-structures-Shakunaga",
            "title": {
                "fragments": [],
                "text": "Pose estimation of jointed structures"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "A framework is proposed for model-based monocular vision covering not only conventional 3-D rigid models, but also flexible structures made up of 3- D rigid bodies connected by rotational joints, which shows the effectiveness of the proposed framework."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145771244"
                        ],
                        "name": "Andrew D. Wilson",
                        "slug": "Andrew-D.-Wilson",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Wilson",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew D. Wilson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688328"
                        ],
                        "name": "A. Bobick",
                        "slug": "A.-Bobick",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Bobick",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bobick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 80
                            }
                        ],
                        "text": "Baumberg and Hogg [8] Akita [3] Azarbayejani and Pentland [4] Bobick and Wilson [10] Cai and Aggarwal [11] Campbell and Bobick [13] Charayaphan and Marble [16] Chang and Huang [15] Chen and Lee [17] Cootes et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 194
                            }
                        ],
                        "text": "Because of conceptual simplicity and robust performance, Dynamic Time Warping was extensively used in the early days of speech recognition, and more recently in matching human movement patterns [10] [19] [25] [78]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 26506460,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "76d9f69e2a4eafe5e180c3d3ce0856bb0eadf71e",
            "isKey": false,
            "numCitedBy": 205,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We define a gesture to be a sequence of states in a measurement or configuration space. For a given gesture, these states are used to capture both the repeatability and variability evidenced in a training set of example trajectories. The states are positioned along a prototype of the gesture, and shaped such that they are narrow in the directions in which the ensemble of examples is tightly constrained, and wide in directions in which a great deal of variability is observed. We develop techniques for computing a prototype trajectory of an ensemble of trajectories, for defining configuration states along the prototype, and for recognizing gestures from an unsegmented, continuous stream of sensor data. The approach is illustrated by application to a range of gesture-related sensory data: the two-dimensional movements of a mouse input device, the movement of the hand measured by a magnetic spatial position and orientation sensor, and, lastly, the changing eigenvector projection coefficients computed from an image sequence.<<ETX>>"
            },
            "slug": "A-state-based-technique-for-the-summarization-and-Wilson-Bobick",
            "title": {
                "fragments": [],
                "text": "A state-based technique for the summarization and recognition of gesture"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work develops techniques for computing a prototype trajectory of an ensemble of trajectories, for defining configuration states along the prototype, and for recognizing gestures from an unsegmented, continuous stream of sensor data."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47579815"
                        ],
                        "name": "Masanobu Yamamoto",
                        "slug": "Masanobu-Yamamoto",
                        "structuredName": {
                            "firstName": "Masanobu",
                            "lastName": "Yamamoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Masanobu Yamamoto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2638101"
                        ],
                        "name": "K. Koshikawa",
                        "slug": "K.-Koshikawa",
                        "structuredName": {
                            "firstName": "Kazutada",
                            "lastName": "Koshikawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Koshikawa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 51
                            }
                        ],
                        "text": "based on image intensities [46] [81] or optical ow [85]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 69
                            }
                        ],
                        "text": "One approach using such parametrized models [21] [29] [69] [70] [81] [85] [87] updates pose by inverse kinematics, a common technique in robot control theory [76]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 51
                            }
                        ],
                        "text": "[81] Webb and Aggarwal [82] Yamamoto and Koshikawa [85] Zhao [87]"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 35103895,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "4ff071ca1e5207975ca8cd146f5c33eddfdb2d98",
            "isKey": false,
            "numCitedBy": 131,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A model-based method for analyzing a human body motion is presented. The method is based on a robot arm model which represents a human body motion. Combining the model and the gradient scheme, the movement of the configuration of the model (Human) can be directly estimated from an image sequence.<<ETX>>"
            },
            "slug": "Human-motion-analysis-based-on-a-robot-arm-model-Yamamoto-Koshikawa",
            "title": {
                "fragments": [],
                "text": "Human motion analysis based on a robot arm model"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "A model-based method based on a robot arm model which represents a human body motion and the movement of the configuration of the model can be directly estimated from an image sequence."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710918"
                        ],
                        "name": "J. Yamato",
                        "slug": "J.-Yamato",
                        "structuredName": {
                            "firstName": "Junji",
                            "lastName": "Yamato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Yamato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708785"
                        ],
                        "name": "J. Ohya",
                        "slug": "J.-Ohya",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Ohya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ohya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072192824"
                        ],
                        "name": "K. Ishii",
                        "slug": "K.-Ishii",
                        "structuredName": {
                            "firstName": "Kenichiro",
                            "lastName": "Ishii",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Ishii"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 137
                            }
                        ],
                        "text": "Because of these bene ts, HMMs are currently widespread in speech recognition and more recently in matching human movement patterns [77] [86]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[86] use the number of foreground pixels and Takahashi et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 28489640,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "45336e96c04ea005b203ff3fc84aa4f4159e8cb0",
            "isKey": false,
            "numCitedBy": 1527,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "A human action recognition method based on a hidden Markov model (HMM) is proposed. It is a feature-based bottom-up approach that is characterized by its learning capability and time-scale invariability. To apply HMMs, one set of time-sequential images is transformed into an image feature vector sequence, and the sequence is converted into a symbol sequence by vector quantization. In learning human action categories, the parameters of the HMMs, one per category, are optimized so as to best describe the training sequences from the category. To recognize an observed sequence, the HMM which best matches the sequence is chosen. Experimental results for real time-sequential images of sports scenes show recognition rates higher than 90%. The recognition rate is improved by increasing the number of people used to generate the training data, indicating the possibility of establishing a person-independent action recognizer.<<ETX>>"
            },
            "slug": "Recognizing-human-action-in-time-sequential-images-Yamato-Ohya",
            "title": {
                "fragments": [],
                "text": "Recognizing human action in time-sequential images using hidden Markov model"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The recognition rate is improved by increasing the number of people used to generate the training data, indicating the possibility of establishing a person-independent action recognizer."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2220450"
                        ],
                        "name": "C. Charayaphan",
                        "slug": "C.-Charayaphan",
                        "structuredName": {
                            "firstName": "Charoensak",
                            "lastName": "Charayaphan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Charayaphan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712072"
                        ],
                        "name": "A. Marble",
                        "slug": "A.-Marble",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Marble",
                            "middleNames": [
                                "E."
                            ],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Marble"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 155
                            }
                        ],
                        "text": "Baumberg and Hogg [8] Akita [3] Azarbayejani and Pentland [4] Bobick and Wilson [10] Cai and Aggarwal [11] Campbell and Bobick [13] Charayaphan and Marble [16] Chang and Huang [15] Chen and Lee [17] Cootes et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 82
                            }
                        ],
                        "text": "For the above systems, action classi cation is based on hard-coded decision trees [16] [20] [79], nearest neighbor criteria [38] [65] or is based on general pattern matching techniques for time-varying data, as described in Section 6."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 7
                            }
                        ],
                        "text": "Others [16] [20] [77] [79] consider the motion trajectories of the hand centroids."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 27148468,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b0bf058b536fc9b7258831d0f64decca5c41636f",
            "isKey": false,
            "numCitedBy": 94,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Image-processing-system-for-interpreting-motion-in-Charayaphan-Marble",
            "title": {
                "fragments": [],
                "text": "Image processing system for interpreting motion in American Sign Language."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of biomedical engineering"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2590676"
                        ],
                        "name": "H. Kollnig",
                        "slug": "H.-Kollnig",
                        "structuredName": {
                            "firstName": "Henner",
                            "lastName": "Kollnig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kollnig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144721252"
                        ],
                        "name": "H. Nagel",
                        "slug": "H.-Nagel",
                        "structuredName": {
                            "firstName": "Hans-Hellmut",
                            "lastName": "Nagel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Nagel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144055354"
                        ],
                        "name": "M. Otte",
                        "slug": "M.-Otte",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Otte",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Otte"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 40895626,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2adb6bb86633a5d3581c781ce5b5dd18c6c69c84",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "This contribution addresses the problem of detection and tracking of moving vehicles in image sequences from traffic scenes recorded by a stationary camera. By replacing the low level vision system component for the estimation of displacement vectors by an optical flow estimation module we are able to detect all moving vehicles in our test image sequence. By replacing the edge detector and by doubling the sampling rate we improve the model-based object tracking system significantly compared to an earlier system. The trajectories of vehicles are characterized by motion verbs and verb phrases. Results from various experiments with real world traffic scenes are presented."
            },
            "slug": "Association-of-Motion-Verbs-with-Vehicle-Movements-Kollnig-Nagel",
            "title": {
                "fragments": [],
                "text": "Association of Motion Verbs with Vehicle Movements Extracted from Dense Optical Flow Fields"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This contribution addresses the problem of detection and tracking of moving vehicles in image sequences from traffic scenes recorded by a stationary camera by replacing the low level vision system component for the estimation of displacement vectors by an optical flow estimation module."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145787720"
                        ],
                        "name": "J. Webb",
                        "slug": "J.-Webb",
                        "structuredName": {
                            "firstName": "Jon",
                            "lastName": "Webb",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Webb"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705627"
                        ],
                        "name": "J. Aggarwal",
                        "slug": "J.-Aggarwal",
                        "structuredName": {
                            "firstName": "Jake",
                            "lastName": "Aggarwal",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Aggarwal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8129680,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "9ea315676e07e7c3d678efc9de30f84aef86cd47",
            "isKey": false,
            "numCitedBy": 245,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Structure-from-Motion-of-Rigid-and-Jointed-Objects-Webb-Aggarwal",
            "title": {
                "fragments": [],
                "text": "Structure from Motion of Rigid and Jointed Objects"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3267020"
                        ],
                        "name": "S. Kurakake",
                        "slug": "S.-Kurakake",
                        "structuredName": {
                            "firstName": "Shoji",
                            "lastName": "Kurakake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kurakake"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144862593"
                        ],
                        "name": "R. Nevatia",
                        "slug": "R.-Nevatia",
                        "structuredName": {
                            "firstName": "Ramakant",
                            "lastName": "Nevatia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nevatia"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 12454684,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c155df6c101f219c469bfd73be639aff4d90c3d",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper discusses the problem of deriving a description for an articulated object from images taken in the real environment. Sometimes with the articulated object, the detection of the articulation is difficult depending on the deformation or the direction of the view line. Also, the false articulation is detected due to the disconnection of the object contour derived from the image or due to the noise. \n \n \n \nTo cope with such difficulties, a method is proposed for the moving articulated object, where the articulation is detected with a high reliability, and the description as well as the segmentation of the articulated object are derived by processing a series of images containing different outblocks and deformations of the object. In this method, the ribbon, which is the two-dimensional version of the generalized cylinder, is used as the basic representation for the part. The initial description is derived from each frame image, and the initial descriptions of various frames are compared by ribbon matching to detect the articulation position with a high reliability. Based on the detected positions, the initial descriptions are integrated selectively and the final description is obtained. As a by-product of the ribbon matching, the tracking of parts also is realized. By an experiment using a human walking scene, the usefulness of the proposed method is demonstrated."
            },
            "slug": "Description-and-tracking-of-moving-articulated-Kurakake-Nevatia",
            "title": {
                "fragments": [],
                "text": "Description and tracking of moving articulated objects"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A method to obtain reliable shape description of articulated objects by integrating initial descriptions computed from different view images by using ribbon, which is a 2-D analog of a generalized cone, as the basic shape representation scheme."
            },
            "venue": {
                "fragments": [],
                "text": "Systems and Computers in Japan"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1851641"
                        ],
                        "name": "Q. Cai",
                        "slug": "Q.-Cai",
                        "structuredName": {
                            "firstName": "Quin",
                            "lastName": "Cai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Cai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705627"
                        ],
                        "name": "J. Aggarwal",
                        "slug": "J.-Aggarwal",
                        "structuredName": {
                            "firstName": "Jake",
                            "lastName": "Aggarwal",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Aggarwal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 102
                            }
                        ],
                        "text": "Baumberg and Hogg [8] Akita [3] Azarbayejani and Pentland [4] Bobick and Wilson [10] Cai and Aggarwal [11] Campbell and Bobick [13] Charayaphan and Marble [16] Chang and Huang [15] Chen and Lee [17] Cootes et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 103
                            }
                        ],
                        "text": "Earlier reviews on non-rigid motion, motion-based recognition and gesture interpretation were given by Aggarwal et al. [1], Cedras and Shah [14] and Pavlovic, Sharma and Huang [61], respectively."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 17
                            }
                        ],
                        "text": "Cai and Aggarwal [11] describe a system with a simpli ed head-trunk model to track humans across multiple cameras."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15213458,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9695c6ebbbdc1341f8197d7c0a0cf6a6a1cbd47",
            "isKey": false,
            "numCitedBy": 210,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Presents a framework for tracking human motion in an indoor environment from sequences of monocular grayscale images obtained from multiple fixed cameras. Multivariate Gaussian models are applied to find the most likely matches of human subjects between consecutive frames taken by cameras mounted in various locations. Experimental results from real data show the robustness of the algorithm and its potential for real time applications."
            },
            "slug": "Tracking-human-motion-using-multiple-cameras-Cai-Aggarwal",
            "title": {
                "fragments": [],
                "text": "Tracking human motion using multiple cameras"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "Experimental results from real data show the robustness of the algorithm and its potential for real time applications."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 13th International Conference on Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708785"
                        ],
                        "name": "J. Ohya",
                        "slug": "J.-Ohya",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Ohya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ohya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3289052"
                        ],
                        "name": "F. Kishino",
                        "slug": "F.-Kishino",
                        "structuredName": {
                            "firstName": "Fumio",
                            "lastName": "Kishino",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Kishino"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "[68] Ohya and Kishino [58] Segen and Pingali [73] O'Rourke and Badler [60] Shio and Sklansky [75] Pentland [62] Starner and Pentland [77] Perales and Torres [64] Takahashi et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 33
                            }
                        ],
                        "text": "To nd a good t, Ohya and Kishino [58] use a global search strategy based on genetic algorithms."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 114
                            }
                        ],
                        "text": "Some of the combinatoric pose-recovery approaches have also been applied to the multi-camera case, in simulations [58] and with real data [26]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 180
                            }
                        ],
                        "text": "Instead, it uses the measurement equation directly to synthesize the model and uses a tting measure between synthesized and observed features for feedback; see [22] [26] [36] [46] [58] [64] [71]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 46946327,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "1cc06cf0e8c342903d585a1c22377ce6dbf4af8c",
            "isKey": true,
            "numCitedBy": 55,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method for estimating human postures at a time instant from multiple images using a genetic algorithm is proposed. The posture parameters to be estimated are assigned to the genes of individuals in the population. For each individual, its fitness evaluates to what extent the multiple human images synthesized by deforming a 3D human model according to the values of the genes are registered to the real multiple human images. Genetic operations such as natural selection, crossover and mutation are performed, and individuals in the next generation are generated. After a certain number of repetitions for these processes, the estimated parameter values are obtained from the individual with the best fitness. Experiments using synthesized human multiple images show promising results."
            },
            "slug": "Human-posture-estimation-from-multiple-images-using-Ohya-Kishino",
            "title": {
                "fragments": [],
                "text": "Human posture estimation from multiple images using genetic algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "A new method for estimating human postures at a time instant from multiple images using a genetic algorithm is proposed, and experiments using synthesized human multiple images show promising results."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 12th International Conference on Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143942359"
                        ],
                        "name": "M. Rosenblum",
                        "slug": "M.-Rosenblum",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Rosenblum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Rosenblum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1964574"
                        ],
                        "name": "Y. Yacoob",
                        "slug": "Y.-Yacoob",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Yacoob",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Yacoob"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069324532"
                        ],
                        "name": "L. Davis",
                        "slug": "L.-Davis",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Davis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Davis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 145637328,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "b82984419868beff9512ddf4e1ec314c44174df7",
            "isKey": false,
            "numCitedBy": 114,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "A radial basis function network architecture is developed that learns the correlation of facial feature motion patterns and human emotions. We describe a hierarchical approach which at the highest level identifies emotions, at the mid level determines motion of facial features, and at the low level recovers motion directions. Individual emotion networks were trained to recognize the 'smile' and 'surprise' emotions. Each emotion network was trained by viewing a set of sequences of one emotion for many subjects. The trained neural network was then tested for retention, extrapolation and rejection ability. Success rates were about 88% for retention, 73% for extrapolation, and 79% for rejection.<<ETX>>"
            },
            "slug": "Human-emotion-recognition-from-motion-using-a-basis-Rosenblum-Yacoob",
            "title": {
                "fragments": [],
                "text": "Human emotion recognition from motion using a radial basis function network architecture"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1994 IEEE Workshop on Motion of Non-rigid and Articulated Objects"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144429686"
                        ],
                        "name": "James W. Davis",
                        "slug": "James-W.-Davis",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Davis",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James W. Davis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145103012"
                        ],
                        "name": "M. Shah",
                        "slug": "M.-Shah",
                        "structuredName": {
                            "firstName": "Mubarak",
                            "lastName": "Shah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Shah"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 87
                            }
                        ],
                        "text": "For the above systems, action classi cation is based on hard-coded decision trees [16] [20] [79], nearest neighbor criteria [38] [65] or is based on general pattern matching techniques for time-varying data, as described in Section 6."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 12
                            }
                        ],
                        "text": "Others [16] [20] [77] [79] consider the motion trajectories of the hand centroids."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 135
                            }
                        ],
                        "text": "Earlier reviews on non-rigid motion, motion-based recognition and gesture interpretation were given by Aggarwal et al. [1], Cedras and Shah [14] and Pavlovic, Sharma and Huang [61], respectively."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 106
                            }
                        ],
                        "text": "[18] Geurtz [27] Dorner [21] Darell and Pentland [19] Goddard [28] Downton and Drouet [22] Davis and Shah [20] Guo et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7097815,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6f2df5d02d226d75d7c47b203d7054f7bcf3dbd",
            "isKey": true,
            "numCitedBy": 139,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for recognizing human-hand gestures using a model-based approach. A nite state machine is used to model four qualitatively distinct phases of a generic gesture. Fingertips are tracked in multiple frames to compute motion trajectories. The trajectories are then used for nding the start and stop position of the gesture. Gestures are represented as a list of vectors and are then matched to stored gesture vector models using table lookup based on vector displacements. Results are presented showing recognition of seven gestures using images sampled at 4Hz on a SPARC-1 without any special hardware. The seven gestures are representatives for"
            },
            "slug": "Gesture-Recognition-Davis-Shah",
            "title": {
                "fragments": [],
                "text": "Gesture Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "This paper presents a method for recognizing human-hand gestures using a model-based approach and results are presented showing recognition of seven gestures using images sampled at 4Hz on a SPARC-1 without any special hardware."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47600483"
                        ],
                        "name": "J. K. Aggarwal",
                        "slug": "J.-K.-Aggarwal",
                        "structuredName": {
                            "firstName": "Jagdishkumar",
                            "lastName": "Aggarwal",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. K. Aggarwal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1851641"
                        ],
                        "name": "Q. Cai",
                        "slug": "Q.-Cai",
                        "structuredName": {
                            "firstName": "Quin",
                            "lastName": "Cai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Cai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33832634"
                        ],
                        "name": "W. Liao",
                        "slug": "W.-Liao",
                        "structuredName": {
                            "firstName": "Wen-Hung",
                            "lastName": "Liao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Liao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "91886573"
                        ],
                        "name": "B. Sabata",
                        "slug": "B.-Sabata",
                        "structuredName": {
                            "firstName": "Bk",
                            "lastName": "Sabata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sabata"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15793598,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "9f116f0922ea7704f1cdb4a4a254f2fb2aac4ab8",
            "isKey": false,
            "numCitedBy": 128,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "Motion of physical objects is non-rigid, in general. Most researchers have focused on the study of the motion and structure of rigid objects because of its simplicity and elegance. Recently, investigation of non-rigid structure and motion transformation has drawn the attention of researchers from a wide spectrum of disciplines. Since the non-rigid motion class encompasses a huge domain, we restrict our overview to the motion analysis of articulated and elastic non-rigid objects. Numerous approaches that have been proposed to recover the 3D structure and motion of objects are studied. The discussion includes both: 1) motion recovery without shape models, and 2) model-based analysis, and covers a number of examples of real world objects.<<ETX>>"
            },
            "slug": "Articulated-and-elastic-non-rigid-motion:-a-review-Aggarwal-Cai",
            "title": {
                "fragments": [],
                "text": "Articulated and elastic non-rigid motion: a review"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The discussion includes both: 1) motion recovery without shape models, and 2) model-based analysis, and covers a number of examples of real world objects."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1994 IEEE Workshop on Motion of Non-rigid and Articulated Objects"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145505338"
                        ],
                        "name": "S. Tamura",
                        "slug": "S.-Tamura",
                        "structuredName": {
                            "firstName": "Shinichi",
                            "lastName": "Tamura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Tamura"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059277796"
                        ],
                        "name": "S. Kawasaki",
                        "slug": "S.-Kawasaki",
                        "structuredName": {
                            "firstName": "Shingo",
                            "lastName": "Kawasaki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kawasaki"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 205012928,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "69494481ace5549e8dfe2041cdc006090997c7a7",
            "isKey": false,
            "numCitedBy": 136,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Recognition-of-sign-language-motion-images-Tamura-Kawasaki",
            "title": {
                "fragments": [],
                "text": "Recognition of sign language motion images"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145271456"
                        ],
                        "name": "A. Azarbayejani",
                        "slug": "A.-Azarbayejani",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Azarbayejani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Azarbayejani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 19017719,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2d7bcb538b03c67e5e7daecabd26d4941fa1bb07",
            "isKey": false,
            "numCitedBy": 177,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a method for estimation of 3D geometry from 2D blob features. Blob features are clusters of similar pixels in the image plane and can arise from similarity of color, texture, motion and other signal-based metrics. The motivation for considering such features comes from recent successes in real-time extraction and tracking of such blob features in complex cluttered scenes in which traditional feature finders fail, e.g. scenes containing moving people. We use nonlinear modeling and a combination of iterative and recursive estimation methods to recover 3D geometry from blob correspondences across multiple images. The 3D geometry includes the 3D shapes, translations, and orientations of blobs and the relative orientation of the cameras. Using this technique, we have developed a real-time wide-baseline stereo person tracking system which can self-calibrate itself from watching a moving person and can subsequently track people's head and hands with RIMS errors of 1-2 cm in translation and 2 degrees in rotation. The blob formulation is efficient and reliable, running at 20-30 Hz on a pair of SGI Indy R4400 workstations with no special hardware."
            },
            "slug": "Real-time-self-calibrating-stereo-person-tracking-Azarbayejani-Pentland",
            "title": {
                "fragments": [],
                "text": "Real-time self-calibrating stereo person tracking using 3-D shape estimation from blob features"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A real-time wide-baseline stereo person tracking system which can self-calibrate itself from watching a moving person and can subsequently track people's head and hands with RIMS errors of 1-2 cm in translation and 2 degrees in rotation."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 13th International Conference on Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40178596"
                        ],
                        "name": "T. Heap",
                        "slug": "T.-Heap",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Heap",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Heap"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1967104"
                        ],
                        "name": "David C. Hogg",
                        "slug": "David-C.-Hogg",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hogg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David C. Hogg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 31
                            }
                        ],
                        "text": "Finally, work by Heap and Hogg [31] involves an example-based approach"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 17
                            }
                        ],
                        "text": "Finally, work by Heap and Hogg [31] involves an example-based approach\nto articulated pose recovery."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 13
                            }
                        ],
                        "text": "Baumberg and Hogg [8] apply Active Shape Models to the tracking of pedestrians."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 90
                            }
                        ],
                        "text": "In terms of experimental results on whole (or upper body) movement using a single camera, Hogg [36] and Rohr [71] deal with the restricted movement of gait (parallel to image plane)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 98
                            }
                        ],
                        "text": "Typical measures are correlation on a raw or smoothed LOG- ltered image [29] [70], perpendicular- [31] and chamfer-distance [26] (from projected model edges to image edges) and straight-line distance metrics [71]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 0
                            }
                        ],
                        "text": "Heap and Hogg [31] show preliminary tracking results on hand model and hand pose recovery."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2267948,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8f0eef23c9e5eba83a73113cf9950a90d695233e",
            "isKey": true,
            "numCitedBy": 276,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we first describe how we have constructed a 3D deformable Point Distribution Model of the human hand, capturing training data semi-automatically from volume images via a physically-based model. We then show how we have attempted to use this model in tracking an unmarked hand moving with 6 degrees of freedom (plus deformation) in real time using a single video camera. In the course of this we show how to improve on a weighted least-squares pose parameter approximation at little computational cost. We note the successes and shortcomings of our system and discuss how it might be improved."
            },
            "slug": "Towards-3D-hand-tracking-using-a-deformable-model-Heap-Hogg",
            "title": {
                "fragments": [],
                "text": "Towards 3D hand tracking using a deformable model"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A 3D deformable Point Distribution Model of the human hand is constructed, capturing training data semi-automatically from volume images via a physically-based model and how to improve on a weighted least-squares pose parameter approximation at little computational cost is shown."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Second International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "122003543"
                        ],
                        "name": "S. Niyogi",
                        "slug": "S.-Niyogi",
                        "structuredName": {
                            "firstName": "Sumanta",
                            "lastName": "Niyogi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Niyogi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2169042067"
                        ],
                        "name": "E. Adelson",
                        "slug": "E.-Adelson",
                        "structuredName": {
                            "firstName": "EH",
                            "lastName": "Adelson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Adelson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 24
                            }
                        ],
                        "text": "Niyogi and Adelson [56] [57] advocate segmentation over time because of robustness; their procedure involves nding human silhouettes with deformable contours in X-T space [56] or deformable surfaces in X-Y-T space [57]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 146
                            }
                        ],
                        "text": "[38] Leung and Yang [48] Ho man and Flinchbaugh [35] Johansson [39] Long and Yang [49] Hogg [36] Kjeldsen and Kender [44] Niyogi and Adelson [56] [57] Holt et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 766730,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "2a4744d550764de0170fe31bcec73e6562e1438a",
            "isKey": false,
            "numCitedBy": 160,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Human motions generate characteristic spatiotemporal patterns. We have developed a set of techniques for analyzing the patterns generated by people walking across the field of view. After change detection, the XYT pattern can be fit with a smooth spatiotemporal surface. This surface is approximately periodic, reflecting the periodicity of the gait. The surface can be expressed as a combination of a standard parameterized surface-the canonical walk-and a deviation surface that is specific to the individual walk.<<ETX>>"
            },
            "slug": "Analyzing-gait-with-spatiotemporal-surfaces-Niyogi-Adelson",
            "title": {
                "fragments": [],
                "text": "Analyzing gait with spatiotemporal surfaces"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A set of techniques for analyzing the patterns generated by people walking across the field of view, including the XYT pattern, which can be fit with a smooth spatiotemporal surface reflecting the periodicity of the gait."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1994 IEEE Workshop on Motion of Non-rigid and Articulated Objects"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403941699"
                        ],
                        "name": "M. Studdert-Kennedy",
                        "slug": "M.-Studdert-Kennedy",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Studdert-Kennedy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Studdert-Kennedy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In the hand gesture area, there have been many studies on how humans use and interpret gestures; see for example work by McNeill [52]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13569413,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "cda4cfadf25c6bef41d9db0a3a98001c1b42493b",
            "isKey": false,
            "numCitedBy": 1941,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "The argument of this original and difficult book is that \u201cgestures are an integral part of language as much as are words, phrases and sentences-gestures and language are one system\u201d (p. 2) . Gestures are instantaneous, imagistic, analog, holistic expressions of the same thought that speech renders in hierarchical, linear, digital, analytic form. David McNeill credits Adam Kendon (1972, 1980) with discovering the link between, and essential unity of, speech sounds and gestural movements; his own work elaborates this insight at the higher linguistic levels of semantics and pragmatics. The topic of the book, then, is gestures that accompany speech, the left-hand end of what McNeill calls \u201c K e n h i \u2019 s coiitiiiiiiim: Gesticulation + Language-like gestures + Pantomimes 3 Emblems + Sign languages\u201d (p. 37). The continuum ranges from the informal, spontaneous, idiosyncratic movements of the hands and arms that often accompany speech, to the socially-regulated, standardized, linguistic forms of a sign language, with its arbitrary (non-iconic) lexicon. Between these poles the obligatory presence of speech declines and the linguistic properties of gestures increase. \u201cLanguage-like gestures\u201d are grammatically integrated into an utterance, as when a speaker, asked about the weather on his vacation, replies: \u201cWell, it was [oscillating hand gesture]\u201d, where the \u201cso-so\u201d gesture replaces an adjectival predicate. \u201cPantomime\u201d conveys its full meaning in silence or, at most, with inarticulate onomatopoeia; also, in pantomime, sequences of gestures can form a unit, as they can in a sign language, but cannot in gesticulation. \u201cEmblems\u201d conform to standards of wellformedness, a language-like property that gesticulation and pantomime lack: in England, the palm-front V-sign is Churchill\u2019s \u201cVictory!\u201d, the palm-back V-sign is a sexual insult. (For an amusing cross-class confusion in emblem dialects, see Collett, Marsh, and O\u2019Shaughnessy, 1979, p. 229, where Margaret Thatcher appears in an Associated Press Photo, making the palm-back V-sign at a moment of electoral triumph.) The contrast between the two ends of Kendon\u2019s continuum, between spontaneous gesture and conventional sign, epitomizes McNeill\u2019s notion of the process by which an utterance evolves in a speaker\u2019s mind. Spontaneous gesture reveals the primitive stage of an utterance, global, unsegmented, non-hierarchical, from which its conventional representation in speech unfolds: hierarchical, segmented, linear. The inner symbols of the primitive stage are private, idiosyncratic, closed to social influence; the end stage is public, grammatical, socially regulated. McNeill supposes that the primitive"
            },
            "slug": "Hand-and-Mind:-What-Gestures-Reveal-About-Thought.-Studdert-Kennedy",
            "title": {
                "fragments": [],
                "text": "Hand and Mind: What Gestures Reveal About Thought."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684626"
                        ],
                        "name": "B. Heisele",
                        "slug": "B.-Heisele",
                        "structuredName": {
                            "firstName": "Bernd",
                            "lastName": "Heisele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Heisele"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693201"
                        ],
                        "name": "U. Kressel",
                        "slug": "U.-Kressel",
                        "structuredName": {
                            "firstName": "Ulrich",
                            "lastName": "Kressel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Kressel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143911258"
                        ],
                        "name": "W. Ritter",
                        "slug": "W.-Ritter",
                        "structuredName": {
                            "firstName": "Werner",
                            "lastName": "Ritter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Ritter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[32] used groups of pixels as basic units for trackin Pixels are grouped by clustering techniques in combined c (R, G, B) and spatial ( x, y) dimensions; the motivation for thi is that adding spatial information makes clustering more sta than using only color information."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 38
                            }
                        ],
                        "text": "ow (from Heisele, Kressel, and Ritter [32], c \u00a9 1997 IEEE)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[32] Kurakake and Nevatia [47] Hel-Or and Werman [33] Hunteret al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15510755,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d1a7225c4a0050d9c65dcaf2ed03013fc6d1264b",
            "isKey": false,
            "numCitedBy": 138,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "In this contribution we present an algorithm for tracking non-rigid, moving objects in a sequence of colored images, which were recorded by a non-stationary camera. The application background is vision-based driving assistance in the inner city. In an initial step, object parts are determined by a divisive clustering algorithm, which is applied to all pixels in the first image of the sequence. The feature space is defined by the color and position of a pixel. For each new image the clusters of the previous image are adapted iteratively by a parallel k-means clustering algorithm. Instead of tracking single points, edges, or areas over a sequence of images, only the centroids of the clusters are tracked. The proposed method remarkably simplifies the correspondence problem and also ensures a robust tracking behaviour."
            },
            "slug": "Tracking-non-rigid,-moving-objects-based-on-color-Heisele-Kressel",
            "title": {
                "fragments": [],
                "text": "Tracking non-rigid, moving objects based on color cluster flow"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "An algorithm for tracking non-rigid, moving objects in a sequence of colored images, which were recorded by a non-stationary camera is presented, which remarkably simplifies the correspondence problem and also ensures a robust tracking behaviour."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2679389"
                        ],
                        "name": "A. Baumberg",
                        "slug": "A.-Baumberg",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Baumberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Baumberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1967104"
                        ],
                        "name": "David C. Hogg",
                        "slug": "David-C.-Hogg",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hogg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David C. Hogg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This method was mentioned earlier in the 2-D context; see Section 3 [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Principal component analysis on a data set of pedestrians represented by B-splines; shown is the shape variation along the principal component (from Baumberg and Hogg [8], c \u00a9 1994 IEEE)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Baumberg and Hogg [8] applied active shape models to the tracking of pedestrians."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62491650,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "67eac618325d5f5f31ce17922d51fad995a57749",
            "isKey": false,
            "numCitedBy": 283,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "There has been considerable research interest recently, in the areas of real time contour tracking and active shape models. This paper demonstrates how dynamic filtering can be used in combination with a modal-based flexible shape model to track an articulated non-rigid body in motion. The results show the method being used to track the silhouette of a walking pedestrian in real time. The active shape model used was generated automatically from real image data and incorporates variability in shape due to orientation as well as object flexibility. A Kalman filter is used to control spatial scale for feature search over successive frames. Iterative refinement allows accurate contour localisation where feasible. The shape model incorporates knowledge of the likely shape of the contour and speeds up tracking by reducing the number of system parameters. A further increase in speed is obtained by filtering the shape parameters independently.<<ETX>>"
            },
            "slug": "An-efficient-method-for-contour-tracking-using-Baumberg-Hogg",
            "title": {
                "fragments": [],
                "text": "An efficient method for contour tracking using active shape models"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper demonstrates how dynamic filtering can be used in combination with a modal-based flexible shape model to track an articulated non-rigid body in motion."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1994 IEEE Workshop on Motion of Non-rigid and Articulated Objects"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2679389"
                        ],
                        "name": "A. Baumberg",
                        "slug": "A.-Baumberg",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Baumberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Baumberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1967104"
                        ],
                        "name": "David C. Hogg",
                        "slug": "David-C.-Hogg",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hogg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David C. Hogg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 6616644,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5f98e31c7eb1c6056428db6b9020f14e78b2cc38",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "There has been considerable research interest recently in the areas of real time contour tracking and active shape models This paper demonstrates how dynamic ltering can be used in combination with a exible shape model to track an articulated non rigid body in motion The results show the method being used to track the silhouette of a walking pedestrian across a scene in real time The active shape model used was generated automatically from real image data and incorporates variability in shape due to orientation as well as object exibility A Kalman lter is used to control spatial scale for fea ture search over successive frames and for contour re nement on an individual frame Iterative re nement allows accurate contour localisation where feasible although there is a trade o between speed and accuracy The shape model in corporates knowledge of the likely shape of the contour and speeds up tracking by reducing the number of system parameters A further increase in speed is obtained by ltering the shape parameters independently"
            },
            "slug": "An-Eecient-Method-for-Contour-Tracking-Using-Active-Baumberg-Hogg",
            "title": {
                "fragments": [],
                "text": "An Eecient Method for Contour Tracking Using Active Shape Models"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper demonstrates how dynamic ltering can be used in combination with a exible shape model to track an articulated non rigid body in motion."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711560"
                        ],
                        "name": "Dimitris N. Metaxas",
                        "slug": "Dimitris-N.-Metaxas",
                        "structuredName": {
                            "firstName": "Dimitris",
                            "lastName": "Metaxas",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dimitris N. Metaxas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750924"
                        ],
                        "name": "Demetri Terzopoulos",
                        "slug": "Demetri-Terzopoulos",
                        "structuredName": {
                            "firstName": "Demetri",
                            "lastName": "Terzopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Demetri Terzopoulos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 31199185,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "6628820be220d48c567095f3aa8ac06516b730be",
            "isKey": false,
            "numCitedBy": 459,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "A physics-based framework for 3-D shape and nonrigid motion estimation for real-time computer vision systems is presented. The framework features dynamic models that incorporate the mechanical principles of rigid and nonrigid bodies into conventional geometric primitives. Through the efficient numerical simulation of Lagrange equations of motion, the models can synthesize physically correct behaviors in response to applied forces and imposed constraints. Applying continuous Kalman filtering theory, a recursive shape and motion estimator that employs the Lagrange equations as a system model is developed. The system model continually synthesizes nonrigid motion in response to generalized forces that arise from the inconsistency between the incoming observations and the estimated model state. The observation forces also account formally for instantaneous uncertainties and incomplete information. A Riccati procedure updates a covariance matrix that transforms the forces in accordance with the system dynamics and prior observation history. Experiments involving model fitting and tracking of articulated and flexible objects from noisy 3-D data are described. >"
            },
            "slug": "Shape-and-Nonrigid-Motion-Estimation-Through-Metaxas-Terzopoulos",
            "title": {
                "fragments": [],
                "text": "Shape and Nonrigid Motion Estimation Through Physics-Based Synthesis"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A physics-based framework for 3-D shape and nonrigid motion estimation for real-time computer vision systems is presented and a recursive shape and motion estimator that employs the Lagrange equations as a system model is developed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144658464"
                        ],
                        "name": "V. Pavlovic",
                        "slug": "V.-Pavlovic",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Pavlovic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Pavlovic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49664054"
                        ],
                        "name": "Rajeev Sharma",
                        "slug": "Rajeev-Sharma",
                        "structuredName": {
                            "firstName": "Rajeev",
                            "lastName": "Sharma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rajeev Sharma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 15
                            }
                        ],
                        "text": "See Aizawa and Huang [2] for a good overview."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 57
                            }
                        ],
                        "text": "[1], Cedras and Shah [14] and Pavlovic, Sharma and Huang [61], respectively."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 10
                            }
                        ],
                        "text": "Chang and Huang [15] detect ribbons corresponding to the arms and feet."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 9
                            }
                        ],
                        "text": "Kuch and Huang [46] use a greedy search strategy based on perturbation of individual state parameters."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 149
                            }
                        ],
                        "text": "Earlier reviews on non-rigid motion, motion-based recognition and gesture interpretation were given by Aggarwal et al. [1], Cedras and Shah [14] and Pavlovic, Sharma and Huang [61], respectively."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7185733,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "8dd3d5ef2e1c40433417cd90e21ce9a0468a7626",
            "isKey": true,
            "numCitedBy": 1923,
            "numCiting": 168,
            "paperAbstract": {
                "fragments": [],
                "text": "In a process for preparing phosphoric acid by contact of sulphuric acid and phosphate rock with filtration of the gypsum slurry and recycle of the rest for contact with fresh rock, a fraction of the recycle slurry is treated with sulphuric acid to convert at least some of the gypsum to calcium sulphate hemihydrate and the slurry comprising hemihydrate is returned to contact the mixture of phosphate rock, phosphoric acid and recycle gypsum slurry. The process gives an easily filtered gypsum slurry with low phosphate losses in the gypsum filter cake."
            },
            "slug": "Visual-Interpretation-of-Hand-Gestures-for-A-Review-Pavlovic-Sharma",
            "title": {
                "fragments": [],
                "text": "Visual Interpretation of Hand Gestures for Human-Computer Interaction: A Review"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A fraction of the recycle slurry is treated with sulphuric acid to convert at least some of the gypsum to calcium sulphate hemihydrate and the slurry comprising hemihYDrate is returned to contact the mixture of phosphate rock, phosphoric acid and recycle Gypsum slurry."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49634061"
                        ],
                        "name": "U. Franke",
                        "slug": "U.-Franke",
                        "structuredName": {
                            "firstName": "Uwe",
                            "lastName": "Franke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Franke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144854796"
                        ],
                        "name": "D. Gavrila",
                        "slug": "D.-Gavrila",
                        "structuredName": {
                            "firstName": "Dariu",
                            "lastName": "Gavrila",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gavrila"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2262044"
                        ],
                        "name": "S. G\u00f6rzig",
                        "slug": "S.-G\u00f6rzig",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "G\u00f6rzig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. G\u00f6rzig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145881356"
                        ],
                        "name": "F. Lindner",
                        "slug": "F.-Lindner",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Lindner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Lindner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050256"
                        ],
                        "name": "F. Paetzold",
                        "slug": "F.-Paetzold",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Paetzold",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Paetzold"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696091"
                        ],
                        "name": "C. W\u00f6hler",
                        "slug": "C.-W\u00f6hler",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "W\u00f6hler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. W\u00f6hler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 110593990,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f76998e7c8f6386409a58dcd1b60776507d895dc",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Most computer vision systems for vehicle guidance developed in the past were designed for the comparatively simple highway scenario. Autonomous driving in the much more complex scenario of urban traffic or driver assistance systems like Intelligent Stop&Go are new challenges not only from the algorithmic but also from the system architecture point of view. This contribution describes our current work on these topics. It includes the appropriate algorithms as well as approaches to control the various vision modules."
            },
            "slug": "Autonomous-Driving-approaches-Downtown-Franke-Gavrila",
            "title": {
                "fragments": [],
                "text": "Autonomous Driving approaches Downtown"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "This contribution describes the current work on autonomous driving in the much more complex scenario of urban traffic or driver assistance systems like Intelligent Stop&Go, which includes the appropriate algorithms as well as approaches to control the various vision modules."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33568342"
                        ],
                        "name": "C. Myers",
                        "slug": "C.-Myers",
                        "structuredName": {
                            "firstName": "Cory",
                            "lastName": "Myers",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Myers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14833627"
                        ],
                        "name": "A. Rosenberg",
                        "slug": "A.-Rosenberg",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Rosenberg",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rosenberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Dynamic time warping (DTW) [55] is a wellknown technique to match a test pattern with a reference pattern if their time scales are not perfectly aligned but when time ordering constraints do hold."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "If the sizes of the test pattern and reference pattern are N and M , an optimal match is found by dynamic programming in O(N \u00d7M2) time (or in O(N \u00d7M) time, if one introduces local continuity constraints, see [55])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14297130,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c2affcf33baef4fe2e595f3f90ec534fb1aa61c5",
            "isKey": false,
            "numCitedBy": 573,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "The technique of dynamic programming for the time registration of a reference and a test pattern has found widespread use in the area of isolated word recognition. Recently, a number of variations on the basic time warping algorithm have been proposed by Sakoe and Chiba, and Rabiner, Rosenberg, and Levinson. These algorithms all assume that the test input is the time pattern of a feature vector from an isolated word whose endpoints are known (at least approximately). The major differences in the methods are the global path constraints (i.e., the region of possible warping paths), the local continuity constraints on the path, and the distance weighting and normalization used to give the overall minimum distance. The purpose of this investigation is to study the effects of such variations on the performance of different dynamic time warping algorithms for a realistic speech database. The performance measures that were used include: speed of operation, memory requirements, and recognition accuracy. The results show that both axis orientation and relative length of the reference and the test patterns are important factors in recognition accuracy. Our results suggest a new approach to dynamic time warping for isolated words in which both the reference and test patterns are linearly warped to a fixed length, and then a simplified dynamic time warping algorithm is used to handle the nonlinear component of the time alignment. Results with this new algorithm show performance comparable to or better than that of all other dynamic time warping algorithms that were studied."
            },
            "slug": "Performance-tradeoffs-in-dynamic-time-warping-for-Myers-Rabiner",
            "title": {
                "fragments": [],
                "text": "Performance tradeoffs in dynamic time warping algorithms for isolated word recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "The results suggest a new approach to dynamic time warping for isolated words in which both the reference and test patterns are linearly warped to a fixed length, and then a simplified dynamic time Warping algorithm is used to handle the nonlinear component of the time alignment."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34469963"
                        ],
                        "name": "J. J. Kuch",
                        "slug": "J.-J.-Kuch",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Kuch",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. J. Kuch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 15
                            }
                        ],
                        "text": "See Aizawa and Huang [2] for a good overview."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 175
                            }
                        ],
                        "text": "Instead, it uses the measurement equation directly to synthesize the model and uses a tting measure between synthesized and observed features for feedback; see [22] [26] [36] [46] [58] [64] [71]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 106
                            }
                        ],
                        "text": "[84] Kahn and Swain [41] Polana and Nelson [65] Kakadiaris and Metaxas [42] [43] Quek [66] Kuch and Huang [46] Rangarajan et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 10
                            }
                        ],
                        "text": "Chang and Huang [15] detect ribbons corresponding to the arms and feet."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "Kuch and Huang [46] use a greedy search strategy based on perturbation of individual state parameters."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 27
                            }
                        ],
                        "text": "based on image intensities [46] [81] or optical ow [85]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 170
                            }
                        ],
                        "text": "Earlier reviews on non-rigid motion, motion-based recognition and gesture interpretation were given by Aggarwal et al. [1], Cedras and Shah [14] and Pavlovic, Sharma and Huang [61], respectively."
                    },
                    "intents": []
                }
            ],
            "corpusId": 29672561,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "084bc4a55619f3215b1df1dc1af488842d7df15d",
            "isKey": true,
            "numCitedBy": 182,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors present a hand model that simultaneously satisfies both the synthesis and analysis requirements of model based compression. The model can be fitted to any person's hand and can be done using a single camera. Once the model is fitted to a real human hand, it is then used in several tracking scenarios in order to verify its effectiveness. With successful tracking achieved, the model is ready to be incorporated into a virtual environment or model based compression scheme such as sign language communication over telephone lines or virtual teleconferences over computer networks at very low bit rates and at very high image quality.<<ETX>>"
            },
            "slug": "Vision-based-hand-modeling-and-tracking-for-virtual-Kuch-Huang",
            "title": {
                "fragments": [],
                "text": "Vision based hand modeling and tracking for virtual teleconferencing and telecollaboration"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "The authors present a hand model that simultaneously satisfies both the synthesis and analysis requirements of model based compression and is ready to be incorporated into a virtual environment or model based compressed scheme such as sign language communication over telephone lines or virtual teleconferences over computer networks."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41183001"
                        ],
                        "name": "N. Thalmann",
                        "slug": "N.-Thalmann",
                        "structuredName": {
                            "firstName": "Nadia",
                            "lastName": "Thalmann",
                            "middleNames": [
                                "Magnenat"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Thalmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143725529"
                        ],
                        "name": "D. Thalmann",
                        "slug": "D.-Thalmann",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Thalmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Thalmann"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 120
                            }
                        ],
                        "text": "Some of the issues have been how to specify spatial interactions and high-level tasks for the human models; see [5] [6] [50]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60630417,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "767c6a84cadb761d81586eeb415c3c1db43bdb20",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "As stated by Norman Badler [1982], one of the best-known specialists in this area, modeling realistic human forms remains one of the most difficult and challenging problems."
            },
            "slug": "Human-Modeling-and-Animation-Thalmann-Thalmann",
            "title": {
                "fragments": [],
                "text": "Human Modeling and Animation"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "As stated by Norman Badler [1982], one of the best-known specialists in this area, modeling realistic human forms remainsone of the most difficult and challenging problems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738894"
                        ],
                        "name": "T. Starner",
                        "slug": "T.-Starner",
                        "structuredName": {
                            "firstName": "Thad",
                            "lastName": "Starner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Starner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069315980"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 133
                            }
                        ],
                        "text": "[68] Ohya and Kishino [58] Segen and Pingali [73] O'Rourke and Badler [60] Shio and Sklansky [75] Pentland [62] Starner and Pentland [77] Perales and Torres [64] Takahashi et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 67
                            }
                        ],
                        "text": "Rather than requiring the typical point features, Azarbayejani and Pentland [4] \\triangulate\" using blob features [84]; a 3-"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 75
                            }
                        ],
                        "text": "In other cases, the application involved seemingly complex activities [65] [77] with no straightforward recognition solution."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 17
                            }
                        ],
                        "text": "Others [16] [20] [77] [79] consider the motion trajectories of the hand centroids."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 16
                            }
                        ],
                        "text": "Both Darell and Pentland [19] and Kjeldsen and Kender [44] use the image pixels directly as input."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 17
                            }
                        ],
                        "text": "Azarbayejani and Pentland [4] obtain the 3-"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 15
                            }
                        ],
                        "text": "In other work, Pentland [62] ts deformable superquadrics to range data."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 23
                            }
                        ],
                        "text": "The work by Darell and Pentland [19] aims to build view models automatically by adding views to the model set whenever correlation with the existing views falls below a certain threshold."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 132
                            }
                        ],
                        "text": "Because of these bene ts, HMMs are currently widespread in speech recognition and more recently in matching human movement patterns [77] [86]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1166742,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "87b75831b61cea4b7cb3f549d47d52c93f6f2bd5",
            "isKey": true,
            "numCitedBy": 953,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Hidden Markov models (HMMs) have been used prominently and successfully in speech recognition and, more recently, in handwriting recognition. Consequently, they seem ideal for visual recognition of complex, structured hand gestures such as are found in sign language. We describe a real-time HMM-based system for recognizing sentence level American Sign Language (ASL) which attains a word accuracy of 99.2% without explicitly modeling the fingers."
            },
            "slug": "Real-time-American-Sign-Language-recognition-from-Starner-Pentland",
            "title": {
                "fragments": [],
                "text": "Real-time American Sign Language recognition from video using hidden Markov models"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A real-time HMM-based system for recognizing sentence level American Sign Language (ASL) which attains a word accuracy of 99.2% without explicitly modeling the fingers."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3021334"
                        ],
                        "name": "A. Barr",
                        "slug": "A.-Barr",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Barr",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Barr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 66
                            }
                        ],
                        "text": "tapering, bending) and/or local deformations on the superquadrics [7] [26] [43] [53] [62]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 69
                            }
                        ],
                        "text": "More accurate modeling of body parts is obtained using superquadrics [7]; these are generalizations of ellipsoids which have additional \\squareness\" parameters along each axis."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16162806,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "3739bc6d4be47169fc9a24a4b9a54b4ab67e21e1",
            "isKey": false,
            "numCitedBy": 946,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "New hierarchical solid modeling operations are developed, which simulate twisting, bending, tapering, or similar transformations of geometric objects. The chief result is that the normal vector of an arbitrarily deformed smooth surface can be calculated directly from the surface normal vector of the undeformed surface and a transformation matrix. Deformations are easily combined in a hierarchical structure, creating complex objects from simpler ones. The position vectors and normal vectors in the simpler objects are used to calculate the position and normal vectors in the more complex forms; each level in the deformation hierarchy requires an additional matrix multiply for the normal vector calculation. Deformations are important and highly intuitive operations which ease the control and rendering of large families of three-dimensional geometric shapes."
            },
            "slug": "Global-and-local-deformations-of-solid-primitives-Barr",
            "title": {
                "fragments": [],
                "text": "Global and local deformations of solid primitives"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "New hierarchical solid modeling operations are developed, which simulate twisting, bending, tapering, or similar transformations of geometric objects, and the chief result is that the normal vector of an arbitrarily deformed smooth surface can be calculated directly from the surfacenormal vector of the undeformed surface and a transformation matrix."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145963824"
                        ],
                        "name": "M. Spong",
                        "slug": "M.-Spong",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Spong",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Spong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 76
                            }
                        ],
                        "text": "Relevant rotations are generally described by their three Euler angles [13] [76]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 158
                            }
                        ],
                        "text": "One approach using such parametrized models [21] [29] [69] [70] [81] [85] [87] updates pose by inverse kinematics, a common technique in robot control theory [76]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14613723,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "7976560c96c3fd326c1f7efb4f96595b9c39e893",
            "isKey": false,
            "numCitedBy": 3752,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nThis self-contained introduction to practical robot kinematics and dynamics includes a comprehensive treatment of robot control. Provides background material on terminology and linear transformations, followed by coverage of kinematics and inverse kinematics, dynamics, manipulator control, robust control, force control, use of feedback in nonlinear systems, and adaptive control. Each topic is supported by examples of specific applications. Derivations and proofs are included in many cases. Includes many worked examples, examples illustrating all aspects of the theory, and problems."
            },
            "slug": "Robot-dynamics-and-control-Spong",
            "title": {
                "fragments": [],
                "text": "Robot dynamics and control"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "This self-contained introduction to practical robot kinematics and dynamics includes a comprehensive treatment of robot control, providing background material on terminology and linear transformations and examples illustrating all aspects of the theory and problems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712839"
                        ],
                        "name": "K. Aizawa",
                        "slug": "K.-Aizawa",
                        "structuredName": {
                            "firstName": "Kiyoharu",
                            "lastName": "Aizawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Aizawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143750392"
                        ],
                        "name": "T. Huang",
                        "slug": "T.-Huang",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Huang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59181404,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f75f68578f503ddbd86d51e4afbb9a09af9de0c0",
            "isKey": false,
            "numCitedBy": 260,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper gives an overview of model-based approaches applied to image coding, by looking at image source models. In these model-based schemes, which are different from the various conventional waveform coding methods, the 3-D properties of the scenes are taken into consideration. They can achieve very low bit rate image transmission. The 2-D model and 3-D model based approaches are explained. Among them, a 3-D model based method using a 3-D facial model and a 2-D model based method utilizing 2-D deformable triangular patches are described. Works related to 3-D model-based coding of facial images and some of the remaining problems are also described. >"
            },
            "slug": "Model-based-image-coding-advanced-video-coding-for-Aizawa-Huang",
            "title": {
                "fragments": [],
                "text": "Model-based image coding advanced video coding techniques for very low bit-rate applications"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "An overview of model-based approaches applied to image coding, by looking at image source models, and works related to 3-D model- based coding of facial images and some of the remaining problems are described."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13618539,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "8fe2ea0a67954f1380b3387e3262f1cdb9f9b3e5",
            "isKey": false,
            "numCitedBy": 24804,
            "numCiting": 98,
            "paperAbstract": {
                "fragments": [],
                "text": "The fabric comprises a novel type of netting which will have particular utility in screening out mosquitoes and like insects and pests. The fabric is defined of voids having depth as well as width and length. The fabric is usable as a material from which to form clothing for wear, or bed coverings, or sleeping bags, etc., besides use simply as a netting."
            },
            "slug": "A-Tutorial-on-Hidden-Markov-Models-and-Selected-Rabiner",
            "title": {
                "fragments": [],
                "text": "A Tutorial on Hidden Markov Models and Selected Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The fabric comprises a novel type of netting which will have particular utility in screening out mosquitoes and like insects and pests."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1865772"
                        ],
                        "name": "A. Geurtz",
                        "slug": "A.-Geurtz",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Geurtz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Geurtz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Geurtz [ 27 ] performed hierarchical and articulated curve fitting with 2-D ellipsoids."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Baumberg and Hogg [8] Akita [3] Azarbayejani and Pentland [4] Bobick and Wilson [10] Cai and Aggarwal [11] Campbell and Bobick [13] Charayaphan and Marble [16] Chang and Huang [15] Chen and Lee [17] Cootes et al. [18] Geurtz [ 27 ] Dorner [21] Darell and Pentland [19] Goddard [28] Downton and Drouet [22] Davis and Shah [20] Guo et al. [30] Gavrila and Davis [25] [26] Franke et al. [23] Herman [34] Goncalves et al. [29] Freeman et al. [24] Ju ..."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 205050418,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "8b1d3d6222d6695357bc94c760fd259b219526be",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Model-based-shape-estimation-Geurtz",
            "title": {
                "fragments": [],
                "text": "Model based shape estimation"
            },
            "venue": {
                "fragments": [],
                "text": "Signal Process."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50757577"
                        ],
                        "name": "F. Perera",
                        "slug": "F.-Perera",
                        "structuredName": {
                            "firstName": "Frederica",
                            "lastName": "Perera",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Perera"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9486719,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "dc332165352a3eab6e824f353855623352e9bd2f",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A growing discipline called molecular epidemiology is attempting to find early biological signposts for heightened risk of cancer. The research should enhance prevention of the disease."
            },
            "slug": "Uncovering-new-clues-to-cancer-risk.-Perera",
            "title": {
                "fragments": [],
                "text": "Uncovering new clues to cancer risk."
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "A growing discipline called molecular epidemiology is attempting to find early biological signposts for heightened risk of cancer, and this research should enhance prevention of the disease."
            },
            "venue": {
                "fragments": [],
                "text": "Scientific American"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 50
                            }
                        ],
                        "text": "Rather than requiring the typical point features, Azarbayejani and Pentland [4] \\triangulate\" using blob features [84]; a 3-"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 16
                            }
                        ],
                        "text": "Both Darell and Pentland [19] and Kjeldsen and Kender [44] use the image pixels directly as input."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 0
                            }
                        ],
                        "text": "Azarbayejani and Pentland [4] obtain the 3-"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 2
                            }
                        ],
                        "text": ", [4, 41]) have obtained 3-D data passive sensing techniques (i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 72
                            }
                        ],
                        "text": "Rather than requiring the typical point featu Azarbayejani and Pentland [4] \u201ctriangulated\u201d using blob fe tures [84]; a 3-D blob (shape, orientation) is recovered from pair of corresponding 2-D blob features using nonlinear e mation techniques."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 15
                            }
                        ],
                        "text": "In other work, Pentland [62] ts deformable superquadrics to range data."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 58
                            }
                        ],
                        "text": "Baumberg and Hogg [8] Akita [3] Azarbayejani and Pentland [4] Bobick and Wilson [10] Cai and Aggarwal [11] Campbell and Bobick [13] Charayaphan and Marble [16] Chang and Huang [15] Chen and Lee [17] Cooteset al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 23
                            }
                        ],
                        "text": "The work by Darell and Pentland [19] aims to build view models automatically by adding views to the model set whenever correlation with the existing views falls below a certain threshold."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 26
                            }
                        ],
                        "text": "Azarbayejani and Pentland [4] obtained 3-D locations of the face and hands by essentially triangu ing on blobs representing the skin regions in the stereo vie Perales and Torres [64] described a multi-view camera sys for whole-body tracking which requires input from a human o erator."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Real-time self-calibrating stereo pe tracking using 3-D shape estimation from blob features, in Proc"
            },
            "venue": {
                "fragments": [],
                "text": "of International Conference on Pattern Recognition, Vienna,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 27
                            }
                        ],
                        "text": "Also, the support of Larry Davis (University of Maryland) and Franz May (Daimler-Benz, Ulm) is gratefully acknowledged."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 89
                            }
                        ],
                        "text": "3-D human models \u201cELLEN\u201d and \u201cDARIU\u201d using tapered superquadrics (from Gavrila and Davis [26], c \u00a9 1995 IEEE)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 196
                            }
                        ],
                        "text": ", tapering, bending) and local deformations on the superquadrics [7, 26, 43, 53, Figure 11 shows an example of human modeling based o pered superquadrics that was used for 3-D model-based trac in [25, 26]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 14
                            }
                        ],
                        "text": "Gav and Davis [26] used local search based on best-first search."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 120
                            }
                        ],
                        "text": "Typical m sures are correlation on a raw or smoothed LOG-filtered im [29, 70], perpendicular- [31] and chamfer-distance [26] (fro projected model edges to image edges) and straight-line tance metrics [71]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": "sdodel to be sue uir[26] pe ard over ent, ely"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 149
                            }
                        ],
                        "text": "Instea uses the measurement equation directly to synthesize the m and uses a fitting measure between synthesized and observe tures for feedback; see [22, 26, 36, 46, 58, 64, 71]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 28
                            }
                        ],
                        "text": "[30] Gavrila and Davis [25] [26] Frankeet al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 9
                            }
                        ],
                        "text": "Finally, Gavrila and Davis [25] [26] show initial results on whole-body tracking using four cameras placed in the corners of a room; see Figure 14."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 27
                            }
                        ],
                        "text": "Finally, Gavrila and Davis [25, 26] showed instances whole-body tracking using four cameras placed in the corn of a room."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 0
                            }
                        ],
                        "text": "Gavrila and Davis [26] use local search based on best- rst search."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 79
                            }
                        ],
                        "text": "Will the Argentine Tango be danced in virtual reality? (from Gavrila and Davis [26],c \u00a9 1996 IEEE)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "3-D model-based tracking of humans in act a multi-view approach, inProc"
            },
            "venue": {
                "fragments": [],
                "text": "of IEEE Conference on Computer Visio and Pattern Recognition, San Francisco,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 175
                            }
                        ],
                        "text": "Another advantage of HMMs are their ability to deal with unsegmented data, i.e. dealing with continuous data streams\nwhere the beginning of a desired data segment is unknown (DTW could be adapted to handle this as well; see Continuous Dynamic Time Warping [78])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 155
                            }
                        ],
                        "text": "The ability to learn from training data and to develop internal representations under a sound mathematical framework make HMMs attractive when compared to DTW."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 27
                            }
                        ],
                        "text": "Dynamic Time Warping (DTW) [55] is a well-known technique to"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 208
                            }
                        ],
                        "text": "If the sizes of the test pattern and reference pattern are N and M , an optimal match is found by dynamic programming in O(N M(2)) time (or in O(N M) time, if one introduces local continuity constraints, see [55])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 22
                            }
                        ],
                        "text": "Dynamic Time Warping (DTW) [55] is a well-known technique to match a test pattern with a reference pattern if their time scales are not perfectly aligned but when time ordering constraints do hold."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Performance tradeo s in dynamic time warping algorithms for isolated word recognition"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on ASSP, 28(6):623{635,"
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 17
                            }
                        ],
                        "text": "Finally, work by Heap and Hogg [31] involves an example-based approach\nto articulated pose recovery."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 94
                            }
                        ],
                        "text": "Typical m sures are correlation on a raw or smoothed LOG-filtered im [29, 70], perpendicular- [31] and chamfer-distance [26] (fro projected model edges to image edges) and straight-line tance metrics [71]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 13
                            }
                        ],
                        "text": "Baumberg and Hogg [8] apply Active Shape Models to the tracking of pedestrians."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 90
                            }
                        ],
                        "text": "In terms of experimental results on whole (or upper body) movement using a single camera, Hogg [36] and Rohr [71] deal with the restricted movement of gait (parallel to image plane)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 31
                            }
                        ],
                        "text": "Finally, work by Heap and Hogg [31] involved an examp based approach to articulated pose recovery."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 0
                            }
                        ],
                        "text": "Heap and Hogg [31] show preliminary tracking results on hand model and hand pose recovery."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Towards 3-D hand tracking using a deforma model, inProc"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE International Conference on Automatic Face a Gesture Recognition,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 7
                            }
                        ],
                        "text": "Dorner [21] tracked articula 3-D hand motion (palm motion and finger bending/unbendi with a single camera."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 165
                            }
                        ],
                        "text": "On downside, by considering the (coupled) parameters simulta ously, one needs to work in a high-dimensional parameter sp One approach using such parametrized models [21, 29, 70, 81, 85, 87] updated pose by inverse kinematics, a comm technique in robot control theory [76]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 24
                            }
                        ],
                        "text": "[18] Geurtz [27] Dorner [21] Darell and Pentland [19] Goddard [28] Downton and Drouet [22] Davis and Shah [20] Guo et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 91
                            }
                        ],
                        "text": "Moreover, relying exc The ing siv ly on a few correspondences makes the resulting approach [21, 69] quite sensitive to occlusion."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "Dorner [21] tracks articulated 3-"
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hand shape identification and tracking for sign langu interpretation, inLooking at People, International Joint Conference o Artificial Intelligence, Chambery"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 26
                            }
                        ],
                        "text": "Finally, work by Heap and Hogg [31] involves an example-based approach\nto articulated pose recovery."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 68
                            }
                        ],
                        "text": "This method was mentioned earlier in the 2-D context; see Section 3 [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 18
                            }
                        ],
                        "text": "Baumberg and Hogg [8] apply Active Shape Models to the tracking of pedestrians."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 18
                            }
                        ],
                        "text": "Baumberg and Hogg [8] Akita [3] Azarbayejani and Pentland [4] Bobick and Wilson [10] Cai and Aggarwal [11] Campbell and Bobick [13] Charayaphan and Marble [16] Chang and Huang [15] Chen and Lee [17] Cootes et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 90
                            }
                        ],
                        "text": "In terms of experimental results on whole (or upper body) movement using a single camera, Hogg [36] and Rohr [71] deal with the restricted movement of gait (parallel to image plane)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 9
                            }
                        ],
                        "text": "Heap and Hogg [31] show preliminary tracking results on hand model and hand pose recovery."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An e cient method for contour tracking using active shape models"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of IEEE Workshop on Motion of Non-Rigid and Articulated Objects, pages 194{199, Austin,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 107
                            }
                        ],
                        "text": "[68] Ohya and Kishino [58] Segen and Pingali [73] O'Rourke and Badler [60] Shio and Sklansky [75] Pentland [62] Starner and Pentland [77] Perales and Torres [64] Takahashi et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 67
                            }
                        ],
                        "text": "Rather than requiring the typical point features, Azarbayejani and Pentland [4] \\triangulate\" using blob features [84]; a 3-"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 16
                            }
                        ],
                        "text": "Both Darell and Pentland [19] and Kjeldsen and Kender [44] use the image pixels directly as input."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 17
                            }
                        ],
                        "text": "Azarbayejani and Pentland [4] obtain the 3-"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 24
                            }
                        ],
                        "text": "In other work, Pentland [62] ts deformable superquadrics to range data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 23
                            }
                        ],
                        "text": "The work by Darell and Pentland [19] aims to build view models automatically by adding views to the model set whenever correlation with the existing views falls below a certain threshold."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 85
                            }
                        ],
                        "text": "tapering, bending) and/or local deformations on the superquadrics [7] [26] [43] [53] [62]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[62]) have used range data so far, given sensor-related drawbacks (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automatic extraction of deformable models"
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 127
                            }
                        ],
                        "text": "Baumberg and Hogg [8] Akita [3] Azarbayejani and Pentland [4] Bobick and Wilson [10] Cai and Aggarwal [11] Campbell and Bobick [13] Charayaphan and Marble [16] Chang and Huang [15] Chen and Lee [17] Cooteset al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": "Campbell and Bobick [13] used a phase\u2013space representa in which the velocity dimensions are projected out, discard the time component of the data altogether."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 0
                            }
                        ],
                        "text": "Campbell and Bobick [13] use a phase-space representation in which the velocity dimensions are projected out, discarding the time component of the data altogether."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 374,
                                "start": 366
                            }
                        ],
                        "text": "3-D graphical models for the human body generally consis two components: a representation for the skeletal structure \u201cstick figure\u201d) and a representation for the flesh surrounding The stick figure is simply a collection of segments and jo angles with various degree of freedom at the articulation s Relevant rotations are generally described by their three E a gles [13, 76]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recognition of human body motion us phase space constraints, in  Proc"
            },
            "venue": {
                "fragments": [],
                "text": "of International Conference on Compute Vision, Cambridge,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 19
                            }
                        ],
                        "text": "Downton and Drouet [22] attemp to track unconstrained upper-body motion but concluded tracking gets lost due to propagation of errors."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 149
                            }
                        ],
                        "text": "Instea uses the measurement equation directly to synthesize the m and uses a fitting measure between synthesized and observe tures for feedback; see [22, 26, 36, 46, 58, 64, 71]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 0
                            }
                        ],
                        "text": "Downton and Drouet [22] attempt to track unconstrained upper-body motion but must conclude that tracking gets lost due to propagation of errors."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 86
                            }
                        ],
                        "text": "[18] Geurtz [27] Dorner [21] Darell and Pentland [19] Goddard [28] Downton and Drouet [22] Davis and Shah [20] Guo et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and H"
            },
            "venue": {
                "fragments": [],
                "text": "Drouet, Model-based image analysis for unconstra human upper-body motion, inIEE International Conference on Image Processing and Its Applications,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 167
                            }
                        ],
                        "text": "Principal component analysis on a data set of pedestrians represented by B-splines; shown is the shape variation along the principal component (from Baumberg and Hogg [8], c \u00a9 1994 IEEE)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 18
                            }
                        ],
                        "text": "Baumberg and Hogg [8] applied active shape models to tracking of pedestrians."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 18
                            }
                        ],
                        "text": "Baumberg and Hogg [8] Akita [3] Azarbayejani and Pentland [4] Bobick and Wilson [10] Cai and Aggarwal [11] Campbell and Bobick [13] Charayaphan and Marble [16] Chang and Huang [15] Chen and Lee [17] Cooteset al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 0
                            }
                        ],
                        "text": "Baumberg and Hogg [8] apply Active Shape Models to the tracking of pedestrians."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 59
                            }
                        ],
                        "text": "method was mentioned earlier in the 2-D context; see Secti [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An efficient method for contour tracking us active shape models, in Proc"
            },
            "venue": {
                "fragments": [],
                "text": "of IEEE Workshop on Motion of Non-Rigi and Articulated Objects, Austin,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 9
                            }
                        ],
                        "text": "Kuch and Huang [46] use a greedy search strategy based on perturbation of individual state parameters."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 170
                            }
                        ],
                        "text": "Earlier reviews on non-rigid motion, motion-based recognition and gesture interpretation were given by Aggarwal et al. [1], Cedras and Shah [14] and Pavlovic, Sharma and Huang [61], respectively."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 10
                            }
                        ],
                        "text": "Chang and Huang [15] detect ribbons corresponding to the arms and feet."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 21
                            }
                        ],
                        "text": "See Aizawa and Huang [2] for a good overview."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Model-based image coding: Advanced vi coding techniques for very low bit-rate applications, Proc"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE83(2),"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 37
                            }
                        ],
                        "text": "The constraint propagation scheme of Chen and Lee [17] starts at the human head and continues via the torso to the limbs."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 0
                            }
                        ],
                        "text": "Chen and Lee's assumption of six known feature points on the head to start the procedure and the overhead of the interpretation tree makes their approach somewhat unappealing for practical applications."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 194
                            }
                        ],
                        "text": "Baumberg and Hogg [8] Akita [3] Azarbayejani and Pentland [4] Bobick and Wilson [10] Cai and Aggarwal [11] Campbell and Bobick [13] Charayaphan and Marble [16] Chang and Huang [15] Chen and Lee [17] Cooteset al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 95
                            }
                        ],
                        "text": ", joint locations) simplifi pose recovery but places a greater burden on segmentation proaches [17, 37, 60, 74, 87] used joint locations as features assumed these are given make strong assumptions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 49
                            }
                        ],
                        "text": "The c straint propagation scheme of Chen and Lee [17] starts at human head and continues via the torso to the limbs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Knowledge-guided visual perception of 3-D hum gait from a single image sequence, IEEE Trans"
            },
            "venue": {
                "fragments": [],
                "text": "Systems Man Cybernet 22(2),"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 135
                            }
                        ],
                        "text": "Earlier reviews on non-rigid motion, motion-based recognition and gesture interpretation were given by Aggarwal et al. [1], Cedras and Shah [14] and Pavlovic, Sharma and Huang [61], respectively."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 80
                            }
                        ],
                        "text": "For the above systems, action classification is based on h coded decision trees [16, 20, 79], nearest neighbor criteria 65], or on general pattern matching techniques for time-vary data, as described in Section 6."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 7
                            }
                        ],
                        "text": "Others [16, 20, 77, 79] conside the motion trajectories of the hand centroids."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 106
                            }
                        ],
                        "text": "[18] Geurtz [27] Dorner [21] Darell and Pentland [19] Goddard [28] Downton and Drouet [22] Davis and Shah [20] Guo et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and M"
            },
            "venue": {
                "fragments": [],
                "text": "Shah,  Gesture Recognition  , Technical Report CS-TR-9311, University of Central Florida,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 44
                            }
                        ],
                        "text": "One approach using such parametrized models [21] [29] [69] [70] [81] [85] [87] updates pose by inverse kinematics, a common technique in robot control theory [76]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 24
                            }
                        ],
                        "text": "[18] Geurtz [27] Dorner [21] Darell and Pentland [19] Goddard [28] Downton and Drouet [22] Davis and Shah [20] Guo et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 29
                            }
                        ],
                        "text": "makes the resulting approach [21] [69] quite sensitive to occlusion."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 7
                            }
                        ],
                        "text": "Dorner [21] tracks articulated 3-D hand motion (palm motion and nger bending/unbending) with a single camera."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "Dorner [21] tracks articulated 3-"
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hand shape identi cation and tracking for sign language interpretation"
            },
            "venue": {
                "fragments": [],
                "text": "Looking at people, International Joint Conference on Arti cial Intelligence, Chambery,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 15
                            }
                        ],
                        "text": "See Aizawa and Huang [2] for a good overview."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 176
                            }
                        ],
                        "text": "Baumberg and Hogg [8] Akita [3] Azarbayejani and Pentland [4] Bobick and Wilson [10] Cai and Aggarwal [11] Campbell and Bobick [13] Charayaphan and Marble [16] Chang and Huang [15] Chen and Lee [17] Cooteset al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 0
                            }
                        ],
                        "text": "Chang and Huang [15] detect ribbons corresponding to the arms and feet."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 9
                            }
                        ],
                        "text": "Kuch and Huang [46] use a greedy search strategy based on perturbation of individual state parameters."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 170
                            }
                        ],
                        "text": "Earlier reviews on non-rigid motion, motion-based recognition and gesture interpretation were given by Aggarwal et al. [1], Cedras and Shah [14] and Pavlovic, Sharma and Huang [61], respectively."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Ribbon-based motion analysis of human movements, inProc"
            },
            "venue": {
                "fragments": [],
                "text": "of International Conference on Pattern Recognitio Vienna,"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3267020"
                        ],
                        "name": "S. Kurakake",
                        "slug": "S.-Kurakake",
                        "structuredName": {
                            "firstName": "Shoji",
                            "lastName": "Kurakake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kurakake"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144862593"
                        ],
                        "name": "R. Nevatia",
                        "slug": "R.-Nevatia",
                        "structuredName": {
                            "firstName": "Ramakant",
                            "lastName": "Nevatia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nevatia"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "... [10] Cai and Aggarwal [11] Campbell and Bobick [13] Charayaphan and Marble [16] Chang and Huang [15] Chen and Lee [17] Cootes et al. [18] Geurtz [27] Dorner [21] Darell and Pentland [19] Goddard [28] Downton and Drouet [22] Davis and Shah [20] Guo et al. [30] Gavrila and Davis [25] [26] Franke et al. [23] Herman [34] Goncalves et al. [29] Freeman et al. [24] Ju et al. [40] Heap and Hogg [31] Heisele et al. [32] Kurakake and Nevatia [ 47 ] ..."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The work by Kurakake and Nevatia [ 47 ] is similar."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 118166342,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "344f54a4b9948d46737e4c32ad1c15731c8886b2",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Proposes a method to obtain reliable shape description of articulated objects by integrating initial descriptions computed from different view images. Ribbon, which is a 2-D analog of a generalized cone, is used as the basic shape representation scheme. An initial description for each frame is the collection of composed ribbons, which is obtained after filtering out most inadequate ribbons and grouping the remaining ribbons by using geometric constraints. Ribbon matching is then conducted between different frames and ribbons which match are retained. From the retained ribbons, the geometric constraints make integrated descriptions and the tracking of parts is established from the ribbon matching results. Since the ribbon matching allows one ribbon to be matched with two ribbons, an articulation which is not detected in one frame but is detected in another frame can be recovered. Experimental results are also shown.<<ETX>>"
            },
            "slug": "Description-and-tracking-of-moving-articulated-Kurakake-Nevatia",
            "title": {
                "fragments": [],
                "text": "Description and tracking of moving articulated objects"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A method to obtain reliable shape description of articulated objects by integrating initial descriptions computed from different view images by using ribbon, which is a 2-D analog of a generalized cone, as the basic shape representation scheme."
            },
            "venue": {
                "fragments": [],
                "text": "[1992] Proceedings. 11th IAPR International Conference on Pattern Recognition"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144286385"
                        ],
                        "name": "Charles L. Wilson",
                        "slug": "Charles-L.-Wilson",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Wilson",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charles L. Wilson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97225935"
                        ],
                        "name": "C. S. Barnes",
                        "slug": "C.-S.-Barnes",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Barnes",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. S. Barnes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9215658"
                        ],
                        "name": "R. Chellappa",
                        "slug": "R.-Chellappa",
                        "structuredName": {
                            "firstName": "Rama",
                            "lastName": "Chellappa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chellappa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2503366"
                        ],
                        "name": "S. Sirohey",
                        "slug": "S.-Sirohey",
                        "structuredName": {
                            "firstName": "Saad",
                            "lastName": "Sirohey",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sirohey"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 107489770,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ac1e71032aca5b9d20cf1e3773c5f9d1bb461f60",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Face-Recognition-Technology-for-Law-Enforcement-Wilson-Barnes",
            "title": {
                "fragments": [],
                "text": "Face Recognition Technology for Law Enforcement Applications"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722477"
                        ],
                        "name": "T. Calvert",
                        "slug": "T.-Calvert",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Calvert",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Calvert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4824113"
                        ],
                        "name": "A. E. Chapman",
                        "slug": "A.-E.-Chapman",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Chapman",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. E. Chapman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 164
                            }
                        ],
                        "text": "A typical procedure involves obtaining 3-D joint data, performing kinematic analysis, and computing the corresponding forces and torques for a movement of interest [12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62267508,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a12fa238a423c53d9ab828790f520015fb8cea6a",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Analysis-and-synthesis-of-human-movement-Calvert-Chapman",
            "title": {
                "fragments": [],
                "text": "Analysis and synthesis of human movement"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688865"
                        ],
                        "name": "A. Broggi",
                        "slug": "A.-Broggi",
                        "structuredName": {
                            "firstName": "Alberto",
                            "lastName": "Broggi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Broggi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[23] [59]) is that dealing with partial occlusion is relatively straightforward."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[23] applies principal component analysis on a grid representation of pedestrians."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62333779,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "513dfb97978a6a0767add3b9175dc42a2aa66cfe",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Vision-Based-Driving-Assistance-in-Vehicles-of-the-Broggi",
            "title": {
                "fragments": [],
                "text": "Vision-Based Driving Assistance in Vehicles of the Future"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "Geurtz [27] performs hierarchical and articulated curve tting with 2-"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 7
                            }
                        ],
                        "text": "Geurtz [27] perform hierarchical and articulated curve fitting with 2-D ellipsoid Niyogi and Adelson [56, 57] advocated segmentation over ti because of robustness; their procedure involves finding hu silhouettes with deformable contours in X-T space [56] or def rmable surfaces inX-Y-T space [57]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 12
                            }
                        ],
                        "text": "[18] Geurtz [27] Dorner [21] Darell and Pentland [19] Goddard [28] Downton and Drouet [22] Davis and Shah [20] Guo et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Shape Estimation"
            },
            "venue": {
                "fragments": [],
                "text": "Ph.D. thesis, Department o Electrical Engineering, Polytechnic Institute of Lausanne,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 0
                            }
                        ],
                        "text": "Goddard [28] represents activities by scenarios: a sequence of events with enabling conditions, and time constraints between successive events."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 140
                            }
                        ],
                        "text": "Usinga Gauss convoluted reference scale-image, one can account for a fi amount of time-offset between reference and test trajectory Goddard [28] represented activities by scenarios: a seque of events with enabling conditions and time constraints betw successive events."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 62
                            }
                        ],
                        "text": "[18] Geurtz [27] Dorner [21] Darell and Pentland [19] Goddard [28] Downton and Drouet [22] Davis and Shah [20] Guo et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Incremental model-based discrimination of articula movement direct from motion features"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of IEEE Workshop on Motion of Non-Rigid and Articulated Objects,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Human modeling and animation , in Computer Animation"
            },
            "venue": {
                "fragments": [],
                "text": "Human modeling and animation , in Computer Animation"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 112
                            }
                        ],
                        "text": "A less investigated but equally interes approach for matching time-varying data is given by neural n works (NN) [30, 72]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[30] Gavrila and Davis [25] [26] Frankeet al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[30] proposed obtaining a 2-D stick figure by obtaining the ske ton of the silhouette of the walking human and matching it a model stick figure."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Understanding human motion patterns, in  Proc"
            },
            "venue": {
                "fragments": [],
                "text": "of International Conference on Pattern Recognition,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 95
                            }
                        ],
                        "text": ", joint locations) simplifi pose recovery but places a greater burden on segmentation proaches [17, 37, 60, 74, 87] used joint locations as features assumed these are given make strong assumptions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[37] provided a constraint propaga tion scheme for human gait, where one joint remains at a fi location."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Determining articulat motion from Perspective views: A decomposition approach, in Proc"
            },
            "venue": {
                "fragments": [],
                "text": "of IEEE Workshop on Motion of Non-Rigid and Articulated Objects, Aus"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 19
                            }
                        ],
                        "text": "Badler and Smoliar [6] prov a good discussion of these issues."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 0
                            }
                        ],
                        "text": "Badler and Smoliar [6] provide a good discussion of these issues."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 103
                            }
                        ],
                        "text": "Some of the issues have how to specify spatial interactions and high-level tasks for human models; see [5, 6, 50]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Digital representations of human movem ACM Comput"
            },
            "venue": {
                "fragments": [],
                "text": "Surveys  11(1),"
            },
            "year": 1979
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Towards model-based recognition of human movements in image sequences Computer Vision, Graphics and Image Processing: Image Understanding"
            },
            "venue": {
                "fragments": [],
                "text": "Towards model-based recognition of human movements in image sequences Computer Vision, Graphics and Image Processing: Image Understanding"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Performance tradeoff dynamic time warping algorithms for isolated word recognition"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans . ASSP"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 32
                            }
                        ],
                        "text": "based on image intensities [46] [81] or optical ow [85]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 64
                            }
                        ],
                        "text": "One approach using such parametrized models [21] [29] [69] [70] [81] [85] [87] updates pose by inverse kinematics, a common technique in robot control theory [76]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[81] Webb and Aggarwal [82] Yamamoto and Koshikawa [85] Zhao [87]"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Analysis of human motion: A model-based approach"
            },
            "venue": {
                "fragments": [],
                "text": "7th Scandinavian Conference on Image Analysis"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A framework for spatiotempo control in the tracking of visual contours,  Int"
            },
            "venue": {
                "fragments": [],
                "text": "J. Comput. Vision11(2),"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Performance tradeoos in dynamic time warping algorithms for isolated word recognition"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on ASSP"
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Davis , 3 - D model - based tracking of humans in act a multiview approach"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Guo et al. 30] Gavrila and Davis 25] 26] Franke et al"
            },
            "venue": {
                "fragments": [],
                "text": "D approaches without 2-D approaches with 3-D approaches explicit shape models explicit shape models Baumberg and Hogg Kakadiaris and Metaxas 42] 43] Quek 66] Kuch and Huang 46] Rangarajan et al. 68] Ohya and Kishino 58] Segen and Pingali 73"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 160
                            }
                        ],
                        "text": "A typical procedure involves obtaining 3-D joint da performing kinematic analysis, and computing the correspo ing forces and torques for a movement of interest [12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Analysis and synthesis of human moveme Handbook of Pattern Recognition and Image Processing: Computer Vi (T"
            },
            "venue": {
                "fragments": [],
                "text": "Young, Ed.), pp. 432\u2013474. Academic Press, San Diego,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 92
                            }
                        ],
                        "text": "Many highly accu surface models have been used in the field of graphics to m the human body [5], often containing thousands of polyg obtained from actual body scans."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 103
                            }
                        ],
                        "text": "Some of the issues have how to specify spatial interactions and high-level tasks for human models; see [5, 6, 50]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Simulating Humans , Oxford Univ"
            },
            "venue": {
                "fragments": [],
                "text": "Press, Oxford,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Kishino , Human posture estimation from multiple ima using genetic algorithm"
            },
            "venue": {
                "fragments": [],
                "text": "Proc . of International Conference on Patter Recognition"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 80
                            }
                        ],
                        "text": "Baumberg and Hogg [8] Akita [3] Azarbayejani and Pentland [4] Bobick and Wilson [10] Cai and Aggarwal [11] Campbell and Bobick [13] Charayaphan and Marble [16] Chang and Huang [15] Chen and Lee [17] Cooteset al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 71
                            }
                        ],
                        "text": "speech recognition and more recently in matching human m ment patterns [10, 19, 25, 78]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A state-based technique for the summariza and recognition of gesture, in  Proc"
            },
            "venue": {
                "fragments": [],
                "text": "of International Conference on Com puter Vision, Cambridge,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "30] Gavrila and Davis [25] [26] Franke et al. [23] Herman [34] Goncalves et al. [29] Freeman"
            },
            "venue": {
                "fragments": [],
                "text": "30] Gavrila and Davis [25] [26] Franke et al. [23] Herman [34] Goncalves et al. [29] Freeman"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Towards model-based recognition of human movements in image sequences, Comput. Vision Graphics Image Process"
            },
            "venue": {
                "fragments": [],
                "text": "Image Understanding"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hand shape identification and tracking for sign language interpretation"
            },
            "venue": {
                "fragments": [],
                "text": "Looking at People, International Joint Conference on Artificial Intelligence"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 112
                            }
                        ],
                        "text": "Some of the issues have been how to specify spatial interactions and high-level tasks for the human models; see [5] [6] [50]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 98
                            }
                        ],
                        "text": "Many highly accurate surface models have been used in the eld of graphics to model the human body [5], often containing thousands of polygons obtained from actual body scans."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Simulating Humans"
            },
            "venue": {
                "fragments": [],
                "text": "Simulating Humans"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Table 2: A selection of previous work on the visual analysis of human move- ment References"
            },
            "venue": {
                "fragments": [],
                "text": "Table 2: A selection of previous work on the visual analysis of human move- ment References"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 66
                            }
                        ],
                        "text": "More accurate modeling of body parts is obtained us superquadrics [7]; these are generalizations of ellipsoids w have additional \u201csquareness\u201d parameters along each axis."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Global and local deformations of solid primitives,  Comput"
            },
            "venue": {
                "fragments": [],
                "text": "Graphics18(3),"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[1], Cedras and Shah [14], and Pavlovic, Sharma, Huang [61], respectively."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Articulated and elastic n rigid motion: A review, inProc"
            },
            "venue": {
                "fragments": [],
                "text": "of IEEE Workshop on Motion of Non-Rigi and Articulated Objects, Austin,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Posture estimation in reduced-model gesture input systems"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of International Workshop on Automatic Face and Gesture Recognition"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "First Sight : A human body outline labeling syst IEEE Trans"
            },
            "venue": {
                "fragments": [],
                "text": ". Pattern Anal . Mach . Intell ."
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Model - based image analysis of human mo using constraint propagation , IEEE Trans"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Anal . Mach . Intell ."
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[29] tracked one arm while keeping the shoulder fixed a known position."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 165
                            }
                        ],
                        "text": "On downside, by considering the (coupled) parameters simulta ously, one needs to work in a high-dimensional parameter sp One approach using such parametrized models [21, 29, 70, 81, 85, 87] updated pose by inverse kinematics, a comm technique in robot control theory [76]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 69
                            }
                        ],
                        "text": "Typical m sures are correlation on a raw or smoothed LOG-filtered im [29, 70], perpendicular- [31] and chamfer-distance [26] (fro projected model edges to image edges) and straight-line tance metrics [71]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Monoc tracking of the human arm in 3-D, in Proc"
            },
            "venue": {
                "fragments": [],
                "text": "of International Conference on Computer Vision, Cambridge,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[38] Leung and Yang [48] Hoffman and Flinchbaugh [35] Johansson [39] Long and Yang [49] Hogg [36] Kjeldsen and Kender [44] Niyogi and Adelson [56] [57] Holt et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[38] used rotationally invariant Zernike moments."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Posture estimation in reduced-m gesture input systems, in  Proc"
            },
            "venue": {
                "fragments": [],
                "text": "of International Workshop on Automati Face and Gesture Recognition, Zurich,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Analysis and synthesis of human movement, in Handbook of Pattern Recognition and Image Processing: Computer Vision ("
            },
            "venue": {
                "fragments": [],
                "text": "Analysis and synthesis of human movement, in Handbook of Pattern Recognition and Image Processing: Computer Vision ("
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Autonomous driving approaches downtown. submitted t o IEEE Expert (Special Issue on Vision-based Driving Assistance i n V ehicles of the Future)"
            },
            "venue": {
                "fragments": [],
                "text": "Autonomous driving approaches downtown. submitted t o IEEE Expert (Special Issue on Vision-based Driving Assistance i n V ehicles of the Future)"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 113
                            }
                        ],
                        "text": "Other approaches have imposed ge constraints on the articulated motion, such as the \u201cfixed-ax [82] or \u201cin-plane\u201d [35] assumptions of rotations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 49
                            }
                        ],
                        "text": "[38] Leung and Yang [48] Hoffman and Flinchbaugh [35] Johansson [39] Long and Yang [49] Hogg [36] Kjeldsen and Kender [44] Niyogi and Adelson [56] [57] Holt et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The interpretation of biological motio Biol"
            },
            "venue": {
                "fragments": [],
                "text": "Cybernet.42,"
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Gesture recognition using the persesus architecture"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hand shape identiication and tracking for sign language interpretation"
            },
            "venue": {
                "fragments": [],
                "text": "Looking at people, International Joint Conference o n Artiicial Intelligence"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recognizing human action in timesequential images using Hidden Markov M o d e l . I n Proc"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bobick , Recognition of human body motion us phase space constraints"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Model - based estimation of 3 - D hum motion with occlusion based on active multiviewpoint selection"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Marble , Image processing system for interpr motion in American Sign Language"
            },
            "venue": {
                "fragments": [],
                "text": "J . Biomed . Engrg ."
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "3-D model-based tracking of humans in action: a m ulti-view approach"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 124
                            }
                        ],
                        "text": "For the above systems, action classi cation is based on hard-coded decision trees [16] [20] [79], nearest neighbor criteria [38] [65] or is based on general pattern matching techniques for time-varying data, as described in Section 6."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[38] use rotationally invariant Zernike moments."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[38] Leung and Yang [48] Ho man and Flinchbaugh [35] Johansson [39] Long and Yang [49] Hogg [36] Kjeldsen and Kender [44] Niyogi and Adelson [56] [57] Holt et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Posture estimation in reducedmodel gesture input systems"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of International Workshop on Automatic Face and Gesture R ecognition"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Moving Posture R econstruction from Perspective Projections of Jointed F i g u r e Motion"
            },
            "venue": {
                "fragments": [],
                "text": "Moving Posture R econstruction from Perspective Projections of Jointed F i g u r e Motion"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[18] uses active shape models for this purpo these are models derived from a training stage where exam shapes are described in terms of known feature point locati Cooteset al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[18] Geurtz [27] Dorner [21] Darell and Pentland [19] Goddard [28] Downton and Drouet [22] Davis and Shah [20] Guo et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Active shape mode their training and applications,  Comput"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Image Understanding  61,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": ": Realtim tracking of the human body"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans . Pattern Anal . Mach . Intell ."
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 155
                            }
                        ],
                        "text": "Baumberg and Hogg [8] Akita [3] Azarbayejani and Pentland [4] Bobick and Wilson [10] Cai and Aggarwal [11] Campbell and Bobick [13] Charayaphan and Marble [16] Chang and Huang [15] Chen and Lee [17] Cooteset al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 80
                            }
                        ],
                        "text": "For the above systems, action classification is based on h coded decision trees [16, 20, 79], nearest neighbor criteria 65], or on general pattern matching techniques for time-vary data, as described in Section 6."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 7
                            }
                        ],
                        "text": "Others [16, 20, 77, 79] conside the motion trajectories of the hand centroids."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Image processing system for interpr motion in American Sign Language, J"
            },
            "venue": {
                "fragments": [],
                "text": "Biomed. Engrg.14(15),"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 124
                            }
                        ],
                        "text": "Earlier reviews on non-rigid motion, motion-based recognition and gesture interpretation were given by Aggarwal et al. [1], Cedras and Shah [14] and Pavlovic, Sharma and Huang [61], respectively."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 21
                            }
                        ],
                        "text": "[1], Cedras and Shah [14], and Pavlovic, Sharma, Huang [61], respectively."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and M"
            },
            "venue": {
                "fragments": [],
                "text": "Shah, Motion-based recognition, a survey, Image Vision Comput.13(2),"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Model-based S h a p e Estimation"
            },
            "venue": {
                "fragments": [],
                "text": "Model-based S h a p e Estimation"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[24] usedx\u2013y image moments an orientation histograms and Hunter t al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Computer vision computer games, in  Proc"
            },
            "venue": {
                "fragments": [],
                "text": "of IEEE International Conference on Automat Face and Gesture Recognition, Killington,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Downton and Drouet 22] Davis and Shah 20] Guo et al. 30] Gavrila and Davis 25] 26] Franke et al"
            },
            "venue": {
                "fragments": [],
                "text": "D approaches without 2-D approaches with 3-D approaches explicit shape models explicit shape models Baumberg and Hogg Kakadiaris and Metaxas 42] 43] Quek 66] Kuch and Huang 46] Rangarajan et al. 68] Ohya and Kishino 58] Segen and Pingali 73"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Model-based estimation of 3-D human motion with occlusion based on active m ulti-viewpoint selection"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 88,
            "methodology": 52,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 146,
        "totalPages": 15
    },
    "page_url": "https://www.semanticscholar.org/paper/The-Visual-Analysis-of-Human-Movement:-A-Survey-Gavrila/b4e4b41b6010ac1e6c90791168f57bcd75b696ab?sort=total-citations"
}