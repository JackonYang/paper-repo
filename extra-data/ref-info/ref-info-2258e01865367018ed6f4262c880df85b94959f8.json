{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "117538614"
                        ],
                        "name": "Kevin Smith",
                        "slug": "Kevin-Smith",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Smith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403029865"
                        ],
                        "name": "D. G\u00e1tica-P\u00e9rez",
                        "slug": "D.-G\u00e1tica-P\u00e9rez",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "G\u00e1tica-P\u00e9rez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. G\u00e1tica-P\u00e9rez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719610"
                        ],
                        "name": "J. Odobez",
                        "slug": "J.-Odobez",
                        "structuredName": {
                            "firstName": "Jean-Marc",
                            "lastName": "Odobez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Odobez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684507"
                        ],
                        "name": "Sil\u00e8ye O. Ba",
                        "slug": "Sil\u00e8ye-O.-Ba",
                        "structuredName": {
                            "firstName": "Sil\u00e8ye",
                            "lastName": "Ba",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sil\u00e8ye O. Ba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 10
                            }
                        ],
                        "text": "It shows the ability of the tracker to estimate precise object positions, independent of its skill at recognizing object configurations, keeping consistent trajectories, and so forth."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 390280,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "616fda61990097f0401b33dbf01541bd83a939a0",
            "isKey": false,
            "numCitedBy": 174,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Multiple object tracking (MOT) is an active and challenging research topic. Many different approaches to the MOT problem exist, yet there is little agreement amongst the community on how to evaluate or compare these methods, and the amount of literature addressing this problem is limited. The goal of this paper is to address this issue by providing a comprehensive approach to the empirical evaluation of tracking performance. To that end, we explore the tracking characteristics important to measure in a real-life application, focusing on configuration (the number and location of objects in a scene) and identification (the consistent labeling of objects over time), and define a set of measures and a protocol to objectively evaluate these characteristics."
            },
            "slug": "Evaluating-Multi-Object-Tracking-Smith-G\u00e1tica-P\u00e9rez",
            "title": {
                "fragments": [],
                "text": "Evaluating Multi-Object Tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The tracking characteristics important to measure in a real-life application are explored, focusing on configuration and identification, and a set of measures and a protocol to objectively evaluate these characteristics are defined."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05) - Workshops"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145492205"
                        ],
                        "name": "Hai Tao",
                        "slug": "Hai-Tao",
                        "structuredName": {
                            "firstName": "Hai",
                            "lastName": "Tao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hai Tao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733393"
                        ],
                        "name": "H. Sawhney",
                        "slug": "H.-Sawhney",
                        "structuredName": {
                            "firstName": "Harpreet",
                            "lastName": "Sawhney",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sawhney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108437389"
                        ],
                        "name": "Rakesh Kumar",
                        "slug": "Rakesh-Kumar",
                        "structuredName": {
                            "firstName": "Rakesh",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rakesh Kumar"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 377847,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "61126e51ee5e00d7cbe962b84a1d74a2026d9250",
            "isKey": false,
            "numCitedBy": 126,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The recently proposed CONDENSATION algorithm and its variants enable the estimation of arbitrary multi-modal posterior distributions that potentially represent multiple tracked objects. However, the specific state representation adopted in the earlier work does not explicitly supports counting, addition, deletion and occlusion of objects. Furthermore, the representation may increasingly bias the posterior density estimates towards objects with dominant likelihood as the estimation progresses over many frames. In this paper, a novel formulation and an associated CONDENSATION-like sampling algorithm that explicitly support counting, addition and deletion of objects are proposed. We represent all objects in an image as an object configuration. The a posteriori distribution of all possible configurations are explored and maintained using sampling techniques. The dynamics of configurations allow addition and deletion of objects and handle occlusion. An efficient hierarchical algorithm is also proposed to approximate the sampling process in high dimensional space. Promising comparative results on both synthetic and real data are demonstrated."
            },
            "slug": "A-Sampling-Algorithm-for-Tracking-Multiple-Objects-Tao-Sawhney",
            "title": {
                "fragments": [],
                "text": "A Sampling Algorithm for Tracking Multiple Objects"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A novel formulation and an associated CONDENSATION-like sampling algorithm that explicitly support counting, addition and deletion of objects are proposed and promising comparative results on both synthetic and real data are demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "Workshop on Vision Algorithms"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50853059"
                        ],
                        "name": "Anurag Mittal",
                        "slug": "Anurag-Mittal",
                        "structuredName": {
                            "firstName": "Anurag",
                            "lastName": "Mittal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anurag Mittal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693428"
                        ],
                        "name": "L. Davis",
                        "slug": "L.-Davis",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Davis",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Davis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 52858684,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ed12ede91d7f7a9792b507aef4cedd43e5b2661",
            "isKey": false,
            "numCitedBy": 231,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a system that is capable of segmenting, detecting and tracking multiple people in a cluttered scene using multiple synchronized cameras located far from each other. The system improves upon existing systems in many ways including: (1)We do not assume that a foreground connected component belongs to only one object; rather, we segment the views taking into account color models for the objects and the background. This helps us to not only separate foreground regions belonging to different objects, but to also obtain better background regions than traditional background subtraction methods (as it uses foreground color models in the algorithm). (2) It is fully automatic and does not require any manual input or initializations of any kind. (3) Instead of taking decisions about object detection and tracking from a single view or camera pair, we collect evidences from each pair and combine the evidence to obtain a decision in the end. This helps us to obtain much better detection and tracking as opposed to traditional systems.Several innovations help us tackle the problem. The first is the introduction of a region-based stereo algorithm that is capable of finding 3D points inside an object if we know the regions belonging to the object in two views. No exact point matching is required. This is especially useful in wide baseline camera systems where exact point matching is very difficult due to self-occlusion and a substantial change in viewpoint. The second contribution is the development of a scheme for setting priors for use in segmentation of a view using bayesian classification. The scheme, which assumes knowledge of approximate shape and location of objects, dynamically assigns priors for different objects at each pixel so that occlusion information is encoded in the priors. The third contribution is a scheme for combining evidences gathered from different camera pairs using occlusion analysis so as to obtain a globally optimum detection and tracking of objects.The system has been tested using different density of people in the scene which helps us to determine the number of cameras required for a particular density of people."
            },
            "slug": "M2Tracker:-A-Multi-view-Approach-to-Segmenting-and-Mittal-Davis",
            "title": {
                "fragments": [],
                "text": "M2Tracker: A Multi-view Approach to Segmenting and Tracking People in a Cluttered Scene Using Region-Based Stereo"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A system that is capable of segmenting, detecting and tracking multiple people in a cluttered scene using multiple synchronized cameras located far from each other and a scheme for combining evidences gathered from different camera pairs using occlusion analysis so as to obtain a globally optimum detection and tracking of objects."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067014022"
                        ],
                        "name": "Rania Y. Khalaf",
                        "slug": "Rania-Y.-Khalaf",
                        "structuredName": {
                            "firstName": "Rania",
                            "lastName": "Khalaf",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rania Y. Khalaf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705903"
                        ],
                        "name": "S. Intille",
                        "slug": "S.-Intille",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Intille",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Intille"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "A few important points need to be considered, though, which make the procedure less straightforward."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9777129,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "909a673c98d7520797b875cce95d53f0c956ba6d",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "This work presents a real-time multi-person or multi-object tracking algorithm that uses multiple hypothesis reasoning in time to enforce multi-person match constraints. The algorithm is intended to augment, not replace, existing multiperson tracking methods. We demonstrate how tracking systems that use inter-frame feature matching can be improved by enforcing contextual matching constraints throughout a 1-5 second temporal window. Robust and efficient multiple hypothesis reasoning in time is achieved for a useful class of tracking problems using a dynamic programming framework. Results are described for a dataset of 40 minutes of test video taken from a static, top-down camera and with two to four people moving about a small room."
            },
            "slug": "Improving-Multiple-People-Tracking-Using-Temporal-Khalaf-Intille",
            "title": {
                "fragments": [],
                "text": "Improving Multiple People Tracking Using Temporal Consistency"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "It is demonstrated how tracking systems that use inter-frame feature matching can be improved by enforcing contextual matching constraints throughout a 1-5 second temporal window."
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3094898"
                        ],
                        "name": "K. Nickel",
                        "slug": "K.-Nickel",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Nickel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Nickel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40303076"
                        ],
                        "name": "T. Gehrig",
                        "slug": "T.-Gehrig",
                        "structuredName": {
                            "firstName": "Tobias",
                            "lastName": "Gehrig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Gehrig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742325"
                        ],
                        "name": "R. Stiefelhagen",
                        "slug": "R.-Stiefelhagen",
                        "structuredName": {
                            "firstName": "Rainer",
                            "lastName": "Stiefelhagen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Stiefelhagen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1791499"
                        ],
                        "name": "J. McDonough",
                        "slug": "J.-McDonough",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "McDonough",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. McDonough"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10291163,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c52e7423c7e01c48a9dda2e7d18ab37600bd0c8b",
            "isKey": false,
            "numCitedBy": 109,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a novel approach for tracking a lecturer during the course of his speech. We use features from multiple cameras and microphones, and process them in a joint particle filter framework. The filter performs sampled projections of 3D location hypotheses and scores them using features from both audio and video. On the video side, the features are based on foreground segmentation, multi-view face detection and upper body detection. On the audio side, the time delays of arrival between pairs of microphones are estimated with a generalized cross correlation function. Computationally expensive features are evaluated only at the particles' projected positions in the respective camera images, thus the complexity of the proposed algorithm is low. We evaluated the system on data that was recorded during actual lectures. The results of our experiments were 36 cm average error for video only tracking, 46 cm for audio only, and 31 cm for the combined audio-video system."
            },
            "slug": "A-joint-particle-filter-for-audio-visual-speaker-Nickel-Gehrig",
            "title": {
                "fragments": [],
                "text": "A joint particle filter for audio-visual speaker tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "This paper uses features from multiple cameras and microphones, and process them in a joint particle filter framework, which performs sampled projections of 3D location hypotheses and scores them using features from both audio and video."
            },
            "venue": {
                "fragments": [],
                "text": "ICMI '05"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3341976"
                        ],
                        "name": "N. Checka",
                        "slug": "N.-Checka",
                        "structuredName": {
                            "firstName": "Neal",
                            "lastName": "Checka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Checka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "12812321"
                        ],
                        "name": "K. Wilson",
                        "slug": "K.-Wilson",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Wilson",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Wilson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073035416"
                        ],
                        "name": "Vibhav Rangarajan",
                        "slug": "Vibhav-Rangarajan",
                        "structuredName": {
                            "firstName": "Vibhav",
                            "lastName": "Rangarajan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vibhav Rangarajan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5702685,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d5dbc2f0eb7d586c2ac9dc52d650d2d18a67eea6",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a probabilistic tracking framework that combines sound and vision to achieve more robust and accurate tracking of multiple objects. In a cluttered or noisy scene, our measurements have a non-Gaussian, multi-modal distribution. We apply a particle filter to track multiple people using combined audio and video observations. We have applied our algorithm to the domain of tracking people with a stereo-based visual foreground detection algorithm and audio localization using a beamforming technique. Our model also accurately reflects the number of people present. We test the efficacy of our system on a sequence of multiple people moving and speaking in an indoor environment."
            },
            "slug": "A-Probabilistic-Framework-for-Multi-modal-Tracking-Checka-Wilson",
            "title": {
                "fragments": [],
                "text": "A Probabilistic Framework for Multi-modal Multi-Person Tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "A probabilistic tracking framework that combines sound and vision to achieve more robust and accurate tracking of multiple objects and accurately reflects the number of people present is presented."
            },
            "venue": {
                "fragments": [],
                "text": "2003 Conference on Computer Vision and Pattern Recognition Workshop"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152886499"
                        ],
                        "name": "Yan Li",
                        "slug": "Yan-Li",
                        "structuredName": {
                            "firstName": "Yan",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yan Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33688051"
                        ],
                        "name": "A. Dore",
                        "slug": "A.-Dore",
                        "structuredName": {
                            "firstName": "Alessio",
                            "lastName": "Dore",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707114"
                        ],
                        "name": "J. Orwell",
                        "slug": "J.-Orwell",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Orwell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Orwell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 144
                            }
                        ],
                        "text": "These metrics have been extensively used in two large-scale international evaluations, the 2006 and 2007 CLEAR evaluations, to measure and compare the performance of multiple object trackers for a wide variety of tracking tasks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16478594,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3fbd00a0b3063e56e529ffcefdcefea5d9f0fb9d",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we discuss the different approaches used for evaluating the results of tracking algorithms, and in particular for analysis of football (soccer) tracking results. The focus of the study is on systems with multiple static cameras. The appropriate data representation and ground truth capture methods are discussed, and evaluation measures that indicate the performance of any given automatic tracker are presented. The evaluation method is demonstrated to compare results of an implemented multi-camera tracker."
            },
            "slug": "Evaluating-the-performance-of-systems-for-tracking-Li-Dore",
            "title": {
                "fragments": [],
                "text": "Evaluating the performance of systems for tracking football players and ball"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The appropriate data representation and ground truth capture methods are discussed, and evaluation measures that indicate the performance of any given automatic tracker are presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Conference on Advanced Video and Signal Based Surveillance, 2005."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2284998"
                        ],
                        "name": "F. Ziliani",
                        "slug": "F.-Ziliani",
                        "structuredName": {
                            "firstName": "Francesco",
                            "lastName": "Ziliani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Ziliani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697856"
                        ],
                        "name": "S. Velast\u00edn",
                        "slug": "S.-Velast\u00edn",
                        "structuredName": {
                            "firstName": "Sergio",
                            "lastName": "Velast\u00edn",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Velast\u00edn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29905643"
                        ],
                        "name": "F. Porikli",
                        "slug": "F.-Porikli",
                        "structuredName": {
                            "firstName": "Fatih",
                            "lastName": "Porikli",
                            "middleNames": [
                                "Murat"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Porikli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689330"
                        ],
                        "name": "L. Marcenaro",
                        "slug": "L.-Marcenaro",
                        "structuredName": {
                            "firstName": "Lucio",
                            "lastName": "Marcenaro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Marcenaro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47382087"
                        ],
                        "name": "T. Kelliher",
                        "slug": "T.-Kelliher",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Kelliher",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kelliher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145440152"
                        ],
                        "name": "A. Cavallaro",
                        "slug": "A.-Cavallaro",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Cavallaro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Cavallaro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2022761"
                        ],
                        "name": "Philippe Bruneaut",
                        "slug": "Philippe-Bruneaut",
                        "structuredName": {
                            "firstName": "Philippe",
                            "lastName": "Bruneaut",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philippe Bruneaut"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 46
                            }
                        ],
                        "text": "In this work, we introduce two intuitive and general metrics to allow for objective comparison of tracker characteristics, focusing on their precision in estimating object locations, their accuracy in recognizing object configurations and their ability to consistently label objects over time."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2424375,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "789a83195628bf965530a3281c690dafb0b28561",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "In video surveillance projects, automatic and real-time event detection solutions are required to guarantee an efficient and cost-effective use of the infrastructure. Many solutions have been proposed to automatically detect a variety of events of interest. However, not all solutions and technologies may satisfy all the requirements of the surveillance scenario. For this reason, performance evaluation of existing event detection solutions becomes an important step in the deployment of video surveillance projects. In this paper, we propose a practical approach that aims at minimizing the ground truth generation problem and the expertise required to evaluate and compare the results by introducing specific requirements of specific event detection scenarios. This approach is believed to be applicable for an initial evaluation of candidate solutions to a specific surveillance scenario before more exhaustive tests in an integrated environment. The proposed method is under evaluation in the framework of the challenge of real-time event detection solutions (CREDS)."
            },
            "slug": "Performance-evaluation-of-event-detection-the-CREDS-Ziliani-Velast\u00edn",
            "title": {
                "fragments": [],
                "text": "Performance evaluation of event detection solutions: the CREDS experience"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A practical approach is proposed that aims at minimizing the ground truth generation problem and the expertise required to evaluate and compare the results by introducing specific requirements of specific event detection scenarios."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Conference on Advanced Video and Signal Based Surveillance, 2005."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1815472"
                        ],
                        "name": "Anh-Tuan Nghiem",
                        "slug": "Anh-Tuan-Nghiem",
                        "structuredName": {
                            "firstName": "Anh-Tuan",
                            "lastName": "Nghiem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anh-Tuan Nghiem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144103389"
                        ],
                        "name": "F. Br\u00e9mond",
                        "slug": "F.-Br\u00e9mond",
                        "structuredName": {
                            "firstName": "Fran\u00e7ois",
                            "lastName": "Br\u00e9mond",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Br\u00e9mond"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686585"
                        ],
                        "name": "M. Thonnat",
                        "slug": "M.-Thonnat",
                        "structuredName": {
                            "firstName": "Monique",
                            "lastName": "Thonnat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Thonnat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31987290"
                        ],
                        "name": "V. Valentin",
                        "slug": "V.-Valentin",
                        "structuredName": {
                            "firstName": "Val\u00e9ry",
                            "lastName": "Valentin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Valentin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8963115,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cdaced1e31d62ea1f8a62a4cc586d889ce081a38",
            "isKey": false,
            "numCitedBy": 151,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents the results of ETISEO, a performance evaluation project for video surveillance systems. Many other projects have already evaluated the performance of video surveillance systems, but more on an end-user point of view. ETISEO aims at studying the dependency between algorithms and the video characteristics. Firstly we describe ETISEO methodology which consists in addressing each video processing problem separately. Secondly, we present the main evaluation metrics of ETISEO as well as their benefits, limitations and conditions of use. Finally, we discuss about the contributions of ETISEO to the evaluation community."
            },
            "slug": "ETISEO,-performance-evaluation-for-video-systems-Nghiem-Br\u00e9mond",
            "title": {
                "fragments": [],
                "text": "ETISEO, performance evaluation for video surveillance systems"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "The results of ETISEO are presented, a performance evaluation project for video surveillance systems that aims at studying the dependency between algorithms and the video characteristics and the main evaluation metrics are presented."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Advanced Video and Signal Based Surveillance"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1430776903"
                        ],
                        "name": "M. Voit",
                        "slug": "M.-Voit",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Voit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Voit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3094898"
                        ],
                        "name": "K. Nickel",
                        "slug": "K.-Nickel",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Nickel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Nickel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742325"
                        ],
                        "name": "R. Stiefelhagen",
                        "slug": "R.-Stiefelhagen",
                        "structuredName": {
                            "firstName": "Rainer",
                            "lastName": "Stiefelhagen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Stiefelhagen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 144
                            }
                        ],
                        "text": "\u2026Systems Lab, Institut fu\u0308r Theoretische Informatik, Universita\u0308t Karlsruhe, 76131 Karlsruhe, Germany\nCorrespondence should be addressed to Keni Bernardin, keni@ira.uka.de\nReceived 2 November 2007; Accepted 23 April 2008\nRecommended by Carlo Regazzoni\nSimultaneous tracking of multiple persons\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 230
                            }
                        ],
                        "text": "Hindawi Publishing Corporation EURASIP Journal on Image and Video Processing Volume 2008, Article ID 246309, 10 pages doi:10.1155/2008/246309\nResearch Article Evaluating Multiple Object Tracking Performance: The CLEAR MOT Metrics\nKeni Bernardin and Rainer Stiefelhagen\nInteractive Systems Lab, Institut fu\u0308r Theoretische Informatik, Universita\u0308t Karlsruhe, 76131 Karlsruhe, Germany\nCorrespondence should be addressed to Keni Bernardin, keni@ira.uka.de\nReceived 2 November 2007; Accepted 23 April 2008\nRecommended by Carlo Regazzoni\nSimultaneous tracking of multiple persons in real-world environments is an active research field and several approaches have been proposed, based on a variety of features and algorithms."
                    },
                    "intents": []
                }
            ],
            "corpusId": 938803,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9e45484c81a335f61f2f914156462235ec4bf5d3",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "In the context of human-computer interaction, information about head pose is an important cue for building a statement about humans' focus of attention. In this paper, we present an approach to estimate horizontal head rotation of people inside a smart-room. This room is equipped with multiple cameras that aim to provide at least one facial view of the user at any location in the room. We use neural networks that were trained on samples of rotated heads in order to classify each camera view. Whenever there is more than one estimate of head rotation, we combine the different estimates into one joint hypothesis. We show experimentally, that by using the proposed combination scheme, the mean error for unknown users could be reduced by up to 50% when combining the estimates from multiple cameras."
            },
            "slug": "Multi-view-head-pose-estimation-using-neural-Voit-Nickel",
            "title": {
                "fragments": [],
                "text": "Multi-view head pose estimation using neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper uses neural networks that were trained on samples of rotated heads in order to classify each camera view and shows experimentally that by using the proposed combination scheme, the mean error for unknown users could be reduced by up to 50% when combining the estimates from multiple cameras."
            },
            "venue": {
                "fragments": [],
                "text": "The 2nd Canadian Conference on Computer and Robot Vision (CRV'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723059"
                        ],
                        "name": "H. Christensen",
                        "slug": "H.-Christensen",
                        "structuredName": {
                            "firstName": "Henrik",
                            "lastName": "Christensen",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Christensen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691986"
                        ],
                        "name": "P. Phillips",
                        "slug": "P.-Phillips",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Phillips",
                            "middleNames": [
                                "Jonathon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Phillips"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 117
                            }
                        ],
                        "text": "In this work, we introduce two intuitive and general metrics to allow for objective comparison of tracker characteristics, focusing on their precision in estimating object locations, their accuracy in recognizing object configurations and their ability to consistently label objects over time."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 60199183,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "71400436e9731778e9fb3fc726c62cac80e92f7b",
            "isKey": false,
            "numCitedBy": 149,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Automated performance evaluation of range image segmentation algorithms training/test data partitioning for empirical performance evaluation analyzing PCA-based face recognition algorithms -eigenvector selection and distance measures design of a visual system for detecting natural events by the use of an independent visual estimate - a human fall detector task-based evaluation of image filtering within a class of geometry-driven-diffusion algorithms a comparative analysis of cross-correlation matching algorithms using a pyramidal resolution approach performance evaluation of medical image processing algorithms."
            },
            "slug": "Empirical-Evaluation-Methods-in-Computer-Vision-Christensen-Phillips",
            "title": {
                "fragments": [],
                "text": "Empirical Evaluation Methods in Computer Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Automated performance evaluation of range image segmentation algorithms training/test data partitioning for empirical performance evaluation analyzing PCA-based face recognition algorithms."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145687022"
                        ],
                        "name": "J. Crowley",
                        "slug": "J.-Crowley",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Crowley",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Crowley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690082"
                        ],
                        "name": "P. Reignier",
                        "slug": "P.-Reignier",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Reignier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Reignier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "123807027"
                        ],
                        "name": "S. Pesnel",
                        "slug": "S.-Pesnel",
                        "structuredName": {
                            "firstName": "Sebastien",
                            "lastName": "Pesnel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Pesnel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 32
                            }
                        ],
                        "text": "In this work, we introduce two intuitive and general metrics to allow for objective comparison of tracker characteristics, focusing on their precision in estimating object locations, their accuracy in recognizing object configurations and their ability to consistently label objects over time."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 54188547,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "4af517b9ebb3e159e59d8608d8369494cca69f52",
            "isKey": false,
            "numCitedBy": 202,
            "numCiting": 127,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper summarizes the 28 video sequences available for result comparison in the PETS04 workshop. The sequences are from about 500 to 1400 frames in length, for a total of about 26500 frames. The sequences are annotated with both target position and activities by the CAVIAR research team members."
            },
            "slug": "CAVIAR-Context-Aware-Vision-using-Image-based-Crowley-Reignier",
            "title": {
                "fragments": [],
                "text": "CAVIAR Context Aware Vision using Image-based Active Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 25
                            }
                        ],
                        "text": "Unfortunately, the lack of common metrics for measuring the performance of multiple object trackers still makes it hard to compare their results."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 45120074,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b04f7580fad9ae9b79014d2b96ee088071f8407b",
            "isKey": false,
            "numCitedBy": 165,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "CHIL (\"Computers in the Human Interaction Loop\") is an Integrated Project under the European Commission's Sixth Framework Programme. The CHIL consortium is jointly coordinated by Universitat Karlsruhe (TH) and the Fraunhofer Institute IITB. CHIL was launched on January 1st, 2004. The objective of this project is to explore and create environments in which computers serve humans who focus on interacting with other humans as opposed to having to attend to and being preoccupied by the machines themselves. Instead of computers operating in an isolated manner, and humans [thrust] in the loop [of computers]. CHIL puts Computers in the Human Interaction Loop (CHIL). Fifteen partners from nine countries in Europe and the US collaborate in the CHIL Consortium to design Technologies and Computer Services that model humans and the state of their activities and intentions. A complete perceptual context enables a family of CHIL computing services that provide helpful assistance implicitly, requiring a minimum of human attention or interruptions. 1. PROJECT DESCRIPTION The objective of the CHIL project is to create environments in which computers serve humans who focus on interacting with other humans as opposed to having to attend to and being preoccupied with the machines themselves. Instead of computers operating in an isolated manner, and Humans [thrust] in the loop [of computers], we will put Computers in the Human Interaction Loop (CHIL). We design Computer Services that model humans and the state of their activities and intentions. Based on the understanding of the human perceptual context, CHIL computers are enabled to provide helpful assistance implicitly, requiring a minimum of human attention or interruptions (see also the CHIL \u2013 Scenarios section). To achieve this overall vision, a broad set of key scientific issues is proposed: Multimodal Perceptual User Interfaces that observe, recognize, fuse, and interpret all available cues and clues to explain human-human activities and intentions. Fundamental new algorithms are needed to achieve these capabilities (see the CHIL \u2013 Technologies section). A suite of Services that instantiate CHIL Computing based on perceptual context awareness and understanding of human activity. These services must balance implicit and explicit computer interaction, and must deliver information in an appropriate manner. Services include better ways of connecting people (without phone-tag), supporting human memory, & providing meeting support (see CHIL \u2013 Services) and more. A supportive infrastructure that supports CHIL Services including Automomic Computing, selfhealing and self-maintaining software, flexible architecture, and a networked infrastructure integrating numerous devices intermittently and dynamically. The resulting shift from HumanComputer Interaction only (requiring full human attention) to increased reliance on human-human interaction is expected to lead to human productivity gains and reduced computer frustration (see CHIL \u2013 Software Architecture)."
            },
            "slug": "CHIL-Computers-in-the-Human-Interaction-Loop-Waibel",
            "title": {
                "fragments": [],
                "text": "CHIL - Computers in the Human Interaction Loop"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A broad set of key scientific issues is proposed: Multimodal Perceptual User Interfaces that observe, recognize, fuse, and interpret all available cues and clues to explain human-human activities and intentions."
            },
            "venue": {
                "fragments": [],
                "text": "MVA"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69393819"
                        ],
                        "name": "J. Munkres",
                        "slug": "J.-Munkres",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Munkres",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Munkres"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 64
                            }
                        ],
                        "text": "One would then count all correspondences where this mapping is violated as errors."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15996572,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "848c717ba51e48afef714dfef4bd6ab1cc050dab",
            "isKey": false,
            "numCitedBy": 3433,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we presen algorithms for the solution of the general assignment and transportation problems. In Section 1, a statement of the algorithm for the assignment problem appears, along with a proof for the correctness of the algorithm. The remarks which constitute the proof are incorporated parenthetically into the statement of the algorithm. Following this appears a discussion of certain theoretical aspects of the problem. In Section 2, the algorithm is generalized to one for the transportation problem. The algorithm of that section is stated as concisely as possible, with theoretical remarks omitted."
            },
            "slug": "Algorithms-for-the-Assignment-and-Transportation-Munkres",
            "title": {
                "fragments": [],
                "text": "Algorithms for the Assignment and Transportation Problems"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "In this paper, algorithms for the solution of the general assignment and transportation problems are presen, and the algorithm is generalized to one for the transportation problem."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1957
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2133982016"
                        ],
                        "name": "Charles L. Smith",
                        "slug": "Charles-L.-Smith",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Smith",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charles L. Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 230
                            }
                        ],
                        "text": "The classification of events, activities, and relationships (CLEARs) workshops [11] as organized in a collaboration between the European CHIL project, the U.S. VACE project, and the National Institute of Standards and Technology (NIST) [21] (as well as the AMI project, in 2007), and were held in the springs of 2006 and 2007."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 207
                            }
                        ],
                        "text": "\u2026activities, and relationships (CLEARs) workshops [11] as organized in a collaboration between the European CHIL project, the U.S. VACE project, and the National Institute of Standards and Technology (NIST) [21] (as well as the AMI project, in 2007), and were held in the springs of 2006 and 2007."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 401373,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "04a47929aa0838ab344d0cc78171cf0ae0eed793",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "This material is based upon work supported by the Department of Commerce under contract number 50-DKNB-5-00188. Any opinions, findings, and conclusions or recommendations expressed in this publication are those of the authors and do not necessarily reflect the views of the Department of Commerce. There is a recognized need for a more robust method of performing security controls in computer network systems [Ferraiolo et al. 1992]. One promising method is called role-based access control (RBAC). Although the basic ideas for RBAC have existed for over 20 years, there has been a recent resurgence of interest in RBAC, largely because of the disenchantment with traditional mandatory and discretionary access controls by many users. The essence of RBAC is that rights and permissions are assigned to roles rather than to individual users. Users acquire these rights and permissions by virtue of being assigned membership in appropriate roles. This method makes the administration of security access much simpler than with current approaches. Although RBAC is receiving much attention among potential users and vendors, it is not known what the consumer demand will be for RBAC products. Consequently, this marketing survey was conducted. This study is essentially a marketing survey to identify customer requirements regarding their security needs for information processing systems and to determine whether an RBAC product can meet these requirements. Information system requirements must originate from the system users, that is, from the organizational stakeholders who are concerned about the performance of their system and whose jobs are affected by the system's capabilities. Regarding security aspects of a system, these stakeholders are generally called security managers, security officers, security administrators, or some similar name. There are existing packages that sometimes purport to be role-based security implementations, but these packages are greatly limited in their capabilities to emulate the robustness of an RBAC product as manifested in the reference material. It should be understood that RBAC is not a replacement for the existing mandatory access control (MAC) and discretionary access control (DAC) products, it is an adjunct to them. Moreover, RBAC adds security capabilities that are not resident in the current security products. Some stakeholders understand that security needs represent a set of complex issues, yet their purchased security packages are often a response to \"we need a security product\" without understanding what the actual security issues are nor having an appreciation for the need of a capable security system. The complexity \u2026"
            },
            "slug": "NIST-National-Institute-of-Standards-and-Technology-Smith",
            "title": {
                "fragments": [],
                "text": "NIST National Institute of Standards and Technology Small Business Innovation Research ( SBIR ) A Marketing Survey of Civil Federal Government Organizations to Determine the Need for a Role-Based Access Control ( RBAC ) Security Product SETA"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This study is essentially a marketing survey to identify customer requirements regarding their security needs for information processing systems and to determine whether an RBAC product can meet these requirements."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742325"
                        ],
                        "name": "R. Stiefelhagen",
                        "slug": "R.-Stiefelhagen",
                        "structuredName": {
                            "firstName": "Rainer",
                            "lastName": "Stiefelhagen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Stiefelhagen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2467151"
                        ],
                        "name": "John S. Garofolo",
                        "slug": "John-S.-Garofolo",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Garofolo",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John S. Garofolo"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 126
                            }
                        ],
                        "text": "A complete description of the CLEAR evaluation workshops, the participating systems, and the achieved results can be found in [22, 23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59650024,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3e7b5214c054b30378b30f611b07fd0367655007",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Multimodal-Technologies-for-Perception-of-Humans:-Stiefelhagen-Garofolo",
            "title": {
                "fragments": [],
                "text": "Multimodal Technologies for Perception of Humans: First International Evaluation Workshop on Classification of Events, Activities and Relationships, CLEAR ... Papers (Lecture Notes in Computer Science)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742325"
                        ],
                        "name": "R. Stiefelhagen",
                        "slug": "R.-Stiefelhagen",
                        "structuredName": {
                            "firstName": "Rainer",
                            "lastName": "Stiefelhagen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Stiefelhagen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33875838"
                        ],
                        "name": "Rachel Bowers",
                        "slug": "Rachel-Bowers",
                        "structuredName": {
                            "firstName": "Rachel",
                            "lastName": "Bowers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rachel Bowers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3241934"
                        ],
                        "name": "J. Fiscus",
                        "slug": "J.-Fiscus",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Fiscus",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Fiscus"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 131
                            }
                        ],
                        "text": "A complete description of the CLEAR evaluation workshops, the participating systems, and the achieved results can be found in [22, 23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11442395,
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "id": "d4cfd4e69cabf0045d29b077fc6561fc955a2252",
            "isKey": false,
            "numCitedBy": 173,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Multimodal-Technologies-for-Perception-of-Humans,-Stiefelhagen-Bowers",
            "title": {
                "fragments": [],
                "text": "Multimodal Technologies for Perception of Humans, International Evaluation Workshops CLEAR 2007 and RT 2007, Baltimore, MD, USA, May 8-11, 2007, Revised Selected Papers"
            },
            "venue": {
                "fragments": [],
                "text": "CLEAR"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 106
                            }
                        ],
                        "text": "In this work, we introduce two intuitive and general metrics to allow for objective comparison of tracker characteristics, focusing on their precision in estimating object locations, their accuracy in recognizing object configurations and their ability to consistently label objects over time."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "PETS\u2014Performance Evaluation of Tracking and Surveillance"
            },
            "venue": {
                "fragments": [],
                "text": "PETS\u2014Performance Evaluation of Tracking and Surveillance"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 114
                            }
                        ],
                        "text": "Unfortunately, the lack of common metrics for measuring the performance of multiple object trackers still makes it hard to compare their results."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "ETISEO\u2014Video Understanding Evaluation"
            },
            "venue": {
                "fragments": [],
                "text": "ETISEO\u2014Video Understanding Evaluation"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 16
                            }
                        ],
                        "text": "In this work, we introduce two intuitive and general metrics to allow for objective comparison of tracker characteristics, focusing on their precision in estimating object locations, their accuracy in recognizing object configurations and their ability to consistently label objects over time."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The i-LIDS dataset, http://scienceandresearch.homeoffice.gov. uk/hosdb/cctv-imaging-technology/video-based-detection- systems/i-lids"
            },
            "venue": {
                "fragments": [],
                "text": "The i-LIDS dataset, http://scienceandresearch.homeoffice.gov. uk/hosdb/cctv-imaging-technology/video-based-detection- systems/i-lids"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 91
                            }
                        ],
                        "text": "Unfortunately, the lack of common metrics for measuring the performance of multiple object trackers still makes it hard to compare their results."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "VACE\u2014Video Analysis and Content Extraction"
            },
            "venue": {
                "fragments": [],
                "text": "VACE\u2014Video Analysis and Content Extraction"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "11] CLEAR\u2014Classification of Events, Activities and Relationships , http://www.clear-evaluation"
            },
            "venue": {
                "fragments": [],
                "text": "11] CLEAR\u2014Classification of Events, Activities and Relationships , http://www.clear-evaluation"
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 9,
            "methodology": 14
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 22,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Evaluating-Multiple-Object-Tracking-Performance:-Bernardin-Stiefelhagen/2258e01865367018ed6f4262c880df85b94959f8?sort=total-citations"
}