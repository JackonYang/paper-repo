{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8191738,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "73ba229d5fe920e33ad0509707602a97ef492ffd",
            "isKey": false,
            "numCitedBy": 215,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Constraint-Propagation-Approach-to-Probabilistic-Pearl",
            "title": {
                "fragments": [],
                "text": "A Constraint-Propagation Approach to Probabilistic Reasoning"
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152674014"
                        ],
                        "name": "Jin H. Kim",
                        "slug": "Jin-H.-Kim",
                        "structuredName": {
                            "firstName": "Jin",
                            "lastName": "Kim",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jin H. Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1907708,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f8d16924d37ac2ad2fe23e641673f9f2b5434733",
            "isKey": false,
            "numCitedBy": 398,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces a representation of evidential relationships which permits updating of belief in two simultaneous modes: causal (i. e. top-down) and diagnostic (i.e. bottom-up). It extends the hierarchical tree representation by allowing multiple causes to a given manifestation. We develop an updating scheme that obeys the axioms of probability, is computationally efficient, and is compatible with experts reasoning. The belief parameters of each variable are defined and updated by those of its neighbors in such a way that the impact of each new evidence propagates and settles through the network in a single pass."
            },
            "slug": "A-Computational-Model-for-Causal-and-Diagnostic-in-Kim-Pearl",
            "title": {
                "fragments": [],
                "text": "A Computational Model for Causal and Diagnostic Reasoning in Inference Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "A representation of evidential relationships which permits updating of belief in two simultaneous modes: causal and diagnostic is introduced, which extends the hierarchical tree representation by allowing multiple causes to a given manifestation."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2932960"
                        ],
                        "name": "Ross D. Shachter",
                        "slug": "Ross-D.-Shachter",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Shachter",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross D. Shachter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9157064,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3b99793e181ea13b6f79a046b33b65ed692b3614",
            "isKey": false,
            "numCitedBy": 90,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Intelligent-Probabilistic-Inference-Shachter",
            "title": {
                "fragments": [],
                "text": "Intelligent Probabilistic Inference"
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40484982"
                        ],
                        "name": "P. Cheeseman",
                        "slug": "P.-Cheeseman",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Cheeseman",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Cheeseman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1916080,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9c6a1d357695f96ef42d97a6a218a11094bf76ec",
            "isKey": false,
            "numCitedBy": 179,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new method for calculating the conditional probability of any multi-valued predicate given particular information about the individual case. This calculation is based on the principle of Maximum Entropy (ME), sometimes called the principle of least information, and gives the most unbiased probability estimate given the available evidence. Previous methods for computing maximum entropy values shows that they are either very restrictive in the probabilistic information (constraints) they can use or combinatorially explosive. The computational complexity of the new procedure depends on the inter-connectedness of the constraints, but in practical cases it is small. In addition, the maximum entropy method can give a measure of how accurately a calculated conditional probability is known."
            },
            "slug": "A-Method-of-Computing-Generalized-Bayesian-Values-Cheeseman",
            "title": {
                "fragments": [],
                "text": "A Method of Computing Generalized Bayesian Probability Values for Expert Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "A new method for calculating the conditional probability of any multi-valued predicate given particular information about the individual case is presented, based on the principle of Maximum Entropy (ME), and gives the most unbiased probability estimate given the available evidence."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3288569"
                        ],
                        "name": "H. Kiiveri",
                        "slug": "H.-Kiiveri",
                        "structuredName": {
                            "firstName": "Harri",
                            "lastName": "Kiiveri",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kiiveri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29989822"
                        ],
                        "name": "T. Speed",
                        "slug": "T.-Speed",
                        "structuredName": {
                            "firstName": "Terence",
                            "lastName": "Speed",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Speed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145779280"
                        ],
                        "name": "J. Carlin",
                        "slug": "J.-Carlin",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Carlin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Carlin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 123563836,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9cef473b998702c904ada536c1b403d28eb5c88a",
            "isKey": false,
            "numCitedBy": 208,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract The notion of a recursive causal graph is introduced, hopefully capturing the essential aspects of the path diagrams usually associated with recursive causal models. We describe the conditional independence constraints which such graphs are meant to embody and prove a theorem relating the fulfilment of these constraints by a probability distribution to a particular sort of factorisation. The relation of our results to the usual linear structural equations on the one hand, and to log-linear models, on the other, is also explained"
            },
            "slug": "Recursive-causal-models-Kiiveri-Speed",
            "title": {
                "fragments": [],
                "text": "Recursive causal models"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The conditional independence constraints which such graphs are meant to embody are described and a theorem relating the fulfilment of these constraints by a probability distribution to a particular sort of factorisation is proved."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Australian Mathematical Society. Series A. Pure Mathematics and Statistics"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48616434"
                        ],
                        "name": "D. Spiegelhalter",
                        "slug": "D.-Spiegelhalter",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Spiegelhalter",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Spiegelhalter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 22141936,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "0186cd6bb844ceb0d03538f5bb3677c77505ddd6",
            "isKey": false,
            "numCitedBy": 333,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "It is argued that the provision of accurate and useful probabilistic assessments of future events should be a fundamental task for biostatisticians collaborating in clinical or experimental medicine, and we explore two aspects of obtaining and evaluating such predictions. When covariate information on patients is available, logistic regression and other multivariate techniques are often used to select prognostic factors and create predictive models. An example shows how the explicit aim of prediction needs to be taken into account in such modelling, and how predictive performance may be assessed by decomposition of a scoring rule. Secondly, results from a program that provides pretrial and interim predictions in clinical trials are displayed, bringing together the use of subjective opinion, Bayesian methodology and techniques for evaluating and criticizing predictions."
            },
            "slug": "Probabilistic-prediction-in-patient-management-and-Spiegelhalter",
            "title": {
                "fragments": [],
                "text": "Probabilistic prediction in patient management and clinical trials."
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "It is argued that the provision of accurate and useful probabilistic assessments of future events should be a fundamental task for biostatisticians collaborating in clinical or experimental medicine, and two aspects of obtaining and evaluating predictions are explored."
            },
            "venue": {
                "fragments": [],
                "text": "Statistics in medicine"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40128558"
                        ],
                        "name": "J. Hilden",
                        "slug": "J.-Hilden",
                        "structuredName": {
                            "firstName": "J",
                            "lastName": "Hilden",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hilden"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145217017"
                        ],
                        "name": "J. Habbema",
                        "slug": "J.-Habbema",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Habbema",
                            "middleNames": [
                                "Dik",
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Habbema"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3065841"
                        ],
                        "name": "B. Bjerregaard",
                        "slug": "B.-Bjerregaard",
                        "structuredName": {
                            "firstName": "Beth",
                            "lastName": "Bjerregaard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Bjerregaard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 46142233,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2df8c738eee2c4420056686b936f6c758c4fdecd",
            "isKey": false,
            "numCitedBy": 120,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The measurement of performance in probabilistic diagnosis. III. Methods based on continuous functions of the diagnostic probabilities. -"
            },
            "slug": "The-measurement-of-performance-in-probabilistic-on-Hilden-Habbema",
            "title": {
                "fragments": [],
                "text": "The measurement of performance in probabilistic diagnosis. III. Methods based on continuous functions of the diagnostic probabilities."
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "The measurement of performance in probabilistic diagnosis using methods based on continuous functions of the diagnostic probabilities and its application in medicine."
            },
            "venue": {
                "fragments": [],
                "text": "Methods of information in medicine"
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40484982"
                        ],
                        "name": "P. Cheeseman",
                        "slug": "P.-Cheeseman",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Cheeseman",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Cheeseman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14912563,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "932ab48b61b7c139345632afc46da8e1341a5545",
            "isKey": false,
            "numCitedBy": 290,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, it is argued that probability theory, when used correctly, is suffrcient for the task of reasoning under uncertainty. Since numerous authors have rejected probability as inadequate for various reasons, the bulk of the paper is aimed at refuting these claims and indicating the scources of error. In particular, the definition of probability as a measure of belief rather than a frequency ratio is advocated, since a frequency interpretation of probability drastically restricts the domain of applicability. Other sources of error include the confusion between relative and absolute probability, the distinction between probability and the uncertainty of that probability. Also, the interaction of logic and probability is discusses and it is argued that many extensions of logic, such as \"default logic\" are better understood in a probabilistic framework. The main claim of this paper is that the numerous schemes for representing and reasoning about uncertainty that have appeared in the AI literature are unnecessary--probability is all that is needed."
            },
            "slug": "In-Defense-of-Probability-Cheeseman",
            "title": {
                "fragments": [],
                "text": "In Defense of Probability"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "It is argued that probability theory, when used correctly, is suffrcient for the task of reasoning under uncertainty and many extensions of logic, such as \"default logic\" are better understood in a probabilistic framework."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16242797"
                        ],
                        "name": "J. Lemmer",
                        "slug": "J.-Lemmer",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Lemmer",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lemmer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47045482"
                        ],
                        "name": "Stephen W. Barth",
                        "slug": "Stephen-W.-Barth",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Barth",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen W. Barth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8667285,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e07fab3c22eed88926192452d5702d847904b3c2",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "This short paper Dresents a new algorithm for minimun information Bayesian Inferencing within Expert Systems. This algorithm is as efficient in both time and space as previously reported work [3 3 but always provides a minimum information result. In addition to describing the new algorithm, we will prove that it does indeed satisfy minimum information criteria. Since both algorithms are sub stantially different from the \"Bayesian\" approaches in well known expert systems such as the original Prospector [1], AL/X [8], and MYCIN [9 3, and from the approach of Kulikowski [5], background is provided to show the motivation for using the minimum information approach to Bayesian updating."
            },
            "slug": "Efficient-Minimum-Information-Updating-for-Bayesian-Lemmer-Barth",
            "title": {
                "fragments": [],
                "text": "Efficient Minimum Information Updating for Bayesian Inferencing in Expert Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A new algorithm for minimun information Bayesian Inferencing within Expert Systems is presented and it is proved that it does indeed satisfy minimum information criteria."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "104199178"
                        ],
                        "name": "David Lindley",
                        "slug": "David-Lindley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lindley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Lindley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118415039,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f6f2f95405922022acfee38a58aadb3cd853140f",
            "isKey": false,
            "numCitedBy": 311,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : Let a person express his uncertainty about an event E, conditional upon an event F, by a number x and let him be given, as a result, a score which depends on x and the truth or falsity of E when F is true. It is shown that if the scores are additive for different events and if the person chooses admissible values only, then there exists a known transform of the values x to values which are probabilities. In particular, it follows that values x derived by significance tests, confidence intervals or by the rules of fuzzy logic are inadmissible. Only probability is a sensible description of uncertainty."
            },
            "slug": "Scoring-rules-and-the-inevitability-of-probability-Lindley",
            "title": {
                "fragments": [],
                "text": "Scoring Rules and the Inevitability of Probability"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726406"
                        ],
                        "name": "G. Cooper",
                        "slug": "G.-Cooper",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Cooper",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cooper"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 58660085,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "373b1817afebdced6119cb6564a6be187b4823a9",
            "isKey": false,
            "numCitedBy": 256,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : In order to address some existing problems in computer-aided medical decision making, a computer program called NESTOR has been developed to aid physicians in determining the most likely diagnostic hypothesis to account for a set of patient findings. The domain of hypercalcemic disorders is used to test solution methods that should be applicable to other medical areas. A key design philosophy underlying NESTOR is that the physicians should have control of the computer interaction to determine what is done and when. In order to provide such controllable, interactive aid, specific technical tasks to be addressed. The unifying philosophy in addressing them is the use of knowledge-based methods within a formal probability theory framework. A user interface module gives the physician control over when and how these tasks are used to aid in diagnosing the cause of a patient's condition. This dissertation presents the problems that are addressed by each of the three tasks, and the details of the methods used to address them. In addition, the results of an evaluation of the hypothesis scoring and search techniques are presented and discussed. Additional keywords: artificial intelligence; expert systems; medical applications; computer aided diagnosis; medical computer applications."
            },
            "slug": "NESTOR:-A-Computer-Based-Medical-Diagnostic-Aid-and-Cooper",
            "title": {
                "fragments": [],
                "text": "NESTOR: A Computer-Based Medical Diagnostic Aid That Integrates Causal and Probabilistic Knowledge."
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This dissertation presents the problems that are addressed by each of the three tasks of NESTOR, the use of knowledge-based methods within a formal probability theory framework, and the details of the methods used to address them."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40504483"
                        ],
                        "name": "R. Giles",
                        "slug": "R.-Giles",
                        "structuredName": {
                            "firstName": "Robin",
                            "lastName": "Giles",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Giles"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62732200,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "d10af902dac25fbf246fd1e79aa94f4c24b8e1a6",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Semantics-for-fuzzy-reasoning-Giles",
            "title": {
                "fragments": [],
                "text": "Semantics for fuzzy reasoning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3184408"
                        ],
                        "name": "N. Wermuth",
                        "slug": "N.-Wermuth",
                        "structuredName": {
                            "firstName": "Nanny",
                            "lastName": "Wermuth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Wermuth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050895"
                        ],
                        "name": "S. Lauritzen",
                        "slug": "S.-Lauritzen",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Lauritzen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lauritzen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122212913,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3fd09c27013b58827b8f8a71825c86128744b162",
            "isKey": false,
            "numCitedBy": 255,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "SUMMARY We discuss two classes of models for contingency tables, graphical and recursive models, both of which arise from restrictions that are expressible as conditional independencies of variable pairs. The first of these is a subclass of hierarchical log linear models. Each of its models can be represented by an undirected graph. In the second class each model corresponds to a particular kind of a directed graph instead and can be characterized by a nontrivial factorization of the joint distribution in terms of response variables. We derive decomposable or multiplicative models as the intersecting class. This result has useful consequences for exploratory types of analysis as well as for the model interpretation: we can give an aid for detecting well-fitting decomposable models in a transformation of the observed contingency table and each decomposable model may be interpreted with the help of an undirected or directed graph."
            },
            "slug": "Graphical-and-recursive-models-for-contingency-Wermuth-Lauritzen",
            "title": {
                "fragments": [],
                "text": "Graphical and recursive models for contingency tables"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1830895"
                        ],
                        "name": "R. L. Winkler",
                        "slug": "R.-L.-Winkler",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Winkler",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. L. Winkler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 119728573,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "128079a3d2ed046c6b67930b03bcfd34a297c7bc",
            "isKey": false,
            "numCitedBy": 260,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract The personalistic theory of probability prescribes that personal probability assessments to be used in decision-making situations should correspond with the assessor's judgments. A payoff function which depends on the assessor's stated probabilities and on the event which actually occurs may be used (1) to keep the assessor honest or (2) to evaluate the assessor. It is shown that with the exception of a logarithmic payoff function, these two uses of payoff functions for assessors are not compatible. This conflict is explained in terms of the differences in the situations facing the assessor and the evaluator (the user of the probabilistic predictions)."
            },
            "slug": "Scoring-Rules-and-the-Evaluation-of-Probability-Winkler",
            "title": {
                "fragments": [],
                "text": "Scoring Rules and the Evaluation of Probability Assessors"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2975527"
                        ],
                        "name": "L. Zadeh",
                        "slug": "L.-Zadeh",
                        "structuredName": {
                            "firstName": "Lotfi",
                            "lastName": "Zadeh",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Zadeh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 53121887,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f3f40eb2a52040440a54b1b61421f52c9da83920",
            "isKey": false,
            "numCitedBy": 1301,
            "numCiting": 110,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-role-of-fuzzy-logic-in-the-management-of-in-Zadeh",
            "title": {
                "fragments": [],
                "text": "The role of fuzzy logic in the management of uncertainty in expert systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116914338"
                        ],
                        "name": "A. Wold",
                        "slug": "A.-Wold",
                        "structuredName": {
                            "firstName": "Atle",
                            "lastName": "Wold",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Wold"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 156107934,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "351aba16a4f1ecacbec517feb61a724a36e76633",
            "isKey": false,
            "numCitedBy": 87,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "The parting of the ways between causal chain (recursive) and interdependent (nonrecursive) systems is reviewed from the point of view of explanatory relations specified in terms of conditional expectations. On the customary assumptions, a causal chain system is designed so that its relations both in the original form and in the reduced form can be specified in terms of conditional expectations, whereas the relations of interdependent systems allow such specification only in the reduced form. A third type of model is discussed, called conditional causal chains, which formally is similar to interdependent systems, with the important difference that the behavioural relations of the original system are specified in terms of conditional expectations."
            },
            "slug": "A-GENERALIZATION-OF-CAUSAL-CHAIN-MODELS-(PART-III-A-Wold",
            "title": {
                "fragments": [],
                "text": "A GENERALIZATION OF CAUSAL CHAIN MODELS (PART III OF A TRIPTYCH ON CAUSAL CHAIN SYSTEMS)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1960
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145673139"
                        ],
                        "name": "D. Edwards",
                        "slug": "D.-Edwards",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Edwards",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Edwards"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3603472"
                        ],
                        "name": "S. Kreiner",
                        "slug": "S.-Kreiner",
                        "structuredName": {
                            "firstName": "Svend",
                            "lastName": "Kreiner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kreiner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120667815,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "3162dd7d3ae591f3132bd21ea3f9f6720b58eb92",
            "isKey": false,
            "numCitedBy": 78,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "SUMMARY Some aspects of the analysis of multidimensional contingency tables in practice are considered. The class of graphical models defined by Darroch, Lauritzen & Speed (1980) is described, strategies for model selection based on this class are considered and an example is given."
            },
            "slug": "The-analysis-of-contingency-tables-by-graphical-Edwards-Kreiner",
            "title": {
                "fragments": [],
                "text": "The analysis of contingency tables by graphical models"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49223598"
                        ],
                        "name": "J. Darroch",
                        "slug": "J.-Darroch",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Darroch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Darroch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050895"
                        ],
                        "name": "S. Lauritzen",
                        "slug": "S.-Lauritzen",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Lauritzen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lauritzen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29989822"
                        ],
                        "name": "T. Speed",
                        "slug": "T.-Speed",
                        "structuredName": {
                            "firstName": "Terence",
                            "lastName": "Speed",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Speed"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3545924,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "10143673f3f1a49d346120928d6b9a56851d6cf0",
            "isKey": false,
            "numCitedBy": 437,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We use a close connection between the theory of Markov fields and that of log-linear interaction models for contingency tables to define and investigate a new class of models for such tables, graphical models. These models are hierarchical models that can be represented by a simple, undirected graph on as many vertices as the dimension of the corresponding table. Further all these models can be given an interpretation in terms of conditional independence and the interpretation can be read directly off the graph in the form of a Markov property. The class of graphical models contains that of decomposable models and we give a simple criterion for decomposability of a given graphical model. To some extent we discuss estimation problems and give suggestions for further work."
            },
            "slug": "Markov-Fields-and-Log-Linear-Interaction-Models-for-Darroch-Lauritzen",
            "title": {
                "fragments": [],
                "text": "Markov Fields and Log-Linear Interaction Models for Contingency Tables"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3194361"
                        ],
                        "name": "S. Geman",
                        "slug": "S.-Geman",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Geman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707642"
                        ],
                        "name": "D. Geman",
                        "slug": "D.-Geman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5837272,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "459b30a9a960080f3b313e41886b1aa0e51e882c",
            "isKey": false,
            "numCitedBy": 18711,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "We make an analogy between images and statistical mechanics systems. Pixel gray levels and the presence and orientation of edges are viewed as states of atoms or molecules in a lattice-like physical system. The assignment of an energy function in the physical system determines its Gibbs distribution. Because of the Gibbs distribution, Markov random field (MRF) equivalence, this assignment also determines an MRF image model. The energy function is a more convenient and natural mechanism for embodying picture attributes than are the local characteristics of the MRF. For a range of degradation mechanisms, including blurring, nonlinear deformations, and multiplicative or additive noise, the posterior distribution is an MRF with a structure akin to the image model. By the analogy, the posterior distribution defines another (imaginary) physical system. Gradual temperature reduction in the physical system isolates low energy states (``annealing''), or what is the same thing, the most probable states under the Gibbs distribution. The analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations. The result is a highly parallel ``relaxation'' algorithm for MAP estimation. We establish convergence properties of the algorithm and we experiment with some simple pictures, for which good restorations are obtained at low signal-to-noise ratios."
            },
            "slug": "Stochastic-Relaxation,-Gibbs-Distributions,-and-the-Geman-Geman",
            "title": {
                "fragments": [],
                "text": "Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "The analogy between images and statistical mechanics systems is made and the analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations, creating a highly parallel ``relaxation'' algorithm for MAP estimation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3072213"
                        ],
                        "name": "J. Besag",
                        "slug": "J.-Besag",
                        "structuredName": {
                            "firstName": "Julian",
                            "lastName": "Besag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Besag"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15128952,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "47865b56fee61d9c9ff477f7c79f090cc6663d3a",
            "isKey": false,
            "numCitedBy": 4635,
            "numCiting": 79,
            "paperAbstract": {
                "fragments": [],
                "text": "may 7th, 1986, Professor A. F. M. Smith in the Chair] SUMMARY A continuous two-dimensional region is partitioned into a fine rectangular array of sites or \"pixels\", each pixel having a particular \"colour\" belonging to a prescribed finite set. The true colouring of the region is unknown but, associated with each pixel, there is a possibly multivariate record which conveys imperfect information about its colour according to a known statistical model. The aim is to reconstruct the true scene, with the additional knowledge that pixels close together tend to have the same or similar colours. In this paper, it is assumed that the local characteristics of the true scene can be represented by a nondegenerate Markov random field. Such information can be combined with the records by Bayes' theorem and the true scene can be estimated according to standard criteria. However, the computational burden is enormous and the reconstruction may reflect undesirable largescale properties of the random field. Thus, a simple, iterative method of reconstruction is proposed, which does not depend on these large-scale characteristics. The method is illustrated by computer simulations in which the original scene is not directly related to the assumed random field. Some complications, including parameter estimation, are discussed. Potential applications are mentioned briefly."
            },
            "slug": "On-the-Statistical-Analysis-of-Dirty-Pictures-Besag",
            "title": {
                "fragments": [],
                "text": "On the Statistical Analysis of Dirty Pictures"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145700185"
                        ],
                        "name": "S. Weiss",
                        "slug": "S.-Weiss",
                        "structuredName": {
                            "firstName": "Sholom",
                            "lastName": "Weiss",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Weiss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3285789"
                        ],
                        "name": "C. Kulikowski",
                        "slug": "C.-Kulikowski",
                        "structuredName": {
                            "firstName": "Casimir",
                            "lastName": "Kulikowski",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Kulikowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2182836"
                        ],
                        "name": "S. Amarel",
                        "slug": "S.-Amarel",
                        "structuredName": {
                            "firstName": "Saul",
                            "lastName": "Amarel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Amarel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2765291"
                        ],
                        "name": "A. Safir",
                        "slug": "A.-Safir",
                        "structuredName": {
                            "firstName": "Aran",
                            "lastName": "Safir",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Safir"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8835382,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "da2802b3af2458adfd2246202e3f4a4ca5afe7a0",
            "isKey": false,
            "numCitedBy": 503,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Model-Based-Method-for-Computer-Aided-Medical-Weiss-Kulikowski",
            "title": {
                "fragments": [],
                "text": "A Model-Based Method for Computer-Aided Medical Decision-Making"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4640201"
                        ],
                        "name": "V. Isham",
                        "slug": "V.-Isham",
                        "structuredName": {
                            "firstName": "Valerie",
                            "lastName": "Isham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Isham"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121854003,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "c5632b40077a9783b5afaa65f0bbe918eb63cec0",
            "isKey": false,
            "numCitedBy": 88,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Binary-valued Markov random fields may be used as models for point processes with interactions (e.g. repulsion or attraction) between their points. This paper aims to provide a simple nontechnical introduction to Markov random fields in this context. The underlying spaces on which points occur are taken to be countable (e.g. lattice vertices) or continuous (Euclidean space). The role of Markov random fields as equilibrium processes for the temporal evolution of spatial processes is also discussed and various applications and examples are given."
            },
            "slug": "An-Introduction-to-Spatial-Point-Processes-and-Isham",
            "title": {
                "fragments": [],
                "text": "An Introduction to Spatial Point Processes and Markov Random Fields"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The role of Markov random fields as equilibrium processes for the temporal evolution of spatial processes is discussed and various applications and examples are given."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70056214"
                        ],
                        "name": "S. Wright",
                        "slug": "S.-Wright",
                        "structuredName": {
                            "firstName": "Sewall",
                            "lastName": "Wright",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Wright"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 121382684,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "f6d9ba13cb2f6354787e1c8fe4ee30cbd5f6addb",
            "isKey": false,
            "numCitedBy": 1791,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "The Method of path coefficients was suggested a number of years ago (Wright 1918, more fully 1920, 1921), as a flexible means of relating the correlation coefficients between variables in a multiple system to the functional relations among them. The method has been applied in quite a variety of cases. It seems desirable now to make a restatement of the theory and to review the types of application, especially as there has been a certain amount of misunderstanding both of purpose and of procedure."
            },
            "slug": "The-Method-of-Path-Coefficients-Wright",
            "title": {
                "fragments": [],
                "text": "The Method of Path Coefficients"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1934
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721050"
                        ],
                        "name": "R. Tarjan",
                        "slug": "R.-Tarjan",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Tarjan",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Tarjan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748179"
                        ],
                        "name": "M. Yannakakis",
                        "slug": "M.-Yannakakis",
                        "structuredName": {
                            "firstName": "Mihalis",
                            "lastName": "Yannakakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Yannakakis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 2995077,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "1ffc977d82798cfab971e4abdb46ae7b707c57c0",
            "isKey": false,
            "numCitedBy": 1113,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "An article of golfing equipment has a golf tee attached to a spring-biassed reel by a length of string. The reel is mounted in a casing which receives the tee when the spring rotates the reel to wind the spring onto it. The reel is normally locked by a one-way ratchet but is released to wind in the string by a push-button which has a spike and is detachable from the casing so as to be usable as a ball marker. When practising, the cord can be aligned with the green or hole and used as an aid in swinging the club face in the correct direction. The casing has a spring-clip so that the article can be clipped into the golfer's pocker when he is not using it."
            },
            "slug": "Simple-Linear-Time-Algorithms-to-Test-Chordality-of-Tarjan-Yannakakis",
            "title": {
                "fragments": [],
                "text": "Simple Linear-Time Algorithms to Test Chordality of Graphs, Test Acyclicity of Hypergraphs, and Selectively Reduce Acyclic Hypergraphs"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "An article of golfing equipment has a golf tee attached to a spring-biassed reel by a length of string which can be aligned with the green or hole and used as an aid in swinging the club face in the correct direction."
            },
            "venue": {
                "fragments": [],
                "text": "SIAM J. Comput."
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52011509"
                        ],
                        "name": "Spiegelhalter Dj",
                        "slug": "Spiegelhalter-Dj",
                        "structuredName": {
                            "firstName": "Spiegelhalter",
                            "lastName": "Dj",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Spiegelhalter Dj"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 77424532,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "b65a7277195ee5dc1b59922b33c8d2573b15eb42",
            "isKey": false,
            "numCitedBy": 50,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Statistical-methodology-for-evaluating-symptoms.-Dj",
            "title": {
                "fragments": [],
                "text": "Statistical methodology for evaluating gastrointestinal symptoms."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48616434"
                        ],
                        "name": "D. Spiegelhalter",
                        "slug": "D.-Spiegelhalter",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Spiegelhalter",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Spiegelhalter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401542432"
                        ],
                        "name": "R. Knill-Jones",
                        "slug": "R.-Knill-Jones",
                        "structuredName": {
                            "firstName": "Robin",
                            "lastName": "Knill-Jones",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Knill-Jones"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 67474556,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "8a46454717a596e7ffee369e8f806b7bfbcbef6c",
            "isKey": false,
            "numCitedBy": 368,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Statistical-and-Knowledge\u2010Based-Approaches-to-with-Spiegelhalter-Knill-Jones",
            "title": {
                "fragments": [],
                "text": "Statistical and Knowledge\u2010Based Approaches to Clinical Decision\u2010Support Systems, with an Application in Gastroenterology"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48616434"
                        ],
                        "name": "D. Spiegelhalter",
                        "slug": "D.-Spiegelhalter",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Spiegelhalter",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Spiegelhalter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 57948699,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6cb6c5548f9dc097ff62fd921802eccf2371adf0",
            "isKey": false,
            "numCitedBy": 122,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-statistical-view-of-uncertainty-in-expert-systems-Spiegelhalter",
            "title": {
                "fragments": [],
                "text": "A statistical view of uncertainty in expert systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 38301295,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a46c3d804e45c161427c43df0c206ef7b5e56d6c",
            "isKey": false,
            "numCitedBy": 70,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "How-to-Do-with-Probabilities-What-People-Say-You-Pearl",
            "title": {
                "fragments": [],
                "text": "How to Do with Probabilities What People Say You Can't"
            },
            "venue": {
                "fragments": [],
                "text": "CAIA"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145870717"
                        ],
                        "name": "H. Wold",
                        "slug": "H.-Wold",
                        "structuredName": {
                            "firstName": "Herman",
                            "lastName": "Wold",
                            "middleNames": [
                                "O.",
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wold"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 41105071,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "6ffcec31b0a6e7e030e2b39b2d35cc9eac790f25",
            "isKey": false,
            "numCitedBy": 174,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Causality-and-Econometrics-Wold",
            "title": {
                "fragments": [],
                "text": "Causality and Econometrics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1954
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35106875"
                        ],
                        "name": "R. Duda",
                        "slug": "R.-Duda",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Duda",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Duda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108177"
                        ],
                        "name": "P. Hart",
                        "slug": "P.-Hart",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144497046"
                        ],
                        "name": "N. Nilsson",
                        "slug": "N.-Nilsson",
                        "structuredName": {
                            "firstName": "Nils",
                            "lastName": "Nilsson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Nilsson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207171419,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a47176e0ec512a450c2aed106700fdb3b5f653ca",
            "isKey": false,
            "numCitedBy": 370,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "The general problem of drawing inferences from uncertain or incomplete evidence has invited a variety of technical approaches, some mathematically rigorous and some largely informal and intuitive. Most current inference systems in artificial intelligence have emphasized intuitive methods, because the absence of adequate statistical samples forces a reliance on the subjective judgment of human experts. We describe in this paper a subjective Bayesian inference method that realizes some of the advantages of both formal and informal approaches. Of particular interest are the modifications needed to deal with the inconsistencies usually found in collections of subjective statements."
            },
            "slug": "Subjective-bayesian-methods-for-rule-based-systems-Duda-Hart",
            "title": {
                "fragments": [],
                "text": "Subjective bayesian methods for rule-based inference systems"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A subjective Bayesian inference method that realizes some of the advantages of both formal and informal approaches, and modifications needed to deal with the inconsistencies usually found in collections of subjective statements are described."
            },
            "venue": {
                "fragments": [],
                "text": "AFIPS '76"
            },
            "year": 1976
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 30,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Probabilistic-Reasoning-in-Predictive-Expert-Spiegelhalter/4e9c168f6d744174efad3764e03522fe55be5ada?sort=total-citations"
}