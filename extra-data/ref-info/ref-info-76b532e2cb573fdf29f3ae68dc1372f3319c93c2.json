{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32250556"
                        ],
                        "name": "D. H. Cooper",
                        "slug": "D.-H.-Cooper",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Cooper",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. H. Cooper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47581828"
                        ],
                        "name": "J. Graham",
                        "slug": "J.-Graham",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Graham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Graham"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 73
                            }
                        ],
                        "text": "Although an AAM search is slightly slower than Active Shape Model search [2], the procedure tends to be be more robust than ASM search alone, since all the image evidence is used."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 79
                            }
                        ],
                        "text": "Poggio et al. [6], [9] use an optical flow algorithm to match shape and texture models iteratively, and Vetter [14] uses a general purpose optimization method to match photorealistic human face models to images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15242659,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f731b6745d829241941307c3ebf163e90e200318",
            "isKey": false,
            "numCitedBy": 7909,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "!, Model-based vision is firmly established as a robust approach to recognizing and locating known rigid objects in the presence of noise, clutter, and occlusion. It is more problematic to apply modelbased methods to images of objects whose appearance can vary, though a number of approaches based on the use of flexible templates have been proposed. The problem with existing methods is that they sacrifice model specificity in order to accommodate variability, thereby compromising robustness during image interpretation. We argue that a model should only be able to deform in ways characteristic of the class of objects it represents. We describe a method for building models by learning patterns of variability from a training set of correctly annotated images. These models can be used for image search in an iterative refinement algorithm analogous to that employed by Active Contour Models (Snakes). The key difference is that our Active Shape Models can only deform to fit the data in ways consistent with the training set. We show several practical examples where we have built such models and used them to locate partially occluded objects in noisy, cluttered images. Q 199s A&& prrss, IN."
            },
            "slug": "Active-Shape-Models-Their-Training-and-Application-Cootes-Taylor",
            "title": {
                "fragments": [],
                "text": "Active Shape Models-Their Training and Application"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work describes a method for building models by learning patterns of variability from a training set of correctly annotated images that can be used for image search in an iterative refinement algorithm analogous to that employed by Active Contour Models (Snakes)."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50564384"
                        ],
                        "name": "G. Edwards",
                        "slug": "G.-Edwards",
                        "structuredName": {
                            "firstName": "Gareth",
                            "lastName": "Edwards",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Edwards"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1830709"
                        ],
                        "name": "A. Lanitis",
                        "slug": "A.-Lanitis",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Lanitis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lanitis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u00d0Appearance models, deformable templates, model matching.\n\u00e6"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 108
                            }
                        ],
                        "text": "Active Appearance Models\nTimothy F. Cootes, Gareth J. Edwards, and Christopher J. Taylor\nAbstract\u00d0We describe a new method of matching statistical models of appearance to images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 129
                            }
                        ],
                        "text": "One motivation is to achieve robust segmentation by using the model to constrain solutions to be valid examples of the class of images modeled."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 41
                            }
                        ],
                        "text": "Several authors have described methods for matching deformable models of shape and appearance to novel images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 807316,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "14e013ca6a01c63e4fa4b4339d00463d0d11a617",
            "isKey": false,
            "numCitedBy": 145,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Statistical-models-of-face-images-improving-Edwards-Lanitis",
            "title": {
                "fragments": [],
                "text": "Statistical models of face images - improving specificity"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50564384"
                        ],
                        "name": "G. Edwards",
                        "slug": "G.-Edwards",
                        "structuredName": {
                            "firstName": "Gareth",
                            "lastName": "Edwards",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Edwards"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11269423,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bd8eeaee7b622e0e2a6b7218df5236407c45091f",
            "isKey": false,
            "numCitedBy": 583,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "We demonstrate a fast, robust method of interpreting face images using an Active Appearance Model (AAM). An AAM contains a statistical model of shape and grey level appearance which can generalise to almost any face. Matching to an image involves finding model parameters which minimise the difference between the image and a synthesised face. We observe that displacing each model parameter from the correct value induces a particular pattern in the residuals. In a training phase, the AAM learns a linear model of the correlation between parameter displacements and the induced residuals. During search it measures the residuals and uses this model to correct the current parameters, leading to a better fit. A good overall match is obtained in a few iterations, even from poor starting estimates. We describe the technique in detail and show it matching to new face images."
            },
            "slug": "Interpreting-face-images-using-active-appearance-Edwards-Taylor",
            "title": {
                "fragments": [],
                "text": "Interpreting face images using active appearance models"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A fast, robust method of interpreting face images using an Active Appearance Model (AAM), which contains a statistical model of shape and grey level appearance which can generalise to almost any face."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Third IEEE International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749590"
                        ],
                        "name": "S. Sclaroff",
                        "slug": "S.-Sclaroff",
                        "structuredName": {
                            "firstName": "Stan",
                            "lastName": "Sclaroff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sclaroff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2900092"
                        ],
                        "name": "J. Isidoro",
                        "slug": "J.-Isidoro",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Isidoro",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Isidoro"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2072105,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "bab1ba30c3385f460c62588e6f3674f68b3528f9",
            "isKey": false,
            "numCitedBy": 194,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "A new region-based approach to nonrigid motion tracking is described. Shape is defined in terms of a deformable triangular mesh that captures object shape plus a color texture map that captures object appearance. Photometric variations are also modeled. Nonrigid shape registration and motion tracking are achieved by posing the problem as an energy-based, robust minimization procedure. The approach provides robustness to occlusions, wrinkles, shadows, and specular highlights. The formulation is tailored to rake advantage of texture mapping hardware available in many workstations, PCs, and game consoles. This enables nonrigid tracking at speeds approaching video rate."
            },
            "slug": "Active-blobs-Sclaroff-Isidoro",
            "title": {
                "fragments": [],
                "text": "Active blobs"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "A new region-based approach to nonrigid motion tracking that provides robustness to occlusions, wrinkles, shadows, and specular highlights and is tailored to rake advantage of texture mapping hardware available in many workstations, PCs, and game consoles."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9242811,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e49ad8354bdd2fd6e8babd348df9e9a5b30bf3a6",
            "isKey": false,
            "numCitedBy": 461,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an unsupervised technique for visual learning which is based on density estimation in high-dimensional spaces using an eigenspace decomposition. Two types of density estimates are derived for modeling the training data: a multivariate Gaussian (for a unimodal distributions) and a multivariate Mixture-of-Gaussians model (for multimodal distributions). These probability densities are then used to formulate a maximum-likelihood estimation framework for visual search and target detection for automatic object recognition. This learning technique is tested in experiments with modeling and subsequent detection of human faces and non-rigid objects such as hands.<<ETX>>"
            },
            "slug": "Probabilistic-visual-learning-for-object-detection-Moghaddam-Pentland",
            "title": {
                "fragments": [],
                "text": "Probabilistic visual learning for object detection"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "An unsupervised technique for visual learning which is based on density estimation in high-dimensional spaces using an eigenspace decomposition and a multivariate Mixture-of-Gaussians model is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50564384"
                        ],
                        "name": "G. Edwards",
                        "slug": "G.-Edwards",
                        "structuredName": {
                            "firstName": "Gareth",
                            "lastName": "Edwards",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Edwards"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2573397,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "248fb34a10dcd3cfb7e606692b920e4bbca0ea6a",
            "isKey": false,
            "numCitedBy": 455,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new framework for interpreting face images and image sequences using an Active Appearance Model (AAM). The AAM contains a statistical, photo-realistic model of the shape and grey-level appearance of faces. This paper demonstrates the use of the AAM's efficient iterative matching scheme for image interpretation. We use the AAM as a basis for face recognition, obtain good results for difficult images. We show how the AAM framework allows identity information to be decoupled from other variation, allowing evidence of identity to be integrated over a sequence. The AAM approach makes optimal use of the evidence from either a single image or image sequence. Since we derive a complete description of a given image our method can be used as the basis for a range of face image interpretation tasks."
            },
            "slug": "Face-Recognition-Using-Active-Appearance-Models-Edwards-Cootes",
            "title": {
                "fragments": [],
                "text": "Face Recognition Using Active Appearance Models"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper demonstrates the use of the AAM's efficient iterative matching scheme for image interpretation, which allows identity information to be decoupled from other variation, allowing evidence of identity to be integrated over a sequence."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Cootes et al [5] describe a 3D model of the grey-level surface, allowing full synthesis of shape and appearance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12226703,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d2f8191d69e5e7093004bd09301daf759f7b09ec",
            "isKey": false,
            "numCitedBy": 46,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a new approach to modelling the appearance of structures in grey-level images. We assume that both the shape and grey-levels of the structures can vary from one image to another, and that a number of example images are available for training. A 2-D image can be thought of as a surface in 3 dimensions, with the third dimension being the grey-level intensity at each image point. We can represent the shape of this surface by planting landmark points across it. By examining the way such collections of points vary across different examples we can build a statistical model of the shape, which can be used to generate new examples, and to locate examples of the modelled structure in new images. We show examples of these composite appearance models and demonstrate their use in image interpretation."
            },
            "slug": "Modelling-Object-Appearance-using-The-Grey-Level-Cootes-Taylor",
            "title": {
                "fragments": [],
                "text": "Modelling Object Appearance using The Grey-Level Surface"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "A new approach to modelling the appearance of structures in grey-level images, which assumes that both the shape and grey-levels of the structures can vary from one image to another, and that a number of example images are available for training."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145319478"
                        ],
                        "name": "Michael J. Jones",
                        "slug": "Michael-J.-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Poggio and co-workers [10] [12] synthesise new views of an object from a set of example views."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Direct optimisation using standard methods over such a high dimensional space is possible but slow [12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10299793,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f96248048d349fa9a24277f266a8b5033bae7b09",
            "isKey": false,
            "numCitedBy": 149,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a flexible model for representing images of objects of a certain class, known a priori, such as faces, and introduce a new algorithm for matching it to a novel image and thereby performing image analysis. We call this model a multidimensional morphable model or just a, morphable model. The morphable model is learned from example images (called prototypes) of objects of a class. In this paper we introduce an effective stochastic gradient descent algorithm that automaticaIly matches a model to a novel image by finding the parameters that minimize the error between the image generated by the model and the novel image. Two examples demonstrate the robustness and the broad range of applicability of the matching algorithm and the underlying morphable model. Our approach can provide novel solutions to several vision tasks, including the computation of image correspondence, object verification, image synthesis and image compression."
            },
            "slug": "Multidimensional-morphable-models-Jones-Poggio",
            "title": {
                "fragments": [],
                "text": "Multidimensional morphable models"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "An effective stochastic gradient descent algorithm is introduced that automaticaIly matches a model to a novel image by finding the parameters that minimize the error between the image generated by the model and the novel image."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1776507"
                        ],
                        "name": "Michael Gleicher",
                        "slug": "Michael-Gleicher",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Gleicher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Gleicher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u00d0Appearance models, deformable templates, model matching.\n\u00e6"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 71
                            }
                        ],
                        "text": "In order to interpret novel images, an efficient method of finding the best match between model and image is required."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1628532,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "42f53ab8d6206dd475be459ccd3fd6809b3bfdd8",
            "isKey": false,
            "numCitedBy": 105,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Current methods for registering image regions perform well for simple transformations or large image regions. The author presents a new method that is better able to handle small image regions as they deform with nonlinear transformations. He introduces difference decomposition, a novel approach to solving the registration problem. The method is a generalization of previous methods and can better handle nonlinear transforms. Although the methods are general, he focuses on projective transformations and introduces piecewise-projective transformations for modeling the motions of non-planar objects. He concludes with examples from a prototype implementation."
            },
            "slug": "Projective-registration-with-difference-Gleicher",
            "title": {
                "fragments": [],
                "text": "Projective registration with difference decomposition"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "The author presents a new method that is better able to handle small image regions as they deform with nonlinear transformations and introduces difference decomposition, a novel approach to solving the registration problem."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50564384"
                        ],
                        "name": "G. Edwards",
                        "slug": "G.-Edwards",
                        "structuredName": {
                            "firstName": "Gareth",
                            "lastName": "Edwards",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Edwards"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Model-based approaches to the interpretation of images of variable objects axe now attracting considerable interest [6][8][10] [11][14] [16][19][20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Edwards et al [8] for faces), they typically involve a large number of parameters (50-100) in order to deal with variability in the target objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The approach follows that described in Edwards et al [8] but includes extra normalisation and weighting steps."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5497564,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "98f4a96d0bb9112fffceb108cbbab5bf80407f84",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of robust face identification in the presence of pose, lighting, and expression variation. Previous approaches to the problem have assumed similar models of variation for each individual, estimated from pooled training data. We describe a method of updating a first order global estimate of identity by learning the class-specific correlation between the estimate and the residual variation during a sequence. This is integrated with an optimal tracking scheme, in which identity variation is decoupled from pose, lighting and expression variation. The method results in robust tracking and a more stable estimate of facial identity under changing conditions."
            },
            "slug": "Learning-to-identify-and-track-faces-in-image-Edwards-Taylor",
            "title": {
                "fragments": [],
                "text": "Learning to identify and track faces in image sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A method of updating a first order global estimate of identity by learning the class-specific correlation between the estimate and the residual variation during a sequence is described, integrated with an optimal tracking scheme, in which identity variation is decoupled from pose, lighting and expression variation."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678633"
                        ],
                        "name": "Gregory Hager",
                        "slug": "Gregory-Hager",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Hager",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gregory Hager"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767767"
                        ],
                        "name": "P. Belhumeur",
                        "slug": "P.-Belhumeur",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Belhumeur",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Belhumeur"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u00d0Appearance models, deformable templates, model matching.\n\u00e6"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 146
                            }
                        ],
                        "text": "We have shown previously [11], [3] that a statistical model of appearance can be matched to an image in two steps: First, an Active Shape Model is matched to boundary features in the image, then a separate eigenface model is used to reconstruct the texture (in the graphics sense) in a\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11616840,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b844126725ab2dad5bf69dc11d58e465742694a",
            "isKey": false,
            "numCitedBy": 1309,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "As an object moves through the field of view of a camera, the images of the object may change dramatically. This is not simply due to the translation of the object across the image plane; complications arise due to the fact that the object undergoes changes in pose relative to the viewing camera, in illumination relative to light sources, and may even become partially or fully occluded. We develop an efficient general framework for object tracking, which addresses each of these complications. We first develop a computationally efficient method for handling the geometric distortions produced by changes in pose. We then combine geometry and illumination into an algorithm that tracks large image regions using no more computation than would be required to track with no accommodation for illumination changes. Finally, we augment these methods with techniques from robust statistics and treat occluded regions on the object as statistical outliers. Experimental results are given to demonstrate the effectiveness of our methods."
            },
            "slug": "Efficient-Region-Tracking-With-Parametric-Models-of-Hager-Belhumeur",
            "title": {
                "fragments": [],
                "text": "Efficient Region Tracking With Parametric Models of Geometry and Illumination"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work develops a computationally efficient method for handling the geometric distortions produced by changes in pose and combines geometry and illumination into an algorithm that tracks large image regions using no more computation than would be required to track with no accommodation for illumination changes."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47529803"
                        ],
                        "name": "G. Page",
                        "slug": "G.-Page",
                        "structuredName": {
                            "firstName": "Gary",
                            "lastName": "Page",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Page"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143684467"
                        ],
                        "name": "C. B. Jackson",
                        "slug": "C.-B.-Jackson",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Jackson",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. B. Jackson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16195340,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "773248e0ef6c6a190044c0e84c793512cc8dd23d",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract This paper presents a new method for modelling and locating objects in images for applications such as Printed Circuit Board (PCB) inspection. Objects of interest are assumed to exhibit little variation in size or shape from one example to the next, but may vary considerably in grey-level appearance. Simple correlation based approaches perform poorly on such examples. To deal with variation we build statistical models of the grey levels across the structure in a set of training examples. A multi-resolution search technique is used to locate the best match to the model in an area of a new image to sub-pixel accuracy. A fit measure with predictable statistical properties can then be used to determine the probability that best match is a valid example of the model. We describe a \u2018bootstrap\u2019 approach to training and a method of automatically refining the final model to improve its performance. We demonstrate the method on PCB inspection, showing the approach is robust enough for use in a real production environment."
            },
            "slug": "Statistical-Grey-Level-Models-for-Object-Location-Cootes-Page",
            "title": {
                "fragments": [],
                "text": "Statistical Grey-Level Models for Object Location and Identification"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A \u2018bootstrap\u2019 approach to training and a method of automatically refining the final model to improve its performance are described, showing the approach is robust enough for use in a real production environment."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1983127"
                        ],
                        "name": "C. Nastar",
                        "slug": "C.-Nastar",
                        "structuredName": {
                            "firstName": "Chahab",
                            "lastName": "Nastar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Nastar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 125
                            }
                        ],
                        "text": "THE \u00aainterpretation through synthesis\u00ba approach has received considerable attention over the past few years [3], [6], [11], [14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8155583,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8104cdea0329f989d27218c2601681bc7535684c",
            "isKey": false,
            "numCitedBy": 90,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a novel approach for image matching based on deformable intensity surfaces. In this approach, the intensity surface of the image is modeled as a deformable 3D mesh in the (x,y,I(x,y)) space. Each surface point has 3 degrees of freedom, thus capturing fine surface changes. A set of representative deformations within a class of objects (e.g. faces) are statistically learned through a Principal Components Analysis, thus providing a priori knowledge about object-specific deformations. We demonstrate the power of the approach by examples such as image matching and interpolation of missing data. Moreover this approach dramatically reduces the computational cost of solving the governing equation for the physically based system by approximately three orders of magnitude."
            },
            "slug": "Generalized-Image-Matching:-Statistical-Learning-of-Nastar-Moghaddam",
            "title": {
                "fragments": [],
                "text": "Generalized Image Matching: Statistical Learning of Physically-Based Deformations"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "A novel approach for image matching based on deformable intensity surfaces that dramatically reduces the computational cost of solving the governing equation for the physically based system by approximately three orders of magnitude."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1932050"
                        ],
                        "name": "T. Ezzat",
                        "slug": "T.-Ezzat",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Ezzat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Ezzat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 113
                            }
                        ],
                        "text": "Active Appearance Models\nTimothy F. Cootes, Gareth J. Edwards, and Christopher J. Taylor\nAbstract\u00d0We describe a new method of matching statistical models of appearance to images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 135
                            }
                        ],
                        "text": "A suitable model also provides a basis for a broad range of applications by coding the appearance of a given image in terms of a compact set of parameters that are useful for higher-level interpretation of the scene."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7571405,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "359b2b5c47d023f7b31261262f52639934d3b2ca",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe image-based modeling techniques that make possible the creation of photo-realistic computer models of real human faces. The image-based model is built using example views of the face, bypassing the need for any three-dimensional computer graphics models. A learning network is trained to associate each of the example images with a set of pose and expression parameters. For a novel set of parameters, the network synthesizes a novel, intermediate view using a morphing approach. This image-based synthesis paradigm can adequately model both rigid and non-rigid facial movements. We also describe an analysis-by-synthesis algorithm, which is capable of extracting a set of high-level parameters from an image sequence involving facial movement using embedded image-based models. The parameters of the models are perturbed in a local and independent manner for each image until a correspondence-based error metric is minimized. A small sample of experimental results is presented."
            },
            "slug": "Facial-analysis-and-synthesis-using-image-based-Ezzat-Poggio",
            "title": {
                "fragments": [],
                "text": "Facial analysis and synthesis using image-based models"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "An analysis-by-synthesis algorithm is described, which is capable of extracting a set of high-level parameters from an image sequence involving facial movement using embedded image-based models."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Second International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1830709"
                        ],
                        "name": "A. Lanitis",
                        "slug": "A.-Lanitis",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Lanitis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lanitis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u00d0Appearance models, deformable templates, model matching.\n\u00e6"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 118
                            }
                        ],
                        "text": "Active Appearance Models\nTimothy F. Cootes, Gareth J. Edwards, and Christopher J. Taylor\nAbstract\u00d0We describe a new method of matching statistical models of appearance to images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 105
                            }
                        ],
                        "text": "One motivation is to achieve robust segmentation by using the model to constrain solutions to be valid examples of the class of images modeled."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 699530,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b7e722de154fa30da9d534a935ed7c5dc233ff9",
            "isKey": false,
            "numCitedBy": 724,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Face images are difficult to interpret because they are highly variable. Sources of variability include individual appearance, 3D pose, facial expression, and lighting. We describe a compact parametrized model of facial appearance which takes into account all these sources of variability. The model represents both shape and gray-level appearance, and is created by performing a statistical analysis over a training set of face images. A robust multiresolution search algorithm is used to fit the model to faces in new images. This allows the main facial features to be located, and a set of shape, and gray-level appearance parameters to be recovered. A good approximation to a given face can be reconstructed using less than 100 of these parameters. This representation can be used for tasks such as image coding, person identification, 3D pose recovery, gender recognition, and expression recognition. Experimental results are presented for a database of 690 face images obtained under widely varying conditions of 3D pose, lighting, and facial expression. The system performs well on all the tasks listed above."
            },
            "slug": "Automatic-Interpretation-and-Coding-of-Face-Images-Lanitis-Taylor",
            "title": {
                "fragments": [],
                "text": "Automatic Interpretation and Coding of Face Images Using Flexible Models"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A compact parametrized model of facial appearance which takes into account all sources of variability and can be used for tasks such as image coding, person identification, 3D pose recovery, gender recognition, and expression recognition is described."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144517651"
                        ],
                        "name": "T. Vetter",
                        "slug": "T.-Vetter",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Vetter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Vetter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u00d0Appearance models, deformable templates, model matching.\n\u00e6"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "Suitable methods of modeling photo-realistic appearance have been described previously, e.g., Edwards et al. [3], Jones and Poggio [9], or Vetter [14])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 124
                            }
                        ],
                        "text": "Active Appearance Models\nTimothy F. Cootes, Gareth J. Edwards, and Christopher J. Taylor\nAbstract\u00d0We describe a new method of matching statistical models of appearance to images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 37417042,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9556a56653cb0b851de05a7f70127b4456009889",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "A new technique is described for synthesizing images of faces from new viewpoints, when only a single 2D image from a known viewpoint is available. A novel 2D image of a face can be computed without knowledge about the 3D structure of the head. The technique draws on prior knowledge of faces based on example images of other faces seen in different poses and on a single generic 3D model of a human head. The example images are used to learn a pose-invariant shape and texture description of a new face. The 3D model is used to solve the correspondence problem between images showing faces in different poses. Examples of synthetic \"rotations\" over 24/spl deg/ based on a training set of 100 faces are shown."
            },
            "slug": "Learning-novel-views-to-a-single-face-image-Vetter",
            "title": {
                "fragments": [],
                "text": "Learning novel views to a single face image"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A new technique is described for synthesizing images of faces from new viewpoints, when only a single 2D image from a known viewpoint is available, and the 3D model is used to solve the correspondence problem between images showing faces in different poses."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Second International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1983127"
                        ],
                        "name": "C. Nastar",
                        "slug": "C.-Nastar",
                        "structuredName": {
                            "firstName": "Chahab",
                            "lastName": "Nastar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Nastar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 34880986,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7473a6934710fbf9ac9aafd04a407c32770e602b",
            "isKey": false,
            "numCitedBy": 73,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a novel technique for matching and recognition based on deformable intensity surfaces which incorporates both the shape (x,y) and the texture (I(x,y)) components of a 2D image. Specifically, the intensity surface is modeled as a deformable 3D mesh in (x,y,I(x,y)) space which obeys Lagrangian dynamics. Using an efficient technique for matching two surfaces (in terms of the analytic modes of vibration), we can obtain a dense correspondence field (or 3D warp) between two images. Furthermore, we use explicit statistical learning of the class of valid deformations in order to provide a priori knowledge about object-specific deformations. The resulting formulation leads to a compact representation based on the physically-based modes of deformation as well as the statistical modes of variation observed in actual training data. We demonstrate the power of this approach with experiments utilizing image matching, interpolation of missing data, and image retrieval in a large face database."
            },
            "slug": "Flexible-Images:-Matching-and-Recognition-Using-Nastar-Moghaddam",
            "title": {
                "fragments": [],
                "text": "Flexible Images: Matching and Recognition Using Learned Deformations"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A novel technique for matching and recognition based on deformable intensity surfaces which incorporates both the shape and the texture of a 2D image and uses explicit statistical learning of the class of valid deformations in order to provide a priori knowledge about object-specific deformations."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9127836"
                        ],
                        "name": "M. L. Cascia",
                        "slug": "M.-L.-Cascia",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Cascia",
                            "middleNames": [
                                "La"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. L. Cascia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749590"
                        ],
                        "name": "S. Sclaroff",
                        "slug": "S.-Sclaroff",
                        "structuredName": {
                            "firstName": "Stan",
                            "lastName": "Sclaroff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sclaroff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720747"
                        ],
                        "name": "V. Athitsos",
                        "slug": "V.-Athitsos",
                        "structuredName": {
                            "firstName": "Vassilis",
                            "lastName": "Athitsos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Athitsos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 142
                            }
                        ],
                        "text": "This approach is not, however, guaranteed to give an optimal fit of the appearance model to the image because small errors in the match of the shape model can result in a shape-normalized texture map that cannot be reconstructed correctly using the eigenface model."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5874123,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "436ad5af721c56b714b13d68a45ab8898d75514f",
            "isKey": false,
            "numCitedBy": 601,
            "numCiting": 92,
            "paperAbstract": {
                "fragments": [],
                "text": "An improved technique for 3D head tracking under varying illumination conditions is proposed. The head is modeled as a texture mapped cylinder. Tracking is formulated as an image registration problem in the cylinder's texture map image. The resulting dynamic texture map provides a stabilized view of the face that can be used as input to many existing 2D techniques for face recognition, facial expressions analysis, lip reading, and eye tracking. To solve the registration problem in the presence of lighting variation and head motion, the residual error of registration is modeled as a linear combination of texture warping templates and orthogonal illumination templates. Fast and stable on-line tracking is achieved via regularized, weighted least squares minimization of the registration error. The regularization term tends to limit potential ambiguities that arise in the warping and illumination templates. It enables stable tracking over extended sequences. Tracking does not require a precise initial fit of the model; the system is initialized automatically using a simple 2D face detector. The only assumption is that the target is facing the camera in the first frame of the sequence. The formulation is tailored to take advantage of texture mapping hardware available in many workstations, PC's, and game consoles. The non-optimized implementation runs at about 15 frames per second on a SGI O2 graphic workstation. Extensive experiments evaluating the effectiveness of the formulation are reported. The sensitivity of the technique to illumination, regularization parameters, errors in the initial positioning and internal camera parameters are analyzed. Examples and applications of tracking are reported."
            },
            "slug": "Fast,-Reliable-Head-Tracking-under-Varying-An-Based-Cascia-Sclaroff",
            "title": {
                "fragments": [],
                "text": "Fast, Reliable Head Tracking under Varying Illumination: An Approach Based on Registration of Texture-Mapped 3D Models"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "An improved technique for 3D head tracking under varying illumination conditions is proposed, modeled as a texture mapped cylinder, which provides a stabilized view of the face that can be used as input to many existing 2D techniques for face recognition, facial expressions analysis, lip reading, and eye tracking."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35146156"
                        ],
                        "name": "M. Lades",
                        "slug": "M.-Lades",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Lades",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lades"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3189439"
                        ],
                        "name": "J. Vorbr\u00fcggen",
                        "slug": "J.-Vorbr\u00fcggen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Vorbr\u00fcggen",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Vorbr\u00fcggen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682548"
                        ],
                        "name": "J. Buhmann",
                        "slug": "J.-Buhmann",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Buhmann",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Buhmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075388397"
                        ],
                        "name": "J. Lange",
                        "slug": "J.-Lange",
                        "structuredName": {
                            "firstName": "J\u00f6rg",
                            "lastName": "Lange",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lange"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3038814"
                        ],
                        "name": "R. W\u00fcrtz",
                        "slug": "R.-W\u00fcrtz",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "W\u00fcrtz",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. W\u00fcrtz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34993891"
                        ],
                        "name": "W. Konen",
                        "slug": "W.-Konen",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Konen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Konen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 12
                            }
                        ],
                        "text": "Lades at al [13] model shape and some grey level information using Gabor jets."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1266405,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4fb52984078d75ec5655962dc94dc7848182286b",
            "isKey": false,
            "numCitedBy": 2069,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "An object recognition system based on the dynamic link architecture, an extension to classical artificial neural networks (ANNs), is presented. The dynamic link architecture exploits correlations in the fine-scale temporal structure of cellular signals to group neurons dynamically into higher-order entities. These entities represent a rich structure and can code for high-level objects. To demonstrate the capabilities of the dynamic link architecture, a program was implemented that can recognize human faces and other objects from video images. Memorized objects are represented by sparse graphs, whose vertices are labeled by a multiresolution description in terms of a local power spectrum, and whose edges are labeled by geometrical distance vectors. Object recognition can be formulated as elastic graph matching, which is performed here by stochastic optimization of a matching cost function. The implementation on a transputer network achieved recognition of human faces and office objects from gray-level camera images. The performance of the program is evaluated by a statistical analysis of recognition results from a portrait gallery comprising images of 87 persons. >"
            },
            "slug": "Distortion-Invariant-Object-Recognition-in-the-Link-Lades-Vorbr\u00fcggen",
            "title": {
                "fragments": [],
                "text": "Distortion Invariant Object Recognition in the Dynamic Link Architecture"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "An object recognition system based on the dynamic link architecture, an extension to classical artificial neural networks (ANNs), is presented and the implementation on a transputer network achieved recognition of human faces and office objects from gray-level camera images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Computers"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1396777509"
                        ],
                        "name": "M. Covell",
                        "slug": "M.-Covell",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Covell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Covell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9057102,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "40895071441aa527c4ac0c39e6e42c35df30fb10",
            "isKey": false,
            "numCitedBy": 50,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Eigen-points estimates the image-plane locations of fiduciary points on an object. By estimating multiple locations simultaneously, eigen-points exploits the interdependence between these locations. This is done by associating neighboring, inter-dependent control-points with a model of the local appearance. The model of local appearance is used to find the feature in new unlabeled images. Control-point locations are then estimated from the appearance of this feature in the unlabeled image. The estimation is done using an affine manifold model of the coupling between the local appearance and the local shape. Eigen-points uses models aimed specifically at recovering shape from image appearance. The estimation equations are solved non-iteratively, in a way that accounts for noise in the training data and the unlabeled images and that accounts for uncertainty in the distribution and dependencies within these noise sources."
            },
            "slug": "Eigen-points:-control-point-location-using-analyses-Covell",
            "title": {
                "fragments": [],
                "text": "Eigen-points: control-point location using principal component analyses"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "Eigen-points estimates the image-plane locations of fiduciary points on an object by associating neighboring, inter-dependent control-points with a model of the local appearance, aimed specifically at recovering shape from image appearance."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Second International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700330"
                        ],
                        "name": "L. Staib",
                        "slug": "L.-Staib",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Staib",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Staib"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145947161"
                        ],
                        "name": "J. Duncan",
                        "slug": "J.-Duncan",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Duncan",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Duncan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9209299,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8fb0eb1e3733014ed7124de26f0ea498cab304c6",
            "isKey": false,
            "numCitedBy": 921,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "Segmentation using boundary finding is enhanced both by considering the boundary as a whole and by using model-based global shape information. The authors apply flexible constraints, in the form of a probabilistic deformable model, to the problem of segmenting natural 2-D objects whose diversity and irregularity of shape make them poorly represented in terms of fixed features or form. The parametric model is based on the elliptic Fourier decomposition of the boundary. Probability distributions on the parameters of the representation bias the model to a particular overall shape while allowing for deformations. Boundary finding is formulated as an optimization problem using a maximum a posteriori objective function. Results of the method applied to real and synthetic images are presented, including an evaluation of the dependence of the method on prior information and image quality. >"
            },
            "slug": "Boundary-Finding-with-Parametrically-Deformable-Staib-Duncan",
            "title": {
                "fragments": [],
                "text": "Boundary Finding with Parametrically Deformable Models"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The authors apply flexible constraints, in the form of a probabilistic deformable model, to the problem of segmenting natural 2-D objects whose diversity and irregularity of shape make them poorly represented in terms of fixed features or form."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784213"
                        ],
                        "name": "R. Bajcsy",
                        "slug": "R.-Bajcsy",
                        "structuredName": {
                            "firstName": "Ruzena",
                            "lastName": "Bajcsy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bajcsy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802545"
                        ],
                        "name": "S. Kovacic",
                        "slug": "S.-Kovacic",
                        "structuredName": {
                            "firstName": "Stanislav",
                            "lastName": "Kovacic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kovacic"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Bajcsy and Kovacic [1] describe a volume model (of the brain) that also deforms elastically to generate new examples."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 19718946,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "36c9356db20ab4eace62d86e0a576fa6382d84b9",
            "isKey": false,
            "numCitedBy": 1217,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Multiresolution-elastic-matching-Bajcsy-Kovacic",
            "title": {
                "fragments": [],
                "text": "Multiresolution elastic matching"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Graph. Image Process."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144097660"
                        ],
                        "name": "M. Turk",
                        "slug": "M.-Turk",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Turk",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Turk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Model-based approaches to the interpretation of images of variable objects axe now attracting considerable interest [6][8][10] [11][14] [16][19][20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Turk and Pentland [20] use principal component analysis to describe face images in terms of a set of basis functions, or 'eigenfaces'."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 26127529,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6f1dfcc44277d4cfd8507284d994c9283dc3a2f",
            "isKey": false,
            "numCitedBy": 14954,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We have developed a near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals. The computational approach taken in this system is motivated by both physiology and information theory, as well as by the practical requirements of near-real-time performance and accuracy. Our approach treats the face recognition problem as an intrinsically two-dimensional (2-D) recognition problem rather than requiring recovery of three-dimensional geometry, taking advantage of the fact that faces are normally upright and thus may be described by a small set of 2-D characteristic views. The system functions by projecting face images onto a feature space that spans the significant variations among known face images. The significant features are known as \"eigenfaces,\" because they are the eigenvectors (principal components) of the set of faces; they do not necessarily correspond to features such as eyes, ears, and noses. The projection operation characterizes an individual face by a weighted sum of the eigenface features, and so to recognize a particular face it is necessary only to compare these weights to those of known individuals. Some particular advantages of our approach are that it provides for the ability to learn and later recognize new faces in an unsupervised manner, and that it is easy to implement using a neural network architecture."
            },
            "slug": "Eigenfaces-for-Recognition-Turk-Pentland",
            "title": {
                "fragments": [],
                "text": "Eigenfaces for Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals, and that is easy to implement using a neural network architecture."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Cognitive Neuroscience"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 108
                            }
                        ],
                        "text": "THE ainterpretation through synthesiso approach has received considerable attention over the past few years [3], [6], [11], [14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 109
                            }
                        ],
                        "text": "Finally, the correlations between shape and texture are learned to generate a combined appearance model (see [3] for details)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[3], our statistical appearance models are generated by combining a model of shape variation with a model of texture variation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 31
                            }
                        ],
                        "text": "We have shown previously [11], [3] that a statistical model of"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[3] use a boundary finding algorithm (an aActive Shape Modelo) to find the best shape, then use this to match a model of image texture."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aStatistical Models of Face Images\u00d0Improving Specificity,o"
            },
            "venue": {
                "fragments": [],
                "text": "Image and Vision Computing,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 139
                            }
                        ],
                        "text": "Suitable methods of modeling photo-realistic appearance have been described previously, e.g., Edwards et al. [3], Jones and Poggio [9], or Vetter [14])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 97
                            }
                        ],
                        "text": "[6], [9] use an optical flow algorithm to match shape and texture models iteratively, and Vetter [14] uses a general purpose optimization method to match photorealistic human face models to images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 104
                            }
                        ],
                        "text": "Poggio et al. [6], [9] use an optical flow algorithm to match shape and texture models iteratively, and Vetter [14] uses a general purpose optimization method to match photorealistic human face models to images."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 124
                            }
                        ],
                        "text": "THE ainterpretation through synthesiso approach has received considerable attention over the past few years [3], [6], [11], [14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aLearning Novel Views to a Single Face Image,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Second Int'l Conf. Automatic Face and Gesture Recognition,"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50564384"
                        ],
                        "name": "G. Edwards",
                        "slug": "G.-Edwards",
                        "structuredName": {
                            "firstName": "Gareth",
                            "lastName": "Edwards",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Edwards"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107314796"
                        ],
                        "name": "C. J. Taylor",
                        "slug": "C.-J.-Taylor",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. J. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 63858346,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "44381035bb69940b43bbe0d530491468ac1da234",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Face-recognition-using-the-active-appearance-model.-Edwards-Taylor",
            "title": {
                "fragments": [],
                "text": "Face recognition using the active appearance model."
            },
            "venue": {
                "fragments": [],
                "text": "eccv 1998"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1964574"
                        ],
                        "name": "Y. Yacoob",
                        "slug": "Y.-Yacoob",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Yacoob",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Yacoob"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59722783,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c261c06e70da3526a54fb308d751dea19794450f",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Recognizing-facial-expressions-under-rigid-and-Black-Yacoob",
            "title": {
                "fragments": [],
                "text": "Recognizing facial expressions under rigid and non-rigid facial motions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2256718"
                        ],
                        "name": "W. Press",
                        "slug": "W.-Press",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Press",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Press"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48590121"
                        ],
                        "name": "S. Teukolsky",
                        "slug": "S.-Teukolsky",
                        "structuredName": {
                            "firstName": "Saul",
                            "lastName": "Teukolsky",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Teukolsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2608024"
                        ],
                        "name": "W. Vetterling",
                        "slug": "W.-Vetterling",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Vetterling",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Vetterling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35046585"
                        ],
                        "name": "B. Flannery",
                        "slug": "B.-Flannery",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Flannery",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Flannery"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "It may be possible to modify the algorithm to be more like a conjugate gradient descent method, or to use second order information to use the Levenberg-Marquardt algorithm [17], which could lead to faster convergence."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "With no other information, this would be difficult, but could be tackled with general purpose algorithms such as Powells, Simplex, Simulated Annealing or Genetic Algorithms [17]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 21409595,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1db212040657728644b1813994d701e68d3608a6",
            "isKey": false,
            "numCitedBy": 4046,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Numerical-Recipes-in-C,-2nd-Edition-Press-Teukolsky",
            "title": {
                "fragments": [],
                "text": "Numerical Recipes in C, 2nd Edition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2862374"
                        ],
                        "name": "U. Grenander",
                        "slug": "U.-Grenander",
                        "structuredName": {
                            "firstName": "Ulf",
                            "lastName": "Grenander",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Grenander"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111174510"
                        ],
                        "name": "M. I. Miller",
                        "slug": "M.-I.-Miller",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Miller",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. I. Miller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Model-based approaches to the interpretation of images of variable objects axe now attracting considerable interest [6][8][10] [11][14] [16][19][20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 117719085,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1a8bddd2b1666f3a862d7e2bdbcd89e3037ba172",
            "isKey": false,
            "numCitedBy": 656,
            "numCiting": 85,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "REPRESENTATIONS-OF-KNOWLEDGE-IN-COMPLEX-SYSTEMS-Grenander-Miller",
            "title": {
                "fragments": [],
                "text": "REPRESENTATIONS OF KNOWLEDGE IN COMPLEX SYSTEMS"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[12] describe a model of shape and intensity variations using a 3D deformable model of the intensity landscape."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aGeneralized Image Matching: Statistical Learning of Physically-Based Deformations,o"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Vision and Image Understanding,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Probabilistic visual learning for object recognition"
            },
            "venue": {
                "fragments": [],
                "text": "5 th International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 256,
                                "start": 252
                            }
                        ],
                        "text": "\u2026previously [11], [3] that a statistical model of appearance can be matched to an image in two steps: First, an Active Shape Model is matched to boundary features in the image, then a separate eigenface model is used to reconstruct the texture (in the graphics sense) in a shape-normalized frame."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u00d0Appearance models, deformable templates, model matching.\n\u00e6"
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proc. Sixth Int'l Conf. Computer Vision"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Sixth Int'l Conf. Computer Vision"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 204
                            }
                        ],
                        "text": "In practice, we use a multiresolution implementation, in which we start at a coarse resolution and iterate to convergence at each level before projecting the current solution to the next level of the model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 5
                            }
                        ],
                        "text": "In this paper, we show an efficient direct optimization approach that matches shape and texture simultaneously, resulting in an algorithm that is rapid, accurate, and robust."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Cootes, \u00aaInterpreting Face Images Using Active Appearance Models"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Third Int'l Conf. Automatic Face and Gesture Recognition"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 9
                            }
                        ],
                        "text": "Gleicher [7] describes a method of tracking objects by allowing a single template to deform under a variety of transformations (affine, projective, etc."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 35
                            }
                        ],
                        "text": "decompositiono tracking algorithms [7], [8], [13], but rather than tracking a single deforming object we match a model which can fit a whole class of objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aProjective Registration with Difference Decomposition,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE Conf. Computer Vision and Pattern Recognition,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Reliable Head Tracking under Varying Illumination : An Approach Based on Registration of Texture Mapped 3 D Models"
            },
            "venue": {
                "fragments": [],
                "text": "o Int ' l J . Computer Vision"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 88
                            }
                        ],
                        "text": "We have tested the method extensively with images of faces and with medical images [1], [5] and have obtained encouraging results in other domains."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Cootes, \u00aaFace Recognition Using the Active Appearance Model,\u00ba Proc. Fifth European Conf"
            },
            "venue": {
                "fragments": [],
                "text": "Cootes, \u00aaFace Recognition Using the Active Appearance Model,\u00ba Proc. Fifth European Conf"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 16
                            }
                        ],
                        "text": "In earlier work [4], [1], we described a training algorithm based on regressing random displacement vectors against residual error vectors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 79
                            }
                        ],
                        "text": "The Active Appearance Models described below are an extension of this approach [4], [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aInterpreting Face Images Using Active Appearance Models,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Third Int'l Conf. Automatic Face and Gesture Recognition,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[6], [9] use an optical flow algorithm to match shape and texture models iteratively, and Vetter [14] uses a general purpose optimization method to match photorealistic human face models to images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 113
                            }
                        ],
                        "text": "THE ainterpretation through synthesiso approach has received considerable attention over the past few years [3], [6], [11], [14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aFacial Analysis and Synthesis Using Image-Based Models,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Second Int'l Conf. Automatic Face and Gesture Recognition"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "For further information on this or any computing topic, please visit our Digital Library at http://computer.org/publications/dlib"
            },
            "venue": {
                "fragments": [],
                "text": "For further information on this or any computing topic, please visit our Digital Library at http://computer.org/publications/dlib"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Probabilistic visual learning for object recogni tion"
            },
            "venue": {
                "fragments": [],
                "text": "In 5th International Conference on Computer Vision,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Reliable Head Tracking under Varying Illumination : An Approach Based on Registration of Texture Mapped 3 D Models , o IEEE Trans"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Analysis and Machine Intelligence"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 18
                            }
                        ],
                        "text": "Christensen et al [3] describe a viscous ow model of deformation which they also apply to the brain, but is very computationally expensive."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Topological Properties of Smooth Anatomic Maps,  pages 101{112"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 155
                            }
                        ],
                        "text": "1 Introduction Model-based approaches to the interpretation of images of variable objects are now attracting considerable interest [6][8][10] [11][14] [16][19][20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Boundary nding with parametrically de formable models"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelli gence,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Eigen - points : Controlpoint location using principal component analy"
            },
            "venue": {
                "fragments": [],
                "text": "2 nd International Conference on Automatic Face and Gesture Recognition"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 127
                            }
                        ],
                        "text": "We apply Procrustes analysis to align the sets of points (each represented as a vector, x) and build a statistical shape model [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 73
                            }
                        ],
                        "text": "Although an AAM search is slightly slower than Active Shape Model search [2], the procedure tends to be be more robust than ASM search alone, since all the image evidence is used."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aActive Shape Models\u00d0Their Training and Application,o"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Vision and Image Understanding,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 25
                            }
                        ],
                        "text": "We have shown previously [11], [3] that a statistical model of"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 118
                            }
                        ],
                        "text": "THE ainterpretation through synthesiso approach has received considerable attention over the past few years [3], [6], [11], [14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aAutomatic Interpretation and Coding of Face Images using Flexible Models,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 1997
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 17,
            "methodology": 21
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 46,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/Active-Appearance-Models-Cootes-Edwards/76b532e2cb573fdf29f3ae68dc1372f3319c93c2?sort=total-citations"
}