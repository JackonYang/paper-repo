{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51114267"
                        ],
                        "name": "Alastair Moore",
                        "slug": "Alastair-Moore",
                        "structuredName": {
                            "firstName": "Alastair",
                            "lastName": "Moore",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alastair Moore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144827387"
                        ],
                        "name": "S. Prince",
                        "slug": "S.-Prince",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Prince",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Prince"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734784"
                        ],
                        "name": "J. Warrell",
                        "slug": "J.-Warrell",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Warrell",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Warrell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2058367335"
                        ],
                        "name": "U. Mohammed",
                        "slug": "U.-Mohammed",
                        "structuredName": {
                            "firstName": "Umar",
                            "lastName": "Mohammed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Mohammed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110799401"
                        ],
                        "name": "Graham Jones",
                        "slug": "Graham-Jones",
                        "structuredName": {
                            "firstName": "Graham",
                            "lastName": "Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Graham Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 165
                            }
                        ],
                        "text": "propose a method to generate superpixels that conform to a grid by finding optimal paths, or seams, that split the image into smaller vertical or horizontal regions [21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14444827,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "1328880541640d3c9aa1ce7b5201f90d6c4e0925",
            "isKey": false,
            "numCitedBy": 370,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Unsupervised over-segmentation of an image into superpixels is a common preprocessing step for image parsing algorithms. Ideally, every pixel within each superpixel region will belong to the same real-world object. Existing algorithms generate superpixels that forfeit many useful properties of the regular topology of the original pixels: for example, the nth superpixel has no consistent position or relationship with its neighbors. We propose a novel algorithm that produces superpixels that are forced to conform to a grid (a regular superpixel lattice). Despite this added topological constraint, our algorithm is comparable in terms of speed and accuracy to alternative segmentation approaches. To demonstrate this, we use evaluation metrics based on (i) image reconstruction (ii) comparison to human-segmented images and (iii) stability of segmentation over subsequent frames of video sequences."
            },
            "slug": "Superpixel-lattices-Moore-Prince",
            "title": {
                "fragments": [],
                "text": "Superpixel lattices"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A novel algorithm is proposed that produces superpixels that are forced to conform to a grid (a regular superpixel lattice) despite this added topological constraint, which is comparable in terms of speed and accuracy to alternative segmentation approaches."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2329582"
                        ],
                        "name": "Alex Levinshtein",
                        "slug": "Alex-Levinshtein",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Levinshtein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Levinshtein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2924284"
                        ],
                        "name": "Adrian Stere",
                        "slug": "Adrian-Stere",
                        "structuredName": {
                            "firstName": "Adrian",
                            "lastName": "Stere",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adrian Stere"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734027"
                        ],
                        "name": "Kiriakos N. Kutulakos",
                        "slug": "Kiriakos-N.-Kutulakos",
                        "structuredName": {
                            "firstName": "Kiriakos",
                            "lastName": "Kutulakos",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kiriakos N. Kutulakos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793739"
                        ],
                        "name": "David J. Fleet",
                        "slug": "David-J.-Fleet",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Fleet",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Fleet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1779136"
                        ],
                        "name": "S. Dickinson",
                        "slug": "S.-Dickinson",
                        "structuredName": {
                            "firstName": "Sven",
                            "lastName": "Dickinson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dickinson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144003778"
                        ],
                        "name": "Kaleem Siddiqi",
                        "slug": "Kaleem-Siddiqi",
                        "structuredName": {
                            "firstName": "Kaleem",
                            "lastName": "Siddiqi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaleem Siddiqi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Table 1 provides a qualitative and quanti-\ntative summary of the reviewed methods, including their relative\nperformance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Superpixels, segmentation, clustering, k-means\n\u00c7"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 11
                            }
                        ],
                        "text": "E-mail: kevin.smith@lmc.biol.ethz.ch."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1111731,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a3269505b943d3549a82c4eef23d9e29cea3be11",
            "isKey": false,
            "numCitedBy": 1076,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a geometric-flow-based algorithm for computing a dense oversegmentation of an image, often referred to as superpixels. It produces segments that, on one hand, respect local image boundaries, while, on the other hand, limiting undersegmentation through a compactness constraint. It is very fast, with complexity that is approximately linear in image size, and can be applied to megapixel sized images with high superpixel densities in a matter of minutes. We show qualitative demonstrations of high-quality results on several complex images. The Berkeley database is used to quantitatively compare its performance to a number of oversegmentation algorithms, showing that it yields less undersegmentation than algorithms that lack a compactness constraint while offering a significant speedup over N-cuts, which does enforce compactness."
            },
            "slug": "TurboPixels:-Fast-Superpixels-Using-Geometric-Flows-Levinshtein-Stere",
            "title": {
                "fragments": [],
                "text": "TurboPixels: Fast Superpixels Using Geometric Flows"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A geometric-flow-based algorithm for computing a dense oversegmentation of an image, often referred to as superpixels, which yields less undersegmentation than algorithms that lack a compactness constraint while offering a significant speedup over N-cuts, which does enforce compactness."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1922280"
                        ],
                        "name": "O. Veksler",
                        "slug": "O.-Veksler",
                        "structuredName": {
                            "firstName": "Olga",
                            "lastName": "Veksler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Veksler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692688"
                        ],
                        "name": "Yuri Boykov",
                        "slug": "Yuri-Boykov",
                        "structuredName": {
                            "firstName": "Yuri",
                            "lastName": "Boykov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuri Boykov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3272158"
                        ],
                        "name": "Paria Mehrani",
                        "slug": "Paria-Mehrani",
                        "structuredName": {
                            "firstName": "Paria",
                            "lastName": "Mehrani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paria Mehrani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Table 1 provides a qualitative and quanti-\ntative summary of the reviewed methods, including their relative\nperformance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Superpixels, segmentation, clustering, k-means\n\u00c7"
                    },
                    "intents": []
                }
            ],
            "corpusId": 10939961,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "ddd36382c3034cd9eebe18a61e8bedd2d1a40601",
            "isKey": false,
            "numCitedBy": 468,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Many methods for object recognition, segmentation, etc., rely on a tessellation of an image into \"superpixels\". A superpixel is an image patch which is better aligned with intensity edges than a rectangular patch. Superpixels can be extracted with any segmentation algorithm, however, most of them produce highly irregular superpixels, with widely varying sizes and shapes. A more regular space tessellation may be desired. We formulate the superpixel partitioning problem in an energy minimization framework, and optimize with graph cuts. Our energy function explicitly encourages regular superpixels. We explore variations of the basic energy, which allow a trade-off between a less regular tessellation but more accurate boundaries or better efficiency. Our advantage over previous work is computational efficiency, principled optimization, and applicability to 3D \"supervoxel\" segmentation. We achieve high boundary recall on images and spatial coherence on video. We also show that compact superpixels improve accuracy on a simple application of salient object segmentation."
            },
            "slug": "Superpixels-and-Supervoxels-in-an-Energy-Framework-Veksler-Boykov",
            "title": {
                "fragments": [],
                "text": "Superpixels and Supervoxels in an Energy Optimization Framework"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work forms the superpixel partitioning problem in an energy minimization framework, and explores variations of the basic energy, which allow a trade-off between a less regular tessellation but more accurate boundaries or better efficiency."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2487006"
                        ],
                        "name": "B. Fulkerson",
                        "slug": "B.-Fulkerson",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Fulkerson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Fulkerson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687524"
                        ],
                        "name": "A. Vedaldi",
                        "slug": "A.-Vedaldi",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Vedaldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vedaldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715959"
                        ],
                        "name": "Stefano Soatto",
                        "slug": "Stefano-Soatto",
                        "structuredName": {
                            "firstName": "Stefano",
                            "lastName": "Soatto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stefano Soatto"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "Previous works have used QS08 for object localization [9] and motion segmentation [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 160
                            }
                        ],
                        "text": "They have become key building blocks of many computer vision algorithms, such as top scoring multiclass object segmentation entries to the PASCAL VOC Challenge [9], [29], [11], depth estimation [30], segmentation [16], body model estimation [22], and object localization [9]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2117454,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "52727dcc2d948093b8be500b5e8c66ed9b2ae729",
            "isKey": false,
            "numCitedBy": 688,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a method to identify and localize object classes in images. Instead of operating at the pixel level, we advocate the use of superpixels as the basic unit of a class segmentation or pixel localization scheme. To this end, we construct a classifier on the histogram of local features found in each superpixel. We regularize this classifier by aggregating histograms in the neighborhood of each superpixel and then refine our results further by using the classifier in a conditional random field operating on the superpixel graph. Our proposed method exceeds the previously published state-of-the-art on two challenging datasets: Graz-02 and the PASCAL VOC 2007 Segmentation Challenge."
            },
            "slug": "Class-segmentation-and-object-localization-with-Fulkerson-Vedaldi",
            "title": {
                "fragments": [],
                "text": "Class segmentation and object localization with superpixel neighborhoods"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A method to identify and localize object classes in images by constructing a classifier on the histogram of local features found in each superpixel using superpixels as the basic unit of a class segmentation or pixel localization scheme."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1918688"
                        ],
                        "name": "Alper Ayvaci",
                        "slug": "Alper-Ayvaci",
                        "structuredName": {
                            "firstName": "Alper",
                            "lastName": "Ayvaci",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alper Ayvaci"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715959"
                        ],
                        "name": "Stefano Soatto",
                        "slug": "Stefano-Soatto",
                        "structuredName": {
                            "firstName": "Stefano",
                            "lastName": "Soatto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stefano Soatto"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 15
                            }
                        ],
                        "text": "It is O\u00f0N logN\u00de complex and fast in\n."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14646763,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "8384cd2ca07a10c837d47e1119e1fdd326a082f7",
            "isKey": false,
            "numCitedBy": 46,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a motion segmentation algorithm that partitions the image plane into disjoint regions based on their parametric motion. It relies on a finer partitioning of the image domain into regions of uniform photometric properties, with motion segments made of unions of such \u201csuperpixels.\u201d We exploit recent advances in combinatorial graph optimization that yield computationally efficient estimates. The energy functional is built on a superpixel graph, and is iteratively minimized by computing a parametric motion model in closed-form, followed by a graph cut of the superpixel adjacency graph. It generalizes naturally to multi-label partitions that can handle multiple motions."
            },
            "slug": "Motion-segmentation-with-occlusions-on-the-graph-Ayvaci-Soatto",
            "title": {
                "fragments": [],
                "text": "Motion segmentation with occlusions on the superpixel graph"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A motion segmentation algorithm that partitions the image plane into disjoint regions based on their parametric motion, which generalizes naturally to multi-label partitions that can handle multiple motions."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145273587"
                        ],
                        "name": "Stephen Gould",
                        "slug": "Stephen-Gould",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Gould",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen Gould"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33869638"
                        ],
                        "name": "J. Rodgers",
                        "slug": "J.-Rodgers",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Rodgers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Rodgers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115017312"
                        ],
                        "name": "David S. Cohen",
                        "slug": "David-S.-Cohen",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Cohen",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David S. Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684677"
                        ],
                        "name": "G. Elidan",
                        "slug": "G.-Elidan",
                        "structuredName": {
                            "firstName": "Gal",
                            "lastName": "Elidan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Elidan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736370"
                        ],
                        "name": "D. Koller",
                        "slug": "D.-Koller",
                        "structuredName": {
                            "firstName": "Daphne",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Koller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 136
                            }
                        ],
                        "text": "26 GHz processor with 2GB RAM, and the class-averaged segmentation accuracy obtained on the MSRC data set using the method described in [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 100
                            }
                        ],
                        "text": "(bottom) Results obtained using SLIC superpixels in place of NC05, following the method proposed in [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 29
                            }
                        ],
                        "text": "Segmentation accuracy (using [11] on MSRC) 74."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 48
                            }
                        ],
                        "text": "These results were obtained using the method of [11], which uses superpixels to compute color, texture, geometry, and location features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 196
                            }
                        ],
                        "text": "However, GS04 showed relatively poor segmentation performance and under-segmentation error, likely because its large, irregularly shaped superpixels are not suited to segmentation methods such as [11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 99
                            }
                        ],
                        "text": "SLIC also reduces the the computational time by a factor of over 500 over NC05, the method used in [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 171
                            }
                        ],
                        "text": "They have become key building blocks of many computer vision algorithms, such as top scoring multiclass object segmentation entries to the PASCAL VOC Challenge [9], [29], [11], depth estimation [30], segmentation [16], body model estimation [22], and object localization [9]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 9779450,
            "fieldsOfStudy": [
                "Computer Science",
                "Environmental Science"
            ],
            "id": "599c8d460575ddfea702075b8ccde01b6fe987e8",
            "isKey": true,
            "numCitedBy": 432,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Multi-class image segmentation has made significant advances in recent years through the combination of local and global features. One important type of global feature is that of inter-class spatial relationships. For example, identifying \u201ctree\u201d pixels indicates that pixels above and to the sides are more likely to be \u201csky\u201d whereas pixels below are more likely to be \u201cgrass.\u201d Incorporating such global information across the entire image and between all classes is a computational challenge as it is image-dependent, and hence, cannot be precomputed.In this work we propose a method for capturing global information from inter-class spatial relationships and encoding it as a local feature. We employ a two-stage classification process to label all image pixels. First, we generate predictions which are used to compute a local relative location feature from learned relative location maps. In the second stage, we combine this with appearance-based features to provide a final segmentation. We compare our results to recent published results on several multi-class image segmentation databases and show that the incorporation of relative location information allows us to significantly outperform the current state-of-the-art."
            },
            "slug": "Multi-Class-Segmentation-with-Relative-Location-Gould-Rodgers",
            "title": {
                "fragments": [],
                "text": "Multi-Class Segmentation with Relative Location Prior"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work proposes a method for capturing global information from inter-class spatial relationships and encoding it as a local feature and shows that the incorporation of relative location information allows it to significantly outperform the current state-of-the-art."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10771328"
                        ],
                        "name": "Greg Mori",
                        "slug": "Greg-Mori",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Mori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Greg Mori"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 241
                            }
                        ],
                        "text": "They have become key building blocks of many computer vision algorithms, such as top scoring multiclass object segmentation entries to the PASCAL VOC Challenge [9], [29], [11], depth estimation [30], segmentation [16], body model estimation [22], and object localization [9]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2983119,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "32510e7f88bc0767fbbc811397ba068dbc4cf549",
            "isKey": false,
            "numCitedBy": 340,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we show how segmentation as preprocessing paradigm can be used to improve the efficiency and accuracy of model search in an image. We operationalize this idea using an over-segmentation of an image into superpixels. The problem domain we explore is human body pose estimation from still images. The superpixels prove useful in two ways. First, we restrict the joint positions in our human body model to lie at centers of superpixels, which reduces the size of the model search space. In addition, accurate support masks for computing features on half-limbs of the body model are obtained by using agglomerations of superpixels as half limb segments. We present results on a challenging dataset of people in sports news images"
            },
            "slug": "Guiding-model-search-using-segmentation-Mori",
            "title": {
                "fragments": [],
                "text": "Guiding model search using segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "It is shown how segmentation as preprocessing paradigm can be used to improve the efficiency and accuracy of model search in an image by using an over-segmentation of an image into superpixels."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685089"
                        ],
                        "name": "Pedro F. Felzenszwalb",
                        "slug": "Pedro-F.-Felzenszwalb",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Felzenszwalb",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pedro F. Felzenszwalb"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713089"
                        ],
                        "name": "D. Huttenlocher",
                        "slug": "D.-Huttenlocher",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Huttenlocher",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Huttenlocher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 0
                            }
                        ],
                        "text": "Felzenszwalb and Huttenlocher [8] propose an alter-\nnative graph-based approach that has been applied to generate\nsuperpixels."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 90
                            }
                        ],
                        "text": "We therefore performed an empirical comparison of five stateof-the-art superpixel methods [8], [23], [26], [25], [15], evaluating their speed, ability to adhere to image boundaries, and impact on segmentation performance."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 30
                            }
                        ],
                        "text": "Felzenszwalb and Huttenlocher [8] propose an alter-"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 38
                            }
                        ],
                        "text": "Like some other superpixel algorithms [8], SLIC does not explicitly"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 100
                            }
                        ],
                        "text": "For example, if adherence to image boundaries is of paramount importance, the graph-based method of [8] may be an ideal choice."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207663697,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aeeffe327e6c93e9010c7b1e401caa9113723851",
            "isKey": true,
            "numCitedBy": 3751,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of segmenting an image into regions. We define a predicate for measuring the evidence for a boundary between two regions using a graph-based representation of the image. We then develop an efficient segmentation algorithm based on this predicate, and show that although this algorithm makes greedy decisions it produces segmentations that satisfy global properties. We apply the algorithm to image segmentation using two different kinds of local neighborhoods in constructing the graph, and illustrate the results with both real and synthetic images. The algorithm runs in time nearly linear in the number of graph edges and is also fast in practice. An important characteristic of the method is its ability to preserve detail in low-variability image regions while ignoring detail in high-variability regions."
            },
            "slug": "Efficient-Graph-Based-Image-Segmentation-Felzenszwalb-Huttenlocher",
            "title": {
                "fragments": [],
                "text": "Efficient Graph-Based Image Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "An efficient segmentation algorithm is developed based on a predicate for measuring the evidence for a boundary between two regions using a graph-based representation of the image and it is shown that although this algorithm makes greedy decisions it produces segmentations that satisfy global properties."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699161"
                        ],
                        "name": "C. L. Zitnick",
                        "slug": "C.-L.-Zitnick",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Zitnick",
                            "middleNames": [
                                "Lawrence"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. L. Zitnick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738740"
                        ],
                        "name": "S. B. Kang",
                        "slug": "S.-B.-Kang",
                        "structuredName": {
                            "firstName": "Sing",
                            "lastName": "Kang",
                            "middleNames": [
                                "Bing"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. B. Kang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 194
                            }
                        ],
                        "text": "They have become key building blocks of many computer vision algorithms, such as top scoring multiclass object segmentation entries to the PASCAL VOC Challenge [9], [29], [11], depth estimation [30], segmentation [16], body model estimation [22], and object localization [9]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 95
                            }
                        ],
                        "text": "SLIC is similar to the approach used as a preprocessing step for depth estimation described in [30], which was not fully explored in the context of superpixel generation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 44
                            }
                        ],
                        "text": "generate superpixels in a manner similar to [30]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 17267819,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ca89388a7f1ff47578bd8c32bc4c497185d3ec07",
            "isKey": false,
            "numCitedBy": 303,
            "numCiting": 78,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a stereo method specifically designed for image-based rendering. For effective image-based rendering, the interpolated views need only be visually plausible. The implication is that the extracted depths do not need to be correct, as long as the recovered views appear to be correct. Our stereo algorithm relies on over-segmenting the source images. Computing match values over entire segments rather than single pixels provides robustness to noise and intensity bias. Color-based segmentation also helps to more precisely delineate object boundaries, which is important for reducing boundary artifacts in synthesized views. The depths of the segments for each image are computed using loopy belief propagation within a Markov Random Field framework. Neighboring MRFs are used for occlusion reasoning and ensuring that neighboring depth maps are consistent. We tested our stereo algorithm on several stereo pairs from the Middlebury data set, and show rendering results based on two of these data sets. We also show results for video-based rendering."
            },
            "slug": "Stereo-for-Image-Based-Rendering-using-Image-Zitnick-Kang",
            "title": {
                "fragments": [],
                "text": "Stereo for Image-Based Rendering using Image Over-Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "A stereo method specifically designed for image-based rendering that relies on over-segmenting the source images, which helps to more precisely delineate object boundaries, which is important for reducing boundary artifacts in synthesized views."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40401747"
                        ],
                        "name": "Aur\u00e9lien Lucchi",
                        "slug": "Aur\u00e9lien-Lucchi",
                        "structuredName": {
                            "firstName": "Aur\u00e9lien",
                            "lastName": "Lucchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aur\u00e9lien Lucchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145548651"
                        ],
                        "name": "Kevin Smith",
                        "slug": "Kevin-Smith",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Smith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118589"
                        ],
                        "name": "R. Achanta",
                        "slug": "R.-Achanta",
                        "structuredName": {
                            "firstName": "Radhakrishna",
                            "lastName": "Achanta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Achanta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689738"
                        ],
                        "name": "V. Lepetit",
                        "slug": "V.-Lepetit",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Lepetit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Lepetit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717736"
                        ],
                        "name": "P. Fua",
                        "slug": "P.-Fua",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Fua",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Fua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [18], SLIC superpixels significantly reduce the complexity of the graph, making the segmentation tractable."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 28
                            }
                        ],
                        "text": "Segmented mitochondria from [18] are shown in Figs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 47
                            }
                        ],
                        "text": "(b) The segmentation result from the method of [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16766181,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1faf917f4f7388a63957d065607cdc706a7d2879",
            "isKey": false,
            "numCitedBy": 101,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "While there has been substantial progress in segmenting natural images, state-of-the-art methods that perform well in such tasks unfortunately tend to underperform when confronted with the different challenges posed by electron microscope (EM) data. For example, in EM imagery of neural tissue, numerous cells and subcellular structures appear within a single image, they exhibit irregular shapes that cannot be easily modeled by standard techniques, and confusing textures clutter the background. We propose a fully automated approach that handles these challenges by using sophisticated cues that capture global shape and texture information, and by learning the specific appearance of object boundaries. We demonstrate that our approach significantly outperforms state-of-the-art techniques and closely matches the performance of human annotators."
            },
            "slug": "A-Fully-Automated-Approach-to-Segmentation-of-in-EM-Lucchi-Smith",
            "title": {
                "fragments": [],
                "text": "A Fully Automated Approach to Segmentation of Irregularly Shaped Cellular Structures in EM Images"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work proposes a fully automated approach that handles EM imagery of neural tissue challenges by using sophisticated cues that capture global shape and texture information, and by learning the specific appearance of object boundaries."
            },
            "venue": {
                "fragments": [],
                "text": "MICCAI"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739551"
                        ],
                        "name": "J. M. Gonfaus",
                        "slug": "J.-M.-Gonfaus",
                        "structuredName": {
                            "firstName": "Josep",
                            "lastName": "Gonfaus",
                            "middleNames": [
                                "Maria"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. M. Gonfaus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2343486"
                        ],
                        "name": "X. Boix",
                        "slug": "X.-Boix",
                        "structuredName": {
                            "firstName": "Xavier",
                            "lastName": "Boix",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Boix"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2820687"
                        ],
                        "name": "Joost van de Weijer",
                        "slug": "Joost-van-de-Weijer",
                        "structuredName": {
                            "firstName": "Joost",
                            "lastName": "Weijer",
                            "middleNames": [
                                "van",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joost van de Weijer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749498"
                        ],
                        "name": "Andrew D. Bagdanov",
                        "slug": "Andrew-D.-Bagdanov",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Bagdanov",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew D. Bagdanov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3061716"
                        ],
                        "name": "J. Gual",
                        "slug": "J.-Gual",
                        "structuredName": {
                            "firstName": "Joan",
                            "lastName": "Gual",
                            "middleNames": [
                                "Serrat"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Gual"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763726"
                        ],
                        "name": "Jordi Gonz\u00e0lez",
                        "slug": "Jordi-Gonz\u00e0lez",
                        "structuredName": {
                            "firstName": "Jordi",
                            "lastName": "Gonz\u00e0lez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jordi Gonz\u00e0lez"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 26
                            }
                        ],
                        "text": "Results for the method of [10], using SLIC and QS09 superpixels."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 73
                            }
                        ],
                        "text": "We also tested on the PASCAL VOC 2010 data set [7] using the approach of [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17114901,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "24c20c28871fa923c3f45b745b9b9f2d3d280e81",
            "isKey": false,
            "numCitedBy": 177,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Hierarchical conditional random fields have been successfully applied to object segmentation. One reason is their ability to incorporate contextual information at different scales. However, these models do not allow multiple labels to be assigned to a single node. At higher scales in the image, this yields an oversimplified model, since multiple classes can be reasonable expected to appear within one region. This simplified model especially limits the impact that observations at larger scales may have on the CRF model. Neglecting the information at larger scales is undesirable since class-label estimates based on these scales are more reliable than at smaller, noisier scales. To address this problem, we propose a new potential, called harmony potential, which can encode any possible combination of class labels. We propose an effective sampling strategy that renders tractable the underlying optimization problem. Results show that our approach obtains state-of-the-art results on two challenging datasets: Pascal VOC 2009 and MSRC-21."
            },
            "slug": "Harmony-potentials-for-joint-classification-and-Gonfaus-Boix",
            "title": {
                "fragments": [],
                "text": "Harmony potentials for joint classification and segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work proposes a new potential, called harmony potential, which can encode any possible combination of class labels, and proposes an effective sampling strategy that renders tractable the underlying optimization problem."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1815078"
                        ],
                        "name": "S. Avidan",
                        "slug": "S.-Avidan",
                        "structuredName": {
                            "firstName": "Shai",
                            "lastName": "Avidan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Avidan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2947946"
                        ],
                        "name": "Ariel Shamir",
                        "slug": "Ariel-Shamir",
                        "structuredName": {
                            "firstName": "Ariel",
                            "lastName": "Shamir",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ariel Shamir"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Table 1 provides a qualitative and quanti-\ntative summary of the reviewed methods, including their relative\nperformance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6717725,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "58648b7f6c7424c256abdd7db8ba024801f0aca1",
            "isKey": false,
            "numCitedBy": 1111,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Effective resizing of images should not only use geometric constraints, but consider the image content as well. We present a simple image operator called seam carving that supports content-aware image resizing for both reduction and expansion. A seam is an optimal 8-connected path of pixels on a single image from top to bottom, or left to right, where optimality is defined by an image energy function. By repeatedly carving out or inserting seams in one direction we can change the aspect ratio of an image. By applying these operators in both directions we can retarget the image to a new size. The selection and order of seams protect the content of the image, as defined by the energy function. Seam carving can also be used for image content enhancement and object removal. We support various visual saliency measures for defining the energy of an image, and can also include user input to guide the process. By storing the order of seams in an image we create multi-size images, that are able to continuously change in real time to fit a given size."
            },
            "slug": "Seam-carving-for-content-aware-image-resizing-Avidan-Shamir",
            "title": {
                "fragments": [],
                "text": "Seam carving for content-aware image resizing"
            },
            "venue": {
                "fragments": [],
                "text": "ACM Transactions on Graphics"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143774737"
                        ],
                        "name": "J. Shotton",
                        "slug": "J.-Shotton",
                        "structuredName": {
                            "firstName": "Jamie",
                            "lastName": "Shotton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shotton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33652486"
                        ],
                        "name": "J. Winn",
                        "slug": "J.-Winn",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Winn",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Winn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756036"
                        ],
                        "name": "C. Rother",
                        "slug": "C.-Rother",
                        "structuredName": {
                            "firstName": "Carsten",
                            "lastName": "Rother",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rother"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716777"
                        ],
                        "name": "A. Criminisi",
                        "slug": "A.-Criminisi",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Criminisi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Criminisi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Superpixels, segmentation, clustering, k-means\n\u00c7"
                    },
                    "intents": []
                }
            ],
            "corpusId": 242941,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0d1bfcdfc90e662defd26b8b0deae6ef6e661b23",
            "isKey": false,
            "numCitedBy": 1084,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract\nThis paper details a new approach for learning a discriminative model of object classes, incorporating texture, layout, and context information efficiently. The learned model is used for automatic visual understanding and semantic segmentation of photographs. Our discriminative model exploits texture-layout filters, novel features based on textons, which jointly model patterns of texture and their spatial layout. Unary classification and feature selection is achieved using shared boosting to give an efficient classifier which can be applied to a large number of classes. Accurate image segmentation is achieved by incorporating the unary classifier in a conditional random field, which (i) captures the spatial interactions between class labels of neighboring pixels, and (ii) improves the segmentation of specific object instances. Efficient training of the model on large datasets is achieved by exploiting both random feature selection and piecewise training methods.\n\nHigh classification and segmentation accuracy is demonstrated on four varied databases: (i) the MSRC 21-class database containing photographs of real objects viewed under general lighting conditions, poses and viewpoints, (ii) the 7-class Corel subset and (iii) the 7-class Sowerby database used in He et\u00a0al. (Proceeding of IEEE Conference on Computer Vision and Pattern Recognition, vol.\u00a02, pp.\u00a0695\u2013702, June 2004), and (iv) a set of video sequences of television shows. The proposed algorithm gives competitive and visually pleasing results for objects that are highly textured (grass, trees, etc.), highly structured (cars, faces, bicycles, airplanes, etc.), and even articulated (body, cow, etc.).\n"
            },
            "slug": "TextonBoost-for-Image-Understanding:-Multi-Class-by-Shotton-Winn",
            "title": {
                "fragments": [],
                "text": "TextonBoost for Image Understanding: Multi-Class Object Recognition and Segmentation by Jointly Modeling Texture, Layout, and Context"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A new approach for learning a discriminative model of object classes, incorporating texture, layout, and context information efficiently, which gives competitive and visually pleasing results for objects that are highly textured, highly structured, and even articulated."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1820595"
                        ],
                        "name": "L. Vincent",
                        "slug": "L.-Vincent",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Vincent",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Vincent"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2987794"
                        ],
                        "name": "P. Soille",
                        "slug": "P.-Soille",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Soille",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Soille"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 11
                            }
                        ],
                        "text": "R. Achanta, A. Shaji, and S. Su\u0308sstrunk are with the Images and Visual Representation Group, School of Computer and Communication Sciences, Ecole Polytechnique Fe\u0301de\u0301rale de Lausanne, Station 14, EPFL, CH-1015, Lausanne, Switzerland."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15436061,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a3819dda9a5f00dbb8cd3413ca7422e37a0d5794",
            "isKey": false,
            "numCitedBy": 5733,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": "A fast and flexible algorithm for computing watersheds in digital gray-scale images is introduced. A review of watersheds and related motion is first presented, and the major methods to determine watersheds are discussed. The algorithm is based on an immersion process analogy, in which the flooding of the water in the picture is efficiently simulated using of queue of pixel. It is described in detail provided in a pseudo C language. The accuracy of this algorithm is proven to be superior to that of the existing implementations, and it is shown that its adaptation to any kind of digital grid and its generalization to n-dimensional images (and even to graphs) are straightforward. The algorithm is reported to be faster than any other watershed algorithm. Applications of this algorithm with regard to picture segmentation are presented for magnetic resonance (MR) imagery and for digital elevation models. An example of 3-D watershed is also provided. >"
            },
            "slug": "Watersheds-in-Digital-Spaces:-An-Efficient-Based-on-Vincent-Soille",
            "title": {
                "fragments": [],
                "text": "Watersheds in Digital Spaces: An Efficient Algorithm Based on Immersion Simulations"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A fast and flexible algorithm for computing watersheds in digital gray-scale images is introduced, based on an immersion process analogy, which is reported to be faster than any other watershed algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40401747"
                        ],
                        "name": "Aur\u00e9lien Lucchi",
                        "slug": "Aur\u00e9lien-Lucchi",
                        "structuredName": {
                            "firstName": "Aur\u00e9lien",
                            "lastName": "Lucchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aur\u00e9lien Lucchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145548651"
                        ],
                        "name": "Kevin Smith",
                        "slug": "Kevin-Smith",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Smith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118589"
                        ],
                        "name": "R. Achanta",
                        "slug": "R.-Achanta",
                        "structuredName": {
                            "firstName": "Radhakrishna",
                            "lastName": "Achanta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Achanta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144237098"
                        ],
                        "name": "G. Knott",
                        "slug": "G.-Knott",
                        "structuredName": {
                            "firstName": "Graham",
                            "lastName": "Knott",
                            "middleNames": [
                                "William"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Knott"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717736"
                        ],
                        "name": "P. Fua",
                        "slug": "P.-Fua",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Fua",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Fua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [19], this approach is extended to 3D image stacks, which can contain billions of voxels."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 57
                            }
                        ],
                        "text": "(d) Mitochondria extracted using the method described in [19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17867317,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "637772da5a954a884bc6e62fd41584dbfb9a5ae5",
            "isKey": false,
            "numCitedBy": 228,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": "It is becoming increasingly clear that mitochondria play an important role in neural function. Recent studies show mitochondrial morphology to be crucial to cellular physiology and synaptic function and a link between mitochondrial defects and neuro-degenerative diseases is strongly suspected. Electron microscopy (EM), with its very high resolution in all three directions, is one of the key tools to look more closely into these issues but the huge amounts of data it produces make automated analysis necessary. State-of-the-art computer vision algorithms designed to operate on natural 2-D images tend to perform poorly when applied to EM data for a number of reasons. First, the sheer size of a typical EM volume renders most modern segmentation schemes intractable. Furthermore, most approaches ignore important shape cues, relying only on local statistics that easily become confused when confronted with noise and textures inherent in the data. Finally, the conventional assumption that strong image gradients always correspond to object boundaries is violated by the clutter of distracting membranes. In this work, we propose an automated graph partitioning scheme that addresses these issues. It reduces the computational complexity by operating on supervoxels instead of voxels, incorporates shape features capable of describing the 3-D shape of the target objects, and learns to recognize the distinctive appearance of true boundaries. Our experiments demonstrate that our approach is able to segment mitochondria at a performance level close to that of a human annotator, and outperforms a state-of-the-art 3-D segmentation technique."
            },
            "slug": "Supervoxel-Based-Segmentation-of-Mitochondria-in-EM-Lucchi-Smith",
            "title": {
                "fragments": [],
                "text": "Supervoxel-Based Segmentation of Mitochondria in EM Image Stacks With Learned Shape Features"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work proposes an automated graph partitioning scheme that is able to segment mitochondria at a performance level close to that of a human annotator, and outperforms a state-of-the-art 3-D segmentation technique."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Medical Imaging"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706355"
                        ],
                        "name": "Vivek Kwatra",
                        "slug": "Vivek-Kwatra",
                        "structuredName": {
                            "firstName": "Vivek",
                            "lastName": "Kwatra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vivek Kwatra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39685930"
                        ],
                        "name": "A. Sch\u00f6dl",
                        "slug": "A.-Sch\u00f6dl",
                        "structuredName": {
                            "firstName": "Arno",
                            "lastName": "Sch\u00f6dl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sch\u00f6dl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21472040"
                        ],
                        "name": "Irfan Essa",
                        "slug": "Irfan-Essa",
                        "structuredName": {
                            "firstName": "Irfan",
                            "lastName": "Essa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Irfan Essa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713189"
                        ],
                        "name": "Greg Turk",
                        "slug": "Greg-Turk",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Turk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Greg Turk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688328"
                        ],
                        "name": "A. Bobick",
                        "slug": "A.-Bobick",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Bobick",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bobick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 76
                            }
                        ],
                        "text": "use a global optimization approach similar to the texture synthesis work of [14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6175301,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "55c3ecb47aebba55a9de761c0e4dc0fd6d8d28b0",
            "isKey": false,
            "numCitedBy": 1556,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we introduce a new algorithm for image and video texture synthesis. In our approach, patch regions from a sample image or video are transformed and copied to the output and then stitched together along optimal seams to generate a new (and typically larger) output. In contrast to other techniques, the size of the patch is not chosen a-priori, but instead a graph cut technique is used to determine the optimal patch region for any given offset between the input and output texture. Unlike dynamic programming, our graph cut technique for seam optimization is applicable in any dimension. We specifically explore it in 2D and 3D to perform video texture synthesis in addition to regular image synthesis. We present approximative offset search techniques that work well in conjunction with the presented patch size optimization. We show results for synthesizing regular, random, and natural images and videos. We also demonstrate how this method can be used to interactively merge different images to generate new scenes."
            },
            "slug": "Graphcut-textures:-image-and-video-synthesis-using-Kwatra-Sch\u00f6dl",
            "title": {
                "fragments": [],
                "text": "Graphcut textures: image and video synthesis using graph cuts"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "A new algorithm for image and video texture synthesis where patch regions from a sample image or video are transformed and copied to the output and then stitched together along optimal seams to generate a new (and typically larger) output."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Trans. Graph."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056091"
                        ],
                        "name": "M. Everingham",
                        "slug": "M.-Everingham",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Everingham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Everingham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145715698"
                        ],
                        "name": "Christopher K. I. Williams",
                        "slug": "Christopher-K.-I.-Williams",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Williams",
                            "middleNames": [
                                "K.",
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher K. I. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33652486"
                        ],
                        "name": "J. Winn",
                        "slug": "J.-Winn",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Winn",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Winn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4246903,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "82635fb63640ae95f90ee9bdc07832eb461ca881",
            "isKey": false,
            "numCitedBy": 11697,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "The Pascal Visual Object Classes (VOC) challenge is a benchmark in visual object category recognition and detection, providing the vision and machine learning communities with a standard dataset of images and annotation, and standard evaluation procedures. Organised annually from 2005 to present, the challenge and its associated dataset has become accepted as the benchmark for object detection.This paper describes the dataset and evaluation procedure. We review the state-of-the-art in evaluated methods for both classification and detection, analyse whether the methods are statistically different, what they are learning from the images (e.g. the object or its context), and what the methods find easy or confuse. The paper concludes with lessons learnt in the three year history of the challenge, and proposes directions for future improvement and extension."
            },
            "slug": "The-Pascal-Visual-Object-Classes-(VOC)-Challenge-Everingham-Gool",
            "title": {
                "fragments": [],
                "text": "The Pascal Visual Object Classes (VOC) Challenge"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The state-of-the-art in evaluated methods for both classification and detection are reviewed, whether the methods are statistically different, what they are learning from the images, and what the methods find easy or confuse."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46865129"
                        ],
                        "name": "Jianbo Shi",
                        "slug": "Jianbo-Shi",
                        "structuredName": {
                            "firstName": "Jianbo",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianbo Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652147"
                        ],
                        "name": "J. Malik",
                        "slug": "J.-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 19
                            }
                        ],
                        "text": "Table 1 provides a qualitative and quanti-\ntative summary of the reviewed methods, including their relative\nperformance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Superpixels, segmentation, clustering, k-means\n\u00c7"
                    },
                    "intents": []
                }
            ],
            "corpusId": 14848918,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b94c7ff9532ab26c3aedbee3988ec4c7a237c173",
            "isKey": false,
            "numCitedBy": 12819,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel approach for solving the perceptual grouping problem in vision. Rather than focusing on local features and their consistencies in the image data, our approach aims at extracting the global impression of an image. We treat image segmentation as a graph partitioning problem and propose a novel global criterion, the normalized cut, for segmenting the graph. The normalized cut criterion measures both the total dissimilarity between the different groups as well as the total similarity within the groups. We show that an efficient computational technique based on a generalized eigenvalue problem can be used to optimize this criterion. We have applied this approach to segmenting static images and found results very encouraging."
            },
            "slug": "Normalized-cuts-and-image-segmentation-Shi-Malik",
            "title": {
                "fragments": [],
                "text": "Normalized cuts and image segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work treats image segmentation as a graph partitioning problem and proposes a novel global criterion, the normalized cut, for segmenting the graph, which measures both the total dissimilarity between the different groups as well as the total similarity within the groups."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2807482"
                        ],
                        "name": "Timoth\u00e9e Cour",
                        "slug": "Timoth\u00e9e-Cour",
                        "structuredName": {
                            "firstName": "Timoth\u00e9e",
                            "lastName": "Cour",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Timoth\u00e9e Cour"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2475859"
                        ],
                        "name": "F. B\u00e9n\u00e9zit",
                        "slug": "F.-B\u00e9n\u00e9zit",
                        "structuredName": {
                            "firstName": "Florence",
                            "lastName": "B\u00e9n\u00e9zit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. B\u00e9n\u00e9zit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46865129"
                        ],
                        "name": "Jianbo Shi",
                        "slug": "Jianbo-Shi",
                        "structuredName": {
                            "firstName": "Jianbo",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianbo Shi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Table 1 provides a qualitative and quanti-\ntative summary of the reviewed methods, including their relative\nperformance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6830366,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b820164b7597c186232e90f076b95382a36ed0c",
            "isKey": false,
            "numCitedBy": 615,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a multiscale spectral image segmentation algorithm. In contrast to most multiscale image processing, this algorithm works on multiple scales of the image in parallel, without iteration, to capture both coarse and fine level details. The algorithm is computationally efficient, allowing to segment large images. We use the normalized cut graph partitioning framework of image segmentation. We construct a graph encoding pairwise pixel affinity, and partition the graph for image segmentation. We demonstrate that large image graphs can be compressed into multiple scales capturing image structure at increasingly large neighborhood. We show that the decomposition of the image segmentation graph into different scales can be determined by ecological statistics on the image grouping cues. Our segmentation algorithm works simultaneously across the graph scales, with an inter-scale constraint to ensure communication and consistency between the segmentations at each scale. As the results show, we incorporate long-range connections with linear-time complexity, providing high-quality segmentations efficiently. Images that previously could not be processed because of their size have been accurately segmented thanks to this method."
            },
            "slug": "Spectral-segmentation-with-multiscale-graph-Cour-B\u00e9n\u00e9zit",
            "title": {
                "fragments": [],
                "text": "Spectral segmentation with multiscale graph decomposition"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The segmentation algorithm works simultaneously across the graph scales, with an inter-scale constraint to ensure communication and consistency between the segmentations at each scale, and incorporates long-range connections with linear-time complexity, providing high-quality segmentations efficiently."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2143685864"
                        ],
                        "name": "Yi Yang",
                        "slug": "Yi-Yang",
                        "structuredName": {
                            "firstName": "Yi",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yi Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2555602"
                        ],
                        "name": "S. Hallman",
                        "slug": "S.-Hallman",
                        "structuredName": {
                            "firstName": "Sam",
                            "lastName": "Hallman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hallman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770537"
                        ],
                        "name": "D. Ramanan",
                        "slug": "D.-Ramanan",
                        "structuredName": {
                            "firstName": "Deva",
                            "lastName": "Ramanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ramanan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143800213"
                        ],
                        "name": "Charless C. Fowlkes",
                        "slug": "Charless-C.-Fowlkes",
                        "structuredName": {
                            "firstName": "Charless",
                            "lastName": "Fowlkes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charless C. Fowlkes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 165
                            }
                        ],
                        "text": "They have become key building blocks of many computer vision algorithms, such as top scoring multiclass object segmentation entries to the PASCAL VOC Challenge [9], [29], [11], depth estimation [30], segmentation [16], body model estimation [22], and object localization [9]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 3505099,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3044cb9dc9a364c6ec8d85fdc6dc4f9d14efcc20",
            "isKey": false,
            "numCitedBy": 113,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We formulate a layered model for object detection and multi-class segmentation. Our system uses the output of a bank of object detectors in order to define shape priors for support masks and then estimates appearance, depth ordering and labeling of pixels in the image. We train our system on the PASCAL segmentation challenge dataset and show good test results with state of the art performance in several categories including segmenting humans."
            },
            "slug": "Layered-object-detection-for-multi-class-Yang-Hallman",
            "title": {
                "fragments": [],
                "text": "Layered object detection for multi-class segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A layered model for object detection and multi-class segmentation that uses the output of a bank of object detectors in order to define shape priors for support masks and then estimates appearance, depth ordering and labeling of pixels in the image."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111190090"
                        ],
                        "name": "Yin Li",
                        "slug": "Yin-Li",
                        "structuredName": {
                            "firstName": "Yin",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yin Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152147500"
                        ],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2088295"
                        ],
                        "name": "Chi-Keung Tang",
                        "slug": "Chi-Keung-Tang",
                        "structuredName": {
                            "firstName": "Chi-Keung",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chi-Keung Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144154486"
                        ],
                        "name": "H. Shum",
                        "slug": "H.-Shum",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Shum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Shum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 7
                            }
                        ],
                        "text": "Despite its simplicity, SLIC adheres to boundaries as well as or better than previous methods."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1904479,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4f51d84009a1ec30dffa5ab8a1c3214f669086cf",
            "isKey": false,
            "numCitedBy": 650,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present Lazy Snapping, an interactive image cutout tool. Lazy Snapping separates coarse and fine scale processing, making object specification and detailed adjustment easy. Moreover, Lazy Snapping provides instant visual feedback, snapping the cutout contour to the true object boundary efficiently despite the presence of ambiguous or low contrast edges. Instant feedback is made possible by a novel image segmentation algorithm which combines graph cut with pre-computed over-segmentation. A set of intuitive user interface (UI) tools is designed and implemented to provide flexible control and editing for the users. Usability studies indicate that Lazy Snapping provides a better user experience and produces better segmentation results than the state-of-the-art interactive image cutout tool, Magnetic Lasso in Adobe Photoshop."
            },
            "slug": "Lazy-snapping-Li-Sun",
            "title": {
                "fragments": [],
                "text": "Lazy snapping"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Usability studies indicate that Lazy Snapping provides a better user experience and produces better segmentation results than the state-of-the-art interactive image cutout tool, Magnetic Lasso in Adobe Photoshop."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Trans. Graph."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692688"
                        ],
                        "name": "Yuri Boykov",
                        "slug": "Yuri-Boykov",
                        "structuredName": {
                            "firstName": "Yuri",
                            "lastName": "Boykov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuri Boykov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144197071"
                        ],
                        "name": "M. Jolly",
                        "slug": "M.-Jolly",
                        "structuredName": {
                            "firstName": "Marie-Pierre",
                            "lastName": "Jolly",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Jolly"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 68
                            }
                        ],
                        "text": "Many popular graph-based segmentation approaches such as graph cuts [3] become increasingly expensive as more nodes are added to the graph, limiting image size in practice."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2245438,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0d3b177e8d027d44c191e739a3a70ccacc2eac82",
            "isKey": false,
            "numCitedBy": 4175,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe a new technique for general purpose interactive segmentation of N-dimensional images. The user marks certain pixels as \"object\" or \"background\" to provide hard constraints for segmentation. Additional soft constraints incorporate both boundary and region information. Graph cuts are used to find the globally optimal segmentation of the N-dimensional image. The obtained solution gives the best balance of boundary and region properties among all segmentations satisfying the constraints. The topology of our segmentation is unrestricted and both \"object\" and \"background\" segments may consist of several isolated parts. Some experimental results are presented in the context of photo/video editing and medical image segmentation. We also demonstrate an interesting Gestalt example. A fast implementation of our segmentation method is possible via a new max-flow algorithm."
            },
            "slug": "Interactive-graph-cuts-for-optimal-boundary-&-of-in-Boykov-Jolly",
            "title": {
                "fragments": [],
                "text": "Interactive graph cuts for optimal boundary & region segmentation of objects in N-D images"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "A new technique for general purpose interactive segmentation of N-dimensional images where the user marks certain pixels as \"object\" or \"background\" to provide hard constraints for segmentation."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685020"
                        ],
                        "name": "D. Comaniciu",
                        "slug": "D.-Comaniciu",
                        "structuredName": {
                            "firstName": "Dorin",
                            "lastName": "Comaniciu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Comaniciu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145776090"
                        ],
                        "name": "P. Meer",
                        "slug": "P.-Meer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Meer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Meer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 22
                            }
                        ],
                        "text": "Superpixels are\ncreated by minimizing a cost function defined over the graph."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 691081,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74f4ecc3e4e5b91fbb54330b285ed5214afe2001",
            "isKey": false,
            "numCitedBy": 11481,
            "numCiting": 122,
            "paperAbstract": {
                "fragments": [],
                "text": "A general non-parametric technique is proposed for the analysis of a complex multimodal feature space and to delineate arbitrarily shaped clusters in it. The basic computational module of the technique is an old pattern recognition procedure: the mean shift. For discrete data, we prove the convergence of a recursive mean shift procedure to the nearest stationary point of the underlying density function and, thus, its utility in detecting the modes of the density. The relation of the mean shift procedure to the Nadaraya-Watson estimator from kernel regression and the robust M-estimators; of location is also established. Algorithms for two low-level vision tasks discontinuity-preserving smoothing and image segmentation - are described as applications. In these algorithms, the only user-set parameter is the resolution of the analysis, and either gray-level or color images are accepted as input. Extensive experimental results illustrate their excellent performance."
            },
            "slug": "Mean-Shift:-A-Robust-Approach-Toward-Feature-Space-Comaniciu-Meer",
            "title": {
                "fragments": [],
                "text": "Mean Shift: A Robust Approach Toward Feature Space Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is proved the convergence of a recursive mean shift procedure to the nearest stationary point of the underlying density function and, thus, its utility in detecting the modes of the density."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144891282"
                        ],
                        "name": "David R. Martin",
                        "slug": "David-R.-Martin",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Martin",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David R. Martin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143800213"
                        ],
                        "name": "Charless C. Fowlkes",
                        "slug": "Charless-C.-Fowlkes",
                        "structuredName": {
                            "firstName": "Charless",
                            "lastName": "Fowlkes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charless C. Fowlkes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2082299938"
                        ],
                        "name": "D. Tal",
                        "slug": "D.-Tal",
                        "structuredName": {
                            "firstName": "Doron",
                            "lastName": "Tal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Tal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Superpixels, segmentation, clustering, k-means\n\u00c7"
                    },
                    "intents": []
                }
            ],
            "corpusId": 64193,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9a1ed876196ec9733acb1daa6d65e35ff0414291",
            "isKey": false,
            "numCitedBy": 6039,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a database containing 'ground truth' segmentations produced by humans for images of a wide variety of natural scenes. We define an error measure which quantifies the consistency between segmentations of differing granularities and find that different human segmentations of the same image are highly consistent. Use of this dataset is demonstrated in two applications: (1) evaluating the performance of segmentation algorithms and (2) measuring probability distributions associated with Gestalt grouping factors as well as statistics of image region properties."
            },
            "slug": "A-database-of-human-segmented-natural-images-and-to-Martin-Fowlkes",
            "title": {
                "fragments": [],
                "text": "A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "A database containing 'ground truth' segmentations produced by humans for images of a wide variety of natural scenes is presented and an error measure is defined which quantifies the consistency between segmentations of differing granularities."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722831"
                        ],
                        "name": "C. Elkan",
                        "slug": "C.-Elkan",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Elkan",
                            "middleNames": [
                                "Peter"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Elkan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 123
                            }
                        ],
                        "text": "In contrast, the trivial upper bound for the classical k-means algorithm is O\u00f0kN\u00de [17], and the practical time complexity is O\u00f0NkI\u00de [6], where I is the number of iterations required for convergence."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 7
                            }
                        ],
                        "text": "bounds [6], these methods are very general in nature."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 118
                            }
                        ],
                        "text": "the trivial upper bound for the classical k-means algorithm is O\u00f0k\u00de [17], and the practical time complexity is O\u00f0NkI\u00de [6], where"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1261520,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b8d8f2fb88e03f8f3ad01efbfef52718b70d104",
            "isKey": true,
            "numCitedBy": 770,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "The k-means algorithm is by far the most widely used method for discovering clusters in data. We show how to accelerate it dramatically, while still always computing exactly the same result as the standard algorithm. The accelerated algorithm avoids unnecessary distance calculations by applying the triangle inequality in two different ways, and by keeping track of lower and upper bounds for distances between points and centers. Experiments show that the new algorithm is effective for datasets with up to 1000 dimensions, and becomes more and more effective as the number k of clusters increases. For k \u2265 20 it is many times faster than the best previously known accelerated k-means method."
            },
            "slug": "Using-the-Triangle-Inequality-to-Accelerate-k-Means-Elkan",
            "title": {
                "fragments": [],
                "text": "Using the Triangle Inequality to Accelerate k-Means"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "The accelerated k-means algorithm is shown how to accelerate dramatically, while still always computing exactly the same result as the standard algorithm, and is effective for datasets with up to 1000 dimensions, and becomes more and more effective as the number k of clusters increases."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687524"
                        ],
                        "name": "A. Vedaldi",
                        "slug": "A.-Vedaldi",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Vedaldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vedaldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715959"
                        ],
                        "name": "Stefano Soatto",
                        "slug": "Stefano-Soatto",
                        "structuredName": {
                            "firstName": "Stefano",
                            "lastName": "Soatto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stefano Soatto"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 154
                            }
                        ],
                        "text": "However, the boundary adherence of NC05 is\nrelatively poor and it is the slowest among the methods\n(particularly for large images), although attempts to speed up the algorithm exist [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Superpixels, segmentation, clustering, k-means\n\u00c7"
                    },
                    "intents": []
                }
            ],
            "corpusId": 8489515,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b6ccf4cb35365b81bb19e034dfdbf2aafe62b842",
            "isKey": false,
            "numCitedBy": 782,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We show that the complexity of the recently introduced medoid-shift algorithm in clustering N points is O(N 2), with a small constant, if the underlying distance is Euclidean. This makes medoid shift considerably faster than mean shift, contrarily to what previously believed. We then exploit kernel methods to extend both mean shift and the improved medoid shift to a large family of distances, with complexity bounded by the effective rank of the resulting kernel matrix, and with explicit regularization constraints. Finally, we show that, under certain conditions, medoid shift fails to cluster data points belonging to the same mode, resulting in over-fragmentation. We propose remedies for this problem, by introducing a novel, simple and extremely efficient clustering algorithm, called quick shift, that explicitly trades off under- and over-fragmentation. Like medoid shift, quick shift operates in non-Euclidean spaces in a straightforward manner. We also show that the accelerated medoid shift can be used to initialize mean shift for increased efficiency. We illustrate our algorithms to clustering data on manifolds, image segmentation, and the automatic discovery of visual categories."
            },
            "slug": "Quick-Shift-and-Kernel-Methods-for-Mode-Seeking-Vedaldi-Soatto",
            "title": {
                "fragments": [],
                "text": "Quick Shift and Kernel Methods for Mode Seeking"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "It is shown that the complexity of the recently introduced medoid-shift algorithm in clustering N points is O(N 2), with a small constant, if the underlying distance is Euclidean, which makes medoid shift considerably faster than mean shift, contrarily to what previously believed."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143626870"
                        ],
                        "name": "T. Kanungo",
                        "slug": "T.-Kanungo",
                        "structuredName": {
                            "firstName": "Tapas",
                            "lastName": "Kanungo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanungo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709509"
                        ],
                        "name": "D. Mount",
                        "slug": "D.-Mount",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mount",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mount"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712586"
                        ],
                        "name": "N. Netanyahu",
                        "slug": "N.-Netanyahu",
                        "structuredName": {
                            "firstName": "Nathan",
                            "lastName": "Netanyahu",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Netanyahu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718753"
                        ],
                        "name": "C. Piatko",
                        "slug": "C.-Piatko",
                        "structuredName": {
                            "firstName": "Christine",
                            "lastName": "Piatko",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Piatko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37746341"
                        ],
                        "name": "R. Silverman",
                        "slug": "R.-Silverman",
                        "structuredName": {
                            "firstName": "Ruth",
                            "lastName": "Silverman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Silverman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736712"
                        ],
                        "name": "A. Wu",
                        "slug": "A.-Wu",
                        "structuredName": {
                            "firstName": "Angela",
                            "lastName": "Wu",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Wu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "local cluster swapping [12], and by setting lower and upper"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1044133,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c5c44f42cca460f0d86e77fda448770684b3c3ca",
            "isKey": false,
            "numCitedBy": 601,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "In k-means clustering we are given a set of n data points in d-dimensional space Rd and an integer k, and the problem is to determine a set of k points in \u00d3C;d, called centers, to minimize the mean squared distance from each data point to its nearest center. No exact polynomial-time algorithms are known for this problem. Although asymptotically efficient approximation algorithms exist, these algorithms are not practical due to the extremely high constant factors involved. There are many heuristics that are used in practice, but we know of no bounds on their performance.We consider the question of whether there exists a simple and practical approximation algorithm for k-means clustering. We present a local improvement heuristic based on swapping centers in and out. We prove that this yields a (9+\u03b5)-approximation algorithm. We show that the approximation factor is almost tight, by giving an example for which the algorithm achieves an approximation factor of (9-\u03b5). To establish the practical value of the heuristic, we present an empirical study that shows that, when combined with Lloyd's algorithm, this heuristic performs quite well in practice."
            },
            "slug": "A-local-search-approximation-algorithm-for-k-means-Kanungo-Mount",
            "title": {
                "fragments": [],
                "text": "A local search approximation algorithm for k-means clustering"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work considers the question of whether there exists a simple and practical approximation algorithm for k-means clustering, and presents a local improvement heuristic based on swapping centers in and out that yields a (9+\u03b5)-approximation algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "SCG '02"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "101639166"
                        ],
                        "name": "S. P. Lloyd",
                        "slug": "S.-P.-Lloyd",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Lloyd",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. P. Lloyd"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10833328,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9241ea3d8cb85633d314ecb74b31567b8e73f6af",
            "isKey": false,
            "numCitedBy": 11647,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "It has long been realized that in pulse-code modulation (PCM), with a given ensemble of signals to handle, the quantum values should be spaced more closely in the voltage regions where the signal amplitude is more likely to fall. It has been shown by Panter and Dite that, in the limit as the number of quanta becomes infinite, the asymptotic fractional density of quanta per unit voltage should vary as the one-third power of the probability density per unit voltage of signal amplitudes. In this paper the corresponding result for any finite number of quanta is derived; that is, necessary conditions are found that the quanta and associated quantization intervals of an optimum finite quantization scheme must satisfy. The optimization criterion used is that the average quantization noise power be a minimum. It is shown that the result obtained here goes over into the Panter and Dite result as the number of quanta become large. The optimum quautization schemes for 2^{b} quanta, b=1,2, \\cdots, 7 , are given numerically for Gaussian and for Laplacian distribution of signal amplitudes."
            },
            "slug": "Least-squares-quantization-in-PCM-Lloyd",
            "title": {
                "fragments": [],
                "text": "Least squares quantization in PCM"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The corresponding result for any finite number of quanta is derived; that is, necessary conditions are found that the quanta and associated quantization intervals of an optimum finite quantization scheme must satisfy."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2123128590"
                        ],
                        "name": "Amit Kumar",
                        "slug": "Amit-Kumar",
                        "structuredName": {
                            "firstName": "Amit",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amit Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1787471"
                        ],
                        "name": "Yogish Sabharwal",
                        "slug": "Yogish-Sabharwal",
                        "structuredName": {
                            "firstName": "Yogish",
                            "lastName": "Sabharwal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yogish Sabharwal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703654"
                        ],
                        "name": "Sandeep Sen",
                        "slug": "Sandeep-Sen",
                        "structuredName": {
                            "firstName": "Sandeep",
                            "lastName": "Sen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sandeep Sen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7808035,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3f1fdbd748f757541ed04f607f996a74a8c0711b",
            "isKey": false,
            "numCitedBy": 206,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We present the first linear time (1 + /spl epsiv/)-approximation algorithm for the k-means problem for fixed k and /spl epsiv/. Our algorithm runs in O(nd) time, which is linear in the size of the input. Another feature of our algorithm is its simplicity - the only technique involved is random sampling."
            },
            "slug": "A-simple-linear-time-(1-+-/spl-algorithm-for-in-any-Kumar-Sabharwal",
            "title": {
                "fragments": [],
                "text": "A simple linear time (1 + /spl epsiv/)-approximation algorithm for k-means clustering in any dimensions"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "This work presents the first linear time (1 + /spl epsiv/)-approximation algorithm for the k-means problem for fixed k and /spl Epsiv/, which runs in O(nd) time."
            },
            "venue": {
                "fragments": [],
                "text": "45th Annual IEEE Symposium on Foundations of Computer Science"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145089978"
                        ],
                        "name": "D. Damen",
                        "slug": "D.-Damen",
                        "structuredName": {
                            "firstName": "Dima",
                            "lastName": "Damen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Damen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1967104"
                        ],
                        "name": "David C. Hogg",
                        "slug": "David-C.-Hogg",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hogg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David C. Hogg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Table 1 provides a qualitative and quanti-\ntative summary of the reviewed methods, including their relative\nperformance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 64711781,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dd116435b6f93e803e8db708ad4d0bce71499982",
            "isKey": false,
            "numCitedBy": 1554,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Computer-Vision-and-Pattern-Recognition-(CVPR)-Damen-Hogg",
            "title": {
                "fragments": [],
                "text": "Computer Vision and Pattern Recognition (CVPR)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2141732326"
                        ],
                        "name": "Jianguo Zhang",
                        "slug": "Jianguo-Zhang",
                        "structuredName": {
                            "firstName": "Jianguo",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianguo Zhang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Superpixels, segmentation, clustering, k-means\n\u00c7"
                    },
                    "intents": []
                }
            ],
            "corpusId": 63925014,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "0ec48ac86456cea3d6d6172ca81ef68e98b21a61",
            "isKey": false,
            "numCitedBy": 3322,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-PASCAL-Visual-Object-Classes-Challenge-Zhang",
            "title": {
                "fragments": [],
                "text": "The PASCAL Visual Object Classes Challenge"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Table 1 provides a qualitative and quanti-\ntative summary of the reviewed methods, including their relative\nperformance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Superpixels, segmentation, clustering, k-means\n\u00c7"
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Efficient Graph-Based Image Segmentation Int'l J. Computer Vision"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Lloyd . Least squares quantization in PCM"
            },
            "venue": {
                "fragments": [],
                "text": "ACM Transactions on Graphics ( SIGGRAPH )"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Mount , Nathan S . Netanyahu , Christine D . Piatko , Ruth Silverman , and Angela Y . Wu . A local search approximation algorithm for k - means clustering"
            },
            "venue": {
                "fragments": [],
                "text": "Interna - tional Journal of Computer Vision ( IJCV )"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 57
                            }
                        ],
                        "text": "using prime number length sampling [27], random sampling [13],"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Simple Linear Time (1+e)- Approximation Algorithm for K-Means Clustering in Any Dimensions"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Ann. IEEE Symp. Foundations of Computer Science"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 35
                            }
                        ],
                        "text": "using prime number length sampling [27], random sampling [13],"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Local K-Means Algorithm for Color Image Quantization"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Graphics Interface"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Local k-means algorithm for color image quantization. Graphics Interface"
            },
            "venue": {
                "fragments": [],
                "text": "Local k-means algorithm for color image quantization. Graphics Interface"
            },
            "year": 1995
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 17,
            "methodology": 12
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 37,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/SLIC-Superpixels-Compared-to-State-of-the-Art-Achanta-Shaji/b3c785b99ec147049caa47f707f337b717705970?sort=total-citations"
}