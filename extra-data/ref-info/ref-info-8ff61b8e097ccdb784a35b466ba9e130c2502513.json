{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145833095"
                        ],
                        "name": "S. Kothari",
                        "slug": "S.-Kothari",
                        "structuredName": {
                            "firstName": "Suresh",
                            "lastName": "Kothari",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kothari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681982"
                        ],
                        "name": "H. Oh",
                        "slug": "H.-Oh",
                        "structuredName": {
                            "firstName": "Heekuck",
                            "lastName": "Oh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Oh"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 177751,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dbc0a468ab103ae29717703d4aa9f682f6a2b664",
            "isKey": false,
            "numCitedBy": 15338,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Neural-Networks-for-Pattern-Recognition-Kothari-Oh",
            "title": {
                "fragments": [],
                "text": "Neural Networks for Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Adv. Comput."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2272582"
                        ],
                        "name": "L. Vlacic",
                        "slug": "L.-Vlacic",
                        "structuredName": {
                            "firstName": "Ljubo",
                            "lastName": "Vlacic",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Vlacic"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 59656950,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a170263d43fc173d8a2f9dd5788c6412709e250",
            "isKey": false,
            "numCitedBy": 96,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-and-Soft-Computing,-Support-Vector-Neural-Vlacic",
            "title": {
                "fragments": [],
                "text": "Learning and Soft Computing, Support Vector Machines, Neural Networks, and Fuzzy Logic Models, Vojislav Kecman; MIT Press, Cambridge, MA, 2001, ISBN 0-262-11255-8, 2001, pp 578"
            },
            "venue": {
                "fragments": [],
                "text": "Neurocomputing"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685083"
                        ],
                        "name": "N. Cristianini",
                        "slug": "N.-Cristianini",
                        "structuredName": {
                            "firstName": "Nello",
                            "lastName": "Cristianini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cristianini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404459229"
                        ],
                        "name": "J. Shawe-Taylor",
                        "slug": "J.-Shawe-Taylor",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shawe-Taylor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shawe-Taylor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14727192,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5c04f8002e24a8c09bfbfedca3c6c346fe1e5d53",
            "isKey": false,
            "numCitedBy": 13352,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "From the publisher: This is the first comprehensive introduction to Support Vector Machines (SVMs), a new generation learning system based on recent advances in statistical learning theory. SVMs deliver state-of-the-art performance in real-world applications such as text categorisation, hand-written character recognition, image classification, biosequences analysis, etc., and are now established as one of the standard tools for machine learning and data mining. Students will find the book both stimulating and accessible, while practitioners will be guided smoothly through the material required for a good grasp of the theory and its applications. The concepts are introduced gradually in accessible and self-contained stages, while the presentation is rigorous and thorough. Pointers to relevant literature and web sites containing software ensure that it forms an ideal starting point for further study. Equally, the book and its associated web site will guide practitioners to updated literature, new applications, and on-line software."
            },
            "slug": "An-Introduction-to-Support-Vector-Machines-and-Cristianini-Shawe-Taylor",
            "title": {
                "fragments": [],
                "text": "An Introduction to Support Vector Machines and Other Kernel-based Learning Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "This is the first comprehensive introduction to Support Vector Machines (SVMs), a new generation learning system based on recent advances in statistical learning theory, and will guide practitioners to updated literature, new applications, and on-line software."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144108246"
                        ],
                        "name": "D. Ruppert",
                        "slug": "D.-Ruppert",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Ruppert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ruppert"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118901444,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5176a2f31dace77db9135dde7020d2c37f78cca0",
            "isKey": false,
            "numCitedBy": 11811,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "In the words of the authors, the goal of this book was to \u201cbring together many of the important new ideas in learning, and explain them in a statistical framework.\u201d The authors have been quite successful in achieving this objective, and their work is a welcome addition to the statistics and learning literatures. Statistics has always been interdisciplinary, borrowing ideas from diverse \u008e elds and repaying the debt with contributions, both theoretical and practical, to the other intellectual disciplines. For statistical learning, this cross-fertilization is especially noticeable. This book is a valuable resource, both for the statistician needing an introduction to machine learning and related \u008e elds and for the computer scientist wishing to learn more about statistics. Statisticians will especially appreciate that it is written in their own language. The level of the book is roughly that of a second-year doctoral student in statistics, and it will be useful as a textbook for such students. In a stimulating article, Breiman (2001) argued that statistics has been focused too much on a \u201cdata modeling culture,\u201d where the model is paramount. Breiman argued instead for an \u201calgorithmic modeling culture,\u201d with emphasis on black-box types of prediction. Breiman\u2019s article is controversial, and in his discussion, Efron objects that \u201cprediction is certainly an interesting subject, but Leo\u2019s paper overstates both its role and our profession\u2019s lack of interest in it.\u201d Although I mostly agree with Efron, I worry that the courses offered by most statistics departments include little, if any, treatment of statistical learning and prediction. (Stanford, where Efron and the authors of this book teach, is an exception.) Graduate students in statistics certainly need to know more than they do now about prediction, machine learning, statistical learning, and data mining (not disjoint subjects). I hope that graduate courses covering the topics of this book will become more common in statistics curricula. Most of the book is focused on supervised learning, where one has inputs and outputs from some system and wishes to predict unknown outputs corresponding to known inputs. The methods discussed for supervised learning include linear and logistic regression; basis expansion, such as splines and wavelets; kernel techniques, such as local regression, local likelihood, and radial basis functions; neural networks; additive models; decision trees based on recursive partitioning, such as CART; and support vector machines. There is a \u008e nal chapter on unsupervised learning, including association rules, cluster analysis, self-organizing maps, principal components and curves, and independent component analysis. Many statisticians will be unfamiliar with at least some of these algorithms. Association rules are popular for mining commercial data in what is called \u201cmarket basket analysis.\u201d The aim is to discover types of products often purchased together. Such knowledge can be used to develop marketing strategies, such as store or catalog layouts. Self-organizing maps (SOMs) involve essentially constrained k-means clustering, where prototypes are mapped to a two-dimensional curved coordinate system. Independent components analysis is similar to principal components analysis and factor analysis, but it uses higher-order moments to achieve independence, not merely zero correlation between components. A strength of the book is the attempt to organize a plethora of methods into a coherent whole. The relationships among the methods are emphasized. I know of no other book that covers so much ground. Of course, with such broad coverage, it is not possible to cover any single topic in great depth, so this book will encourage further reading. Fortunately, each chapter includes bibliographic notes surveying the recent literature. These notes and the extensive references provide a good introduction to the learning literature, including much outside of statistics. The book might be more suitable as a textbook if less material were covered in greater depth; however, such a change would compromise the book\u2019s usefulness as a reference, and so I am happier with the book as it was written."
            },
            "slug": "The-Elements-of-Statistical-Learning:-Data-Mining,-Ruppert",
            "title": {
                "fragments": [],
                "text": "The Elements of Statistical Learning: Data Mining, Inference, and Prediction"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This book is a valuable resource, both for the statistician needing an introduction to machine learning and related \u008e elds and for the computer scientist wishing to learn more about statistics, and statisticians will especially appreciate that it is written in their own language."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143797114"
                        ],
                        "name": "A. Pinkus",
                        "slug": "A.-Pinkus",
                        "structuredName": {
                            "firstName": "Allan",
                            "lastName": "Pinkus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pinkus"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16800260,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "6e37979d2a910e8a2337927731619fd789a5213b",
            "isKey": false,
            "numCitedBy": 776,
            "numCiting": 194,
            "paperAbstract": {
                "fragments": [],
                "text": "In this survey we discuss various approximation-theoretic problems that arise in the multilayer feedforward perceptron (MLP) model in neural networks. The MLP model is one of the more popular and practical of the many neural network models. Mathematically it is also one of the simpler models. Nonetheless the mathematics of this model is not well understood, and many of these problems are approximation-theoretic in character. Most of the research we will discuss is of very recent vintage. We will report on what has been done and on various unanswered questions. We will not be presenting practical (algorithmic) methods. We will, however, be exploring the capabilities and limitations of this model."
            },
            "slug": "Approximation-theory-of-the-MLP-model-in-neural-Pinkus",
            "title": {
                "fragments": [],
                "text": "Approximation theory of the MLP model in neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "This survey discusses various approximation-theoretic problems that arise in the multilayer feedforward perceptron (MLP) model in neural networks."
            },
            "venue": {
                "fragments": [],
                "text": "Acta Numerica"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70310502"
                        ],
                        "name": "A. Beauville",
                        "slug": "A.-Beauville",
                        "structuredName": {
                            "firstName": "Arnaud",
                            "lastName": "Beauville",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Beauville"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5864470,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a189a5b6c8d72687a14fc95c3c17f8df23146f96",
            "isKey": false,
            "numCitedBy": 97,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "The moduli spaces of vector bundles on a compact Riemann surface carry a natural line bundle, the determinant bundle. The sections of this line bundle and its multiples constitute a non-abelian generalization of the classical theta functions. New ideas coming from mathematical physics have shed a new light on these spaces of sections\u2014allowing notably to compute their dimension (Verlinde\u2019s formula). This survey paper is devoted to giving an overview of these ideas and of the most important recent results on the subject."
            },
            "slug": "Vector-bundles-on-curves-and-generalized-theta-and-Beauville",
            "title": {
                "fragments": [],
                "text": "Vector bundles on curves and generalized theta functions: recent results and open problems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34911188"
                        ],
                        "name": "S. Smale",
                        "slug": "S.-Smale",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Smale",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Smale"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1002516,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d8cc06f9035fd11cf30ecd1b36266cc7b31c4df1",
            "isKey": false,
            "numCitedBy": 542,
            "numCiting": 81,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract Learning is key to developing systems tailored to a broad range of data analysis and information extraction tasks. We outline the mathematical foundations of learning theory and describe a key algorithm of it."
            },
            "slug": "The-Mathematics-of-Learning:-Dealing-with-Data-Poggio-Smale",
            "title": {
                "fragments": [],
                "text": "The Mathematics of Learning: Dealing with Data"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "The mathematical foundations of learning theory are outlined and a key algorithm of it is described, which is key to developing systems tailored to a broad range of data analysis and information extraction tasks."
            },
            "venue": {
                "fragments": [],
                "text": "2005 International Conference on Neural Networks and Brain"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102056092"
                        ],
                        "name": "A. Tsuchiya",
                        "slug": "A.-Tsuchiya",
                        "structuredName": {
                            "firstName": "Akihiro",
                            "lastName": "Tsuchiya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Tsuchiya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49128415"
                        ],
                        "name": "Y. Kanie",
                        "slug": "Y.-Kanie",
                        "structuredName": {
                            "firstName": "Yukihiro",
                            "lastName": "Kanie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Kanie"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 204007017,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "2b8929a222e131f1fbc2ec9a96593d2ee9134d6c",
            "isKey": false,
            "numCitedBy": 174,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Vertex-operators-in-conformal-field-theory-on-P(1)-Tsuchiya-Kanie",
            "title": {
                "fragments": [],
                "text": "Vertex operators in conformal field theory on P(1) and monodromy representations of braid group"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 33
                            }
                        ],
                        "text": "More importantly, \nthe authors suggest that several courses based on this book has been taught successfully at both undergraduate \nand graduate levels at the State University of New York at Buffalo."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Introduction to Algorithms, second edition 3Notice that if fully unbounded parallelism is physically realizable, we can solve NP-complete problems in polynomial time"
            },
            "venue": {
                "fragments": [],
                "text": "Introduction to Algorithms, second edition 3Notice that if fully unbounded parallelism is physically realizable, we can solve NP-complete problems in polynomial time"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 25
                            }
                        ],
                        "text": "More importantly, \nthe authors suggest that several courses based on this book has been taught successfully at both undergraduate \nand graduate levels at the State University of New York at Buffalo."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Algorithhms in C"
            },
            "venue": {
                "fragments": [],
                "text": "Algorithhms in C"
            },
            "year": 1998
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 10,
        "totalPages": 1
    },
    "page_url": "https://www.semanticscholar.org/paper/Learning-with-Kernels:-Support-Vector-Machines,-and-Atiya/8ff61b8e097ccdb784a35b466ba9e130c2502513?sort=total-citations"
}