{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144556482"
                        ],
                        "name": "Saurabh Singh",
                        "slug": "Saurabh-Singh",
                        "structuredName": {
                            "firstName": "Saurabh",
                            "lastName": "Singh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Saurabh Singh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726095131"
                        ],
                        "name": "A. Gupta",
                        "slug": "A.-Gupta",
                        "structuredName": {
                            "firstName": "Abhinav",
                            "lastName": "Gupta",
                            "middleNames": [
                                "Kumar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 29
                            }
                        ],
                        "text": "Recently, several approaches [5, 6, 11, 12, 15, 23, 26, 27] have proposed mining visual data for discriminative mid-level visual elements, i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 78
                            }
                        ],
                        "text": ", scene categories [12] or GPS coordinates [5] (but can also run unsupervised [23]), and have been recently used for tasks including image classification [12, 23, 27], object detection [6], visual data mining [5, 15], action recognition [11], and geometry estimation [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 82
                            }
                        ],
                        "text": "Finally, we include the algorithm of [5], which is a weakly supervised version of [23], except that knn is being used for initialization instead of kmeans."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 16
                            }
                        ],
                        "text": "However, unlike [23], which makes the ad-hoc choice of 5 positive examples, our algorithm allows each cluster to select the optimal number of positives based on the decision boundary."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 19
                            }
                        ],
                        "text": "Several approaches [5, 6, 12, 23] have been proposed to discover mid-level visual elements, that are both 1) representative, i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 28
                            }
                        ],
                        "text": "Note that this differs from [23], which selects only the elements for a given class in each class-specific SVM."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 147
                            }
                        ],
                        "text": "Indeed, the negative set is treated very much like the negative set in an SVM (we penalize the linear sum of the margin violations), which follows [23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14970392,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce854ea2c797bd10cbdf4563a558cd8652c4946e",
            "isKey": false,
            "numCitedBy": 575,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "The goal of this paper is to discover a set of discriminative patches which can serve as a fully unsupervised mid-level visual representation. The desired patches need to satisfy two requirements: 1) to be representative, they need to occur frequently enough in the visual world; 2) to be discriminative, they need to be different enough from the rest of the visual world. The patches could correspond to parts, objects, \"visual phrases\", etc. but are not restricted to be any one of them. We pose this as an unsupervised discriminative clustering problem on a huge dataset of image patches. We use an iterative procedure which alternates between clustering and training discriminative classifiers, while applying careful cross-validation at each step to prevent overfitting. The paper experimentally demonstrates the effectiveness of discriminative patches as an unsupervised mid-level visual representation, suggesting that it could be used in place of visual words for many tasks. Furthermore, discriminative patches can also be used in a supervised regime, such as scene classification, where they demonstrate state-of-the-art performance on the MIT Indoor-67 dataset."
            },
            "slug": "Unsupervised-Discovery-of-Mid-Level-Discriminative-Singh-Gupta",
            "title": {
                "fragments": [],
                "text": "Unsupervised Discovery of Mid-Level Discriminative Patches"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "The paper experimentally demonstrates the effectiveness of discriminative patches as an unsupervised mid-level visual representation, suggesting that it could be used in place of visual words for many tasks."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108645975"
                        ],
                        "name": "Quannan Li",
                        "slug": "Quannan-Li",
                        "structuredName": {
                            "firstName": "Quannan",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quannan Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3045089"
                        ],
                        "name": "Jiajun Wu",
                        "slug": "Jiajun-Wu",
                        "structuredName": {
                            "firstName": "Jiajun",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiajun Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 209
                            }
                        ],
                        "text": ", scene categories [12] or GPS coordinates [5] (but can also run unsupervised [23]), and have been recently used for tasks including image classification [12, 23, 27], object detection [6], visual data mining [5, 15], action recognition [11], and geometry estimation [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 29
                            }
                        ],
                        "text": "Recently, several approaches [5, 6, 11, 12, 15, 23, 26, 27] have proposed mining visual data for discriminative mid-level visual elements, i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2566868,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4bfce93a0d431e9f9c908bdf467f8b58fbb719f1",
            "isKey": false,
            "numCitedBy": 146,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Obtaining effective mid-level representations has become an increasingly important task in computer vision. In this paper, we propose a fully automatic algorithm which harvests visual concepts from a large number of Internet images (more than a quarter of a million) using text-based queries. Existing approaches to visual concept learning from Internet images either rely on strong supervision with detailed manual annotations or learn image-level classifiers only. Here, we take the advantage of having massive well organized Google and Bing image data, visual concepts (around 14, 000) are automatically exploited from images using word-based queries. Using the learned visual concepts, we show state-of-the-art performances on a variety of benchmark datasets, which demonstrate the effectiveness of the learned mid-level representations: being able to generalize well to general natural images. Our method shows significant improvement over the competing systems in image classification, including those with strong supervision."
            },
            "slug": "Harvesting-Mid-level-Visual-Concepts-from-Internet-Li-Wu",
            "title": {
                "fragments": [],
                "text": "Harvesting Mid-level Visual Concepts from Large-Scale Internet Images"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "This paper proposes a fully automatic algorithm which harvests visual concepts from a large number of Internet images using text-based queries, and shows significant improvement over the competing systems in image classification, including those with strong supervision."
            },
            "venue": {
                "fragments": [],
                "text": "2013 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3045340"
                        ],
                        "name": "Tomasz Malisiewicz",
                        "slug": "Tomasz-Malisiewicz",
                        "structuredName": {
                            "firstName": "Tomasz",
                            "lastName": "Malisiewicz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomasz Malisiewicz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 68
                            }
                        ],
                        "text": "This is somewhat reminiscent of unsupervised marginbased clustering [29, 16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 580381,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "88482475e5dffab106149c7b358732e6c973e611",
            "isKey": false,
            "numCitedBy": 163,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We pose the recognition problem as data association. In this setting, a novel object is explained solely in terms of a small set of exemplar objects to which it is visually similar. Inspired by the work of Frome et al., we learn separate distance functions for each exemplar; however, our distances are interpretable on an absolute scale and can be thresholded to detect the presence of an object. Our exemplars are represented as image regions and the learned distances capture the relative importance of shape, color, texture, and position features for that region. We use the distance functions to detect and segment objects in novel images by associating the bottom-up segments obtained from multiple image segmentations with the exemplar regions. We evaluate the detection and segmentation performance of our algorithm on real-world outdoor scenes from the LabelMe (B. Russel, et al., 2007) dataset and also show some promising qualitative image parsing results."
            },
            "slug": "Recognition-by-association-via-learning-distances-Malisiewicz-Efros",
            "title": {
                "fragments": [],
                "text": "Recognition by association via learning per-exemplar distances"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This work uses the distance functions to detect and segment objects in novel images by associating the bottom-up segments obtained from multiple image segmentations with the exemplar regions and learns separate distance functions for each exemplar."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059431849"
                        ],
                        "name": "Megha Pandey",
                        "slug": "Megha-Pandey",
                        "structuredName": {
                            "firstName": "Megha",
                            "lastName": "Pandey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Megha Pandey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749609"
                        ],
                        "name": "S. Lazebnik",
                        "slug": "S.-Lazebnik",
                        "structuredName": {
                            "firstName": "Svetlana",
                            "lastName": "Lazebnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lazebnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15916373,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c6489d8dc7ddd117c4ec24576fe182a56ada47e7",
            "isKey": false,
            "numCitedBy": 452,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Weakly supervised discovery of common visual structure in highly variable, cluttered images is a key problem in recognition. We address this problem using deformable part-based models (DPM's) with latent SVM training [6]. These models have been introduced for fully supervised training of object detectors, but we demonstrate that they are also capable of more open-ended learning of latent structure for such tasks as scene recognition and weakly supervised object localization. For scene recognition, DPM's can capture recurring visual elements and salient objects; in combination with standard global image features, they obtain state-of-the-art results on the MIT 67-category indoor scene dataset. For weakly supervised object localization, optimization over latent DPM parameters can discover the spatial extent of objects in cluttered training images without ground-truth bounding boxes. The resulting method outperforms a recent state-of-the-art weakly supervised object localization approach on the PASCAL-07 dataset."
            },
            "slug": "Scene-recognition-and-weakly-supervised-object-with-Pandey-Lazebnik",
            "title": {
                "fragments": [],
                "text": "Scene recognition and weakly supervised object localization with deformable part-based models"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work demonstrates that deformable part-based models, introduced for fully supervised training of object detectors, are also capable of more open-ended learning of latent structure for such tasks as scene recognition and weakly supervised object localization."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Computer Vision"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2040091191"
                        ],
                        "name": "Li-Jia Li",
                        "slug": "Li-Jia-Li",
                        "structuredName": {
                            "firstName": "Li-Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li-Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144914140"
                        ],
                        "name": "Hao Su",
                        "slug": "Hao-Su",
                        "structuredName": {
                            "firstName": "Hao",
                            "lastName": "Su",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hao Su"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143977260"
                        ],
                        "name": "E. Xing",
                        "slug": "E.-Xing",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Xing",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Xing"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 591187,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6286a82f72f632672c1890f3dd6bbb15b8e5168b",
            "isKey": false,
            "numCitedBy": 996,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Robust low-level image features have been proven to be effective representations for a variety of visual recognition tasks such as object recognition and scene classification; but pixels, or even local image patches, carry little semantic meanings. For high level visual tasks, such low-level image representations are potentially not enough. In this paper, we propose a high-level image representation, called the Object Bank, where an image is represented as a scale-invariant response map of a large number of pre-trained generic object detectors, blind to the testing dataset or visual task. Leveraging on the Object Bank representation, superior performances on high level visual recognition tasks can be achieved with simple off-the-shelf classifiers such as logistic regression and linear SVM. Sparsity algorithms make our representation more efficient and scalable for large scene datasets, and reveal semantically meaningful feature patterns."
            },
            "slug": "Object-Bank:-A-High-Level-Image-Representation-for-Li-Su",
            "title": {
                "fragments": [],
                "text": "Object Bank: A High-Level Image Representation for Scene Classification & Semantic Feature Sparsification"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A high-level image representation, called the Object Bank, is proposed, where an image is represented as a scale-invariant response map of a large number of pre-trained generic object detectors, blind to the testing dataset or visual task."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40417846"
                        ],
                        "name": "Mayank Juneja",
                        "slug": "Mayank-Juneja",
                        "structuredName": {
                            "firstName": "Mayank",
                            "lastName": "Juneja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mayank Juneja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687524"
                        ],
                        "name": "A. Vedaldi",
                        "slug": "A.-Vedaldi",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Vedaldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vedaldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694502"
                        ],
                        "name": "C. Jawahar",
                        "slug": "C.-Jawahar",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Jawahar",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Jawahar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 29
                            }
                        ],
                        "text": "Recently, several approaches [5, 6, 11, 12, 15, 23, 26, 27] have proposed mining visual data for discriminative mid-level visual elements, i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 100
                            }
                        ],
                        "text": "This is much like the well-established method of \u201cquery expansion\u201d for retrieval, and is similar to [12] (although they use multiple iterations of query expansion)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 19
                            }
                        ],
                        "text": ", scene categories [12] or GPS coordinates [5] (but can also run unsupervised [23]), and have been recently used for tasks including image classification [12, 23, 27], object detection [6], visual data mining [5, 15], action recognition [11], and geometry estimation [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 104
                            }
                        ],
                        "text": "For indoor scenes, objects within the scene are often more useful features than global scene statistics [12]: for instance, shoe shops are similar to other stores in global layout, but they mostly contain shoes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 49
                            }
                        ],
                        "text": "We even outperform the Improved Fisher Vector of [12], as well as IFV combined with discriminative patches (IFV+BoP)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 19
                            }
                        ],
                        "text": "Several approaches [5, 6, 12, 23] have been proposed to discover mid-level visual elements, that are both 1) representative, i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8763431,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b730f5dfbd73172a4bba2d00d377a145c046bca",
            "isKey": true,
            "numCitedBy": 416,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "The automatic discovery of distinctive parts for an object or scene class is challenging since it requires simultaneously to learn the part appearance and also to identify the part occurrences in images. In this paper, we propose a simple, efficient, and effective method to do so. We address this problem by learning parts incrementally, starting from a single part occurrence with an Exemplar SVM. In this manner, additional part instances are discovered and aligned reliably before being considered as training examples. We also propose entropy-rank curves as a means of evaluating the distinctiveness of parts shareable between categories and use them to select useful parts out of a set of candidates. We apply the new representation to the task of scene categorisation on the MIT Scene 67 benchmark. We show that our method can learn parts which are significantly more informative and for a fraction of the cost, compared to previous part-learning methods such as Singh et al. [28]. We also show that a well constructed bag of words or Fisher vector model can substantially outperform the previous state-of-the-art classification performance on this data."
            },
            "slug": "Blocks-That-Shout:-Distinctive-Parts-for-Scene-Juneja-Vedaldi",
            "title": {
                "fragments": [],
                "text": "Blocks That Shout: Distinctive Parts for Scene Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper proposes a simple, efficient, and effective method to learn parts incrementally, starting from a single part occurrence with an Exemplar SVM, and can learn parts which are significantly more informative and for a fraction of the cost, compared to previous part-learning methods."
            },
            "venue": {
                "fragments": [],
                "text": "2013 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3253737"
                        ],
                        "name": "Fereshteh Sadeghi",
                        "slug": "Fereshteh-Sadeghi",
                        "structuredName": {
                            "firstName": "Fereshteh",
                            "lastName": "Sadeghi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fereshteh Sadeghi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802944"
                        ],
                        "name": "M. Tappen",
                        "slug": "M.-Tappen",
                        "structuredName": {
                            "firstName": "Marshall",
                            "lastName": "Tappen",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Tappen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17532612,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cfeea01314ebf4f10a7eaceb0a01b3e71162ef74",
            "isKey": false,
            "numCitedBy": 91,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we propose a simple but efficient image representation for solving the scene classification problem. Our new representation combines the benefits of spatial pyramid representation using nonlinear feature coding and latent Support Vector Machine (LSVM) to train a set of Latent Pyramidal Regions (LPR). Each of our LPRs captures a discriminative characteristic of the scenes and is trained by searching over all possible sub-windows of the images in a latent SVM training procedure. Each LPR is represented in a spatial pyramid and uses non-linear locality constraint coding for learning both shape and texture patterns of the scene. The final response of the LPRs form a single feature vector which we call the LPR representation and can be used for the classification task. We tested our proposed scene representation model in three datasets which contain a variety of scene categories (15-Scenes, UIUC-Sports and MIT-indoor). Our LPR representation obtains state-of-the-art results on all these datasets which shows that it can simultaneously model the global and local scene characteristics in a single framework and is general enough to be used for both indoor and outdoor scene classification."
            },
            "slug": "Latent-Pyramidal-Regions-for-Recognizing-Scenes-Sadeghi-Tappen",
            "title": {
                "fragments": [],
                "text": "Latent Pyramidal Regions for Recognizing Scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The proposed LPR representation obtains state-of-the-art results on all these datasets which shows that it can simultaneously model the global and local scene characteristics in a single framework and is general enough to be used for both indoor and outdoor scene classification."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2786693"
                        ],
                        "name": "Carl Doersch",
                        "slug": "Carl-Doersch",
                        "structuredName": {
                            "firstName": "Carl",
                            "lastName": "Doersch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carl Doersch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144556482"
                        ],
                        "name": "Saurabh Singh",
                        "slug": "Saurabh-Singh",
                        "structuredName": {
                            "firstName": "Saurabh",
                            "lastName": "Singh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Saurabh Singh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726095131"
                        ],
                        "name": "A. Gupta",
                        "slug": "A.-Gupta",
                        "structuredName": {
                            "firstName": "Abhinav",
                            "lastName": "Gupta",
                            "middleNames": [
                                "Kumar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782755"
                        ],
                        "name": "Josef Sivic",
                        "slug": "Josef-Sivic",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Sivic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Josef Sivic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 5
                            }
                        ],
                        "text": "Recently, several approaches [5, 6, 11, 12, 15, 23, 26, 27] have proposed mining visual data for discriminative mid-level visual elements, i.e., entities which are more informative than \u201cvisual words,\u201d and more frequently occurring and easier to detect than high-level objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2275683,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d913b9d742b99119d96ad2b661f3e7e7c2fa5e2b",
            "isKey": false,
            "numCitedBy": 598,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Given a large repository of geotagged imagery, we seek to automatically find visual elements, e. g. windows, balconies, and street signs, that are most distinctive for a certain geo-spatial area, for example the city of Paris. This is a tremendously difficult task as the visual features distinguishing architectural elements of different places can be very subtle. In addition, we face a hard search problem: given all possible patches in all images, which of them are both frequently occurring and geographically informative? To address these issues, we propose to use a discriminative clustering approach able to take into account the weak geographic supervision. We show that geographically representative image elements can be discovered automatically from Google Street View imagery in a discriminative manner. We demonstrate that these elements are visually interpretable and perceptually geo-informative. The discovered visual elements can also support a variety of computational geography tasks, such as mapping architectural correspondences and influences within and across cities, finding representative elements at different geo-spatial scales, and geographically-informed image retrieval."
            },
            "slug": "What-makes-Paris-look-like-Paris-Doersch-Singh",
            "title": {
                "fragments": [],
                "text": "What makes Paris look like Paris?"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that geographically representative image elements can be discovered automatically from Google Street View imagery in a discriminative manner and it is demonstrated that these elements are visually interpretable and perceptually geo-informative."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Trans. Graph."
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35561551"
                        ],
                        "name": "Arpit Jain",
                        "slug": "Arpit-Jain",
                        "structuredName": {
                            "firstName": "Arpit",
                            "lastName": "Jain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arpit Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726095131"
                        ],
                        "name": "A. Gupta",
                        "slug": "A.-Gupta",
                        "structuredName": {
                            "firstName": "Abhinav",
                            "lastName": "Gupta",
                            "middleNames": [
                                "Kumar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144113391"
                        ],
                        "name": "Mikel D. Rodriguez",
                        "slug": "Mikel-D.-Rodriguez",
                        "structuredName": {
                            "firstName": "Mikel",
                            "lastName": "Rodriguez",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mikel D. Rodriguez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693428"
                        ],
                        "name": "L. Davis",
                        "slug": "L.-Davis",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Davis",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Davis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 241,
                                "start": 237
                            }
                        ],
                        "text": ", scene categories [12] or GPS coordinates [5] (but can also run unsupervised [23]), and have been recently used for tasks including image classification [12, 23, 27], object detection [6], visual data mining [5, 15], action recognition [11], and geometry estimation [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 29
                            }
                        ],
                        "text": "Recently, several approaches [5, 6, 11, 12, 15, 23, 26, 27] have proposed mining visual data for discriminative mid-level visual elements, i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5710020,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eece43a4680e80e9dfba7027927b5e4ecae70eb2",
            "isKey": false,
            "numCitedBy": 152,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "How should a video be represented? We propose a new representation for videos based on mid-level discriminative spatio-temporal patches. These spatio-temporal patches might correspond to a primitive human action, a semantic object, or perhaps a random but informative spatio-temporal patch in the video. What defines these spatio-temporal patches is their discriminative and representative properties. We automatically mine these patches from hundreds of training videos and experimentally demonstrate that these patches establish correspondence across videos and align the videos for label transfer techniques. Furthermore, these patches can be used as a discriminative vocabulary for action classification where they demonstrate state-of-the-art performance on UCF50 and Olympics datasets."
            },
            "slug": "Representing-Videos-Using-Mid-level-Discriminative-Jain-Gupta",
            "title": {
                "fragments": [],
                "text": "Representing Videos Using Mid-level Discriminative Patches"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A new representation for videos based on mid-level discriminative spatio-temporal patches that establish correspondence across videos and align the videos for label transfer techniques is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "2013 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808816"
                        ],
                        "name": "Jianxin Wu",
                        "slug": "Jianxin-Wu",
                        "structuredName": {
                            "firstName": "Jianxin",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianxin Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144177248"
                        ],
                        "name": "James M. Rehg",
                        "slug": "James-M.-Rehg",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Rehg",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James M. Rehg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8581232,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "435e2a5164c1ee3006c403199d072823d83a5a21",
            "isKey": false,
            "numCitedBy": 707,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "CENsus TRansform hISTogram (CENTRIST), a new visual descriptor for recognizing topological places or scene categories, is introduced in this paper. We show that place and scene recognition, especially for indoor environments, require its visual descriptor to possess properties that are different from other vision domains (e.g., object recognition). CENTRIST satisfies these properties and suits the place and scene recognition task. It is a holistic representation and has strong generalizability for category recognition. CENTRIST mainly encodes the structural properties within an image and suppresses detailed textural information. Our experiments demonstrate that CENTRIST outperforms the current state of the art in several place and scene recognition data sets, compared with other descriptors such as SIFT and Gist. Besides, it is easy to implement and evaluates extremely fast."
            },
            "slug": "CENTRIST:-A-Visual-Descriptor-for-Scene-Wu-Rehg",
            "title": {
                "fragments": [],
                "text": "CENTRIST: A Visual Descriptor for Scene Categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "CENsus TRansform hISTogram (CENTRIST), a new visual descriptor for recognizing topological places or scene categories, is introduced and is shown to be a holistic representation and has strong generalizability for category recognition."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145160921"
                        ],
                        "name": "Bryan C. Russell",
                        "slug": "Bryan-C.-Russell",
                        "structuredName": {
                            "firstName": "Bryan",
                            "lastName": "Russell",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bryan C. Russell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782755"
                        ],
                        "name": "Josef Sivic",
                        "slug": "Josef-Sivic",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Sivic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Josef Sivic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 102
                            }
                        ],
                        "text": "However, \u201cvisual words\u201d is a very low-level representation, mostly capturing local edges and corners ([21] notes that \u201cvisual letters\u201d or \u201cvisual phonemes\u201d would have been a more accurate term)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2066830,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "56766bab76cdcd541bf791730944a5e453006239",
            "isKey": false,
            "numCitedBy": 740,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Given a large dataset of images, we seek to automatically determine the visually similar object and scene classes together with their image segmentation. To achieve this we combine two ideas: (i) that a set of segmented objects can be partitioned into visual object classes using topic discovery models from statistical text analysis; and (ii) that visual object classes can be used to assess the accuracy of a segmentation. To tie these ideas together we compute multiple segmentations of each image and then: (i) learn the object classes; and (ii) choose the correct segmentations. We demonstrate that such an algorithm succeeds in automatically discovering many familiar objects in a variety of image datasets, including those from Caltech, MSRC and LabelMe."
            },
            "slug": "Using-Multiple-Segmentations-to-Discover-Objects-in-Russell-Freeman",
            "title": {
                "fragments": [],
                "text": "Using Multiple Segmentations to Discover Objects and their Extent in Image Collections"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work compute multiple segmentations of each image and then learns the object classes and chooses the correct segmentations, demonstrating that such an algorithm succeeds in automatically discovering many familiar objects in a variety of image datasets, including those from Caltech, MSRC and LabelMe."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152146009"
                        ],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 29
                            }
                        ],
                        "text": "Recently, several approaches [5, 6, 11, 12, 15, 23, 26, 27] have proposed mining visual data for discriminative mid-level visual elements, i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8253125,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c194cec502b3991b22a22d81bc531d2dd7239ba3",
            "isKey": false,
            "numCitedBy": 137,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we address the problem of learning discriminative part detectors from image sets with category labels. We propose a novel latent SVM model regularized by group sparsity to learn these part detectors. Starting from a large set of initial parts, the group sparsity regularizer forces the model to jointly select and optimize a set of discriminative part detectors in a max-margin framework. We propose a stochastic version of a proximal algorithm to solve the corresponding optimization problem. We apply the proposed method to image classification and co segmentation, and quantitative experiments with standard benchmarks show that it matches or improves upon the state of the art."
            },
            "slug": "Learning-Discriminative-Part-Detectors-for-Image-Sun-Ponce",
            "title": {
                "fragments": [],
                "text": "Learning Discriminative Part Detectors for Image Classification and Cosegmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "This paper proposes a stochastic version of a proximal algorithm to solve the corresponding optimization problem of discriminative part detectors from image sets with category labels and applies it to image classification and co segmentation."
            },
            "venue": {
                "fragments": [],
                "text": "2013 IEEE International Conference on Computer Vision"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747498"
                        ],
                        "name": "B. Georgescu",
                        "slug": "B.-Georgescu",
                        "structuredName": {
                            "firstName": "Bogdan",
                            "lastName": "Georgescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Georgescu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782918"
                        ],
                        "name": "I. Shimshoni",
                        "slug": "I.-Shimshoni",
                        "structuredName": {
                            "firstName": "Ilan",
                            "lastName": "Shimshoni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Shimshoni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145776090"
                        ],
                        "name": "P. Meer",
                        "slug": "P.-Meer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Meer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Meer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 27
                            }
                        ],
                        "text": "While approximations exist [9], they rely on approximate nearest neighbor algorithms, which work for low-dimensional spaces (\uf8ff 48 dimensions in [9]), but empirically we have found poor performance in HOG feature space (> 2000 dimensions)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1833221,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c41bf09e692ae81b7f81e8c657303b30a4d807b5",
            "isKey": false,
            "numCitedBy": 484,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Feature space analysis is the main module in many computer vision tasks. The most popular technique, k-means clustering, however, has two inherent limitations: the clusters are constrained to be spherically symmetric and their number has to be known a priori. In nonparametric clustering methods, like the one based on mean shift, these limitations are eliminated but the amount of computation becomes prohibitively large as the dimension of the space increases. We exploit a recently proposed approximation technique, locality-sensitive hashing (LSH), to reduce the computational complexity of adaptive mean shift. In our implementation of LSH the optimal parameters of the data structure are determined by a pilot learning procedure, and the partitions are data driven. As an application, the performance of mode and k-means based textons are compared in a texture classification study."
            },
            "slug": "Mean-shift-based-clustering-in-high-dimensions:-a-Georgescu-Shimshoni",
            "title": {
                "fragments": [],
                "text": "Mean shift based clustering in high dimensions: a texture classification example"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work exploits a recently proposed approximation technique, locality-sensitive hashing (LSH), to reduce the computational complexity of adaptive mean shift and implements the implementation of LSH, where the optimal parameters of the data structure are determined by a pilot learning procedure, and the partitions are data driven."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790580"
                        ],
                        "name": "Bharath Hariharan",
                        "slug": "Bharath-Hariharan",
                        "structuredName": {
                            "firstName": "Bharath",
                            "lastName": "Hariharan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bharath Hariharan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770537"
                        ],
                        "name": "D. Ramanan",
                        "slug": "D.-Ramanan",
                        "structuredName": {
                            "firstName": "Deva",
                            "lastName": "Ramanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ramanan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 101
                            }
                        ],
                        "text": "Implementation details: We use the same patch descriptors described in [5] and whiten them following [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 53
                            }
                        ],
                        "text": "The simplest baseline is \u201cExemplar LDA,\u201d proposed by [10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9024161,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ea6dff5b3687760da4a23908ab8a90b177c02297",
            "isKey": false,
            "numCitedBy": 298,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Object detection has over the past few years converged on using linear SVMs over HOG features. Training linear SVMs however is quite expensive, and can become intractable as the number of categories increase. In this work we revisit a much older technique, viz. Linear Discriminant Analysis, and show that LDA models can be trained almost trivially, and with little or no loss in performance. The covariance matrices we estimate capture properties of natural images. Whitening HOG features with these covariances thus removes naturally occuring correlations between the HOG features. We show that these whitened features (which we call WHO) are considerably better than the original HOG features for computing similarities, and prove their usefulness in clustering. Finally, we use our findings to produce an object detection system that is competitive on PASCAL VOC 2007 while being considerably easier to train and test."
            },
            "slug": "Discriminative-Decorrelation-for-Clustering-and-Hariharan-Malik",
            "title": {
                "fragments": [],
                "text": "Discriminative Decorrelation for Clustering and Classification"
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2443233"
                        ],
                        "name": "Xinggang Wang",
                        "slug": "Xinggang-Wang",
                        "structuredName": {
                            "firstName": "Xinggang",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xinggang Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2450889"
                        ],
                        "name": "Baoyuan Wang",
                        "slug": "Baoyuan-Wang",
                        "structuredName": {
                            "firstName": "Baoyuan",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Baoyuan Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145905113"
                        ],
                        "name": "X. Bai",
                        "slug": "X.-Bai",
                        "structuredName": {
                            "firstName": "Xiang",
                            "lastName": "Bai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Bai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743698"
                        ],
                        "name": "Wenyu Liu",
                        "slug": "Wenyu-Liu",
                        "structuredName": {
                            "firstName": "Wenyu",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wenyu Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 154
                            }
                        ],
                        "text": ", scene categories [12] or GPS coordinates [5] (but can also run unsupervised [23]), and have been recently used for tasks including image classification [12, 23, 27], object detection [6], visual data mining [5, 15], action recognition [11], and geometry estimation [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 29
                            }
                        ],
                        "text": "Recently, several approaches [5, 6, 11, 12, 15, 23, 26, 27] have proposed mining visual data for discriminative mid-level visual elements, i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9937767,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a754989741afb89e588b52de375054dffbeda39d",
            "isKey": false,
            "numCitedBy": 111,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "Dictionary learning has became an increasingly important task in machine learning, as it is fundamental to the representation problem. A number of emerging techniques specifically include a codebook learning step, in which a critical knowledge abstraction process is carried out. Existing approaches in dictionary (codebook) learning are either generative (unsupervised e.g. k-means) or discriminative (supervised e.g. extremely randomized forests). In this paper, we propose a multiple instance learning (MIL) strategy (along the line of weakly supervised learning) for dictionary learning. Each code is represented by a classifier, such as a linear SVM, which naturally performs metric fusion for multi-channel features. We design a formulation to simultaneously learn mixtures of codes by maximizing classification margins in MIL. State-of-the-art results are observed in image classification benchmarks based on the learned codebooks, which observe both compactness and effectiveness."
            },
            "slug": "Max-Margin-Multiple-Instance-Dictionary-Learning-Wang-Wang",
            "title": {
                "fragments": [],
                "text": "Max-Margin Multiple-Instance Dictionary Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper designs a formulation to simultaneously learn mixtures of codes by maximizing classification margins in MIL, and results are observed in image classification benchmarks based on the learned codebooks, which observe both compactness and effectiveness."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782755"
                        ],
                        "name": "Josef Sivic",
                        "slug": "Josef-Sivic",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Sivic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Josef Sivic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 99
                            }
                        ],
                        "text": "Currently, the most popular visual representations in machine learning are based on \u201cvisual words\u201d [24], which are obtained by unsupervised clustering (k-means) of local features (SIFT) over a large dataset."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14457153,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "642e328cae81c5adb30069b680cf60ba6b475153",
            "isKey": false,
            "numCitedBy": 6760,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an approach to object and scene retrieval which searches for and localizes all the occurrences of a user outlined object in a video. The object is represented by a set of viewpoint invariant region descriptors so that recognition can proceed successfully despite changes in viewpoint, illumination and partial occlusion. The temporal continuity of the video within a shot is used to track the regions in order to reject unstable regions and reduce the effects of noise in the descriptors. The analogy with text retrieval is in the implementation where matches on descriptors are pre-computed (using vector quantization), and inverted file systems and document rankings are used. The result is that retrieved is immediate, returning a ranked list of key frames/shots in the manner of Google. The method is illustrated for matching in two full length feature films."
            },
            "slug": "Video-Google:-a-text-retrieval-approach-to-object-Sivic-Zisserman",
            "title": {
                "fragments": [],
                "text": "Video Google: a text retrieval approach to object matching in videos"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "An approach to object and scene retrieval which searches for and localizes all the occurrences of a user outlined object in a video, represented by a set of viewpoint invariant region descriptors so that recognition can proceed successfully despite changes in viewpoint, illumination and partial occlusion."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3171632"
                        ],
                        "name": "A. Quattoni",
                        "slug": "A.-Quattoni",
                        "structuredName": {
                            "firstName": "Ariadna",
                            "lastName": "Quattoni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Quattoni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 32
                            }
                        ],
                        "text": "We use the MIT Scene-67 dataset [19], where machine performance remains substantially below human"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 45
                            }
                        ],
                        "text": "Table 1: Results on MIT 67 scenes ROI + Gist [19] 26."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7910040,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c82d90336ba365c7914fe4bd6c292a8c6916a801",
            "isKey": false,
            "numCitedBy": 681,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Indoor scene recognition is a challenging open problem in high level vision. Most scene recognition models that work well for outdoor scenes perform poorly in the indoor domain. The main difficulty is that while some indoor scenes (e.g. corridors) can be well characterized by global spatial properties, others (e.g, bookstores) are better characterized by the objects they contain. More generally, to address the indoor scenes recognition problem we need a model that can exploit local and global discriminative information. In this paper we propose a prototype based model that can successfully combine both sources of information. To test our approach we created a dataset of 67 indoor scenes categories (the largest available) covering a wide range of domains. The results show that our approach can significantly outperform a state of the art classifier for the task."
            },
            "slug": "Recognizing-indoor-scenes-Quattoni-Torralba",
            "title": {
                "fragments": [],
                "text": "Recognizing indoor scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A prototype based model that can successfully combine local and global discriminative information is proposed that can significantly outperform a state of the art classifier for the indoor scene recognition task."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2483430"
                        ],
                        "name": "S. N. Parizi",
                        "slug": "S.-N.-Parizi",
                        "structuredName": {
                            "firstName": "Sobhan",
                            "lastName": "Parizi",
                            "middleNames": [
                                "Naderi"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. N. Parizi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144971987"
                        ],
                        "name": "John G. Oberlin",
                        "slug": "John-G.-Oberlin",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Oberlin",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John G. Oberlin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685089"
                        ],
                        "name": "Pedro F. Felzenszwalb",
                        "slug": "Pedro-F.-Felzenszwalb",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Felzenszwalb",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pedro F. Felzenszwalb"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6740766,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2aaea1114397155e952a870edf8586d376e69b2f",
            "isKey": false,
            "numCitedBy": 174,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new latent variable model for scene recognition. Our approach represents a scene as a collection of region models (\u201cparts\u201d) arranged in a reconfigurable pattern. We partition an image into a predefined set of regions and use a latent variable to specify which region model is assigned to each image region. In our current implementation we use a bag of words representation to capture the appearance of an image region. The resulting method generalizes a spatial bag of words approach that relies on a fixed model for the bag of words in each image region. Our models can be trained using both generative and discriminative methods. In the generative setting we use the Expectation-Maximization (EM) algorithm to estimate model parameters from a collection of images with category labels. In the discriminative setting we use a latent structural SVM (LSSVM). We note that LSSVMs can be very sensitive to initialization and demonstrate that generative training with EM provides a good initialization for discriminative training with LSSVM."
            },
            "slug": "Reconfigurable-models-for-scene-recognition-Parizi-Oberlin",
            "title": {
                "fragments": [],
                "text": "Reconfigurable models for scene recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A new latent variable model for scene recognition that represents a scene as a collection of region models arranged in a reconfigurable pattern and uses a latent variable to specify which region model is assigned to each image region."
            },
            "venue": {
                "fragments": [],
                "text": "2012 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2831988"
                        ],
                        "name": "Ian Endres",
                        "slug": "Ian-Endres",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Endres",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ian Endres"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143953573"
                        ],
                        "name": "Kevin J. Shih",
                        "slug": "Kevin-J.-Shih",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Shih",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin J. Shih"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743685"
                        ],
                        "name": "Johnston Jiaa",
                        "slug": "Johnston-Jiaa",
                        "structuredName": {
                            "firstName": "Johnston",
                            "lastName": "Jiaa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Johnston Jiaa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433269"
                        ],
                        "name": "Derek Hoiem",
                        "slug": "Derek-Hoiem",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Hoiem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Hoiem"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 185
                            }
                        ],
                        "text": ", scene categories [12] or GPS coordinates [5] (but can also run unsupervised [23]), and have been recently used for tasks including image classification [12, 23, 27], object detection [6], visual data mining [5, 15], action recognition [11], and geometry estimation [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 29
                            }
                        ],
                        "text": "Recently, several approaches [5, 6, 11, 12, 15, 23, 26, 27] have proposed mining visual data for discriminative mid-level visual elements, i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 19
                            }
                        ],
                        "text": "Several approaches [5, 6, 12, 23] have been proposed to discover mid-level visual elements, that are both 1) representative, i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1808519,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b9ea724dd5ad44ede5fa22bb8834ba7e42a9292",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a method to learn a diverse collection of discriminative parts from object bounding box annotations. Part detectors can be trained and applied individually, which simplifies learning and extension to new features or categories. We apply the parts to object category detection, pooling part detections within bottom-up proposed regions and using a boosted classifier with proposed sigmoid weak learners for scoring. On PASCAL VOC 2010, we evaluate the part detectors' ability to discriminate and localize annotated key points. Our detection system is competitive with the best-existing systems, outperforming other HOG-based detectors on the more deformable categories."
            },
            "slug": "Learning-Collections-of-Part-Models-for-Object-Endres-Shih",
            "title": {
                "fragments": [],
                "text": "Learning Collections of Part Models for Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The detection system is competitive with the best-existing systems, outperforming other HOG-based detectors on the more deformable categories and evaluating the part detectors' ability to discriminate and localize annotated key points on PASCAL VOC 2010."
            },
            "venue": {
                "fragments": [],
                "text": "2013 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2867206"
                        ],
                        "name": "H. E. \u00c7eting\u00fcl",
                        "slug": "H.-E.-\u00c7eting\u00fcl",
                        "structuredName": {
                            "firstName": "Hasan",
                            "lastName": "\u00c7eting\u00fcl",
                            "middleNames": [
                                "Ertan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. E. \u00c7eting\u00fcl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144020730"
                        ],
                        "name": "R. Vidal",
                        "slug": "R.-Vidal",
                        "structuredName": {
                            "firstName": "Ren\u00e9",
                            "lastName": "Vidal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Vidal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 159
                            }
                        ],
                        "text": "In this work, we pose visual element discovery as discriminative mode seeking, drawing connections to the the well-known and well-studied mean-shift algorithm [2, 1, 4, 8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 73
                            }
                        ],
                        "text": "Formulations of mean-shift exist for data constrained to the unit sphere [1], but again we must adapt them to the ratio setting."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9802618,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0105fe3a1d77ff6db281a2b03c8a957530268408",
            "isKey": false,
            "numCitedBy": 105,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "The mean shift algorithm, which is a nonparametric density estimator for detecting the modes of a distribution on a Euclidean space, was recently extended to operate on analytic manifolds. The extension is extrinsic in the sense that the inherent optimization is performed on the tangent spaces of these manifolds. This approach specifically requires the use of the exponential map at each iteration. This paper presents an alternative mean shift formulation, which performs the iterative optimization \u201con\u201d the manifold of interest and intrinsically locates the modes via consecutive evaluations of a mapping. In particular, these evaluations constitute a modified gradient ascent scheme that avoids the computation of the exponential maps for Stiefel and Grassmann manifolds. The performance of our algorithm is evaluated by conducting extensive comparative studies on synthetic data as well as experiments on object categorization and segmentation of multiple motions."
            },
            "slug": "Intrinsic-mean-shift-for-clustering-on-Stiefel-and-\u00c7eting\u00fcl-Vidal",
            "title": {
                "fragments": [],
                "text": "Intrinsic mean shift for clustering on Stiefel and Grassmann manifolds"
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145254043"
                        ],
                        "name": "Jun Zhu",
                        "slug": "Jun-Zhu",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jun Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2040091191"
                        ],
                        "name": "Li-Jia Li",
                        "slug": "Li-Jia-Li",
                        "structuredName": {
                            "firstName": "Li-Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li-Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143977260"
                        ],
                        "name": "E. Xing",
                        "slug": "E.-Xing",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Xing",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Xing"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6415745,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a28e370bc3906917fb554ded0816a9d9b0249731",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Upstream supervised topic models have been widely used for complicated scene understanding. However, existing maximum likelihood estimation (MLE) schemes can make the prediction model learning independent of latent topic discovery and result in an unbalanced prediction rule for scene classification. This paper presents a joint max-margin and max-likelihood learning method for upstream scene understanding models, in which latent topic discovery and prediction model estimation are closely coupled and well-balanced. The optimization problem is efficiently solved with a variational EM procedure, which iteratively solves an online loss-augmented SVM. We demonstrate the advantages of the large-margin approach on both an 8-category sports dataset and the 67-class MIT indoor scene dataset for scene categorization."
            },
            "slug": "Large-Margin-Learning-of-Upstream-Scene-Models-Zhu-Li",
            "title": {
                "fragments": [],
                "text": "Large Margin Learning of Upstream Scene Understanding Models"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A joint max-margin and max-likelihood learning method for upstream scene understanding models, in which latent topic discovery and prediction model estimation are closely coupled and well-balanced."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685020"
                        ],
                        "name": "D. Comaniciu",
                        "slug": "D.-Comaniciu",
                        "structuredName": {
                            "firstName": "Dorin",
                            "lastName": "Comaniciu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Comaniciu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145320582"
                        ],
                        "name": "Visvanathan Ramesh",
                        "slug": "Visvanathan-Ramesh",
                        "structuredName": {
                            "firstName": "Visvanathan",
                            "lastName": "Ramesh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Visvanathan Ramesh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145776090"
                        ],
                        "name": "P. Meer",
                        "slug": "P.-Meer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Meer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Meer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 93
                            }
                        ],
                        "text": "One way to deal with the non-uniformity of the feature space is to use an adaptive bandwidth [4]: that is, different bandwidths are used in different regions of the space."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 111
                            }
                        ],
                        "text": "It is admittedly difficult to analyze how well these heuristics approximate the adaptive bandwidth approach of [4], and even there the setting of the bandwidth for each datapoint has heuristic aspects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 99
                            }
                        ],
                        "text": "However, previous algorithms are difficult to implement for large data in high-dimensional spaces; [4], for instance, requires a density estimate for every point used in computing the gradient of their objective, because their formulation relies on a per-point bandwidth rather than a per-cluster bandwidth."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 159
                            }
                        ],
                        "text": "In this work, we pose visual element discovery as discriminative mode seeking, drawing connections to the the well-known and well-studied mean-shift algorithm [2, 1, 4, 8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 99
                            }
                        ],
                        "text": "One way to deal with this is to assign smaller bandwidths to patches in dense regions of the space [4], e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14661676,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "7fc921ebf33ca27c60c1b72b9652f547935bc5ef",
            "isKey": true,
            "numCitedBy": 486,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We present two solutions for the scale selection problem in computer vision. The first one is completely nonparametric and is based on the the adaptive estimation of the normalized density gradient. Employing the sample point estimator, we define the Variable Bandwidth Mean Shift, prove its convergence, and show its superiority over the fixed bandwidth procedure. The second technique has a semiparametric nature and imposes a local structure on the data to extract reliable scale information. The local scale of the underlying density is taken as the bandwidth which maximizes the magnitude of the normalized mean shift vector. Both estimators provide practical tools for autonomous image and quasi real-time video analysis and several examples are shown to illustrate their effectiveness."
            },
            "slug": "The-variable-bandwidth-mean-shift-and-data-driven-Comaniciu-Ramesh",
            "title": {
                "fragments": [],
                "text": "The Variable Bandwidth Mean Shift and Data-Driven Scale Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The sample point estimator is defined, prove its convergence, and show its superiority over the fixed bandwidth procedure, and an alternative approach for data-driven scale selection which imposes a local structure on the data is studied."
            },
            "venue": {
                "fragments": [],
                "text": "ICCV"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786435"
                        ],
                        "name": "David F. Fouhey",
                        "slug": "David-F.-Fouhey",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Fouhey",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David F. Fouhey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726095131"
                        ],
                        "name": "A. Gupta",
                        "slug": "A.-Gupta",
                        "structuredName": {
                            "firstName": "Abhinav",
                            "lastName": "Gupta",
                            "middleNames": [
                                "Kumar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 270,
                                "start": 267
                            }
                        ],
                        "text": ", scene categories [12] or GPS coordinates [5] (but can also run unsupervised [23]), and have been recently used for tasks including image classification [12, 23, 27], object detection [6], visual data mining [5, 15], action recognition [11], and geometry estimation [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 598952,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c855d8b75090e4d4aadd6ce936046327774470c9",
            "isKey": false,
            "numCitedBy": 162,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "What primitives should we use to infer the rich 3D world behind an image? We argue that these primitives should be both visually discriminative and geometrically informative and we present a technique for discovering such primitives. We demonstrate the utility of our primitives by using them to infer 3D surface normals given a single image. Our technique substantially outperforms the state-of-the-art and shows improved cross-dataset performance."
            },
            "slug": "Data-Driven-3D-Primitives-for-Single-Image-Fouhey-Gupta",
            "title": {
                "fragments": [],
                "text": "Data-Driven 3D Primitives for Single Image Understanding"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "This work argues that these primitives should be both visually discriminative and geometrically informative and presents a technique for discovering such primitives and demonstrates the utility of their utility by using them to infer 3D surface normals given a single image."
            },
            "venue": {
                "fragments": [],
                "text": "2013 IEEE International Conference on Computer Vision"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064160"
                        ],
                        "name": "A. Krizhevsky",
                        "slug": "A.-Krizhevsky",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Krizhevsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krizhevsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[13]) are not equipped to handle it directly, at the raw pixel level, making research on finding good visual representations particularly relevant and timely."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 195908774,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
            "isKey": false,
            "numCitedBy": 80960,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called \"dropout\" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry."
            },
            "slug": "ImageNet-classification-with-deep-convolutional-Krizhevsky-Sutskever",
            "title": {
                "fragments": [],
                "text": "ImageNet classification with deep convolutional neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A large, deep convolutional neural network was trained to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes and employed a recently developed regularization method called \"dropout\" that proved to be very effective."
            },
            "venue": {
                "fragments": [],
                "text": "Commun. ACM"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2230211"
                        ],
                        "name": "Linli Xu",
                        "slug": "Linli-Xu",
                        "structuredName": {
                            "firstName": "Linli",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Linli Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2094697289"
                        ],
                        "name": "James Neufeld",
                        "slug": "James-Neufeld",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Neufeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Neufeld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054132336"
                        ],
                        "name": "Bryce Larson",
                        "slug": "Bryce-Larson",
                        "structuredName": {
                            "firstName": "Bryce",
                            "lastName": "Larson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bryce Larson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714772"
                        ],
                        "name": "Dale Schuurmans",
                        "slug": "Dale-Schuurmans",
                        "structuredName": {
                            "firstName": "Dale",
                            "lastName": "Schuurmans",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dale Schuurmans"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 68
                            }
                        ],
                        "text": "This is somewhat reminiscent of unsupervised marginbased clustering [29, 16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1123993,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5f93423c41914639a147ad8dd589967daf2ea877",
            "isKey": false,
            "numCitedBy": 478,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new method for clustering based on finding maximum margin hyperplanes through data. By reformulating the problem in terms of the implied equivalence relation matrix, we can pose the problem as a convex integer program. Although this still yields a difficult computational problem, the hard-clustering constraints can be relaxed to a soft-clustering formulation which can be feasibly solved with a semidefinite program. Since our clustering technique only depends on the data through the kernel matrix, we can easily achieve nonlinear clusterings in the same manner as spectral clustering. Experimental results show that our maximum margin clustering technique often obtains more accurate results than conventional clustering methods. The real benefit of our approach, however, is that it leads naturally to a semi-supervised training method for support vector machines. By maximizing the margin simultaneously on labeled and unlabeled training data, we achieve state of the art performance by using a single, integrated learning principle."
            },
            "slug": "Maximum-Margin-Clustering-Xu-Neufeld",
            "title": {
                "fragments": [],
                "text": "Maximum Margin Clustering"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "A new method for clustering based on finding maximum margin hyperplanes through data that leads naturally to a semi-supervised training method for support vector machines by maximizing the margin simultaneously on labeled and unlabeled training data."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49097100"
                        ],
                        "name": "Yizong Cheng",
                        "slug": "Yizong-Cheng",
                        "structuredName": {
                            "firstName": "Yizong",
                            "lastName": "Cheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yizong Cheng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14842224,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1c168275c59ba382588350ee1443537f59978183",
            "isKey": false,
            "numCitedBy": 3719,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Mean shift, a simple interactive procedure that shifts each data point to the average of data points in its neighborhood is generalized and analyzed in the paper. This generalization makes some k-means like clustering algorithms its special cases. It is shown that mean shift is a mode-seeking process on the surface constructed with a \"shadow\" kernal. For Gaussian kernels, mean shift is a gradient mapping. Convergence is studied for mean shift iterations. Cluster analysis if treated as a deterministic problem of finding a fixed point of mean shift that characterizes the data. Applications in clustering and Hough transform are demonstrated. Mean shift is also considered as an evolutionary strategy that performs multistart global optimization. >"
            },
            "slug": "Mean-Shift,-Mode-Seeking,-and-Clustering-Cheng",
            "title": {
                "fragments": [],
                "text": "Mean Shift, Mode Seeking, and Clustering"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "Mean shift, a simple interactive procedure that shifts each data point to the average of data points in its neighborhood is generalized and analyzed and makes some k-means like clustering algorithms its special cases."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143651750"
                        ],
                        "name": "Milo\u0161 Radovanovi\u0107",
                        "slug": "Milo\u0161-Radovanovi\u0107",
                        "structuredName": {
                            "firstName": "Milo\u0161",
                            "lastName": "Radovanovi\u0107",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Milo\u0161 Radovanovi\u0107"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728442"
                        ],
                        "name": "A. Nanopoulos",
                        "slug": "A.-Nanopoulos",
                        "structuredName": {
                            "firstName": "Alexandros",
                            "lastName": "Nanopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Nanopoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144395551"
                        ],
                        "name": "M. Ivanovi\u0107",
                        "slug": "M.-Ivanovi\u0107",
                        "structuredName": {
                            "firstName": "Mirjana",
                            "lastName": "Ivanovi\u0107",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ivanovi\u0107"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 35
                            }
                        ],
                        "text": "In high-dimensional feature space, [20] suggests that normalized correlation provides a better metric than the Euclidean distance commonly used in mean-shift."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15419964,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "20d8fbd7cab21b1c9495413e1a19aaf156478e8c",
            "isKey": false,
            "numCitedBy": 103,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "High dimensionality can pose severe difficulties, widely recognized as different aspects of the curse of dimensionality. In this paper we study a new aspect of the curse pertaining to the distribution of k-occurrences, i.e., the number of times a point appears among the k nearest neighbors of other points in a data set. We show that, as dimensionality increases, this distribution becomes considerably skewed and hub points emerge (points with very high k-occurrences). We examine the origin of this phenomenon, showing that it is an inherent property of high-dimensional vector space, and explore its influence on applications based on measuring distances in vector spaces, notably classification, clustering, and information retrieval."
            },
            "slug": "Nearest-neighbors-in-high-dimensional-data:-the-and-Radovanovi\u0107-Nanopoulos",
            "title": {
                "fragments": [],
                "text": "Nearest neighbors in high-dimensional data: the emergence and influence of hubs"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "This paper studies a new aspect of the curse pertaining to the distribution of k-occurrences, i.e., the number of times a point appears among the k nearest neighbors of other points in a data set, and shows that, as dimensionality increases, this distribution becomes considerably skewed and hub points emerge (points with very high k-Occurrences)."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '09"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685020"
                        ],
                        "name": "D. Comaniciu",
                        "slug": "D.-Comaniciu",
                        "structuredName": {
                            "firstName": "Dorin",
                            "lastName": "Comaniciu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Comaniciu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145320582"
                        ],
                        "name": "Visvanathan Ramesh",
                        "slug": "Visvanathan-Ramesh",
                        "structuredName": {
                            "firstName": "Visvanathan",
                            "lastName": "Ramesh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Visvanathan Ramesh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145776090"
                        ],
                        "name": "P. Meer",
                        "slug": "P.-Meer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Meer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Meer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 36
                            }
                        ],
                        "text": "The well-known mean-shift algorithm [2, 3, 8] has been proposed to address many of these problems."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 559739,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "2cfa006b33084abe8160b001f9a24944cda25d05",
            "isKey": false,
            "numCitedBy": 3282,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method for real time tracking of non-rigid objects seen from a moving camera is proposed. The central computational module is based on the mean shift iterations and finds the most probable target position in the current frame. The dissimilarity between the target model (its color distribution) and the target candidates is expressed by a metric derived from the Bhattacharyya coefficient. The theoretical analysis of the approach shows that it relates to the Bayesian framework while providing a practical, fast and efficient solution. The capability of the tracker to handle in real time partial occlusions, significant clutter, and target scale variations, is demonstrated for several image sequences."
            },
            "slug": "Real-time-tracking-of-non-rigid-objects-using-mean-Comaniciu-Ramesh",
            "title": {
                "fragments": [],
                "text": "Real-time tracking of non-rigid objects using mean shift"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The theoretical analysis of the approach shows that it relates to the Bayesian framework while providing a practical, fast and efficient solution for real time tracking of non-rigid objects seen from a moving camera."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "67154907"
                        ],
                        "name": "Masashi Sugiyama",
                        "slug": "Masashi-Sugiyama",
                        "structuredName": {
                            "firstName": "Masashi",
                            "lastName": "Sugiyama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Masashi Sugiyama"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108444623"
                        ],
                        "name": "Teruyuki Suzuki",
                        "slug": "Teruyuki-Suzuki",
                        "structuredName": {
                            "firstName": "Teruyuki",
                            "lastName": "Suzuki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Teruyuki Suzuki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1897617"
                        ],
                        "name": "T. Kanamori",
                        "slug": "T.-Kanamori",
                        "structuredName": {
                            "firstName": "Takafumi",
                            "lastName": "Kanamori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanamori"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 75
                            }
                        ],
                        "text": "While a number of algorithms exist for estimating ratios of densities (see [25] for a review), we did not find any that were particularly suitable for finding local maxima of density ratios."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10275872,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fb361d6104b3f158ab4e74aa89779f0600ff6512",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Density ratio estimation has attracted a great deal of attention in the statistics and machine learning communities since it can be used for solving various statistical data processing tasks such as non-stationarity adaptation, two-sample test, outlier detection, independence test, feature selection/extraction, independent component analysis, causal inference, and conditional probability estimation. When estimating the density ratio, it is preferable to avoid estimating densities since density estimation is known to be a hard problem. In this paper, we give a comprehensive review of density ratio estimation methods based on moment matching, probabilistic classification, and ratio matching."
            },
            "slug": "Density-Ratio-Estimation:-A-Comprehensive-Review-Sugiyama-Suzuki",
            "title": {
                "fragments": [],
                "text": "Density Ratio Estimation: A Comprehensive Review"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A comprehensive review of density ratio estimation methods based on moment matching, probabilistic classification, and ratio matching is given."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2295441"
                        ],
                        "name": "K. Fukunaga",
                        "slug": "K.-Fukunaga",
                        "structuredName": {
                            "firstName": "Keinosuke",
                            "lastName": "Fukunaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fukunaga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2322936"
                        ],
                        "name": "L. Hostetler",
                        "slug": "L.-Hostetler",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Hostetler",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Hostetler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15299210,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "98431da7222ee3fe12d277facf5ca1561c56d4f3",
            "isKey": false,
            "numCitedBy": 2994,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Nonparametric density gradient estimation using a generalized kernel approach is investigated. Conditions on the kernel functions are derived to guarantee asymptotic unbiasedness, consistency, and uniform consistency of the estimates. The results are generalized to obtain a simple mcan-shift estimate that can be extended in a k -nearest-neighbor approach. Applications of gradient estimation to pattern recognition are presented using clustering and intrinsic dimensionality problems, with the ultimate goal of providing further understanding of these problems in terms of density gradients."
            },
            "slug": "The-estimation-of-the-gradient-of-a-density-with-in-Fukunaga-Hostetler",
            "title": {
                "fragments": [],
                "text": "The estimation of the gradient of a density function, with applications in pattern recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Applications of gradient estimation to pattern recognition are presented using clustering and intrinsic dimensionality problems, with the ultimate goal of providing further understanding of these problems in terms of density gradients."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 86
                            }
                        ],
                        "text": "We show two patches with their 5 nearest-neighbors from the Paris Street View dataset [5]; beneath each nearest neighbor is its distance from query."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 29
                            }
                        ],
                        "text": "Recently, several approaches [5, 6, 11, 12, 15, 23, 26, 27] have proposed mining visual data for discriminative mid-level visual elements, i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 91
                            }
                        ],
                        "text": "We could perform this analysis on any dataset containing positive and negative images, but [5] presents a dataset which is particularly suitable."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 48
                            }
                        ],
                        "text": "This is much like the iterative SVM training of [5], except that it uses LDA instead of an SVM."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 108
                            }
                        ],
                        "text": "2, 000-dimensional HOG) causes k-means to produce visually poor clusters due to the curse of dimensionality [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 43
                            }
                        ],
                        "text": ", scene categories [12] or GPS coordinates [5] (but can also run unsupervised [23]), and have been recently used for tasks including image classification [12, 23, 27], object detection [6], visual data mining [5, 15], action recognition [11], and geometry estimation [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 37
                            }
                        ],
                        "text": "Finally, we include the algorithm of [5], which is a weakly supervised version of [23], except that knn is being used for initialization instead of kmeans."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 19
                            }
                        ],
                        "text": "Several approaches [5, 6, 12, 23] have been proposed to discover mid-level visual elements, that are both 1) representative, i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 221
                            }
                        ],
                        "text": "We also propose the Purity-Coverage plot as a principled way of experimentally analyzing and evaluating different visual discovery approaches, and compare our method against prior work on the Paris Street View dataset of [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and A"
            },
            "venue": {
                "fragments": [],
                "text": "A. Efros. What makes Paris look like Paris? SIGGRAPH"
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Maximum margin clustering. In NIPS"
            },
            "venue": {
                "fragments": [],
                "text": "Maximum margin clustering. In NIPS"
            },
            "year": 2004
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 20,
            "methodology": 14
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 32,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Mid-level-Visual-Element-Discovery-as-Mode-Seeking-Doersch-Gupta/b222b3b05d8d313420dbde8b163e4336a85dcde9?sort=total-citations"
}