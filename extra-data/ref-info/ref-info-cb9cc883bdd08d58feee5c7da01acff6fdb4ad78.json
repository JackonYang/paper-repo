{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708581"
                        ],
                        "name": "Sebastian Pad\u00f3",
                        "slug": "Sebastian-Pad\u00f3",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Pad\u00f3",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sebastian Pad\u00f3"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747893"
                        ],
                        "name": "Mirella Lapata",
                        "slug": "Mirella-Lapata",
                        "structuredName": {
                            "firstName": "Mirella",
                            "lastName": "Lapata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mirella Lapata"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 125
                            }
                        ],
                        "text": "This corresponds to a beneficial effect of syntactic information found for other applications of semantic spaces (Lin, 1998; Pado\u0301 and Lapata, 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 4
                            }
                        ],
                        "text": "See Pado\u0301 and Lapata (2007).\ncentroid of seen filler vectors ~va."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 6
                            }
                        ],
                        "text": "However, the concrete instantiations that Mitchell and Lapata consider disregards K and R, thus sharing the other models\u2019 limitations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 56
                            }
                        ],
                        "text": "We also consider a \u201cdependency-based\u201d vector space (SYN, (Pado\u0301 and Lapata, 2007))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7747235,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "7441116c5b5a745708a9d7c5aa0ecf04e0c76c93",
            "isKey": false,
            "numCitedBy": 695,
            "numCiting": 103,
            "paperAbstract": {
                "fragments": [],
                "text": "Traditionally, vector-based semantic space models use word co-occurrence counts from large corpora to represent lexical meaning. In this article we present a novel framework for constructing semantic spaces that takes syntactic relations into account. We introduce a formalization for this class of models, which allows linguistic knowledge to guide the construction process. We evaluate our framework on a range of tasks relevant for cognitive science and natural language processing: semantic priming, synonymy detection, and word sense disambiguation. In all cases, our framework obtains results that are comparable or superior to the state of the art."
            },
            "slug": "Dependency-Based-Construction-of-Semantic-Space-Pad\u00f3-Lapata",
            "title": {
                "fragments": [],
                "text": "Dependency-Based Construction of Semantic Space Models"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This article presents a novel framework for constructing semantic spaces that takes syntactic relations into account, and introduces a formalization for this class of models, which allows linguistic knowledge to guide the construction process."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40591835"
                        ],
                        "name": "K. Lund",
                        "slug": "K.-Lund",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Lund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Lund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50611682"
                        ],
                        "name": "C. Burgess",
                        "slug": "C.-Burgess",
                        "structuredName": {
                            "firstName": "Curt",
                            "lastName": "Burgess",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Burgess"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 66
                            }
                        ],
                        "text": "Our first space is a traditional \u201cbag-of-words\u201d vector space (BOW, (Lund and Burgess, 1996))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 149
                            }
                        ],
                        "text": "In a default semantic space as described above, each vector represents one lemma, averaging over\nall its possible usages (Landauer and Dumais, 1997; Lund and Burgess, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In addition, the model performs at and above the state of the art for modeling the contextual adequacy of paraphrases."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61090106,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c7093913b4daa0f34d9d58a41ceb0475cc3cc9f4",
            "isKey": false,
            "numCitedBy": 1721,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "A procedure that processes a corpus of text and produces numeric vectors containing information about its meanings for each word is presented. This procedure is applied to a large corpus of natural language text taken from Usenet, and the resulting vectors are examined to determine what information is contained within them. These vectors provide the coordinates in a high-dimensional space in which word relationships can be analyzed. Analyses of both vector similarity and multidimensional scaling demonstrate that there is significant semantic information carried in the vectors. A comparison of vector similarity with human reaction times in a single-word priming experiment is presented. These vectors provide the basis for a representational model of semantic memory, hyperspace analogue to language (HAL)."
            },
            "slug": "Producing-high-dimensional-semantic-spaces-from-Lund-Burgess",
            "title": {
                "fragments": [],
                "text": "Producing high-dimensional semantic spaces from lexical co-occurrence"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A procedure that processes a corpus of text and produces numeric vectors containing information about its meanings for each word, which provide the basis for a representational model of semantic memory, hyperspace analogue to language (HAL)."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34902160"
                        ],
                        "name": "Jeff Mitchell",
                        "slug": "Jeff-Mitchell",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Mitchell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeff Mitchell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747893"
                        ],
                        "name": "Mirella Lapata",
                        "slug": "Mirella-Lapata",
                        "structuredName": {
                            "firstName": "Mirella",
                            "lastName": "Lapata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mirella Lapata"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 126
                            }
                        ],
                        "text": "There have been several approaches in the literature (Smolensky, 1990; Schu\u0308tze, 1998; Kintsch, 2001; McDonald and Brew, 2004; Mitchell and Lapata, 2008) that compute meaning in context from lemma vectors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In addition, the model performs at and above the state of the art for modeling the contextual adequacy of paraphrases."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 121
                            }
                        ],
                        "text": "One proposal for \u201cscaling up\u201d is to straightforwardly interpret c = a b as the meaning of the phrase a + b (Kintsch, 2001; Mitchell and Lapata, 2008)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 0
                            }
                        ],
                        "text": "Mitchell and Lapata (2008) propose a framework to represent the meaning of the combination p + a as a function f operating on four components:\nc = f(p, a, R,K) (3)\nR is the relation holding between p and a, and K additional knowledge."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 83
                            }
                        ],
                        "text": "In both experiments, we compare the SVS model against the state-of-theart model by Mitchell and Lapata 2008 (henceforth M&L; cf. Sec."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This section provides the background to the following experimental evaluation of SVS, including parameters used for computing the SVS representations that will be used in the experiments."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 40
                            }
                        ],
                        "text": "The context b can consist of as little as one word, as shown in Example (1)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18597583,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b5d67d1dc671bce42a9daac0c3605adb3fcfc697",
            "isKey": true,
            "numCitedBy": 730,
            "numCiting": 133,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a framework for representing the meaning of phrases and sentences in vector space. Central to our approach is vector composition which we operationalize in terms of additive and multiplicative functions. Under this framework, we introduce a wide range of composition models which we evaluate empirically on a sentence similarity task. Experimental results demonstrate that the multiplicative models are superior to the additive alternatives when compared against human judgments."
            },
            "slug": "Vector-based-Models-of-Semantic-Composition-Mitchell-Lapata",
            "title": {
                "fragments": [],
                "text": "Vector-based Models of Semantic Composition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Under this framework, a wide range of composition models are introduced which are evaluated empirically on a sentence similarity task and demonstrate that the multiplicative models are superior to the additive alternatives when compared against human judgments."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3025325"
                        ],
                        "name": "W. Kintsch",
                        "slug": "W.-Kintsch",
                        "structuredName": {
                            "firstName": "Walter",
                            "lastName": "Kintsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Kintsch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 107
                            }
                        ],
                        "text": "One proposal for \u201cscaling up\u201d is to straightforwardly interpret c = a b as the meaning of the phrase a + b (Kintsch, 2001; Mitchell and Lapata, 2008)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 53
                            }
                        ],
                        "text": "There have been several approaches in the literature (Smolensky, 1990; Sch\u00fctze, 1998; Kintsch, 2001; McDonald and Brew, 2004; Mitchell and Lapata, 2008) that compute meaning in context from lemma vectors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 219322170,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "040a6d4542111c1b6161533aa0818c0b025505a0",
            "isKey": false,
            "numCitedBy": 562,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Predication-Kintsch",
            "title": {
                "fragments": [],
                "text": "Predication"
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145586618"
                        ],
                        "name": "Diana McCarthy",
                        "slug": "Diana-McCarthy",
                        "structuredName": {
                            "firstName": "Diana",
                            "lastName": "McCarthy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diana McCarthy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733928"
                        ],
                        "name": "R. Navigli",
                        "slug": "R.-Navigli",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Navigli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Navigli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 80
                            }
                        ],
                        "text": "For this experiment, we use the SemEval1 lexical substitution (lexsub) dataset (McCarthy and Navigli, 2007), which contains 10 instances each of 200 target words in sentential contexts, drawn from Sharoff\u2019s (2006) English Internet Corpus."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 170
                            }
                        ],
                        "text": "Semantic spaces are attractive because they provide a model of word meaning that is independent of dictionary senses and their much-discussed problems (Kilgarriff, 1997; McCarthy and Navigli, 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 126584,
            "fieldsOfStudy": [
                "Linguistics",
                "Psychology"
            ],
            "id": "00162f43964fd457a9158408c1ac0e8990489782",
            "isKey": false,
            "numCitedBy": 220,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe the English Lexical Substitution task for SemEval. In the task, annotators and systems find an alternative substitute word or phrase for a target word in context. The task involves both finding the synonyms and disambiguating the context. Participating systems are free to use any lexical resource. There is a subtask which requires identifying cases where the word is functioning as part of a multiword in the sentence and detecting what that multiword is."
            },
            "slug": "SemEval-2007-Task-10:-English-Lexical-Substitution-McCarthy-Navigli",
            "title": {
                "fragments": [],
                "text": "SemEval-2007 Task 10: English Lexical Substitution Task"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "The English Lexical Substitution task for SemEval is described, in the task, annotators and systems find an alternative substitute word or phrase for a target word in context that involves both finding the synonyms and disambiguating the context."
            },
            "venue": {
                "fragments": [],
                "text": "Fourth International Workshop on Semantic Evaluations (SemEval-2007)"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "92063793"
                        ],
                        "name": "M. Croker",
                        "slug": "M.-Croker",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Croker",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Croker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143694777"
                        ],
                        "name": "Frank Keller",
                        "slug": "Frank-Keller",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Keller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frank Keller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711215"
                        ],
                        "name": "U. Pad\u00f3",
                        "slug": "U.-Pad\u00f3",
                        "structuredName": {
                            "firstName": "Ulrike",
                            "lastName": "Pad\u00f3",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Pad\u00f3"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 2
                            }
                        ],
                        "text": "The second category of prior studies concentrates on contexts consisting of a single word only, typically modeling the combination of a predicate p and an argument a. Kintsch (2001) uses vector representations of p and a to identify the set of words that are similar to both p and a."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 180
                            }
                        ],
                        "text": "Expectations affect reading times (McRae et al., 1998), the interpretation of participles (Ferretti et al., 2003), and sentence processing generally (Narayanan and Jurafsky, 2002; Pado\u0301 et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15921186,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a38083e2dab2aae2e4161e96f8c4a6767ab939e5",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a model of human sentence processing that extends a standard probabilistic grammar model with a semantic module which computes the thematic t of verbs and arguments in a cognitively plausible way. Our model differs from existing probabilistic accounts (e.g., Jurafsky, 1996) by capturing both syntactic and semantic inuences in human sentence processing. It also overcomes limitations of constraint-based models (Spivey-Knowlton, 1996; Narayanan and Jurafsky, 2002), as its parameters can be acquired automatically from corpus data, and no hand-coding of constraints is required. We evaluate our semantic module against human ratings of thematic t, and also test the complete model\u2019s performance for two wellstudied ambiguities from the sentence processing literature."
            },
            "slug": "Combining-Syntax-and-Thematic-Fit-in-a-Model-of-Croker-Keller",
            "title": {
                "fragments": [],
                "text": "Combining Syntax and Thematic Fit in a Probabilistic Model of Sentence Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A model of human sentence processing that extends a standard probabilistic grammar model with a semantic module which computes the thematic t of verbs and arguments in a cognitively plausible way is presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746503"
                        ],
                        "name": "A. Kilgarriff",
                        "slug": "A.-Kilgarriff",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Kilgarriff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kilgarriff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 152
                            }
                        ],
                        "text": "Semantic spaces are attractive because they provide a model of word meaning that is independent of dictionary senses and their much-discussed problems (Kilgarriff, 1997; McCarthy and Navigli, 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3265361,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "c212eab7a430dd931ac17e7cd9779838296dd578",
            "isKey": false,
            "numCitedBy": 456,
            "numCiting": 123,
            "paperAbstract": {
                "fragments": [],
                "text": "Word sense disambiguation assumes word senses. Withinthe lexicography and linguistics literature, they areknown to bevery slippery entities. The first part of the paperlooks at problemswith existing accounts of \u2018word sense\u2019 and describesthe various kinds of ways in which a word's meaning candeviate from its coremeaning. An analysis is presented in which wordsenses areabstractions from clusters of corpus citations, inaccordance withcurrent lexicographic practice. The corpus citations,not the wordsenses, are the basic objects in the ontology. Thecorpus citationswill be clustered into senses according to thepurposes of whoever or whatever does the clustering. In theabsence of suchpurposes, word senses do not exist.Word sense disambiguation also needs a set of wordsenses todisambiguate between. In most recent work, the sethas been takenfrom a general-purpose lexical resource, with theassumption that thelexical resource describes the word senses ofEnglish/French/...,between which NLP applications will need todisambiguate. Theimplication of the first part of the paper is, bycontrast, that wordsenses exist only relative to a task. Thefinal part of the paper pursues this, exploring, bymeans of asurvey, whether and how word sense ambiguity is infact a problem forcurrent NLP applications."
            },
            "slug": "\"I-Don\u2019t-Believe-in-Word-Senses\"-Kilgarriff",
            "title": {
                "fragments": [],
                "text": "\"I Don\u2019t Believe in Word Senses\""
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is suggested, by contrast, that wordsenses exist only relative to a task, and whether and how word sense ambiguity is infact a problem for current NLP applications is explored."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Humanit."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144418438"
                        ],
                        "name": "Hinrich Sch\u00fctze",
                        "slug": "Hinrich-Sch\u00fctze",
                        "structuredName": {
                            "firstName": "Hinrich",
                            "lastName": "Sch\u00fctze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hinrich Sch\u00fctze"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 71
                            }
                        ],
                        "text": "There have been several approaches in the literature (Smolensky, 1990; Schu\u0308tze, 1998; Kintsch, 2001; McDonald and Brew, 2004; Mitchell and Lapata, 2008) that compute meaning in context from lemma vectors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 40
                            }
                        ],
                        "text": "The best-known work in this category is Schu\u0308tze (1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8754851,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3cd9fd8a36c8feb74bb20ae25817edb9c6a0518c",
            "isKey": false,
            "numCitedBy": 1401,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents context-group discrimination, a disambiguation algorithm based on clustering. Senses are interpreted as groups (or clusters) of similar contexts of the ambiguous word. Words, contexts, and senses are represented in Word Space, a high-dimensional, real-valued space in which closeness corresponds to semantic similarity. Similarity in Word Space is based on second-order co-occurrence: two tokens (or contexts) of the ambiguous word are assigned to the same sense cluster if the words they co-occur with in turn occur with similar words in a training corpus. The algorithm is automatic and unsupervised in both training and application: senses are induced from a corpus without labeled training instances or other external knowledge sources. The paper demonstrates good performance of context-group discrimination for a sample of natural and artificial ambiguous words."
            },
            "slug": "Automatic-Word-Sense-Discrimination-Sch\u00fctze",
            "title": {
                "fragments": [],
                "text": "Automatic Word Sense Discrimination"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper presents context-group discrimination, a disambiguation algorithm based on clustering that demonstrates good performance of context- group discrimination for a sample of natural and artificial ambiguous words."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111327888"
                        ],
                        "name": "Michael N. Jones",
                        "slug": "Michael-N.-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael N. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1821878"
                        ],
                        "name": "D. Mewhort",
                        "slug": "D.-Mewhort",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Mewhort",
                            "middleNames": [
                                "J.",
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mewhort"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 22
                            }
                        ],
                        "text": "This difference in meaning is due to the difference in relation: in (2a), horse is the subject, while in (2b) it is the object."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 0
                            }
                        ],
                        "text": "Jones and Mewhort (2007) represent lemma meaning by using circular convolution to encode n-gram co-occurrence information into vectors of fixed dimensionality."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7819391,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "d3cf28ab36ff7f7601a55c1e832736b2473a07f0",
            "isKey": false,
            "numCitedBy": 576,
            "numCiting": 164,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors present a computational model that builds a holographic lexicon representing both word meaning and word order from unsupervised experience with natural language. The model uses simple convolution and superposition mechanisms (cf. B. B. Murdock, 1982) to learn distributed holographic representations for words. The structure of the resulting lexicon can account for empirical data from classic experiments studying semantic typicality, categorization, priming, and semantic constraint in sentence completions. Furthermore, order information can be retrieved from the holographic representations, allowing the model to account for limited word transitions without the need for built-in transition rules. The model demonstrates that a broad range of psychological data can be accounted for directly from the structure of lexical representations learned in this way, without the need for complexity to be built into either the processing mechanisms or the representations. The holographic representations are an appropriate knowledge representation to be used by higher order models of language comprehension, relieving the complexity required at the higher level."
            },
            "slug": "Representing-word-meaning-and-order-information-in-Jones-Mewhort",
            "title": {
                "fragments": [],
                "text": "Representing word meaning and order information in a composite holographic lexicon."
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A computational model that builds a holographic lexicon representing both word meaning and word order from unsupervised experience with natural language demonstrates that a broad range of psychological data can be accounted for directly from the structure of lexical representations learned in this way, without the need for complexity to be built into either the processing mechanisms or the representations."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153592298"
                        ],
                        "name": "S. McDonald",
                        "slug": "S.-McDonald",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "McDonald",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. McDonald"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895292"
                        ],
                        "name": "Chris Brew",
                        "slug": "Chris-Brew",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Brew",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Brew"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 101
                            }
                        ],
                        "text": "There have been several approaches in the literature (Smolensky, 1990; Schu\u0308tze, 1998; Kintsch, 2001; McDonald and Brew, 2004; Mitchell and Lapata, 2008) that compute meaning in context from lemma vectors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 0
                            }
                        ],
                        "text": "McDonald and Brew (2004) present a similar model."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18143695,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "2f55b6959997e8464c19140644c6e3d6781a55b4",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the most robust findings of experimental psycholinguistics is that the context in which a word is presented influences the effort involved in processing that word. We present a computational model of contextual facilitation based on word co-occurrence vectors, and empirically validate the model through simulation of three representative types of context manipulation: single word priming, multiple-priming and contextual constraint. The aim of our study is to find out whether special-purpose mechanisms are necessary in order to capture the pattern of the experimental results."
            },
            "slug": "A-Distributional-Model-of-Semantic-Context-Effects-McDonald-Brew",
            "title": {
                "fragments": [],
                "text": "A Distributional Model of Semantic Context Effects in Lexical Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The aim of the study is to find out whether special-purpose mechanisms are necessary in order to capture the pattern of the experimental results."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690956"
                        ],
                        "name": "Dekang Lin",
                        "slug": "Dekang-Lin",
                        "structuredName": {
                            "firstName": "Dekang",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dekang Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 114
                            }
                        ],
                        "text": "This corresponds to a beneficial effect of syntactic information found for other applications of semantic spaces (Lin, 1998; Pado\u0301 and Lapata, 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15698938,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fd1901f34cc3673072264104885d70555b1a4cdc",
            "isKey": false,
            "numCitedBy": 1928,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Bootstrapping semantics from text is one of the greatest challenges in natural language learning. We first define a word similarity measure based on the distributional pattern of words. The similarity measure allows us to construct a thesaurus using a parsed corpus. We then present a new evaluation methodology for the automatically constructed thesaurus. The evaluation results show that the thesaurus is significantly closer to WordNet than Roget Thesaurus is."
            },
            "slug": "Automatic-Retrieval-and-Clustering-of-Similar-Words-Lin",
            "title": {
                "fragments": [],
                "text": "Automatic Retrieval and Clustering of Similar Words"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A word similarity measure based on the distributional pattern of words allows the automatically constructed thesaurus to be significantly closer to WordNet than Roget Thesaurus is."
            },
            "venue": {
                "fragments": [],
                "text": "COLING-ACL"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719404"
                        ],
                        "name": "Alessandro Moschitti",
                        "slug": "Alessandro-Moschitti",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Moschitti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alessandro Moschitti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794305"
                        ],
                        "name": "S. Quarteroni",
                        "slug": "S.-Quarteroni",
                        "structuredName": {
                            "firstName": "Silvia",
                            "lastName": "Quarteroni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Quarteroni"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 166
                            }
                        ],
                        "text": "It is difficult to conceive how c could encode deeper semantic properties, like predicateargument structure (distinguishing \u201cdog bites man\u201d and \u201cman bites dog\u201d), that are crucial for sentencelevel semantic tasks such as the recognition of textual entailment (Dagan et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 146
                            }
                        ],
                        "text": "Current kernels are mostly tree kernels that compare syntactic structure, and use semantic information mostly for smoothing syntactic similarity (Moschitti and Quarteroni, 2008)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12670725,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8faaad91790c3b8e5c57cde9fb0403d008ce10b0",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Natural Language Processing (NLP) for Information Retrieval has always been an interesting and challenging research area. Despite the high expectations, most of the results indicate that successfully using NLP is very complex. In this paper, we show how Support Vector Machines along with kernel functions can effectively represent syntax and semantics. Our experiments on question/answer classification show that the above models highly improve on bag-of-words on a TREC dataset."
            },
            "slug": "Kernels-on-Linguistic-Structures-for-Answer-Moschitti-Quarteroni",
            "title": {
                "fragments": [],
                "text": "Kernels on Linguistic Structures for Answer Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Support Vector Machines along with kernel functions can effectively represent syntax and semantics in NLP and show that the above models highly improve on bag-of-words on a TREC dataset."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708581"
                        ],
                        "name": "Sebastian Pad\u00f3",
                        "slug": "Sebastian-Pad\u00f3",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Pad\u00f3",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sebastian Pad\u00f3"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711215"
                        ],
                        "name": "U. Pad\u00f3",
                        "slug": "U.-Pad\u00f3",
                        "structuredName": {
                            "firstName": "Ulrike",
                            "lastName": "Pad\u00f3",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Pad\u00f3"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708114"
                        ],
                        "name": "Katrin Erk",
                        "slug": "Katrin-Erk",
                        "structuredName": {
                            "firstName": "Katrin",
                            "lastName": "Erk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Katrin Erk"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 187
                            }
                        ],
                        "text": "Recently, a vectorspaced model of selectional preferences has been proposed that computes the typicality of an argument simply through similarity to previously seen arguments (Erk, 2007; Pado\u0301 et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10375802,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6fc56fac2ab7ac0554d2d1e2569e48bf3b259442",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we consider the computational modelling of human plausibility judgements for verb-relation-argument triples, a task equivalent to the computation of selectional preferences. Such models have applications both in psycholinguistics and in computational linguistics. By extending a recent model, we obtain a completely corpus-driven model for this task which achieves significant correlations with human judgements. It rivals or exceeds deeper, resource-driven models while exhibiting higher coverage. Moreover, we show that our model can be combined with deeper models to obtain better predictions than from either model alone."
            },
            "slug": "Flexible,-Corpus-Based-Modelling-of-Human-Pad\u00f3-Pad\u00f3",
            "title": {
                "fragments": [],
                "text": "Flexible, Corpus-Based Modelling of Human Plausibility Judgements"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A completely corpus-driven model is obtained for this task which rivals or exceeds deeper, resource-driven models while exhibiting higher coverage and can be combined with deeper models to obtain better predictions than from either model alone."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21169546"
                        ],
                        "name": "Donald Hindle",
                        "slug": "Donald-Hindle",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Hindle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Donald Hindle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2416786"
                        ],
                        "name": "Mats Rooth",
                        "slug": "Mats-Rooth",
                        "structuredName": {
                            "firstName": "Mats",
                            "lastName": "Rooth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mats Rooth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 134
                            }
                        ],
                        "text": "Attention has mostly been limited to selectional preferences of verbs, which have been used for example for syntactic disambiguation (Hindle and Rooth, 1993), word sense disambiguation (McCarthy and Carroll, 2003) and semantic role labeling (Gildea and Jurafsky, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 38
                            }
                        ],
                        "text": "The procedure does not take the relation between p and a into account."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5410054,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "bdaf232c561f1f50e88b1d24097e214890b37e8b",
            "isKey": false,
            "numCitedBy": 638,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose that many ambiguous prepositional phrase attachments can be resolved on the basis of the relative strength of association of the preposition with verbal and nominal heads, estimated on the basis of distribution in an automatically parsed corpus. This suggests that a distributional approach can provide an approximate solution to parsing problems that, in the worst case, call for complex reasoning."
            },
            "slug": "Structural-Ambiguity-and-Lexical-Relations-Hindle-Rooth",
            "title": {
                "fragments": [],
                "text": "Structural Ambiguity and Lexical Relations"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "It is proposed that many ambiguous prepositional phrase attachments can be resolved on the based of the relative strength of association of the preposition with verbal and nominal heads, estimated on the basis of distribution in an automatically parsed corpus."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680292"
                        ],
                        "name": "P. Resnik",
                        "slug": "P.-Resnik",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Resnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Resnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 217
                            }
                        ],
                        "text": "In linguistics, expectations, in the form of selectional restrictions and selectional preferences, have long been used in semantic theories (Katz and Fodor, 1964; Wilks, 1975), and more recently induced from corpora (Resnik, 1996; Brockmann and Lapata, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 41
                            }
                        ],
                        "text": "After this set has been narrowed down in a self-inhibitory network, the meaning of the predicateargument combination is obtained by computing the\ncentroid of its members\u2019 vectors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17857497,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "7fd71b88b0ec248336410f58a4e37ed3fbe84698",
            "isKey": false,
            "numCitedBy": 297,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Selectional-constraints:-an-information-theoretic-Resnik",
            "title": {
                "fragments": [],
                "text": "Selectional constraints: an information-theoretic model and its computational realization"
            },
            "venue": {
                "fragments": [],
                "text": "Cognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1836606"
                        ],
                        "name": "T. Landauer",
                        "slug": "T.-Landauer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Landauer",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Landauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728602"
                        ],
                        "name": "S. Dumais",
                        "slug": "S.-Dumais",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "Dumais",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dumais"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 251,
                                "start": 226
                            }
                        ],
                        "text": "These vectors are able to provide a robust model of semantic similarity that has been used in NLP (Salton et al., 1975; McCarthy and Carroll, 2003; Manning et al., 2008) and to model experimental results in cognitive science (Landauer and Dumais, 1997; McDonald and Ramscar, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 122
                            }
                        ],
                        "text": "In a default semantic space as described above, each vector represents one lemma, averaging over\nall its possible usages (Landauer and Dumais, 1997; Lund and Burgess, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 80
                            }
                        ],
                        "text": "In addition, the model performs at and above the state of the art for modeling the contextual adequacy of paraphrases."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1144461,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "68dd4b89ce1407372a29d05ca9e4e1a2e0513617",
            "isKey": false,
            "numCitedBy": 5788,
            "numCiting": 210,
            "paperAbstract": {
                "fragments": [],
                "text": "How do people know as much as they do with as little information as they get? The problem takes many forms; learning vocabulary from text is an especially dramatic and convenient case for research. A new general theory of acquired similarity and knowledge representation, latent semantic analysis (LSA), is presented and used to successfully simulate such learning and several other psycholinguistic phenomena. By inducing global knowledge indirectly from local co-occurrence data in a large body of representative text, LSA acquired knowledge about the full vocabulary of English at a comparable rate to schoolchildren. LSA uses no prior linguistic or perceptual similarity knowledge; it is based solely on a general mathematical learning method that achieves powerful inductive effects by extracting the right number of dimensions (e.g., 300) to represent objects and contexts. Relations to other theories, phenomena, and problems are sketched."
            },
            "slug": "A-Solution-to-Plato's-Problem:-The-Latent-Semantic-Landauer-Dumais",
            "title": {
                "fragments": [],
                "text": "A Solution to Plato's Problem: The Latent Semantic Analysis Theory of Acquisition, Induction, and Representation of Knowledge."
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A new general theory of acquired similarity and knowledge representation, latent semantic analysis (LSA), is presented and used to successfully simulate such learning and several other psycholinguistic phenomena."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145586618"
                        ],
                        "name": "Diana McCarthy",
                        "slug": "Diana-McCarthy",
                        "structuredName": {
                            "firstName": "Diana",
                            "lastName": "McCarthy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diana McCarthy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144708726"
                        ],
                        "name": "John A. Carroll",
                        "slug": "John-A.-Carroll",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Carroll",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John A. Carroll"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 120
                            }
                        ],
                        "text": "These vectors are able to provide a robust model of semantic similarity that has been used in NLP (Salton et al., 1975; McCarthy and Carroll, 2003; Manning et al., 2008) and to model experimental results in cognitive science (Landauer and Dumais, 1997; McDonald and Ramscar, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 66
                            }
                        ],
                        "text": "This makes it possible to integrate syntax into the computation of word meaning in context."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 186
                            }
                        ],
                        "text": "Attention has mostly been limited to selectional preferences of verbs, which have been used for example for syntactic disambiguation (Hindle and Rooth, 1993), word sense disambiguation (McCarthy and Carroll, 2003) and semantic role labeling (Gildea and Jurafsky, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2252135,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "1712bcad35ba5764fbfcdb624e9a7f3d4a880717",
            "isKey": false,
            "numCitedBy": 150,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Selectional preferences have been used by word sense disambiguation (WSD) systems as one source of disambiguating information. We evaluate WSD using selectional preferences acquired for English adjectivenoun, subject, and direct object grammatical relationships with respect to a standard test corpus. The selectional preferences are specific to verb or adjective classes, rather than individual word forms, so they can be used to disambiguate the co-occurring adjectives and verbs, rather than just the nominal argument heads. We also investigate use of the one-senseper-discourse heuristic to propagate a sense tag for a word to other occurrences of the same word within the current document in order to increase coverage. Although the preferences perform well in comparison with other unsupervised WSD systems on the same corpus, the results show that for many applications, further knowledge sources would be required to achieve an adequate level of accuracy and coverage. In addition to quantifying performance, we analyze the results to investigate the situations in which the selectional preferences achieve the best precision and in which the one-sense-per-discourse heuristic increases performance."
            },
            "slug": "Disambiguating-Nouns,-Verbs,-and-Adjectives-Using-McCarthy-Carroll",
            "title": {
                "fragments": [],
                "text": "Disambiguating Nouns, Verbs, and Adjectives Using Automatically Acquired Selectional Preferences"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Although the preferences perform well in comparison with other unsupervised WSD systems on the same corpus, the results show that for many applications, further knowledge sources would be required to achieve an adequate level of accuracy and coverage."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708114"
                        ],
                        "name": "Katrin Erk",
                        "slug": "Katrin-Erk",
                        "structuredName": {
                            "firstName": "Katrin",
                            "lastName": "Erk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Katrin Erk"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 87
                            }
                        ],
                        "text": "We use a simple, knowledge-lean representation for selectional preferences inspired by Erk (2007), who models selectional preference through similarity to seen filler vectors ~va: We compute the selectional preference vector for word b and relation r as the weighted\n2More specifically, we used the\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 176
                            }
                        ],
                        "text": "Recently, a vectorspaced model of selectional preferences has been proposed that computes the typicality of an argument simply through similarity to previously seen arguments (Erk, 2007; Pado\u0301 et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 46
                            }
                        ],
                        "text": "This framework allows sensitivity to the relation."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2032205,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3cce57b4eb593359862817e93eb47e8655520652",
            "isKey": false,
            "numCitedBy": 161,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new, simple model for the automatic induction of selectional preferences, using corpus-based semantic similarity metrics. Focusing on the task of semantic role labeling, we compute selectional preferences for semantic roles. In evaluations the similarity-based model shows lower error rates than both Resnik\u2019s WordNet-based model and the EM-based clustering model, but has coverage problems."
            },
            "slug": "A-Simple,-Similarity-based-Model-for-Selectional-Erk",
            "title": {
                "fragments": [],
                "text": "A Simple, Similarity-based Model for Selectional Preferences"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "A new, simple model for the automatic induction of selectional preferences, using corpus-based semantic similarity metrics, focuses on the task of semantic role labeling and shows lower error rates than both Resnik's WordNet-based model and the EM-based clustering model."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153592298"
                        ],
                        "name": "S. McDonald",
                        "slug": "S.-McDonald",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "McDonald",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. McDonald"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799021"
                        ],
                        "name": "Michael Ramscar",
                        "slug": "Michael-Ramscar",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Ramscar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Ramscar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 279,
                                "start": 253
                            }
                        ],
                        "text": "These vectors are able to provide a robust model of semantic similarity that has been used in NLP (Salton et al., 1975; McCarthy and Carroll, 2003; Manning et al., 2008) and to model experimental results in cognitive science (Landauer and Dumais, 1997; McDonald and Ramscar, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 107
                            }
                        ],
                        "text": "In addition, the model performs at and above the state of the art for modeling the contextual adequacy of paraphrases."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13161362,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "878e4a4bcbd9938269cc44e28888e7492bd1df93",
            "isKey": false,
            "numCitedBy": 112,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Testing the Distributional Hypothesis: The Influence of Context on Judgements of Semantic Similarity Scott McDonald (scottm@cogsci.ed.ac.uk) Michael Ramscar (michael@cogsci.ed.ac.uk) Institute for Communicating and Collaborative Systems, University of Edinburgh 2 Buccleuch Place, Edinburgh EH8 9LW Scotland Abstract Distributional information has recently been implicated as playing an important role in several aspects of lan- guage ability. Learning the meaning of a word is thought to be dependent, at least in part, on exposure to the word in its linguistic contexts of use. In two experiments, we manipulated subjects\u2019 contextual experience with mar- ginally familiar and nonce words. Results showed that similarity judgements involving these words were af- fected by the distributional properties of the contexts i n which they were read. The accrual of contextual experi- ence was simulated in a semantic space model, by succes- sively adding larger amounts of experience in the form of item-in-context exemplars sampled from the British National Corpus. The experiments and the simulation provide support for the role of distributional information in developing representations of word meaning. The Distributional Hypothesis The basic human ability of language understanding \u2013 mak- ing sense of another person\u2019s utterances \u2013 does not develop in isolation from the environment. There is a growing body of research suggesting that distributional information plays a more powerful role than previously thought in a number of aspects of language processing. The exploita- tion of statistical regularities in the linguistic environment has been put forward to explain how language learners accomplish tasks from segmenting speech to bootstrap- ping word meaning. For example, Saffran, Aslin and Newport (1996) have demonstrated that infants are highly sensitive to simple conditional probability statistics, indicating how the ability to segment the speech stream into words may be realised. Adults, when faced with the task of identifying the word boundaries in an artificial language, also appear able to readily exploit such statistics (Saffran, Newport & Aslin, 1996). Redington, Chater and Finch (1998) have proposed that distributional information may contribute to the acquisition of syntactic knowledge by children. Useful information about the similarities and differences in the meaning of words has also been shown to be present in simple distributional statistics (e.g., Landauer & Dumais, 1997; McDonald, 2000). Based on the convergence of these recent studies into a cognitive role for distributional information in explaining language ability, we call the general principle under exploration the Distributional Hypothesis. The purpose of the present paper is to further test the distributional hypothesis, by examining the influence of context on similarity judgements involving marginally familiar and novel words. Our investigations are framed under the \u2018semantic space\u2019 approach to representing word meaning, to which we turn next. Distributional Models of Word Meaning The distributional hypothesis has provided the motivation for a class of objective statistical methods for representing meaning. Although the surge of interest in the approach arose in the fields of computational linguistics and infor- mation retrieval (e.g., Schutze, 1998; Grefenstette, 1994), where large-scale models of lexical semantics are crucial for tasks such as word sense disambiguation, high- dimensional \u2018semantic space\u2019 models are also useful tools for investigating how the brain represents the meaning of words. Word meaning can be considered to vary along many dimensions; semantic space models attempt to capture this variation in a coherent way, by positioning words in a geometric space. How to determine what the crucial dimensions are has been a long-standing problem; a recent and fruitful approach to this issue has been to label the dimensions of semantic space with words. A word is located in the space according to the degree to which it co- occurs with each of the words labelling the dimensions of the space. Co-occurrence frequency information is extracted from a record of language experience \u2013 a large corpus of natural language. Using this approach, two words that tend to occur in similar linguistic contexts \u2013 that is, they are distributionally similar \u2013 will be positioned closer together in semantic space than two words which are not as distributionally similar. Such simple distributional knowledge has been implicated in a variety of language processing behaviours, such as lexical priming (e.g., Lowe & McDonald, 2000; Lund, Burgess & Atchley, 1995; McDonald & Lowe, 1998), synonym selection (Landauer & Dumais, 1997), retrieval in analogical reason- ing (Ramscar & Yarlett, 2000) and judgements of semantic similarity (McDonald, 2000). Contextual co-occurrence, the fundamental relationship underlying the success of the semantic space approach to representing word meaning, can be defined in a number of ways. Perhaps the simplest (and the approach taken in the majority of the studies cited above) is to define co- occurrence in terms of a \u2018context window\u2019: the co-occur-"
            },
            "slug": "Testing-the-Distributioanl-Hypothesis:-The-of-on-of-McDonald-Ramscar",
            "title": {
                "fragments": [],
                "text": "Testing the Distributioanl Hypothesis: The influence of Context on Judgements of Semantic Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The general principle under exploration the Distributional Hypothesis, which combines the convergence of these recent studies into a cognitive role for distributional information in explaining language ability, is called."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797808"
                        ],
                        "name": "G. Salton",
                        "slug": "G.-Salton",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Salton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153873834"
                        ],
                        "name": "A. Wong",
                        "slug": "A.-Wong",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Wong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40498308"
                        ],
                        "name": "Chung-Shu Yang",
                        "slug": "Chung-Shu-Yang",
                        "structuredName": {
                            "firstName": "Chung-Shu",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chung-Shu Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 72
                            }
                        ],
                        "text": "We will explore the usability of vector space models of word meaning in NLP applications, formulated as the question of how to perform inferences on them in the context of the Textual Entailment task (Dagan et al., 2006)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 78
                            }
                        ],
                        "text": "Consequently, vector space methods and kernel methods have both been used for NLP tasks based on similarity, notably Information Retrieval and Textual Entailment."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 99
                            }
                        ],
                        "text": "These vectors are able to provide a robust model of semantic similarity that has been used in NLP (Salton et al., 1975; McCarthy and Carroll, 2003; Manning et al., 2008) and to model experimental results in cognitive science (Landauer and Dumais, 1997; McDonald and Ramscar, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 39
                            }
                        ],
                        "text": "This section reports on a second, more NLP-oriented experiment whose task is to distinguish between appropriate and inappropriate paraphrases on a broader range of constructions."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6473756,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d5f169880e30e1f76827d72f862555d00b01bed9",
            "isKey": true,
            "numCitedBy": 7617,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "In a document retrieval, or other pattern matching environment where stored entities (documents) are compared with each other or with incoming patterns (search requests), it appears that the best indexing (property) space is one where each entity lies as far away from the others as possible; in these circumstances the value of an indexing system may be expressible as a function of the density of the object space; in particular, retrieval performance may correlate inversely with space density. An approach based on space density computations is used to choose an optimum indexing vocabulary for a collection of documents. Typical evaluation results are shown, demonstating the usefulness of the model."
            },
            "slug": "A-vector-space-model-for-automatic-indexing-Salton-Wong",
            "title": {
                "fragments": [],
                "text": "A vector space model for automatic indexing"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "An approach based on space density computations is used to choose an optimum indexing vocabulary for a collection of documents, demonstating the usefulness of the model."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145811519"
                        ],
                        "name": "K. McRae",
                        "slug": "K.-McRae",
                        "structuredName": {
                            "firstName": "Ken",
                            "lastName": "McRae",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. McRae"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31683897"
                        ],
                        "name": "M. Hare",
                        "slug": "M.-Hare",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Hare",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hare"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2884373"
                        ],
                        "name": "J. Elman",
                        "slug": "J.-Elman",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Elman",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Elman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3370111"
                        ],
                        "name": "Todd R Ferretti",
                        "slug": "Todd-R-Ferretti",
                        "structuredName": {
                            "firstName": "Todd",
                            "lastName": "Ferretti",
                            "middleNames": [
                                "R"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Todd R Ferretti"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 65
                            }
                        ],
                        "text": "Expectations exist both for verbs and nouns (McRae et al., 1998; McRae et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 107
                            }
                        ],
                        "text": "However, their existence is supported in psycholinguistics by priming effects from nouns to typical verbs (McRae et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 93
                            }
                        ],
                        "text": "Current kernels are mostly tree kernels that compare syntactic structure, and use semantic information mostly for smoothing syntactic similarity (Moschitti and Quarteroni, 2008)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17666299,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "8b6effa8c7d0063e16db0c0d73cb97a4cca45b26",
            "isKey": false,
            "numCitedBy": 211,
            "numCiting": 81,
            "paperAbstract": {
                "fragments": [],
                "text": "We explore the implications of an event-based expectancy generation approach to language understanding, suggesting that one useful strategy employed by comprehenders is to generate expectations about upcoming words. We focus on two questions: (1) What role is played by elements other than verbs in generating expectancies? (2) What connection exists between expectancy generation and event-based knowledge? Because verbs follow their arguments in many constructions (particularly in verb-final languages), deferring expectations until the verb seems inefficient. Both human data and computational modeling suggest that other sentential elements may also play a role in predictive processing and that these constraints often reflect knowledge regarding typical events. We investigated these predictions, using both short and long stimulus onset asynchrony priming. Robust priming obtained when verbs were named aloud following typical agents, patients, instruments, and locations, suggesting that event memory is organized so that nouns denoting entities and objects activate the classes of events in which they typically play a role. These computations are assumed to be an important component of expectancy generation in sentence processing."
            },
            "slug": "A-basis-for-generating-expectancies-for-verbs-from-McRae-Hare",
            "title": {
                "fragments": [],
                "text": "A basis for generating expectancies for verbs from nouns"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Robust priming obtained when verbs were named aloud following typical agents, patients, instruments, and locations, suggesting that event memory is organized so that nouns denoting entities and objects activate the classes of events in which they typically play a role."
            },
            "venue": {
                "fragments": [],
                "text": "Memory & cognition"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48777451"
                        ],
                        "name": "J. Katz",
                        "slug": "J.-Katz",
                        "structuredName": {
                            "firstName": "Jerrold",
                            "lastName": "Katz",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Katz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38663378"
                        ],
                        "name": "J. Fodor",
                        "slug": "J.-Fodor",
                        "structuredName": {
                            "firstName": "Jerry",
                            "lastName": "Fodor",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Fodor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 141
                            }
                        ],
                        "text": "In linguistics, expectations, in the form of selectional restrictions and selectional preferences, have long been used in semantic theories (Katz and Fodor, 1964; Wilks, 1975), and more recently induced from corpora (Resnik, 1996; Brockmann and Lapata, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 269,
                                "start": 249
                            }
                        ],
                        "text": "The second category of prior studies concentrates on contexts consisting of a single word only, typically modeling the combination of a predicate p and an argument a. Kintsch (2001) uses vector representations of p and a to identify the set of words that are similar to both p and a."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9860676,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "7adb3c40ef03a458d35a3851fa66046936211cc3",
            "isKey": false,
            "numCitedBy": 1848,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide range of content in a trusted digital archive. We use information technology and tools to increase productivity and facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org.. Linguistic Society of America is collaborating with JSTOR to digitize, preserve and extend access to Language. 1. Introduction. This paperl does not attempt to present a semantic theory of a natural language, but rather to characterize the form of such a theory. A semantic theory of a natural language is part of a linguistic description of that language. Our problem, on the other hand, is part of the general theory of language, fully on a par with the problem of characterizing the structure of grammars of natural languages. A characterization of the abstract form of a semantic theory is given by a metatheory which answers such questions as these: What is the domain of a semantic theory? What are the descriptive and explanatory goals of a semantic theory? What mechanisms are employed in pursuit of these goals? What are the empirical and methodological constraints upon a semantic theory? The present paper approaches the problem of characterizing the form of semantic theories by describing the structure of a semantic theory of English. There can be little doubt but that the results achieved will apply directly to semantic theories of languages closely related to English. The question of their applicability to semantic theories of more distant languages will be left for subsequent investigations to explore. Nevertheless, the present investigation will provide results that can be applied to semantic theories of languages unrelated to English and suggestions about how to proceed with the construction of such theories. We may put our problem this way: What form should a semantic theory of a natural language take to accommodate in the most revealing way the facts about the semantic structure of that language supplied by descriptive research? This question is of primary importance at the present stage of the development of semantics because semantics suffers not from a dearth of facts about meanings and meaning relations in natural languages, but rather from the lack of an adequate theory to organize, systematize, and generalize these facts. Facts about the semantics of natural languages have been contributed in abundance by many diverse fields, including philosophy, linguistics, philology, and \u2026"
            },
            "slug": "The-structure-of-a-semantic-theory-Katz-Fodor",
            "title": {
                "fragments": [],
                "text": "The structure of a semantic theory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1963
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145811519"
                        ],
                        "name": "K. McRae",
                        "slug": "K.-McRae",
                        "structuredName": {
                            "firstName": "Ken",
                            "lastName": "McRae",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. McRae"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403814853"
                        ],
                        "name": "M. Spivey-Knowlton",
                        "slug": "M.-Spivey-Knowlton",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Spivey-Knowlton",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Spivey-Knowlton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144171250"
                        ],
                        "name": "M. Tanenhaus",
                        "slug": "M.-Tanenhaus",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Tanenhaus",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Tanenhaus"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 45
                            }
                        ],
                        "text": "Expectations exist both for verbs and nouns (McRae et al., 1998; McRae et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 122
                            }
                        ],
                        "text": "They compute the expectation for a word wi in a sequence by summing the first-order vectors for the words w1 to wi\u22121 and showed that the distance between expectation and first-order vector for wi correlates with human reading times."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 35
                            }
                        ],
                        "text": "Expectations affect reading times (McRae et al., 1998), the interpretation of participles (Ferretti et al., 2003), and sentence processing generally (Narayanan and Jurafsky, 2002; Pado\u0301 et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11171797,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "7a2e9d06002c40fc470b01d67c724d335e031633",
            "isKey": false,
            "numCitedBy": 622,
            "numCiting": 98,
            "paperAbstract": {
                "fragments": [],
                "text": "The time-course with which readers use event-specific world knowledge (thematic fit) to resolve structural ambiguity was explored through experiments and implementation of constraint-based and two-stage models. In a norming study, subjects completed fragments that ended in the ambiguous region of a reduced relative clause (The crook arrested/by/the/detective). Completion proportions up to and includingthewere influenced by thematic fit. The results were simulated using a competition model in which independently quantified syntactic and semantic constraints simultaneously influenced interpretation. Predictions were then generated for a self-paced reading task using model parameter values established by the off-line simulations. The pattern of reading times matched the predictions of the constraint-based version of the model but differed substantially from a one-region delay garden-path version. In addition, a garden-path model with a very short delay simulated the data better than the one-region delay model, but not as closely as the constraint-based version. The experiment and modeling illustrate that thematic fit is computed and used immediately in on-line sentence comprehension. Furthermore, the modeling highlighted the difficulty of interpreting sentence comprehension experiments without both quantifying the relevant constraints and implementing the mechanisms involved."
            },
            "slug": "Modeling-the-Influence-of-Thematic-Fit-(and-Other-McRae-Spivey-Knowlton",
            "title": {
                "fragments": [],
                "text": "Modeling the Influence of Thematic Fit (and Other Constraints) in On-line Sentence Comprehension"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793218"
                        ],
                        "name": "D. Gildea",
                        "slug": "D.-Gildea",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Gildea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gildea"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 77
                            }
                        ],
                        "text": "Mitchell and Lapata (2008) propose a framework to represent the meaning of the combination p + a as a function f operating on four components:\nc = f(p, a, R,K) (3)\nR is the relation holding between p and a, and K additional knowledge."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 267,
                                "start": 242
                            }
                        ],
                        "text": "Attention has mostly been limited to selectional preferences of verbs, which have been used for example for syntactic disambiguation (Hindle and Rooth, 1993), word sense disambiguation (McCarthy and Carroll, 2003) and semantic role labeling (Gildea and Jurafsky, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62182406,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c274b8aac56e49e65a3827c570b2496b14429166",
            "isKey": false,
            "numCitedBy": 1099,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a system for identifying the semantic relationships, or semantic roles, filled by constituents of a sentence within a semantic frame. Various lexical and syntactic features are derived from parse trees and used to derive statistical classifiers from hand-annotated training data."
            },
            "slug": "Automatic-Labeling-of-Semantic-Roles-Gildea-Jurafsky",
            "title": {
                "fragments": [],
                "text": "Automatic Labeling of Semantic Roles"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "This work presents a system for identifying the semantic relationships, or semantic roles, filled by constituents of a sentence within a semantic frame, derived from parse trees and hand-annotated training data."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3370111"
                        ],
                        "name": "Todd R Ferretti",
                        "slug": "Todd-R-Ferretti",
                        "structuredName": {
                            "firstName": "Todd",
                            "lastName": "Ferretti",
                            "middleNames": [
                                "R"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Todd R Ferretti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34830081"
                        ],
                        "name": "C. Gagn\u00e9",
                        "slug": "C.-Gagn\u00e9",
                        "structuredName": {
                            "firstName": "Christina",
                            "lastName": "Gagn\u00e9",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Gagn\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145811519"
                        ],
                        "name": "K. McRae",
                        "slug": "K.-McRae",
                        "structuredName": {
                            "firstName": "Ken",
                            "lastName": "McRae",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. McRae"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 178
                            }
                        ],
                        "text": "They compute the expectation for a word wi in a sequence by summing the first-order vectors for the words w1 to wi\u22121 and showed that the distance between expectation and first-order vector for wi correlates with human reading times."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 91
                            }
                        ],
                        "text": "Expectations affect reading times (McRae et al., 1998), the interpretation of participles (Ferretti et al., 2003), and sentence processing generally (Narayanan and Jurafsky, 2002; Pado\u0301 et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16145510,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "2b1cdee1e63853282bb3e910bd31514b20ae2dd9",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors examined how people integrate knowledge of agents and patients of events with the temporal and causal properties of present and past participles to constrain interpretation of isolated participle-noun phrases like arresting cop and arrested crook. Good-agent head nouns were more easily combined with present participles (e.g., arresting cop) than with past participles (e.g., arrested cop), and the reverse was true for good patients. Furthermore, present-participle good-patient phrases (e.g., serving customer) were often interpreted as verb phrases. This research provides further evidence of the interaction between morphosyntactic cues and world knowledge of events in language comprehension."
            },
            "slug": "Thematic-role-focusing-by-participle-inflections:-Ferretti-Gagn\u00e9",
            "title": {
                "fragments": [],
                "text": "Thematic role focusing by participle inflections: evidence from conceptual combination."
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The authors examined how people integrate knowledge of agents and patients of events with the temporal and causal properties of present and past participles to constrain interpretation of isolated participle-noun phrases like arresting cop and arrested crook."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of experimental psychology. Learning, memory, and cognition"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32222467"
                        ],
                        "name": "Carsten Brockmann",
                        "slug": "Carsten-Brockmann",
                        "structuredName": {
                            "firstName": "Carsten",
                            "lastName": "Brockmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carsten Brockmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747893"
                        ],
                        "name": "Mirella Lapata",
                        "slug": "Mirella-Lapata",
                        "structuredName": {
                            "firstName": "Mirella",
                            "lastName": "Lapata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mirella Lapata"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 257,
                                "start": 231
                            }
                        ],
                        "text": "In linguistics, expectations, in the form of selectional restrictions and selectional preferences, have long been used in semantic theories (Katz and Fodor, 1964; Wilks, 1975), and more recently induced from corpora (Resnik, 1996; Brockmann and Lapata, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 55
                            }
                        ],
                        "text": "After this set has been narrowed down in a self-inhibitory network, the meaning of the predicateargument combination is obtained by computing the\ncentroid of its members\u2019 vectors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 965246,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "8e3a93ab58a97c9cad6caf46baceb44f95ad91b8",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Previous work on the induction of selectional preferences has been mainly carried out for English and has concentrated almost exclusively on verbs and their direct objects. In this paper, we focus on class-based models of selectional preferences for German verbs and take into account not only direct objects, but also subjects and prepositional complements. We evaluate model performance against human judgments and show that there is no single method that overall performs best. We explore a variety of parametrizations for our models and demonstrate that model combination enhances agreement with human ratings."
            },
            "slug": "Evaluating-and-Combining-Approaches-to-Selectional-Brockmann-Lapata",
            "title": {
                "fragments": [],
                "text": "Evaluating and Combining Approaches to Selectional Preference Acquisition"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This paper focuses on class-based models of selectional preferences for German verbs and takes into account not only direct objects, but also subjects and prepositional complements, and demonstrates that model combination enhances agreement with human ratings."
            },
            "venue": {
                "fragments": [],
                "text": "EACL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2506104"
                        ],
                        "name": "S. Sharoff",
                        "slug": "S.-Sharoff",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Sharoff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sharoff"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15168069,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bcb0871b3d9c8b6228367b30197886d50efbc5d4",
            "isKey": false,
            "numCitedBy": 98,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper proposes a methodology for collecting \"open-source\" corpora, i.e. corpora that are automatically collected from the Internet and distributed in the form of a list of links with open-source software for recreating their full text. The result is a random snapshot of Internet pages which contain stretches of connected text in a given language. The paper discusses a methodology for acquiring such corpora, two ways of documenting them (using a set of metatextual categories and by comparison to frequency lists from existing corpora) and their function as benchmarks for comparing results of linguistic inquiry. Experiments with a variety of languages show that Internet-derived corpora can be successfully used in the absence of large representative corpora that are rare and expensive to build."
            },
            "slug": "Open-source-Corpora:-Using-the-net-to-fish-for-data-Sharoff",
            "title": {
                "fragments": [],
                "text": "Open-source Corpora: Using the net to fish for linguistic data"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Experiments with a variety of languages show that Internet-derived corpora can be successfully used in the absence of large representative corpora that are rare and expensive to build."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7465342"
                        ],
                        "name": "Ido Dagan",
                        "slug": "Ido-Dagan",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Dagan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2807469"
                        ],
                        "name": "Oren Glickman",
                        "slug": "Oren-Glickman",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Glickman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Glickman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712352"
                        ],
                        "name": "B. Magnini",
                        "slug": "B.-Magnini",
                        "structuredName": {
                            "firstName": "Bernardo",
                            "lastName": "Magnini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Magnini"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 273,
                                "start": 255
                            }
                        ],
                        "text": "It is difficult to conceive how c could encode deeper semantic properties, like predicateargument structure (distinguishing \u201cdog bites man\u201d and \u201cman bites dog\u201d), that are crucial for sentencelevel semantic tasks such as the recognition of textual entailment (Dagan et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 201
                            }
                        ],
                        "text": "We will explore the usability of vector space models of word meaning in NLP applications, formulated as the question of how to perform inferences on them in the context of the Textual Entailment task (Dagan et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In addition, the model performs at and above the state of the art for modeling the contextual adequacy of paraphrases."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8587959,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de794d50713ea5f91a7c9da3d72041e2f5ef8452",
            "isKey": false,
            "numCitedBy": 1762,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents the Third PASCAL Recognising Textual Entailment Challenge (RTE-3), providing an overview of the dataset creating methodology and the submitted systems. In creating this year's dataset, a number of longer texts were introduced to make the challenge more oriented to realistic scenarios. Additionally, a pool of resources was offered so that the participants could share common tools. A pilot task was also set up, aimed at differentiating unknown entailments from identified contradictions and providing justifications for overall system decisions. 26 participants submitted 44 runs, using different approaches and generally presenting new entailment models and achieving higher scores than in the previous challenges."
            },
            "slug": "The-PASCAL-Recognising-Textual-Entailment-Challenge-Dagan-Glickman",
            "title": {
                "fragments": [],
                "text": "The PASCAL Recognising Textual Entailment Challenge"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper presents the Third PASCAL Recognising Textual Entailment Challenge (RTE-3), providing an overview of the dataset creating methodology and the submitted systems."
            },
            "venue": {
                "fragments": [],
                "text": "MLCW"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690956"
                        ],
                        "name": "Dekang Lin",
                        "slug": "Dekang-Lin",
                        "structuredName": {
                            "firstName": "Dekang",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dekang Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 65
                            }
                        ],
                        "text": "After parsing all sentences with verbal and nominal targets with Minipar, this resulted in three\nsets of sentences: (a), target intransitive verbs with noun subjects (V-SUBJ, 48 sentences); (b), target transitive verbs with noun objects (V-OBJ, 213 sent.)"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 33
                            }
                        ],
                        "text": "We collect seen fillers from the Minipar-parse of the BNC."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 205
                            }
                        ],
                        "text": "In this space, target and context words have to be linked by a \u201cvalid\u201d dependency path in a dependency graph to count as co-occurring.2 This space was built from BNC dependency parses obtained from Minipar (Lin, 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9541345,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d431d03433275a68bd4ccd6b97af665bb979294d",
            "isKey": true,
            "numCitedBy": 202,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Overgeneration is the main source of computational complexity in previous principle-based parsers. This paper presents a message passing algorithm for principle-based parsing that avoids the overgeneration problem. This algorithm has been implemented in C++ and successfully tested with example sentences from (van Riemsdijk and Williams, 1986)."
            },
            "slug": "Principle-Based-Parsing-without-Overgeneration-Lin",
            "title": {
                "fragments": [],
                "text": "Principle-Based Parsing without Overgeneration"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A message passing algorithm for principle-based parsing that avoids the overgeneration problem is presented and has been implemented in C++ and successfully tested with example sentences from (van Riemsdijk and Williams, 1986)."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144928136"
                        ],
                        "name": "S. Narayanan",
                        "slug": "S.-Narayanan",
                        "structuredName": {
                            "firstName": "Srini",
                            "lastName": "Narayanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Narayanan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 4
                            }
                        ],
                        "text": "Predicate-argument combination."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 150
                            }
                        ],
                        "text": "Expectations affect reading times (McRae et al., 1998), the interpretation of participles (Ferretti et al., 2003), and sentence processing generally (Narayanan and Jurafsky, 2002; Pado\u0301 et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1307252,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "214f9df609f004a5e65e6a72ca8404b77f29549b",
            "isKey": false,
            "numCitedBy": 78,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Narayanan and Jurafsky (1998) proposed that human language comprehension can be modeled by treating human comprehenders as Bayesian reasoners, and modeling the comprehension process with Bayesian decision trees. In this paper we extend the Narayanan and Jurafsky model to make further predictions about reading time given the probability of difference parses or interpretations, and test the model against reading time data from a psycholinguistic experiment."
            },
            "slug": "A-Bayesian-Model-Predicts-Human-Parse-Preference-in-Narayanan-Jurafsky",
            "title": {
                "fragments": [],
                "text": "A Bayesian Model Predicts Human Parse Preference and Reading Times in Sentence Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The Narayanan and Jurafsky model is extended to make further predictions about reading time given the probability of difference parses or interpretations, and test the model against reading time data from a psycholinguistic experiment."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145503401"
                        ],
                        "name": "P. Raghavan",
                        "slug": "P.-Raghavan",
                        "structuredName": {
                            "firstName": "Prabhakar",
                            "lastName": "Raghavan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Raghavan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144418438"
                        ],
                        "name": "Hinrich Sch\u00fctze",
                        "slug": "Hinrich-Sch\u00fctze",
                        "structuredName": {
                            "firstName": "Hinrich",
                            "lastName": "Sch\u00fctze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hinrich Sch\u00fctze"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "These vectors are able to provide a robust model of semantic similarity that has been used in NLP (Salton et al., 1975; McCarthy and Carroll, 2003; Manning et al., 2008) and to model experimental results in cognitive science (Landauer and Dumais, 1997; McDonald and Ramscar, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 53807573,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "806c2c4327a31fded64a5d673ab82b133194c234",
            "isKey": false,
            "numCitedBy": 9167,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Class-tested and coherent, this textbook teaches classical and web information retrieval, including web search and the related areas of text classification and text clustering from basic concepts. It gives an up-to-date treatment of all aspects of the design and implementation of systems for gathering, indexing, and searching documents; methods for evaluating systems; and an introduction to the use of machine learning methods on text collections. All the important ideas are explained using examples and figures, making it perfect for introductory courses in information retrieval for advanced undergraduates and graduate students in computer science. Based on feedback from extensive classroom experience, the book has been carefully structured in order to make teaching more natural and effective. Slides and additional exercises (with solutions for lecturers) are also available through the book's supporting website to help course instructors prepare their lectures."
            },
            "slug": "Introduction-to-information-retrieval-Manning-Raghavan",
            "title": {
                "fragments": [],
                "text": "Introduction to information retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This textbook teaches classical and web information retrieval, including web search and the related areas of text classification and text clustering from basic concepts, making it perfect for introductory courses in information retrieval for advanced undergraduates and graduate students in computer science."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711977"
                        ],
                        "name": "Idan Szpektor",
                        "slug": "Idan-Szpektor",
                        "structuredName": {
                            "firstName": "Idan",
                            "lastName": "Szpektor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Idan Szpektor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7465342"
                        ],
                        "name": "Ido Dagan",
                        "slug": "Ido-Dagan",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Dagan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693525"
                        ],
                        "name": "Roy Bar-Haim",
                        "slug": "Roy-Bar-Haim",
                        "structuredName": {
                            "firstName": "Roy",
                            "lastName": "Bar-Haim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roy Bar-Haim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34508613"
                        ],
                        "name": "J. Goldberger",
                        "slug": "J.-Goldberger",
                        "structuredName": {
                            "firstName": "Jacob",
                            "lastName": "Goldberger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Goldberger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 108
                            }
                        ],
                        "text": "Paraphrase-based inference rules play a large role in several recent approaches to Textual Entailment (e.g. Szpektor et al (2008)); appropriateness judgments of paraphrases in context, the task of Experiments 1 and 2 above, can be viewed as testing the applicability of these inferences rules."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14802888,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "30605532d0cf1ceab85f1b5bc1b9d50acae3ecc8",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "The validity of semantic inferences depends on the contexts in which they are applied. We propose a generic framework for handling contextual considerations within applied inference, termed Contextual Preferences. This framework defines the various context-aware components needed for inference and their relationships. Contextual preferences extend and generalize previous notions, such as selectional preferences, while experiments show that the extended framework allows improving inference quality on real application data."
            },
            "slug": "Contextual-Preferences-Szpektor-Dagan",
            "title": {
                "fragments": [],
                "text": "Contextual Preferences"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This framework defines the various context-aware components needed for inference and their relationships and extends and generalizes previous notions, such as selectional preferences, while experiments show that the extended framework allows improving inference quality on real application data."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145561618"
                        ],
                        "name": "A. Yeh",
                        "slug": "A.-Yeh",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Yeh",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yeh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 293,
                                "start": 284
                            }
                        ],
                        "text": "\u2026on the size-invariant cosine similarity, the use of this model does not require normalization.\nsubject-verb pair with high- and low-similarity landmarks\nDifferences between the performance of models were tested for significance using a stratified shuffling-based randomization test (Yeh, 2000).4."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1105,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "9dcf566fa1515896ac7df2c6ff4b158536cc584f",
            "isKey": false,
            "numCitedBy": 436,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Statistical significance testing of differences in values of metrics like recall, precision and balanced F-score is a necessary part of empirical natural language processing. Unfortunately, we find in a set of experiments that many commonly used tests often underestimate the significance and so are less likely to detect differences that exist between different techniques. This underestimation comes from an independence assumption that is often violated. We point out some useful tests that do not make this assumption, including computationally-intensive randomization tests."
            },
            "slug": "More-accurate-tests-for-the-statistical-of-result-Yeh",
            "title": {
                "fragments": [],
                "text": "More accurate tests for the statistical significance of result differences"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is found in a set of experiments that many commonly used tests often underestimate the significance and so are less likely to detect differences that exist between different techniques, including computationally-intensive randomization tests."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 20
                            }
                        ],
                        "text": "The first problem concerns the manner of vector composition, which ignores the relation between the target a and its context b."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 0
                            }
                        ],
                        "text": "Smolensky (1990) uses tensor product to combine two word vectors a and b into a vector c representing the expression a+b."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 54
                            }
                        ],
                        "text": "There have been several approaches in the literature (Smolensky, 1990; Schu\u0308tze, 1998; Kintsch, 2001; McDonald and Brew, 2004; Mitchell and Lapata, 2008) that compute meaning in context from lemma vectors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 125580247,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "9438172bfbb74a6a4ea4242b180d4335bb1f18b7",
            "isKey": false,
            "numCitedBy": 642,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter contains sections titled: 1. Introduction, 2. Connectionist Representation and Tensor Product Binding: Definition and Examples, 3. Tensor Product Representation: Properties, 4. Conclusion"
            },
            "slug": "Tensor-Product-Variable-Binding-and-the-of-Symbolic-Hinton",
            "title": {
                "fragments": [],
                "text": "Tensor Product Variable Binding and the Representation of Symbolic Structures in Connectionist Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "This chapter contains sections titled connectionist Representation and Tensor Product Binding: Definition and Examples, and tensor Product Representation: Properties."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 167
                            }
                        ],
                        "text": "The second category of prior studies concentrates on contexts consisting of a single word only, typically modeling the combination of a predicate p and an argument a. Kintsch (2001) uses vector representations of p and a to identify the set of words that are similar to both p and a."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In addition, the model performs at and above the state of the art for modeling the contextual adequacy of paraphrases."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 86
                            }
                        ],
                        "text": "There have been several approaches in the literature (Smolensky, 1990; Schu\u0308tze, 1998; Kintsch, 2001; McDonald and Brew, 2004; Mitchell and Lapata, 2008) that compute meaning in context from lemma vectors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 106
                            }
                        ],
                        "text": "One proposal for \u201cscaling up\u201d is to straightforwardly interpret c = a b as the meaning of the phrase a + b (Kintsch, 2001; Mitchell and Lapata, 2008)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Predication. Cognitive Science"
            },
            "venue": {
                "fragments": [],
                "text": "Predication. Cognitive Science"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2722515"
                        ],
                        "name": "H. Levkowitz",
                        "slug": "H.-Levkowitz",
                        "structuredName": {
                            "firstName": "Haim",
                            "lastName": "Levkowitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Levkowitz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 148
                            }
                        ],
                        "text": "These vectors are able to provide a robust model of semantic similarity that has been used in NLP (Salton et al., 1975; McCarthy and Carroll, 2003; Manning et al., 2008) and to model experimental results in cognitive science (Landauer and Dumais, 1997; McDonald and Ramscar, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 2
                            }
                        ],
                        "text": "In addition, the model performs at and above the state of the art for modeling the contextual adequacy of paraphrases."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61517903,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b8b0ff62a9de3b107131f7cc9f56de0a89fc036",
            "isKey": false,
            "numCitedBy": 156,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Introduction-to-information-retrieval-(IR)-Levkowitz",
            "title": {
                "fragments": [],
                "text": "Introduction to information retrieval (IR)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 217
                            }
                        ],
                        "text": "In linguistics, expectations, in the form of selectional restrictions and selectional preferences, have long been used in semantic theories (Katz and Fodor, 1964; Wilks, 1975), and more recently induced from corpora (Resnik, 1996; Brockmann and Lapata, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Selectional constraints: An informationtheoretic model and its computational realization. Cognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 163
                            }
                        ],
                        "text": "In linguistics, expectations, in the form of selectional restrictions and selectional preferences, have long been used in semantic theories (Katz and Fodor, 1964; Wilks, 1975), and more recently induced from corpora (Resnik, 1996; Brockmann and Lapata, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 282,
                                "start": 271
                            }
                        ],
                        "text": "The second category of prior studies concentrates on contexts consisting of a single word only, typically modeling the combination of a predicate p and an argument a. Kintsch (2001) uses vector representations of p and a to identify the set of words that are similar to both p and a."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Preference semantics"
            },
            "venue": {
                "fragments": [],
                "text": "Formal Semantics of Natural Language. CUP"
            },
            "year": 1975
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 29,
            "methodology": 21
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 38,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/A-Structured-Vector-Space-Model-for-Word-Meaning-in-Erk-Pad\u00f3/cb9cc883bdd08d58feee5c7da01acff6fdb4ad78?sort=total-citations"
}