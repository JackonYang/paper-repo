{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741453"
                        ],
                        "name": "A. Culotta",
                        "slug": "A.-Culotta",
                        "structuredName": {
                            "firstName": "Aron",
                            "lastName": "Culotta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Culotta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144431938"
                        ],
                        "name": "Jeffrey Scott Sorensen",
                        "slug": "Jeffrey-Scott-Sorensen",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Sorensen",
                            "middleNames": [
                                "Scott"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeffrey Scott Sorensen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 76
                            }
                        ],
                        "text": "The shortest-path dependency kernels outperform the dependency kernel from (Culotta and Sorensen, 2004) in both scenarios, with a more significant difference for SP-CFG."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 60
                            }
                        ],
                        "text": "In the case of the tree kernels from (Zelenko et al., 2003; Culotta and Sorensen, 2004), the authors reduce each relation example to the smallest subtree in the parse or dependency tree that includes both entities."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 58
                            }
                        ],
                        "text": ", 2003) to dependency trees derived from full parse trees (Culotta and Sorensen, 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 39
                            }
                        ],
                        "text": "We also show the results presented in (Culotta and Sorensen, 2004) for their best performing kernel K4 (a sum between a bag-of-words kernel and their dependency kernel) under both scenarios."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 265,
                                "start": 239
                            }
                        ],
                        "text": "The amount of syntactic knowledge used in IE systems varies from partof-speech only (Ray and Craven, 2001) to chunking (Ray and Craven, 2001) to shallow parse trees (Zelenko et al., 2003) to dependency trees derived from full parse trees (Culotta and Sorensen, 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 4
                            }
                        ],
                        "text": "In (Culotta and Sorensen, 2004) the authors propose doing relation extraction in two steps: first, one binary SVM is trained forrelation detection, which means that all positive relation instances are combined into one class."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 3
                            }
                        ],
                        "text": "In (Culotta and Sorensen, 2004) the authors propose doing relation extraction in two steps: first, one binary SVM is trained for rela-"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 49
                            }
                        ],
                        "text": "The same tree kernel is slightly generalized in (Culotta and Sorensen, 2004) and used in conjunction with dependency trees."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 59
                            }
                        ],
                        "text": "A recent approach to extracting relations is described in (Culotta and Sorensen, 2004)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7395989,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "70a2fcfc4e78e8d6db23bf2922f18dd73162b644",
            "isKey": true,
            "numCitedBy": 865,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We extend previous work on tree kernels to estimate the similarity between the dependency trees of sentences. Using this kernel within a Support Vector Machine, we detect and classify relations between entities in the Automatic Content Extraction (ACE) corpus of news articles. We examine the utility of different features such as Wordnet hypernyms, parts of speech, and entity types, and find that the dependency tree kernel achieves a 20% F1 improvement over a \"bag-of-words\" kernel."
            },
            "slug": "Dependency-Tree-Kernels-for-Relation-Extraction-Culotta-Sorensen",
            "title": {
                "fragments": [],
                "text": "Dependency Tree Kernels for Relation Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "This work extends previous work on tree kernels to estimate the similarity between the dependency trees of sentences, and uses this kernel within a Support Vector Machine to detect and classify relations between entities in the Automatic Content Extraction (ACE) corpus of news articles."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3190501"
                        ],
                        "name": "D. Zelenko",
                        "slug": "D.-Zelenko",
                        "structuredName": {
                            "firstName": "Dmitry",
                            "lastName": "Zelenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Zelenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939759"
                        ],
                        "name": "Chinatsu Aone",
                        "slug": "Chinatsu-Aone",
                        "structuredName": {
                            "firstName": "Chinatsu",
                            "lastName": "Aone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chinatsu Aone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49754061"
                        ],
                        "name": "A. Richardella",
                        "slug": "A.-Richardella",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Richardella",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Richardella"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 63
                            }
                        ],
                        "text": "The authors use a generalized version of the tree kernel from (Zelenko et al., 2003) to compute a kernel over\nrelation examples, where a relation example consists of the smallest dependency tree containing the two entities of the relation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 4
                            }
                        ],
                        "text": "In (Zelenko et al., 2003), the authors do relation extraction using a tree kernel defined over shallow parse tree representations of sentences."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 38
                            }
                        ],
                        "text": "In the case of the tree kernels from (Zelenko et al., 2003; Culotta and Sorensen, 2004), the authors reduce each relation example to the smallest subtree in the parse or dependency tree that includes both entities."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 166
                            }
                        ],
                        "text": "The amount of syntactic knowledge used in IE systems varies from partof-speech only (Ray and Craven, 2001) to chunking (Ray and Craven, 2001) to shallow parse trees (Zelenko et al., 2003) to dependency trees derived from full parse trees (Culotta and Sorensen, 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Experiments on extracting top-level relations from the ACE (Automated Content Extraction) newspaper corpus show that the new shortest path dependency kernel outperforms a recent approach based on dependency tree kernels."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 4
                            }
                        ],
                        "text": "In (Zelenko et al., 2003), the\ntree kernel is computed inO(mn) time, wherem andn are the number of nodes in the two trees."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11074539,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cc1cad12521b5aab43fdda5b4dec67586aef1f87",
            "isKey": true,
            "numCitedBy": 919,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an application of kernel methods to extracting relations from unstructured natural language sources. We introduce kernels defined over shallow parse representations of text, and design efficient algorithms for computing the kernels. We use the devised kernels in conjunction with Support Vector Machine and Voted Perceptron learning algorithms for the task of extracting person-affiliation and organization-location relations from text. We experimentally evaluate the proposed methods and compare them with feature-based learning algorithms, with promising results."
            },
            "slug": "Kernel-Methods-for-Relation-Extraction-Zelenko-Aone",
            "title": {
                "fragments": [],
                "text": "Kernel Methods for Relation Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This work introduces kernels defined over shallow parse representations of text, and design efficient algorithms for computing the kernels, and uses the devised kernels in conjunction with Support Vector Machine and Voted Perceptron learning algorithms for the task of extracting person-affiliation and organization-location relations from text."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145527877"
                        ],
                        "name": "Soumya Ray",
                        "slug": "Soumya-Ray",
                        "structuredName": {
                            "firstName": "Soumya",
                            "lastName": "Ray",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Soumya Ray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144557047"
                        ],
                        "name": "M. Craven",
                        "slug": "M.-Craven",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Craven",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Craven"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 84
                            }
                        ],
                        "text": "The amount of syntactic knowledge used in IE systems varies from partof-speech only (Ray and Craven, 2001) to chunking (Ray and Craven, 2001) to shallow parse trees (Zelenko et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10437060,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5d2d6034c5afd4ab047fe4687d47559722142c90",
            "isKey": false,
            "numCitedBy": 154,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the application of Hidden Markov Models (HMMs) to learning information extractors for -ary relations from free text. We propose an approach to representing the grammatical structure of sentences in the states of the model. We also investigate using an objective function during HMM training which maximizes the ability of the learned models to identify the phrases of interest. We evaluate our methods by deriving extractors for two binary relations in biomedical domains. Our experiments indicate that our approach learns more accurate models than several baseline approaches."
            },
            "slug": "Representing-Sentence-Structure-in-Hidden-Markov-Ray-Craven",
            "title": {
                "fragments": [],
                "text": "Representing Sentence Structure in Hidden Markov Models for Information Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "An approach to representing the grammatical structure of sentences in the states of the model by using an objective function during HMM training which maximizes the ability of the learned models to identify the phrases of interest is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143643017"
                        ],
                        "name": "R. Levy",
                        "slug": "R.-Levy",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Levy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Levy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2029816,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "502a0987e09450129a4ab22492e69448a08bedc9",
            "isKey": false,
            "numCitedBy": 76,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a linguistically-motivated algorithm for reconstructing nonlocal dependency in broad-coverage context-free parse trees derived from treebanks. We use an algorithm based on loglinear classifiers to augment and reshape context-free trees so as to reintroduce underlying nonlocal dependencies lost in the context-free approximation. We find that our algorithm compares favorably with prior work on English using an existing evaluation metric, and also introduce and argue for a new dependency-based evaluation metric. By this new evaluation metric our algorithm achieves 60% error reduction on gold-standard input trees and 5% error reduction on state-of-the-art machine-parsed input trees, when compared with the best previous work. We also present the first results on non-local dependency reconstruction for a language other than English, comparing performance on English and German. Our new evaluation metric quantitatively corroborates the intuition that in a language with freer word order, the surface dependencies in context-free parse trees are a poorer approximation to underlying dependency structure."
            },
            "slug": "Deep-Dependencies-from-Context-Free-Statistical-the-Levy-Manning",
            "title": {
                "fragments": [],
                "text": "Deep Dependencies from Context-Free Statistical Parsers: Correcting the Surface Dependency Approximation"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A linguistically-motivated algorithm for reconstructing nonlocal dependency in broad-coverage context-free parse trees derived from treebanks is presented and a new dependency-based evaluation metric is introduced, which quantitatively corroborates the intuition that in a language with freer word order, the surface dependencies in context- free parse trees are a poorer approximation to underlying dependency structure."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "74534452"
                        ],
                        "name": "R. Campbell",
                        "slug": "R.-Campbell",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Campbell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Campbell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 167
                            }
                        ],
                        "text": "In this paper we tried extracting both types of dependencies using a CCG parser, however another approach is to recover deep dependencies from syntactic parses, as in (Campbell, 2004; Levy and Manning, 2004)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14139945,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a41a778ee93381e9bd301bfcaad6538099d40425",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes an algorithm for detecting empty nodes in the Penn Treebank (Marcus et al., 1993), finding their antecedents, and assigning them function tags, without access to lexical information such as valency. Unlike previous approaches to this task, the current method is not corpus-based, but rather makes use of the principles of early Government-Binding theory (Chomsky, 1981), the syntactic theory that underlies the annotation. Using the evaluation metric proposed by Johnson (2002), this approach outperforms previously published approaches on both detection of empty categories and antecedent identification, given either annotated input stripped of empty categories or the output of a parser. Some problems with this evaluation metric are noted and an alternative is proposed along with the results. The paper considers the reasons a principle-based approach to this problem should outperform corpus-based approaches, and speculates on the possibility of a hybrid approach."
            },
            "slug": "Using-Linguistic-Principles-to-Recover-Empty-Campbell",
            "title": {
                "fragments": [],
                "text": "Using Linguistic Principles to Recover Empty Categories"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "An algorithm for detecting empty nodes in the Penn Treebank, finding their antecedents, and assigning them function tags, without access to lexical information such as valency is described."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144105277"
                        ],
                        "name": "Wen-tau Yih",
                        "slug": "Wen-tau-Yih",
                        "structuredName": {
                            "firstName": "Wen-tau",
                            "lastName": "Yih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wen-tau Yih"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 17
                            }
                        ],
                        "text": "Recent research (Roth and Yih, 2004) indicates that integrating entity recognition with relation extraction in a global model that captures the mutual influences between the two tasks can lead to significant improvements in accuracy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10048734,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5aa70188f70d349580aed96c10a68f57dace2d33",
            "isKey": false,
            "numCitedBy": 419,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : Given a collection of discrete random variables representing outcomes of learned local predictors in natural language. e.g.. named entities and relations. we seek an optimal global assignment to the variables in the presence of general (non-sequential) constraints. Examples of these constraints include the type of arguments a relation can take, and the mutual activity of different relations. etc. We develop a linear programing formulation for this problem and evaluate it in the context of simultaneously learning named entities and relations. Our approach allows us to efficiently incorporate domain and task specific constraints at decision time, resulting in significant improvements in the accuracy and the \"human-like\" quality of the inferences."
            },
            "slug": "A-Linear-Programming-Formulation-for-Global-in-Roth-Yih",
            "title": {
                "fragments": [],
                "text": "A Linear Programming Formulation for Global Inference in Natural Language Tasks"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work develops a linear programing formulation for this problem and evaluates it in the context of simultaneously learning named entities and relations to efficiently incorporate domain and task specific constraints at decision time, resulting in significant improvements in the accuracy and the \"human-like\" quality of the inferences."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 71
                            }
                        ],
                        "text": "In our experiments, we used the full parse output from Collins\u2019 parser (Collins, 1997), in which every non-terminal node is already annotated with head information."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1345,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0ffa423a5283396c88ff3d4033d541796bd039cc",
            "isKey": false,
            "numCitedBy": 873,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we first propose a new statistical parsing model, which is a generative model of lexicalised context-free grammar. We then extend the model to include a probabilistic treatment of both subcategorisation and wh-movement. Results on Wall Street Journal text show that the parser performs at 88.1/87.5% constituent precision/recall, an average improvement of 2.3% over (Collins 96)."
            },
            "slug": "Three-Generative,-Lexicalised-Models-for-Parsing-Collins",
            "title": {
                "fragments": [],
                "text": "Three Generative, Lexicalised Models for Statistical Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "A new statistical parsing model is proposed, which is a generative model of lexicalised context-free grammar and extended to include a probabilistic treatment of both subcategorisation and wh-movement."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788050"
                        ],
                        "name": "R. Grishman",
                        "slug": "R.-Grishman",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Grishman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Grishman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2620384"
                        ],
                        "name": "B. Sundheim",
                        "slug": "B.-Sundheim",
                        "structuredName": {
                            "firstName": "Beth",
                            "lastName": "Sundheim",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sundheim"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11986411,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6723dda58e5e09089ec78ba42827b65859f030e2",
            "isKey": false,
            "numCitedBy": 1446,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "We have recently completed the sixth in a series of \"Message Understanding Conferences\" which are designed to promote and evaluate research in information extraction. MUC-6 introduced several innovations over prior MUCs, most notably in the range of different tasks for which evaluations were conducted. We describe some of the motivations for the new format and briefly discuss some of the results of the evaluations."
            },
            "slug": "Message-Understanding-Conference-6:-A-Brief-History-Grishman-Sundheim",
            "title": {
                "fragments": [],
                "text": "Message Understanding Conference- 6: A Brief History"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "MUC-6 introduced several innovations over prior MUCs, most notably in the range of different tasks for which evaluations were conducted and the motivations for the new format."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3118681"
                        ],
                        "name": "J. Hockenmaier",
                        "slug": "J.-Hockenmaier",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Hockenmaier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hockenmaier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145332819"
                        ],
                        "name": "Mark Steedman",
                        "slug": "Mark-Steedman",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Steedman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Steedman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 109
                            }
                        ],
                        "text": "In order to obtain CCG derivations for all sentences in the ACE corpus, we used the CCG parser introduced in (Hockenmaier and Steedman, 2002)3."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2876869,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "976c95f69e8ee160868b1d54d477f56212ee794b",
            "isKey": false,
            "numCitedBy": 216,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper compares a number of generative probability models for a wide-coverage Combinatory Categorial Grammar (CCG) parser. These models are trained and tested on a corpus obtained by translating the Penn Treebank trees into CCG normal-form derivations. According to an evaluation of unlabeled word-word dependencies, our best model achieves a performance of 89.9%, comparable to the figures given by Collins (1999) for a linguistically less expressive grammar. In contrast to Gildea (2001), we find a significant improvement from modeling word-word dependencies."
            },
            "slug": "Generative-Models-for-Statistical-Parsing-with-Hockenmaier-Steedman",
            "title": {
                "fragments": [],
                "text": "Generative Models for Statistical Parsing with Combinatory Categorial Grammar"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "This paper compares a number of generative probability models for a wide-coverage Combinatory Categorial Grammar (CCG) parser and finds a significant improvement from modeling word-word dependencies."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145493610"
                        ],
                        "name": "M. Kay",
                        "slug": "M.-Kay",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Kay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kay"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 69
                            }
                        ],
                        "text": "In this paper we tried extracting both types of dependencies using a CCG parser, however another approach is to recover deep dependencies from syntactic parses, as in (Campbell, 2004; Levy and Manning, 2004)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 45
                            }
                        ],
                        "text": "Special syntactic categories are assigned in CCG to lexical items that project unbounded dependencies, such as the relative pronouns \u2019who\u2019, \u2019which\u2019 and \u2019that\u2019."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 179
                            }
                        ],
                        "text": "We present in Table 5 the performance of our shortest path (SP) dependency kernel on the task of relation extraction from ACE, where the dependencies are extracted using either a CCG parser (SPCCG), or a CFG parser (SP-CFG)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 19
                            }
                        ],
                        "text": "In order to obtain CCG derivations for all sentences in the ACE corpus, we used the CCG parser introduced in (Hockenmaier and Steedman, 2002)3."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 82
                            }
                        ],
                        "text": "Mildly context sensitive formalisms such as Combinatory Categorial Grammar (CCG) (Steedman, 2000) model wordword dependencies more directly and can be used to extract both local and long-distance dependencies, giving rise to a directed acyclic graph, as illustrated in Figure 1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 120
                            }
                        ],
                        "text": "It is therefore important to design the IE system so that the input data is stripped of unnecessary features as much as possible."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 5
                            }
                        ],
                        "text": "CCG (Steedman, 2000) is a type-driven theory of grammar where most language-specific aspects of the grammar are specified into lexicon."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 58106824,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "ce8cca19455e8d3055c57a9bafe882984c95a201",
            "isKey": true,
            "numCitedBy": 911,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "In computational linguistics, which began in the 1950's with machine translation, systems that are based mainly on the lexicon have a longer t r a d i t i o n than anything e l se f o r these purposes, twenty f i ve years must be allowed to count as a tradition. The bulk of many of the early translation systems was made up by a d ic t ionary whose ent r ies consisted of a rb i t ra ry ins t ruc t ions In machine language. In the early 60's, computational llnsulsts---at least those with theoretical pretentlons---abandoned this way of doing business for at least three related reasons:"
            },
            "slug": "Syntactic-Process-Kay",
            "title": {
                "fragments": [],
                "text": "Syntactic Process"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "In computational linguistics, which began in the 1950's with machine translation, systems that are based mainly on the lexicon have a longer lifespan than anything else, so twenty years must be allowed to count as a tradition."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34615574"
                        ],
                        "name": "B. Richards",
                        "slug": "B.-Richards",
                        "structuredName": {
                            "firstName": "Bradley",
                            "lastName": "Richards",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Richards"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 976718,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "652f701013c73c28dd182b1acc2aed8583addb6c",
            "isKey": false,
            "numCitedBy": 169,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "First-order learning systems (e.g., FOIL, FOCL, FORTE) generally rely on hill-climbing heuristics in order to avoid the combinatorial explosion inherent in learning first-order concepts. However, hill-climbing leaves these systems vulnerable to local maxima and local plateaus. We present a method, called relational pathfinding, which has proven highly effective in escaping local maxima and crossing local plateaus. We present our algorithm and provide learning results in two domains: family relationships and qualitative model building."
            },
            "slug": "Learning-Relations-by-Pathfinding-Richards-Mooney",
            "title": {
                "fragments": [],
                "text": "Learning Relations by Pathfinding"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work presents a method, called relational pathfinding, which has proven highly effective in escaping local maxima and crossing local plateaus, and provides learning results in two domains: family relationships and qualitative model building."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685083"
                        ],
                        "name": "N. Cristianini",
                        "slug": "N.-Cristianini",
                        "structuredName": {
                            "firstName": "Nello",
                            "lastName": "Cristianini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cristianini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404459229"
                        ],
                        "name": "J. Shawe-Taylor",
                        "slug": "J.-Shawe-Taylor",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shawe-Taylor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shawe-Taylor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Here we can exploit dual learning algorithms that process examples only via computing their dot-products, such as the Support Vector Machines (SVMs) (Vapnik, 1998; Cristianini and Shawe-Taylor, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 163
                            }
                        ],
                        "text": "Here we can exploitdual learning algorithms that process examples only via computing their dot-products, such as the Support Vector Machines (SVMs) (Vapnik, 1998; Cristianini and Shawe-Taylor, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14727192,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5c04f8002e24a8c09bfbfedca3c6c346fe1e5d53",
            "isKey": false,
            "numCitedBy": 13352,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "From the publisher: This is the first comprehensive introduction to Support Vector Machines (SVMs), a new generation learning system based on recent advances in statistical learning theory. SVMs deliver state-of-the-art performance in real-world applications such as text categorisation, hand-written character recognition, image classification, biosequences analysis, etc., and are now established as one of the standard tools for machine learning and data mining. Students will find the book both stimulating and accessible, while practitioners will be guided smoothly through the material required for a good grasp of the theory and its applications. The concepts are introduced gradually in accessible and self-contained stages, while the presentation is rigorous and thorough. Pointers to relevant literature and web sites containing software ensure that it forms an ideal starting point for further study. Equally, the book and its associated web site will guide practitioners to updated literature, new applications, and on-line software."
            },
            "slug": "An-Introduction-to-Support-Vector-Machines-and-Cristianini-Shawe-Taylor",
            "title": {
                "fragments": [],
                "text": "An Introduction to Support Vector Machines and Other Kernel-based Learning Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "This is the first comprehensive introduction to Support Vector Machines (SVMs), a new generation learning system based on recent advances in statistical learning theory, and will guide practitioners to updated literature, new applications, and on-line software."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Here we can exploit dual learning algorithms that process examples only via computing their dot-products, such as the Support Vector Machines (SVMs) (Vapnik, 1998; Cristianini and Shawe-Taylor, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 149
                            }
                        ],
                        "text": "Here we can exploitdual learning algorithms that process examples only via computing their dot-products, such as the Support Vector Machines (SVMs) (Vapnik, 1998; Cristianini and Shawe-Taylor, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 28637672,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "385197d4c02593e2823c71e4f90a0993b703620e",
            "isKey": false,
            "numCitedBy": 26320,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "A comprehensive look at learning and generalization theory. The statistical theory of learning and generalization concerns the problem of choosing desired functions on the basis of empirical data. Highly applicable to a variety of computer science and robotics fields, this book offers lucid coverage of the theory as a whole. Presenting a method for determining the necessary and sufficient conditions for consistency of learning process, the author covers function estimates from small data pools, applying these estimations to real-life problems, and much more."
            },
            "slug": "Statistical-learning-theory-Vapnik",
            "title": {
                "fragments": [],
                "text": "Statistical learning theory"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Presenting a method for determining the necessary and sufficient conditions for consistency of learning process, the author covers function estimates from small data pools, applying these estimations to real-life problems, and much more."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 116
                            }
                        ],
                        "text": "We applied the shortest path dependency kernel to the problem of extracting top-level relations from the ACE corpus (NIST, 2000), the version used for the September 2002 evaluation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 125
                            }
                        ],
                        "text": "Consequently, IE corpora are typically annotated with information corresponding to these subtasks (MUC (Grishman, 1995), ACE (NIST, 2000)), facilitating the development of systems that target only one or a subset of the three problems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 101
                            }
                        ],
                        "text": "Precision and recall values are reported for the task of extracting the 5 top-level relations in the ACE corpus under two different scenarios:\n\u2013 [S1] This is the classic setting: one multi-class SVM is learned to discriminate among the 5 toplevel classes, plus one more class for the no-relation cases."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 89
                            }
                        ],
                        "text": "In Table 1 we show the paths corresponding to the four relation instances encoded in the ACE corpus for the two sentences from Figure 1."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 55
                            }
                        ],
                        "text": "Experiments on extracting top-level relations from the ACE (Automated Content Extraction) newspaper corpus show that the new shortest path dependency kernel outperforms a recent approach based on dependency tree kernels."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 122
                            }
                        ],
                        "text": "We present in Table 5 the performance of our shortest path (SP) dependency kernel on the task of relation extraction from ACE, where the dependencies are extracted using either a CCG parser (SPCCG), or a CFG parser (SP-CFG)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 60
                            }
                        ],
                        "text": "In order to obtain CCG derivations for all sentences in the ACE corpus, we used the CCG parser introduced in (Hockenmaier and Steedman, 2002)3."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 20
                            }
                        ],
                        "text": "This version of the ACE corpus contains three types of annotations: coreference, named entities and relations."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 103
                            }
                        ],
                        "text": "In this paper we focus exclusively on extracting relations between predefined types of entities in the ACE corpus."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 67
                            }
                        ],
                        "text": "Comparative experiments on extracting top-level relations from the ACE corpus show significant improvements over a recent dependency tree kernel."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 32
                            }
                        ],
                        "text": "However, because \u2019vans\u2019 is not an ACE markable, it cannot participate in an annotated relationship."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 74
                            }
                        ],
                        "text": "In Figure 1 we show the full dependency graphs for two sentences from the ACE newspaper corpus."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 71
                            }
                        ],
                        "text": "We can see this happening also in the task of relation extraction from ACE, where \u201cimportant concepts\u201d are the 5 types of relations, and the \u201cconstants\u201d defining a positive instance are the 5 types of entities."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 41
                            }
                        ],
                        "text": "Figure 1 shows two sample sentences from ACE, with entity mentions in bold."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "ACE \u2013 Automatic Content Extraction"
            },
            "venue": {
                "fragments": [],
                "text": "http://www.nist.gov/speech/tests/ace."
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 63
                            }
                        ],
                        "text": "The authors use a generalized version of the tree kernel from (Zelenko et al., 2003) to compute a kernel over\nrelation examples, where a relation example consists of the smallest dependency tree containing the two entities of the relation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 62
                            }
                        ],
                        "text": "The authors use a generalized version of the tree kernel from (Zelenko et al., 2003) to compute a kernel over"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 4
                            }
                        ],
                        "text": "In (Zelenko et al., 2003), the authors do relation extraction using a tree kernel defined over shallow parse tree representations of sentences."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 38
                            }
                        ],
                        "text": "In the case of the tree kernels from (Zelenko et al., 2003; Culotta and Sorensen, 2004), the authors reduce each relation example to the smallest subtree in the parse or dependency tree that includes both entities."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 166
                            }
                        ],
                        "text": "The amount of syntactic knowledge used in IE systems varies from partof-speech only (Ray and Craven, 2001) to chunking (Ray and Craven, 2001) to shallow parse trees (Zelenko et al., 2003) to dependency trees derived from full parse trees (Culotta and Sorensen, 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 4
                            }
                        ],
                        "text": "In (Zelenko et al., 2003), the\ntree kernel is computed inO(mn) time, wherem andn are the number of nodes in the two trees."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Kernel methods for relation extraction.Journal of Machine Learning Research"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Kernel methods for relation extraction.Journal of Machine Learning Research"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 149
                            }
                        ],
                        "text": "Here we can exploit dual learning algorithms that process examples only via computing their dot-products, such as the Support Vector Machines (SVMs) (Vapnik, 1998; Cristianini and Shawe-Taylor, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 149
                            }
                        ],
                        "text": "Here we can exploitdual learning algorithms that process examples only via computing their dot-products, such as the Support Vector Machines (SVMs) (Vapnik, 1998; Cristianini and Shawe-Taylor, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "1998.Statistical Learning Theory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 103
                            }
                        ],
                        "text": "Consequently, IE corpora are typically annotated with information corresponding to these subtasks (MUC (Grishman, 1995), ACE (NIST, 2000)), facilitating the development of systems that target only one or a subset of the three problems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Message Understanding Conference 6"
            },
            "venue": {
                "fragments": [],
                "text": "http://cs.nyu.edu/cs/faculty/grishman/muc6.html."
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "1998.Statistical Learning Theory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 8,
            "methodology": 11
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 19,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/A-Shortest-Path-Dependency-Kernel-for-Relation-Bunescu-Mooney/8a8832216fa59867aab8bb98270763fc2de3d8d8?sort=total-citations"
}