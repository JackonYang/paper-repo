{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784512"
                        ],
                        "name": "A. Vashist",
                        "slug": "A.-Vashist",
                        "structuredName": {
                            "firstName": "Akshay",
                            "lastName": "Vashist",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vashist"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3254812"
                        ],
                        "name": "Natalya Pavlovitch",
                        "slug": "Natalya-Pavlovitch",
                        "structuredName": {
                            "firstName": "Natalya",
                            "lastName": "Pavlovitch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Natalya Pavlovitch"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14846870,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1d5a28680bf61c2da909d4df900c0e796446081a",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we consider a new paradigm of learning: learning using hidden information. The classical paradigm of the supervised learning is to learn a decision rule from labeled data (x<inf>i</inf>, y<inf>i</inf>), x<inf>i</inf> \u2208 X, y<inf>i</inf> \u2208 {\u22121, 1}, i = 1, \u2026, \u2113. In this paper we consider a new setting: given training vectors in space X along with labels and description of this data in another space X<sup>*</sup>, find in space X a decision rule better than the one found in the classical paradigm."
            },
            "slug": "Learning-using-hidden-information-(Learning-with-Vapnik-Vashist",
            "title": {
                "fragments": [],
                "text": "Learning using hidden information (Learning with teacher)"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A new setting is considered: given training vectors in space X along with labels and description of this data in another space X, find in spaceX a decision rule better than the one found in the classical paradigm."
            },
            "venue": {
                "fragments": [],
                "text": "2009 International Joint Conference on Neural Networks"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143977260"
                        ],
                        "name": "E. Xing",
                        "slug": "E.-Xing",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Xing",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Xing"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145107462"
                        ],
                        "name": "Stuart J. Russell",
                        "slug": "Stuart-J.-Russell",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Russell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stuart J. Russell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2643381,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d1a2d203733208deda7427c8e20318334193d9d7",
            "isKey": false,
            "numCitedBy": 3025,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Many algorithms rely critically on being given a good metric over their inputs. For instance, data can often be clustered in many \"plausible\" ways, and if a clustering algorithm such as K-means initially fails to find one that is meaningful to a user, the only recourse may be for the user to manually tweak the metric until sufficiently good clusters are found. For these and other applications requiring good metrics, it is desirable that we provide a more systematic way for users to indicate what they consider \"similar.\" For instance, we may ask them to provide examples. In this paper, we present an algorithm that, given examples of similar (and, if desired, dissimilar) pairs of points in \u211dn, learns a distance metric over \u211dn that respects these relationships. Our method is based on posing metric learning as a convex optimization problem, which allows us to give efficient, local-optima-free algorithms. We also demonstrate empirically that the learned metrics can be used to significantly improve clustering performance."
            },
            "slug": "Distance-Metric-Learning-with-Application-to-with-Xing-Ng",
            "title": {
                "fragments": [],
                "text": "Distance Metric Learning with Application to Clustering with Side-Information"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper presents an algorithm that, given examples of similar (and, if desired, dissimilar) pairs of points in \ufffd\u201dn, learns a distance metric over \u211dn that respects these relationships."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732280"
                        ],
                        "name": "Gal Chechik",
                        "slug": "Gal-Chechik",
                        "structuredName": {
                            "firstName": "Gal",
                            "lastName": "Chechik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gal Chechik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777660"
                        ],
                        "name": "Naftali Tishby",
                        "slug": "Naftali-Tishby",
                        "structuredName": {
                            "firstName": "Naftali",
                            "lastName": "Tishby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naftali Tishby"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 114
                            }
                        ],
                        "text": "The idea of using additional information formatrix learningwas considered in the unsupervised learning framework (Chechik & Tishby, 2002; Xing, Ng, Jordan, & Russell, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11448230,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb6c16a826441df21b6792d895500b2c4f4ed449",
            "isKey": false,
            "numCitedBy": 104,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of extracting the relevant aspects of data, in face of multiple conflicting structures, is inherent to modeling of complex data. Extracting structure in one random variable that is relevant for another variable has been principally addressed recently via the information bottleneck method [15]. However, such auxiliary variables often contain more information than is actually required due to structures that are irrelevant for the task. In many other cases it is in fact easier to specify what is irrelevant than what is, for the task at hand. Identifying the relevant structures, however, can thus be considerably improved by also minimizing the information about another, irrelevant, variable. In this paper we give a general formulation of this problem and derive its formal, as well as algorithmic, solution. Its operation is demonstrated in a synthetic example and in two real world problems in the context of text categorization and face images. While the original information bottleneck problem is related to rate distortion theory, with the distortion measure replaced by the relevant information, extracting relevant features while removing irrelevant ones is related to rate distortion with side information."
            },
            "slug": "Extracting-Relevant-Structures-with-Side-Chechik-Tishby",
            "title": {
                "fragments": [],
                "text": "Extracting Relevant Structures with Side Information"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper gives a general formulation of this problem and derives its formal, as well as algorithmic, solution and its operation is demonstrated in a synthetic example and in two real world problems in the context of text categorization and face images."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145675811"
                        ],
                        "name": "Sayan Mukherjee",
                        "slug": "Sayan-Mukherjee",
                        "structuredName": {
                            "firstName": "Sayan",
                            "lastName": "Mukherjee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sayan Mukherjee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781874"
                        ],
                        "name": "E. Osuna",
                        "slug": "E.-Osuna",
                        "structuredName": {
                            "firstName": "Edgar",
                            "lastName": "Osuna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Osuna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804489"
                        ],
                        "name": "F. Girosi",
                        "slug": "F.-Girosi",
                        "structuredName": {
                            "firstName": "Federico",
                            "lastName": "Girosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Girosi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 45
                            }
                        ],
                        "text": "To predict if x(t + T ) > x(t) we use (as in Mukherjee et al. (1997)) a four dimensional vector of observations on time series xt = (x(t \u2212 3), x(t \u2212 2), x(t \u2212 1), x(t))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 9
                            }
                        ],
                        "text": "Article (Mukherjee et al., 1997) considered one step ahead prediction problem (T = 1)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 100
                            }
                        ],
                        "text": "Below to compare the LUPI paradigm with the SVM, we use the same parameters as used in the article (Mukherjee et al., 1997) where it has been demonstrated that SVM outperformsmany classical algorithms for time series prediction."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 15
                            }
                        ],
                        "text": "In contrast to Mukherjee et al. (1997), we used the pattern recognition setting rather than the regression setting."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16950792,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d81512c6c2582fa91fe151efdaf80a867f66d12a",
            "isKey": true,
            "numCitedBy": 548,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "A novel method for regression has been recently proposed by Vapnik et al. (1995, 1996). The technique, called support vector machine (SVM), is very well founded from the mathematical point of view and seems to provide a new insight in function approximation. We implemented the SVM and tested it on a database of chaotic time series previously used to compare the performances of different approximation techniques, including polynomial and rational approximation, local polynomial techniques, radial basis functions, and neural networks. The SVM performs better than the other approaches. We also study, for a particular time series, the variability in performance with respect to the few free parameters of SVM."
            },
            "slug": "Nonlinear-prediction-of-chaotic-time-series-using-Mukherjee-Osuna",
            "title": {
                "fragments": [],
                "text": "Nonlinear prediction of chaotic time series using support vector machines"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The SVM is implemented and tested on a database of chaotic time series previously used to compare the performances of different approximation techniques, including polynomial and rational approximation, localPolynomial techniques, radial basis functions, and neural networks; the SVM performs better than the other approaches."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks for Signal Processing VII. Proceedings of the 1997 IEEE Signal Processing Society Workshop"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145115014"
                        ],
                        "name": "Corinna Cortes",
                        "slug": "Corinna-Cortes",
                        "structuredName": {
                            "firstName": "Corinna",
                            "lastName": "Cortes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Corinna Cortes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 52874011,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "52b7bf3ba59b31f362aa07f957f1543a29a4279e",
            "isKey": false,
            "numCitedBy": 33420,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "The support-vector network is a new learning machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very high-dimension feature space. In this feature space a linear decision surface is constructed. Special properties of the decision surface ensures high generalization ability of the learning machine. The idea behind the support-vector network was previously implemented for the restricted case where the training data can be separated without errors. We here extend this result to non-separable training data.High generalization ability of support-vector networks utilizing polynomial input transformations is demonstrated. We also compare the performance of the support-vector network to various classical learning algorithms that all took part in a benchmark study of Optical Character Recognition."
            },
            "slug": "Support-Vector-Networks-Cortes-Vapnik",
            "title": {
                "fragments": [],
                "text": "Support-Vector Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "High generalization ability of support-vector networks utilizing polynomial input transformations is demonstrated and the performance of the support- vector network is compared to various classical learning algorithms that all took part in a benchmark study of Optical Character Recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2219581"
                        ],
                        "name": "B. Boser",
                        "slug": "B.-Boser",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Boser",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Boser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743797"
                        ],
                        "name": "I. Guyon",
                        "slug": "I.-Guyon",
                        "structuredName": {
                            "firstName": "Isabelle",
                            "lastName": "Guyon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Guyon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207165665,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2599131a4bc2fa957338732a37c744cfe3e17b24",
            "isKey": false,
            "numCitedBy": 10832,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "A training algorithm that maximizes the margin between the training patterns and the decision boundary is presented. The technique is applicable to a wide variety of the classification functions, including Perceptrons, polynomials, and Radial Basis Functions. The effective number of parameters is adjusted automatically to match the complexity of the problem. The solution is expressed as a linear combination of supporting patterns. These are the subset of training patterns that are closest to the decision boundary. Bounds on the generalization performance based on the leave-one-out method and the VC-dimension are given. Experimental results on optical character recognition problems demonstrate the good generalization obtained when compared with other learning algorithms."
            },
            "slug": "A-training-algorithm-for-optimal-margin-classifiers-Boser-Guyon",
            "title": {
                "fragments": [],
                "text": "A training algorithm for optimal margin classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A training algorithm that maximizes the margin between the training patterns and the decision boundary is presented, applicable to a wide variety of the classification functions, including Perceptrons, polynomials, and Radial Basis Functions."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '92"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2676309"
                        ],
                        "name": "C. Burges",
                        "slug": "C.-Burges",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Burges",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Burges"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60502900,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9c4da62e9e89e65ac78ee271e424e8b498053e8c",
            "isKey": false,
            "numCitedBy": 5546,
            "numCiting": 260,
            "paperAbstract": {
                "fragments": [],
                "text": "Introduction to support vector learning roadmap. Part 1 Theory: three remarks on the support vector method of function estimation, Vladimir Vapnik generalization performance of support vector machines and other pattern classifiers, Peter Bartlett and John Shawe-Taylor Bayesian voting schemes and large margin classifiers, Nello Cristianini and John Shawe-Taylor support vector machines, reproducing kernel Hilbert spaces, and randomized GACV, Grace Wahba geometry and invariance in kernel based methods, Christopher J.C. Burges on the annealed VC entropy for margin classifiers - a statistical mechanics study, Manfred Opper entropy numbers, operators and support vector kernels, Robert C. Williamson et al. Part 2 Implementations: solving the quadratic programming problem arising in support vector classification, Linda Kaufman making large-scale support vector machine learning practical, Thorsten Joachims fast training of support vector machines using sequential minimal optimization, John C. Platt. Part 3 Applications: support vector machines for dynamic reconstruction of a chaotic system, Davide Mattera and Simon Haykin using support vector machines for time series prediction, Klaus-Robert Muller et al pairwise classification and support vector machines, Ulrich Kressel. Part 4 Extensions of the algorithm: reducing the run-time complexity in support vector machines, Edgar E. Osuna and Federico Girosi support vector regression with ANOVA decomposition kernels, Mark O. Stitson et al support vector density estimation, Jason Weston et al combining support vector and mathematical programming methods for classification, Bernhard Scholkopf et al."
            },
            "slug": "Advances-in-kernel-methods:-support-vector-learning-Sch\u00f6lkopf-Burges",
            "title": {
                "fragments": [],
                "text": "Advances in kernel methods: support vector learning"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Support vector machines for dynamic reconstruction of a chaotic system, Klaus-Robert Muller et al pairwise classification and support vector machines, Ulrich Kressel."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782193"
                        ],
                        "name": "Ingo Steinwart",
                        "slug": "Ingo-Steinwart",
                        "structuredName": {
                            "firstName": "Ingo",
                            "lastName": "Steinwart",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ingo Steinwart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143790221"
                        ],
                        "name": "C. Scovel",
                        "slug": "C.-Scovel",
                        "structuredName": {
                            "firstName": "Clint",
                            "lastName": "Scovel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Scovel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 190
                            }
                        ],
                        "text": "However for special constructions of the correcting space X\u2217 (for example, that satisfies the conditions defined by Tsybakov (2004) or the conditions defined by Steinwart and Scovel for SVM (Steinwart & Scovel, 2004)) the convergence can be faster (O([1/`]\u03b1), \u03b1 > 1/2)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 21735238,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "98ad27e2f4060e9bd7aed02b6facf9557edcba08",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We establish learning rates to the Bayes risk for support vector machines (SVM\u2019s) with hinge loss. Since a theorem of Devroye states that no learning algorithm can learn with a uniform rate to the Bayes risk for all probability distributions we have to restrict the class of considered distributions: in order to obtain fast rates we assume a noise condition recently proposed by Tsybakov and an approximation condition in terms of the distribution and the reproducing kernel Hilbert space used by the SVM. For Gaussian RBF kernels with varying widths we propose a geometric noise assumption on the distribution which ensures the approximation condition. This geometric assumption is not in terms of smoothness but describes the concentration of the marginal distribution near the decision boundary. In particular we are able to describe nontrivial classes of distributions for which SVM\u2019s using a Gaussian kernel can learn with almost linear rate. AMS classification: primary 68Q32, secondary 62G20, 62G99, 68T05, 68T10, 41A46, 41A99"
            },
            "slug": "When-do-Support-Vector-Machines-learn-fast-Steinwart-Scovel",
            "title": {
                "fragments": [],
                "text": "When do Support Vector Machines learn fast ?"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A geometric noise assumption is proposed on the distribution which ensures the approximation condition and nontrivial classes of distributions for which SVM\u2019s using a Gaussian kernel can learn with almost linear rate are described."
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69401379"
                        ],
                        "name": "A. Tsybakov",
                        "slug": "A.-Tsybakov",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Tsybakov",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Tsybakov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 115
                            }
                        ],
                        "text": "However for special constructions of the correcting space X\u2217 (for example, that satisfies the conditions defined by Tsybakov (2004) or the conditions defined by Steinwart and Scovel for SVM (Steinwart & Scovel, 2004)) the convergence can be faster (O([1/`]\u03b1), \u03b1 > 1/2)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16400015,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "a77888e8042df733280f4f017a2d42950d9a7b0f",
            "isKey": false,
            "numCitedBy": 694,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Classification can be considered as nonparametric estimation of sets, where the risk is defined by means of a specific distance between sets associated with misclassification error. It is shown that the rates of convergence of classifiers depend on two parameters: the complexity of the class of candidate sets and the margin parameter. The dependence is explicitly given, indicating that optimal fast rates approaching O(n -1 ) can be attained, where n is the sample size, and that the proposed classifiers have the property of robustness to the margin. The main result of the paper concerns optimal aggregation of classifiers: we suggest a classifier that automatically adapts both to the complexity and to the margin, and attains the optimal fast rates, up to a logarithmic factor."
            },
            "slug": "Optimal-aggregation-of-classifiers-in-statistical-Tsybakov",
            "title": {
                "fragments": [],
                "text": "Optimal aggregation of classifiers in statistical learning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The main result of the paper concerns optimal aggregation of classifiers: a classifier that automatically adapts both to the complexity and to the margin, and attains the optimal fast rates, up to a logarithmic factor."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145039030"
                        ],
                        "name": "J. Platt",
                        "slug": "J.-Platt",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Platt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Platt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 55
                            }
                        ],
                        "text": "Consider onemore idea of using privileged information defined by the training vectors\n(x1, x\u22171, y1), . . . , (x`, x \u2217 `, y`)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 59
                            }
                        ],
                        "text": "(2) For both the problems there exist effective solutions (Platt, 1998; Vapnik, 1995, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 577580,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "53fcc056f79e04daf11eb798a7238e93699665aa",
            "isKey": false,
            "numCitedBy": 2853,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a new algorithm for training support vector machines: Sequential Minimal Optimization, or SMO. Training a support vector machine requires the solution of a very large quadratic programming (QP) optimization problem. SMO breaks this large QP problem into a series of smallest possible QP problems. These small QP problems are solved analytically, which avoids using a time-consuming numerical QP optimization as an inner loop. The amount of memory required for SMO is linear in the training set size, which allows SMO to handle very large training sets. Because matrix computation is avoided, SMO scales somewhere between linear and quadratic in the training set size for various test problems, while the standard chunking SVM algorithm scales somewhere between linear and cubic in the training set size. SMO\u2019s computation time is dominated by SVM evaluation, hence SMO is fastest for linear SVMs and sparse data sets. On realworld sparse data sets, SMO can be more than 1000 times faster than the chunking algorithm."
            },
            "slug": "Sequential-Minimal-Optimization-:-A-Fast-Algorithm-Platt",
            "title": {
                "fragments": [],
                "text": "Sequential Minimal Optimization : A Fast Algorithm for Training Support Vector Machines"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1807167"
                        ],
                        "name": "R. Kuang",
                        "slug": "R.-Kuang",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Kuang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kuang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2042413"
                        ],
                        "name": "Eugene Ie",
                        "slug": "Eugene-Ie",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Ie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eugene Ie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48884646"
                        ],
                        "name": "Ke Wang",
                        "slug": "Ke-Wang",
                        "structuredName": {
                            "firstName": "Ke",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ke Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2148896417"
                        ],
                        "name": "Kai Wang",
                        "slug": "Kai-Wang",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2058219787"
                        ],
                        "name": "Mahira Siddiqi",
                        "slug": "Mahira-Siddiqi",
                        "structuredName": {
                            "firstName": "Mahira",
                            "lastName": "Siddiqi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mahira Siddiqi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703537"
                        ],
                        "name": "Y. Freund",
                        "slug": "Y.-Freund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Freund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3209133"
                        ],
                        "name": "C. Leslie",
                        "slug": "C.-Leslie",
                        "structuredName": {
                            "firstName": "Christina",
                            "lastName": "Leslie",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Leslie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14032548,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "572487e1968d1717fb3f1f92c9e50e6a5c6fa87e",
            "isKey": false,
            "numCitedBy": 245,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce novel profile-based string kernels for use with support vector machines (SVMs) for the problems of protein classification and remote homology detection. These kernels use probabilistic profiles, such as those produced by the PSI-BLAST algorithm, to define position-dependent mutation neighborhoods along protein sequences for inexact matching of k-length subsequences (\"k-mers\") in the data. By use of an efficient data structure, the kernels are fast to compute once the profiles have been obtained. For example, the time needed to run PSI-BLAST in order to build the profiles is significantly longer than both the kernel computation time and the SVM training time. We present remote homology detection experiments based on the SCOP database where we show that profile-based string kernels used with SVM classifiers strongly outperform all recently presented supervised SVM methods. We also show how we can use the learned SVM classifier to extract \"discriminative sequence motifs\" - short regions of the original profile that contribute almost all the weight of the SVM classification score - and show that these discriminative motifs correspond to meaningful structural features in the protein data. The use of PSI-BLAST profiles can be seen as a semi-supervised learning technique, since PSI-BLAST leverages unlabeled data from a large sequence database to build more informative profiles. Recently presented \"cluster kernels \" give general semi-supervised methods for improving SVM protein classification performance. We show that our profile kernel results are comparable to cluster kernels while providing much better scalability to large datasets."
            },
            "slug": "Profile-based-string-kernels-for-remote-homology-Kuang-Ie",
            "title": {
                "fragments": [],
                "text": "Profile-based string kernels for remote homology detection and motif extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "Novel profile-based string kernels for use with support vector machines (SVMs) for the problems of protein classification and remote homology detection are introduced and it is shown that the profile kernel results are comparable to cluster kernels while providing much better scalability to large datasets."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 2004 IEEE Computational Systems Bioinformatics Conference, 2004. CSB 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143931058"
                        ],
                        "name": "Li Liao",
                        "slug": "Li-Liao",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Liao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Liao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144458655"
                        ],
                        "name": "William Stafford Noble",
                        "slug": "William-Stafford-Noble",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Noble",
                            "middleNames": [
                                "Stafford"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William Stafford Noble"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1111309,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "0ec64d06ff98230bc6b4c94bbe5212d479dfbbe9",
            "isKey": false,
            "numCitedBy": 175,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "One key element in understanding the molecular machinery of the cell is to understand the meaning, or function, of each protein encoded in the genome. A very successful means of inferring the function of a previously unannotated protein is via sequence similarity with one or more proteins whose functions are already known. Currently, one of the most powerful such homology detection methods is the SVM-Fisher method of Jaakkola, Diekhans and Haussler (ISMB 2000). This method combines a generative, profile hidden Markov model (HMM) with a discriminative classification algorithm known as a support vector machine (SVM). The current work presents an alternative method for SVM-based protein classification. The method, SVM-pairwise, uses a pairwise sequence similarity algorithm such as Smith-Waterman in place of the HMM in the SVM-Fisher method. The resulting algorithm, when tested on its ability to recognize previously unseen families from the SCOP database, yields significantly better remote protein homology detection than SVM-Fisher, profile HMMs and PSI-BLAST."
            },
            "slug": "Combining-pairwise-sequence-similarity-and-support-Liao-Noble",
            "title": {
                "fragments": [],
                "text": "Combining pairwise sequence similarity and support vector machines for remote protein homology detection"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The current work presents an alternative method for SVM-based protein classification that uses a pairwise sequence similarity algorithm such as Smith-Waterman in place of the HMM in the S VM-Fisher method, and yields significantly better remote protein homology detection."
            },
            "venue": {
                "fragments": [],
                "text": "RECOMB '02"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782193"
                        ],
                        "name": "Ingo Steinwart",
                        "slug": "Ingo-Steinwart",
                        "structuredName": {
                            "firstName": "Ingo",
                            "lastName": "Steinwart",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ingo Steinwart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 238,
                                "start": 207
                            }
                        ],
                        "text": "However first let us make the following remark: It is known that well defined learning algorithms (say SVM with a universal kernel) converge, with increasing number of observations, to the Bayesian solution (Steinwart, 2002; Vapnik, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 208
                            }
                        ],
                        "text": "However first let us make the following remark:\nIt is known that well defined learning algorithms (say SVM with a universal kernel) converge, with increasing number of observations, to the Bayesian solution (Steinwart, 2002; Vapnik, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6337970,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6dc89a5bf39cc05113e1ad2b8ddbbcd1e737be62",
            "isKey": false,
            "numCitedBy": 175,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We show that support vector machines of the 1-norm soft margin type are universally consistent provided that the regularization parameter is chosen in a distinct manner and the kernel belongs to a specific class-the so-called universal kernels-which has recently been considered by the author. In particular it is shown that the 1-norm soft margin classifier with Gaussian RBF kernel on a compact subset X of Rd and regularization parameter cn = n\u03b2-1 is universally consistent, if n is the training set size and 0 >\u03b2> 1/d."
            },
            "slug": "Support-Vector-Machines-are-Universally-Consistent-Steinwart",
            "title": {
                "fragments": [],
                "text": "Support Vector Machines are Universally Consistent"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "It is shown that the 1-norm soft margin classifier with Gaussian RBF kernel on a compact subset X of Rd and regularization parameter cn = n\u03b2-1 is universally consistent, if n is the training set size and 0 >\u03b2> 1/d."
            },
            "venue": {
                "fragments": [],
                "text": "J. Complex."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145884505"
                        ],
                        "name": "V. Cherkassky",
                        "slug": "V.-Cherkassky",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Cherkassky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Cherkassky"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 189
                            }
                        ],
                        "text": "The basic idea of SVM is to find the optimal separating hyperplane, the one that makes a small number of training errors and possesses a largemargin (Boser, Guyon, & Vapnik, 1992; Cortes & Vapnik, 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 72
                            }
                        ],
                        "text": "(2) For both the problems there exist effective solutions (Platt, 1998; Vapnik, 1995, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 174
                            }
                        ],
                        "text": "In RSVM we consider the following setting: we minimize the functional\nR(w, b) = 1 2 (w,w)+ C \u2211\u0300 i=1 |yi \u2212 (w, zi)\u2212 b|\u03b5,\nwhere u\u03b5 is the so-called \u03b5-insensitive function introduced in Vapnik (1995): u\u03b5 = 0 if |u| \u2264 \u03b5 and u\u03b5 = u if |u| > \u03b5."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 32
                            }
                        ],
                        "text": "For detail on the SVMmethod see Vapnik (1995, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 82
                            }
                        ],
                        "text": "(In the space X this hyperplane corresponds to some non-linear function (Cortes & Vapnik, 1995; Vapnik, 1998))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206755547,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "e64fecbaf4d75e0dd6711f8f335c8a53da9fd360",
            "isKey": true,
            "numCitedBy": 3182,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "If you really want to be smarter, reading can be one of the lots ways to evoke and realize. Many people who like reading will have more knowledge and experiences. Reading can be a way to gain information from economics, politics, science, fiction, literature, religion, and many others. As one of the part of book categories, the nature of statistical learning theory always becomes the most wanted book. Many people are absolutely searching for this book. It means that many love to read this kind of book."
            },
            "slug": "The-Nature-Of-Statistical-Learning-Theory-Cherkassky",
            "title": {
                "fragments": [],
                "text": "The Nature Of Statistical Learning Theory"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "As one of the part of book categories, the nature of statistical learning theory always becomes the most wanted book."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 72
                            }
                        ],
                        "text": "(2) For both the problems there exist effective solutions (Platt, 1998; Vapnik, 1995, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 237,
                                "start": 225
                            }
                        ],
                        "text": "However first let us make the following remark:\nIt is known that well defined learning algorithms (say SVM with a universal kernel) converge, with increasing number of observations, to the Bayesian solution (Steinwart, 2002; Vapnik, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 32
                            }
                        ],
                        "text": "For detail on the SVMmethod see Vapnik (1995, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 96
                            }
                        ],
                        "text": "(In the space X this hyperplane corresponds to some non-linear function (Cortes & Vapnik, 1995; Vapnik, 1998))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 149
                            }
                        ],
                        "text": "\u2026by the equation\nw = \u2211\u0300 i=1 yi\u03b1izi,\nand therefore the decision function sgn[(w, z)+ b] is defined as (w, z)+ b = \u2211\u0300 i=1 yi\u03b1i(zi, z)+ b. (17)\nSince according to Mercer\u2019s theorem (Vapnik, 1998) for any inner product in Z space there exists a positive definite function (kernel) K(xi, xj) such\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 28637672,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "385197d4c02593e2823c71e4f90a0993b703620e",
            "isKey": false,
            "numCitedBy": 26320,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "A comprehensive look at learning and generalization theory. The statistical theory of learning and generalization concerns the problem of choosing desired functions on the basis of empirical data. Highly applicable to a variety of computer science and robotics fields, this book offers lucid coverage of the theory as a whole. Presenting a method for determining the necessary and sufficient conditions for consistency of learning process, the author covers function estimates from small data pools, applying these estimations to real-life problems, and much more."
            },
            "slug": "Statistical-learning-theory-Vapnik",
            "title": {
                "fragments": [],
                "text": "Statistical learning theory"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Presenting a method for determining the necessary and sufficient conditions for consistency of learning process, the author covers function estimates from small data pools, applying these estimations to real-life problems, and much more."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2865389"
                        ],
                        "name": "A. Murzin",
                        "slug": "A.-Murzin",
                        "structuredName": {
                            "firstName": "Alexey",
                            "lastName": "Murzin",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Murzin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3329398"
                        ],
                        "name": "S. Brenner",
                        "slug": "S.-Brenner",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Brenner",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Brenner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8126949"
                        ],
                        "name": "T. Hubbard",
                        "slug": "T.-Hubbard",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Hubbard",
                            "middleNames": [
                                "J.",
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hubbard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2216149"
                        ],
                        "name": "C. Chothia",
                        "slug": "C.-Chothia",
                        "structuredName": {
                            "firstName": "Cyrus",
                            "lastName": "Chothia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Chothia"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6869184,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5ef2cf7b7aa6f7e44488d5db5409ef7f76b9ef9a",
            "isKey": false,
            "numCitedBy": 6453,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "SCOP:-a-structural-classification-of-proteins-for-Murzin-Brenner",
            "title": {
                "fragments": [],
                "text": "SCOP: a structural classification of proteins database for the investigation of sequences and structures."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of molecular biology"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48747133"
                        ],
                        "name": "A. Ortiz",
                        "slug": "A.-Ortiz",
                        "structuredName": {
                            "firstName": "Angel",
                            "lastName": "Ortiz",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ortiz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144465303"
                        ],
                        "name": "C. Strauss",
                        "slug": "C.-Strauss",
                        "structuredName": {
                            "firstName": "Charlie",
                            "lastName": "Strauss",
                            "middleNames": [
                                "E.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Strauss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2886611"
                        ],
                        "name": "O. Olmea",
                        "slug": "O.-Olmea",
                        "structuredName": {
                            "firstName": "O.",
                            "lastName": "Olmea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Olmea"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 35422800,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "b6df329e1f595da06f198556b92ad3e04ce4511b",
            "isKey": false,
            "numCitedBy": 519,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Advances in structural genomics and protein structure prediction require the design of automatic, fast, objective, and well benchmarked methods capable of comparing and assessing the similarity of low\u2010resolution three\u2010dimensional structures, via experimental or theoretical approaches. Here, a new method for sequence\u2010independent structural alignment is presented that allows comparison of an experimental protein structure with an arbitrary low\u2010resolution protein tertiary model. The heuristic algorithm is given and then used to show that it can describe random structural alignments of proteins with different folds with good accuracy by an extreme value distribution. From this observation, a structural similarity score between two proteins or two different conformations of the same protein is derived from the likelihood of obtaining a given structural alignment by chance. The performance of the derived score is then compared with well established, consensus manual\u2010based scores and data sets. We found that the new approach correlates better than other tools with the gold standard provided by a human evaluator. Timings indicate that the algorithm is fast enough for routine use with large databases of protein models. Overall, our results indicate that the new program (MAMMOTH) will be a good tool for protein structure comparisons in structural genomics applications. MAMMOTH is available from our web site at http://physbio.mssm.edu/\u223cortizg/."
            },
            "slug": "MAMMOTH-(Matching-molecular-models-obtained-from-An-Ortiz-Strauss",
            "title": {
                "fragments": [],
                "text": "MAMMOTH (Matching molecular models obtained from theory): An automated method for model comparison"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A new method for sequence\u2010independent structural alignment is presented that allows comparison of an experimental protein structure with an arbitrary low\u2010resolution protein tertiary model and finds that the new approach correlates better than other tools with the gold standard provided by a human evaluator."
            },
            "venue": {
                "fragments": [],
                "text": "Protein science : a publication of the Protein Society"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143931058"
                        ],
                        "name": "Li Liao",
                        "slug": "Li-Liao",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Liao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Liao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144458655"
                        ],
                        "name": "William Stafford Noble",
                        "slug": "William-Stafford-Noble",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Noble",
                            "middleNames": [
                                "Stafford"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William Stafford Noble"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2912265,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "174e2900e9b08a657d360fb51607f96b8ec133da",
            "isKey": false,
            "numCitedBy": 358,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "One key element in understanding the molecular machinery of the cell is to understand the structure and function of each protein encoded in the genome. A very successful means of inferring the structure or function of a previously unannotated protein is via sequence similarity with one or more proteins whose structure or function is already known. Toward this end, we propose a means of representing proteins using pairwise sequence similarity scores. This representation, combined with a discriminative classification algorithm known as the support vector machine (SVM), provides a powerful means of detecting subtle structural and evolutionary relationships among proteins. The algorithm, called SVM-pairwise, when tested on its ability to recognize previously unseen families from the SCOP database, yields significantly better performance than SVM-Fisher, profile HMMs, and PSI-BLAST."
            },
            "slug": "Combining-Pairwise-Sequence-Similarity-and-Support-Liao-Noble",
            "title": {
                "fragments": [],
                "text": "Combining Pairwise Sequence Similarity and Support Vector Machines for Detecting Remote Protein Evolutionary and Structural Relationships"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A means of representing proteins using pairwise sequence similarity scores, combined with a discriminative classification algorithm known as the support vector machine (SVM), provides a powerful means of detecting subtle structural and evolutionary relationships among proteins."
            },
            "venue": {
                "fragments": [],
                "text": "J. Comput. Biol."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 189
                            }
                        ],
                        "text": "The basic idea of SVM is to find the optimal separating hyperplane, the one that makes a small number of training errors and possesses a largemargin (Boser, Guyon, & Vapnik, 1992; Cortes & Vapnik, 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 72
                            }
                        ],
                        "text": "(2) For both the problems there exist effective solutions (Platt, 1998; Vapnik, 1995, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 174
                            }
                        ],
                        "text": "In RSVM we consider the following setting: we minimize the functional\nR(w, b) = 1 2 (w,w)+ C \u2211\u0300 i=1 |yi \u2212 (w, zi)\u2212 b|\u03b5,\nwhere u\u03b5 is the so-called \u03b5-insensitive function introduced in Vapnik (1995): u\u03b5 = 0 if |u| \u2264 \u03b5 and u\u03b5 = u if |u| > \u03b5."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 32
                            }
                        ],
                        "text": "For detail on the SVMmethod see Vapnik (1995, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 82
                            }
                        ],
                        "text": "(In the space X this hyperplane corresponds to some non-linear function (Cortes & Vapnik, 1995; Vapnik, 1998))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7138354,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8213dbed4db44e113af3ed17d6dad57471a0c048",
            "isKey": false,
            "numCitedBy": 38755,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Setting of the learning problem consistency of learning processes bounds on the rate of convergence of learning processes controlling the generalization ability of learning processes constructing learning algorithms what is important in learning theory?."
            },
            "slug": "The-Nature-of-Statistical-Learning-Theory-Vapnik",
            "title": {
                "fragments": [],
                "text": "The Nature of Statistical Learning Theory"
            },
            "venue": {
                "fragments": [],
                "text": "Statistics for Engineering and Information Science"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5216020"
                        ],
                        "name": "M. Casdagli",
                        "slug": "M.-Casdagli",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Casdagli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Casdagli"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 112
                            }
                        ],
                        "text": "There exist many articles devoted to the prediction of the Mackey-Glass time series using different algorithms (Casdagli, 1989; Mukherjee, Osuna, & Girosi, 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 122236599,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "be946457d3f880d9ec836aee3d0d231ffa3bcc9a",
            "isKey": false,
            "numCitedBy": 1398,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Nonlinear-prediction-of-chaotic-time-series-Casdagli",
            "title": {
                "fragments": [],
                "text": "Nonlinear prediction of chaotic time series"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679221"
                        ],
                        "name": "H. Berman",
                        "slug": "H.-Berman",
                        "structuredName": {
                            "firstName": "Helen",
                            "lastName": "Berman",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Berman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34819339"
                        ],
                        "name": "J. Westbrook",
                        "slug": "J.-Westbrook",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Westbrook",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Westbrook"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2272834"
                        ],
                        "name": "Zukang Feng",
                        "slug": "Zukang-Feng",
                        "structuredName": {
                            "firstName": "Zukang",
                            "lastName": "Feng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zukang Feng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1848948"
                        ],
                        "name": "G. Gilliland",
                        "slug": "G.-Gilliland",
                        "structuredName": {
                            "firstName": "Gary",
                            "lastName": "Gilliland",
                            "middleNames": [
                                "L"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Gilliland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145506090"
                        ],
                        "name": "T. Bhat",
                        "slug": "T.-Bhat",
                        "structuredName": {
                            "firstName": "Talapady",
                            "lastName": "Bhat",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Bhat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3309680"
                        ],
                        "name": "H. Weissig",
                        "slug": "H.-Weissig",
                        "structuredName": {
                            "firstName": "Helge",
                            "lastName": "Weissig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Weissig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145522"
                        ],
                        "name": "I. Shindyalov",
                        "slug": "I.-Shindyalov",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Shindyalov",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Shindyalov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2048644"
                        ],
                        "name": "P. Bourne",
                        "slug": "P.-Bourne",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Bourne",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bourne"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 78
                            }
                        ],
                        "text": "The 3D-structures for SCOP sequences are available at PDB (Protein Data Bank) (Berman et al., 2000) We focused on determining homology based on protein amino-acid sequences from different superfamilies (third level of hierarchy)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8721150,
            "fieldsOfStudy": [
                "Chemistry"
            ],
            "id": "548fe25043edbe4539c68550383875466ed0d777",
            "isKey": false,
            "numCitedBy": 31037,
            "numCiting": 93,
            "paperAbstract": {
                "fragments": [],
                "text": "The Protein Data Bank [PDB; Berman, Westbrook et al. (2000), Nucleic Acids Res. 28, 235-242; http://www.pdb.org/] is the single worldwide archive of primary structural data of biological macromolecules. Many secondary sources of information are derived from PDB data. It is the starting point for studies in structural bioinformatics. This article describes the goals of the PDB, the systems in place for data deposition and access, how to obtain further information and plans for the future development of the resource. The reader should come away with an understanding of the scope of the PDB and what is provided by the resource."
            },
            "slug": "The-Protein-Data-Bank-Berman-Westbrook",
            "title": {
                "fragments": [],
                "text": "The Protein Data Bank"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "The goals of the PDB are described, the systems in place for data deposition and access, how to obtain further information and plans for the future development of the resource are described."
            },
            "venue": {
                "fragments": [],
                "text": "Nucleic Acids Res."
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 220722344,
            "fieldsOfStudy": [],
            "id": "aee6ec255f608c840b4c9480a34ff99a83ab78d9",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Estimation of Dependences Based on Empirical Data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784512"
                        ],
                        "name": "A. Vashist",
                        "slug": "A.-Vashist",
                        "structuredName": {
                            "firstName": "Akshay",
                            "lastName": "Vashist",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vashist"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3254812"
                        ],
                        "name": "Natalya Pavlovitch",
                        "slug": "Natalya-Pavlovitch",
                        "structuredName": {
                            "firstName": "Natalya",
                            "lastName": "Pavlovitch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Natalya Pavlovitch"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 71
                            }
                        ],
                        "text": "For every training image we created its holistic (poetic) description (Vapnik et al., 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 159
                            }
                        ],
                        "text": "We used 100 examples of 10\u00d710 images as a training set, 4000 as a validation set (for tuning the parameters in SVM and SVM+) and the rest 1866 as the test set (Vapnik et al., 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 146120484,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1a74cb1e44e84d68aac43e1fee9c53e4a8596f4b",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-using-hidden-information:-Master-class-Vapnik-Vashist",
            "title": {
                "fragments": [],
                "text": "Learning using hidden information: Master-class learning"
            },
            "venue": {
                "fragments": [],
                "text": "NATO ASI Mining Massive Data Sets for Security"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "114788213"
                        ],
                        "name": "D. Signorini",
                        "slug": "D.-Signorini",
                        "structuredName": {
                            "firstName": "DavidF.",
                            "lastName": "Signorini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Signorini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4137433"
                        ],
                        "name": "J. Slattery",
                        "slug": "J.-Slattery",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Slattery",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Slattery"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2058057862"
                        ],
                        "name": "S. Dodds",
                        "slug": "S.-Dodds",
                        "structuredName": {
                            "firstName": "Sally",
                            "lastName": "Dodds",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dodds"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51934565"
                        ],
                        "name": "V. Lane",
                        "slug": "V.-Lane",
                        "structuredName": {
                            "firstName": "V",
                            "lastName": "Lane",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Lane"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2095059657"
                        ],
                        "name": "P. Littlejohns",
                        "slug": "P.-Littlejohns",
                        "structuredName": {
                            "firstName": "P",
                            "lastName": "Littlejohns",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Littlejohns"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 2878979,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "20b844e395355b40fa5940c61362ec40e56027aa",
            "isKey": false,
            "numCitedBy": 4703,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Neural-networks-Signorini-Slattery",
            "title": {
                "fragments": [],
                "text": "Neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "The Lancet"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 145
                            }
                        ],
                        "text": "\u2026h is the VC dimension of the set of admissible hyperplanes while for the non-separable case one can guarantee only O( \u221a h/`) rate of convergence (Vapnik, 1982\u2013 2006, 1998) (since choosing the slacks is equivalent to choosing a slack-function \u03c6(x, \u03b4\u2217) from the set \u03c6(x, \u03b4), \u03b4 \u2208 \u2206 which defines\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Estimation of dependencies based on empirical data. In Empirical inference science"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 8,
            "methodology": 6
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 25,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/A-new-learning-paradigm:-Learning-using-privileged-Vapnik-Vashist/58059409e131f2a854367052636138e835f14f60?sort=total-citations"
}